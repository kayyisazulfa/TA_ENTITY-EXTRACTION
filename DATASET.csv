title,full_text,task,methods,data_set,matrix_evaluation
SENTIMEN ANALISIS PUBLIK TERHADAP  KEBIJAKAN LOCKDOWN PEMERINTAH JAKARTA MENGGUNAKAN ALGORITMA  SVM ,"SENTIMEN ANALISIS PUBLIK TERHADAP  KEBIJAKAN LOCKDOWN PEMERINTAH JAKARTA MENGGUNAKAN ALGORITMA  SVM 

Auliya Rahman Isnain 1), Adam Indra Sakti 2), Debby Alita 3), Nurman Satya Marga 4) 

Abstract 
Social media makes people experience a shift in behavior, both culture, ethics, and existing norms so that they can express their opinions. The opinion is an opinion from the public's thinking about a problem that is happening, currently, Indonesia is being faced with a problem regarding the Covid -19 virus which has taken so many lives so that people issue their opinions about the virus and th e policies implemented by the government to deal with the virus. This study aims to determine how public sentiment is on policies that will be carried out by the government regarding lockdown policies or large -scale social restrictions using the Support V e ctor Machine method with the extraction of the TF-IDF feature with testing which will see the accuracy, precision, recall, and F1-Score values. The use of the Support V ector Machine method and feature extraction with TF -IDF which divides the class into p ositive sentiment 68.75% and negative 31.25% results in an accuracy value of 74%, precision of 75%, recall of 92% and F1 -Score of 83 %.  

Keyword : Sentiment Analysis, Support V ector Machine, Tf -idf, Twitter, Lockdown, Covid-19 

Abstrak  
Media sosial menjadikan masyarakat mengalami pergeseran perilaku baik budaya, etika dan norma  yang ada, sehingga mereka dapat mengeluarkan opini-opini yang mereka miliki. Opini merupakan suatu pendapat dari pemikiran masayarakat mengenai suatu permasalahan yang sedang terjadi, saat ini Indonesia sedang dihadapkan oleh masalah mengenai virus Covid -19 yang memakan begitu banyak korban jiwa sehingga masyarakat mengeluarkan opini mereka mengenai virus tersebut dan kebijakan yang dilakukan pemerintah menghadapi virus tersebut. Penelitian ini bertujuan untuk mengetahui bagaimana sentiment publik terhadap kebijakan yang akan dilakukan pemerintah mengenai kebijakan lockdown ataupun pembatasan sosial berskala besar menggunakan metode Support Vector Machine denga ekstraksi fitur tf-idf  dengan pengujian 
yang nantinya akan dilihat bagaimana nilai accuracy, precision, Recall dan F1 -Score.  Penggunaan metode Support Vector Machine dan ekstraksi fitur dengan tf-idf yang membagi kelas menjadi sentiment positif 68,75% dan negative 31,25%  menghasilkan nilai accuracy  sebesar 74%, precision  sebesar 75%, recall  sebesar 92% dan F1-Score sebesar 83% . 

Kata Kunci:  Sentiment Analisis, Support Vector Machine, Tf-idf, Twitter, Lockdown, Covid-19 

1. Pendahuluan   
Lahirnya media sosial menjadikan pola perilaku masyarakat mengalami pergeseran baik budaya, etika dan norma yang ada, sehingga dari berbagai kalangan dan usia semua masyarakat Indonesia memiliki dan menggunakan media sosial sebagai salah satu sarana guna memperoleh dan menyampaikan informasi ke 
masyarakat [1]. Saat ini media sosial sebagai media komunikasi telah menjadi bagian penting dalam kehidupan masyarakat luas sehari -hari [2], dengan munculnya media sosial telah merubah cara pemikiran sesorang dalam mengekspresikan pendapat.  Selain itu, 
teknologi internet juga berperan aktif  dalam masyarakat mengakses informasi dari manapun [3]. Dari hasil survey yang dilakukan oleh Asosiasi Penyelenggara Jasa Internet Indonesia (APJII) tahun 2018, mengungkapkan bahwa jumlah penduduk Indonesia mencapai 264,16 juta jiwa, dari jumlah tersebut sebanyak 171,17 juta adalah pengguna internet atau sebanyak 64,8 % dari populasi penduduk Indonesia. Meningkatnya aktivitas  pengguna di media sosial ini tidak menutup kemungkinan akan adanya saran, pendapat ataupun tanggapan dari masyarakat luas mengenai sesuatu yang sedang terjadi [4]. Twitter merupakan media sosial yang dapat dipakai oleh berbagai pihak untuk mengekspresikan pendapat mereka secara bebas [5]. Saat ini Twitter merupakan sebuah media sosial yan g baik untuk memberikan pengaruh dalam penelitian [6] Namun sejauh ini masih belum banyak aplikasi dan metode sentiment analisis  yang dikembangkan untuk bahasa Indonesia, hal tersebut yang mendorong perlunya dilakukan sentiment analisis untuk dokumen bahasa Indonesia. Penelitian sentiment analisis ini dilakukan untuk mengetahui sentiment mengenai sesuatu dengan menggunakan pendekatan dalam machine learning  yang dikenal dengan nama support vect or machine  yang dikhususkan dengan dokumen teks berbahasa Indonesia. Pemilihan metode support vector machine  dalam penelitian ini karena memiliki kemampuan generalisasi dalam mengklasifikasikan suatu pattern , dan tidak termasuk data yang dipakai dalam fase  pembelajaran metode tersebut [7]. 

2. Landasan Teori  
2.1 Text Mining  
Text mining merupakan bagian dari  data mining, yaitu proses untuk memperoleh suatu pengetahuan menggunakan seperangkat alat analisis dimana pengguna berinteraksi dengan sekumpulan dokumen dari waktu ke waktu. Seperti halnya data mining, text mining  berusaha untuk mengekstraksi informasi d ari suatu sumber data (sekumpulan dokumen) melalui identifikasi dan eksplorasi pola yang ada. Teks mining merupakan teknik yang digunakan untuk menangani classification, information extraction dan information retrieval. Konsep teks mining yang digunakan da lam klasifikasi yaitu 
dokumen tekstual dengan tujuan unuk megkasifikasi doumen yang sesuai dengan topic pembahasan. Perbedaan antara  data mining  dan text mining  terletak pada prepocessing, pada data mining prepocessing berfokus pada penomoran (indexing) d an normalisasi data, sedangkan text mining berfokus pada identifikasi dan ekstraksi fitur [8] 
2.2 Text Preprocessing  
Dalam melakukan text mining, text  dokumen harus dilakukan persiapan terlebih dahulu sehingga dapat digunakan untuk proses utama. Proses mempersiapkan text atau data mentah ini disebut text preprocessing. Text preprocessing berfungsi mengubah data yang tidak terstruktur menjadi terstruktur (Han dan Kamber, 2006). 
Proses yang dilakukan dalam preprocessing adalah 
sebagai berikut :  
a. Case folding, merupakan proses merubah kalimat data teks menjadi seragam  
b. Cleansing, yaitu proses membersihkan dokumen dan menyeleksi kata yang tidak diperlukan seperti html, emoticon, hashtag, mention dan url.  
c. Stopwords, yaitu menghilangkan kata yang kurang efektif  
d. Steaming,  yaitu proses untuk menyaring kata yang terdapat kata sambung, kata ganti, kata depan, menjadi kata dasar dengan menghilangkan awalan atau akhiran.  
e. Tokenization,  merupakan proses seleksi pemotongan kata dalam kalimat. Diberikan pemisah seperti tanda koma ( ,), titik (.), dan tanda pemisah lainnya.  
 2.3 Sentiment Analysis  
Sentiment Analisis adalah sentiment dari teks subjektif tersebut menganalisis, memproses, meringkas dan proses inferensial. Sentiment analisis saat ini dibagi menjadi penggunaan klasifikasi pembelajaran mesin dan metode klasifikasi berdasarkan aturan, metode pembelajaran mesin menggunakan kata kata emosi sebagai klasifikasi fitur, dan kamus emosi dapat digunakan untukmewujudkan pemilihan karakteristik sentiment dengan cepat dan efisien. Dalam kombinasi dengan pengklasifikasian dalam menyelesaikan tugas  
metode yang umumnya digunakan adalah Naive Bayes (NB), Support Vector Machine (SVM) dan Entropi Maksimum (EM)  [9]. 
 2.4 Support Vector Machine  
Support Vector Machine  merupakan sistem pembelajaran yang menggunakan hipotesis berupa fungsi-fungsi linear dalam sebuah fitur yang berdimensi tinggi dan dilatih dengan menggunakan algoritma pembelajaran yang didasarkan dengan teori optimasi [10] Support Vector Machine diperkenalkan pertama kali oleh Vapnik pada tahun 1992 s ebagai rangkaian harmonis konsep konsep unggulan dalam bidang pattern recognition [11] Tingkat akurasi pada model yang akan dihasilkan oleh proses peralihan pada svm sangat bergantung pada fungsi kernel dan parameter yang digunakan.  Berdasarkan dengan karakteristiknya metode SVM dibagi menjadi dua yaitu linear dan non linear, SVM linear merupakan data yang dipisahkan secara linear yaitu memsiahkan dua kelas p ada hyperplane dengan soft margin. Sedangkan non linear yaitu merupakan fungsi dari kernel trick terhadap ruang yang berdimensi tinggi [12]. SVM sangat cepat dan efektif untuk masalah klasifikasi teks, dalam istilah geometris sebuah klasifikasi biner dapat dilihat sebagai hyperplane dalam ruang fitur yang memisahkan tiitk -titik yang mewakili contoh positif dari kategori yang mewakili keadaan negative. Klasifikasi ini dipilih selama pelatihan sebagai hyperplane  unik yang memisahkan instance positif yang diketahui dari instance  negative, dalam kalsifikasi SVM memiliki keungulan penting dalam 
pendekatan teorinya yang dibenarkan atas masalah overfitting  yang memungkinkannya bekerja dengan baik [8].  Support V ector Machine  menggunakan 2 titik (vector) yang selanjutnya dua titik tersebut akan membentuk garis pembatas (sisi pembatas jika 3 dimensi atau lebih) garis pembatas yang dibentuk dari da u buah vector ini disebut hyperplane.  
Gambar 1 Hyperplane memisahkan dua kelas.  
Dua titik yang menjadi patokan hyperplane disebut dengan support vector. Dapat dilihat bahwa memiliki dua kelompok data yang disebut klasifikasi, kemudian tugas SVM adalah membagi dua kelompok ini sebaik mungkin atau menentukan hyperplane terbaik, pembagian dimana garis batasnya dapat memisahkan dua kelompok dengan jarak terjauh antara titik terluar di masing masing kelompok dengan garis pembatas itu sendiri [13]. Permasalahan non linear dapat diatasi dengan memodifikasi trick kernel  ke dalam SVM yang akan menjadi pemisah kelas atau hyperplane menjadi dua kelas didalam ruang vector dalam penelitian ini kernel yang akan digunakan adalah kernel linear.  Seperti yang dapat dilihat persamaannya pada Tabel 1 di bawah ini.  
Tabel 1 Rumus Kernel  
Jenis  Kernel  Model  
Linear  ð¾(ð‘¥.ð‘¥â€²)=ð‘¥.ð‘¥â€² 
Polynomial  ð¾(ð‘¥.ð‘¥â€²)=(ð‘¥.ð‘¥â€²+ð‘)â€² 
RBF 
Gaussian  ð¾(ð‘¥.ð‘¥â€²)=expâ¡(âˆ’ð›¾||ð‘¥âˆ’ð‘¥â€²||2) 
Siqmoid  ð¾(ð‘¥.ð‘¥â€²)=tanh(ð›¼ð‘¥.ð‘¥â€²+ð›½) 
 
3. Metode Penelitian  
Pada Penelitian ini terdapat beberapa tahapan yang dilakukan untuk menyelesaikan penelitian ini dapat 
dilihat pada Gambar 2.  
Gambar 2 Tahapan Penelitian  
3.1 Crawling  
Crawling merupakan proses pengunduhan data yang berfungsi sebagai pengumpulan dataset dan menjadi tahap awal dalam penelitian ini. Data yang dikumpulkan berupa data tweet berbahasa Indonesia mengenai kebijakan lockdown atau pembatasan wilayah yang dilakukan oleh pemerintah Jakarta demi menangani Covid-19. Dari hasil pengambilan data tersebut yang berjumlah 2000 data yang selanjutnya perlu dilakukan pengolahan agar menjadi data yang lebih mudah digunakan dalam proses sentiment analisis.  
Tabel 2 Hasil Crawling  
Hasil Crawling  
@diaraherlina : Jangan nunggu korban lebih banyak gerak sekarang, tegas dan melihat visi yang lebih jauh Kesal sama para pelanggar psbb !! https://t.co/NfhnfMjtXw  
Haruskah Indonesia lockdown 
Sebenernya psbb ini efektif gak sih 
Indonesia terserah  
Dukung lockdown Jakarta !!  
3.2 Preprocessing  Dalam Preprocessing data, kita perlu melakukan 
pembersihan data dengan tujuan supaya data digunakan 
dapat digunakan pada tahap selanjutnya. Adapaun tahapan yang dilakukan pada penelitian ini adalah Menghilangkan teks html, case folding, cleansing, stemming, stopword, dan tokenisasi.  
3.3 Seleksi Fitur  
Pada tahap ini untuk meningkatkan kinerja classifier yang berguna untuk meningkatkan akurasi dan mengurangi waktu komputasi. Dalam hal ini fitur yang digunakan yaitu TF -IDF. Dapat dilihat padaTabel 3 data training.  
Tabel 3 Data Training  
Dokumen  Tweet  
D1 jangan nunggu korban lebih banyak gerak sekarang tegas lihat visi lebih jauh  
D2 kesal sama para pelanggar psbb  
D3 haruskah Indonesia lockdown  
D4 sebenarnya psbb ini efektif gak sih  
D5 indonesia terserah  
D6 dukung lockdown Jakarta  
Perhitungan TF -IDF 
Tabel 4 Perhitungan TF-IDF 
Term  TF IDF D1 D2 D3 D4 D5 D6 
Korban  1 0 0 0 0 0 0.778  
Banyak  1 0 0 0 0 0 0.778  
Gerak  1 0 0 0 0 0 0.778  
Tegas  1 0 0 0 0 0 0.778  
Kesal  1 0 0 0 0 0 0.778  
Para 1 0 0 0 0 0 0.778  
Pelanggar  1 0 0 0 0 0 0.778  
Psbb  0 1 0 1 0 0 0.477  
Indonesia  0 1 0 0 1 0 0.477  
Lockdown  0 0 1 0 0 1 0.477  
Jakarta  0 0 0 0 0 1 0.778  
Keterangan :  
TF(D)  = jumlah kata di setiap dokumen-D 
IDF = log (D/df)  
3.4 Traning and Testing  
Training merupakan tahapan pada algoritma SVM untuk menyesuaikan data yang telah melewati tahap cleansing dan preprocessing sehingga dapat mencapai set data yang telah ditentukan. Training akan digunakan untuk pembuatan model machine learning sementara testing  berguna untuk menguji  performa pada metode Support Vector Machine.  
a. Data training yang digunakan adalah data yang telah melakukan proses labeling  secara manual oleh peneliti yang akan ditemukan nilai dari perkata, dan nilai ini yang akan digunakan sebagai data masukan untuk proses training  dan testing.  
b. Data training yang digunakan adalah data yang telah melakukan proses labeling  secara manual oleh peneliti yan g akan ditemukan nilai dari perkata, dan nilai ini yang akan digunakan sebagai data masukan untuk proses training  dan testing.  
3.5 Klasifikasi  
Klasifikasi di penelitian ini menggunakan metode Support Vector Machine  dengan seleksi fitur. Seleksi fitur dalam pe ngklasifikasian diharapkan dapat lebih efisien dengan mengurangi jumlah data yang di analisis dengan mengidentifikasi fitur yang selanjutnya akan diproses berdasarkan model classifier yang telah dihasilkan dari proses training pada penelitian ini data dibagi menjadi dua bagian yaitu data training dan data testing langkah ynag dilakukan dalam penelitina ini adalah sebagai berikut:  
1. Menginisiasi nilai awal untuk nilai Î±, C, epsilon gamma dan lamda  
Î± = 0, C = 1, epsilon  = 0,001, gamma  = 0,5, lamda  = 0,5 
2. Memasukkan data training  (latih) berdasarkan kemunculan keyword dalam satu kalimat. 
3. Menentukan dot product  setiap data dengan memasukkan fungsi kernel [K]. Rumus fungsi kernel yang umum sama pada Tabel 1. fungsi kernel yang digunakan adalah fungsi linear . Sebelumnya data di transpose karena menggunakan perkalian matriks 
AxAT seperti Tabel 5:  
Tabel 5 Transpose Dat a 
D1 D2 D3 D4 D5 D6 
1 0 0 0 0 0 
1 0 0 0 0 0 
1 0 0 0 0 0 
1 0 0 0 0 0 
1 0 0 0 0 0 
1 0 0 0 0 0 
1 0 0 0 0 0 
1 0 0 1 0 0 
0 1 0 0 1 0 
0 1 1 0 0 0 
0 0 0 0 0 1 
Pada metode kernel data tidak direpresentasikan secara individu, melainkan melalui perbandingan antara sepasang data. setiap data akan dibandingkan pada dirinya dan kata lain.  
4. Menghitung matriks dengan rumus :  
Dij = y i yj (K(x i.xj) + ð›ŒðŸ) 
Dij = elemen matriks ke i j  
yi = kelas data ke -i 
yj = kelas data ke -j 
Î» = batas teoritis  
Contoh perhitungan D1 dengan D1 :  
Dij = [1] [1] [ 8] + 0,5Ë† 2 = 5,25  
5. Mencari nilai error dengan rumus :  
Ei =  âˆ‘ð‘—ð‘– = 1 Î± j Dij 
Dimana Ei = nilai error data ke-i 
Î±j= 0,5 
E1 = (0,5*8,25) + (0,5*0,25) + (0,5*0,25) + 
(0,5*1,25) + (0,5*0,25) +  (0.5*0,25)  = 5,25    
6. Menghitung nilai delta alpha  
Î´Î±i = min{max[Î³(1 -Ei) â€“ Î±i] C â€“ Î±i 
data pertama :  Min {max [0,5(1 -5,75) -0,5] 1 â€“ 0,5) -3,375
7. Menghitung nilai alpha baru dengan rumus :  
Î±i = Î± i + Î´Î± i 
Contoh perhitungan pada D1 :  
Î±i = 0,5 + (-1,312) = -0.812  
8. Mencari nilai bias  
b = -  2 ( < w . x -1 > + < w . x+1 )  
terlebih dahulu mencari nilai w  
wx+ = ( -0,812 x (1) x 8,25) + (-0,312 x (1) x 0,25)  + (0.063 x ( -1) x 0,25) +  (0,188 x ( -1) x 1,25) + (0,063 x ( -1) x 
0,25) + (0,188 x (1) x 0,25)  = -6.99 
wx-  =  (-0,812 x (1) x 0,25 ) + (-0,312 x (1) x 2,25) + (0.063 x ( -1) x 1,25) +  (0,188 x ( -1) x 0,25) + (0.063 x ( -1) x 
0,25) + (0,188 x (1) x 0,25)  = -0.99 
Nilai b = -  2 (-6.9) +(-0,99) = 3.99 
9. Setelah mendapatkan nilai Î±, w, dan b maka 
akan dilakukan pengujian  
Langkah pertama untuk menguji yaitu menghitung dot product anatar data uji dengan semua data latih dengan fungsi kernel  K (x.xi) = x.xi  Dimana x adalah data uji dan xi adalah data latih 
Data ke -1 = (1x1) + (1x1) + (1x1) + (1x1) + (1x1) + ( 1x1) + (1x1) + (1x1) + (0x0) + (0x0) + (0x0) = 8  
Data ke -2 = (1x0) + (1x0) + (1x0) + (1x0) + (1x0) + ( 1x0) + (1x0) + (1x0) + (1x1) + (1x1) + (1x0) = 2  
 3.6 Pengujian  
Tahap pengujian digunakan untuk menghitung nilai akurasi, recall, precision. Didapatkan dari proses pelabellan secara manual dan hasil klasifikasi menggunakan metode Support V ector Machine pada 
proses  testing data. Pengujian dilakukan dengan menggunakan metode Confusion Matrix sebagai berikut :  
Tabel 6 Confusion Matrix  
No Jenis  Model  
1 Accuracy  ð‘‡ð‘ƒ+ð‘‡ð‘
ð‘‡ð‘ƒ+ð‘‡ð‘+ð¹ð‘ƒ+ð¹ð‘âˆ—100 
2 Precision  ð‘‡ð‘ƒ
ð¹ð‘ƒ+ð‘‡ð‘ƒâˆ—100 
3 Recall  ð‘‡ð‘ƒ
ð‘‡ð‘ƒ+ð¹ð‘âˆ—100 
4 F1-Score  2*(recall*precission) / (recall+precision)  
 
4. Implementasi  
4.1 Crawling Data  
Penelitian ini memakai data twitter yang dikumpulkan dalam satu file berformat CSV menggunakan library twint yang dijalankan melalui 
commant prompt yang selanjutnya diberi label sesuai dengan kelasnya dan data yang digunakan adalah tweet dengan kata kunci #Lockdownjakarta #Karantinawilayah 
4.2 Implementasi Preprocessing  
twint -s """"#lockdownjakarta"""" -o ockdown.csv --limit 2000 --since 
2020-04-01 --until 2020 -05-31 --csv --lang id 
import re  
def process_tweet(tweet):  
    tweet = tweet.lower()     
    tweet = re.sub('@[^ \\s]+', '', tweet)  
    tweet = re.sub('((www \\.[^\\s]+)|(https?://[^ \\s]+))', ' ', tweet)    
    tweet = re.sub(r"""" \\d+"""", """" """", str(tweet))  
    tweet = re.sub('&quot
    tweet = re.sub(r"""" \\b[a-zA-Z]\\b"""", """""""", str(tweet))   
    for word in tweet.split():  
        if wo rd.lower() in contractions:  
            tweet = tweet.replace(word, contractions[word.lower()])  
    tweet = re.sub(r""""[^ \\w\\s]"""", """" """", str(tweet))  
    tweet = re.sub(r'(.) \\1+', r' \\1\\1', tweet)  
    tweet = re.sub(r"""" \\s+"""", """" """", str(tweet))  
    return tweet  
from Sastrawi.Stemmer.StemmerFactory 
import StemmerFactory  
factory = StemmerFactory()  
stemmer = factory.create_stemmer()  
stemming = stemmer.stem(tweet)    
1. tweet = tweet.lower() berfungsi untuk 
transformasi huruf kapital menjadi huruf kecil  
2. tweet = re.sub('@[^ \\s]+', '', tweet), Berfungsi 
untuk menghapus username  
3. tweet = re.sub('((www \\.[^\\s]+)|(https?://[^ \\s]+))', 
' ', tweet), Berf ungsi untuk menghapus Url  
4. tweet = re.sub(r"""" \\d+"""", """" """", str(tweet)), Berfugsi 
untuk menghapus digit  
5. tweet = re.sub('&quot
untuk menghapus (&quot
6. tweet = re.sub(r"""" \\b[a-zA-Z]\\b"""", """""""", str(tweet)), 
berfungsi menghapus karakter tunggal seperti 
a,b,c, dll     
7. tweet = re.sub(r""""[^ \\w\\s]"""", """" """", str(tweet)), 
menghapus tanda baca  
8. tweet = re.sub(r'(.) \\1+', r' \\1\\1', tweet), Berfungsi 
untuk menghapus data ganda  
9. tweet = re.sub(r"""" \\s+"""", """" """", str(tweet)), Berfungsi 
untuk mengubah 2 spasi atau lebih menjadi 1 
spasi.  
4.3 Implementasi TF -IDF 
4.4 Implemetasi Support Vector Machine  
 
5. Hasil dan pembahasan  
Data yang digunakan dalam penelitian ini diambil dari twitter.com menggunakan  Twitterscrapper  dan Twint sebanyak 1377 data tweet berbahasa Indonesia mengenai kebijakan lockdown Jakarta. Data tersebut dibagi menjadi dua kelas yaitu positif dan negatif yang berarti setuju atau tidak setuju dengan kebijakan lockdown yang dilakukan pemerintah Jakarta.  Tahap pengujian ini dilakukan dengan pengujian confusion matrix yang mengacu pada TP, FP, TN, FN untuk mengetahui seberapa baik akurasi metode svm dengan ekstraksi fitur tf-idf dalam kebijakan tersebut.  
5.1 Perhitungan Kelas Sentimen  
Dalam pengujian data sentimen tweet tentang kebijakan pemerintah mengenai kenijakan Lockdown  didapatkan hasil sentimen negatif dan sentimen positif secara manual. Dari hasil pelabelan data tersebut kemudian dilakukan training data  dan testing data yaitu 80% data Training dan 20% data testing  yang dilakukan secara acak. Hasil dari perhitungan data sentimen kelas Negatif berjumlah 275 data, dan sentimen kelas positif sebesar 1:100 data. perbandingan dalam bentuk persentase dapat dilihat pada Gambar 3:  
Gambar 3 Kelas Sentimen  
bisa kita lihat perbandingan antara tweet masyarakat yang berkomentar positif  mengenai  kebijakan lockdown  dengan tweet masyarakat yang berkomentar negatif  yaitu 68,75  % tweet positif berbanding 31,25 % tweet negatif dengan jumlah kelas Negatif sebanyak 275 data, dan sentimen kelas positif sebesar 1 100 data dari hasil perhitungan sentimen didapat kata - kata yang memiliki kemunculan terbesar yang terdapat pada Gambar 4 :  
Gambar 4 Kemuncul Kata Terbesar  
5.2 Pengujian TF -IDF Terhadap Support Vector Machine  
Pengujian yang digunakan yaitu dengan fitur tf-idf  yang bertujuan mengetahui seberapa besar nilai Accuracy, P recision,  recall  dan F1-Score  berdasarkan pengujian memiliki hasil y ang ditunjukkan pada tabel 5.1. 
Tabel 5.1 Hasil Pengujian Dengan TF-IDF 
TF-IDF Hasil (%)  
Accuracy  74 
Precision  75 
Recall  92 
F1-Score  83 
Berdasarkan tabel diatas dapat dilihat bahwa hasil metode Support Vector Machine  dengan fitur tf-idf  from sklearn.feature_extraction.text import TfidfVectorizer final_vectorized_data=tf_idf_vectorizer.fit_transform(total_data['proc essed_tweet'])  final_vectorized_data  
from sklearn.svm import SVC  
model_svm = SVC(kernel = 'linear', random_state = 0)  
model_svm.fit(X_train, y_train)  
predicted_svm = model_svm.predict(X_test)  
didapat dengan tinggak nilai accuracy  sebesar 74%, precision  sebesar 75%, recall  sebesar 92%, dan F1-Score  sebesar 83% dengan akurasi metode Support Vector Machine  sebesar 74% yang artinya cukup baik dalam penelitian mengenai kebijakan lockdown pemerintah Jakarta.  
 
6. Kesimpulan  
Berdasarkan hasil penelitian dan pengujian metode Support Vector Machine  untuk mengklasifikasi kebijakan lockdown pemerintah Jakarta dengan tweet berbahasa Indonesia menggunakan ekstraksi fitur tf-idf  didapat kesimpulan bahwa penggunaan  metode Support Vector Machine tingkat nilai Accuracy  sebesar 74%, Precision sebesar 7 5%, Recall  sebesar 92% dan F1-Score  sebesar 83%. Yang artinya cukup baik dalam penelitian mengenai kebijakan lockdown pemerintah  Jakarta.  
 
7. Saran  
Penelitian ini dapat dikembangkan dengan menggabungkan metode SVM  dengan metode Firefly  sebagai metode optimasi. Metode SVM dioptimasi dengan metode Firefly menghasilkan akurasi lebih tinggi dibandingkan dengan SVM tanpa optimasi [14].  
 
Daftar Pustaka  
[1] A. S. Cahyono, â€œAnang Sugeng Cahyono, Pengaruh Media Sosial Terhadap Perubahan Sosial Masyarakat di Indonesia,â€ pp. 140 â€“157, 2016.  
[2] I. Alfina, R. Mulia, M. I. Fanany, and Y. Ekanata, â€œHate Speech Detection in the Indonesian Languageâ€¯: A Dataset and Preliminary Study,â€ in 9th Int. Conf. Adv. Comput. Sci. Inf. Sys t. (ICACSIS 2017) , 2017, no. October, doi: 10.1109/ICACSIS.2017.8355039.  
[3] S. Styawati and F. Ariany, â€œSistem Monitoring Tumbuh Kembang Balita/Batita di Tengah Covid -19 Berbasis Mobile,â€ J. Inform. Univ. Pamulang , vol. 5, no. 4, p. 490, 2021, doi: 10.324 93/informatika.v5i4.7067.  
[4] G. A. Buntoro and A. E. Purnamasari, â€œSentiment Analysis Candidates of Indonesian Presiden 2014 with Five Class Sentiment Analysis Candidates of Indonesian Presiden 2014 with Five Class Attribute,â€ no. May, 2016, doi: 10.5120/ ijca2016908288.  
[5] A. Fathan Hidayatullah and A. Sn, â€œISSN: 1979 -2328 UPN """"Veteran,â€ Semin. Nas. Inform. , vol. 2014, no. semnasIF, pp. 115 â€“122, 2014.  
[6] J. Weng, E. Lim, J. Jiang, H. I. Search, and R. Information, â€œTwitterRankâ€¯: Finding Topic-sensitive I nfluential Twitterers,â€ pp. 261 â€“270, 2010.  
[7] Monarizqa, Nugroho, and Hantono, â€œIMPLEMENTASI SUPPORT VECTOR MACHINE UNTUK ANALISIS SENTIMEN 
PENGGUNA TWITTER TERHADAP,â€ vol. 15, no. 2, pp. 171 â€“176, 2019, doi: 10.33480/pilar.v15i2.699.  
[8] R. Feldman and J.  Sanger, â€œBook Reviews,â€ 
2007.  
[9] J. Li and L. Qiu, â€œA Sentiment Analysis Method 
of Short Texts in Microblog,â€ 2017, doi: 10.1109/CSE -EUC.2017.153.  
[10] D. E. Ratnawati and A. W. Widodo, â€œKlasifikasi Penyakit Gigi Dan Mulut Menggunakan Metode Support Vect or Klasifikasi Penyakit Gigi Dan Mulut Menggunakan Metode Support Vector 
Machine,â€ no. January, 2018.  
[11] E. Susilowati, M. K. Sabariah, A. A. Gozali, J. T. Informatika, U. Telkom, and S. V . Machine, â€œIMPLEMENTASI METODE SUPPORT VECTOR MACHINE UNTUK MELAKUKAN KLASIFIKASI  KEMACETAN LALU LINTAS PADA TWITTER IMPLEMENTATION 
SUPPORT VECTOR MACHINE METHOD FOR TRAFFIC JAM CLASSIFICA TION ON TWITTER,â€ vol. 2, no. 1, pp. 1478 â€“1484, 2015.  
[12] W. Purnami, A. M. Regresi, and L. Ordinal, â€œPerbandingan Klasifikasi Tingkat Keganasan Breast Cancer Dengan Menggunakan Regresi Logistik Ordinal Dan Support Vector Machine ( SVM ),â€ vol. 1, no. 1, 2012.  
[13] A. Kowalczyk, Support V ector Machines Succinctly . Syncfusion Inc., 2017.  
[14] S. Styawati and K. Mustofa, â€œA Support Vector Machine -Firefly Algorithm for Movie Opinion Data Classification,â€ IJCCS (Indonesian J. Comput. Cybern. Syst. , vol. 13, no. 3, p. 219, 
2019, doi: 10.22146/ijccs.41302.  

",Sentimen analisis,"SVM, Support Vector Machine, TF-IDF",tweet berbahasa Indonesia mengenai kebijakan locdown atau pembatasan wilayah,"accuracy, precision, recall, F1-Score"
Sentimen Analisis Tweet Berbahasa Indonesia dengan  Deep Belief Network,"Sentimen Analisis Tweet Berbahasa Indonesia dengan  Deep Belief Network

Ira Zulfa *1, Edi Winarko*2 

Abstrak  
Sentimen analisis adalah riset komputasional dari opini sentiment dan emosi yang diekspresikan secara tekstual. Twitter menjadi perangkat komunikasi paling popular di kalangan pengguna internet . Deep Learning adalah area baru dalam penelitian machine learning, yang telah diperkenalkan dengan tujuan m enggerakkan machine learning lebih dekat dengan salah satu tujuan aslinya yaitu artificial intelligence. Tujuan deep learning mengganti manual engineering dengan learning, pada perkembangannya deep learning memiliki himpunan algoritma yang fokus pada pembe lajaran representasi data (nonlinear) bertingkat. Deep Belief Network (DBN) merupakan salah satu metode machine learning yang termasuk dalam metode Deep Learning yang merupakan tumpukan atau stack dari beberapa algoritma atau metode dengan feature extraction yang memanfaatkan seluruh resource seoptimal mungkin. Penelitian ini bertujuan untuk melakukan pengklasifikasian terhadap sentimen positif, negatif, dan netral terhadap data uji dan untuk mengetahui akurasi model klasifikasi dengan menggunakan metode Deep Belief Network ketika diaplikasikan pada klasifikasi tweet untuk menandai kelas sentimen data trai ning tweet berbahasa Indonesia. Dari percobaan yang dilakukan, hasil pengujian pada sistem yang dibangun memperlihatkan bahwa metode terbaik pada data tweet adalah metode DBN yaitu dengan akurasi sebesar 93,31%, ketika dibandingkan dengan metode Naive Bayes yang memiliki akurasi sebesar 79,10%, dan SVM (Support Vector Machine) yang memiliki akurasi sebesar 92,18%.  
 
Kata kunci Sentimen Analisis, Twitter, deep belief  
 
Abstract  
Sentiment analysis is a computational research of opinion sentiment and emotion which is expressed in textual mode. Twitter becomes the most popular communication device among internet users. Deep Learning  is a new area of machine learning research. It aims to move machine learning closer to its main goal, artificial intelligence. The purpose of deep learning is to change the manual of engineering with learning. At its growth, deep learning has algorithms arrangement that focus on non-linear data representation. One of the machine learning methods is Deep Belief Network (DBN). Deep Belief Network (DBN), which is included in Deep Learning method, is a stack of several algorithms with some extraction features that optimally utilize all  resources. This study has two points. First, it aims to classify positive, negative, and neutral sentiments towards the test data. Second, it determines the classification model accuracy by using Deep Belief Network method so it would be able to be applied into the tweet classification, to highlight the sentiment class of training data tweet in Bahasa Indonesia. Based on the experimental result, it can be concluded that the best method in managing tweet data is the DBN method with an accuracy of 93.31%, co mpared with  Naive Bayes method which has an accuracy of 79.10%, and SVM (Support Vector Machine) method with an accuracy of 92.18%.  
 
Keywords Sentimen Analisis, Twitter, deep belief  

1. PENDAHULUAN  
Keingintahuan pihak korporasi akan sentimen terhadap produk ataupun layanannya biasanya dipacu oleh tingkat persaingan yang semakin tinggi diantara para pelaku pasar. Namun, untuk mengetahui sentimen publik terkadang membutuhkan biaya dan usaha yang tidak mudah. Namun melalui web, perusahaan maupun perorangan dapat mencari jawaban atas keingintahuan tersebut. Opini-opini orang akan berbagai hal dituangkan di web. Yang perlu dilakukan adalah usaha untuk mengumpulkan semua opini tersebut dan mengolahnya menjadi suatu yang dapat menjawab pertanyaan -pertanyaan tadi.  Opini mining atau sentimen analisis adalah riset komputasional dari opini, sentimen dan emosi yang diekpresikan secara tekstual [1]. Sekarang ketika suatu organisasi / perusahaan / 
perorangan ingin memperoleh opini publik mengenai produk, citra dan layanannya, maka mereka tidak perlu melakukan survei konvensional dan fokus group yang mahal biayanya  [2]. Deep Learning  adalah area baru dalam penelitian Machine Learning, yang telah diperkenalkan dengan tujuan menggerakkan Machine Learning  lebih dekat dengan salah satu tujuan aslinya yaitu Artificial Intelligence. Deep Learning  adalah tentang belajar beberapa 
tingkat representasi dan abstraksi yang membantu untuk memahami data seperti gambar, suara, dan teks [3]. Deep Belief Network  (DBN) adalah suatu pengembangan dari Deep Learning yang merupakan tumpukan atau stack dari beberapa algoritma atau metode yang bertujuan feature extraction yang memanfaatkan seluruh resou rce seoptimal mungkin. Deep Learning mencakup algoritma unsupervised dan supervised learning sehingga dapat memanfaatkan data yang berlabel maupun tidak berlabel. Pendekatan yang sering digunakan untuk mengimplementasikan 
Deep Learning adalah graphical met hods atau multi layer representation atau multi layer graphical model seperti Deep Belief Network  [4]. Metode klasifikasi sentimen yang dipilih adalah  DBN yaitu salah satu metode machine learning  untuk pemodelan semantik kalimat yang termasuk dalam metode Deep learning. 
Dalam pemprosesan text data sentimen analisis untuk membedakan dengan penelitian sebelumnya. Hasil dari penelitian ini untuk membandingkan hasil akurasi yang dilakukan oleh Aliandu (2012) dengan metode Naive Bayesian  dan metode Support Vektor Machine. Nantinya dapat dilihat hasil mana  yang lebih akurat dari metode-metode yang digunakan. Sumber data  Twitter berbahasa Indonesia dipilih karena penelitian dalam bahasa Indonesia belum banyak dilakukan, sedangkan DBN dipilih karena metode ini belum pernah digunakan dalam kasus sentimen analisis sebelumnya dan diharapkan dapat mencapai kinerja yang lebih baik dari metode metode sebelumnya. Metode DBN diharapkan bisa digunakan dalam pengimplementasian Tweet untuk keperluan data training dikumpulkan dari beragam data yang dianotasikan kelas sentimennya secara atomatis dengan akun media nasional di Twitter. Akum media nasional merupakan teks yang hanya berisi pernyataan atas suatu fakta atau kejadian dan tidak mengekpresikan emosi tertentu. Apakah nantinya karakteristik DBN  ini sesuai jika diaplikasikan pada data Twitter. Bedasarkan hal tersebut akan dibuat  analisa sentimen tweet berbahasa Indonesia dengan menggunakan metode Deep Belief Network  dalam membangun model klasifikasi.  
 
2. METODE PENELITIAN  
2.1 Inputan Data  
2.1.1 Data tweet  Berbahasa Indonesia  
Data tweet diperoleh dengan melakukan scraping  pada situs www.search.twitter.com  dengan memanfaatkan API twitter. tweet  yang diperoleh berisi daftar tweet berbahasa Indonesia.
2.1.2 Data Kata Baku Bahasa Indonesia  
Data kata baku diperoleh berdasarkan kamus besar bahasa  Indonesia. Total kata baku atau kata dasar bahasa Indonesia yang digunakan dalam penelitian ini berjumlah 828 kata. Data kata baku  diperoleh dari inputan secara manual  
2.1.3 Data Kata Tidak Baku  
Data kata tidak baku diperoleh  dari data kotor hasil scraping  tweet . 
2.1.4 Data Stopword  
Stopword  adalah kata-kata yang tidak memiliki pengaruh dalam proses klasifikasi, seperti: yang, dan, atau, ke, dari, dan lain-lain.Total Kata Umum  yang digunakan dalam penelitian ini berjumlah 754 kata.  Data Kata Umum diperoleh dari data kotor hasil scraping  tweet  yang diinput secara manual.  
2.1.5 Data Simbol  
Data Simbols adalah symbol tidak memiliki pengaruh dalam proses klasifikasi, seperti: (.,:
2.1.6 Data Antonim  
Antonim adalah kata-kata yang berlawanan makna dengan kata lain. Data antonim berfungsi sebagai konversi sesudah kata negasi kemudian kata negasi dihilangkan. Misalnya, terdapat kalimat yang mengandung dua kata  ""tidak besar"" maka susunan kata setelah 
dikonversi dengan data antonym menjadi ""keciL"". Total antonim yang digunakan dalam penelitian ini berjumlah 289 kata yang diperoleh dari hasil inputan secara manual pada sistem.  
2.1.7 Data POS Tagging  
POS Tagging merupakan kata yang telah dilabelisasi kelas kata berdasarkan kamus besar bahasa Indone sia. Contoh : ""makanan enak"" setelah di POS Tagging  menjadi ""makanan NN// 
enak JJ//"". Total POS Tagging yang digunakan dalam penelitian ini berjumlah 48,274 kata. Data POS Tagging diperoleh dari link berikut: http://hikaruyuuki.lecture.ub.ac.id/kamus-kata-dasar-dan-stopword-list-bahasa-indonesia/  dan ditambahsecara manual berdasarkan pengamatan dalam proses pengembangan sistem ini.  
2.2 Arsitektur Sistem  
Secara umum arsitek tur sistem ini terdiri dari lima  bagian diantaranya adalah pengumpulan data, preprocessing, pelabelan, klasifikasi sentimen, hasil akurasi sentimen. Arsitektur sistem yang dirancang seperti terlihat  pada Gambar 1. Tahap pertama dari aristektur sistem yaitu melakukan pengum pulan data dari server Twitter memanfaatkan API Twitter  dengan cara scraping, Selanjutnya data hasil scraping tersebut akan mengalami proses preprocessing  agar data siap digunakan untuk proses klasifikasi. Hal ini dil akukan karena tidak semua data tweet  tersebut dapat digunakan. Pada tahap preprocessing  ini dilakukan pembersihan data tweet  yang terdiri dari case folding, penghapusan simbol-simbol, tokenisasi, konversi slangword, penghapusan stopword. Kemudian data tweet  hasil preprocessing disimpan dalam database dengan tempat yang berbeda dari data tweet kotor. Kemudian data tweet  bersih yang sudah diberi label secara manual akan dirubah menjadi vector dengan bagofword  untuk dilakukan perhitungan dengan metode deep belief network, naIve bayes  dan support vector machine agar menghasilkan model klasifikasi sentimen. Kemudian tahap terakhir adalah pengujian klasifikasi tweet yang meliputi pengujian akurasi, presisi, recall , dan f1-score  yaitu menghitung keakuratan tweet  pada sistem.  
Gambar 1 Arsitektur Sistem  
2.3 Pengumpulan Data  
Pada tahap ini dilakukan pengumpulan data -data yang dibutuhkan dalam penelitian. Data-data yang dimaksud adalah kumpulan dari tweet terkait tentang tranding topik di www.search.twitter.com.  
2.3.1 Scraping  
Pengumpulan data pada penelitian ini dilakukan dengan cara  scraping  pada situs www.search.twitter.com. Proses scraping  dilakukan dengan memanfaatkan library Python Tweepy http://tweepy.readthedocs.io/en/v3.5.0/api.html#tweepy-api-twitter-api-wrapper  dan Twitter API. Scraping tweet  dilakukan secara otomatis untuk mengambil data tweet dengan jangka waktu data yang bisa ditentukan. Sebelum dapat melakukan scrapping, sistem ini akan melakukan pengecekan key consumen  dan access token  agar sistem dapat mengembil data dari twitter apabila data token ada terdaftar dalam sistem twitter  maka sistem dapat mengambil data twitter  pada wilayah Indonesia. Data tweet  bahasa Indonesia dengan query yang dicari. Sistem ini menyimpan data tweet keda lam database , jika data tweet  yang diambil telah tersimpan didalam database  maka sistem tidak menyimpan data tersebut sehingga tidak terdapat tweet yang sama pada data tweet. Data tweet  terkumpul secara otomatis  tersimpan dalam database mysql . Dari mysql data akan diekspor ke file .txt. . Langkah-langkah proses scraping tweet  seperti terlihat  pada Gambar 2.  
Gambar 2 Proses scraping tweet  
2.4 Preprocessing  
Preprocessing sangat menentukan dalam proses penentuan sentimen dengan deep belief network dan klasifikasi tweet menjadi lebih akurat. Preprocessing juga digunakan untuk mendapatkan data bersih. Tahap preprocessing  terdiri dari beberapa proses yang akan dibahas satu per satu secara detail , antara lain:  
2.4.1 Case Folding  
Tahap ini berfungsi untuk merubah karakter huruf di dalam komentar menjadi karakter huruf kecil semua.  
2.4.2 Penghapusan Simbol-Simbol  
Penghapusan simbol -simbolberfungsi  untuk menghapus karakter khusus dalam komentar seperti tanda baca (seperti : koma (,), titik(.), tanda tanya (?), tanda seru (!) dan sebagainya), angka numerik (0 - 9), dan karakter lainnya(seperti: $, %, *, dan sebagainya).  
2.4.3 Tokenisasi  
Tokenisasi  berfungsi untuk memecah komentar menjadi satuan kata. Proses tokenisasi dilakukan dengan melihat setiap spasi yang ada dalam komentar maka berdasarkan spasi tersebut kata-kata dapat dipecah.  
2.4.4 Konversi  Slangword  
Konversi slangword merupakan proses  mengubah terhadap kata tidak baku  ke kata baku. Tahap ini dilakukan dengan menggunakan bantuan kamus slangword  dan padanannya dalam kata-kata baku . Tahapan ini akanmemeriksa kata yang terdapat dalam kamus slangword atau tidak. Jika kata tidak baku terdapat dalam kamus slangword  maka kata tidak baku akan dirubah ke kata baku yang terdapat didalam kamus slangword.  
2.4.5 Penghapusan Stopword  
Tahap ini berfungsi untuk menghilangkan kata -kata yang tidak penting dalam proses klasifikasi dan penentuan alasan , seperti kata: yang, tetapi, atau, ke, di, dengan,  dan sebagainya.  
2.5 Perancangan Training  
Perancangan proses training dilakukan dengan menggunakan metode deep belief network dan support vector machine, NaIve bayes sebagai metode pembanding . 
2.5.1 Perancangan deep belief network  
Perancangan  deep belief network dibagi menjadi 2 tahapan yaitu tahap pembelajaran dan tahap klasifikasi. Proses tahapan perhitungan deep belief network  pada tahap pembelajaran adalah sebagai berikut :  
a. Menghitung jumlah seluruh tweet  (data) dalam data training.  
b. Menghitung jumlah tweet  pada masing-masing kelas.  
c. Lakukan pelatihan pada RBM pertama pada model dengan data input x =  atau dapat dikatakan ini merupakan lapisan terlihat v pada RBM pertama untuk  mendapatkan parameter. 
d. Tetapkan parameter  dan gunakan lapisan pertama untuk memperoleh representasi ï¬tur yang akan digunakan sebagai data untuk lapisan kedua dengan  melakukan sampling h1 dari 
e. Tetapkan parameter    yang dideï¬nisikan oleh ï¬tur lapisan kedua dan gunakan  sampel    dari. sebagai data latih pada lapisan ketiga.  
Lakukan langkah diatas secara berulang untuk lapisan berikutnya. Berikut adalah tahapan rinci dari CD-1 untuk training RBM [3] : 
a. Inisialisasi bobot dan bias, laju pembelajaran  dan tetapkan maksil epoch.   
b. Ketika kondisi berhenti tidak terpenuhi atau epoch maksimal tidak terpenuhi  lakukan langkah ke -3 sampai ke -8 secara berulang -ulang.  
c. Gunakan data training x sebagai neuron -neuron terlihat pada lapisan terlihat    
 (        ) 
   âˆ‘                                                                                 
d. Perbaharui lapisan tersembunyi dengan p(h = 1, v aktivasi neuron-neuron biner stokastik pada lapisan tersembunyi dengan mengambil 
probabilitas pada persamaan (1) lebih dari nilai random yang tersebar  antara 0 dan 1.  
              (âˆ‘   
        )                                                                 
e. Rekonstruksi neuron-neuron terlihat dengan menggunakan hasil dari neuron-neuron biner stokastik pada langkah ke -2 sebagai masukan pada persamaan  (2). 
f. Hitung probabilitas output dari rekonstruksi dengan melakukan perhitungan probabilitas pada persamaan (1), namun hasil rekonstruksi dijadikan sebagai masukan.  
g. Hitung bobot delta dengan mengikuti persamaa n (3) atau dapat melihat Gambar 3 dengan 
rumus sebagai berikut:  
-1
-2
(3) 
Gambar 3 Langkah CD -1 
h. Perbaharui bobot dengan mengikuti persamaan (4 )  
2.5.2 Perancangan Support Vector Machine  dan NaÃ¯ve Bayes  
Metode pembanding yang digunakan pada penelitian ini adalah metode Support Vector Machine (SVM) dan Naive Bayes (NB) . Proses perancangan diawali dengan pemanggilan library sklearn dari Python dengan menggunakan beberapa parameter, antara lain : kernel yang  digunakan adalah kernel linear  untuk SVM, nilai gamma yang digunakan adalah 1.0, dan nilai coef0 yang digunakan adalah 1.0.  
2.6 Algoritma Pelatihan pada DBN   
Menggunakan  algoritma DBN yang secara supervised . Hal tersebut dilakukan karena pada data pelatihan sudah terdapat label yang nantinya juga akan digunakan pada lapisan output jaringan. Meskipun demikian pre-training  tetap dilakukan dengan mengatur tumpukan RBM yang digunakan dalam DBN menyesuaikan data yaitu dengan Bernoulli (Biner) RBM  [5]. 
2.6.1  Inisialisasi RBM dan Kontruksi DBN  
Pada RBM pertama, lapisan terlihat    mendapatkan  inputan langsung dari sampel data x. Dari lapisan terlihat    dan lapisan tersembunyi     pada RBM dilakukan pelatihan untuk 
membentuk bobot. Setelah RBM pertama selesai dilatih, dengan mengambil pola aktivitas pada  lapisan tersembunyi RBM pertama, kemudian dapat digunakan sebagai data pada lapisan terlihat    untuk melatih RBM kedua. Dengan menyalin h1 sebagai pada RBM kedua, maka bobot akan dapat dilatih.Proses ini juga dapat dikatakan membentuk tumpukan (stack) RBM. Perhatik an bahwa pada proses ini label tidak terlibat  [6]. 
2.6.2 Pelatihan Setiap Lapis RBM  
Pada konstruksi DBN sudah dijelaskan pembelajaran lapis -demi -lapis pada DBN dengan melakukan pelatihan pa da setiap lapisan RBM. Pelatihan lapis-demi-lapis ini bertujuan untuk membentuk bobot-bobot yang menghubungkan lapisan input dengan lapisan tersembunyi pertama dan lapisan tersembunyi kedua (Karena terdapat 2 lapisan tersembunyi pada DBN). Tahapan latihan ini dapat dikatakan sebagai tahapan pre -training mengacu pada penelitian 
yang dila kukan oleh [7], dimana pelatihan setiap lapis. RBM dilakukan secara Unsupervised Learning  tanpa melibatkan kelas label atau target  [8]. 
2.6.3 Mini-Batch Gradien Descent  
Pembaharuan bobot pada RBM mengacu pada aturan pembaharuan Gradient Descent. Pada gradient descent biasa atau batch gradient descent untuk seluruh data akan dikenakan penjumlahan gradien dalam suatu perulangan sebanyak epoch yang diingikan. Gradient 
merupakan turunan parsial untuk setiap bobot dan bias.  Besarnya gradien dapat memberikan petunjuk tentang berapa banyak bobot atau bias yang harus berubah.  
(4) ï®                
2.6.4 Fine-tunning Backpropagation  
Karena DBN dapat digunakan secara supervised (setelah melalui proses pretraining) dengan melibatkan kelas label bobot akan disempurnakan atau proses ini  disebut dengan ï¬ne -tuning. Fine-tuning dilakukan dengan melatih jaringan menggunakan algoritma 
Backpropagation [9][10]. Pada proses sebelumnya, hasil pembobotan yang dilakukan pada saat pelatihan setiap lapisan RBM digunakan dalam inisialisasi ï¬ne -tuning dengan Backpropagation ini. Namun, untuk bobot yang menghubungkan lapisan tersembunyi kedua  dengan lapisan output tetap menggunakan inisialisasi random. Dengan demikian, jaringan DBN dapat dianggap seperti MLP dengan dua lapisan tersembunyi dan satu lapisan output yang terhubung secara penuh. Gambar 4. menunjukkan tahapan ï¬ne -tuning pada keseluruhan jaringan DBN yang terhubung secara penuh.  
Gambar 4 Fine-tuning secara supervised DBN  
3. HASIL DAN PEMBAHASAN  
3.1 Pengujian Klasifikasi Tweet  
Bagian ini membahas tentang pengujian dari klasifikasi tweet  yang telah dibangun. Pengujian klasifikasi tweet  dilakukan dengan mengukur akurasi, presisi, recall, dan f1-score dari hasil perhitungan deep belief network , naive bayes classifier dan support vector machine.  Adapun total data tweet  yang digunakan untuk pengujian klasifikasi (uji) adalah 2378 tweet. Total data tweet untuk proses pengujian tersebut dibagi ke dalam delapan tranding topik yang telah diinputkan sebelumnya oleh user. Rincian  data tweet  untuk proses pengujian klasifikasi tweet dan pengujian tweet  diperlihatkan pada Tabel 2. 
Tabel 1  Rincian sentiment tweet pengujian klasifikasi  Tranding Topik  Jumlah Tweet   Sentimen    
 Positif  Negatif  Netral  
Anies  682 36.20%  13.90%  49.90%  
Hari Bebas Kendaraan Bermotor  179 9.50%  14.50%  76.00%  
Total  2023  26.99%  21.73%  50.91%  
Sentimen Analisis Tweet Berbahasa Indonesia Dengan  Deep Belief Network  (Ira Zulfa ) 195 Sebelum dilakukan pengujian terhadap klasifikasi tweet, seluruh data tweet dilabeli secara manual sesuai berdasarkan jenis klasifikasinya (sentimennya). Sebagai contoh komentar ""penjara Ahok"" maka akan dilabeli dengan ""•""karena  memiliki nilai sentimen negatif  yang berisi tentang  penjarakan Ahok. 
Pengujian klasifikasi alasan untuk mengukur akurasi, presisi, recall , dan f1-score diperoleh dengan membandingkan tiap tweet yang telah dilabeli secara manual dengan hasil perhitungan deeb belief network  yang dilakukan oleh sistem. Jumlah tweet  yang sesuai antara hasil perhitungan deeb belief network  oleh sistem dengan pelabelan secara manual, akan mempengaruhi nilai akurasi, presisi, recall  dan f1-score  yang diperoleh. Semakin besar jumlah tweet  yang sesuai, maka semakin tinggi pula nilai akurasi, presisi, recall dan f1-score  yang didapatkan. Rekapitulasi hasil pengujian klasifik asi perhitungan klasifikasi tweet dengan menggunakan deeb belief network  untuk tiap tranding topik diperlihatkan pada Tabel 2. 
Tabel 2 Hasil Pengu jian Klasifikasi Menggunakan DBN  
Tranding Topik  Akurasi  Presisi  Recall  F1-score  
Anies  49.93%  25% 50% 33% 
Hari Bebas Kendaraan 
Bermotor  75.98%  58% 76% 66% 
Total  50.35%  27% 50% 35% 
Berdasarkan Tabel 3 di atas dapat disimpulkan  bahwa hasil akurasi perhitungan klasifikasialasan secara keseluruhan dengan menggunakan  deeb belief network  yaitu sebesar 50,35%, presis i 27%, recall  50%, sedangkan hasil perhitungan untuk  f1-score  yaitu  35%. Sedangkan hasil pengujian sistem keseluruhan dari perhitungan klasifikasi  dengan menggunakan metode support vector machine memperlihatkan bahwa metode support vector machine  menghasilkan nilai akurasi yang sama besar dengan metode deeb  belief network. Nilai akurasi keseluruhan yang didapatkan dari hasil perhitungan klasifikasi  dengan metode support vector machine  yaitu sebesar 50,35 %, nilai presisinya sebesar 27%, nilai recall sebesar 50 % dan nilai f1-score  sebesar 35 %. Rekapitulasi confusion matrix  hasil perhitungan klasifikasi menggunakan support vector machine  dari tiap tranding topik ditunjukkan oleh Tabel 3. 
Tabel 3  Hasil Pengujian Klasifikasi Menggunakan Support Vector Machine  
Tranding Topik  Akurasi  Presisi  Recall  F1-score  
Anies  49.93%  25% 50% 33% 
Hari Bebas Kendaraan Bermotor  75.98%  58% 76% 66% 
Total  50.35%  27% 50% 35% 
Sedangkan hasil pengujian sistem keseluruhan dari perhitungan klasifikasi  dengan menggunakan metode Naive Bayes memperlihatkan bahwa metode Naive Bayes menghasilkan nilai akurasi yang lebih baik dari pada metode  Deep Belief Network dan support vector machine. Nilai akurasi keseluruhan yang didapatkan dari hasil perhitungan klasifikasi  dengan metode Naive Bayes  yaitu sebesar 80.16 %, presis i 82%, recall  70%,  f1-score 78% , support  
2373% Rekapitulasi hasil perhitungan klasifikasi menggunakan Naive Bayes  dari tiap tranding topik  ditunjukkan oleh Tabel 4 . 
Tabel 4 Hasil Pengujian Klasifikasi Menggunakan Naive Bayes  
Tranding Topik  Akurasi  Presisi  Recall  F1-score  
Anies  76.53%  78% 77% 75% 
Hari Bebas Kendaraan 
Bermotor  79.89%  83% 80% 74% 
Total  80.16%  82% 80% 78% 
3.2 Perbandingan Hasil Akurasi  
Perbandingan hasil akurasi dari perhitungan klasifikasi dengan menggunakan metode Deep Belief Network,  support vector machine, dan metode Naive Bayes diperlihatkan oleh Tabel 5 Perhitungan klasifikasi dengan menggunakan metode Navei Bayes menghasilkan nilai pengujian yang lebih baik secara keseluruhan dari pada menggunakan metode  Deep Belief Network, dan support vector machine. 
Tabel 5 Hasil Perbandingan hasil pengujian klasifik asi 
Tranding Topik  Akurasi    Presisi    Recall    
DBN  SVM  NB DBN  SVM  NB DBN  SVM  NB 
Anies  49.93%  49.93%  75.93%  25% 25% 78% 50% 50% 76% 
Hari Bebas Kendaraan 
Bermotor  75.98%  75.98%  80.45%  58% 58% 83% 76% 76% 80% 
Total  50.91%  50.91%  78.81%  28% 28% 81% 51% 51% 79% 
Hasil perbandingan pengujian sistem keseluruhan dari perhitungan klasifikasi  total data dengan menggunakan metode support vector machine memperlihatkan bahwa metode support vector machine  menghasilkan nilai akurasi yang sama besar dengan metode  Deep Belief Network. Nilai akurasi keseluruhan yang didapatkan dari hasil perhitungan klasifikasi  dengan metode support vector machine  yaitu sebesar 50.91 %, presis i 28%, dan recall  51%. Rekapitulasi  hasil perhitungan klasifikasi menggunakan support vector machine  dari tiap tranding topik ditunjukkan oleh Tabel 5.  Sedangkan hasil pengujian sistem total tweet keseluruhan  dari perhitungan klasifikasi  
dengan menggunakan metode Deep Belief Network  , support vector machine, dan Naive Bayes memperlihatkan bahwa metode Deep Belief Network  menghasilkan nilai akurasi yang lebih baik dari pada metode  Naive Bayes  dan support vector machine seperti  yang  diperlihatkan oleh Tabel 6. 
Tabel 6 Hasil Perbandingan hasil pengujian klasifikasi total  
Metode  Presisi  recall  F1-score  Akurasi  Deep Belief 
Network  93% 93% 93% 93.31%  
Support Vector 
Machine  92% 92% 92% 92.18%  
Naive Bayes  79% 79% 79% 79.10%  
Nilai akurasi keseluruhan yang didapatkan dari hasil perhitungan klasifikasi  dengan metode Deep Belief Network  yaitu sebesar 93.31 %, presis i 93%, recall  93%,  f1-score 93% , support  2378, support vector machine yaitu sebesar 92.18 %, presisi 92%, recall  92%,  f1-score 92% , support  2378, dan Naive Bayes yaitu sebesar 79.10%, presis i 79%, recall  79%,  f1-score 79% , support  2378.  
4. KESIMPULAN  
Berdasarkan penelitian yang telah dilakukan, maka diperoleh kesimpulan sebagai berikut:  
1. Hasil pengujian pada sistem yang dibangun memperlihatkan bahwa metode  Deep Belief Network  memberikan hasil pengujian klasifikasi lebih baik dengan akurasi sebesar 93.31 %, presis i 93%, recall  93%,  f1-score 93%, dan support  2378, sedangkan hasil pengujian pada sistem menggunakan metode Naive Bayes  memberikan hasil pengujian  klasifikasi dengan akurasi sebesar 79.10 %, presisi 79%, recall  79%,  f1-score 79%, support  2378 dan Support Vector Machine sebesar 92.18 %, presis i 92%, recall  92%,  f1-score 92% , support  2378.  
2. Penggunaan metode DBN dengan menggunakan BagofWord  sebagai fitur ekstraksinya terbukti tidak memberikan akurasi lebih baik, ketika dibandingkan dengan metode Naive Bayes dan SVM  (Support Vector Machine) dengan menggunakan BagofWord  sebagai fitur ektraksinya pada aplikasi yang dibangun.  
 
5. SARAN  
1. Saran yang  dapat diberikan untuk penelitian selanjutnya adalah dapat mengembangkan sentimen analisis ini dengan mengkombinasikan metode Deep learning  yang lain selain DBN untuk mendapatkan hasil akurasi yang lebih baik lagi.  
2. Sistem ini tidak dapat digunakan untuk menentukan sentimen tweet  dari bahasa selain bahasa Indonesia. Diharapkan pada penelitian selanjutnya bisa dikembangkan suatu multilingual sentimen klasifikasi yaitu sistem yang dapat menentukan sentimen  dari berbagai  bahasa. 

DAFTAR PUSTAKA  
[1] B. Liu, â€•Sentiment Analysis and Subjectivity,â€– Handb. Nat. Lang. Process. , no. 1, pp. 1 â€“ 38, 2010.  http://www.cs.uic.edu/~liub/FBS/NLP -handbook -sentiment -
analysis.pdf%5Cnhttp://people .sabanciuniv.edu/berrin/proj102/1 -BLiu -Sentiment Analysis and Subjectivity -NLPHandbook -2010  [Online] . Available: pdf%5Cnhttp://www.cs.uic.edu/ ~ liub/FBS/NLP -handbook -sentiment -analysis.pdf$%5Cbacks . [Accessed: 20 -Apr-2017].  
[2] N. D. Putranti and E. Winarko, â€•Analisis Sentimen Twitter untuk Teks Berbahasa Indonesia dengan Maximum Entropy dan Support Vector Machine,â€– IJCCS (Indonesian J. Comput. Cybern. Syst. , vol. 8, no. 1, pp. 91 â€“100, 2014  [Online] . Available:  https://jurnal.ugm .ac.id/ijccs/article/view/3499 . [Accessed: 21 -Apr-2017].  
[3] A. Ng, J. Ngiam, C. Y. Foo, Y. Mai, C. Suen, A. Coates, A. Maas, A. Hannun, B. Huval, T. Wang, and Sameep Tandon, â€•Deep Learning Tutorial,â€– Univ. Stanford , 2015  [Online] . Available: 
http://ufldl.stanford.edu/tutorial/supervised/ConvolutionalNeuralNetwork/ . [Accessed: 18-Jan-2017].  
[4] Yuming Hua, Junhai Guo, and Hua Zhao, â€•Deep Belief Networks and deep learning,â€– Proc. 2015 Int. Conf. Intell. Comput. Internet Things , pp. 1 â€“4, 2015 [Online] . Available: http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7111524 . [Accessed: 6-Mar-2017].  
[5] A. A. Al Sallab, R. Baly, and H. Hajj, â€•Deep Learning Models for Sentiment Analysis in Arabic,â€– ANLP Work.  â€¦ , no. Nove mber, pp. 9 â€“17, 2015 [Online] . Available:  http://www.aclweb.org/anthology/W15 -32#page=21 . [Accessed: 22 -Feb-2017].  
[6] G. Hinton, â€•A Practical Guide to Training Restricted Boltzmann Machines A Practical Guide to Training Restricted Boltzmann Machines,â€– Computer (Long. Beach. Calif). , vol. 9, no. 3, p . 1, 2010 [Online] . Available:   http://link.springer.com/10.1007/978 -3-
642-35289 -8_32 . [Accessed: 10 -Jan-2017].  
[7] D. Erhan, A. Courville, and P. Vincent, â€•Why Does Unsupervised Pre -training Help Deep Learningâ€¯?,â€– J. Mach. Learn. Res. , vol.  11, pp. 625 â€“660, 2010 [Online] . Available: 
http://arxiv.org/abs/1206.5538 . [Accessed: 7 -Feb-2017].  
[8] G. Tzortzis and A. Likas, â€•Deep Belief Networks for Spam Filtering,â€– 19th IEEE Int. Conf. Tools with Artif. Intell. 2007) , pp. 306 â€“309, 2007 [Online] . Available:  http://www.annualreviews.org/doi/10.1146/annurev -statistics -010814 -020120 . [Accessed: 21 -Apr-2017].  
[9] G. E. Hinton, S. Osindero, and Y. -W. Teh, â€•A Fast Learning Algorithm for Deep Belief Nets,â€– Neural Comput. , vol.  18, no. 7, pp. 1527 â€“1554, 2 006 [Online] . Available: http://www.mitpressjournals.org/doi/10.1162/neco.2006.18.7.1527 . [Accessed: 15 -Mar-2017].  
[10] R. Salakhutdinov, â€•Learning Deep Generative Models,â€– Mit.Edu , pp. 1 â€“84, 2009 [Online] . Available: http://www.annualreviews.org/doi/10.11 46/annurev -statistics -010814 -020120 . [Accessed: 3 -Jan-2017].  ",Sentimen analisis,"Deep Belief Network, Naive Bayes, Support Vector Machine, SVM",tweet berbahasa Indonesia,"akurasi, presisi, recall, f1-score"
"Sentimen Analisis Aplikasi Belajar Online Menggunakan Klasifikasi SVM  ","Sentimen Analisis Aplikasi Belajar Online Menggunakan Klasifikasi SVM  

Adi Ariyo Munandar1, Farikhin2, Catur Edi Widodo3 

Abstract  
Google Play Store is where a wide variety of applications are available, whether paid or not. Google Play Store page is a place for application users to express opinions, reviews and ratings.  Ruang Guru, Zenius and Quipper are available on the platform. Analysis was carried out using senti ment analysis and SVM algorithm. Data was obtained using data scraping techniques, using  help of google -play-scraper library. Web scraping process is divided into 3 stages namely Fetching, Extraction, and Transformation.  Data collected is 30,000 data which  is divided into 10,000 data for each application . Research begins with data preprocessing stage which includes normalization, case folding, cleaning, tokenizing, and stopwords. then data is divided into 90% training data and 10% test data. Training data is labeled with values 1, 0, and -1. Value 1 means 
positive, value 0 means neutral and -1 means negative. Results of classification sentiment using SVM show that Ruang Guru has highest positive value compared to Zenius and Quipper. However, user response equally gives a positive value for application. Accuracy value of research shows that sentiment classification data with SVM has an average accuracy for Ruang Guru of 99%, Zenius of 96%, and Quipper of 82%.  

Keywords:  Ruang Guru

Abstrak  
Google Play Store  adalah tempat berbagai macam aplikasi tersedia, baik berbayar ataupun tidak. Halaman Google Play Store menjadi tempat pengguna aplikasi untuk menyampaikan pendapat, ulasan dan penilaian.  Ruang Guru, Zenius dan Quipper  tersedia di platform tersebut. Data pada ulasan, menjadi sangat bermanfaat untuk dianalisa. Analisa dilakukan dengan menggunakan sentimen analisis dan algoritma SVM. Data diperoleh dengan menggunakan teknik scraping data, dengan menggunakan bantuan librar y google -play-scraper. Proses web Scraping, dibagi menjadi 3 tahap yaitu Fetching, Extraction, dan Transformation . Data dikumpulkan sebanyak 30.000 data, yang dibagi menjadi 10.000 data Ruang Guru, Zenius dan Quipper. Peneltian diawali dengan Tahap preproc esing data meliputi normalisasi , case folding , cleaning , tokenizing , dan  Stopword.  kemudian data dibagi menjadi 90 % data latih dan 10% data uji. Data latih diberi label dengan nilai 1, 0, dan -1. Nilai 1 berarti positif, nilai 0 berarti netral dan -1 berarti negatif. Hasil sentimen klasifikasi menggunakan SVM, menunjukkan bahwa Ruang Guru memiliki nilai positif tertinggi dibandingkan Zenius dan Quipper. Akan tetapi, respon pengguna sama-sama memberikan nilai positif untuk aplikasi tersebut. Nilai akurasi d ari penelitian menunjukkan bahwa, data Klasifikasi sentimen dengan SVM, mempunyai akurasi rata -rata untuk Ruang Guru sebesar 99%, Zenius sebesar 96%, dan Quipper sebesar 82%.  

Kata kunci:  Ruang Guru

1. Pendahuluan  
Pendidikkan  merupakan proses perubahan tingkah laku dan cara berfikir seseorang untuk menjadi lebih baik dari sebelumnya. Pendidikkan memiliki peranan yang sangat penting dalam proses perubahan hidup manusia yang didasari pada akal dan pengetahuan yang diberikan. Sehingga melahirkan berbagai macam konsep dan 
pengetahuan yang mendalam, salah satunya mengenai teknologi. Perkembangan tekonologi dan pendidikkan saat ini berdampingan dan sangat maju dengan pesat, berbagai bentuk inovasi teknologi untuk pendidikan sangat be rmanfaat bagi kehidupan manusia. Teknologi dan pendidikan tidak dapat dipisahkan sesuai dengan 
perkembangan zaman karena teknologi dapat membantu proses perkembangan pada bidang pendidikan [1]. Kemajuan teknologi saat ini, menjadi salah satu alat penunjang kehidupan seha ri-hari umat manusia, baik dibidang ekonomi, sosial maupun pendidikan. Perkembangan teknologi dibidang pendidikan ditandai adanya aplikasi belajar online , sebagai salah satu  sarana  untuk memenuhi tuntutan belajar anak dan masyarakat yang masih menempuh pen didikan.  Aplikasi belajar online  dapat memberikan alternatif pilihan bagi siswa yang memiliki akses jaringan internet untuk memperoleh layanan bantuan belajar yang efektif, efisien, dan interaktif secara optimal[2]. Dampak dari perkembangan teknol ogi pendidikkan yaitu, munculnya perusahaan penyedia berbagai macam Platform aplikasi, 
seperti Quipper, Zenius dan Ruangguru [3]. Google Play Store  merupakan pasar terbuka untuk berbagai macam aplikasi seperti toko online, permainan, buku elektronik, kelas belajar, dan lain -lain, yang tersedia di platform  tersebut. Negara  Indonesia memiliki 
banyak perusahaan pembuat aplikasi belajar, seperti, Ruangguru,  Zenius,  Quipper,  dan lain-lain. Setiap aplikasi memiliki kelemahan dan kelebihannya masing-masing. Sebagaian besar pengguna menyampaikan hal tersebut melalui halaman keluhan dan saran yang tersedia di halaman Google Play Store [4]. Setiap halaman aplikasi di Google Play Store  memiliki bagian komentar di mana pengguna menyampaikan kritik membangun mereka terhadap aplikasi yang telah diunduh dan digunakan [5]. Halaman Google Play Store,  terdapat sebuah ulasan mengenai pendapat pengguna yang telah menggunakan aplikasi tersebut [6]. Ulasan mengenai aplikasi 
merupakan ruang yang digunakan pengembang aplikasi untuk memperbaiki kinerja aplikasi. sehingga pengembang aplikasi dapat mengambil sebuah keputusan berdasarkan rekomendasi yang diberikan oleh pelanggan [7]. Kelebihan dan kekurangan dari masing-masing brand  aplikasi belajar online  masih perlu 
dianalisis lebih dalam, agar dapat menguntungkan dan mempermudah penggunanya. Google PlayStore menjadi tempat para pen ggunanya memberikan review  jujur terhadap penilaian dari kualitas masing-masing brand bimbingan belajar online  (bimbel online) [8]. Sentimen analisis merupakan proses pengolahan data yang diperoleh dari berbagai macam data untuk mendapatkan sebuah informasi. Analisis sentimen digunakan untuk menemukan atau menganalisa umpan balik pengguna mengenai sebuah produk dan layanan [9]. Analisis sentimen adalah instrumen terbaik untuk menentukan apakah evaluasi itu positif atau negatif. Hasil dari senti men analisis didapatkan dari keterkaitan hubungan saling mempengaruhi aspek kognitif, psikologis dan social [10]. Para pengguna tidak hanya menggambarkan isi dari konten tentang acara 
tetapi juga terkait perasaan penggunanya [11]. Hampir semua perusahaan profesional dan non-teknis menggunakan teknik sentimen analisis untuk mengartikan maksud dari masukkan dan keinginan pelanggan mengenai bagaimana kualitas dari produk 
atau layanannya [12]. Penelitian sebelumnya mengenai sentimen analisis, yang dilakukan  Omar Alqaryouti  dkk, melakukan analisa 
terhadap aplikasi smart government, yang berguna untuk meningkatkan kinerja aplikasi dan layanan pemerintah. Evaluasi dilakukan dengan menganalisa ribuan data, kemudian diklasifikasi menggunakan SVM dan leksikon SVM.  Hasilnya, bahwa leksikon SVM lebih baik  [13]. Mohammad Al -Smadi  dkk, melakukan analisis sentimen dari ulasan Hotel Arab. Penelitian dilakukan dengan 
mengimplementasik an deep recurrent neural network (RNN) dan Support Vector Machine (SVM). Hasil evaluasi, menunjukkan bahwa metode SVM lebih baik daripada metode RNN [14]. Ziedhan Alifio Diekson  dkk, membahas kepuasan pelanggan terhadap layanan 
Traveloka. Dataset dikumpulkan dari platform media sosial yang terdiri dari 1200 tweet terkait Traveloka. Penelitian ini menggunakan tiga metode klasifikasi: Support Model Vektor (SVM), Regresi Logistik, dan Naive Bayes. Hasil menunjukkan, dari 1200 tweets  
kebenyakan memberikan nilai postif terhadap traveloka. Hasilnya menunjukkan bahwa SVM lebih baik akurasi dalam menentukan sentimen tweet tentang Traveloka [15]. Penilitian bertujuan mengimplementasikan  dan meningkatkan performa akurasi dari kinerja algoritma SVM  dalam konteks analisis sentimen. SVM merupakan algoritma klasifikasi yang  bagus  dan efektif, terutama 
dalam kasus pemisahan linear dan non-linear. Sentimen  
analisis adalah teknik dalam  digunakan untuk mengidentifikasi, memahami, dan mengklasifikasikan sentimen atau opini dalam teks.  Penelitian ini, akan dilakukan dengan mengembangkan  sentiment analisis menggunakan algoritma Support Vector Machine dalam  
menentukan aplikasi belajar online  terbaik dengan menggukur kepuasan dari konsumen dan bedasarkan pengalaman pengguna.  Penelitian memanfaatkan ulasan yang tersedia di Google Play Store. Hasil dari analisis pada penelitian ini dapat membandingkan hasil sentimen antara dua atau lebih dari brand  aplikasi belajar online  
berdasarkan tingkat akurasi dan klasifikasi sentimen analisis menggunakan SVM.  

2. Metode  Penelitian  
Pada tahap ini, akan dijelaskan mengenai proses dan 
tahapan mengenai metode penelitian yang digunakan. 
Tahapan penelitian dijelaskan secara runtut pada Gambar 1.kerangkan Umum Penelitian. Berikut alur penelitian.  
Gambar 1. Kerangka Umum Penelitian  
Metode penelitian, dimulai dari tahapan pengumpulan data yang dilakukan dengan teknik scraping data di Google PlayStore. Kemudian, masuk ke tahapan pengolahan data. Pengolahan data dilakukan dengan teknik preprocessing data, yang meliput i cleansing, case folding, tokenize dan filter stopwords . Selanjutnya, data akan diklasifikasi menggunakan algoritma SVM, 
sehingga menghasilkan keluaran berupa sentimen negatif dan positif.  
2.1. Scraping  Data.
Teknik Scraping  merupakan teknik untuk mengubah data web yang tidak terstruktur menjadi data terstruktur yang dapat disimpan dan dianalisis dalam database atau spreadsheet pusat.  Proses web Scraping, dibagi menjadi 3 tahap yaitu Fetching , Extraction , dan Transformation. Tahap Fetching dilakukan dengan akses melalui 
protokol HTTP, untuk mengirim dan menerima permintaan dari server web. Kemudian dilakukan Extraction , melalui halaman HTML dengan melakukan parsing data. Setelah data terkumpul, dilakukan 
Transformation  data, u ntuk mendapatkan data yang terstruktur [16]. 
2.2. Data Set  
Pengumpulan data dilakukan dengan menggunakan data yang diperoleh dari Platform Google Play Store sebagai penyedia aplikasi. Data dikumpulkan dari ulasan beberapa aplikasi b elajar online  seperti Ruangguru, Zenius dan Quipper. Proses pengumpulan data dengan menggunakan bantuan library dari pemrograman Phyton. google-play-scraper merupakan library  yang digunakan penambangan data dari Google PlayStore, dilakukan dengan menggunakan Token , untuk meminta hak akses penggunaan data. Pengambilan data dilakukan dengan membangun sistem Scraping  data. Data hasil Scraping ini dimasukkan ke database untuk diproses 
lebih lanjut . 
2.3. Text Preprocessing  
Tahap teks prepocessing diguna kan untuk memperoleh data yang sesuai dengan proses dari sistem yang akan dibangun, dimana sudah ada pengurangan kosa kata, menghilangkan noise,  membuat data lebih terstruktur sehingga dihapakan dapat mempermudah dan 
mempercepat proses. Adapun tahapan yang  dilakukan pada teks prepocessing diantaranya yaitu, normalisasi, case folding, cleaning, tokenizing  dan Stopword. Normalisasi, sebuah data teks diperlukan pengecekan apakah sebuah kata termasuk dalam kamus bahasa 
Indonesia.  Case Folding, mengubah  huruf besar menjadi kecil untuk menyamakan atau menyeragamkan karakter pada data teks [17]. Cleaning, cleaning merupakan proses membersihkan sebuah review  atau penilaian dari kata-kata yang tidak diperlukan untuk mengurangi proses noise pada proses klasifikasi.  Tokenizing , proses tokenizing dan Stopword adalah tahap pemotongan string masukan bedasarkan kata-kata yang menyusun atau dengan kata lain pemecahan kalimat menjadi kata-kata kemudian diubah menjadi bagian token-token yang akan digunakan dalam klasifikasi SVM  dan pe nghilang kata sambung atau kata umum yang besar dan tak mempunyai makna [18]. 
2.4. Klasifikasi SVM  
Support Vector Machine (SVM)  adalah salah satu algoritma yang sangat berguna dalam klasifikasi  data yang besar. Ide Algoritma SVM diciptakan oleh Vladimir Vapnik dan sebagai algoritma yang efisien dan bisa diterapkan di berbagai bidang [19]. SVM merupakan 
pembelajaran dengan analisa data dan mengenali sebuah pola. Standar dari SVM yaitu mengambil himpunan data masukan dan memprediksi untuk setiap masukkan yang diberikan, hasil kemungkinan masukkan adalah anggota dari salah satu kelas dari dua kelas yan g ada, yang mana membuat algoritma SVM sebagai penggolong non probabilistic linier biner , dikarenakan algoritma SVM sebuah pengklasifikasi, dengan kemudian diberi himpuanan pelatihan yang mana masing-masing ditandai sebagai m ilik salah satu dari dua kategori[20]. klasifikasi linier SVM dinotasikan sebagai formula perumusan berikut [21]: 
ð‘“(ð‘¥)=ð‘Šð‘‡ð‘‹+ð‘                (1) 
Dalam klasifikasi SVM , fungsi klasifikasi dilambangkan dengan  ð‘“(ð‘¥). Fungsi ð‘“(ð‘¥) memprediksi kelas target y berdasarkan fitur input x . W adalah vektor bobot, X adalah vektor fitur masukan , dan b adalah bias.  Sehingga menurut Vapnik dan Cortes (1995) diperoleh persamaan formula perumusan sebagai berikut:  
[(ð‘Šð‘‡.ð‘¥ð‘–)+ð‘]â‰¥1 ð‘¢ð‘›ð‘¡ð‘¢ð‘˜  ð‘¦ð‘–= +1              (2) 
[(ð‘Šð‘‡.ð‘¥ð‘–)+ð‘]â‰¤1 ð‘¢ð‘›ð‘¡ð‘¢ð‘˜  ð‘¦ð‘–= âˆ’1              (3) 
Tabel 1.Confusion Matrix  
Kelas Prediksi  
Kelas Aktual   
Kelas Positif  
Kelas Negatif  
Kelas Positif  TP 
(True Positive)  FP 
(False 
Positive)  
Kelas 
Negatif  FN 
(False 
Negative)  TN 
(True 
Negative)  
Tabel 2.Data Set Penelitian  
Belajar Online  Token  Jumlah Data  
Ruang Guru  com.ruangguru.livestudents  10.000  
Zenius  net.zenius.mobile  10.000  
Quipper  com.quipper.school.assignment  10.000  
Tabel 3.Contoh Hasil Scraping  
Id Nama  Ulasan  
bc7e11c2 - 47be - 48a6 -be9e -537bf0862134  Anindya  aplikasinya bagus bangettt, ngebantu banget buat aku yang 
cara belajarnya memang audiovisual. tapi abis di update 
kok malah lag & ga bisa nonton vidio. aku coba install ulang, pas 
mau log in lagi malah ga bisa, selalu ke force stop sendiri. 
mohon perbaikannya ya ðŸ™ðŸ» 
17447195 - f12c-47e3 - 8a2e - fee8fe42a19d  Muhammad Iqbal  Mengapa setelah update aplikasi jadi sering force close dan stuck 
layar hitam, padahal saya sudah berulang kali instal dan uninstall. 
Saya sudah hapus cache aplikasi ruanggurunya dan restart hp saya, 
tapi hasilnya tetap tidak bisa di akses. Mohon kepada ruangguru 
untuk memperbaiki aplikasinya, kemungkinan ini adalah bug.  
Klasifikasi dila kukan dengan dataset latih yang dinotasikan dengan ð‘“(ð‘¥)  = himpunan data training , ke - i = 1, 2, ..., n dan, ð‘¦ð‘– = label kelas dari  ð’™ð‘°. 
Pengelompokkan menggunakan hyperplane linier seperti terlihat pada rumus. Parameter ð‘¤ menotasikan vector  terhadap hyperplane , ð‘ adalah offse t[22]. 
2.5. Evaluasi Hasil Analisa  
Tahap evaluasi menjadi salah satu tahap penting dalam membangun sebuah program sistem, dengan adanya tahap evaluasi maka pengguna akan mengetahui setiap point akurasi, presisi bahkan error  dari sebuah program sistem yang dibuatnya. Salah satu  teknik untuk mengetahui hasil evaluasi dari program sentimen 
analisis yaitu bisa menggunakan Confusion Matrix. Confusion Matrix  merupakan sebuah metode yang dapat mempermudah program untuk dapat menentukan nilai penting dalam menimbang nilai akurasi, pres isi, recall dan error dari sebuah program sistem, yang 
diilustrasikan pada Tabel 1. Confusion Matrix [23]. Confusion Matrix  terdiri dari kelas prediksi dan kelas aktual. Tabel 1 menggambarkan kinerja klasifikasi pada hasil prediksi dan nilai aktual dalam penelitian.  Matrix menampilkan jumlah data yang diklasifikasikan dengan benar dan salah dalam setiap kelasnya. Berdasarkan 
bentuk dari confusion matrix  diatas,  maka dengan mudah untuk dapat mengetahui nilai-nilai penting yang memudahkan peneliti untuk menghitung akurasi, recall dan presisi dari sebuah program sistem, maka berikut 
formula perumusannya:  
ð¶ð‘™ð‘Žð‘ ð‘–ð‘“ð‘–ð‘ð‘Žð‘¡ð‘–ð‘œð‘›  ð´ð‘˜ð‘¢ð‘Ÿð‘Žð‘ ð‘– = ð‘‡ð‘+ð‘‡ð‘›
ð‘‡ð‘+ð‘‡ð‘›+ð¹ð‘+ð¹ð‘›Ã— 100%      (4) 
ð‘…ð‘’ð‘ð‘Žð‘™ð‘™ = ð‘‡ð‘
ð‘‡ð‘+ð¹ð‘Ã— 100%                  (5) 
ð´ð‘˜ð‘¢ð‘Ÿ ð‘Žð‘ ð‘– = ð‘‡ð‘
ð‘‡ð‘+ð¹ð‘›Ã— 100%                 (6) 
Metode Confusion Matrix  merupakan metode yang populer saat ini untuk melaporkan kinerja  pengklasifikasi an dengan menghitung akurasi dan recall [24]. Hasil analisa disimpulkan dengan  confusion 
matrix yang dinotasi kan Tp, Tn, Fp, dan  Fn. Tp merupakan  Jumlah kelas positif yang diklasifikasi positif.  Tn penunjukkan  Jumlah kelas positif yang diklasifikasi negatif. Fp menunjukkan Jumlah kelas  
negatif yang diklasifikasi positif. Fn  adalah Jumlah kelas negatif yang diklasifikasi negatif.   

3.  Hasil dan Pembahasan  
Hasil dan pembahasan merupakan penjelasan hasil dari penelitian yang telah dilakukan mengenai Sentimen dan SVM terhadap data Ruang Guru, Zenius dan Quipper. Pada tahapan ini, hasil akan dijelaskan dari Pengu mpulan Data, Preprocessing  Data, Hasil dari Klasifikasi Sentimen Analisis menggunakan SVM dan Evaluasi terhadap hasil yang telah diperoleh dalam penelitian. Berikut penjelasan mengenai hasil dan pembahasan dari setiap langkah penelitian.  
3.1. Pengumpulan Data  
Data pada penelitian ini, diperoleh dengan cara melakukan scraping  data. Teknik scraping data digunakan dengan bantuan library google play scraper  yang tersedia di bahasa pemrograman python . Library 
dihubungkan dengan menggunakan API dan token yang terdapat pada Tabel 2.  Data yang dikumpulkan sebanyak 30.000 data dengan kategori most relevant. Hal ini dilakukan, agar data yang diperoleh adalah data yang terbaik dari setiap review  produk.  
Penelitian dilakukan dengan mengumpulkan 10.000 data setiap produknya. Setiap data dibagi menjadi 90% data latih dan 10% data uji untuk diproses kedalam penelitian. Seperti yang terlihat pada Tabel 2  menunjukkan token dan jumlah data yang diperoleh. Data yang terkumpul menjadi sebuah dataset yang dihimpun dalam lembar kerja CSV. Kemudian data diproses kedalam pemrosesan teks. Tabel 3 menunjukkan hasil dari scraping data yang telah 
diperoleh dan akan dijadikan sebuah dataset penelitian.  
3.2. Hasil Prepocesing Data  
Tahap selanjutnya, yaitu preprocesing  data. Data yang telah diperoleh dijadikan sebuah dataset yang siap untuk 
Tabel 4. Contoh Hasil Normalisasi  Text Hasil  
Saya sangan membantu dgn aplikasi ini.. krena kata2nya yg 
sopan dan mudah di mengerti.. pokoknya baguslah. Cumana yg 
saya sarankan koinnya dimurahkan dikitlah.. soalnya 
kemahalan hehhe ðŸ˜ŠðŸ˜Š  Saya sangan membantu dgn aplikasi ini.. krena kata2nya yg sopan dan mudah di mengerti.. 
pokoknya baguslah. Cumana yg saya sarankan koinnya 
dimurahkan dikitlah.. soalnya kemahalan hehhe ðŸ˜ŠðŸ˜Š  
zenius keren asiik dan bikin semngat belajar !  
zenius keren asiik dan bikin semngat belajar !  
Selalu berbuat yg terbaik utk kemajuan.....  Selalu berbuat yg terbaik utk kemajuan.....  
Tabel 5. Contoh Hasil Case Folding  
Text Hasil  
Saya sangan membantu dgn aplikasi ini.. krena kata2nya yg 
sopan dan mudah di mengerti.. pokoknya baguslah. Cumana yg 
saya sarankan koinnya dimurahkan dikitlah.. soalnya 
kemahalan hehhe ðŸ˜ŠðŸ˜Š  saya sangan membantu dgn 
aplikasi ini.. krena  kata2nya yg sopan dan mudah di mengerti.. 
pokoknya baguslah. cumana yg saya sarankan koinnya 
dimurahkan dikitlah.. soalnya kemahalan hehhe ðŸ˜ŠðŸ˜Š  
zenius keren asiik dan bikin semngat belajar !  
zenius keren asiik dan bikin 
semngat belajar !  
Selalu berbuat yg terbaik utk kemajuan.....  selalu berbuat yg terbaik utk kemajuan.....  
diolah kedalam sistem. Data akan melalui beberapa tahapan  untuk membersihkan, memformat, dan menyiapkan data teks sebelum menggunakannya sebagai input untuk model analisis sentimen . Data akan diperbaiki dan menjadi data yang terstruktur.  Tahap 
preprocesing data meliputi normalisasi, case folding, 
cleaning, tokenizing, dan Stopword. Tahap awal yaitu normalisasi, data yang diproses dipastikan bahwa data mengandung bahasa indonesia. Selanjutanya, casefolding dilakukan untuk 
menyeragamkan data. Kata atau kalimat yang ada diubah kedalam bentuk huruf kecil semua  (lower case). Contoh hasil Normalisasi dan casefolding  terlihat pada Tabel 4 dan Tabel 5. Cleansing merupakan proses pembersihan sebuah kalimat atau kata dari beberapa karakter yang tidak bermakna. Proses, pembersihan dilakukan dengan menghilang URL  dari dalam konten, menghapus  
hashtag  (#) dan mention  (@) dan tanda baca seperti titik(.),koma (,), dan lain -lain. Karakter emoticon juga dihilangkan . Cleansing dilakukan untuk membersihkan teks dari karakter khusus, menghilangkan noise yang tidak relevan  dan mempermudah proses pembuatan tokenize  stopword. Berikut adalah contoh dari hasil 
proses cleans ing yang dilakukan, seperti yang terlihat pada Tabel 6.  
3.3. Klasifikasi Sentimen Analisis  Menggunakan SVM  
Sentimen analisis merupakan pengolahan sebuah kata atau kalimat untuk mendapatkan informasi. Data Ruang  guru, Zenius dan Quipper diolah untuk mendapatkan  
Tabel 6. Contoh Hasil Cleansing  
Text Hasil  
saya sangan membantu dgn aplikasi ini.. krena kata2nya yg 
sopan dan mudah di mengerti.. pokoknya baguslah. cumana yg 
saya sarankan koinnya dimurahkan dikitlah.. soalnya kemahalan hehhe ðŸ˜ŠðŸ˜Š  saya sangan membantu dgn aplikasi ini krena katanya yg sopan dan mudah di mengerti pokoknya baguslah cumana yg saya sarankan koinnya dimurahkan dikitlah soalnya 
kemahalan hehhe  
zenius keren asiik dan bikin semngat belajar !  
zenius keren asiik dan bikin semngat belajar  selalu berbuat yg terbaik utk kemajuan.....  selalu berbuat yg terbaik utk 
kemajuan  
Tabel 7.Contoh Hasil Tokenize  
Text Hasil  
saya sangan membantu dgn aplikasi ini krena katanya yg  
sopan dan mudah di mengerti pokoknya baguslah cumana yg saya sarankan koinnya dimurahkan dikitlah soalnya 
kemahalan hehhe   [â€˜sayaâ€™,â€™sanganâ€™, â€˜membantuâ€™, â€˜dgnâ€™, â€˜aplikasiâ€™, â€˜iniâ€™, â€˜krenaâ€™, â€˜katanyaâ€™, â€˜ygâ€™, â€˜sopanâ€™, â€˜danâ€™, â€˜mudahâ€™, â€˜diâ€™, â€˜mengertiâ€™, 
â€˜pokokn yaâ€™, â€˜baguslahâ€™, â€˜cumanaâ€™, â€˜ygâ€™, â€˜sayaâ€™, â€˜sarankanâ€™, â€˜koinnyaâ€™, â€˜dimurahkanâ€™, â€˜dikitlahâ€™, â€˜soalnyaâ€™, â€˜kemahalanâ€™, â€˜hehheâ€™]  
zenius keren asiik dan bikin semngat belajar  [â€˜zeniusâ€™, â€˜kerenâ€™, â€˜asiikâ€™, â€˜danâ€™, â€˜bikinâ€™, â€˜semngatâ€™, â€˜belajarâ€™]  
selalu berbuat yg  terbaik utk kemajuan [â€˜selaluâ€™,â€™berbuatâ€™, â€˜ygâ€™, â€˜terbaikâ€™, â€˜utkâ€™, â€˜kemajuanâ€™]  
Tokenize merupakan tahapan untuk mengubah data ke dalam struktur text menjadi kata. Kemudian Stopword  merupakan proses untuk menghilangkan kata-kata yang jumlahnya besar namun tidak memiliki makna. Struktur kata yang telah diubah, akan menjadi sebuah token-token. Token ini, berfungsi untuk membantu proses perhitungan dan menjadi perhitungan ke dalam sebuah array data. Proses tokenize  dan Stopword, dilihatkan dalam Tabel 7 dan Tabel 8 dalam mendapatkan sebuah informasi mengenai produk tersebut. Setelah melalui tahap preprocessing, data siap diolah dan dianalisa untuk menghasilkan sebuah informasi, berupa sentimen negatif, netral dan positif. Klasifikasi dilakukan dengan membagi data menjadi data latih dan data uji . Peneltian melakukan percobaan perbandingan 90% data latih dan 10% data uji.  Data latih diberi label dengan nilai 1, 0, dan -1. Nilai 1 berarti po sitif, nilai 0 berarti netral dan -1 berarti negatif.  Hasil klasifikasi sentimen dilihatkan pada Gambar  2. Analisa sentimen pada Gambar 2, menunjukkan bahwa 
data yang ada berhasil diolah dan diproses menjadi sebuah informasi. Data sebanyak 30.000, yang dibagi menjadi 10.000/produk, dapat begitu mudah dianalisa dengan bantuan sentimen analisis. Nilai positif banyak diberikan pengguna kepada lembaga belajar online Ruang Guru. Nilai netral dan negatif diberikan pengguna kepada lembaga Quipper. Akan tetapi tang gapan pengguna mengenai Quipper, Zenius dan Ruang Guru, semuanya memberikan respon positif. Hal ini, membuktikan bahwa masyarakat pada umumnya dan khususnya peserta didik, sangat menyambut dengan baik kemajuan teknologi dan pendidikan.   
Tabel 8. Contoh Hasil Stopword  
Text Hasil  
saya sangan membantu dgn aplikasi ini krena katanya yg 
sopan dan mudah di mengerti pokoknya baguslah cumana yg 
saya sarankan koinnya dimurahkan dikitlah soalnya 
kemahalan hehhe   [â€™sanganâ€™, â€˜membantuâ€™, â€˜dgnâ€™, â€˜aplikasiâ€™, â€˜krenaâ€™, â€˜katanyaâ€™, â€˜ygâ€™, â€˜sopanâ€™, â€˜mudahâ€™,  â€˜mengertiâ€™, â€˜pokoknyaâ€™, â€˜baguslahâ€™, â€˜cumanaâ€™, â€˜ygâ€™, â€˜sarankanâ€™, â€˜koinnyaâ€™, â€˜dimurahkanâ€™, â€˜dikitlahâ€™, â€˜soalnyaâ€™, â€˜kemahalanâ€™, â€˜hehheâ€™]  
zenius keren asiik dan bikin semngat belajar  [â€˜zeniusâ€™, â€˜kerenâ€™,  â€˜asiikâ€™, â€˜bikinâ€™, â€˜semngatâ€™,â€˜ajarâ€™]  
selalu berbuat yg terbaik utk kemajuan  [â€™berbuatâ€™, â€˜ygâ€™, â€˜terbaikâ€™, â€˜utkâ€™, â€˜kemajuanâ€™]  
Gambar 2. Hasil Klasifikasi Sentimen  
Gambar 3. Hasil Evaluasi Ruang Guru  
3.4 Hasil dan Evaluasi  
Tahap akhir dari penelitian yaitu hasil dan evaluasi terhadap klasifikasi sentimen analisis menggunakan SVM. Hasil dan evaluasi didapatkan dengan merumuskan nilai akurasi, recall dan precision. Nilai tersebut didasarkan pada perhitun gan sentimen dan SVM yang telah dilakukan. Gambar 2, Gambar 3, dan Gambar 4, merupakan evaluasi hasil dari proses klasifikasi sentimen yang telah dijalankan.  
Nilai akurasi digunakan untuk mengukur seberapa tepat, data sentimen melakukan prediksi klasifikas inya dengan benar. Penelitian sentimen analisis menggunakan SVM, menunjukkan bahwa nilai akurasi yang dilakukan pada data RuangGuru menunjukkan sebesar 99% dan menjadi  lebih tinggi dibandingkan data ulasan zenius dan Quipper. Nilai precision,  recall  dan f1-score, juga menunjukkan bahwa penelitian dengan menggunakan data Ruangguru mendapatkan nilai yang baik, yaitu dengan rata -rata 99%.   
 Gambar 4.Hasil Evaluasi Zenius  
 Gambar 5. Hasil Evaluasi Quipper  

4.  Kesimpulan  
Berdasarkan penelitian yang sudah dilakukan, Sentimen analisis menggunakan algoritma SVM  dapat diimplementasikan dengan baik dalam mengklasifikasikan Ruang Guru, Zenius, dan Quipper. Hasil dari penelitian menunjukkan bahwa, data Klasifikasi sentimen dengan SVM, mempunyai akurasi rata-rata untuk Ruang Guru sebesar 99%, Zenius sebesar 96%, dan Quipper sebesar 82%. Penelitian ini berhasil mendapatkan dan meningkatkan performance measure pada akurasi SVM  dengan nilai akurasi 99%. Hasi l ini, 
didapatkan dengan membandingkan data pada Ruang Guru, Zenius dan Quipper.  Penelitian menggunakan perbandingan data 90%:10%. Kedepannya, diharapkan bisa mencoba performa SVM 
dan sentimen analisis dengan membandingkan  perbandingan data latih dan data uji yang lain.
  
Daftar Pustaka  
[1] A. Z. Shoumi, â€œPeran Multimedia Dalam Pendidikan Pada Aplikasi Ruang Guru,â€ in Prosiding Seminar Nasional Cendekiawan , 2019, hal. 2. doi: 10.25105/semnas.v0i0.5809.  
[2] A. Ramad hayanti, â€œAnalisis Strategi Belajar Dengan Metode Bimbel Online Terhadap Kemampuan Pemahaman Kosa Kata Bahasa Inggris dan Pronunciation (Pengucapan/pelafalan) 
Berbahasa Remaja Saat Ini,â€ KREDO  J. Ilm. Bhs. dan Sastra , vol. 2, no. 1, hal. 39 â€“52, 2018, doi:  10.24176/kredo.v2i1.2580.  
[3] A. F. Hayati, â€œPerbedaan Hasil Belajar Siswa Menggunakan Bimbingan Belajar Online,â€ J. Inov. Pendidik. Ekon. , vol. 10, no.1, hal. 79 â€“85, 2020, doi: 10.24036/011085130.  
[4] M. I. Ahmadi, F. Apriani, M. Kurniasari, S. Handayani, dan D. Gustian, â€œSentiment Analysis Online Shop on the Play Store Using Method Support Vector Machine (Svm,â€ in Seminar Nasional â€¦ , 2020, hal. 196 â€“203. [Daring]. Tersedia pada: 
http://jurnal.upnyk.ac.i d/index.php/semnasif/articl
Quipper Zenius Ruang Guru
Positif 51.2 77.9 82.8
Netral 11.9 7.3 6.3
Negatif 36.8 14.8 10.9020406080100 Persentase dalam %Klasifikasi Sentimene/view/4101  
[5] M. M. Jawad Soumik, S. Salvi Md Farhavi, F. Eva, T. Sinha, dan M. S. Alam, â€œEmploying machine learning techniques on sentiment analysis of google play store bangla reviews,â€ in 2019 22nd International Conference o n Computer and Information Technology, ICCIT 2019 , 2019, hal. 1â€“5. doi: 10.1109/ICCIT48885.2019.9038348.  
[6] R. Wahyudi dan G. Kusumawardana, â€œAnalisis Sentimen pada Aplikasi Grab di Google Play Store Menggunakan Support Vector Machine,â€ J. Inform. , vol. 8 , no. 2, hal. 200 â€“207, 2021, doi: 
10.31294/ji.v8i2.9681.  
[7] S. Venkatakrishnan, A. Kaushik, dan J. K. Verma, â€œSentiment Analysis on Google Play Store Data Using Deep Learning,â€ in Applications of Machine Learning , 2020, hal. 15 â€“30. doi: 10.1007/978 -981-15-3357 -0_2. 
[8] L. Kirtibas Singh dan R. Renuga Devi, â€œStudent feedback sentiment analysis: A review,â€ in Materials Today: Proceedings , 2021, no. xxxx. doi: 10.1016/j.matpr.2020.10.782.  
[9] Q. Li, S. Shah, R. Fang, A. Nourbakhsh, dan X. Liu, â€œTweet Sentimen t Analysis by Incorporating Sentiment -Specific Word Embedding and Weighted Text Features,â€ Proc. - 2016 IEEE/WIC/ACM Int. Conf. Web Intell. WI 2016,  hal. 568 â€“571, 2017, doi: 10.1109/WI.2016.0097.  
[10] K. Jindal dan R. Aron, â€œMaterials Todayâ€¯: Proceedings A  systematic study of sentiment analysis for social media data,â€ in Materials Today: Proceedings , 2021, no. xxxx. doi: 10.1016/j.matpr.2021.01.048.  
[11] S. Vashishtha dan S. Susan, â€œFuzzy rule based unsupervised sentiment analysis from social media posts,â€ Expert Syst. Appl. , vol. 138, hal. 112834 â€“112849, 2019, doi: 10.1016/j.eswa.2019.112834.  
[12] P. Chitra dkk., â€œMaterials Todayâ€¯: Proceedings Sentiment analysis of product feedback using natural language processing,â€ 2021. doi: 10.1016/j.matpr.2020.12.1061.  
[13] O. Alqaryouti, N. Siyam, A. A. Monem, dan K. Shaalan, â€œAspect -based sentiment analysis using smart government review data,â€ Appl. Comput. Informatics , vol. 3, hal. 11 â€“23, 2019, doi: 10.1016/j.aci.2019.11.003.  
[14] M. Al -Smadi, O. Qawasmeh, M. Al -Ayyo ub, Y. Jararweh, dan B. Gupta, â€œDeep Recurrent neural network vs. support vector machine for aspect-based sentiment analysis of Arabic hotelsâ€™ reviews,â€ J. Comput. Sci. , vol. 27, hal. 386 â€“393, 2018, doi: 10.1016/j.jocs.2017.11.006.  
[15] Z. A. Diekson, M. R . B. Prakoso, M. S. Q. Putra, M. S. A. F. Syaputra, S. Achmad, dan R. Sutoyo, â€œSentiment analysis for customer review: Case study of Traveloka,â€ Procedia Comput. Sci. , vol. 216, no. 2022, hal. 682 â€“690, 2023, doi: 10.1016/j.procs.2022.12.184.  
[16] M. A. Khd er, â€œWeb scraping or web crawling: State of art, techniques, approaches and application,â€ Int. J. Adv. Soft Comput. its Appl. , vol. 13, no. 3, hal. 144 â€“168, 2021, doi: 10.15849/ijasca.211128.11.  
[17] E. Fitri, â€œAnalisis Sentimen Terhadap Aplikasi 
Ruangguru  Menggunakan Algoritma Naive Bayes, Random Forest Dan Support Vector Machine,â€ J. Transform. , vol. 18, no. 1, hal. 71, 2020, doi: 10.26623/transformatika.v18i1.2317.  
[18] A. P. Nardilasari, A. L. Hananto, S. S. Hilabi, dan B. Priyatna, â€œAnalisis Sentimen C alon Presiden 2024 Menggunakan Algoritma SVM,â€ vol. 7, no. 1, hal. 11 â€“18, 2024.  
[19] D. Wang dan Y. Zhao, â€œUsing News to Predict Investor Sentiment: Based on SVM Model,â€ Procedia Comput. Sci. , vol. 174, no. 2019, hal. 191â€“199, 2020, doi: 10.1016/j.procs.20 20.06.074.  
[20] A. P. Giovani, A. Ardiansyah, T. Haryanti, L. Kurniawati, dan W. Gata, â€œAnalisis Sentimen Aplikasi Ruang Guru Di Twitter Menggunakan Algoritma Klasifikasi,â€ J. Teknoinfo , vol. 14, no. 2, hal. 115, 2020, doi: 10.33365/jti.v14i2.679.  
[21] S. Bo, S. J. Song, dan W. Cheng, â€œA new algorithm of support vector machine based on weighted feature,â€ Proc. 2009 Int. Conf. Mach. Learn. Cybern. , vol. 3, no. July, hal. 1616 â€“1620, 2009, doi: 10.1109/ICMLC.2009.5212256.  
[22] C. O. Sianturi, S. C. Sianturi, d an A. H. Mondolang, â€œKlasifikasi Citra Daun Anggur Menggunakan SVM Kernel Linear,â€ vol. 7, no. 1, hal. 19 â€“26, 2023.  
[23] I. Markoulidakis, G. Kopsiaftis, I. Rallis, dan I. Georgoulas, â€œMulti -Class Confusion Matrix Reduction method and its application on Net Promoter Score classification problem,â€ ACM Int. Conf. Proceeding Ser. , no. Cx, hal. 412 â€“419, 2021, doi: 10.1145/345389 2.3461323.  
[24] M. Heydarian dan T. E. Doyle, â€œMLCMâ€¯: Multi-Label Confusion Matrix,â€ vol. 2, hal. 19083 â€“19095, 2022.  
",Sentimen analisis,"SVM, Support Vector Machine",data yang diperoleh dari Platform Google Play,"akurasi, precision, recall, f1-score"
"SENTIMEN ANALISIS TENTANG KEBIJAKAN PEMERINTAH TERHADAP KASUS CORONA MENGGUNAKAN METODE NAIVE BAYES 
","SENTIMEN ANALISIS TENTANG KEBIJAKAN PEMERINTAH TERHADAP KASUS CORONA MENGGUNAKAN METODE NAIVE BAYES 

Nurman Satya Marga1, Auliya Rahman Isnain2, Debby Alita3 

Abstract  
The Corona virus or often known as Covid19 is a pandemic that attacks the world today, due to the impact of the corona virus not only has an impact on h ealth but also social, cultural and economic 
impacts. The Indonesian government enforces the New Normal rule to maintain economic stabilization and also contain the spread of the virus. This has become a hot topic of conversation on social media, Twitter, many people think positively or negatively. these responses are the basis for conducting sentiment research. Sentiment research carried out is a representation of text mining and text processing using machine learning using the Naive Bayes Classifier class ification method, the aim of the analysis is to find out whether public sentiment towards the New Normal policy produces positive or negative results, and also as a basis for measuring the performance of the TF feature extraction. TF-Idf and N-gram on machine learning using the Naive Bayes method in classifying sentiment tweet data against the New Normal policy. The results of this study produce a value from testing the accuracy of using the Naive Bayes method 
with the TF -IDF feature selection getting a total  accuracy of 81% with a Precission value of 78%, Recall 91% and f1-Score of 84%, while the highest results are obtained from the use of the Naive algorithm parameter. Bayes and N -Gram types of Trigram are 84% with a Precission value of 84%, Recall 86%, and  f1-Score 85%. The Naive Bayes algorithm with the use of the trigram type N-Gram feature extraction shows a fairly good performance in the process of classifying public tweet data against government policies on the implementation of the New Normal system.  

Keywords:  Analysis Sentiment Corona, New Normal, Naive Bayes, N-Gram, Tf-IDF. 

Abstrak  
Virus Corona atau yang sering dikenal dengan Covid19 menjadi pandemi yang menyerang dunia saat ini, akibat dampak virus corona bukan saja berdampak pada kesehatan tapi juga sosial, budaya serta ekonomi. Pemerintah Indonesia memberlakukan peratutan New Normal dalam menjaga stabilisasi ekonomi dan juga menahan penyebaran virus. Hal ini menjadi perbincangan hangat di media sosial twitter banyak masyarakat yang beranggapan positif maupun negatif. tanggapan ini yang dijadikan dasar untuk melakukan penelitian sentimen. Penelitian Sentimen yang dilakukan adalah representasi dari text mining dan text processing menggunakan pembelajaran mesin dengan menggunakan metode klasifikasi Naive Bayes Classifier, tujuan analisis adalah untuk mengetahui apakah sentimen masyarakat terhadap kebijakan New Normal membuahkan hasil positif atau negatif, dan juga sebagai dasar pengukuran performa ekstrasi fitur TF-Idf dan N-gram pada machine learning menggunakan metode Naive Bayes dalam pengklasifikasian data tweet sentimen terhadap kebijakan New Normal. Hasil dari penelitian ini menghasilkan nilai dari pengujian akurasi penggunaan metode Naive Bayes  dengan seleksi fitur TF-IDF mendapat total akurasi sebesar 81% dengan nilai Precission 78%, Recall 91% dan f1-Score 84%, sementara hasil tertinggi didapatkan dari penggunaan parameter algoritma Naive Bayes dan N-Gram jenis Trigram yaitu sebesar 84% dengan nilai Precission 84%, Recall 86%, dan f1-Score 85%. Algoritma Naive Bayes dengan penggunaan ekstrasi fitur N-Gram jenis trigram menunjukan performa yang cukup baik dalam proses pengklasifikasian data tweet masyarakat terhadap kebijakan pemerintah pada pemberlakuan sistem New Normal. 

Kata Kunci: Sentimen analisis corona, new normal, Naive Bayes, N-Gram, Tf-IDF. 
   
PENDAHULUAN  
Pada era ini media sosial telah menjadi bagian yang penting dalam kehidupan masyarakat luas sehari-hari (Ika Alfina  dkk, 2017), dengan keberadaam media sosial mampu mengubah cara orang dalam mengekspresikan pemikiran dan perasaan. Media sosial yang ma sih banyak digunakan oleh masyarakat saat ini, salah satunya yaitu Twitter (Isnain dkk, 2020). Twitter merupakan layanan jejaring sosial dan mikroblog  daring yang memungkinkan pengguna untuk 
mengirim dan membaca pesan berbasis teks hingga 140 karakter, yang dikenal dengan istilah Tweet  (Patihullah, 2018) . Twitter mengalami pertumbuhan yang cepat dalam meraih popularitas di seluruh dunia. Hingga bulan Januari 2013, terdapat lebih dari 500 juta pengguna internet terdaftar di Twitter, 200 juta di antaranya adalah pengguna aktif. Kenaikan pengguna Twitt er umumnya berlangsung saat terjadinya peristiwa -peristiwa populer. Pada awal 2013, pengguna Twitter mengirim lebih dari 340 juta Tweet  per hari, dan Twitter menangani lebih dari 1,6 miliar permintaan pencarian per hari. Melihat tingginya popularitas Twitt er menyebabkan media jejaring sosial ini telah dimanfaatkan dalam berbagai  aspek keperluan, termasuk topik yang saat ini sedang banyak di perbincangkan di seluruh dunia, yaitu Covid-19. Dalam upaya pencegahan dan pemutus penularan pandemi Covid -19 pemerintah Indonesia mengeluarkan beberapa kebijakan mulai dari larangan mengadakan kegiatan sosial kemasyarakatan (Sosial Distancing) yang bertujuan memutus rantai penularan virus, hingga melakukan tatanan hidup normal baru ( New Normal ) dalam upaya menstabilisasi kan ekonomi masyarakat. Semua program tersebut telah berjalan namun saat ini belum ada penelitian tentang respon masyarakat terhadap kebijakan tersebut. Beberapa warga menilai positif kebijakan pemerintah dalam memberlakukan New Normal  dalam masa pandemi Covid-19 dari pemantauan di media sosial twitter diketahui masyarakat memberikan berbagai opini mulai dari opini positif hingga opini negatif pada kebijakan tersebut. Pendapat 
negatif bisa disebabkan karena ada kekurangan atau ketidaksempurnaan informasi pada kebijakan â€“ kebijakan pemerintah dalam menangani Covid -19 atau karena faktor subjektifitas. Opini â€“ opini dari masyarakat ini kemudian 
dapat diolah dan dianalisis dengan menggunakan metode â€“ metode yang dikenal dengan analisis sentimen (Hayuningtyas & Sari, 2019). Analisis sentimen atau Opinion Minning  yaitu suatu bidang pengelolaan data tekstual yang melakukan studi berdasarkan opini, sentimen, evaluasi, prilaku dan emosi seseorang yang dapat digunakan sebagai bahan evaluasi (Alita dkk, 2020) . Dalam metode analisis sentimen dibuthkan teknik pengumpulan data, dalam hal ini data yang digunakan berupa teks berbahasa Indonesia yang di ambil dari tweet  twitter menggunakan pendekatan Text Mining serta pengklasifikasian data dengan pendekatan Machine Learning. Berdasarkan pemaparan masalah yang ada analis is sentimen menggunakan metode Machine Learning  yaitu Naive Bayes Classifier dilakukan dalam penelitian ini dengan tujuan mengetahui respon masyarakat mengenai kebijakan pemerintah dalam menangani kasus covid19 dengan membagi 2 klasifikasi sentimen yaitu Positif dan Negatif. Proses analisis ini dilakukan dengan menggunakan pendekatan Text Mining , dan Machine Learning dalam pelaksanaannya hingga me nghasilkan kesimpulan opini masyarakat mengenai kebijakan tersebut dan juga menguji 
tingkat akurasi, presisi, recall, dan f1 -score pada metode Naive Bayes Classifier dengan ekstrasi fitur N-Gram dan TF-Idf dalam mengklasifikasikan data tweet tentang kebija kan pemerintah mengenai kasus covid19.  

TELAAH PUSTAKA  
Sentimen Analisis  
Sentimen analisis atau Opinion Mining  adalah studi komputasi untuk mengenali dan mengekspresikan opini, sentimen, evaluasi, sikap, emosi, subjektifitas, penilaian atau pandangan yang t erdapat dalam suatu teks (Liu, 2012). Dalam sentimen anali sis terdapat beberapa penelitian yang telah dilakukan menggunakan algoritma Naive Bayes 
Classifier (NBC).  
Twitter  
Twitter adalah salah satu media komunikasi dan media sosial yang tercipta dengan fungsi pengguna dapat berekspresi dan berbagi informasi dengan mudah, Twitter pada saat ini banyak diminati oleh mayarakat di dunia,media sosial ini dapat membagikan kabar terkini tentang berbagai hal seperti topik utama, berekspresi, beraspirasi, dan beropini yang ditulis oleh pengguna twitter (Haranto & Sari, 2019). Twitter merupakan media yang bersifat terbuka (public)  dengan demikian  dapat diakses dan di lihat oleh semua orang, oleh karena itu pengguna twitter akan lebih mudah terhubung dengan pengguna twitter lainnya tak terkecuali orang terdekatnya, serta lebih 
masif dalam mengikuti tren, cerita, informasi dan berita ter baru dari seluruh penjuru dunia , diseluruh tempat, dan disegala waktu.   
Text Mining  
Text mining  dapat didefinisikan secara luas sebagai proses untuk memperoleh suatu pengetahuan menggunakan seperangkat alat anlisis, di mana pengguna berinteraksi dengan sekumpulan dokumen dari waktu ke waktu. Seperti halnya data mining, text mining  berusaha untuk mengekstraksi informasi yang berguna dari suatu sumber data (sekumpulan dokumen) melalui identifikasi dan eksplorasi pola yang ada. Perbedaan antara data mining  dan text 
mining  terletak pada preprocessing. Pada data mining preprocessing berfokus pada penomoran (indexing) dan normalisasi data, sedangkan text minin g berfokus pada identifikasi dan ekstraksi fitur (Feldman & Sanger, 2007) . 
Text Preprocessing  
Tahap yang d ilakukan setelah melakukan pengumpulan data teks, yaitu memutuskan adakah data yang perlu dilakukan modifikasi atau restrukturisasi menggunakan suatu cara tertentu yang dapat mempermudah proses pencarian. Jenis perubahan yang dibuat pada tahap ini disebut transformasi teks atau lebih sering disebut dengan Text Processing  (Croft  dkk, 2015). Text Processing  memiliki tujuan untuk mengubah bentuk kata dalam suatu indeks agar lebih konsisten.Indeks yang dimaksud dalam hal ini adalah representasi dari isi dokumen yang digunakan dalam pencarian. Banyak mesin tidak dapat membedakan antara huruf besar, huruf kecil, tanda baca dan banyak hal lain, maka dari itu Text Processing sangat dibutuhkan.  
Feature Selection  
Seleksi fitur atau Feature Selection  adalah suatu bidang penelitian pada data mining untuk dataset yang memiliki preproses penting untuk mereduksi dataset dengan menghilangkan fitur yang dianggap tidak penting dari suatu dataset  (Juen dkk , 2014) . Dikarenakan hal tersebut penghilangan atribut yang tidak penting dengan kelas label 
merupakan suatu hal penting yang harus dilakukan dalam upaya peningkatan kinerja mesin klasifikasi. Tujuan paling utama dari seleksi fitur yaitu  memilih fitur yang penting dan menghapus fitur yang tidak penting terhadap kelas label sehingga meningkatkan kinerja classifier  yang berguna dalam meningkatkan akurasi dan mengurangi waktu komputasi. (Jupriyadi, 2018) . 
TF-IDF 
TF-IDF adalahh suatu metode yang digunakan dalam kasus penghitungan bobot kata yang paling sering digunakan pada bidang information retrieval . Efesiensi dari metode ini cukup dikenal selain itu metode ini juga mudah dan m emiliki hasil yang akurat (Maarif, 2015) . Cara kerja dari metode ini yaitu akan menghitung nilai Term 
Frequency (TF) dan nilai Inverse Document Frequency  (IDF) pada setiap kata (token) di setiap dokumen dalam korpus. Metode ini nantinya akan menghitung bobot dari setiap token (t ) di dokumen (d) dengan rumus:  
-1
Keterangan :  
d : dokumen ke -d 
t : kata ke -t dari kata kunci  
W : bobot dokumen ke -d terhadap kata ke -t 
tf  : banyaknya kata yang dicari pada sebuah dokumen  
IDF  : Inversed Document Frequency  
Nilai IDF didapatkan dari :  
IDF  : log2 (D/df)         (2) 
Dimana :  
D  : total dokumen  
df  : banyak dokumen yang mengandung kata yang  dicari  
N-Gram  
N-Gram adalah penggabungan kata sifat yang seringkali muncul dalam tujuan menunjukan suatu sentimen (Indhiarta, 2017) . Terdapat beberapa jenis token dalam N -gram diantaranya Unigram, Bigram, dan Trigram. Unigram merupakan token yang hanya terdiri dari satu kata, Bigram yaitu token yang terdiri dari dua kata dan Trigram adalah token yang terdiri dari tiga kata.  Tujuan digunakan N-gram dikarnakan dalam bahasa Indonesia banyak frase yang tidak hanya terdiri dari satu kata.  
Naive Bayes Classifier  
Naive Bayes Classifier adalah suatu algoritma yang b erfungsi untuk mencari nilai probabilitas tertinggi dalam mengklasifikasi data uji pada kategori yang paling tepat  (Falahah, 2015) . Data uji yang dilakukan dalam penelitian ini adalah tweet masyarakat terhadap kebijakan pemerintah dalam mengatasi Covid -19. Ada dua tahapan pada klasifikasi dokumen.  Penerapan algoritma Naive Bayes dilakukan setiap representasi dokumen dengan atribut (x1,x2,x3,â€¦xn) dimana x1 merupakan kosakata pertama, x2 merupakan koskata kedua dan seterusnya. Lambang V yaitu 
melambangkan suatu himpunan kategori pada tweet. Saat proses klasifikasi algoritma Naive Bayes akan mencari probabilitas tertinggi dari semua kategori dokumen yang diujikan  (Alita dkk, 2019) . 
 
METODE PENELITIAN  
Tahapan  Penelitian  
Suatu penelitian adalah bertolak dari adanya permasalahan penting, menarik dan perlu ad anya pemecahan. Untuk menciptakan penelitian yang efektif & efisien, maka diperlukan sebuah kerangka berfikir yang tersusun secara terstruktur dan disampaikan melalui gambar dengan tahapan â€“ tahapan yang terstruktur bersangkutan dengan tindakan yang akan d ilakukan. Berikut kerangka berfikir dalam penelitian ini pada gambar dibawah ini :                                                                                                                                                                                                                     
Gambar 1 Tahapan Penelitian  
Pengumpulan Data  
Pengumpulan data atau Crawling adalah tahap awal dari penelitian ini, crawling  data berfungsi dalam pengumpulan dataset  (Buntoro, 2017) . Dataset yang dikumpulkan berupa  tweet berbahasa Indonesia tentang opini publik terhadap kebijakan pemerintah menangani Covid -19 dengan dengan keyword  â€œNewNormal â€ dan â€œNewNormal Indonesiaâ€.Crawling data tweet tersebut dilakukan pada tweet  yang dituliskan pengguna twitter 
pertanggal 6 Juli 2020 â€“ 25 Juli 2020,  mengg unakan Twitter API ( Application Programming Interface), bahasa pemrograman Python dan disimpan pada Database. Dari hasil pengumpulan data tweet  tersebut didapatkan dataset berjumlah 1823 data yang selanjutnya perlu dilakukan  pengolahan agar menjadi data yan g lebih mudah digunakan dalam proses analisis sentimen.  Berikut adalah contoh hasil dari crawling data twitter menggunkan library Tweepy  dalam bahasa pemrograman python:  
Tabel 1 Hasil Crawling  
Dokumen  Hasil Crawling Tweet  
D1 Kasus meninggal COVID tinggi https://t.co/NfhnfMjtXw  
D2 #NewNormal Indonesia akan mengatasi covid!!!!  
D3 Apakah sudah siap untuk Indonesia NewNormal?  
D4 Kebijakan ini baik bagi Perekonomian.  
D5 Pemimpin Dungu itu bencana!:@  
D6 Optimistis Industri berkembang   
Pre-Processing  Data  
Dataset yang dikumpulkan menggunakan library tweepy pada bahasa pemrograman Python belum cukup mudah dipahami  oleh karna itu diperlukan suatu pemrosesan kata (Text Processing) sehingga data menghasilkan kata-kata yang lebih ringkas yang berisi sentimen de ngan menyeleksi dan membuang kata -kata yang tidak diperlukan, Tahapan ini diperlukan untuk menghasilkan data masukan yang baik pada proses pelabelan, training dan testing  
(Suryono & Budi, 2019). Pre-processing data meliputi beberapa proses, yaitu :  
1. Escapping  HTML characters  
Pada awal pengumpulan data (crawling) terdapat tweet yang terdapat suatu link, dalam hal ini proses Escaping  HTML characters  sangat perlu dilakukan dikarnakan proses ini bertujuan untuk menghapus link URL dan juga karakter-karakter html yang ditemukan dalam suatu teks tweet.  
2. Case Folding  
Suatu proses penyeragaman kata pada sebuah tweet, dalam hal ini  huruf yang digunakan dalam kata adalah huruf kecil (lowercase). Data teks yang mengandung kata huruf besar akan diubah kedalam bentuk kata huruf yang kecil, contoh: â€œPenanggulangan Covid19â€ akan dirubah kedalam bentuk â€œpenanggulanan covid19â€.  
3. Stemming  
Proses seleksi kata yang memiliki kata sambung, kata imbuhan, kata ganti, dan kata kerja menjadi kata dasar, dengan menghapus awalan atau akhiran.contoh â€œBersama melawan virus coronaâ€ dirubah menjadi â€œsama lawan virus coronaâ€.  
4. Remove of punctuation  
Proses ini digunakan untuk menghapus karakter khusus seperti (#), @, (RT). Selain itu juga dilakukan penghapusan terhadap tanda baca(, . ? !, dll), angka numerik(0...9), dan karakter lainnya(+, $, ~, dll).  
5. Tokenization  
Proses untuk pemotongan kata dalam suatu kalimat  kedalam bentuk token, dimana tiap kata dalam satu kalimat dipisahkan oleh spasi.  
6.  Stopwords Removal  
Proses penghapusan kata yang tidak mempengaruhi  dalam proses klasifikasi contoh : dan, ke, atau, dari, yang, dll.  
N-Gram  
Tujuan digunakan N -gram dikarnaka n dalam bahasa Indonesia banyak frase yang tidak hanya terdiri dari satu kata. Dengan N -Gram kosakata menjadi lebih dapat terlihat nilai nya, contoh penggunaan N -Gram :  
Tabel 2 Perhitungan N-Gram  
Dokumen  N-Gram  Hasil Ekstrasi N-Gram  
D1 Unigram  kasus, men inggal, covid, tinggi Bigram  kasus meninggal, meninggal covid, covid tinggi  Trigram  kasus meninggal covid, meninggal covid tinggi  
D2 Unigram  newnormal, indonesia, atasi, covid  Bigram  newnormal indonesia, indonesia atasi, atasi covid  Trigram  newnor mal indonesia atasi, indonesia atasi covid  
D3 Unigram  apa, sudah, siap, indonesia, newnormal  Bigram  apa sudah, sudah siap, siap indonesia, indonesia newnormal  Trigram  apa sudah siap, sudah siap indonesia, siap indonesia newnormal  
D4 Unigram  kebijakan , baik, bagi, ekonomi  Bigram  kebijakan baik, baik bagi, bagi ekonomi  Trigram  kebijakan baik bagi, baik bagi ekonomi  
D5 Unigram  pemimpin, dungu, bencana  Bigram  pemimpin dumgu, dungu bencana  Trigram  pemimpin dungu bencana  
D6 Unigram  optimistis, industri, kembang  Bigram  optimistis industri, industri kembang Trigram  optimistis industri kembang  
TF-IDF  
TF-IDF yang merupakan suatu metode pembobotan kata yang dikenal cukup efisien, mudah, dan memiliki hasil yang akurat. Kata kata yang muncul dalam data tweet akan diberikan bobot sesuai jumlah kemunculuan.  Berikut adalah tahap proses pembobotan menggunakan seleksi fitur TF -IDF:  
Tabel 3 Perhitungan TF -IDF 
Term(t)  TF IDF Kelas 
Sentiman  D1 D2 D3 D4 D5 D6 
Kasus  1 0 0 0 0 0 0,778  Negatif  
Meninggal  1 0 0 0 0 0 0,778  Negatif  
Covid  1 1 0 0 0 0 0,477  Negatif  
Tinggi  1 0 0 0 0 0 0,778  Negatif  
Newnormal  0 1 1 0 0 0 0,477  Positif  
Indonesia  0 1 1 0 0 0 0,477  Positif  
Atasi  0 1 0 0 0 0 0,778  Positif  
Apa 0 0 1 0 0 0 0,778  Positif  
Sudah  0 0 1 0 0 0 0,778  Positif  
Siap 0 0 1 0 0 0 0,778  Positif  
Kebijakan  0 0 0 1 0 0 0,778  Positif  
Baik  0 0 0 1 0 0 0,778  Positif  
Ekonomi  0 0 0 1 0 0 0,778  Positif  
Pemimpin  0 0 0 0 1 0 0,778  Positif  
Dungu  0 0 0 0 1 0 0,778  Negatif  
Bencana  0 0 0 0 1 0 0,778  Negatif  
Optim is 0 0 0 0 0 1 0,778  Positif  
Industri  0 0 0 0 0 1 0,778  Positif  
Kembang  0 0 0 0 0 1 0,778  Positif  
Cara penghitungan TF -IDF sebagai b erikut :  
IDF=  log(D/df)          (3) 
Keterangan :  
D = Total dokumen  
Df = banyak dokumen yang mengandung kata yang dicari  
TF(D)  = jumlah kata di setiap dokumen -D 
Klasifikasi  
Klasifikasi merupakan suatu proses pengidentifikasian objek ke dalam sebuah kategori, kelas atau kelompok berdasarkan prosedur, definisi dan karakteristik yang telah ditentukan sebelumnya. Klasifikasi bert ujuan untuk menempatkan objek yang ditugaskan hanya ke salah satu kategori yang disebut kelas  (Chandani dkk, 2015). Proses klasifikasi dapat dibangun ber dasarkan pengetahuan seorang pakar, namun mengingat himpunan data yang relatif 
besar, model klasifikasi lebih sering dibangun menggunakan teknik pembelajaran dalam bidang machine learning. Proses pembelajaran secara otomatis terhadap suatu himpunan data mampu menghasilkan model klasifikasi yang memetakan objek data x berupa himpunan data latih yang berlabel dan mengeluarkan output yang berupa sebuah model klasifikasi (Suyanto, 2019) Pengklasifikasian data dalam penelitian ini menggunakan salah satu metode pembelajaran mesin ( Machine Learning ) yaitu Naive Bayes Classifier  (NBC) dengan menggunakan suat u Feature Selection . Feature Selection  merupakan proses pemilihan fitur dalam proses pengklasifikasian yang lebih efisien dengan dengan mengidentifikasi fitur yang relevan yang kemudian diproses berdasarkan model classifier yang telah dihasilkan dari prose s training dataset. Metode pemilihan fitur yang digunakan dalam penelitian ini adalah TF-IDF 
dan N -Gram, Dalam perhitungannya algoritma naive bayes memiliki aturan sebagai berikut :  
            
                                     )      (4)  
ð‘‰ð‘šð‘Žð‘ = ð‘‰ð‘—{ð‘ƒð‘œð‘ ð‘–ð‘¡ð‘–ð‘“,Negatif} ð‘ƒ(ð‘‰ð‘—) P(â€œkorbanâ€ | ð‘‰ð‘—) P(â€œcovidâ€ | ð‘‰ð‘—) P(â€œsemakinâ€ | ð‘‰ð‘—) P(â€œtambahâ€ | ð‘‰ð‘—) 
P(â€œpascaâ€ | ð‘‰ð‘—) P(â€œberlakuâ€ | ð‘‰ð‘—) P(â€œkebijakanâ€ | ð‘‰ð‘—)  
 Keterangan :  
 Vj  : Kategori tweet j=1,2,â€¦dst. Misal  j1 = Kelas sentimen positi f, j2 kelas sentimen negatif.  
P(xi | Vj)  : Probabilits xi pada kategori Vj  
P(Vj)   : Probailitas dari Vj  
 Untuk P(Vj) dan P(xi | Vj) dihitung pada saat pelatihan dimana persamaannya adalah sebagai berikut:  
-5
-6
Keterangan:  
|doscs j|  : jumlah dokumen setiap kategori j  
|contoh|  : jumlah dokumen dari semua kategori  
Pengujian  
Pengujian merupakan suatu proses dalam pelaksanaan suatu program dengan tujuan menemukan suatu kesalahan atau pun menguji fungsional data (Mustaqbal dkk,  2015) . Tahapan ini digunakan untuk menghitung nilai accuration , recall, precisi on dan f1-score . Proses ini didapatkan dengan menguji tingkat akurasi yang didapat dari perbandingan label manual dan hasil klasifikasi tweet menggunakan machine learning yaitu algoritma Naive Bayes 
Classifier  (NBC) pada proses testing dataset. Besarnya ni lai akurasi didapatkan dari banyaknya persamaan antara hasil pelabelan dan  hasil dari klasifikasi yang dilakukan.  Dengan menggunakan Confusion Matrix  maka didapat cara perhitungan sebagai berikut :  
Accuracy  =       
-7
Precision  =   
-8
Recall  =    
-9
F1 Score  = 2 * ( Recall *Precission ) / (Recall  + Precission )    (10) 
Keterangan :  
TP (True Positive ) = Data positif yang terdet eksi benar  
TN ( True Negative ) = Data negatif yang terdeteksi benar  
FP (False Poositive ) = Data negatif namun terdeteksi sebagai positif  
FN (False Negative ) = Data positif terdeteksi sebagai data negatif  

HASIL DAN PEMBAHASAN  
Metode Pengujian  
Pada metode pe mgujian akan ada pembahasan pada tahap uji sistem yang dibangun. Tahap ini dilakukan dengan menghitung dan mengukur performa sistem terhadap tingkat akurasi, recall, presisi dan f1 -Score pada hasil metode klasifikasi Naive Bayes dari data twitter mengenai kebijakan pemerintah tentang pemberlakuan New Normal. Hasil dari pengujian dapat dilihat apakah metode Naive Bayes memiliki performa yang baik dalam memprediksi sentimen tweet tentang kebijakan pemerintah pada pemberlakuan New Normal, dari hasil pengujian juga dilihat tanggapan positif ataukah tanggapan negatif yang lebih banyak mengenai tweet tersebut sehingga dapat dijadikan acuan oleh pengambil keputusan.  
Dataset yang digunakan dalam penelitian ini didapat dari tweet berbahasa Indonesia dengan keyword â€œ#NewNormalâ€ yang didapat pada tanggal 6 Juli 2020 â€“ 25 Juli 2020. Dengan jumlah sebanyak 1823 tweet . Pengujian data dilakukan dengan pengujian confusion matrix yaitu mengacu pada TP, TN, FP, dan FN.  Parameter yang diujikan dalam pengujian ini yaitu klasifi kasi Naive bayes menggunakan ekstrasi fitur TF-IDF dan N-Gram. Penghitungan Kelas Sentimen  Dalam pengujian data sentimen tweet tentang kebijakan pemerintah mengenai pemberlakuan New Normal  didapatkan hasil sentimen negatif dan sentimen positif secara manua l. Dari hasil pelabelan data tersebut kemudian 
dilakukan training data  dan testing data  yaitu 80% data Training dan 20% data testing  yang dilakukan secara random. Hasil dari perhitungan data sentimen kelas Negatif berjumlah 795 data, dan sentimen kelas positif sebesar 1028 data, sedangkan perbandingan dalam bentuk persentase dapat dilihat pada gambar 5.1 
Gambar 2 Persentase perbandingan kelas negatif dan positif  
Dari Gambar 2 bisa kita lihat perbandingan antara tweet  masyarakat yang berkomentar positif k ebijakan pemerintah dalam pemberlakuan sistem tatanan baru  New Normal dengan tweet masyarakat yang berkomentar negatif pada kebijakan pemerintah mengenai New Normal  yaitu 56,39 % tweet positif berbanding 43,61% tweet negatif 
dengan jumlah kelas Negatif seb anyak 795 data, dan sentimen kelas positif sebesar 1028 data dari hasil perhitungan sentimen didapat kata kata yang memiliki kemunculan terbesar yang terdapat pada gambar 3 dan gambar 4 
Gambar 3 Kemunculan kata terbesar dalam kelas positive  
Dari hasil p erhitungan kelas sentimen positif menyatakan bahwa 56,39% publik setuju dengan kebijakan pemerintah tentang pemberlakuan New Normal melalui tweet yang di tulis pada akun twitter pertanggal 6 Juli 2020 â€“ 25 Juli 2020.  
Gambar 5.3 Kemunculan kata Terbesar a lam kelas negatif  
Dari hasil perhitungan kelas sentimen negatif menyatakan bahwa 43,61% publik tidak setuju dengan kebijakan pemerintah tentang pemberlakuan New Normal melalui tweet yang di tulis pada akun twitter pertanggal 6 Juli 2020 â€“ 25 Juli 2020. De ngan jumlah sebanyak 1823 tweet  yang dikumpulkan secara random dengan keyword â€œ#NewNormalâ€ dan didapatkan menggunakan library tweepy pada bahasa pemrograman python. Pengujian TF -IDF dan N-Gram terhadap Naive Bayes  Dari dataset yang telah didapat nilai sent imen maka tahap selnjutnya dilakukan uji pembelajaran mesin  
menggunakan metode Naive Bayes dengan parameter pengujian menggunakan seleksi fitur TF-IDF dan N-Gram, dan didapatkan hasil seperti pada tabel 4 
Tabel 4 Hasil Klasifikasi menggunakan TF -IDF & N -Gram 
Feature Selection  Accuracy  
TF-IDF 0.819  
N-Gram (Unigram)  0.827  
N-Gram (Bigram)  0.835  
N-Gram (Trigram)  0.841  
Dari data hasil pengujian yang dilakukan dengan menggunakan ekstrasi fitur TF-IDF & N-Gram didapat hasil akurasi tertinggi pada N-Gram (Tri gram) sebesar 84,1%, sementara hasil terendah terdapat dalam penggunaan seleksi fitur TF -IDF dengan total akurasi sebesar 81,9%, Berdasarkan hasil uji akurasi penggunaan TF-IDF dan N -Gram yang telah dilakukan terlihat kenaikan performa klasifikasi saat pen ggunaan N-Gram sementara TF -IDF dirasa belum cukup menunjukan performa yang baik dalam pengaplikasian menggunakan metode Naive Bayes. Peningkatan performa klasifikasi Naive Bayes terhadap fitur selek si dapat dilihat pada gambar 5  
Gambar 5  Grafik Akurasi  Klasifikasi  
Hasil Pengujian Confusion Matrix  
Pada penelitian ini digunakan metode confusion matrix untuk menguji performa Algoritma Naive Bayes dalam menganalisis sentimen dataset tentang tweet pandangan masyarakat terhadap kebijakan pemerintah dalam pemberlakuan NewNormal . Pada pengujian akurasi, Seleksi fitur N -Gram dengan parameter Trigram menjadi nilai akurasi tertinggi, dalam pengujian akurasi tersebut didapat melalui pengujian confusion matrix dengan mengacu pada 
TP (hasil positif terdeteksi benar), TF(Hasil Negatif terdeteksi benar), FP(Hasil Positif terdeteksi salah), dan FN(hasil negatif terbaca salah). Confusion matrix pada pengujian Seleksi fitur TF -IDF dapat dilihat pada gambar 6  sedangkan untuk pengujian menggunakan seleksi fitur N -Gram dengan parameter Trigram pada algoritma Naive Bayes dapat dilihat pada gambar 7 
Gambar 6 Hasil Pengujian Confusion Matrix  TF-IDF 
Hasil pengujian pada gambar 5.5 dapat diketahui pengujian confusion matrix pada ekstrasi fitur TF-IDF menggunakan klasifikasi Naive Bayes mendapatkan hasil TP=172, TN=127, FP=48, dan FN=18.  78% 80% 82% 84% 86% TF-IDF Unigram Bigram Trigram Akurasi Fitur Seleksi Terhadap Naive Bayes   
Gambar 7 Hasil Pengujian Confusion Matrix  N-Gram(Trigram)  
Hasil pengujian Confusion Matrix  penggunaan ekstrasi fitur N-Gram parameter Trigram menggunakan klasifikasi Naive Bayes didapatkan hasi l TP=164, TN=143, FP=32, dan FN=26 setelah sistem mendapatkan data tersbut maka pengujian terakhir yaitu presisi, recal l, dan F1-Score pada Tabel 5  Tabel 5  Hasil report pengujian Confusion Matrix  
Pengujian  TF IDF  N-Gram (Trigram)  
Precission  0.78 0.84 
Recall 0.91 0.86 
F1-score  0.84 0.85 
Accuracy  0.81 0.84 
Pada tabel 5.2 didapatkan informasi report dari pengujian Seleksi fitur TF -IDF mendapat hasil nilai Precission  78%, Recall  91%, f1-Score  84%, dan Akurasi 81%. Sedangkan report dari seleksi fitur N -Gram dengan parameter Trigram pada klasifikasi Naive Bayes dengan nilai Precission  84%, Recall  86%, f1-Score  85%, dan Akurasi 84%.
  
SIMPULAN  
Dari penelitian yang dilakukan dengan penggunaan pembelajaran mesin ( Machine Learning ) yaitu algoritma Naive Bayes pada  dataset tweet sentimen tentang kebijakan pemerintah terhadap covid19 sebagai berikut:  
1. Dari perhitungan sentimen pemberlakuan sistem New Normal diketahui 56,39% publik berpendapat positif sementara 43,61% berpendapat negatif pada kebijakan pemerintah tenta ng pemberlakuan New Normal, dengan data yang diambil melalui tweet yang di tulis pada akun twitter pertanggal 6 Juli 2020 â€“ 25 Juli 2020 yang jumlah sebanyak 1823 tweet .  
2. Hasil pengujian menggunakan Confusion Matrix  didapat nilai akurasi terendah dengan kla sifikasi Naive Bayes menggunakan ekstrasi fitur TF -IDF yaitu sebesar 81%, dengan nilai Precission  78%, Recall  91% dan f1-Score  84%. Sedangkan Nilai akurasi tertinggi didapatkan menggunakan parameter algoritma Naive Bayes dengan N-Gram jenis Trigram yaitu s ebesar 84%, terdapat juga nilai Precission 84%, Recall 86%, dan f1-Score 85%. Hal ini menunjukan Algoritma Naive Bayes menggunakan ekstrasi fitur TF-Idf dan N-Gram dapat digunakan dengan baik dalam proses pengklasifikasian data tweet masyarakat terhadap ke bijakan pemerintah pada 
pemberlakuan sistem New Normal. Peningkatan Akurasi yang didapat setelah penggunaan N-Gram hal ini dikarenakan banyak farasa bahasa Indonesia yang memiliki 2 hingga 3 kosa kata.   
 
UCAPAN TERIMA KASIH  
Puji syukur penulis panjatkan ke pada Allah SWT, karena atas berkat dan rahrnat-Nya, penulis dapat menyelesaikan Penelitian dengan judul â€œ Sentimen Analisis Tentang Kebijakan Pemerintah Terhadap Kasus Corona Menggunakan Metode Naive Bayes â€. 
1. Bapak Dr. H.M. Nasrullah Yusuf, S.E., M.B.A. sela ku Rektor Universitas Teknokrat  Indonesia.  
2. Bapak Dr. H. Mahathir Muhammad, S.E., M.M. selaku Dekan Fakultas Teknik dan Ilmu  Komputer Universitas Teknokrat  Indonesia.  
3. Ibu Dyah Ayu Megawaty, M.Kom., selaku Ketua Program Studi S1 Informatika Fakultas Teknik dan Ilmu Komputer Universitas Teknokrat  Indonesia.   
  
REFERENSI/DAFTAR PUSTAKA  
Alita, D., Priyanta, S., & Rokhman, N. (2019). Analysis of Emoticon and Sarcasm Effect on Sentiment Analysis of Indonesian 
Language on Twitter. Journal of Information Systems Engineering and Business Intelligence , 5(2), 100.  
Bing, L. ( 2012). Sentiment analysis and opinion mining . Morgan & Claypool.  
Buntoro, G. A. (2017). Analisis Sentimen Calon Gubernur DKI Jakarta 2017 Di Twitter. Integer Journal Maret , 1(1), 32 â€“41.  
Chandani, V., Komputer, F. I., & Nuswantoro, U. D. (2015). Komparasi Algoritma Klasifikasi Machine Learning Dan Feature 
Selection pada Analisis Sentimen Review Film. Journal of Intelligent Systems , 1(1), 56 â€“60. 
Croft, W. B., Metzler, D., & Strohman, T. (2015). Information retrieval in practice.  
Falahah. (2015). Pengembangan  Aplikasi Sentiment Analysis Menggunkan Metode NaÃ¯ve Bayes . Bandung.  
Feldman, R., & Sanger, J. (2007). The Text Mining Handbook Text . New York: Cambridge University Press.  
Hayuningtyas, R. Y., & Sari, R. (2019). Analisis Sentimen Opini Publik Bahasa Indone sia Terhadap Wisata Tmii Menggunakan 
NaÃ¯ve Bayes Dan Pso. Jurnal Techno Nusa Mandiri , 16(1), 37 â€“42.  
Ika Alfina, R Mulia, Fanany, M.I, Y. E. (2017). Hate Speech Detection in the Indonesian Language: A Dataset and Preliminary 
Study . 9th Int. Conf. Adv. Comp ut. Sci. Inf. Syst. (ICACSIS 2017), Jakarta . 
Indhiarta, W. C. (2017). Penggunaan N -Gram Pada Analisa Sentimen, 1 â€“18. 
Isnain, A. R., Sihabuddin, A., & Suyanto, Y. (2020). Bidirectional Long Short Term Memory Method and Word2vec Extraction 
Approach for Hate Speech Detection . IJCCS (Indonesian Journal of Computing and Cybernetics Systems) , 14(2), 169.  
Juen, L., Kencana, I. P. E. N., & Oka, T. B. (2014). Analisis Sentimen Menggunakan Metode NaÃ¯ve Bayes Classifier Dengan 
Seleksi Fitur Chi Square. E-Jurnal Matema tika, 3(3), 92.  
Jupriyadi. (2018). Implementasi Seleksi Fitur Menggunakan Algoritma FVBRM Untuk Klasifikasi Serangan Pada Intrusion 
Detection System (Ids). Seminar Nasional Teknologi Informasi (SEMNASTEK) , 17(January 2018) .  
Maarif, A. A. (2015). Penerapan  Algoritma TF -IDF untuk Pencarian Karya Ilmiah. Dokumen Karya Ilmiah | Tugas Akhir | 
Program Studi Teknik Informatika - S1 | Fakultas Ilmu Komputer | Universitas Dian Nuswantoro Semarang , (5), 4.  
Mustaqbal, M. S., Firdaus, R. F., & Rahmadi, H. (2015). Pengujian Aplikasi Menggunakan Black Box Testing Boundary Value 
Analysis  (Studi Kasusâ€¯: Aplikasi Prediksi Kelulusan SNMPTN), I(3), 31 â€“36. 
Patihullah, J. (2018). Analisis Hate Speech Bahasa Indonesia Menggunakan Word Embeddings Dan Gated Recurrent Unit . 
Sari, B. W., & Haranto, F. F. (2019). Implementasi Support Vector Machine Untuk Analisis Sentimen Pengguna Twitter Terhadap 
Pelayanan Telkom Dan Biznet. Jurnal Pilar Nusa Mandiri , 15(2), 171 â€“176.  
Suryono, R. R., & Budi, I. (2019). P2P Lending Sentiment Analysis  in Indonesian Online News, 172(Siconian 2019).  
Suyanto. (2019). Data Mining Untuk Klasifikasi dan Klusterisasi Data. 
 Alita, D., Fernando, Y., & Sulistiani, H. (2020). Implementasi Algoritma Multiclass Svm Pada Opini Publik Berbahasa Indonesia 
Di Twitter , 14(2), 86 â€“91. 
",Sentimen analisis,Naive Bayes,twet masyarakat,"akurasi, precission, recall, f1-score"
"Sistem Analisis Sentimen pada Ulasan Produk Menggunakan Metode Naive Bayes
","Sistem Analisis Sentimen pada Ulasan Produk Menggunakan Metode Naive Bayes

Billy Gunawan, Helen Sasty Pratiwi, Enda Esyudha Pratama

Abstrak
Sistem analisis sentimen merupakan sistem yang digunakan untuk melakukan proses analisis otomatis pada ulasan produk online bahasa Indonesia untuk memperoleh informasi meliputi informasi sentimen yang merupakan bagiandari ulasan online. Data tersebut diklasifikasikan menggunakan Naive Bayes. Sistem analisis sentimen dibagi menjadi 5 (lima) tahap, yaitu crawling, pre-processing, pembobotan kata, pembentukan model dan klasifikasi sentimen. Pada pembobotan kata digunakan metode TF-IDF (Term Frequency â€“Inverse Document Frequency). Data yang ada akan diklasifikasikan ke dalam 5 (lima) kelas, yaitu sangat negatif, negatif, netral, positif dan sangat positif. Data tersebut kemudian akan dievaluasi menggunakan pengujian confusion matrix 
dengan parameter akurasi, recall, dan precision. Hasil pengujian menunjukkan pada pengujian 3 kelas (negatif, netral dan positif) hasil terbaik didapatkan pada 90% data latih dan 10% data uji dengan nilai akurasi 77.78%, recall 93.33% dan precision 77.78% dan pada pengujian 5 kelas hasil terbaik didapatkan pada 90% data latih dan 10% data uji  dengan nilai akurasi 59.33 %, recall 58.33 % dan precision 59.33 %. Hasil prediksi kelas data uji 
yang relevan dibandingkan antara kelas sentimen yang ditandai supervisor dan kelas sentimen yang dihasilkan oleh sistem analisis sentimen walaupun belum sepenuhnya akurat.

Kata kunci -Naive bayes, Klasifikasi sentimen, TF-IDF, Confusion matrix, Akurasi

I. PENDAHULUAN
Pada zaman modern ini, sentimen atau opini masyarakat semakin bertambah luas dan bebas diungkapkan di berbagai media. Sentimen dapat menjadi potensi besar bagi perusahaan yang ingin mengetahui umpan balik (feedback) dari masyarakat ter
hadap merk dagang mereka. Merk telah dianggap sebagai salah satu asset tidak berwujud (intangible asset) yang paling berharga dan manajemen merk adalah prioritas penting bagi pihak manajemen perusahaan atau organisasi [1]. Jumlah pengguna (user) aktif dalam komunikasi online memiliki jumlah data yang sangat banyak sehingga memunculkan data besar (big data). Munculnya teknologi big data yang merupakan himpunan data dalam jumlah 
yang sangat besar, rumit, dan tidak terstruktur menjadi salah satu sumber daya besar yang dapat diolah untuk memperoleh hasil sentimen yang lebih akurat. Jumlah review dan opini sangat banyak sehingga akan menyulitkan dan memakan waktu untuk membaca secara keseluruhan. Oleh karena itu dapat dirancang sistem yang secara otomatis akan mengelompokkan opini dan review yang ada
sesuai kelasnya. Kelas sentimen dibagi menjadi kelas sangat positif, positif, netral, negatif, dan sangat negatif sehingga pengguna dapat membaca memilih ingin membaca opini sesuai yang diinginkan [2]. Sistem analisis sentimen yang dibangun menggunakan 
algoritma klasifikasi Naive Bayes. Ciri utama dari algoritma Naive Bayes adalah asumsi yang sangat kuat (naif) akan independensi dari masing-masing kondisi atau kejadian [3]. Kelebihan dari Naive Bayes adalah proses klasifikasi data dapat disesuaikan dengan sifat dan 
kebutuhan masing-masing. Dengan adanya sistem analisis sentimen ini diharapkan dapat membantu perusahaan mengetahui umpan balik terhadap merk dagangnya dan masyarakat dalam menilai 
sebuah produk berdasarkan opini dan review yang ada. Penelitian Kristiyanti [4], pengkajian ulang tentang review produk kosmetik dengan cara pengklasifikasian review tersebut ke dalam class positif dan negatif. Teknik klasifikasi yang digunakan untuk klasifikasi data adalah Support Vector Machine (SVM) denganpenggabungan  metode pemilihan fitur Particle Swarm Optimization agar bisa meningkatkan akurasi. Evaluasi pengukuran sebelum dan sesudah penambahan metode pemilihan fitur dilakukan menggunakan 10 Fold Cross Validation. Sedangkan pengukuran akurasi diukur dengan Confusion Matrix dan Kurva ROC. Hasil penelitian menunjukkan peningkatan akurasi Support Vector Machine dari 
89.00 % menjadi 97.00 %. Sipayung, Maharani dan Zefanya [5] membuat sistem analisis sentimen menggunakan metode Naive Bayes Classifier (NBC). Komentar dibagi berdasarkan sentimen positif dan negatif, sehingga dapat dievaluasi kepuasan pelanggan terhadap produk dan jasa yang disediakan secara terkomputerisasi dan spesifik. Hasil dari penelitian yang dilakukan mendap
atkan enam kategori yang ditinjau dengan 55 keyword kata benda, terdapat 120 keyword sentimen dengan 66 kata sentimen positif dan 54 kata sentimen negatif. Hasil pengolahan terhadap 175 data latih 
disimpulkan bahwa hasil klasifikasi sentimen yang 
didapat adalah sentimen positif sebanyak 155 komentar dan sentimen negatif sebanyak 20 komentar. Kategori sentimen positif terbesar adalah kategori kamar sebesar 73 komentar dan kategori dengan sentimen negatif terbesar adalah kategori kamar sebesar 17 komentar. Tingkat akurasi dalam penentuan kategori adalah sebesar 77.14% dan 75.42% dalam penentuan sentimen memiliki tingkat precision 99.12% dan recall 72.9%.
Gambar. 1 Diagram alir penelitian
Budi [6] menyatakan ada beberapa algoritma yang di gunakan untuk penggalian dokumen untuk analisis sentimen, salah satunya adalah K-Means. Didalam penelitian ini algoritma yang digunakan adalah K-Means dengan pembobotan kata TF-IDF. Dengan tujuan untuk mengetahui kinerja algoritma K-Means tanpa seleksi fitur dan menggunakan seleksi fitur information gain. Hasil penelitian menunjukkan bahwa akurasi K-Means dengan dataset digunakan 300 positif dan 300 negatif  akurasinya 57.83%,  700 dokumen positif dan 700  negatif akurasinya 56.71%%, 1000 dokumen positif dan 1000  negatif akurasinya 50.40%%. Dari hasil pengujian disimpulkan  bahwa semakin besar dataset yang digunakan semakin rendah akurasi K-Means.
 
II. METODE PENELITIAN 
Sentimen adalah pendapat atau pandangan yang didasarkan pada perasaan yang berlebih-lebihan terhadap sesuatu (bertentangan dengan pertimbangan pikiran) [7]. Sentimen terdapat pada pernyataan atau kalimat yang memiliki pendapat. Sentimen digunakan untuk mengetahui perasaan yang diberikan terhadap topik atau objek. Data pre-processing adalah teknik data mining yang melibatkan transformasi data mentah menjadi format yang mudah dimengerti. Langkah data pre-precossing diperlukan untuk menyelesaikan beberapa jenis masalah termasuk noisy data, data redundansi, nilai data yang hilang, dll [8]. Adapun langkah-langkah data pre-proccesing adalah tokenisasi, case folding, stemming, filtering,dan labelling. 
1.Tokenisasi
Tokenisasi merupakan proses pemisahan suatu rangkaian karakter berdasarkan karakter spasi, dan mungkin pada waktu yang bersamaan dilakukan juga proses penghapusan karakter tertentu, seperti tanda baca [9].  
2.Case Folding
Case folding merupakan proses mengubah semua huruf 
dalam suatu dokumen atau kalimat menjadi huruf kecil [10]. Case folding digunakan untuk mempermudah pencarian. Tidak semua data konsisten dalam penggunaan huruf kapital. 
3.Stemming
Kata-kata yang sudah diubah menjadi huruf kecil perlu dilakukan pengecekan. Stemming digunakan untuk menyeragamkan kata sehingga mengurangi daftar kata yang ada pada data latih [11]. 
4. Filtering
Filtering / eliminasi stopwords memiliki banyak keuntungan, yaitu akan mengurangi space pada tabel term index hingga 40% atau lebih [12]. Proses stopword removal merupakan proses penghapusan term yang tidak memiliki arti atau tidak relevan [9]. 
5.Labelling
Labelling berasal dari kata label. Label berarti karakter atau himpunan karakter yang digunakan untuk mengidentifikasi suatu variabel atau bagian dari data atau berkas [7]. Labelling / proses pemberian label ada 2 (dua), yaitu pemberian label kepada 
token dengan kata penguat (exaggeration) dan kata negasi (negation). Pembobotan kata adalah proses pemberian bobot untuk 
setiap kata yang terdapat dalam sebuah dokumen. Dalam pencarian informasi peringkat berdasarkan frekuensi kata, salah satu metode yang paling populer adalah metode TF-IDF (Term Frequency-Inversed Document Frequency).  Dalam metode TF-IDF, Term Frequency lebih berfokus pada istilah yang sering muncul dalam suatu dokumen sedangkan Inverse Document Frequency lebih berfokus pada pemberian bobot rendah untuk istilah yang muncul dalam banyak dokumen [13]. Klasifikasi Naive Bayes merupakan klasifikasi yang bersifat supervised learning karena memiliki supervisor (manusia melakukan klasifikasi secara manual pada data 
yang digunakan dalam pelatihan) selaku pengajar dalam 
proses belajar atau learning [11]. Selain itu, performansi Naive Bayes memiliki waktu klasifikasi yang singkat sehingga mempercepat proses sistem analisis sentimen. Pada penelitian ini pengujian digunakan dengan menggunakan 5 kelas (sangat negatif, negatif, netral, positif dan sangat positif ) dan 3 kelas (negatif, netral, dan 
positif). Diagram alir penelitian dilakukan dengan tahap-tahap 
studi literatur, pengumpulan data, perancangan sistem, pembuatan dan implementasi sistem, pengujian sistem, analisis hasil pengujian, dan penarikan kesimpulan seperti pada gambar 1. Studi literatur dilakukan dengan mencari referensi ilmu pengetahuan yang berhubungan dengan sistem yang akan dibuat seperti referensi tentang kritik dan saran, Data Pre-Processing maupun melalui penelitian-penelitian sebelumnya. Pengumpulan data dilakukan untuk memperoleh data-data yang berhubungan dengan sistem yang akan dibuat seperti data opini dan review yang berasal dari Female 
Daily (www.femaledaily.com). Opini dan review yang diambil sebanyak 300 data latih per kelas dengan total 1500 data latih. Perancangan sistem dilakukan dengan menggunakan UML (Unified Modelling Language) dengan tahapan antara lain, perancangan use case diagram, perancangan sequence diagram, perancangan class diagram dan perancangan activity diagram. Kemudian dilanjutkan dengan perancangan struktur antarmuka sistem dan perancangan layout serta antarmuka sistem. Pembuatan dan Implementasi sistem dilakukan berdasar kepada desain dan perancangan aplikasi yang telah dilakukan pada tahapan sebelumnya. Pada tahapan ini, sistem akan dibuat berbasis website HTML dan PHP.  Pengujian sistem dilakukan untuk mengetahui apakah sistem yang telah dibuat dapat menganalisis sentimen yang diambil oleh crawler yang kemudian dilakukan pre-processing dan pembobotan kata menggunakan metode TF-IDF  dan mengkategorikannya kedalam kelas-kelas menggunakan metode Naive Bayes. Dalam hal ini dilakukan pengujian dengan metode blackbox, confusion matrix, perhitungan akurasi, precision dan recall. Analisis Hasil Pengujian dilakukan analisis terhadap sistem secara keseluruhan untuk memudahkan dalam melakukan penarikan kesimpulan. Kesimpulan dirumuskan berdasarkan analisis hasil pengujian sistem yang telah dilakukan.
 
III. PERANCANGAN APLIKASI
A.Gambaran Umum Sistem
Sistem yang dibangun adalah sistem yang dapat digunakan untuk menganalisis sentimen pada ulasan produk dan berjenis coarsed-grained sentiment analysis, dikarenakan sebuah review / ulasan dapat dinilai apabila dibaca secara kesuluruhan. Sistem bekerja dengan melakukan crawling review pada website e-commerce yang nantinya akan diproses pada sistem. Adapun pengguna dari sistem ini dibagi menjadi admin dan pengunjung website. seperti pada gambar 2.
Gambar. 2
Arsitektur sistem
Workflow sistem analisis sentimen dibagi menjadi 2 bagian yaitu koleksi data latih dan koleksi data uji, sebelum dapat dilakukan klasifikasi sentiment dapat dilihat pada gambar 3.
Gambar. 3
Workflow sistem analisis sentimen
B. Perancangan UML
1. Use Case Diagram
Use Case Diagram menggambarkan fungsionalitas yang diharapkan dari sebuah sistem [14]. Sebuah use case mereprensentasikan interaksi antara aktor dengan sistem. Berikut merupakan use case diagram yang telah dirancang pada gambar berikut. Use Case diagram digambarkan seperti pada gambar 4.
Gambar. 4
Use case diagram
2. Class Diagram
Diagram kelas atau class diagram menggambarkan struktur sistem dari segi pendefinisian kelas-kelas yang akan dibuat untuk membangun sistem [14]. Class diagram digambarkan seperti pada gambar 5.
Gambar. 5 Class diagram 
3. Sequence Diagram
Sequence diagram menggambarkan kelakuan objek pada use case dengan mendeskripsikan waktu hidup objek dan message yang dikirimkan dan diterima antar objek [14]. Sequence diagram digambarkan seperti pada gambar 6.
Gambar. 6 Sequence diagram
4. Activity Diagram
Diagram aktivitas atau activity diagram menggambarkan workflow (aliran kerja) atau aktivitas dari sebuah sistem atau proses bisnis [14]. Activity diagram digambarkan seperti pada gambar 7.
Gambar. 7 Activity diagram
C. Peracangan Antarmuka
Perancangan antarmuka sistem analisis sentimen ini memiliki beberapa layout yang disesuaikan dengan use case diagram yang telah dirancang. Struktur antar muka sistem yang dibangun dapat dilihat pada gambar 8 untuk user dan gambar 9 untuk admin berikut :
Gambar. 8 Rancangan antarmuka user
Gambar. 9 Rancangan antarmuka admin
 
IV. HASIL 
PERANCANGAN DAN ANALISIS
A.IMPLEMENTASI
1. Antarmuka Halaman Utama / Beranda
Antarmuka halaman utama / beranda memiliki form yang memerlukan input pengguna yaitu link halaman awal produk pada website FemaleDaily seperti pada gambar 10.
Gambar. 10
Antarmuka halaman utama/beranda
2.Antarmuka Halaman Hasil Analisis
Antarmuka halaman hasil analisis memberikan informasi dari analisis yang telah dilakukan sistem seperti pada gambar 11.
Gambar. 11
Antarmuka halaman hasil analisis 
3. Antarmuka Admin Panel
Antarmuka admin panel memberikan admin hak akses mengatur atau memanajemen korpus data latih dan koleksi kamus seperti pada gambar 12.
Gambar.12 Antarmuka halaman admin panel
B.Pengujian Confusion Matrix
Confusion matrix adalah suatu metode yang umumnya digunakan untuk melakukan perhitungan tingkat akurasi pada data mining. Confusion matrix memuat informasi tentang klasifikasi yang diprediksi dengan benar oleh sebuah sistem klasifikasi [15]. Terdapat tiga parameter yang akan dihitung, yaitu akurasi, recall, dan precision yang dapat dilihat pada tabel I.  
TABEL I HASIL PENGUJIAN
Jumlah Kelas
Total Data
Data Latih
Data Uji
Akurasi
Recall
Precision
3
900
90%
10%
77.78%
93.33%
77.78%
3
900
80%
20%
73.89% 
95.00%
74.44%
5
1500
90%
10%
59.33%
58.33% 
59.33% 
5 
1500 
80% 
20% 
52.66% 
50.83% 
52.67%  
C. Analisis Hasil Pengujian
Dari pengujian yang dilakukan dengan menghitung akurasi, recall dan precision pada sistem analisis sentimen review produk online maka analisis yang dapat disimpulkan adalah sebagai berikut.
1. Hasil prediksi kelas data uji yang relevan dibandingkan antara kelas sentimen yang ditandai supervisor dan kelas sentimen yang dihasilkan oleh sistem analisis sentimen.
2.Prediksi kelas sentimen pada review dapat dilakukan dengan pre-processing, pembobotan kata, pembentukan model dengan perhitungan probabilitas kelas.
3. Prediksi sistem analisis sentimen menggunakan metode Naive Bayes belum sepenuhnya relevan. Hal ini dapat dilihat pada nilai akurasi pengujian terutama pada pengujian 5 kelas menggunakan dataset 80% latih - 20% data uji memiliki akurasi terendah sebear 52.66%, pengujian 5 kelas menggunakan dataset 90% latih -10% sebesar 59.33 %, pengujian   3 kelas menggunakan dataset 90% data latih dan 10% data uji memiliki 73.89% sedangkan pada pengujian 3 kelas menggunakan dataset 90% data latih dan 10% data uji memiliki akurasi tertinggi sebesar 77.78%.
4. Nilai akurasi terendah pada sistem analisis sentimen pada setiap pengujian yang dilakukan terdapat pada kelas netral yang dapat dilihat pada tabel II. Hal ini disebabkan sifat kelas netral yang 
memiliki vocabulary yang luas sehingga sistem mengklasifikasikan kalimat pada kelas netral menjadi kelas lain.
5. Dari  pengujian 5 kelas dan 3 kelas yang dilakukan data latih 90% dan data uji 10% memiliki akurasi yang lebih tinggi dibandingkan dengan data latih 80% dan data uji 20%. Hal ini disebabkan semakin banyak data latih yang digunakan maka vocabulary sistem menjadi lebih banyak dan pengklasifikasian pun akan menjadi akurat. 
 
V. KESIMPULAN DAN SARAN
A.Kesimpulan
Berdasarkan hasil analisis dan pengujian terhadap sistem a
nalisis sentimen pada ulasan produk online menggunakan metode Naive Bayes, maka dapat ditarik kesimpulan sebagai berikut 
1.Metode Naive Bayes dapat memprediksi kelas sentimen pada ulasan produk online sesuai dengan sistem yang disiapkan.
2. Sistem analisis yang dibentuk belum sepenuhnya relevan dalam memprediksi kelas sentimen yang sesuai terhadap pemberian kelas dari supervisor. 
3.Sistem analisis sentimen pada ulasan produk online menggunakan metode Naive Bayes menghasilkan nilai akurasi terendah pada pengujian 5 kelas menggunakan dataset 80% latih dan 20% data uji 
sebesar 52.66%, sedangkan pada pengujian 3 kelas menggunakan dataset 90% data latih dan 10% data uji memiliki akurasi tertinggi sebesar 77.78%.
4.Jumlah data latih dalam sistem analisis sentimen memiliki pengaruh terhadap prediksi sistem. Selain jumlah, kualitas data latih juga berperan karena semakin tinggi kualitas data maka sistem akan 
mendapatkan vocabulary yang semakin besar sehingga akan lebih tepat dalam memprediksi kelas sentimen.
5. Review yang diluar batasan cenderung akan memiliki kelas sentimen yang salah dikarenakan sistem tidak dilatih diluar batasan yang telah ditentukan. Seperti review dalam bahasa Inggris atau kata-kata gaul baru yang tidak terdapat dalam kamus.
B. Saran
Adapun beberapa hal yang perlu ditambahkan dalam pengembangan sistem analisis sentimen pada ulasan produk online menggunakan metode Naive Bayes ini adalah sebagai berikut : 
1.Sistem analisis sentimen pada ulasan produk online menggunakan metode Naive Bayes ini dapat menggunakan metode lain untuk memperoleh hasil prediksi yang lebih baik. Contoh metode yang dapat digunakan Support Vector Machine (SVM) [4] atau K-Means [6].
2.Sistem ini dapat dikembangkan lagi dengan menambahkan website ulasan produk online yang dapat dicrawl sehingga tidak terbatas pada satu website. 
3.Sistem analisis sentimen dapat ditambahkan proses semantik sehingga kata-kata yang harusnya memiliki makna dapat ditandai. Dan dapat membantu sistem dalam menilai kelas sentimen pada review.
 
REFERENSI
[1]Keller, Kevin L., dan Donald R. Lehmann.2006. Brands and Branding: Research Findings and Future Priorities. Marketing Science. Vol. 25, No 6. Maryland: INFORMS. 
[2] Buntoro, Ghulam Asrofi, Teguh Bharata Adji, dan Adhistya Erna Purnamasari. 2016. Sentiment Analysis Candidates of Indonesian Presiden 2014 with Five Class Attribute. International Journal of Computer Applications. Vol. 136 No. 2. Ronowijayan :Universitas Muhammadiyah Ponorogo. 
[3] Natalius, Samuel. 2010. Metode Naive Bayes Classifier dan 
Penggunaannya pada Klasifikasi Dokumen. Bandung: Institut Teknologi Bandung. 
[4] Kristiyanti, Dinar Ajeng. 2015. Analisis Sentimen Review Produk Kosmetik Menggunakan Algoritma Support Vector Machine dan Particle Swarm Optimization Sebagai Seleksi Fitur. Seminar Nasional Inovasi dan Tren (SNIT) 2015. Jakarta: STMIK Nusa Mandiri. 
[5] Sipayung, Evasaria M., Herastia Maharani, dan Ivan Zefanya. 2016. Perancangan Sistem Analisis Sentimen Komentar Pelanggan Menggunakan Metode Naive Bayes Classifier. Jurnal Sistem Informasi (JSI), VOL. 8, NO. 2. Bandung:  Institut Teknologi Harapan Bangsa. 
[6] Budi, Setyo. 2017. Text Mining Untuk Analisis Sentimen Review 
Film  Menggunakan Algoritma K-Means. Techno.COM, Vol. 16, No. 1. Semarang : Universitas Dian Nuswantoro Semarang 
[7] Anonim. 2018. Kamus Besar Bahasa Indonesia. https://kbbi.kemdikbud.go.id/,  24 Maret 2018 
[8] Kotsiantis, S. B., D. Kanellopoulos dan P. E. Pintelas. 2006. Data Preprocessing for Supervised Learning. International Journal of Computer Science Volume 1 Number 2. Patras: University of Patras. 
[9] Amin, Fatkhul. 2012. Sistem Temu Kembali Informasi dengan Metode Vector Space Model. Jurnal Sistem Informasi Bisnis 02. Semarang: Universitas Stikubank. 
[10] Valatehan, Lucky, Muhammad Fachrurrozi, dan Osvari Arsalan. 2016. Identifikasi Kalimat Pemborosan Menggunakan Rule Based Reasoning. Annual Research Seminar Vol 2 No. 1. Palembang: Universitas Sriwijaya. 
[11] Manning, Christopher D, Prabhakar Raghavan, dan Hinrich SchÃ¼tze. Introduction to Information Retrieval. Cambridge: Cambridge University Press, 2008. 
[12] Baeza R.Y., dan Neto R., 1999. Modern Information Retrieval. Boston: USA. 
[13] Wilson, Garnett, Rodolphe Devillers,  and Orland Hoeber. 2011. Fuzzy Logic Ranking For Personalized Geographical Information Retrieval. Proceedings of the Third International Conference on 
Intelligent Human Computer Interaction (IHCI 2011). Czech Republic: Springer Berlin Heidelberg. 
[14] A.S., Rosa dan M. Shalahudin. 2016. Rekayasa Perangkat Lunak Terstruktur dan Berorientasi Objek. Bandung: Informatika Bandung. [15] Hamilton, Howard. 2017. Confusion Matrix. http:/
/www2.cs.uregina.ca/~hamilton/courses/831/notes/confusion_matrix/confusion_matrix.html, 24 Maret 2018.",Analisis Sentimen,Naive Bayes,Ulasan Produk,"akurasi, recall, precision"
"Sentimen Analisis Aplikasi E-Commerce Berdasarkan Ulasan Pengguna Menggunakan Algoritma Stochastic Gradient Descent     
","Sentimen Analisis Aplikasi E-Commerce Berdasarkan Ulasan Pengguna Menggunakan Algoritma Stochastic Gradient Descent     

Wilya Kurnia 

Abstrak
Tokopedia dan Shopee merupakan e -commerce yang banyak digunakan untuk melakukan jual beli barang         dan bertransaksi online selama pandemi covid-19. Tokopedia dan Shopee juga menempati kategori aplikasi belanja         paling populer di situs Google Play Store. Pada Google Play Store terdapat kolom ulasan yang memudahkan                                                                 
pengguna untuk  memberikan review. Pentingnya review bagi perusahaan atau organisasi yaitu mengetahui persepsi dari pengguna untuk dijadikan bahan evaluasi. Review pengguna juga dapat dijadikan sebagai alat tolak ukur dalam pengambilan keputusan dan menemukan informasi t erhadap suatu produk atau jasa.  Oleh karena itu, banyaknya review dari pengguna memerlukan sebuah metode yang dapat mengkategorikan review-review tersebut                                                                 
apakah termasuk review positif atau negatif. Sentimen analisis merupakan cara untuk menentukan dan mengelompokkan polaritas teks yang berisi tentang pendapat, opini, persepsi dan emosi. Metode klasifikasi yang dapat digunakan salah satunya ialah Stochastic Gradient Descent (SGD). SGD adalah metode klasifikasi text mining yang mampu untuk diterapkan pada data dengan jumlah yang besar. Hasil klasifikasi yang didapatkan untuk tokopedia menunjukkan nilai akurasi sebesar 84%, nilai presisi 87%, nilai recall 90%, dan untuk shopee menunjukkan nilai akurasi sebesar 66%, nilai presisi 65%, nilai recall 66%.                                                                  

Kata Kunci: Sentimen Analisis, Klasifikasi, E-Commerce, Opini, Stochastic Gradient Descent                                  

Abstract
Tokopedia and Shopee are e -commerce sites that are widely used to buy and sell goods and transact online during the COVID-19 pandemic. Tokopedia and Shopee also occupy the most popular shopping application category on the Google Play Store site. On the Google Play Store, there is a review column that makes it easy for                                                                 
users to provide reviews. The importance of a review for a company or organization is  to learn the perceptions of users so they can be used as evaluation material. User reviews can also be used as a benchmark in making decisions and finding information on a product or service. The number of reviews from users requires a method that can categorize these reviews, whether they are positive or negative reviews. Sentiment analysis is a way to determine and classify the polarity of a text that contains opinions, perceptions, and emotions. One of the classification methods that can be used is Stoc hastic Gradient Descent (SGD). SGD is a text mining classification method that is capable of being applied to large amounts of data. The classification results obtained for Tokopedia show an accuracy value of 84%, a precision value of 87%, a recall value o f 90%, and for Shopee an accuracy value of 66%, a precision value of 65%, and a recall value of 66%.                                                                  

Keywords : Analysis of Sentiment, Classification, E-Commerce, Opinions, Stochastic Gradient Descent.                                  

1. PENDAHULUAN                                                                  
Pengguna internet terus bertambah setiap tahunnya. pengguna internet tak hanya digunakan masyarakat Indonesia untuk mencari informasi dan berkomunikasi, melainkan juga untuk kegiatan ekonomi. Transaksi jual-beli yang awalnya bertemu langsung antara penjual pembeli kini mulai berubah. Proses jual-beli barang dan jasa dapat dilakukan dalam genggaman jari berbasis elektronik. Hal inilah yang disebut dengan E-Commerce [1], [2] . Kehadiran e-commerce  sangat memudahkan masyarakat jika hendak membeli produk karena pelanggan tidak perlu datang langsung ke toko. Tokoped ia dan Shopee merupakan e-commerce  yang banyak digunakan untuk melakukan jual beli barang dan bertransaksi online selama pandemi covid-19. E-commerce  merupakan segala bentuk transaksi perdagangan/perniagaan barang atau jasa ( trade of goods and service ) dengan menggunakan media elektronik [1], [3] . Proses jual beli atau pertukaran produk, jasa, dan informasi melalui jaringan komputer termasuk internet dan ini merupakan sebuah penerapan pada teknologi menuju otomatisasi transaksi bisnis dan juga alur kerja [4], [5] . Mulai dari pengiriman informasi, produk, layanan, juga pembayaran melalui saluran telepon, jaringan komputer, atau alat elektronik lainnya.  Tokopedia dan shopee adalah model dari e - commerce Customer to Customer (C2C) yang dapat diartikan bahwa model ini m erupakan transaksi jual-beli yang dilakukan oleh konsumen ke konsumen lainnya. Kedua e -commerce ini merupakan aplikasi belanja kategori paling populer di situs Google Play Store. Pada situs  Google Play Store  dilengkapi dengan fitur review dimana pengguna  bisa mengirimkan ulasan berupa kritik, pujian, saran, atau penilaian lain terhadap suatu aplikasi. Ulasan dari pengguna ini sering digunakan sebagai alat tolak ukur yang efektif dan efisien dalam menemukan informasi terhadap suatu produk atau jasa. Umumnya ulasan dari pengguna berisi saran yang bersifat positif maupun negatif yang dituliskan pada kolom komentar di Google Play dan secara tidak langsung baik sedikit maupun banyak akan memberikan pengaruh bagi calon pelanggan karena ulasan dari pengguna dapat menyediakan informasi yang terbaru dari produk tersebut. Pelanggan yang merasa tidak puas dengan layanan produk biasanya akan menuliskan keluhannya di kolom komentar platform online dan ada juga pelanggan yang memberikan komentar positif mereka terhadap produk. Opini-opini yang diekspresikan                                                                 
pelanggan itulah yang nantinya akan menentukan keputusan calon pelanggan. Text mining  adalah sebuah proses menambang data yang berupa teks, dimana sumber data yang didapatkan biasanya dari dokumen dan tujuannya yaitu mencari kata-kata yang dapat mewakili isi dari dokumen sehingga  dapat dilakukan analisa dari keterhubungan antar dokumen [6]. Analisis Sentimen ( Sentimen Analysis ) atau dikenal opinion mining  adalah bidang studi yang                                                                 
menganalisis pendapat orang, opini, evaluasi, penilaian, sikap, dan emosi terhadap entitas seperti produk, jasa, organisasi, individu, dan lain-lain[7][9]. Analisis sentimen pada situs Google Play Store. Pada penelitian ini yang bertujuan untuk memprediksi label sentimen pada ulasan para pengguna aplikasi Tokopedia dan Shopee pada bulan Maret â€“ Mei 2021. Klasifikasi data ulasan dari pengguna berdasarkan sentimen dapat membantu mempermudah pihak Shopee dan Tokop edia dalam mendapatkan informasi tentang persepsi dari pengguna aplikasi. Proses pengklasifikasian dilakukan                                                                 
dengan machine learning menggunakan metode Stochastic Gradient Descent. Klasifikasi adalah penggolongan sejumlah objek, gagasan, buku atau benda-benda lain berdasarkan subyek atau ciri-ciri yang sama agar dalam penyusunannya dapat teratur sesuai dengan                                                                 kesamaan subyeknya dan saling berdekatan letaknya, sedangkan subyek yang berbeda akan ditempatkan terpisah atau berjauhan [10], [11] . Stochastic Gradient Descent  menggunakan gradient stochastic yang meminimalkan fungsi kerugian yang dipilih fungsi linear. Algoritma ini mendekati gradien yang benar dengan me mpertimbangkan satu sampel pada suatu waktu, dan secara bersamaan memperbarui model berdasarkan gradien fungsi kerugian. Algoritma ini adalah algoritma yang paling sering dipakai untuk berbagai macam model pembelajaran. Pada saat melatih sebuah model akan dibutuhkan sebuah loss function  yang dapat                                                                 
memungkinkan peneliti untuk mengukur kualitas dari setiap bobot atau parameter tertentu [12]. Word Cloud  merupakan metode dari text mining  yang dapat menghasilkan kata-kata populer dan                                                                 
juga sering digunakan untuk memperlihatkan istilah trend berdasarkan frekuensi kata dari pengguna. Pada penelitian ini word cloud digunakan untuk memunculkan kata-kata yang paling sering muncul di dalam teks baik kata -kata yang positif dan kata yang bersifat negatif. Word cloud  merupakan salah satu metode untuk memvisualisa sikan data teks secara visual. Dengan menggunakan word cloud, gambaran frekuensi dari kata â€“ kata yang populer dalam text mining  dapat ditampilkan dalam bentuk yang menarik         namun tetap informatif .
                                                                 
2. METODOLOGI PENELITIAN                                                                  
2.1 Pengumpulan Data                                                                  
Data yang digunakan pada penelitian ini adalah data sekunder. Data yang diambil dengan menggunakan proses Scraping  pada kolom komentar ulasan Shopee dan Tokopedia di situs Google Play Store . Sampel yang akan digunakan adalah data yang diambil dari bulan maret - mei 2021.                                                                  
2.2 Tahapan Penelitian                                                                  
Tahapan Penelitian merupakan level atau tingkatan bisa disebut juga jenjang dalam sebuah aktivitas penelitian. Dimana tahapan tersebut terdapat memiliki proses yang dilakukan secara terstruktur, runtut,                                                                 
baku, logis da n sistematis [13]â€“[16].  
Gambar  1. Tahapan Penelitian                                                                  
3. HASIL DAN PEMBAHASAN                                                                  
Analisis deskriptif dilakukan untuk mengetahui infografik mengenai e-commerce Tokopedia dan Shopee.                                                                  
Gambar 3 . Rating Pengguna pada Tokopedia                                                                  
Berdasarkan jumlah penilaian para pengguna dari 10.000 data ulasan mengenai aplikasi Tokopedia, terdapat sebanyak 5.715 pengguna yang memberikan penilaian Sangat Suka, 639 pengguna dengan penilaian Suka, 672 pengguna dengan penilaian Lumayan, 545 pengguna dengan penilaian Tidak Suka, dan 2.429 pengguna memberikan penilaian Sangat Tidak Suka.                                                                  
Gambar 4 . Rating Pengguna pada Shopee                                                                  
Berdasarkan jumlah penilaian para pengguna dari 10.000 data ulasan Shopee, sebanyak 3.861 pengguna yang memberikan penilaian Sangat Tidak Suka, 983 pengguna dengan penilaian Tidak Suka, 893 pengguna dengan penilaian Lumayan, 645 pengguna dengan penilaian Suka, dan 3.618 pengguna memberikan penilaia n Sangat Suka. Akan tetapi banyak juga pengguna Shopee dan Tokopedia yang tidak sinkron rating dengan isi ulasan yang mereka berikan.                                                                  
Gambar 5 . Jumlah dan Persentase Ulasan Tokopedia                                                                  
Tokopedia dengan jumlah ulasan positif yaitu sebanyak  6.646 (66%) ulasan dan jumlah ulasan negatif sebanyak 3.354 (34%) ulasan.                                                                  
Gambar 6 . Jumlah dan Persentase Ulasan Shopee                                                                  
Shopee dengan jumlah ulasan negatif lebih banyak dibandingkan ulasan positif. Jumlah ulasan negatif pada Shopee yaitu sebanyak 5.144 (51%) dan ulasan positif berjumlah 4.856 (49%).                                                                  
4.2 Pelabelan Data                                                                  
Pada pelabelan hanya menggunakan kelas sentimen dengan kategori positif dan negatif. Adapun hasil dari pelabelan tokopedia dan shopee dapat dilihat sebagai berikut :                                                                  
Tabel 1 . Perbandingan Jumlah Data pada Kelas Sentimen                                                                  
4.3 Klasifikasi                                                                  
Hasil klasifikasi yang dilakukan dengan metode Stochastic Gradient Descent untuk Tokopedia lebih tinggi yakni sebesar 84%, sedangkan shopee yakni sebesar 66%. Berdasarkan nilai presisi Tokopedia lebih tinggi sebesar 87% sedangkan Shopee sebesar 65%. Dan berdasarkan nilai recall yang diperoleh Tokopedia sebesar 90% sedangkan Shopee sebesar 66%.                                                                  
4.4 Visualisasi Wordcloud                                                                  
Visualisasi Positif                                                                  
Tokopedia Positif  Shopee Positif                                                                  
Berdasarkan gambar diatas kata yang paling sering muncul atau yang paling sering digunakan oleh pengguna Tokopedia dalam memberikan ulasan positif diantaranya adalah â€œtokopediaâ€, â€œterimaâ€, â€œkasihâ€, â€œlatihâ€, â€œbagusâ€, â€œaplikasiâ€, â€œmudahâ€, â€œ cepatâ€, dan lainnya. Sedangkan Shopee menampilkan hasil dari kata yang bersifat positif yang paling sering digunakan oleh pengguna e-commerce Shopee                                                                 
diantaranya adalah kata â€œshopeeâ€, â€œkirimâ€, â€œmudahâ€, â€œsukaâ€, â€œcepatâ€, â€œmurahâ€, dan lainnya.                                                                  
Visualisasi Negatif                                                                 
Tokopedia Negatif  Shopee Negatif                                                                  
Berdasarkan pada gambar diatas pada Tokopedia menampilkan hasil dari wordcloud  yaitu kata yang paling sering muncul yang bersifat negatif adalah â€œtokopediaâ€, â€œbelanjaâ€, â€œbayarâ€, â€œbatalâ€, â€œkecewaâ€, â€œtipuâ€, dan lainnya. Sedangkan pada Shopee menampilkan kata bersifat negatif yang paling populer dan sering digunakan oleh pengguna shopee adalah kata â€œshopeeâ€, â€œkirimâ€, â€œpilihâ€, â€œjasaâ€, â€œkecewaâ€, â€œbarangâ€ dan lainnya.                                                                  

4. KESIMPULAN                                                                  
Berdasarkan rating  periode bula n Maret â€“ Mei 2021, jumlah ulasan positif pengguna Tokopedia yaitu sebesar 66% dari 10.000 ulasan yang menyatakan sangat suka terhadap e-commerce Tokopedia. Sedangkan jumlah ulasan positif pengguna Shopee yaitu sebesar 49% dari 10.000 ulasan yang menyatakan tidak suka terhadap e-commerce Shopee. Hasil penelitian menggunakan algoritma Stochastic Gradient Descent (SGD)  dengan perbandingan data latih dan data uji sebesar 80% : 20%, diperoleh akurasi yang cukup baik yaitu Tokopedia dengan perolehan tingkat akurasi sebesar 84% yang artinya dari 2.000 data ulasan yang diujikan, terdapat 1.712 ulasan yang benar pengklasifikasiannya oleh metode SGD. Sedangkan pada Shopee diperoleh tingkat akurasi yang lebih rendah sebesar 66% yang artinya dari 2.000 ulasan yang diuj ikan, terdapat 1.448 ulasan yang benar pengklasifikasiannya oleh metode SGD. Hasil dari pengklasifikasian yang telah dilakukan, dapat diketahui bahwa dari pengguna Tokopedia memberikan ulasan negatif yang terdapat beberapa kata yaitu â€œbatalâ€ sebanyak                                                                 
501 pengguna, â€œkecewaâ€ sebanyak 449 pengguna, â€œribetâ€ sebanyak 315 pengguna, dan â€œsalahâ€ sebanyak 307 pengguna. Sedangkan untuk Shopee diketahui bahwa pengguna memberikan ulasan negatif yang terdapat kata â€œkecewaâ€ sebanyak 1381 pengguna dan kata â€œribetâ€ sebanyak 532         pengguna.                                                                  

REFERENCES                                                                  
[1] A. U. Hamdani, â€œMODEL E -COMMERCE DENGAN METODE WEB ENGINEERING METHOD UNTUK MENUNJANGPEMASARAN PRODUK PADA XYZ PET SHOP,â€ 2019.                                                                  
[2] S. A. Widiana, S. Sintaro, R. Arundaa, E. Alfons ius, and D. Lapihu, â€œAplikasi Penjualan Baju Berbasis Web (E-Commerce) dengan Formulasi Penyusunan Kode,â€ J. Inf. Technol. Softw. Eng. Comput. Sci. , vol. 1, no. 1 SE-Articles, pp. 35 â€“43, Jan. 2023, doi: 10.58602/itsecs.v1i1.11.                                                                  
[3] D. I. Sensuse, R. J. Sipahutar, R. K. Jamra, and R. R. Suryono, â€œChallenges and Recommended Solutions for Change Management in Indonesian E-Commerce,â€ in 2020 International Conference on Information Technology Systems and Innovation (ICITSI) , 2020, pp. 250 â€“255.                                                                 
[4] H. Sulistiani, â€œPerancangan Dashboard Interaktif Penjualan (Studi Kasus: PT Jaya Bakery),â€ J. Tekno Kompak , vol. 12, no. 1, pp. 15 â€“17, 2018.                                                                  
[5] H. Sulistiani, S. Setiawansyah, and D. Darwis, â€œPenerapan Metode Agile untuk Pengembangan Online Analytical Processing (OLAP) pada Data Penjualan (Studi Kasus: CV Adilia Lestari),â€ J. CoreIT J. Has. Penelit. Ilmu Komput. dan Teknol. Inf. , vol. 6, no. 1, pp. 50 â€“56, 2020.                                                                  
[6] S. Styawati, W. Yulita, and S. Sarasvananda, â€œSURVEY UKURAN KESAMAAN SEMANTIC ANTA R KATA,â€ J. Data Min. dan Sist. Inf. , vol. 1, no. 1, pp. 32 â€“37, 2020.                                                                  
[7] R. R. SURYONO and B. Indra, â€œP2P Lending sentiment analysis in Indonesian online news,â€ in Sriwijaya International Conference on Information Technology and Its Applications (SICONIAN  2019) , 2020, pp. 39 â€“ 44.                                                                 
[8] A. R. Isnain, N. S. Marga, and D. Alita, â€œSentiment Analysis Of Government Policy On Corona Case Using Naive Bayes Algorithm,â€ IJCCS (Indonesian J. Comput. Cybern. Syst. , vol. 15, no. 1, pp. 55 â€“64.                                                                 
[9] C. ColÃ³n -Ruiz, â€œSemi -Supervised Generative Adversarial Network for Sentiment Analysis of drug reviews.â€ Institute of Electrical and Electronics Engineers (IEEE), 2021. doi: 10.36227/techrxiv.17075054.                                                                  
[10] N. Neneng, A. S. Puspaningrum, and A. A. Aldino, â€œPerbandingan Hasil Klasif ikasi Jenis Daging Menggunakan Ekstraksi Ciri Tekstur Gray Level Co-occurrence Matrices (GLCM) Dan Local Binary Pattern (LBP),â€ SMATIKA J. , vol. 11, no. 01, pp. 48 â€“52, 2021.                                                                  
[11] H. Sulistiani, â€œPemilihan Fitur Untuk Klasifikasi Loyalitas Pelanggan Terhadap Merek Produkfast Moving Consumer Goods (Studi Kasus: Mie Instan).â€ Institut Teknologi Sepuluh Nopember Surabaya, 2016.                                                                  
[12] J. Leinonen, D. Nerini, and A. Berne, â€œStochastic Super -Resolution for Downscaling Time-Evolving Atmospheric Fields with a Generative Adversarial Network,â€ pp. 1 â€“14, 2020.                                                                  
[13] A. Putra, M. R. D. Susanto, and Y. Fernando, â€œPenerapan MDLC Pada Pembelajaran Aksara Lampung Menggunakan Teknologi Augmented Reality,â€ Chain J. Comput. Technol. Comput. Eng. Informatics , vol. 1, no. 2,  pp. 32 â€“43, 2023.                                                                  
[14] E. Alfonsius, S. W. C. Ngangi, and C. F. Lagimpu, â€œSistem Informasi Layanan Surat Bebas Pustaka Pada Dinas Perpustakaan Dan Kearsipan Provinsi Sulawesi Tengah Berbasis Website,â€ J. Inf. Technol. Softw. Eng. Comput. Sci. , vol. 1, no. 2, pp. 66 â€“74, 2023.                                                                  
[15] Andris Silitonga and Dyah Ayu Megawaty, â€œDecision Support System Feasibility for Promotion using the Profile Matching Method,â€ J. Data Sci. Inf. Syst. , vol. 1, no. 2 SE -Articles, pp. 50 â€“56, May 2023, doi: 10.58602/dimis.v1i2.46.                                                                  
[16] A. F. Pasaribu, A. Surahman, A. T. Priandika, S. Sintaro, and Y. T. Utami, â€œSistem Pendukung Keputusan Seleksi Penerimaan Guru Menggunakan SAW,â€ J. Artif. Intell. Technol. Inf. , vol. 1, no. 1, pp. 13 â€“19, 2023.                                                                  
",Sentimen Analisis,Stochastic Gradient Descent,Ulasan Pengguna,"akurasi, presisi, recall"
SENTIMEN ANALISIS TERHADAP KEBIJAKAN PENYELENGGARA SISTEM ELEKTRONIK (PSE) MENGGUNAKAN ALGORITMA BIDIRECTIONAL ENCODER  REPRESENTATIONS FROM TRANSFORMERS  (BERT) ,"SENTIMEN ANALISIS TERHADAP KEBIJAKAN PENYELENGGARA SISTEM ELEKTRONIK (PSE) MENGGUNAKAN ALGORITMA BIDIRECTIONAL ENCODER  REPRESENTATIONS FROM TRANSFORMERS  (BERT) 

Bayu Kurniawan 1, Ahmad Ari Aldino 2, Auliya Rahman Isnain 3  

Abstract  
The rapidly growing development of internet technology has had a very large impact on the world community. This development has changed various conventional methods and people's lifestyles to 
become more modern in all fields, such as social, cultural, economic, military, administration and other fields. Bidirectional Encoder Representations from Transformers or BERT for short, is a 
trained language representation model created in 2018 by Google AI Language researchers. BERT was created using semi-supervised learning, ELMo, ULMFiT, OpenAI Transformers, and Transformers and deep learning techniques. Transformers are components which concentrates on the relevant relationships between words in the text (Vaswani et al., 2017). Sentiment analysis found that Bidirectional Encoder Representations from Transformers (BERT) had 69%, 55%, and 55% accuracy at two different times using the same hyperparameter, namely batch size 16, and epoch 5. Based on the test results, epoch gave satisfactory results. . Therefore, a sentiment analysis was carried out in epoch 5. When using BERT, the accuracy achieved was affected by an unbalanced data set. Although the number of balanced data sets is less than t hat of unbalanced data sets, accuracy is 62% higher.   
  
Keywords: Electronic system organizer, Sentiment Analysis, Twitter API, BERT, Text mining.   
  
Abstrak  
PerkembÐ°ngÐ°n teknologi internet yÐ°ng semÐ°kin pesÐ°t telÐ°h memberikÐ°n dÐ°mpÐ°k yÐ°ng sÐ°ngÐ°t besÐ°r pÐ°dÐ° mÐ°syÐ°rÐ°kÐ°t duniÐ°. PerkembÐ°ngÐ°n ini telÐ°h mengubÐ°h berbÐ°gÐ°i mÐ°cÐ°m metode konvensionÐ°l dÐ°n polÐ° hidup mÐ°syÐ°rÐ°kÐ°t menjÐ°di lebih modern disegÐ°lÐ° bidÐ°ng, seperti sosiÐ°l, budÐ°yÐ°, ekonomi, militer, Ð°dministrÐ°si sertÐ° bidÐ°ng lÐ°innyÐ°. Bidirectional Encoder Represe ntations from Transformers 
atau disingkat BERT, adalah model representasi bahasa terlatih yang dibuat pada tahun 2018 oleh peneliti Google AI Language.BERT dibuat menggunakan pembelajaran semi-diawasi, ELMo, ULMFiT, OpenAI Transformers, dan Transformers se rta teknik deep learning.Transformer adalah komponen yang berkonsentrasi pada hubungan yang relevan antarap kata-kata dalam teksm(Vaswani et al., 2017). Analisis sentimen menemukan bahwa Bidirectional Encoder Representations from Transformers (BERT) memiliki akurasi 69%, 55%, dan 55% pada dua waktu berbeda menggunakan hyperparameter yang sama, yaitu batch size 16, dan epoch 5. Berdasarkan hasil pengujian, epoch memberikan hasil yang memuaskan. Oleh karena itu dilakukan analisis sentimen pada epoch 5. Saat men ggunakan BERT, akurasi yang dicapai dipengaruhi oleh kumpulan data yang tidak seimbang. Meskipun jumlah kumpulan data seimbang lebih sedikit dari pada kumpulan data tidak seimbang, akurasi 62% lebih tinggi.  
 
Kata Kunci: Penyelenggara sistem elektronik , Ana lisis Sentimen, API Twitter, BERT, Text Mining .  
 
1. Pendahuluan   
PerkembÐ°ngÐ°n mteknologi internet nyÐ°ng semÐ°kin npesÐ°t telÐ°h OmemberikÐ°n dÐ°mpÐ°k nyÐ°ng sÐ°ngÐ°t besÐ°r npÐ°dÐ° mÐ°syÐ°rÐ°kÐ°t nduniÐ°. PerkembÐ°ngÐ°n nini telÐ°h mengubÐ°h nberbÐ°gÐ°i mÐ°cÐ°m nmetode konvensionÐ°l ndÐ°n polÐ° hidup nmÐ°syÐ°rÐ°kÐ°t menjÐ°di nlebih modern odisegÐ°lÐ° bidÐ°ng, seperti nsosiÐ°l, budÐ°yÐ°, nekonomi, militer, Ð°dministrÐ°si osertÐ° bidÐ°ng nlÐ°innyÐ°. DengÐ°n Ð°dÐ°nyÐ° n perkembÐ°ngÐ°n nteknologi sertÐ° nkemudÐ°hÐ°n mÐ°syÐ°rÐ°kÐ°t nuntuk berkomunikÐ°si ndÐ°n mengÐ°kses ninformÐ°si membuÐ°t npeluÐ°ng dÐ°n npersÐ°ingÐ°n yÐ°ng nÐ°dÐ° di mÐ°syÐ°rÐ°kÐ°t njugÐ° ikut nbertÐ°mbÐ°h. MÐ°syÐ°rÐ°kÐ°t nsekÐ°rÐ°ng dituntut nuntuk hidup nlebih modern ndÐ°nnikutnpÐ°dÐ° perkembÐ°ngÐ°n mtersebut jikÐ°ntidÐ°k ingin kÐ°lÐ°h nbersÐ°ing. PemÐ°nfÐ°Ð°tÐ°n nteknologi internet nini jugÐ° dilÐ°kukÐ°n noleh sebÐ°giÐ°n nbesÐ°r 
mÐ°syÐ°rÐ°kÐ°t nIndonesiÐ°. HÐ°sil survei nyÐ°ng dilÐ°kukÐ°n noleh ÐsosiÐ°si PenyelenggÐ°rÐ° nJÐ°sÐ° Internet IndonesiÐ° .yÐ°ng dilÐ°kukÐ°n npÐ°dÐ° tÐ°hun 2016 0menunjukÐ°n terdÐ°pÐ°t n132,7 jutÐ° penggunÐ° internet odi I ndonesiÐ°, dimÐ°nÐ° sebÐ°giÐ°n obesÐ°r  penggunÐ° ointernet tersebut pberÐ°dÐ° di wilÐ°yÐ°h jjÐ°wÐ° yÐ°kni sebÐ°nyÐ°k 986,3 jutÐ° orÐ°ng. ÐdÐ°pun ppemÐ°nfÐ°Ð°tÐ°n teknologi internet ttersebut cukup oberÐ°gÐ°m, dimÐ°nÐ° pdÐ°ri 132,7 jutÐ° openggunÐ° internet tersebut 97,4% odiÐ°tÐ°rÐ°nyÐ° menggunÐ°kÐ°n iinternet untuk mediÐ° ososiÐ°l, 96,8% untuk phiburÐ°n, 96.4% untuk pmengÐ°kses beritÐ°, 093.8% untuk pkebutuhÐ°n pendidikÐ°n, 93.1% .untuk komersiÐ°l, dÐ°n 91.6% .diÐ°ntÐ°rÐ°nyÐ° jugÐ° mmenggunÐ°kÐ°n internet untuk lpelÐ°yÐ°n publik kIndonesiÐ° (Rivaldi Moha & Kusumadara, 2020)  Teknologi informasi pdan komunikasi otelah mengubah kperilaku masyarakat dan pperadaban 
manusia lsecara global. Di samping pitu perkembangan pteknologi informasi ptelah menyebabkan pdunai menjadi otanpa batas (bolderless) pdan menyebabkan `perubahan sosial yang secara psignifikan berlangsung pdemikian cepat. Teknologi informasi psaat ini menjadi ppedang bermata dua,okarena selain berkontribusi pada kemajuan peradaban, kemajuan, dan kesejahteraan manusia, serta alat yang efektif untuk kegiatan kriminal. Masyarakat dan teknologi tidak dapat dipisahkan satu sama lain. Orang menjadi semakin bergantung pada teknologi di semua bidang, termasuk pendidikan, perawatan kesehatan, dan lapangan kerja.Internet adalah salah satu teknologi yang paling banyak digunakan. Meluasnya penggunaan  
teknologi internet merupakan perkembangan yang luar biasa. Istilah """"jaringan interkoneksi,"""" yang mengacu pada hubungan berbagi komputer yang membentuk jaringan komputer  global melalui jalur telekomunikasi seperti telepon kabel dan satelit, adalah akar dar i internet. (Hendrik, n.d.) . Sebuah studi komputasi untuk mengenali dan mengungkapkan pendapat, sentimen, evaluasi, sikap, emosi, subjektivitas, penilaian, atau pandangan yang terkandung dalam satu teks dikenal sebagai analisis sentimen (sentiment analysis) atau penggalian opini (Opinion Mining), masing -masing (Zannah R., 2019). Karena tingkat persaingan yang signifikan dalam industri pemasaran dan perubahan kebutuhan individu, analisis sentimen menjadi subjek banyak penelitian. Analisis sentimen telah menjadi subjek banyak penelitian sebelumnya. Dalam penelitian, Navie Bayes metode, jaringan saraf, dan metode SVM semuanya telah digunakan. Eksplorasi ini menyinggung penanganan Sentiment Analysis terhadap kebijakan pemerintah yaitu Penyelen gara 
Sistem Elekronik. Pada Penelitian Tersebut analisis sentimen dilakukan untuk melihat pendapat masyarakat Indonesia tentang Kebijakan Penyelenggara Sistem Elektronik. Dengan mengekstrak sejumlah dataset sentiment pada media sosial (Twitter), kemudian d ilakukan Preprocessing Text, Analisis Sentimen, TopWord Extraction, Development of Classification Model pmengacu pada algoritma BERT yang barusaja diciptakan poleh (Jacob Devlin, 2018).  Teori data mining juga digunakan dalam penelitian ini. Ekstraksi informasi dan pola yang berguna dari sejumlah besar data dikenal sebagai data mining. Ini juga dikenal sebagai """"proses penemuan pengetahuan"""", """"ekstraksi pengetahuan"""", """"analisis data"""", dan """"penambangan pengetahuan dari data."""" Strategi Data mining (Dm) dapat membantu mendukung peningkatan pesat volume data yang 
dihasilkan oleh digitalisasi, yang memiliki konsekuensi untuk proses seperti pengembangan proses. Proses Standar Lintas Industri untuk Data Mining, juga dikenal sebagai CRISP-DM, adalah standar yang dibuat pada tahun 1996 dan ditujukan untuk proses analisis industri sebagai strategi bisnis untuk memecahkan masalah. (Mas Raden Panca Rizqi Wahyu Atmaja Kusuma & Yustanti Wiyli, 2021) . BERT adalah model pembelajaran mendalam yang telah mencapai hasil terobosan dalam berbagai tugas NLP. BERT memiliki enam lapisan Transformer berlapis di atas setiap encoder dan decoder, itulah 
sebabnya file proses pelatihan sangat rumit, konfigurasinya sangat rumit , waktu pelatihan sangat lama, dan biayanya sangat tinggi. Namun, model pra-pelatihan BERT Google tersedia sebagai sumber 
terbuka dan dapat digunakan tanpa terlebih dahulu membuat model. Dimulai dengan kata dan representasi embedding dari lapisan embedding, Pemrosesan BERT dimulai. Untuk membuat 
representasi perantara baru, setiap lapisan menggunakan perhitungan perhatian berkepala banyak pada representasi kata dari lapisan sebelumnya. Ukuran semua representasi perantara ini identik. Token akan memiliki 12 representasi perantara di 12 lapisan model BERT . (Alifia Putri & al Faraby, 2020) . 
  
2. Tinjauan Pustaka   
Berikut tinjauan pustaka yang digunakan sebagai 
referensi atau pembanding terhadap penelitian ini:  
1. Literatur 1 ( Putri, 2020 ) dengan judul â€œAnalisis pSentimen Review Film Berbahasa Inggris Dengan Pende katan Bidirectional Encoder Representations from Transformers .â€ dengan metode  Bidirectional Encoder Representations from Transformers dengan hasil akurasi menggunakan BERT adalah 73%, dengan 2000 review dimana 1000 review dengan m sentimen positif, dan 1000  review dengan sentimen mnegatif.  
2. Literatur 2 ( Abdul et al, 2019 .) dengan judul â€œ Using BERT for Checking lthe Polarity of Movie Reviews. â€ dengan metode Bidirectional Encoder Representations from Transformers dengan hasil  Hasil evaluation accuracy pyang di peroleh mencapai 0.89 dengan loss 0.4856, precissiom 0.9174 dan recall 0.8812 .  
3. Literatur 3 ( Munakir et al, 2019 .) dengan judul â€œFine-grained Sentiment pClassification using BERT. â€ dengan metode Bidirectional Encoder Representations from Transformers dengan hasil Akurasi yang di peroleh saat tarining dataset adalah 90% dan test pdataset adalah 79%. 
4. Literatur 4 ( Maharani, 2020 .) dengan judul â€œSentiment Analysis during Jakarta Flood for Emergency Responses and Situational Awareness in Disas ter Management using BERT â€. Dengan metode Bidirectional Encoder Representations from Transformers dengan hasil  Akurasi yang di peroleh saat tarining dataset adalah 90% dan test dataset adalah 79%.   
5. Literatur 5 ( Kurniawan et al, 2019 .) dengan judul â€œAnalis is sentimen opini film Menggunakan Metode Naive Bayes dan Lexicon Based Features â€ dengan metode NaÃ¯ve Bayes dan Lexicon Based Features  dengan hasil Hasil ppengujian menggunakan Naive-Bayes dengan pembobotan lexicon-based  features menghasilkan nilai akurasi  0.8, precision , recall  0.8, dan f-measure 0.8. Sedangkan hasil pengujian menggunakan Naive-Bayes tanpa pembobotan lexicon-based features  menghasilkan nilai akurasi  0.95, precision  1, recall  0.9, dan f-measure 0.9474 .  Berdasarkan tinjauan pustaka yang telah dilakukan oleh penulis, maka perbedaan antara penelitian terdahulu dan penelitian yang dilakukan adalah 
sebagai berikut:  
1. Data set yang digunakan merupakan tweet  yang berisi komentar masyarakat terhadap penyelenggara sistem elektronik di 
indonesia.  
2. Data set yang digunakan diperoleh dengan cara crawling menggunakan Twitter API.  
3. Penerapan dan visualisasi algoritma Bidirectional encoder representation from transformer menggunakan software Python . 
dilakukan ini tergolong masih belum banyak dilakukan oleh peneliti terdahulu.   
2.2 Natural Language Processing (NLP)  
Salah satu bidang Artificial Intelligence yang mempelajari dan mengembangkan bagaimana komputer pdapat memahami, pmemahami, dan memproses bahasa alami pdalam bentuk teks atau ucapan dikenal sebagai Natural Language Processing.  NLP menganalisis bahasa manusia sedemikian rupa cara komputer 
dapat pmemahami bahasa sebaik manusia. Linguistik komputasi, ilmu komputasi, ilmu kognitif, dan kecerdasan buatan adalah bagian dari bidang interdisipliner yang dikenal sebagai NLP.   
2.3  Analisis Sentimen   
Subbidang penelitian komputasi yang dikenal sebagai """"analisis sentimen"""" menyelidiki opini, perasaan, dan emosi teks. Dalam NLP dan penambangan data, analisis sentimen, juga dikenal sebagai penambangan op ini, telah menjadi topik hangat. Tujuan utama panalisis sentimen adalah untuk mengolah, mengekstrak, meringkas, 
dan menganalisis informasi pdalam sebuah teks menggunakan berbagai metode sehingga dapat menyimpulkan pemosi dan psudut pandang penulis dari teks dan berbagi informasi subjektif penulis tentang kecenderungan emosional teks  termasuk di dalamnya .  
2.4  Machine Learning  
Dalam Artificial Intelligence, salah satu bidang keilmuannya adalah machine learning atau pembelajaran mesin. Seperti nam anya, tujuan pembelajaran mesin adalah melatih mesin dengan pbanyak contoh atau pkumpulan data yang pterkait dengan ptugas yang sedang dikerjakan. Berdasarkan kumpulan data tersebut, mesin mempelajari pola yang diberikan dan membuat aturannya sendiri   
2.5   Neural Network  
Salah psatu metode pyang paling umum muntuk pembelajaran mesin adalah jaringan saraf, juga dikenal sebagai jaringan saraf tiruan. Ia bekerja dengan mensimulasikan pmekanisme pembelajaran yang didasarkan pada cara kerja sistem saraf manusia patau makhluk hidup lainnya. .Sel-sel yang membentuk sistem saraf disebut neuron. Akson dan dendrit menghubungkan neuron ini satu sama lain. Menurut Aggarwal (2018) , sinapsis adalah penghubung antara dendrit dan akson.  
2.6   Deep Leraning   
Subbidang kecerdasan buatan yang dikenal sebagai pembelajaran mendalam adalah subbidang pembelajaran mesin. Menurut Hollet (2018), pembelajaran mendalam adalah jenis jaringan saraf yang lebih maju dan dalam daripada jaringan saraf standar karena jumlah lapisannya meningkat secara signifikan.  
2.7   Pengertian Bidirectional Encoder Representations from Transformers (BERT)  
Representasi Encoder Bidirectional Transformers (Devlin et al.,2019), atau disingkat BERT, adalah model mrepresentasi bahasa terlatih yang dibuat pada tahun 2018 oleh peneliti Google AI Language. BERT dibuat menggunakan pembelajaran semi-diawasi, ELMo, ULMFiT, OpenAI Transformers, dan Transformers serta teknik deep learning.   
3. Metodologi Penelitia  
3.1 Kerangka Penelitian   
Kerangka tahapan penelitian ini dibuat oleh penulis sebagai acuan terstruktur pelaksanaan penelitian. Kerangka Tahapan  Penelitian ini disesuaikan dengan tahapan ( 3.1) Text Mining . Berikut ini merupakan tahapan penelitian yang akan penulis laksanakan tertera pada gambar 1.  
Gambar  Tahapan Penelitian  
Berikut ini merupakan penjelasan tahapan-tahapan dari kerangka penelitian diatas:  
1. penentuan masalah penelitian, yaitu adalah tentang analisis sentimen terhadap pengguna  Twitter. 
2. Opportunity  (Peluang) , memberikan penyelesaian masalah yang 
mencangkup dengan penerapan dari text mining  Penggunaan ptext mining dapat menyelesaikan masalah seperti analisis sentimen, document clustering, document classification, information extraction, information retrieval, dan pweb mining.  
3. pendekatan dengan masalah untuk menentukan solusi apa yang akan digunakan dengan menggunakan model Menentukan sentimen 
masyarakat terhadap kebijakan penyelenggara sistem elektronik Pada Media Sosial Twitter  Menentukan respon Sentimen  
1. Data Pengguna Twitter  
2. Klasifikasi Data  
Menentukan respon positif/negatif  
Confusion Matrix dan 
Cross - Validation  
Menghasilkan nilai dari proses analisis sentimen  yang digunakan untuk analisis sentimen.   
4. merupakan  usulan, usulan  yang diajukan pada penelitian ini adalah menghasilkan data klasifikasi berda sarkan data dari Twitter untuk menentukan analisis sentimen dan untuk melihat apakah respon pengguna grup itu positif atau negatif .  
5. Berikutnya merupakan tahap  pengujian yang merupakan proses untuk mengevaluasi keakuratan dari model, pengujian pada penelitian ini dilakukan menggunakan confusion matrix  dan cross -
validation  
6. Terakhir merupakan tahapan hasil dari teknik text mining  yang 
menggunakan pBidirectional Encoder Representations From Transformers (BERT) Algorithm  untuk menghasilkan pklasifikasi data dan exploratory  data analisis .  
3.2 Tahapan Penelitian   
Tahapan pada penelitian ini adalah proses untuk memecahkan permasalahan yang terjadi, tahapan penelitian ini terbagi menjadi beberapa sub menu bagian. 
1. Studi Pustaka dan Literatur  
2. Pengumpulan data  
3. Prepocessing  
4. Validasi  
5. penutup  
3.3 Studi Pustaka dan Literatur  
Studi Literatur merupakan cara yang digunakan untuk menghimpun data atau sumber yang berhubungan dengan judul yang di pakai dalam penelitian ini. Studi literatur  dapat di peroleh dengan berbagai sumber antara lain : 
1. Buku/ E-Book  yang digunakan untuk membahas tentang text mining  khususnya deep learning yaitu Bidirectional Encoder Representations from Transformers (BERT)  
2. Jurnal yang mengandung tentang klasifikasi dan  
3. analisis psentimen menggunakan Bidirectional Encoder Representations from Transformers (BERT)   
Prosedur Pengumpulan data  
1. Export Analisis Sentimen  
2. Dokumentasi  
3.4 Alat dan Bahan Penelitian  
Pada penelitian ini pbahan yang dipakai atau digunakan untuk tahap penelitian adalah Sentimen masyarakat dari media sosial Twitter . Data itu akan digunakan sebagai dataset dengan jumlah data yang 
cukup lumayan banyak. Data itu nantinya akan diolah dan hasil akhirnya untuk mengetahui exploratory data analisis yang terjadi dan akan mengetahui analisis sentimen pengguna tersebut apakah mempunyai respon yang baik atau buruk.  
3.5 Proses dan Perhitungan  
1. Crawling  
Penelitian ini menggunakan data tyang diperoleh dari Twitter yang diambil dari Sentimen-sentimen yang diberikan pengguna di otweet  dengan t#PSE yang diunggah pada February 2022.  
2. Labelisasi Dataset  
Dataset yang sudah memiliki label atau annotator beranotasi diperlukan untuk analisis sentimen menggunakan metode pembelajaran terawasi. Pendekatan pembelajaran terawasi memerlukan contoh, sehingga pelabelan ini harus dilakukan Menurut Goldberg (2017). 
Contoh  Dataset Tweet  Sentimen  
Begini Kalau punya pemimpin yang sewenang-wenang  0 
Kapan Mau maju kalau ada PSE masih ada?  1 
PSE sudah dicabut indonesia tidak butuh kalian  0 
Epic Gamers sudah tidak diblokir kominfo lagi  2 
Ini privasi gue, jangan nguntit!  0 
Setujukah PSE benar-benar dihapus?  1 
3. Prepocessing dataset  
Case folding, data cleaning, tokenization, stopword removal, stemming, dan non-standard language normalization merupakan berbagai tahapan preprocessing yang dilakukan pada penelitian ini  untuk pmengubah dataset yang tidak terstruktur menjadi pterstruktur dan membuat pengolahan  data menjadi lebih sederhana.   
a. Case folding  
Dengan membuat semua phuruf besar dalam dataset menjadi phuruf kecil, dilakukan case folding. Untuk memastikan bahwa semua karakter dalam dataset identik, tahap ini menggunakan huruf kecil.   Twett Hasil Casefolding  
Lho kok sulit, padahal kan tinggal SEARCHING yang daftar di pse?  Lho kok sulit, padahal kan tinggal searching yang daftar di pse?  
b. Data Cleaning  
Pada titik ini, kalimat dataset dibersihkan dari apa pun yang pdapat memengaruhi hasil analisis, seperti kata dengan dua atau lebih karakter berulang, tautan, nama pengguna (@namapengguna), tagar 
(#), angka, simbol, dan spasi tambahan angka dan tanda baca.  
Tweet  Hasil Data Cleaning  
PSE sudah dicabut belum? Indonesia tida butuh kalian..  
PSE sudah dicabut belum Indonesia tidak butuh kalian  
c. Tokenisasi  
Tokenisasi adalah proses memecah kalimat menjadi kata-kata, tanda baca, dan ekspresi bermakna lainnya psesuai dengan aturan 
bahasa. Penulis menggunakan fungsi word_tokenize library NLTK selama prosedur ini. Tabel 3.4 menunjukkan ilustrasi tahap tokenisasi.  
Tweet  Hasil Tokenisasi  
Kapan mau maju kalau PSE masih ada â€˜Kapanâ€™ â€˜mauâ€™ â€˜majuâ€™ â€˜kalauâ€™ â€˜PSEâ€™ â€˜masihâ€™ â€˜adaâ€™   
d. Stopwords Removal  
Prosedur yang dikenal sebagai Stopwords Removal digunakan untuk menghilangkan kata-kata yang tidak berarti apa -apa. 
Tweet  Hasil Stopwords Remioval  
Kominfo aib buat pemerintah yang sekrang aja emang hadeh  â€˜Kominfoâ€™ â€˜aibâ€™ â€˜buatâ€™ â€˜pemerintahâ€™ 
â€˜yangâ€™ â€˜sekarangâ€™ â€˜ajaâ€™ â€˜emangâ€™ â€˜hadehâ€™  
e. Steaming  
Stemming adalah penghilangan afiks seperti prefiks, sufiks, dan konfiks untuk mengubah kata-kata berimbuhan menjadi bentuk akarnya.  
Tweet  Hasil Stemming  
Nasionalis boleh, tapi masa harus mundur ke jaman dulu ? Nasionalis era digital itu jago di global bukan cuma maen di kandang  â€˜â€™Nasionalisâ€™ â€˜tapiâ€™ â€˜mundurâ€™ â€˜jamanâ€™ â€˜duluâ€™ â€˜eraâ€™ â€˜digitalâ€™ â€˜jagoâ€™   â€˜globalâ€™ â€˜bukanâ€™ â€˜Cumaâ€™ â€˜kandangâ€™  
f. Normalisasi  
Kata-kata non-standar dataset diubah menjadi kata-kata standar atau dieja selama tahap normalisasi.  
Tweet  Hasil Normalisasi  
Sedangkan aplikasi slot judi online masih legal sampe skrg Sedangkan aplikasi slot judi online masih legal sampe sekarang  
Skenario BERT   
Mulai  
Data 
4. Hasil dan Pembahasan  
Penulis menggunakan scraping untuk mendapatkan tweet dari Twitter. Tweet ini akan digunakan untuk membuat dataset untuk analisis sentimen mengenai kebijakan penyelenggara sistem 
elektronik. Tweet yang dibuat dengan Python. masuk ke tahap selanjutnya, Dataset yang berisi 5.016 kalimat dibuat dengan 
tokenization kalimat Gambar 4.5 menggambarkan bagaimana hasil tokenized dataset disimpan dalam format file.xlsx.Dataset yang digunakan dalam penelitian ini harus diberi anotasi terlebih dahulu sebelum dapat diguna kan. Komentar diberi label secara berurutan untuk mengelompokkannya menurut sentimennya â€”negatif, 
netral, pdan positif. Sentimen positif pdiberi skor 2, sentimen netral diberi skor 1, dan psentimen negatif diberi skor 0. Setelah itu dataset dibagi menjadi  training dataset, validasi dataset, dan testing dataset sebelum tahap klasifikasi. Model dilatih dengan bantuan 
training dataset. Namun demikian, dataset validasi digunakan untuk mengurangi jumlah overfitting yang sering terjadi pada pjaringan syaraf tiruan. pameran.Keakuratan jaringan yang telah dilatih menggunakan dataset pelatihan dievaluasi sebagai pengujian akhir menggunakan dataset pengujian itu sendiri. Masuk ke tahap implementasi Bert penulis melakukan penyesuaian dengan memanfaatkan hyperparameters. Berdasarkan  rekomendasi BERT 
berikut :  
1. Batch size : 32 
2. Epoch : 5  
Ada beberapa faktor yang mempengaruhi pemilihan hyperparameter ukuran batch 32 -batch dipilih karena semakin plama waktu yang dibutuhkan untuk menyelesaikan suatu batch, semakin besar ukuran batch. Penulis menguji dengan lima epoch untuk menentukan mana yang akan digunakan.  
Akurasi dengan 5 epoch  
Akurasi dengan 5 epoch  
Penulis menggunakan lima epoch untuk melakukan analisis sentimen berdasarkan perbandingan ini. Untuk mendapatkan hasil 
terbaik, implementasi BERT dilakukan dua kali. Pada setiap tahap pelatihan, validasi, dan pengujian, benih acak tidak ditentukan untuk 
dataset. sehingga dataset pelatihan, validasi, dan pengujian semuanya berbeda setiap kali analisis sentimen dilakukan.  
Prepocessing  
Pelabelan Data (Positif/Negatif)  
Encoding  
Pengujian Algoritma BERT  
Hasil dan Akurasi  
Selesai  
Berdasarkan pengamatan tersebut, ditentukan bahwa akurasi model pelatihan lebih unggul dari model validasi. Kurva tersebut menunjukkan peningkatan akurasi hasil model pelatihan. Namun, hasil validasi lebih rendah dan cenderung sedikit berfluktuasi. Pada percobaan pertama, kedua, dan ketiga, akurasi keseluruhan dengan BERT mencapai 69%, 55%, dan 55% setelah pengujian dataset. Dataset yang dibagi secara acak oleh sistem menjadi dataset untuk pelatihan, pengujian, dan evaluasi di setiap percobaan berdampak pada perbedaan hasil akurasi yang diperoleh sistem. Selain itu, sentimen positif biasanya memiliki presisi yang lebih tinggi daripada netral dan negatif.  
Diagram Matrix Perc obaan pertama  
Diagram Matrix Percobaan kedua  

5. Kesimpulan  
1. Analisis osentimen menemukan bahwa Bidirectional Encoder Representations from Transformers p(BERT) memiliki akurasi 969%, 55%, dan 55% pada dua waktu berbeda menggunakan hyperparameter yang sama, yaitu batch size 16, dan epoch 5.   
2. Berdasarkan hasil pengujian, epoch memberikan hasil yang memuaskan. Oleh karena itu dilakukan analisis sentimen pada epoch 5.  
3. Saat menggunakan BERT, akurasi yang dicapai dipengaruhi oleh kumpulan  data yang tidak seimbang. Meskipun jumlah kumpulan data seimbang lebih sedikit daripada kumpulan data tidak seimbang, akurasi 62% lebih tinggi.  
 
Daftar Pustaka  
[1]. Abdul, S., Qiang, Y., Basit, S., & Ahmad, W. (2019). Using BERT for Checking the Polarity of Movie Reviews. International Journal of 
Computer Applications , 177(21), 37â€“41. https://doi.org/10.5120/ijca2019919675
[2]. Adina N. (2020). SENTIMEN ANALISIS MULTI -LABEL PADA UJARAN KEBENCIAN DAN UMPATAN DI TWITTER INDONESIA MENGGUNAKAN PENDEKATAN DEEP LEARNING . 
[3]. Alifia Putri, C., & al Faraby, S. (2020). Analisis Sentimen Review 
Film Berbahasa Inggris Dengan Pendekatan Bidirectional Encoder 
Representations from Transformers . 6(2), 181 â€“193. http://jurnal.mdp.ac.id  
[4]. Alwasiâ€™a A. (2020). ANALISIS SENTIMEN PADA REVIEW APLIKASI BERITA ONLINE MENGGUNAKAN METODE MAXIMUM ENTROPY . 
[5]. Cahyadi, R., Damayanti, A., Aryadani, D., Rekayasa Multimedia 
Poltek Negeri Media Kreatif Jakarta Jl Srengseng Sawah, T., Selatan, J., (2020). RECURRENT NEURAL NETWORK (RNN) DENGAN LONG SHORT TERM MEMORY (LSTM) UNTUK ANALISIS SENTIMEN DATA INSTAGRAM. In Jurnal Informatika dan Komputer  (Vol. 5, Issue 1).  
[6]. Hendrik, A. (n.d.). LIABILITY KORPORASI PENGELOLA 
SISTEM ELEKTRONIK & DELIK TERKAIT PENYELENGGARAAN 
SISTEM ELEKTRONIK Dl ERA INDUSTRI 4.0 https://doi.org/10.1145/2833312.28 5044S.,h  
[7]. Kurniawan, A., & Adinugroho, S. (2019). Analisis Sentimen Opini 
Film Menggunakan Metode Naive Bayes dan Lexicon Based Features  (Vol. 3, Issue 9). http://j-ptiik.ub.ac.id  
[8]. Mas Raden Panca Rizqi Wahyu Atmaja Kusuma, & Yustanti Wiyli. (2021). Analisis Sentimen Customer Review Aplikasi Ruang Guru dengan Metode BERT (Bidirectional Encoder Representations from Transformers). JEISBI , 02, 55â€“62. 
[9]. Munikar, M., Shakya, S., & Shrestha, A. (2019). Fine-grained 
Sentiment Classific ation using BERT http://arxiv.org/abs/1910.03474  
[10]. Rivaldi Moha, M., & Kusumadara, A. (2020). 2 (2) 2020 
â€œThe Urgency Of Electronic System Registration For E-Commerce Entrepreneurs.â€  http://ejurnal.ung.ac.id/ index.php/ja
lrev/JALREV  
[11]. Zannah R. (2019). ANALISIS SENTIMEN PADA MEDIA SOSIAL 
TWITTERUNTUK KLASIFIKASI OPINI ISLAM RADIKAL MENGGUNAKAN JARINGAN SARAF TIRUAN . 
[12]. Zulfa, I., & Winarko, E. (2017). Sentimen Analisis Tweet Berbahasa Indonesia dengan Deep Belief Network. IJCCS , 11(2), 187 â€“198. www.search.twitter.com      ",Sentimen Analisis,Biderectional Encoder Representations From Transformers,tweet yang berisi komentar masyarakat,"akurasi, presisi"
ANALISIS SENTIMEN  APLIKASI  RUANG  GURU  DI TWITTER MENGGUNAKAN  ALGORITMA  KLASIFIKASI ,"ANALISIS SENTIMEN  APLIKASI  RUANG  GURU  DI TWITTER MENGGUNAKAN  ALGORITMA  KLASIFIKASI 

Angelina Puput Giovani1), Ardiansyah2), Tuti Haryanti3), Laela Kurniawati4) , Windu Gata5) 

Abstract  
E-learning is electronic -based learning using computers or computer-based. One e -learning application that is widely known today is Ruang Guru. One way to find out the success of an application is to do a sentiment analysis of the application. In this study, sentiment analysis was taken from Twitter s ocial media user comments on Ruang Guru of 513 tweets, after data cleaning, with 338 tweets of positive sentiment and 175 tweets of negative sentiment. The data was extracted using the Naive Bayes (NB) algorithm, Support Vector Machine (SVM), K-Nearest Neighbor (K -NN), and feature selection with the Particle Swarm Optimization (PSO) algorithm. This study compares the NB, SVM, K-NN methods without using feature selection with the NB, SVM, K-NN methods that use feature selection and compares the Area Under Curve (AUC) values of these methods to find the most optimal algorithm. The test results get the results that the best optimization application in this model is the SVO -based PSO algorithm with an accuracy value of 78.55% and AUC of 0.853. This research su cceeded in getting the most effective and best algorithm in classifying positive and negative comments related to Ruang Guru.  
 
Keyword:  Ruang Guru, Sentiment analysis, Twitter, Classification Algorithms.  
 
Abstrak  
E-learning  merupakan pembelajaran berbasis  elektronik dengan menggunakan komputer atau berbasis komputer. Salah satu aplikasi e-learning  yang banyak dikenal saat ini adalah  aplikasi Ruang Guru. Salah satu cara untuk mengetahui keberhasilan suatu aplikasi adalah dengan melakukan analisis sentimen terhadap aplikasi tersebut. Pada penelitian ini, analisis sentimen diambil dari komentar pengguna media sosial Twitter terhadap aplikasi Ruang Guru  sebanyak 513 tweet , setelah dilakukan data cleaning , dengan sentimen positif sebanyak 338 tweet dan sentimen negatif sebanyak 175 tweet. Data tersebut diekstraksi menggunakan algoritma Naive Bayes (NB), Support Vector Machine  (SVM), K-Nearest Neighbour  (K-NN), dan feature selection  dengan algoritma  Particle Swarm Optimization (PSO) . Penelitian ini membandingkan  metode NB, SVM, K-NN tanpa menggunakan feature selection  dengan metode NB, SVM, K -NN yang menggunakan feature selection  serta membandingkan nilai Area Under Curve  (AUC)  dari metode-metode  tersebut untuk mengetahui algoritma  yang paling optimal . Hasil pengujian mendapatkan hasil bahwa aplikasi optimasi terbaik dalam model ini adalah algoritma PSO berbasis SVM dengan nilai akurasi sebesar 78,55% dan AUC sebesar 0,853. Penelitian ini berhasil mendapatkan algoritma yang efektif dan terbaik dalam mengklasifikasikan komentar positif dan komentar negatif terkait dengan aplikasi Ruang Guru. 
 
Kata Kunci:  Ruang Guru, Analisis sentimen , Twitter, Algoritma Klasifikasi.  
 
1. Pendahuluan  
Semakin berkembangnya teknologi informasi membuat metode pembelajaran dituntut untuk mengikuti perkembangan teknologi. Metode pembelajaran yang digunakan seharusnya dapat memanfaatkan berbagai media untuk meningkatkan kualitas hasil pembelajaran. Salah satunya, me dia pembelajaran dapat menggunakan e-learning  atau pembelajaran berbasis elektronik dengan menggunakan komputer atau berbasis komputer. E-learning  pertama kali diperkenalkan oleh Universitas llionis di Urbana -Champaign dengan menggunakan sistem instruksi  berbasis komputer ( computer assisted instruction ) dan komputer bernama PLATO. Sejak saat itu e-learning , pembelajaran berbasis internet , berkembang sejalan dengan perkembangan dan kemajuan teknologi [1]. Sampai saat ini aplikasi atau situs e-learning berkembang sangat pesat. Terdapat beberapa aplikasi  e-learning  di Indonesia, dari mulai yang berbayar hingga tak berbayar , salah satu nya adalah  aplikasi Ruang Guru. Dikutip dari laman ruangguru.com, Ruang Guru 
merupakan perusahaan teknologi terbesar di Indonesia yang berfokus pada layanan berbasis pendidikan, yang telah memiliki lebih dari 15 juta pengguna serta mengelola 300.000 guru yang menawarkan jasa di lebih dari 100 bidang pelajaran. Ruang Guru  mengembangkan berbagai layanan belajar berbasis teknologi, termasuk layanan kelas virtual, platform ujian online, video belajar berlangganan, marketplace, les privat, serta konten -konten pendidikan lainnya yang bisa diakses melalui web dan aplikasi Ruang Guru. Aplikasi ini memudahkan siswa untuk mengakses materi pembelajaran yang berkualitas. Di mana pun mereka berada, dapat membantu proses belajar siswa tanpa batasan ruang dan waktu, dapat membantu siswa, guru, dan orang tua untuk menjalankan aktivitasnya  menjadi lebih efektif dan efisien  [2]. 
Suatu aplikasi selalu memiliki kekurangan dan kelebihan masing-masing, dimana hal tersebut dapat menimbulkan berbagai respon dari pengguna aplikasi seperti kepuasan dan kekecewaan terhadap aplikasi tersebut. Media sosial menjadi salah satu tempat untuk 
melontarkan k epuasaan dan kekecewaan pengguna atau opini terhadap aplikasi tersebut . Hal tersebut dapat  dijadikan bahan analis is sentimen terhadap aplikasi Ruang Guru. Analisis  Sentimen  digunakan untuk menemukan informasi berharga yang dibutuhkan dari data yang tidak terstruktur, sehingga diharapkan pada penelitian ini dapat diketahui sentimen pengguna twitter terhadap aplikasi Ruang Guru. Penelitian ini juga diharapkan dapat mengetahui pengaruh feature selection  terhadap akurasi  proses analisis sentimen yang  dilakukan.  Twitter merupakan salah satu media sosial yang sangat populer dikalangan pengguna internet, hal ini dikarenakan kesederhanaan dan kemudahan dalam penggunaannya, serta pengguna dapat dengan bebas mengeluarkan pendapat atau opini mereka. Beberapa peneliti yang menggunakan bahan penelitian dari twitter antara lain  terkait teks berbahasa Indonesia, calon gubernur DKI Jakarta 2017, calon Presiden Indonesia 2014, dan penggunaan transportasi umum darat dalam kota [3]â€“[6]. Beberapa peneliti sebelumnya telah melakukan penelitian untuk mengukur sentimen analisis dengan berbagai algoritma, antara lain algoritma Naive Bayes  (NB), Support Vector Machine  (SVM), K-Nearest Neighbour  (K-NN), Decision Tree, K-Medoid, dan Backpropagation Neural Network  (BNN).  Beberapa penelitian menambahkan feature selection  seperti Particle Swarm Optimization  (PSO). Diantara penelitian tersebut terdapat beberapa peneliti yang membandingkan dua atau lebih algoritma untuk mengetahui algoritma terbaik dari algoritma yang dibandingkan  [7]â€“[15]. Metode yang digunakan dalam penelitian ini adalah NB, SVM, dan K-NN, dengan tambahan feature selection  dengan  PSO. Penelitian akan membandingkan metode NB, SVM, K -NN tanpa PSO dibandingkan dengan metode NB, SVM, K -NN dengan  PSO. Hal ini untuk menguji pengaruh  penggunaan feature selection  PSO dengan membandingkan nilai AUC ( Area Under Curve ) dari metode tersebut.  Algoritma klasifikasi NB merupakan salah satu algoritma teknik klasifikasi, algoritma ini memanfaatkan metode probabilitas dan statistik. Algoritma ini merupakan salah satu metode klasifikasi yang populer dan termasuk dalam sepuluh algoritma teratas dalam data mining  menurut IEEE International Conference on Data Mining  (ICDMâ€™06) di Hongkong  [16]. Naive Bayes  merupakan cabang matematika yang dikenal sebagai teori probabilitas untuk mencari peluang terbesar dari kemungkinan klasifikasi, dengan melihat frekuensi masing -masing klasifikasi dalam data pelatihan [17]. Pada algoritma klasifikasi NB terdapat dua tahapan dalam proses klasifi kasi teks . Pertama,  proses analisis sampel dokumen seperti penyeleksian kosa kata, yaitu kosa kata yang mungkin muncul dalam koleksi dokumen sampel, yang kemudian dilakukan proses penentuan probabilitas untuk setiap kategori berdasarkan dokumen sampel. Kedua, tahap klasifikasi, dilakukan penentuan nilai kategori suatu dokumen berdasarkan kosa kata yang muncul dalam dokumen yang diklasifikasi. SVM merupakan seperangkat metode pembelajaran yang menganalisis data dan mengenali pola . Algoritma ini  dapat diguna kan untuk klasifikasi dan analisis regresi . Namun tidak hanya itu , algoritma  ini juga dapat melakukan prediksi dan penilaian tentang sebuah sistem [18]. Tujuan dari SVM adalah memberikan nilai dari banyaknya kemunculan sebuah kata dan dapat mengklasifikasi kalimat dengan label  positif dan negatif . Keuntungan SVM yaitu Ruang Input Dimensi Tinggi dan Ruang Dokumen Vektor [19]. K-NN adalah salah satu algoritma  paling sederhana untuk memecahkan masalah klasifikasi. Algoritma ini sering digunakan untuk klasifikasi teks dan data. Pada metode ini d ilakukan klasifikasi terhadap obyek berdasarkan data yang jaraknya paling dekat dengan obyek tersebut [20]. Tujuan dari algoritma ini adalah untuk mengklasifikasikan obyek berdasarkan atribut dan training sample . Algoritma ini menggunakan klasifikasi ketetanggaan sebagai nilai prediksi dari query instance  yang baru. PSO banyak digunakan untuk memecahkan masalah optimasi serta masalah seleksi fitur  (feature selection ). Dalam teknik  PSO terdapat beberapa cara untuk melakukan pengoptimasian , diantaranya meningkatkan bobot  atribut ( attribute weight ) terhadap semua atribut atau variabel yang dipakai, menyeleksi atribut ( attribute selection ) dan feature selection . Algoritma ini  adalah suatu teknik optimasi yang sangat sederhana untuk menerapkan dan memodifikasi beberapa parameter [21]. Beberapa penelitian sebelumnya telah membandingkan beberapa algoritms  klasifikasi, seperti membandingkan algoritma  SVM dengan algoritma NB  yang dilakukan pada penelitian dengan judul Sentiment Analysis Article News Coordinator Minister Of Maritime Affairs Using Algorithm Naive Bayes And Support Vector Machine With Particle Swarm Optimization , yang membandingkan algoritma NB, NB (PS O), SVM dan SVM (PSO)  mendapatkan hasil a kurasi NB (PSO) memiliki  akurasi yang lebih tinggi dibandingkan dengan SVM, SVM (PSO) dan NB , dan optimisasi terbaik adalah PSO berbasis NB [17]. Penelitian lain yang dilakukan dengan judul Sentimen Analisis Operasi Tangkap Tangan KPK Menurut Masyarakat Menggunakan Algoritma Support 
Vector Machine, Naive Bayes Berbasis Particle Swarm Optimizition , menyimpulkan bahwa metode PSO untuk SVM (PSO) menghasilkan akurasi 83.79% dan AUC 0.910 adalah yang paling tinggi dibandingkan algoritma NB, NB (PSO), dan SVM [22]. Dengan adanya perbedaan beberapa penelitian sebelumnya, mendorong penulis untuk melakukan penelitian dengan membandingkan beberapa metode klasifikasi dengan kasus yang berbeda. Di dalam penelitian ini, akan d ibahas tahapan yang dilalui untuk melakukan proses analisis sentimen terhadap komentar tentang aplikasi Ruang Guru pada media sosial  Twitter. Dimulai dari tahap preprocessing  sampai tahap analisis dengan NB SVM, K-NN, dan feature selection PSO se rta mengukur kualitas hasil analisis algoritma tersebut tanpa feature selection  dan menggunakan feature selection.  
2. Bahan dan Metode  
Penelitian ini menggunakan data yang bersumber dari komentar berbahasa Indonesia pada media sosial Twitter mengenai  aplikasi Ruang Guru.  Metode pada penelitian ini diadopsi dari  model  Cross -Industry Standard Process for Data Mining  (CRISP -DM). Kerangka berpikir penelitian ini sebagaimana dapat dilihat pada gambar 1  berikut. Gambar 1.   Kerangka berpikir dalam penelitian   
Langkah-langkah kerangka berpikir yang diadopsi dari Cross -Industry Standard Process for Data Mining  (CRISP-DM)  adalah  sebagai berikut [23]: 
1)  Business Understanding  Proses memahami objek penelitian yang akan dilakukan untuk menghasilkan hasil sesuai dengan yang diharapakan. Pemahaman terhadap objek penelitian dapat dilakukan dengan mencari mencari dan menggali informasi dari sumber objek.  
2) Data Understanding  
Proses yang dilakukan pada tahap ini yaitu pengambilan data mentah yang dilakukan sesuai objek penelitian dengan atribut yang diperlukan Data di peroleh dari media sosial twitter dari tanggal 02 April 2020 hingga 03 April 2020 dengan dengan kata kunci â€œRuang Guruâ€ dan filter  bahasa yang digunakan adalah Bahasa Indonesia. Setelah data diperoleh , kemudian dilakukan proses pembersihan  data (data cleaning ). Data yang diperoleh dari hasil  data cleaning  tersebut 
akan digunakan sebagai bahan penelitian.  
3) Data Preparation  (Preprocessing)  
Data preparation  dilakukan sebelum dataset  dimasukkan kedalam model. Proses tersebut meliputi beberapa tahap, yaitu: 
(1) transform case  untuk mengubah huruf pada text menjadi huruf kecil semua guna menyeragamkan bentuk huruf , 
(2) remove  http untuk menghapus  tautan yang  terdapat di dalam tweet , 
(3) remove  @ untuk menghapus  mention  di dalam 
tweet, 
(4) tokenize  untuk memisahkan kata -kata pad a 
setiap kalimat menjadi kata tersendiri  sekaligus 
menghapus karakter yang tidak diperlukan , 
(5) Filter tokens by length  untuk menghapus kata dengan jumlah 
karakter yang kurang dari nilai yang ditentukan , dalam 
hal ini 4 karakter , dan 
(6)  remove stopwords  untuk  menghapus  kata-kata yang dapat diabaikan , biasanya berupa kata keterangan dan kata sambung , dalam hal ini digunakan kamus stopwords  Bahasa Indonesia.  Alur kerja data preparation  dapat dilihat pada gambar 2 berikut.  
Gambar 2.   Alur proses Data Preparation  (Preprocessing ) 
4) Modelling  
Proses  ini dilakukan menggunakan metode 10-fold cross validation , yaitu metode  membagi dataset  menjadi 10 bagian yang mana 1 bagian diantaranya  menjadi data uji (testing) sedangkan bagian  lainnya menjadi data latih ( training ). Kemudian data tersebut dimasukkan ke  dalam model algoritma yang diuji yaitu NB, SVM, K -NN. Hal ini dilakukan bergantian pada setiap bagian data hingga  didapatkan  nilai terbaik dari model tersebut. Alur proses  10-fold cross validation  dapat dilihat pada gambar 3 berikut.  
Gambar 3.   Alur proses 10-fold cross validation  
5) Evaluation  
Tahap ini melakukan proses evaluasi terhadap hasil dari pemodelan  dengan m embandingkan hasil dari pemodelan yang berupa accuracy, precision, recall  dan AUC antara model yang menggunakan feature selection PSO dengan model yang tidak menggunakan selection PSO.  Tingkat akurasi dan ROC Curve  dari masing -masing algoritma diklasifikasikan berdasarkan nilai AUC sebagai  berikut: 0,90 -1,00 = sangat baik. 0,80 -0,90 = baik. 0,70-0,80 = cukup. 0,60 -0,70 = buruk. 0,50 -0,60 = gagal [17]. 

3. Hasil dan Pembahasan  
Langkah -langkah yang diterapkan dalam penelitian ini terdiri dari beberapa proses, antara lain:  
1) Business Understanding  
Pada penelitian ini sumber informasi yang digunakan yaitu media sosial Twitter . Penelitian dilakukan untuk  menggali informasi mengenai analisis sentimen  mengenai aplikasi  Ruang Guru  berdasarkan data Twitter tersebut . 
2) Data Understanding  
Pengambilan data Twitter dilakukan menggunakan aplikasi RapidMiner Studio Educational  9.6 dengan query â€œRuang Guruâ€  dan parameter -parameter sesuai dengan yang sudah disebutkan di dalam metodologi, kemu dian data tersebut  di-export  ke dalam format  file 
Microsoft Excel. Data yang diperoleh sebanyak 568 tweet . Data tersebut  kemudian dilakukan pembersihan (data cleaning)  untuk menghilangkan duplikasi data . Data bersih yang diperoleh dari hasil data cleaning  sebanyak 513 tweet , yang terdiri dari 338 tweet positif 
dan 175 tweet negatif.   
3) Data Preparation  (Preprocessing)  
Proses data preparation  dilakukan terhadap data 513 tweet tersebut  dalam 6 tahapan, sebagaimana disebutkan dalam metodologi,  menggunakan RapidMiner Studio Educational  9.6 dengan contoh hasil dapat dilihat pada tabel 1 sampai dengan tabel 6 berikut.  
Tabel 1.  Hasil dari Transform Case  
Text Transform Case  
@octania_: Udah pake dunks dari DULU sebelum ada wabahÂ²an' Bagus kook .. Ruang Guru jg bagus, gA NJELIMET juga meski kadang buat KIDDONYA aku agak susah paham bahasanya ??  REKOMEN BANGET BUAT YANG PUNYA ANAKÂ² BELAJAR DIRUMAH  ???? 
https://t.co/BJWPgLCfa4  
@octania_: udah pake dunks dari dulu sebelum ada wabahÂ²an' bagus kook .. ruang guru jg bagus, ga njelimet juga meski kadang buat kiddonya aku agak susah paham bahasanya ??  rekomen banget buat yang punya anakÂ² belajar dirumah ???? https://t.co/bjwpglcfa4   
Tabel 2.  Hasil dari Remove  HTTP  
Text Hasil Remove HTTP  
@octania_: udah pake dunks dari dulu sebelum ada wabahÂ²an' bagus kook .. ruang guru jg bagus, ga njelimet juga meski kadang buat kiddonya aku agak susah paham bahasanya ??  rekomen banget buat yang punya anakÂ² belajar dirumah ???? https://t.co/bjwpglcfa4  @octania_: udah pake dunks dari dulu sebelum ada wabahÂ²an' bagus kook .. ruang guru jg bagus, ga njelimet juga meski kadang kiddonya 
aku agak susah paham bahasanya ??  rekomen banget buat yang punya anakÂ² belajar dirumah ????  
Tabel 3.  Hasil dari Remove  @ Text Hasil Remove @  
@octania_: udah pake dunks dari dulu sebelum ada wabahÂ²an' bagus kook .. ruang guru jg bagus, ga njelimet juga meski kadang buat kiddonya aku agak susah paham bahasanya ??  rekomen banget buat yang punya anakÂ² belajar dirumah ????  
udah pake dunks dari dulu sebelum ada wabahÂ²an' bagus kook .. ruang guru jg bagus, ga njelimet juga meski kadang buat kiddonya aku agak susah paham bahasanya ??  rekomen banget buat yang  punya anakÂ² belajar dirumah ????  
Tabel 4.  Hasil dari Tokenize  
Text Hasil Tokenize  udah pake dunks dari dulu sebelum ada wabahÂ²an' bagus kook .. ruang guru jg bagus, ga udah  pake  dunks  dari njelimet juga meski kadang buat kiddonya aku agak susah paham 
bahasanya ??  rekomen banget buat yang punya anakÂ² belajar dirumah ????  dulu sebelum  wabah an bagus  kook  ruang  guru jg ga njelimet  juga meski  kadang  buat kiddonya  aku agak  susah  paham  bahasanya  rekomen  banget  yang  punya  anak  belajar  dirumah   
Tabel 5. Hasil dari Filter by Length  
Text Hasil Filter by Length  
udah  pake  dunks  dari dulu sebelum  ada wabah  an bagus  kook  ruang  guru jg bagus  ga njelimet  juga meski  kadang  buat kiddonya  aku agak  susah  paham  bahasanya  rekomen  udah  pake  dunks  dari dulu sebelum  wabah  bagus  kook  ruang  guru njelimet  juga meski  kadang  buat kiddonya  agak  susah  paham  bahasanya  rekomen  banget  yang  punya  banget  buat yang  punya  anak  belajar  dirumah   
Tabel 6.  Hasil dari Remove Stopwords  
Text Hasil Remove Stopwords  
udah  pake  dunks  dari dulu sebelum  wabah  bagus  kook  ruang  guru bagus  njelimet  juga meski  kadang  buat kiddonya  agak  susah  paham  bahasanya  rekomen  banget  buat yang  punya  anak  belajar  dirumah  udah  pake  dunks  wabah  bagus  kook  ruang  guru njelimet  kadang  kiddonya  susah  paham  bahasanya  rekomen  banget  anak  belajar  dirumah   
4) Modelling  
Pada tahap ini melibatkan teknik data mining  dengan algoritma klasifikasi menggunakan  RapidMiner Studio Educational  9.6. Hasil pengujian model yang dilakukan adalah mengklasifikasi tweet positif dan tweet negatif menggunakan algoritma NB, SVM, KNN dan feature selection  PSO.  Pertama, dilakukan perbandingan algoritma algoritma NB, SVM, dan KNN tanpa feature selection PSO. Desain model tersebut pada aplikasi yang digunakan dapat dilihat pada Gambar 4. Pada gambar tersebut dapat dijelaskan bahwa bahwa data yan g berhasil diperoleh telah  disimpan dalam sebuah file Microsoft Excel  yang akan dibaca oleh operator Read Excel . Sebelum diproses lebih lanjut, terhadap data tersebut  dilakukan operasi  SMOTE Upsampling  untuk menyeimbangkan kelas data dengan menambah jumlah data kelas minor agar setara dengan kelas mayor.  
Gambar 4.   Desain model perbandingan  NB, SVM, dan K -NN 
Setelah data diseimbangkan, selanjutnya dilakukan operasi Process Document . Proses ini adalah tahap data preparation yang di dalamnya  terdiri dari operator  transform cases,  remove http, remove @,  tokenize, filter tokens by length, dan Stopword Filter , sebagaimana dapat dilihat pada Gambar  5 berikut .  
Gambar 5.   Proses dokumen  
Selanjutnya, hasil proses tersebut digandakan menggunakan operator Multiply  agar dapat digunakan dalam 3 algoritma pemodelan. Masing -masing pemodelan dilakukan menggunakan metode  10 fold cross validation  dengan  operator Cross Validation  sebagaimana dapat dilihat pada gambar 6 (SVM), gambar 7 (NB), dan gambar 8 (K -NN). 
Gambar 6.   Proses didalam Cross Validation -SVM  
Gambar 7.   Proses didalam Cross Validation -NB 
Gambar 8.   Proses didalam Cross Validation -K-NN Berikutnya, dilakukan perbandingan algoritma NB, SVM, K -NN yang menggunakan feature selection  PSO. Proses diawali dengan membaca data dari file 
dengan operator read Excel  hingga penggandaan data dengan operator Multiply , memiliki proses yang sama seperti model desain sebelumnya. Sementara operator  PSO ditempatkan setelah operator Multiply  sebagaimana dapat dilihat pada gambar 9 berikut . 
Gambar 9.   Desain Model Perbandingan  NB (PSO), SVM (PSO), dan K -NN (PSO) 
Setelah dilakukan feature selection PSO, langkah selanjutnya adalah menjalankan masing-masing algoritma pemodelan menggunakan metode 10 fold cross validation  dengan operator Cross Validation  
sebagaimana proses sebelumnya pada gambar 6, gambar 7, dan gambar 8.   
5) Evaluation  
Tahap evaluasi bertujuan untuk menentukan nilai kegunaan model yang telah berhasil dibuat pada langkah sebelumnya. Metode evaluasi yang digunakan dalam penelitian ini adalah metode 10-fold cross validation . Tingkat akurasi dan ROC Curve  dari masing -masing algoritma  diklasifikasikan berdasarkan nilai AUC sebagai  berikut : 0,90-1,00 = sangat baik. 0,80-0,90 = baik. 0,70 -0,80 = cukup . 0,60 -0,70 = buruk. 0,50 -0,60 = gagal . Hasil pengujian akurasi dari algoritma  NB, SVM, K-NN tanpa menggunakan feature selection  PSO dapat dilihat pada gambar 10 sampai dengan gambar 12 berikut.  
Gambar 10.   Tingkat  accuracy algoritma NB  
Gambar 11.  Tingkat accuracy  algoritma SVM  
Gambar 12.   Tingkat accuracy  algoritma KNN  
Hasil pengujian performa dalam bentuk ROC Curve  dari algoritma  NB, SVM, K -NN tanpa menggunakan feature selection  PSO dapat dilihat pada gambar 13 sampai dengan gambar 15 berikut.   
Gambar 13.   ROC Curve  algoritma NB    
Gambar 14.   ROC Curve  algoritma SVM    
Gambar 15.   ROC Curve  algoritma KNN   
Dengan demikian, hasil akurasi dan nilai AUC dari algoritma  NB, SVM, K-NN tanpa menggunakan feature selection  PSO dapat dilihat pada tabel 7 berikut.  
Tabel 7. Akurasi dan AUC algoritma NB, SVM, dan K-NN tanpa PSO  
Algoritma  Accuracy  AUC  Klasifikasi  
SVM  76,93%  0,849  Baik  
NB 65,40%  0,451  Gagal  
K-NN 70,42%  0,787  Cukup  
Berdasarkan hasil tersebut, dapat diketahui bahwa tanpa menggunakan feature selection PSO, algoritma SVM memiliki performa yang terbaik jika dibandingkan algoritma NB dan K-NN dalam penelitian ini. Hasil pengujian akurasi dari algoritma  NB, SVM, K-NN dengan menggunakan feature selection  PSO dapat dilihat pada gambar 16 sampai dengan gambar 18 berikut.  
Gambar 16.   Tingkat accuracy  algoritma NB (PSO)  
Gambar 17.   Tingkat accuracy  algoritma SVM (PSO) 
Gambar 18.   Tingkat accuracy  algoritma KNN (PSO)  
Hasil pengujian performa dalam bentuk ROC Curve  dari algoritma  NB, SVM, K -NN tanpa menggunakan feature selection  PSO dapat dilihat pada gambar 19 sampai dengan gambar 21 berikut.  
Gambar 19.   ROC Curve  algoritma NB (PSO)  
Gambar 20.  ROC Curve  algoritma SVM (PSO) 
Dengan demikian, hasil akurasi dan nilai AUC dari algoritma  NB, SVM, K-NN dengan menggunakan feature selection  PSO dapat dilihat pada tabel 8 berikut.  
Tabel 8. Akurasi dan AUC algoritma NB, SVM, dan K-NN menggunakan  PSO 
Algoritma  Accuracy  AUC  Klasifikasi  
SVM  (PSO)  78,55%  0,853  Baik  
NB (PSO)  67,32%  0,463  Gagal  
K-NN (PSO)  77,21%  0,831  Baik  
Berdasarkan hasil tersebut, dapat diketahui bahwa jika menggunakan feature selection PSO, maka algoritma SVM memiliki performa yang terbaik jika dibandingkan algoritma NB dan K-NN dalam penelitian ini.  
 
4. Kesimpulan  
Berdasarkan penelitian  yang telah dilakukan maka  dapat disimpulkan bahwa penggunaan feature selection PSO dalam algoritma klasifikasi dapat meningkatkan performa dan akurasinya. Hasil dari pengujian secara keseluruhan algoritma SVM (PSO) memiliki nilai akurasi dan performa yang paling tinggi jika dibandingkan dengan NB, SVM, K -NN, NB (PSO), SVM (PSO), dan K-NN (PSO). Sedangkan algoritma NB, tanpa PSO maupun dengan PSO, mendapatkan nilai UAC dengan klsifikasi gagal. Dalam penelitian ini s umber data yang digunakan  hanya dari satu sumber media sosial , yaitu Twitter. Hal ini dapat menjadi  rujukan dalam  peneliti an berikutnya dengan menggunakan sumber data yang berbeda .  

Daftar Pustaka  
[1] M. A. Bora, â€œAnalisa Kepuasan Penggunaan E-Learning Cloud Sekolah Tinggi Teknik ( STT ) Ibnu Sina Batam,â€ vol. 1, no. 1, pp. 55â€“62, 2017.  
[2] RuangGuru, â€œTentang Ruangguru.â€ https://ruangguru.com/general/about (accessed May 08, 2020).  
[3] N. D. Putranti and E. Winarko, â€œAnalisis Sentimen Twitter untuk Teks Berbahasa Indonesia dengan Maximum Entropy dan Support Vector Machine,â€ v ol. 8, no. 1, pp. 91 â€“100, 2014.  
[4] G. A. Buntoro, â€œAnalisis Sentimen Calon Gubernur DKI Jakarta 2017 Di Twitter,â€ vol. 2, no. 1, pp. 32 â€“41, 2017.  
[5] F. Nurhuda and S. W. Sihwi, â€œAnalisis Sentimen Masyarakat terhadap Calon Presiden Indonesia 2014 berdasar kan Opini dari Twitter Menggunakan Metode Naive Bayes Classifier,â€ vol. 2, no. 2, 2014.  
[6] A. Novantirani et al. , â€œAnalisis Sentimen pada Twitter untuk Mengenai Penggunaan Transportasi Umum Darat Dalam Kota dengan Metode Support Vector Machine,â€ vol. 2, n o. 1, pp. 1177 â€“1183, 
 2015.  
[7] S. A. Saputra, D. Rosiyadi, W. Gata, and S. M. Husain, â€œAnalisis Sentimen E -Wallet Pada Google Play Menggunakan Algoritma Naive 
Bayes Berbasis Particle Swarm Optimization,â€ J. RESTI , vol. 1, no. 10, pp. 3 â€“8, 2021.  
[8] D. D. S aputra et al. , â€œOptimization Sentiments of Analysis from Tweets in myXLCare using NaÃ¯ve Bayes Algorithm and Synthetic Minority Over Sampling Technique Method,â€ J. Phys. Conf. Ser. , 2020, doi: 10.1088/1742 -6596/1471/1/012014.  
[9] D. A. Kristiyanti, A. H. Um am, M. Wahyudi, R. Amin, and L.Marlinda, â€œComparison of SVM & NaÃ¯ve Bayes Algorithm for Sentiment Analysis Toward West Java Governor Candidate Period 2018 -2023 Based on Public Opinion on Twitter,â€ Int. Conf. Cyber IT Serv.Manag. , no. Citsm, pp. 1â€“6, 2018 , doi: 10.1109/CITSM.2018.8674352.  
[10] L. N. Pradany and C. Fatichah, â€œAnalisa Sentimen Kebijakan Pemerintah Pada Konten Twitter Berbahasa Indonesia Menggunakan Svm Dan K-Medoid Clustering,â€ SCAN -Jurnal Teknol. Inf. dan Komun. , vol. 11, no. 1, pp. 59 â€“66, 2016.  
[11] N. Y. A. Faradhillah, R. P. Kusumawardani, and I. Hafidz, â€œEksperimen Sistem Klasifikasi Analisa Sentimen Twitter pada Akun Resmi Pemerintah Kota Surabaya Berbasis Pembelajaran Mesin,â€ 
Pros. Semin. Nas. Sist. Inf. Indones. 2016 , pp. 15 â€“24, 2016.  
[12] M. W.  & N. N. Dwi Arum Ningtyas, â€œKlasifikasi Siswa Smk Berpotensi Putus Sekolah Menggunakan Algoritma Decision Tree , Support Vector Machine Dan Naive Bayes,â€ J. Khatulistiwa Inform. , vol. VII, no. 2, pp. 85 â€“90, 2019.  
[13] O. S. S. S. E. Syahfitri Kartika Lidy a, â€œSentiment Analysis Pada Teks Bahasa Indonesia Menggunakan Support Vector Machine (SVM) Dan K -Nearest Neighbor (K -NN),â€ Semin. Nas. Teknol. Inf. dan Komun. , vol. 2015, no. Sentika, pp. 1 â€“8, 2015.  
[14] S. W. Yudha and M. Wahyudi, â€œKomparasi Algoritma Kla sifikasi Untuk Analisis Sentimen Review Film Berbahasa Asing,â€ in Seminar Nasional Informatika, Sistem Informasi Dan Keamanan Siber (SEINASI -KESI) , 2018, pp. 180 â€“185. 
[15] M. A. Assuja and S. Saniati, â€œAnalisis Sentimen Tweet Menggunakan Backpropagation Neural Network,â€ J. Teknoinfo , vol. 10, no. 2, p. 48, 2016, doi: 10.33365/jti.v10i2.20.  
[16] X. Wu et al. , Top 10 algorithms in data mining , vol. 14, no. 1. 2008.  
[17] N. K. Wardhani et al. , â€œSentiment analysis article news coordinator minister of maritime affairs using algorithm naive bayes and support vector machine with particle swarm optimization,â€ J. Theor. Appl. Inf. Technol. , vol. 96, no. 24, pp. 8365 â€“8378, 2018.  
[18] M. A. Maulana, A. Setyanto, and M. P. Kurniawan, â€œAnalisis Sentimen Media Sosial Universitas Amikom,â€ Semin. Nas. Teknol. Inf. dan Multimed. 2018 Univ. AMIKOM Yogyakarta, 10 Februari 2018 , pp. 7 â€“12, 2018.  
[19] E. Indrayuni, â€œAnalisa Sentimen Review Hotel Menggunakan Algoritma Support Vector Machine Berbasis Particle Swarm Optimization Elly,â€ J. Evolusi Vol. , vol. 4, 2016.  
[20] W. E. Nurjanah, R. S. Perdana, and M. A. Fauzi, â€œAnalisis Sentimen Terhadap Tayangan Televisi Berdasarkan Opini Masyarakat pada Media Sosial Twitter menggunakan Metode K-Nearest Neighbor dan Pembobotan Jumlah Retweet, â€ vol. 1, no. 12, pp. 1750 â€“1757, 2017.  
[21] L. A. Utami, â€œMelalui Komparasi Algoritma Support Vector Machine Dan K-Nearest Neighbor Berbasis Particle Swarm Optimization,â€ vol. 13, no. 1, pp. 103 â€“112, 2017.  
[22] Hernawati and W. Gata, â€œSentimen Analisis Operasi Tangkap Tangan KPK Menurut Masyarakat Menggunakan Algoritma Support 
Vector Machine , Naive Bayes Berbasis Particle Swarm Optimizition,â€ faktir Exacta , vol. 12, no. 3, pp. 230 â€“243, 2019, doi: 
10.30998/faktorexacta.v12i3.4992.  
[23] I. Santoso, W. Gata, and A. B. Paryanti, â€œPenggunaan Feature Selection di Algoritma Support Vector Machine untuk Sentimen Analisis Komisi Pemilihan Umum,â€ J. RESTI , vol. 3, no. 3, pp. 5 â€“11, 2019.  ",Analisis Sentimen,"Naive Bayes, Support Vector Machine, K-Nearest Neighbour, feature selection",data Twitter,"akurasi, accuracy, precision, recall, AUC"
Penerapan Algoritma K-Nearest Neighbor (K-NN) Untuk Analisis Sentimen Publik Terhadap Pembelajaran Daring  ,"Penerapan Algoritma K-Nearest Neighbor (K-NN) Untuk Analisis Sentimen Publik Terhadap Pembelajaran Daring  

Jepi Supriyanto1, Debby Alita2, Auliya Rahman Isnain3 

Abstrak: 
Penelitian ini dilakukan untuk menerapkan algoritma KNN (K -Nearest Neighbor) dalam melakukan sentimen analisis pengguna Twitter  tentang isu terkait kebijakan pemerintah tentang Pembelajaran Daring. penelitian menggunakan data Tweet  sebanyak 1825 data tweet Bahasa Indonesia data dikumpulkan sejak tanggal 1 Februari 2020 sampai dengan 30 September 2020. Menggunakan library python ya itu Tweepy  .pembobotan kata menggunakan TF -IDF, akan dilakukan klasifikasi nilai sentimen ke dalam dua kelas yaitu positif dan negatif. Setelah dilakukan pengujian dengan K sebanyak 20 didapatkan hasil akurasi tertinggi terdapat Pada saat K = 10 dengan nil ai akurasi 84,65% dengan presisi mencapai 87%, recall  86% f measure  87% serta error rate mencapai 0,12% dan di dapatkan pula kecenderungan opini publik terhadap Pembelajaran Daring Cenderung Positif  

Kata Kunci: Confusion Matrix, Analisis 
 
Abstract:  
This research was conducted to apply the KNN (K -Nearest Neighbor) algorithm in conducting sentiment analysis of Twitter users on issues related to government policies regarding Online Learning. Research using Tweet data as much as 1825 Indonesian tweet 
data data were collected from February 1, 2020 to September 30, 2020. Using the python library, Tweepy. word weighting using TF -IDF, will be classified into two classes of sentiment values, positive and nega tive. After testing with K of 20, the highest accuracy 
results were obtained when K = 10 with an accuracy value of 84.65% with a precision of 87%, a recall of 86% f measure 87% and an error rate of 0.12% and a tendency was also obtained. public opinion on online learning tends to be positive  

Keywords: Confusion Matrix, TF-IDF
 
1. PENDAHULUAN  
Sejak diumumkanya kasus positip Corona  virus (Covid -19) di Indonesia pada tanggal 2 maret 2020, sampai dengan tanggal 31 juli 2020 tercatat total 108.376 kasus dikonfirmasi dengan rincian pasien 
dalam perawatan mencapai 37,338 orang yang tersebar di seluruh rumah sakit yang ada di indonesia, 65,907 pasien yang dinyatakan sembuh dan tercatat kasus meninggal dunia mencapai angka 5,131 
orang . Pandemi global yang terjadi di Indonesia membuat banyak pihak berupaya ikut berperan serta dalam mengatasi. Para dokter umum dan spesialis angkat bicara bersama guna memberi penjelasan singkat kepada masyarakat maupun himbauan agar menjaga kebersihan diri dan lingkungan sekaligus tak banyak keluar rumah [1]. Salah satu dampak pandemi Corona virus ialah terhadap pendidikan di seluruh dunia, yang mengarah kepada penutupan sekolah, madrasah, universitas, dan pondok pesantren, Sehubungan dengan perkembangan tersebut, Kementerian Pendidikan dan Kebudayaan (Kemendikbud) turut mengambil kebijakan sebagai pandua n dalam menghadapi penyakit tersebut di tingkat satuan pendidikan dengan mengadakan pembelajaran jarak jauh menanggapi kebijakan Kementerian Pendidikan dan Kebudayaan, banyak menuai opini-opini dikalangan masyarakat yang mereka tuangkan melalui media sosia l terutama di Twitter Untuk menafsirkan dan memahami opini tersebut, diperlukan algoritma dan program untuk mengolah data informasi dan opini, juga menganalisa 
opini. Sentiment Analisis  atau biasa disebut opinion mining  merupakan salah satu cabang penelitian Text Mining. Opinion mining  adalah riset komputasional dari opini, sentimen  dan emosi yang diekspresikan secara tekstual. Analisis sentimen atau penambangan opini adalah suatu bidang studi untuk menganalisis pendapat  orang terhadap entitas seperti produk, layanan,organisasi, individu, masalah, peristiwa, dan topik. Analisis sentimen ini berfokus pada pendapat seseorang yang mengekspresikan atau menyiratkan sentimen Positif atau negatif, kebanyakan analis sentimen ini berkaitan dengan orang-orang di media sosial Selain polaritas Positif dan negatif, terkadang polaritas juga dianggap sebagai kisaran dimana suatu dokumen dapat berisi penyataan yang memiliki polaritas campuran Mejova, (2009) . TFIDF adalah teknik pengambilan informasi yang membebani term frequency dan dokumen inversnya (IDF). Setiap kata atau istilah memiliki skor TF dan IDF bobot dari istilah disebut sebagai TFIDF. Algoritma TFIDF digunakan untuk menimbang keyword dalam setiap dokumen dan menghitung seberapa banyak kemunculannya dalam setiap dokumen. K-Nearest Neighbor (KNN) adalah salah satu algoritma klasifikasi supervised learning yang digun akan untuk mengkasifikasikan objek berdasarkan atribut kelas dan data training [3]. Konsep dasar dari K -NN adala h mencari jarak terdekat antara data yang akan dievaluasi dengan K tetangga terdekatnya dalam data pelatihan. Penghitungan jarak dilakukan dengan konsep Euclidean.  Jumlah kelas yang paling banyak dengan jarak terdekat tersebut akan menjadi kelas dimana da ta evaluasi tersebut berada Tahapan awal pada KNN ini adalah menentukan nilai K, misal k=3 artinya 3 dokumen terdekat dengan dokumen uji yang akan diambil.  
Berdasarkan refrensi tersebut Penulis pada penelitian ini akan melakukan analisis  sentimen para pengguna Twitter terhadap pembelajaran Daring. Dengan input berupa data tweet dalam Bahasa Indonesia, akan dilakukan klasifikasi dengan algoritma KNN ( K-Nearest  Neighbor ) untuk menentukan apakah tweet tersebut bersentimen Positif, atau negatif.  
 
2. METODE  PENELITIAN  
Dalam melakukan text mining, text  dokumen harus dilakukan persiapan terlebih dahulu sehingga dapat digunakan untuk proses utama. Proses mempersiapkan text atau data mentah ini disebut text preprocessing. Text preprocessing berfungsi mengubah data yang tidak terstruktur menjadi terstruktur  Tu, (2019)  . Proses yang dilakukan dalam preprocessing adalah sebagai berikut :  
a. Case folding , merupakan proses merubah kalimat data teks men jadi seragam  
b. Cleansing,  yaitu proses membersihkan dokumen dan menyeleksi kata yang tidak diperlukan seperti html, emoticon, hashtag, mention dan url.  
c. Stopwords,  yaitu menghilangkan kata yang kurang efektif  
d. Steaming,  yaitu proses untuk menyaring kata yang terdapat kata sambung, kata ganti, kata depan, menjadi kata dasar dengan menghilangkan awalan atau akhiran.  
e. Tokenization,  merupakan proses seleksi pemotongan kata dalam kalimat. Diberikan pemisah seperti tanda koma (,), titik (.), dan tanda pemisah lainnya.    
Kegiatan penelitian merupakan suatu proses memperoleh atau mendapatkan suatu pengetahuan atau memecahkan permasalahan yang dihadapi, yang dilakukan secara ilmiah, sistematis dan logis [5]â€“[7]. Dalam penelitian di bidang apapun, tahapan -tahapan itu pada umumnya memiliki kesamaan, walaupun ada beberapa hal sering terjadi pemodifikasian dalam pelaksanaannya oleh peneliti sesuai dengan kondisi dan situasi yang dihadapi tanpa mengabaikan prinsip-prinsip umum yang digunakan dalam proses penelitian [8]â€“[11]. Tahapan penelitian yang dilakukan dapat dilihat pada Gambar 1 berikut.   
Gambar 1. Tahapan Penelitian  

3. HASIL  DAN  PEMBAHASAN  
Contoh dari tahap pngambilan data dari twitter di hasilkan data sebagai berikut :  
Tabel 1. Data tweet  
No  Tweet  
1 partai Golkar dan Demokrat akan Bertanding pada saat  kampanye 2009  
2 Pertandingan pertama antara Persema vs Persebaya malang  
3 Sangat besar hapan wasit saay tanding sepakbola dpt berlaku adil  
4 partai demokrat menang 2019 krna ada figur sby  
5 Pertandingan sepakbola persebaya pada kampanye pemilu 2009 akan ditunda  
Setelah melawati tahapan preprocessing , akan di dapat data sebagai berikut :  
Tabel 2. Hasil Tahapan Preprocessing  
No Tweet  Hasil Sentimen  
1 partai Golkar dan Demokrat akan 
Bertanding pada saat kampanye 2009  partai golkar demokrat tanding kampanye 2009 Negatif  
2 Pertandingan pertama antara Persema vs Persebaya malang  tanding pertama persema persebaya malang  positif  
3 Sangat besar hapan wasit saay tanding sepakbola dpt berlaku adil  besar wasit tanding sepakbola adil  positif  
4 partai demokrat menang 2019 krna ada figur sby  partai demokrat menang 2019 figur sby negatif  
5 Pertandingan sepakbola persebaya pada kampanye pemilu 2009 akan ditunda  tanding sepakbola persebaya kampanye pemilu 2009 tunda  ? 
Selanjutnya setelah mendapatkan data yang sudah melalui tahap preprocessing akan dihitung bobotnya dengan TF -IDF berikut hasilnya :  
Tabel 3. Hasil Perhitungan TF -IDF 
tf idf wdt=tf.idf  
term D1 D2 D3 D4 D5 DF log(n/dff)  D1 D2 D3 D4 D5 
partai  1     1   2 0,39794  0,39794  0 0 0,39794  0 
golkar  1         1 0,69897  0,69897  0 0 0 0 
demokrat  1     1   2 0,39794  0,39794  0 0 0,39794  0 
tanding  1 1 1   1 4 0,09691  0,09691  0,09691  0,09691  0 0,09691  
kampanye  1       1 2 0,39794  0,39794  0 0 0 0,39794  
2009 1     1 1 3 0,22185  0,221849  0 0 0,221849  0,221849  
pertama    1       1 0,69897  0 0,69897  0 0 0 
persema    1       1 0,69897  0 0,69897  0 0 0 
persebaya    1     1 2 0,39794  0 0,39794  0 0 0,39794  
malang    1       1 0,69897  0 0,69897  0 0 0 
besar      1     1 0,69897  0 0 0,69897  0 0 
wasit     1     1 0,69897  0 0 0,69897  0 0 
sepakbola      1   1 2 0,39794  0 0 0,39794  0 0,39794  
adil     1     1 0,69897  0 0 0,69897  0 0 
menang        1   1 0,69897  0 0 0 0,69897  0 
pemilu        1 1 2 0,39794  0 0 0 0,39794  0,39794  
figur       1   1 0,69897  0 0 0 0,69897  0 
sby       1   1 0,69897  0 0 0 0,69897  0 
tunda          1 1 0,69897  0 0 0 0 0,69897  
Selanjutnya adalah menghitung kemiripan antar dokumen dengan menggunakan perhitungan cosine similarity  karena yang akan dicari adalah nilai sentimen dari data tweet terakhir, maka data tweet (D5) 
dihitung similaritynya  dengan semua data yang ada hasilnya a dalah sebagai berikut.  
Tabel 4. Hasil Perhitungan TF -IDF Lanjutan  
wd5*wdi  
D1 D2 D3 D4 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0,009391551  0,009392  0,0093916  0 
0,158356251  0 0 0 
0,049216868  0 0 0,049217  
0 0 0 0 
0 0 0 0 
0 0,158356  0 0 
0 0 0 0 
0 0 0 0 
0 0 0 0 
0 0 0,1583563  0 
0 0 0 0 
0 0 0 0 
0 0 0 0,158356  
0 0 0 0 
0 0 0 0 
0 0 0 0 
0,21696  0,16775  0,16775  0,20757   
Langkah selanjutnya hitung panjang setiap dokumen termasuk D5 dengan cara Kuadradkan bobot setiap term dalam setiap dokumen, jumlahkan nilai kuadrad tersebut dan kemudian akarkan hasil dari 
dokumen yang sudah di kuadradkan seperti contoh pada tabel dibawah ini.  
Tabel 5. Hasil Perhitungan TF -IDF Lanjutan  
Panjang Vektor  
D1 D2 D3 D4 D5 
0,158356  0 0 0,158356  0 
0,488559  0 0 0 0 
0,158356  0 0 0,158356  0 
0,009392  0,009392  0,009392  0 0,009392  
0,158356  0 0 0 0,158356  
0,049217  0 0 0,049217  0,049217  
0 0,488559  0 0 0 
0 0,488559  0 0 0 
0 0,158356  0 0 0,158356  
0 0,488559  0 0 0 
0 0 0,488559  0 0 
0 0 0,488559  0 0 
0 0 0,158356  0 0,158356  
0 0 0,488559  0 0 
0 0 0 0,488559  0 
0 0 0 0,158356  0,158356  
0 0 0 0,488559  0 
0 0 0 0,488559  0 
0 0 0 0 0,488559  
1,022236  1,633425  1,633425  1,989963  1,180592  
1,01106  1,27806  1,27806  1,41066  1,08655  
Lalu langkah selanjutnya mencari kemiripan antar dokumen, hitung kemiripan D1 Dengan D5, D2 dengan D5, D3 dengan D5 dan D4 dengan D5 sebagai berikut :  
Tabel 6. Menghitung Kemiripan Dokumen  
Dokumen  Rumus  Hasil 
COS(D5,D1)  0,26196/(1,08655*1,01106)  0,1975  
COS(D5,D2)  0,16775/(1,08655*1,27806)  0,1208  
COS(D5,D3)  0,16775/(1,08655*1,27806)  0,1208  
COS(D5,D4)  0,20757/(1,08655*1,41066)  0,13542  
Lalu hasil pada Tabel 6 Diatas diurutkan berdasarkan jarak dengan nilai terbesar ke terkecil, sehingga dapat dilihat pada Tabel 7:  
Tabel 7. Menghitung Kemiripan Dokumen lanjutan  
D1 D2 D3 D4 
0,1975  0,1208  0,1208  0,13542   
Lalu hasil pada tabel 6 Diatas diurutkan berdasarkan jarak dengan  nilai terbesar ke terkecil, sehingga 
menjadi :  
Tabel 8. Urutan jarak dari dokumen  
1 2 3 4 
D1 D4 D2 D3 
0,1975  0,13542  0,1208  0,1208  
Langkah selanjutnya menetukan kelas dari D5 dengan mengambil dari K senbanyak K (K=3) yang paling tinggi tingkat kemiripanya dengan D1 maka hasilnya sebagai berikut  
Tabel  9. Menentukan Kelas dari D1  
D1 D4 D2 
Negatif  Negatif  Positip  
Pilih kelas yang paling banyak kemunculanya. Untuk K=3 :  Kelas positip, diwakili oleh 2 dokumen yaitu D1 dan D4.  Kelas negatif, hanya diwakili oleh D2.  Kesimpulan D5 terklarifikasi ke Kelas Negatif. Dari hasil pengujian perbandingan antara tweet yang di tuliskan oleh masyarakat terkait Pembelajaran daring yaitu  tweet yang bersifat positif memiliki presentase mencapai 56,24% sedangkan tweet yang bersifat negatif 43,76% dengan total data 1825, dan perbandingan kelas positif mencapai angka 1039 sedangkan kelas negatif mencapai 806 data.  
Gambar 2.  Persentase Perbandingan Kelas Negatif Dan Positif  
Berdasarkan penelitian yang telah dilakukan, dapat diketahui bahwa sebanyak 56,24% tweet positif sedangkan tweet yang bersifat negatif 43,76% dengan total data 1825.  Hasil pengujian menggunakan confusion matri x dapat dilihat pada tabel 10 berikut ini.  
Tabel 10. Hasil Pengujian Sistem Dengan Confusion  Matrix  
Pengujian  Hasil 
Accuration  85% 
Precision  87% 
Recall  86% 
F measure  87% 
Error Rate  0.12%  
Algoritma K Nearest Neighbor dengan pembobotan kata TF -IDF, dengan jumlah dataset 1825 data. Dataset dibagi menjadi dua data yaitu 80% data training dan 20% data testing, menghasilkan tingkat akurasi sebesar yang sebesar 84,93% pada pengujian K=10. Sedangkan presisi mencapai 87%, recall 87%, f measure  87% serta memiliki erorr rate 0,12%.  

4. KESIMPULAN  
Dari hasil pengujian perbandingan antara tweet yang di tuliskan oleh masyarakat terkait Pembelajaran daring yaitu tweet yang bersifat positif memiliki presentase mencapai 56,24% sedangkan tweet yang bersifat negatif 43,76% dengan total data 1825, dan perbandingan kelas positif mencapai angka 1039 sedangkan kelas negatif mencapai 806 data.  Hasil pengujian menggunankan confusion 
matrix dari Algoritma K Nearest Neighbor dengan pembobotan kata TF-IDF, dengan jumlah dataset 1825 data. Dataset dibagi menjadi dua data yaitu 80% data training dan 20% data testing, menghasilkan tingkat akurasi sebesar yang sebesar 84,93% pada pengujian K=10. Sedangkan presisi mencapai 87%, recall 87%, f measure  87% serta memiliki erorr rate 0,12%.  
 
5. REFERENCES  
[1] A. P. Opute, B. O. Irene, and C. G. Iwu, â€œTourism service and digital technologies: A value creation perspective,â€ African J. Hosp. Tour. Leis. , 2020.  
[2] Y. Mejova, â€œSentiment Analysisâ€¯: An Overview Comprehensive Exam Paper,â€ Science (80 -. )., 2009.  
[3] B. Trstenjak, S. Mikac, and D. Donko, â€œKNN with TF -IDF based framework for text categorization,â€ Procedia Eng., vol. 69, pp. 1356 â€“1364, 2014.  
[4] Y. Tu, â€œMachine learning,â€ in EEG Signal Processing and Feature Extraction , 2019. doi: 10.1007/978 -981-13-9113-2_15.  
[5] P. Lestari, D. Darwis, and D. Damayanti, â€œKomparasi Metode Ecomomic Order Quantity Dan Just In Time Terhadap Efisiensi Biaya Persediaan,â€ J. Akunt. , vol. 7, no. 1, pp. 30 â€“44, 2019.  
[6] D. A. Megawaty and D. Santia, â€œAssessment of The Alignment Maturity Level of Business and Information Technology at CV Jaya Technology,â€ in 2019 International Conference on Computer Science, Information Technology, and Electrical Engineering (ICOMITEE) , 2019, pp. 54 â€“58. 
[7] S. Setiawansyah, A. T. Priandika, B. Ulum,  A. D. Putra, and D. A. Megawaty, â€œUMKM Class Determination Support System Using Profile Matching,â€ Bull. Informatics Data Sci. , vol. 1, no. 2, pp. 46 â€“54, 2022.  
[8] A. T. Priandika, â€œSISTEM PENGENDALIAN INTERNAL MONITORING INVENTORY OBAT MENGGUNAKAN SUPPLY  CHAIN MANAGEMENT,â€ J. Ilm. BETRIK Besemah Teknol. Inf. dan Komput. , vol. 12, no. 1, pp. 36 â€“44, 2021.  
[9] S. A. Widiana, S. Sintaro, R. Arundaa, E. Alfonsius, and D.Lapihu, â€œAplikasi Penjualan Baju Berbasis Web (E-Commerce) dengan Formulasi Penyusunan Kod e,â€ J. Inf. Technol. Softw. Eng. Comput. Sci. , vol. 1, no. 1 SE-Articles, pp. 35 â€“43, Jan. 2023, doi: 10.58602/itsecs.v1i1.11.  
[10] F. Hamidy and I. Yasin, â€œImplementation of Moving Average for Forecasting Inventory Data Using CodeIgniter,â€ J. Data Sci. Inf . Syst. , vol. 1, no. 1, pp. 17 â€“23, 2023.  
[11] M. N. D. Satria, â€œSistem Pendukung Keputusan Penerimaan Staff Administrasi Menggunakan Metode VIKOR,â€ J. Artif. Intell. Technol. Inf. , vol. 1, no. 1, pp. 39 â€“49, 2023.  
",Analisis Sentimen,data tweet berbahasa Indonesia,K-Nearest Neighbor,"akurasi, presisi, recall, f measure, error rate"
Sentimen Analisis Publik Terhadap Joko Widodo Terhadap Wabah Covid-19 Menggunakan Metode Machine Learning ,"Sentimen Analisis Publik Terhadap Joko Widodo Terhadap Wabah Covid-19 Menggunakan Metode Machine Learning 

Sisferi Hikmawan 1, Amsal Pardamean 1, Siti Nur Khasanah 2 

Abstract 
Analyzing public sentiment towards a government policy is no longer impossible, the process of analyzing with data mining is a method that is often used. The Data Mining method is always related to the dataset, with the keywords """"Jokowi"""" and """"Covid"""" twitter allowing us to make tweets in it to be used as a dataset. In data mining for sentiment analysis, techniques such as transform, tokenize, stemming, classification, etc. are very influential on its a ccuracy. Gata Framework is used for preprocessing, and Rapidminer is also used to analyze and compare three classification methods namely Naive Bayes, Support Vector Machine, and k-NN. And the best value is obtained, the Support Vector Machine with an accuracy of 84.58%, precision 82.14% and recall 85.82% .  
 
Keywords : Covid, Jokowi, SVM , K-NN, Naive Bayes 
 
Abstrak 
Menganalisa sentimen publik terhadap suatu kebijakan pemerintah merupakan cara yang tidak lagi mustahil, proses analisa dengan data mining merupakan metode yang sering digunakan. Metode Data Mining selalu berkaitan dengan dataset, dengan kata kunci â€œJokowiâ€  dan â€œCovidâ€ twitter memungkinkan kita menjadikan tweet didalamnya untuk dijadikan dataset. Dalam data 
mining untuk sentimen analisis, dilakukan teknik seperti transform, tokenize, stemming, classification, dan lain-lain sangat berpengaruh pada akurasinya. Gata Framework digunakan untuk preprocessing, dan Rapidminer juga digunakan untuk menganalisa dan memban dingkan tiga metode klasifikasi yaitu Naive Bayes, Support Vector Machine, dan k-NN. Dan di hasilkan nilai terbaik yaitu Support Vector Machine dengan accuracy 84.58%, precision 82.14% dan recall 85.82%.    
 
Kata kunci:  Covid, Jokowi, SVM, K- NN, Naive Bayes 
 
1. Pendahuluan 
Covid-19 menjadi topik yang hangat pada awal 2020. Virus yang bermula dari Wuhan China ini telah menyebar secara cepat ke hampir seluruh dunia. Sejak adanya kasus pertama dengan dua orang positif di Indonesia(Kompas.com, 2020), topik covid-19 in i selalu dibahas dalam berbagai media berita, dan tentu saja media sosial. Joko Widodo sebagai Presiden Republik Indonesia tentu menjadi perhatian masyarakat terutama tentang kebijakan yang  diterapkan dalam penanganan Covid-19 di Indonesia. Salah satu media sosial yang dengan bebas masyarakat menuangkan pendapatnya adalah Twitter. Dalam beberapa tahun ini twitter terakhir, twitter  memberi banyak pengaruh dalam menghasilkan sumber informasi (Muthia et al., 2019). Dalam data mini ng, banyak hal menarik yang dapat digali pada twitter  diantaranya bagaimana opini yang terdapat di masyarakat tentang suatu pemerintah. Seperti kebijakan pemerintah yang  telah dikeluarkan bahkan yang masih dalam wacana terkait Covid-19. Hal ini menjadi s angat penting 
karena dapat menjadi bahan pertimbangan untuk pemerintah dalam menanggapi sikap publik. Tujuan dari penelitian ini adalah mengkasifikasikan sentimen positif, netral dan negatif dari twitter terhadap dua kata kunci yaitu â€œJokowiâ€ dan â€œCovidâ€. Dengan penggunaan dua kata kunci tersebut dapat dihasilkan hasil twit yang fokus hanya pada â€œJokowiâ€ dan â€œ Covidâ€. Dalam pengumpulan data, hingga klasifikasi menggunakan metode Machine Learning  diantaranya adalah menggunakan algoritma Naive, Support Vector Machine dan k-NN serta dengan Pembobotan fitur menggunakan Algoritma Term Frequency Invert Document Frequency  (TF-IDF). 
 
2. Metode Penelitian 
2.1. Pengumpulan Data 
Berikut Diagram Proses Klasifikasi Sentiment Analysis yang akan dibahas dalam penelitian ini:  
Sumber: Hasil Penelitian (2020) 
Gambar 1. Diagram Proses Klasifikasi Sentiment Analysis  Sentimen Analisis Publik Terhadap Joko Widodo Terhadap Wabah Covid-19 Menggunakan Metode Machine Learning  
Dalam penelitian ini hal pertama yang dilakukan adalah pengumpulan data dengan melakukan Web scrapping  dari twitter . Web scrapping  adalah proses yang digunakan untuk 
mengekstraksi data dari situs web yang diinginkan dengan langsung mengakses World Wide Web dengan bantuan HTTP, atau melalui browser web (Jain et al., 2019).  Scrapping web digunakan untuk mengubah data yang tidak terstruktur pada sebuah web menjadi data terstruktur yang dapat disimpan dan dianalisis dalam database atau spreadsheet (S .C.M. de S Sirisuriya, 2015). Dalam penelitian ini, penarikan data menggunakan apli kasi berbasis python yaitu twitscraper (Helmi Satria, 2018). Setelah itu dilakukan pelabelan untuk membuat data training dengan memberi kolom label berisi nilai sentimen â€œpositifâ€, â€œn etralâ€ dan â€œnegatifâ€. Hasil 
keluaran dari proses ini berformat csv agar setelahnya dapat dilakukan preprocessing data. 
Tabel 1. Contoh Dataset Yang Telah Memiliki Label 
Text label  
Tolong diam di rumah..."""" netral 
https://www.obsessionnews.com/covid-19- beri-dampak-terberat-pada -dunia-pariwisata/ 
@jokowi #COVID19indonesia #Covid_19 #COVIDÃ£Æ’Â¼19 #IndonesiaMelawanCovid19 gulung. Biaya hidup Naik. negatif 
[GERAK CEPAT] Anggaran Rp.62,3 Triliun APBN, Menter @KemenkeuR I Sri Mulyani: Siap Dukung Program Prioritas Pemerintah Hadapi Dampak Pandemi Cov id-19 http://infokabinet.id/2020/03/21/gerak-cepat- anggaran -rp-623-triliun- apbn -menkeu-sri-mulyani-siap-dukung- program -prioritas-pemerintah- hadapi -dampak-pandemi-covid-19 positif 
Indonesia pasti bisa kalahkan covid 19 positif 
Sumber: Hasil Penelitian (2020) 
2.2. Preprosessing Data 
Setelah data terekstraksi dari situs web langkah selanjutnya adalah melakukan pembersihan data, diantaranya adalah: 
1. Menghapus tanda baca yang tidak diinginkan dari dataset. 
2. Menghapus Stop-words  atau kata umum yang tidak memiliki makna seperti angka, kata yang / di / ke.  
3. Menghapus link url dan tanda baca seperti (@, :, //) dan tanda baca lainnya. 
4. Menyeragamkan huruf besar dan kecil ( lowercase, uppercase ) 
5. Pada tahapan ini dilakukan penyeragaman seluruh teks menjadi huruf kecil ( lowercase ) dan pembersihan atau penghapusan pada pada semua dokumen yang berisi angka, url (http://), username  (@), tanda pagar (#), delimiter seperti koma (,) dan titik (.) dan juga 
tanda baca lainya. 
6. Pemeriksaan ejaan untuk memastikan kalimat yang dihasilkan terdiri dari kata-kata yang relevan dan tidak salah dalam pengejaan, pemeriksaan ejaan ini penting untuk menghitung frekuensi kata secara akurat. 
2.3. Pembobotan TF/IDF 
Tahap selanjutnya pembobotan terhadap kata berdasarkan frekuensi dari term atau istilah yang muncul pada dokumen dengan metode Pembobotan TF-IDF ( Term Frequency-Inverse Document Frequency). Pembobotan pada metode ini mengkombinasikan dua konsep yaitu konsep frekuensi kata dan frekuensi dokumen. Yang dimaksud dengan term frequency adalah nilai frekuensi term terhadap satu dokumen, sedangkan document frequency adalah 
nilai frekuensi dokumen yang terdapat term tersebut. Untuk itu perlu adanya tindakan preprocessing agar metode TF-IDF ini dapat optimal. Berikut adalah rumusnya. ð‘¡ð‘“âˆ’ð‘–ð‘‘ð‘“ð‘¡,ð‘‘= ð‘¡ð‘“ ð‘¡,ð‘‘âˆ—ð‘–ð‘‘ð‘“ð‘¡ 
Dimana: 
tf = term frequency  adalah jumlah kemunculan term 
t, d = term (t) di dokumen (d) 
2.4. Klasifikasi Sentimen Analisis 
Selanjutnya dilakukan proses pengklasifikasian menggunakan algoritma Naive Bayes, Support Vector Machine  dan k-NN dan diakhiri dengan pengujian akurasi dengan metode N-Fold Cross-Validation . N-Fold Cross-Validation  adalah salah satu cara untuk resampling data yang paling banyak digunakan untuk memprediksi kesalahan dari model dan untuk  mengatur parameter dari model (Berrar, 2018), Dalam pengujian N- Fold Cross-Validation  dataset dibagi menjadi N buah partisi secara acak. Kemudian dilakukan eksperimen sejumlah N kali, dimana masing-masing eksperimen menggunakan data partisi ke N sebagai data testing dan memanfaatkan sisa partisi lainnya sebagai data training.  
Sumber: Hasil Penelitian (2020) 
Gambar 2. Cross Validation  dengan Sub-proses Naive Bayes  
Sentimen Analisis Publik Terhadap Joko Widodo Terhadap Wabah Covid-19 Men ggunakan 
Metode Machine Learning   
Sumber: Hasil Penelitian (2020) 
Gambar 3 . Cross Validation  dengan Sub- proses SVM 
Sumber: Hasil Penelitian (2020) 
Gambar 4. Cross Validation  dengan Sub-proses k-NN 
Untuk lebih jelasnya tentang perbedaan metode klasifikasi yang digunakan berikut adalah penjelasannya: 
1. Naive Bayes Classifier 
Metode klasifikasi Naive Bayes adalah metode machine learning ysang sering digunakan untuk klasifikasi teks. Naive Bayes mengasumsikan bahwa fitur (kata) memiliki nilai yang independen pada posisi kata(Dewi et al., 2018) . Naive Bayes  menggunakan metode probabilitas dan statistik untuk memprediksi peluang di masa depan dari data m asa lalu. Namun, Naive Bayes  juga memiliki kelemahan, yaitu kesalahan dalam pemilihan feature  dapat 
mengurangi akurasi, di beberapa kasus terlalu banyak feature membuat metode ini memiliki akurasi yang rendah dan juga membuat waktu perhitungan semakin bertambah. 
2. K-NN 
K-NN merupakan  metode machine learning  yang berdasarkan data pembelajaran untuk mengklasifikasikan suatu objek berdasarkan k-tetangga terdekat (Bayhaqy et al., 201 8). K-NN merupakan salah satu metode machine learning  yang cukup populer dan simpel(Wibawa et al., 2018) .  
3. Support Vector Machine 
Support Vector Machine (SVM) sejak awal sudah digunakan dalam machine learning untuk meng klasifikasi dari data yang dianalisa(Herlawati, 2020). SVM sangat memun gkinkan 
digunakan untuk text mining (Kristiyanti et al., 2019). SVM berfungsi untuk memisahkan antara beberapa class yang berbeda. SVM memiliki proses yang efektif dan efisien untuk k lasifikasi. Namun SVM memiliki kelemahan yaitu pemilihan parameter atau feature dalam beberapa kasus sangat mempengaruhi akurasi secara signifikan. 
2.5. Evaluasi 
Setelah proses klasifikasi sentimen analisis telah selesai, langkah selanjut nya adalah mengevaluasi dengan mengukur keakurasian dan kualitas dari hasil tersebut. Evaluasi yang dilakukan adalah dengan pengujian performa dan akurasi sehingga menghasilkan nilai 
accuracy, precision , dan recall. Accuracy  (A) adalah total nilai True Positif dan True Negatif  dibagi dengan jumlah keseluruhan data.  
ð´ =(TP+TN)(TP+FP+FN+TN)ð‘¥ 100%  
Precision  (P) adalah prosentase nilai True Positif dari seluruh nilai Positif yang diprediks i. 
ð‘ƒ =TP
(TP+FP)ð‘¥ 100%  
Recall (R) adalah persentase prediksi Positif dibandingkan dengan True Positif. 
ð‘… =TP
(TP+FN)ð‘¥ 100%  
Parameter TP, FP, FN, TN berdasarkan Confusion Matrix seperti pada Gambar 5. 
Sumber: Hasil Penelitian (2020) 
Gambar 5. Tabel Confusion Matrix (Nugroho, 2019)  
Ketika proses pengumpulan data telah selesai, maka dipisahkan data menjadi data training dan data testing. Pembagian data tersebut dilakukan pada petode N -Fold Cross-Validation.  N-Fold Cross Validation adalah metode untuk memisahkan data dengan sebagi an 
terdapat label sebagai data training dan sebagian dihapus labelnya sebagai data training lalu membagi data secara acak sebanyak N untuk dilakukan pengujian sebanyak N kali. Ini  adalah langkah terakhir untuk mengetahui hasil dan performa dari machine learning  yang telah dibuat. 
 
3. Hasil dan Pembahasan 
Pada bagian ini akan dijelaskan hasil dari percobaan yang telah dilakukan yaitu menganalisa hasil performa dan akurasinya. Dalam preprocessing  penelitian ini menggunakan Gata Framework (Gata Framework Website , n.d.) dengan melakukan pengaturan pada teknik seperti pada Gambar 6. 
Sentimen Analisis Publik Terhadap Joko Widodo Terhadap Wabah Covid-19 Menggunakan Metode Machine Learning 
Sumber: Hasil Penelitian (2020) 
Gambar 6. Gata Framework â€“ Preprocessing Menu  
Penggunaan Gata Framework dikarenakan tweet text yang diambil merupakan text berbahasa Indonesia. Dan hasil keluaran ini digunakan pada rapidminer untuk dijadikan dataset untuk dilakukan pengujian. 
Sumber: Hasil Penelitian (2020) 
Gambar 7 . Proses utama di Rapidminer 
Pada gambar 7 operator â€œRead Excelâ€  berfungsi untuk membaca file Excel hasil dari keluaran twitterscraper yang telah di preprocessing dengan Gataframework sebelumnya, dan dilakukan â€œProcess Documents â€ untuk melakukan preprocessing kembali agar data benar-benar bersih. Di tahap selanjutnya dengan menggunakan operator â€œCross Validationâ€ ditambahkan di 
dalamnya operator untuk klasifikasi dan evaluasi dari sentimen analisis dengan nilai N adalah 10 (10- Fold Cross Validation ). 
Tabel 2. Hasil prediksi nilai Confidence (positif, netral, negatif)  terhadap nilai label  
Sumber: Hasil Penelitian (2020) 
Pada tabel 2 ditampilkan hasilnya, yaitu label dengan sentimen sesungguhnya dan prediksi label. 
3.1. Perbandingan Pengujian 
Dalam penerapan metode Naive Bayes, SVM dan k-NN diperlukan tuning dan percobaan untuk mengoptimalisasi hasil agar lebih baik. Pada k-NN memb utuhkan penentuan nilai k untuk mendapatkan akurasi tertinggi, dan pada kajian ini didapatkan nilai terbaik k=3. 
Serta Naive Bayes dan SVM sangat sensitif terhadap dataset yang telah dibuat, yaitu  menghapus missing value pada dataset. Missing value  muncul dikarenakan pada saat pre-processing terdapat text pada twitter yang tidak berisi tulisan yang memiliki term.  Tabel 3 adalah hasil confusion matrix  dari Rapid Miner: 
Tabel 3 . Confusion matrix  hasil klasifikasi 
Metode True 
Positif True 
Negatif True 
Netral False 
Positif False 
Negatif False 
Netral 
Naive Bayes 224 476 161 19 18 120 
SVM 227 572 147 5 66 1 
k-NN 246 465 141 77 23 66 
Sumber: Hasil Penelitian (2020) 
Tabel 4 adalah nilai rata-rata dari  accuracy, precision dan recall  pada setiap metode yang digunakan.  
Tabel 4. Hasil Accurace , Precision  dan Recall  
Metode Accuracy Precision Recall 
Naive Bayes 84.58% 82.14% 85.82% 
SVM 92.93% 95.70% 89.17% 
k-NN 83.70% 80.66% 84.13%  
Sumber: Hasil Penelitian (2020) 
Dari hasil yang ditampilkan pada Tabel 4 , accuracy dari Naive Bayes sebesar 84.58%, Support Vector Machine sebesar 92.93%, dan k-NN sebesar 83.70%. Hasil precision  dari Naive Bayes Sentimen Analisis Publik Terhadap Joko Widodo Terhadap Wabah Covid-19 Men ggunakan Metode Machine Learning sebesar 82.14%, SVM sebesar 95.70% dan k-NN sebesar 80.66%. Juga hasil recall  dari Naive Bayes sebesar 85.82%, SVM sebesar 89.17%, dan k-NN sebesar 84.13%. Jadi dapat dilihat bahwa pengklasifikasian Support Vector Machine yang terbaik di antara Naive Bayes dan Random Forest jika digunakan untuk dataset sentimen analisis yang menggunakan bahasa  Indonesia karena memiliki akurasi dan presisi tertinggi. Perbedaan hasil ini k arena pengaruh karakteristik dataset dan juga proses lainnya.  
 
4. Kesimpulan 
Pada penelitian ini, upaya untuk mengetahui pendapat publik dilakukan berupa sentimen positif, negatif dan netral di media twitter terhadap tindakan pencegahan Covid-19 oleh Pemerintahan di Indonesia dapat menjadi masukan bagi indikator keberhasilan 
pemerintah. Untuk merepresentasikannya maka dilakukan text mining  dengan menggunakan metode SVM, Naive Bayes dan k-NN untuk mengklasifikasikan label sentimen dari dataset.  Dari hasil pengujian menunjukkan , accuracy dari Naive Bayes sebesar 84.58%, Support Vector Machine sebesar 92.93%, dan k-NN sebesar 83.70%. Hasil precision  dari Naive Bayes sebesar 82.14%, SVM sebesar 95.70% dan k-NN sebesar 80.66%. Juga hasil recall  dari Naive Bayes sebesar 85.82%, SVM sebesar 89.17%, dan k-NN sebesar 84.13%. Dapat disimpulkan bahwa Support Vector Machine yang terbaik karena memiliki akurasi dan presisi tertinggi . Untuk 
kedepannya kita perlu menggunakan dataset yang lebih besar dan kompleks lagi serta penyempurnaan preprocessing untuk bahasa Indonesia yang tidak baku. 
 
Daftar Pustaka  
Bayhaqy, A., Sfenrianto, S., Nainggolan, K., & Kaburuan, E. R. (2018). Sentiment Analysis about E-Commerce from Tweets Using Decision Tree, K-Nearest Neighbor, and Naive Bayes. 2018 International Conference on Orange Technologies, ICOT 2018 , 1â€“6. https://doi.org/10.1109/ICOT.2018.8705796 
Berrar, D. (2018). Cross-validation. In Encyclopedia of Bioinformatics and Computational Biology: ABC of Bioinformatics . https://doi.org/10.1016/B978-0- 12-809633-8.20349-X 
Dewi, Y. N., Riana, D., & Mantoro, T. (2018). Improving Naive Bayes performance in single image pap smear using weighted principal component analysis (WPCA). 3rd International 
Conference on Computing, Engineering, and Design, ICCED 2017 , 2018-March , 1â€“5. https://doi.org/10.1109/CED.2017.8308130 
Gata Framework Website . (n.d.). http://www.gataframework.com 
Helmi Satria. (2018). Cara Mendapatkan Data (Tweet) dari Twitter . 
https://medium.com/@helmisatria/cara-mendapatkan-data-tweet-dari-twitter-e0ce79cdeed4 
Herlawati, H. (2020). COVID-19 Spread Pattern Using Support Vector Regression. PIKSELâ€¯: Penelitian Ilmu Komputer Sistem Embedded and Logic , 8(1), 67 â€“74. Sisferi Hikmawan, Amsal Pardamean, https://doi.org/10.33558/PIKSEL.V8I1.2024 
Jain, M., Vaish, S., Patil, M., & Anant, G. M. (2019). Data extraction and senti mental analysis from â€œtwitterâ€ usin g web scrapping. International Journal of Engineering and Advanced Technology . https://doi.org/10.35940/ijeat.A2226.109119 
Kompas.com. (2020). Fakta Lengkap Kasus Pertama Virus Corona di Indonesia https://nasional.kompas.com/read/2020/03/03/06314981/fakta-lengkap-kasus-pertama-virus-corona- di-indonesia?page=all 
Kristiyanti, D. A., Umam, A. H., Wahyudi, M., Amin, R., & Marlinda, L. (20 19). Comparison of SVM Naive Bayes Algorithm for Sentiment Analysis Toward West Java Governor Candidate Period 2018-2023 Based on Public Opinion on Twitter. 2018 6th International Conference on Cyber and IT Service Management, CITSM 2018 , Citsm , 1â€“6. https://doi.org/10.1109/CITSM.2018.8674352 
Muthia, D. A., Putri, D. A., Rachmi, H., & Surniandari, A. (2019). Implementation of Text Mining in Predicting Consumer Interest on Digital Camera Products. 2018 6th International Conference on Cyber and IT Service Management, CITSM 2018 , Citsm , 1â€“7. 
https://doi.org/10.1109/CITSM.2018.8674063 
Nugroho, K. S. (2019). Confusion Matrix untuk Evaluasi Model pada Supervised Learning . https://medium.com/@ksnugroho/confusion-matrix-untuk-evaluasi-model-pada-unsupervised-machine-learning-bc4b1ae9ae3f 
S.C.M. de S Sirisuriya. (2015). A Comparative Study on Web Scraping. 8th International Research Conference KDU . Wibawa, D. W., Nasrun, M., & Setianingsih, C. (2018). Sentiment Analysis on User Satisfaction Level of Cellular Data Service Using the K-Nearest Neighbor (K-NN) Algorithm. Proceedings - 2018 International Conference on Control, Electronics, Renewable Energy and Communications, ICCEREC 2018 , 235 â€“241. https://doi.org/10.1109/ICCEREC.2018.8711992 
",Sentimen Analisis,"Metode Machine Learning, k-NN, Naive Bayes, Support Vector Machine",tweet,"accuracy, precision, recall"
Sentimen Analisis Customer Review  Produk Shopee Indonesia Menggunakan Algortima Naive Bayes Classifier,"Sentimen Analisis Customer Review  Produk Shopee Indonesia Menggunakan Algortima Naive Bayes Classifier   

Loemongga Oktaria Sihombing1, Hannie2, Budi Arif Dermawan3  

Abstrak  
Mendapatkan kepuasan serta kepercayaan customer  telah menjadi tantangan utama dalam mencapai kesuksesan dalam dunia bisnis. Pelaku bisnis perlu mengidentifikasi masalah yang muncul dari review  yang diberikan oleh para customer . Namun, membaca dan mengklasifikasikan setiap review membutuhkan waktu lama dan dianggap tidak efektif. Untuk mengatasi hal tersebut, maka penelitian ini bertujuan untuk menganalisis sentimen customer  produk shopee menggunakan algortima naive bayes classifier . Data yang digun akan pada penelitian ini adalah customer  review  dari produk Xiaomi 
Redmi Note 9  yang dijual pada website  Shopee Indonesia. Data review customer  dikumpulkan dengan menerapkan teknik Web Scraping . Algoritma yang digunakan pada penelitian ini adalah Naive  Bayes Classifier  yang dikenal populer dan efektif dalam melakukan klasifikasi data. Penelitian ini juga menerapkan metodologi Knowledge Discovery in Text  (KDT) untuk menggali informasi dari sebuah data teks.  Hasil klasifikasi menggunakan algoritma Naive Bayes  mendapati nilai akurasi sebesar 85%. 
Penelitian ini membuktikan bahwa dengan menerapkan teknik analisis sentimen, para pelaku bisnis mampu mengetahui opini para customer  sebagai bahan evaluasi yang perlu dilakukan untuk melakukan optimalisasi terhadap produk serta  layanan yang diberikan.  

Kata kunci: Analisis Sentimen , Knowledge Discovery in Text , Naive Bayes Classifier , Shopee , Text Mining . 
 
Abstract  
Gaining customer satisfaction and trust has become the main challenge in achieving success in the business world. Business people need to identify problems that arise from reviews given by customers. However, reading and classifying each review takes a long time and is considered ineffective. To overcome this, this study aims to analyze the customer sentiment of shopee products using the nave Bayes classifier algorithm. The data used in this study is a customer review of the Xiaomi Redmi Note 9 products which are sold on the Shopee Indonesia website. Customer review data is collected by applying the Web Scraping technique. The algorithm used in this study is the Naive Bayes Classifier which is known to be popular and effective in classifying data. This study also applies the Knowledge 
Discovery in Text (KDT) methodology to extract informat ion from text data. The results of the classification using the Naive Bayes algorithm found an accuracy value of 85%. This study proves that 
by applying sentiment analysis techniques, business people are able to find out the opinions of customers as an eva luation material that needs to be done to optimize the products and services provided.  
 
Keywords:  Sentiment Analysis , Knowledge Discovery in Text , Naive Bayes Classifier , Shopee , Text Mining . 
 
PENDAHULUAN   
Kegiatan jual beli barang dan jasa secara online  atau yang biasa disebut dengan e-commerce  telah berkembang pesat saat ini. Salah satu marketplace  dengan model e-commerce  yang populer khususnya di Indonesia adalah Shopee. E-commerce  menawarkan pengguna Sentimen Analisis Customer Review  Produk Shopee Indonesia Menggunakan Algoritma Naive Bayes Classifier dalam melakukan sebuah transaksi barang maupu n jasa tanpa batas jarak dan waktu selama pengguna memiliki akses internet (IÅ¡oraitÄ— & MiniotienÄ—, 2018) . Namun begitu, tidak jarang customer  merasa ragu membeli produk secara online  dengan harga pasar yang tinggi seperti smartphone . Hal ini dibuktikan berdasarkan hasil penelitian sebelumnya yang mendapati sebuah kesimpulan bahwa kepercayaan pelanggan mempengaruhi niat pembelian produk 
smartphone  di Shopee Indonesia. Pelanggan dinilai masih merasa kurang percaya terhadap para penjual smar tphone  dalam me menuhi keinginan para pelanggan (Picaully, 2018) . Kurangnya rasa kepercayaan customer  terhadap penjual menjadi tantangan bagi para pelaku bisnis agar mampu melakukan evaluasi terhadap produk dan layanannya. Pelaku bisnis perlu mengidentifikasi masalah yang muncul dari review  yang diberikan oleh para customer . Namun, membaca dan mengklasifikasikan setiap review  yang diberikan oleh para customer  membutuhkan waktu lama, dan dianggap tidak efektif (Wiratama & Rusli, 2019) . Untuk mengatasi masalah tersebut, dibutuhkan sistem yang dapat mengklasifikasikan opini ke dalam kelas sentimen positif, netral, atau negatif secara otomatis  yang biasa disebut dengan analisis sentimen (Santoso et al., 2017) .   
Naive Bayes  merupakan salah satu algoritma yang mampu melakukan pengklasifikasian dengan cepat . Naive Bayes  juga merupakan salah s atu algoritma yang sangat efisien dan efektif 
bahkan saat digunakan untuk m enganalisis data berskala besar  (Ahmad et al., 2017)  . Penelitian sebelumnya yang dilakukan oleh (Pintoko, 2018) , mendapatkan hasil akurasi yang cukup tinggi 
yaitu sebesar 86 ,80%. Penelitian tersebut dilakukan untuk menganalisa tanggapan masyarakat  terhadap jasa transportasi online  dengan analis is data berupa tweet  kemudian diklasifikasikan 
menjadi kelas positif dan negatif menggunakan metode Naive Bayes Classifier . Data mining  merupakan salah satu teknik atau metode yang digunakan dalam  proses ekstrasi pengetahuan dari kumpulan data. Data mining  mampu mempelajari kebiasaan pelanggan sehingga para pelaku bisnis mampu  mengembangkan strategi yang lebih efektif  (Umarani et al., 2020) . Klasifikasi merupakan salah satu teknik yang ada didalam data mining  dan berguna dalam pengelompokan data berdasarkan keterikatan data dengan data sampel (Harianto et al., 2020) penelitian saat ini adalah teknik klasifikasi dengan mengg unakan algoritma Naive Bayes Classifier . Pendekatan ini dimulai dari proses pelatihan dataset yang kemudian dilakukan pengembangan fungsi yang telah disimpulkan untuk memperkirakan nilai output (Saravanan & Sujatha, 2019) . Setelahnya, algoritma ini akan membandingkan hasi l yang diperoleh dengan hasil aktual atau yang diharapkan untuk mengidentifikasi kesalahan (Saravanan & Sujatha, 2019) . Dengan meningkatnya kebutuhan informasi dan pengetahuan dari data teks, algoritma ini sudah semakin banyak digunakan untuk klasifikasi  data teks (Kristiyanti et al., 2019) . Penelitian saat ini berfokus pada analisis sentimen menggunakan algoritma Naive Bayes  terhadap produk smartphone  yang diperjual belikan di website  Shopee. Penjualan smartphone  di Shopee cukup banyak diminati dibandingkan dengan marketplace  lainnya seperti  Tokopedia dan Lazada. Hal ini dib uktikan dengan hasil pengamatan peneliti terhadap produk smartphone  yang terjual di beberapa marketplace . Produk smartphone  yang akan menjadi objek penelitian saat ini merupakan smartphone  keluaran tahun 2020 yaitu Xiaomi Redmi Note 9  yang telah terjual lebih dari 10.000 produk. Banyaknya produk yang terjual diikuti dengan banyaknya review  yang masuk terhadap produk tersebut. Tujuan dari penelitian ini adalah menganalisis sentimen untuk mengetahui opini customer  terhadap seb uah produk serta layanan yang telah diterima oleh para customer. Informasi  yang didapatkan bisa menjadi bahan evaluasi dalam melakukan optimalisasi guna meningkatkan kepercayaan customer  terhadap para pelaku bisnis.  

METODE  
Data mining  merupakan  salah satu teknik atau metode yang digunakan dalam proses ekstrasi pengeta huan dari kumpulan data untuk mengubah data mentah  menjadi  sebuah informasi atau pengetahuan yang berguna (Shu -Hsien et al., 2017) . Salah satu penerapan konsep dan teknik data mining  untuk mencari pola dalam teks adalah text mining . Manfaat text mining  akan sangat terasa di bidang-bidang yang me miliki banyak data b erupa teks seperti 
manajemen risiko,  deteksi penipuan, business intelligence , serta  analisis media sosial  (Ferreira-Mello et al., 2019) . Penelitian ini menggunakan  teknik analisis sentimen untuk menghasilkan sebuah 
informasi berupa pandangan seseorang terhadap suatu kejadian atau isu . Teks yang tidak terstruktur mudah diproses dan dirasakan oleh manusia, tetapi secara signifikan lebih sulit untuk dipahami oleh mesin  (Allahyari et al., 2017)  . Maka dari itu, a nalisis sentimen diperlukan untuk dapat memahami opini seseorang yang tertulis di platform online  secara otomatis dengan bantuan mesin. Tugas dasar dalam analisis sentimen adalah mengelompokkan polaritas dari  teks yang ada dalam dokumen, kalimat, atau fitur atau tingkat aspek dan menentukan apakah pendapat yang dikemukakan dalam dokumen, kalimat atau fitur entitas atau aspek bersifat positif, negatif atau netral  (Murnawan, 2017) .  Metodologi yang digunakan pada penelitian ini adalah Knowledge Discovery in Text  (KDT). Knowledge Discovery in Text  atau disingkat dengan KDT merupakan bagian dari 
proses penggalian atau pencarian data teks  yang sebelumnya tidak diketa hui menjadi sebuah informasi yang dapat dimengerti  (Firdaus, 2017) . Adapun tahapan  yang akan dilakukan pada penelitian ini diantaranya adalah collecting  dan labeling data , dimana data didapat dari hasil web scraping website  Shopee  yang kemudian diberi label positive , neutral , dan negative  secara manual . Data yang telah diberi label kemudian masuk ke dalam tahap preprocessing  untuk membersihkan noise  dari sebua h data sebelu m akhirnya data diklasifikasi  menggunakan algoritma Naive Bayes Classifier . Tahap terakhir yang akan dilakukan pada penelitian ini 
adalah evaluation  berupa classification accuracy . Penelitian saat ini menggunakan  tools  software Orange Data Mining sebagai perangkat bantu analisis . Orange Data Mining  merupakan salah satu software open source  untuk mengolah data, visualisasi data, machine learning , dan penambangan data atau data mining  yang ditulis menggunakan bahasa Python (Mohi, 2020) .  

HASIL DAN PEMBAHASAN  
Hasil  
Skenario penelitian yang  akan dilakukan pada penelitian ini diperlihatkan pada gambar 1 dengan menggunakan bantuan software Orange Data Mining . 
Gambar 1 . Skenario Penelitian Collection  dan Labeling Data  
Data yang akan digunakan pada  penelitian ini adalah data review  salah satu produk smartphone  dengan merek Xioami Redmi Note 9  yang dijual secara online  di website  Shopee Indonesia dan dikelola langsung oleh xiaomi.official.id . Pengambilan data dilakukan dengan 
menerapkan teknik web scraping  menggunakan bahasa Python . Data mentah yang terkumpul Sentimen Analisis Customer Review  Produk Shopee Indonesia Menggunakan Algoritma Naive Bayes 
Classifier review  yang kemudian dilakukan pemberian label atau labeling secara manual ke dalam beberapa kelas diantaranya positive , neutral , dan negative  sesuai dengan sentimen kata yang berada pada review  produk. Review  yang tidak mengandung sentimen manapun dan tidak berkaitan dengan produk tersebut akan diberi label unrelated . Data  dengan label  unrelated  kemudian dihapus sehingga menyisakan kelas positive , neutral , dan negative  seperti yang terlihat pada tabel 1. 
Tabel 1 . Jumlah Data  
Dengan  Unrelated  Tanpa  Unrelated  Kelas  Jumlah  Kelas  Jumlah  
Positive  2475  Positive  2475  
Neutral  372 Neutral  372 
Negative  102 Negative  102 
Unrelated  57   
Total  3006  Total  2949  
Pre-processing Data  
Data testing  yang telah terbentuk akan melalui empat tahap pre-processing  diantaranya adalah Transformation , Tokenization , Filtering , dan N-Gram . Tranformation merupakan proses mengubah atau mentransformasi data yang sebelumnya mentah menjadi data yang lebih seragam guna mempermudah proses analisis. Beberapa proses transfomasi yang digunakan pada penelitian ini diantaranya adalah sebagai berikut:  
1. Lowercase : Transformasi lowercase  akan mengubah huruf kapital menjadi huruf kecil secara default  untuk mempermudah proses analisis. Contoh : Barang bagus, saya suka! â†’ barang bagus, saya suka!.  
2. Remove accents : berfungsi untuk mengubah data teks yang memiliki aksen menjadi teks tanpa aksen. Contoh : NaÃ¯ve Bayes â†’ Naive Bayes.  
3. Parse html:  Parse html pada proses transformasi bertujuan untuk mendeteksi tag html  dan mengurainya menjadi bentuk teks. Contoh : <a href â€¦> Produk rusak! Kecewa banget. Nyesel belanja disini â€¦</a> â†’ Produk rusak! Kecewa banget. Nyesel belanja disini â€¦  
4. Remove urls  : Transformasi  ini berfungsi  untuk menghapus urls yang berada pada data teks. Contoh : Hpnya bagus, warnanya juga cantik. Ga nyesel beli disini. Jangan lupa tonton video aku di https://www.youtube.com/watch?v=EGKeC2S4  4Rs â†’ Hpnya bagus, warnanya ju ga cantik. Ga nyesel beli disini. Jangan lupa tonton video aku di.  
Proses selanjutnya pada tahapan pre-processing  merupakan Tokenization  dimana teks akan dipecah menjadi komponen yang lebih kecil. Proses Tokenization  dilakukan dengan menerapkan Regexp  atau Regular Expression  pada software Orange Data Mining  dimana data akan dipisahkan menjadi satuan kata tanpa mengikutsertakan tanda baca seperti titik (.), dan koma (,). Filtering  dilakukan untuk menghapus komponen yang tidak penting dan hanya mempertahankan komponen yang dianggap penting sehingga proses analisis dapat dilakukan dengan lebih mudah . Fitur yang akan digunakan pada penelitian ini diantaranya adalah Stopwords , Regexp , dan Most frequent tokens . 
1. Stop Word Removal  berfungsi untuk mengh apus kata yang tidak memiliki bobot atau kata tidak  penting  seperti yang terlihat pada tabel 2. 
2. Regular Expression atau Regexp  pada Orange Data Mining  secara default diatur untuk menghapus tanda baca yang tidak memiliki bobot atau pera n penting dalam proses analisis. 
Tabel 3  memperlihatkan sejumlah tanda baca dan angka yang akan dihilangkan pada sebuah data.  
2. Filtering Stopwords  
Stopwords  nya, aj, suks, banget, pake, d, du, yg, dgn, kak, yaa, ya, sih, dg, krn, mulu, tgl, g, jg, sdh, n, bgt, deh , wa, tp dr, gk, y, pa, udh, dll. 
Tabel 3 . Filtering Regexp  
Filtering Regexp  
\\.|,|:|
3. Most Frequent Token  berfungsi untuk menyimpan token atau  kata yang paling sering muncul pada keseluruhan data. Penelitian ini menetapkan ketentuan default yaitu 100.000 token sebagai Most Frequent Token . Model n-gram  bekerja  untuk memprediksi kata berikutnya yang memungkinkan untuk dilakukan penggabungan berdasarkan kata sebelumnya. N-gram  merupakan salah satu teknik 
penting dalam analisis teks mengingat banyak data input yang ambigu.  Setelah tahap preprocessing  dilakukan, data yang telah siap dapat dilihat dalam bentuk kumpulan kata dengan bantuan visualisasi Word Cloud  pada software Orange Data Mining  seperti yang terlihat pada Gambar 2 . Terlihat pada Gambar 2  bahwa sepuluh besar kata yang paling sering muncul diantaranya adalah barang,  pengiriman, cepat, bagus, aman, produk, hp, pengiriman 
cepat, semoga, sesuai. Visualisasi word cloud  tentunya mampu mempermudah user dalam mengamati topik utama dalam sebuah data.  
Gambar 2 . Word Cloud  
 Analisis dan Klasifikasi Sentimen  
Pada penelitian ini, klasifikasi analisis sentimen dilakukan menggunakan algoritma Naive Bayes . Metode yang diterapkan pada proses ini adalah metode Multilingual Sentiment  dengan bahasa Indonesia  menggunakan widget Sentiment Analysis  pada software Orange Data Mining . Database  Multilingual Sentiment pada software  Orange Data Mining  bersumber dari situs Data Science Lab  yang menyimpan lexicon  atau kamus kata dari berbagai bahasa di dunia. Lexicon  bahasa Indonesia pada situs Data Science Lab  memiliki dua file yang berisi kumpulan kata yang memiliki nilai sentimen positi ve dan negative . Tabel 4  menunjukkan beberapa tahap skoring algoritma Naive Bayes . Masing -masing 
data teks di analisis dan melalui proses perhitungan untuk menemukan skor dari masing-masing label atau nilai sentimen. Sentimen dengan skor tertinggi kemudian  akan dijadikan hasil sebuah prediksi dari penerapan klasifikasi dengan algoritma Naive Bayes . Visualisasi hasil klasifikasi sentimen mneggunakan algoritma Naive Bayes  dapat dilihat pada gambar 3 . Visualisasi dilakukan dengan menggunakan widget  Distributions . Sentimen Analisis Customer Review  Produk Shopee Indonesia Menggunakan Algoritma NaÃ¯ve Bayes 
Classifier  
Hasil Skoring Naive Bayes  
Label  Review  Naive 
Bayes  NB 
Negative  NB 
Neutral  NB 
Positive  
Positive  untuk pengirimannya cepat sekali, dn packingnya juga rapih  Positive  0,016 0,134 0,849 
Negative  baterai kapasitas gede.tp gk ada bedanya sama betre yg brkpasitas kcil.jg gk ada jarum pembuka slot.mgkn d jual terpisah x yaâ€¦  Negative  0,505 0,262 0,232 
Neutral  barang sampai dengan aman dan selamatâ€¦.tp di deskripsi helio 85g, tp nyatanya helio 65g sedikit mengecewakan  Negative  0,505 0,262 0,232 
Gambar 3 . Distributions  Klasifikasi Naive Bayes  
Pada Gambar 3  terlihat bahwa review  dengan label positive  memiliki frekuensi terbanyak yang menunjukkan bahwa produk serta pelayanan yang diberikan sudah cukup baik. Namun begitu, terlihat pada grafik bahwa masih ada review  dengan label negative , yang berarti masih terdapat kekurangan pada produk serta pelayanan yang diberikan. Total masing-masing label hasil klasifikasi Naive Bayes  adalah 2750 review  dengan label positive , 65 review dengan label neutral , dan 134 review  dengan label negative . Data kemudian di filter untuk mengetahui apa saja review customer  yang memiliki label negative  sebagai bahan evaluasi pengelola toko.  
Tabel 5  memperlihatkan beberapa contoh review customer  yang  diklasifikasikan ke dalam label negative  oleh algoritma Naive Bayes. Sebagian besar data dengan label negative menunjukkan kekecewaan pada customer  terhadap packing  yang rusak saat dalam perjalanan, kurangnya barang, dan pengiriman yang lama. Dengan menge tahui kekurangan yang ada, pengelola toko diharapkan mampu melakukan perbaikan serta pengoptimalan dalam produk serta pelayanan yang diberikan. Setelah dilakukan proses skoring dan klasifikasi sentimen terhadap data teks 
menggunakan algoritma Naive Bayes  maka selanjutnya dapat dilakukan visualisasi dengan widget  Scatter Plot  mengenai keterhubungan antara jumlah rating  yang diberikan para  costumer  dengan hasil klasifikasi sentimen menggunakan Naive Bayes  dan didapati hasil 
seperti pada gambar 4 . 
Naive Bayes Negative  
Review  Naive Bayes  
gua beli hp, bukan beli botol susu yang cuma di packing asal asalan  Negative  
Knp gad kartu garansi?  Negative  
Pengiriman lama buaangettt  Negative  
Packingnya uhuu seremm . Kerdusnya penyokâ€  Negative  
Barang sampe sekarang belom tiba  Negative  
Pengiriman lama sgt  Negative  
Berdasarkan visualisasi scatter p lot pada gambar 4, terlihat bahwa pemberian jumlah rating  dan isi review  tidak begitu relevan dimana terlihat masih ada review  dengan nilai sentimen negatif berada di rating  5 atau rating  tertinggi dan review  dengan nilai sentimen neutral  lebih banyak tersebar pada nilai sentimen positive . 
Gambar 4 . Scatter Plot Rating  dan Naive Bayes  
Evaluation  
Evaluasi dilakukan untuk mengetahui performa algoritma Naive Bayes  dalam melakukan klasifikasi analisis sentimen. Evaluasi pada penelitian ini menggunakan metode Cross Validation  dengan 10 fold atau 10 lipatan. Data dibagi menjadi 10 lipatan dengan ukuran yang 
kira-kira sama, kemu dian 10 subset  data tersebut yang dipakai untuk mengevaluasi kinerja model atau algoritma. Evaluasi cross validation  akan menggunakan 9 fold sebagai data training  dan 1 fold sisanya sebagai data testing . Berdasarkan evaluasi cross validation  yang dilakukan , didapati hasil akurasi yang cukup baik yaitu sebesar 85%. Dengan hasil akurasi yang didapat, diketahui bahwa ada beberapa misclassified data hasil klasifikasi dengan 
algoritma Naive Bayes . Untuk mengamati contoh spesifik dari sebuah data yang salah diklasifikasi, maka akan dilakukan proses evaluasi lanjutan dengan menerapkan metode confusion matrix .  
Gambar 5  memperlihatkan bahwa masih terdapat banyak data yang salah diklasifikasi atau misclassified . Berdasarkan hasil evaluasi , total data yang mengalami misclassified berjumlah 437 data.  Dari keseluruhan data misclassified , ditemukan bahwa data dengan label 
neutral  merupakan data yang paling banyak mengalami kesalahan klasifikasi.  Hal ini dikarenakan Lexicon  atau kamus kata yang  terdapat pada Multilingual Sentiment  hanya memiliki dua kelas yaitu positive  dan negative , sehingga metode tersebut dinilai masih belum akurat untuk memprediksi teks yang memiliki nilai sentimen neutral . Visualisasi persebaran data juga d apat dilihat pada  gambar 6 . 
Gambar 5 . Confusion Matrix  
Berdasarkan visualisasi scatter plot  pada gambar 6, terlihat persebaran data yang  mengalami misclassified  dan terlihat juga bahwa data dengan aktual label Neutral adalah data terbanyak 
yang mengalami misclassified . Sebagian besar data dengan aktual label neutral  saat diklasifikasikan dengan algoritma NaÃ¯ve Bayes  menjadi data berlabel positive.  
Gambar 6 . Scatter Plot  
Pembahasan  
Naive Bayes  merupakan salah satu algoritma yang populer dalam melakukan sebuah klasifikasi sentimen. Hal ini dapat dibuktikan dari hasil penelitian saat ini yang memiliki tingkat akurasi yan g cukup baik yaitu sebesar 85%. Hasil akurasi yang didapat juga dipengaruhi oleh tahap preprocessing  yang dilakukan. Transformation , tokenization , filtering  dan n-grams  mampu menghilangkan noise  yang ada pada data sehingga data yang akan memasuki proses analisis menjadi lebih baik. Namun begitu, masih banyak data yang ketika diklasifikasi menghasilkan nilai prediksi  yang salah. Data dengan aktual label neutral  mendominasi misclassified data. Hal ini dipengaruhi oleh kata yang sulit dikenali sebagai nilai sentimen neutral. Pada umumnya kalimat bersentimen neutral memiliki variasi kata yang lebih beragam dan cenderung tidak memiliki kata yang khas seperti nilai sentimen lainnya sehingga sulit dikenali  (Santoso et al., 2017) .  Lexicon  atau kamus ka ta yang terdapat pada Multilingual Sentiment  hanya memiliki dua kelas yaitu positive  dan negative , sehingga metode tersebut dinilai masih belum akurat untuk memprediksi teks yang memiliki nilai sentimen neutral .  
Klasifikasi sentimen menggunakan Naive Bayes menghasilkan prediksi 2750 review  dengan label positive , 65 review  dengan label neutral , dan 134 review  dengan label negative . Hal ini membuktikan bahwa dengan melakukan analisis sentimen, para pelaku bisnis mampu mengetahui pandangan customer  terhadap produk serta pelayanan yang telah diberikan. Dari hasil yang didapat, terlihat bahwa hasil penjualan produk Xiaomi Redmi Note 9  memiliki tingkat kepuasan yang cukup tinggi. Namun begitu, masih terdapat beberapa customer  yang tidak begitu puas deng an apa yang didapat. Beberapa ungkapan ketidakpuasan customer berfokus pada packing  yang rusak dalam perjalanan, kurangnya barang, dan pengiriman yang lama.  Hasil temuan kami sesuai dengan hasil penelitian yang dilak ukan oleh (Picaully, 2018) . Dimana hasil tersebut menjadi salah satu faktor yang me nguatkan hasil penelitian sebelumnya mengenai kepercayaan pelanggan terhadap  niat pembelian produk smartphone  di Shopee Indonesia  yang dinilai masih kurang .  

SIMPULAN  
Algoritma Naive Bayes  yang digunakan sebagai model klasifikasi dinilai mampu melakukan sebuah prediksi terhadap sebuah data teks yang mengandung nilai sentimen positive , neutral , atau negative . Masing -masing data teks dianalisis dan melalui proses 
perhitungan untuk menemukan skor dari masing -masing label atau nilai sentimen. Sentimen dengan skor tertinggi kemudian akan dijadikan hasil sebuah prediksi dari penerapan klasifikasi 
dengan algoritma Naive Bayes . Penggunaan algoritma NaÃ¯ve Bayes  sebagai model klasifikasi sentimen memiliki hasil akurasi yang cukup tinggi yaitu 85%. Walaupun be gitu, masih terdapat 
banyak data yang tidak terklasifikasi dengan baik atau bisa disebut dengan data misclassified . Terdapat total 436 data yang tidak terklasifikasi sempurna. Banyak dari data tersebut adalah data dengan aktual label neutral  yang dinilai sulit untuk dikenali .  
 
REFERENSI  
Ahmad, M., Aftab, S., Muhammad, S. S., & Ahmad, S. (2017). Machine Learning Techniques for Sentiment Analysisâ€¯: A Review. International Journal of Multidisciplinary Sciences and Engineering , 8(3), 27 â€“32. 
Allahyari, M., Pouriyeh, S., Assefi, M., Safaei, S., Trippe, E. D., Gutierrez, J. B., & Kochut, K. (2017). A Brief Survey of Text Mining: Classification, Clustering and Extraction Techniques . https://arxiv.org/abs/1707.02919  
Ferre ira-Mello, R., AndrÃ©, M., Pinheiro, A., Costa, E., & Romero, C. (2019). Text mining in education. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery , 9(6), e1332. https://doi.org/https://doi.org/10.1002/widm.1332  
Firdaus, A. (2017). Reput ation Scoring Fake News Using Text Mining. ACMIT Proceedings , 4(1), 12 â€“17. https://doi.org/10.33555/acmit.v4i1.52  
Harianto, H., Sunyoto, A., & Sudarmawan, S. (2020). Optimasi Algoritma Naive Bayes Classifier untuk Mendeteksi Anomaly dengan Univariate Fitur  Selection. Edumatic: Jurnal Pendidikan Informatika , 4(2), 40 â€“49. 
IÅ¡oraitÄ—, M., & MiniotienÄ—, N. (2018). Electronic Commerce: Theory and Practice. IJBE (Integrated Journal of Business and Economics) , 2(2), 194 â€“200. https://doi.org/10.33019/ijbe.v2i2.78  
Kristiyanti, D. A., Umam, A. H., Wahyudi, M., Amin, R., & Marlinda, L. (2019). Comparison of SVM NaÃ¯ve Bayes Algorithm for Sentiment Analysis Toward West Java Governor Candidate Period 2018 -2023 Based on Public Opinion on Twitter. The 6th International Conference on Cyber and IT Service Management, CITSM , 1â€“6. Indonesia: IEEE. https://doi.org/10.1109/CITSM.2018.8674352  
Mohi, Z. R. (2020). Orange Data Mining as a tool to compare Classification Algorithms. Dijlah Journal of Sciences and Engineering , 3(3), 13 â€“23. Murnawan, M. (2017). Pemanfaatan Analisis Sentimen Untuk Pemeringkatan Popularitas Tujuan Wisata. Jurnal Penelit ian Pos Dan Informatika , 7(2), 109 â€“120. https://doi.org/10.17933/jppi.2017.070203  
Picaully, M. R. (2018). Pengaruh Kepercayaan Pelanggan Terhadap Niat Pembelian Gadget Di Shopee Indonesia. Jurnal Manajemen Maranatha , 18(1), 31 â€“40. https://doi.org/10.28932/ jmm.v18i1.1094  Sentimen Analisis Customer Review  Produk Shopee Indonesia Menggunakan Algoritma Naive Bayes 
Classifier  
Pintoko, B. (2018). Analisis Sentimen Jasa Transportasi Online pada Twitter Menggunakan Metode Naive Bayes Classifier. E-Proceeding of Engineering , 5(3), 8121 â€“8130.  Pramadhana, D. (2021). Klasifikasi Penyakit Diabetes Menggunakan Metode CFS Dan ROS 
dengan Algoritma J48 Berbasis Adaboost. Edumatic: Jurnal Pendidikan Informatika , 5(1), 89 â€“98. https://doi.org/10.29408/edumatic.v5i1.3336  
Santoso, V. I., Virginia, G., & Lukito, Y. (2017). Penerapan Sentiment Analysis Pada Hasil Evaluasi Dosen Deng an Metode Support Vector Machine. Jurnal Transformatika , 14(2), 72â€“76. https://doi.org/10.26623/transformatika.v14i2.439  
Saravanan, R., & Sujatha, P. (2019). A State of Art Techniques on Machine Learning Algorithms: A Perspective of Supervised Learning App roaches in Data Classification. Proceedings of the 2nd International Conference on Intelligent Computing and Control 
Systems, ICICCS 2018 , Iciccs , 945 â€“949. https://doi.org/10.1109/ICCONS.2018.8663155  
Sari, V., Firdausi, F., & Azhar, Y. (2020). Perbandingan  Prediksi Kualitas Kopi Arabika dengan Menggunakan Algoritma SGD, Random Forest dan Naive Bayes. Edumatic: Jurnal Pendidikan Informatika , 4(2), 1 â€“9. https://doi.org/10.29408/edumatic.v4i2.2202  
Shu-Hsien, L., Pei -Hui, C., & Pei -Yuan, H. (2017). Data mining techniques and applications â€“ A decade review from 2000 to 2011. Expert Systems with Applications , 39, 11303 â€“11311.  Umarani, J., Manikandan, S., Centre, D., & Nadu, T. (2020). Implementation of Data Mining Concepts in R Programming . International Journal o f Trendy Research in Engineering and Technology ,  4(1), 1 â€“7. 
Wiratama, G. P., & Rusli, A. (2019). Sentiment analysis of application user feedback in Bahasa Indonesia using multinomial naive bayes. The 5th International Conference on New Media Studies, CONM EDIA , 223 â€“227. Indonesia: IEEE. https://doi.org/10.1109/CONMEDIA46929.2019.8981850  ",Sentimen Analisis,"Naive Bayes Classifier, Knowledge Discovery in Text",customer review dari produk Xiaomi,akurasi
Sentimen Analisis Vaksin Covid-19 Menggunakan Naive Bayes Dan Support Vector Machine  ,"Sentimen Analisis Vaksin Covid-19 Menggunakan Naive Bayes Dan Support Vector Machine  

Debby Alita1, RB Ali Shodiqin2 

Abstrak:  
Pemberian vaksin di Indonesia saat ini sudah mencapai tahapan vaksin boster, berbagai jenis vaksin telah diberikan kepada masyarakat Indonesia dari vaksin Sinovac, AstraZeneca, Sinopharm, Moderna, Pfizer, dsb. Tidak sedikit masyarakat Indonesia yang menggu nakan beberpa jenis vaksin yang ditawarkan hingga vaksin booster akan tetapi ada beberapa masyarakat yang berpendapat masih terinfeksi virus covid ini dengan gejala berat. Pendapat lain juga terdapat   kemudian terdapat vaksin  Pada tahun 2019 masyarakat d ihebohkan dengan adanya virus baru dari Wuhan, China yaitu virus corona atau disebut COVID -19 (Corona Virus Desease 2019). Pemerintah mengajak masyarakat untuk melakuk an vaksin Covid-19 agar terbentuk herd immunity atau kekebalan kelompok terdapat virus Covid-19. Analisis sentimen dapat digunakan untuk melakukan evaluasi suatu kinerja pelayanan dan sebagainya. Maka penulis akan melakukan suatu perbandingan antara metode Naive Bayer Classifier dan Support Vector Machine  untuk mengetahui metode mana yang lebih efisien dalam mengetahui pandangan akurasi masyarakat terhadap vaksin Covid -19. Hasil pengujian performa dari kedua metode menunjukkan bahwa performa metode Naive Bayes Classifier (Accuracy 72.88% , Precision 43.49%, Recall 54.95% , dan rata -rata p erforma 57.10% ) lebih tinggi dibandingkan dengan rata -rata performa metode  Support Vector Machine (Accuracy 77.00%, Precision 75.00%, Recall 7.70%,  dan rata-rata performa 53.52%) . Berdasarkan nilai rata -rata performance 
metode Naive Bayes Classifier dapat dinilai lebih efisien dibandingkan metode Support Vector Machine.  

Kata Kunci: Analisis Sentimen, Vector Machine
 
Abstract:  
Vaccine administration in Indonesia has now reached the booster vaccine stage, various types of vaccines have been given to the Indonesian people from the Sinovac, AstraZeneca, Sinopharm, Moderna, Pfizer vaccines, etc. Not a few Indonesian people use sever al types of vaccines that are offered up to booster vaccines, but there are some people who think they are still infected with this Covid virus with severe symptoms. Another opinion is that there is also a vaccine. In 2019, people were shocked by a new virus from Wuhan, China, namely the corona virus or called COVID -19 (Corona Virus Disease 2019). The government invites the public to get the Covid -19 vaccine in order to form herd immunity or group immunity to the Covid -19 virus. Sentiment analysis can be us ed to evaluate a service performance and so on. So the author will conduct a comparison between the Naive Bayer Classifier method and the Support Vector Machine to find out which method is more efficient in knowing people's accurate views of the Covid -19 vaccine. The performance test results of the two methods show that the performance of the Naive Bayes Classifier method (Accuracy 72.88%, Precision 43.49%, 
Recall 54.95%, and average performance 57.10%) is higher than the average performance of the Support Vector Machine method (Accuracy 77.00% , Precision 75.00%, Recall 7.70%, and average 
performance 53.52%). Based on the average performance value of the Naive Bayes Classifier method, it can be considered more efficient than the Support Vector Machine method 

Keywords: Covid -19 Vaccination Vector Machine
 
1. PENDAHULUAN  
Akhir-akhir ini masyarakat dihebohkan dengan adanya virus baru dari Wuhan, China yaitu virus corona atau disebut COVID -19 (Corona Virus Desease 2019) . COVID -19 telah memakan korban jiwa di Indonesia hingga mencapai 157.754 jiwa. Melihat pesatnya penyebaran Covid-19 dan bahaya yang akan muncul jika tidak segera ditangani akan sangat berdampak buruk  bagi suatu Negara. Telah banyak dilakukan beberapa cara oleh pemerintah, institusi, hingga kalangan masyarakat untuk memutus rantai penyebaran virus corona. S alah satu cara yang sangat mungkin untuk  mencegah penyebaran virus ini dengan men erapkan protokol kesehatan yaitu 5M (M encuci tangan, Memakai masker, Menjaga jarak, Menjauhi  kerumun an dan Mengurangi Mobilitas), tidak hanya menerapkan 5M tetapi pemerintah mengajak ma syarakat untuk melakuk an vaksin Covid-19 supaya 
adanya herd immunity atau k ekebalan kelompok terdapat virus Covid-19, Sehingga pemerintah Indonesia saat ini sudah meng giatkan program vaksinasi kepada masyarakat Kemenkes. Kegiatan vaksinasi  haruslah memp ertimb angkan segala aspek, mulai dari aspek kelayakan vaksin yang akan digunakan, resiko pasca pemakaian, sampai tah apan dan prosedur dari pemberian vaksin hingga nantinya sampai ke masyarakat. Semua itu haruslah 
dipertimbangkan secara terperinci agar kegiatan vaksinasi dapat berjalan dengan baik dan terhindar  dari hal-hal yang jus tru akan merugikan, tidak hanya itu program vaksinasi  juga harus memp ertimban gkan berbagai masukan di ant aranya adalah me lihat respon dan opini ma syarakat terhadap program vaksinasi  yang saat ini sedang berjalan[1].  Dengan adanya hal ini membuat kebanyakan orang merasa was-was dan resah bahkan ketakutan dengan adanya virus ini. Selain itu penelitian dan produksi vaksin dilakukan dalam waktu yang dapat dibilang singkat membuat warga ragu untuk melakukan vaksin. Hal ini  juga dikarenakan sempat beredar kasus efek samping vaksin yang mengganggu kesehatan bahkan meninggal. Sehingga membuat masyarakat umum ingin mengungkapkan pendapat, aspirasi dan kritikan, namun keterbatasan waktu dan ruang membuat aspirasi masyarakat tida k tersampaikan. Dengan adanya jejaring sosial masyarakat umum dapat mengungkapkan segala hal yang ada contohnya seperti twitter [2], [3]. Setiap twit dari netizen  tidak mengandung makna yang selaras, sehingga perlu dilakukan analisis terhadap opini netizen  di twitter  mengenai COVID -19 denga n klasifikasi positif dan negatif. Hal tersebut menunjukkan adanya peluang sumber data yang sangat besar yang dapat dimanfaatkan untuk  menghasilkan suatu knowledge yang bermanfaat[4]â€“[6]. Pemanfaatan data yang bersumber dari media  sosial merupakan suatu terobos an baru untuk  dijadikan sebagai alternatif sumb er data. Analisis sentimen merupakan cara mengumpulkan pendapat khalayak menggunakan jejaring sosial yang di dalamnya mengandung pelayanan umum, serta isu terkini. Analisis sentimen dapat digunakan untuk melakukan evaluasi suatu kinerja pelayanan dan sebagainya . Jenis analisis sentimen yang sering digunakan dalam kalangan penelitian yaitu, 
analisis sentimen dalam bentuk dokumen atau kalimat. Terdapat teks mining  yang dapat bekerja dalam komputer dengan tujuan mengolah informasi lama secara eksplisit sehingga menghasilkan temuan informasi baru [7]. Dalam penjelasan latar belakang diatas maka penulis akan melakukan suatu perbandingan antara metode Naive Bayer Classifier dan Support Vector Machine  untuk mengetahui metode mana yang lebih efisien dalam mengetahui pandangan akurasi masyarakat terhadap vaksin Covid -19. Metode Support 
Vector Machine  bekerja dengan membagi dua kelompok data menggunakan fungsi linear dalam sebap ruang fitur berdimensi tin ggi dengan proses menemukan garis pemisah (hyperlane) terbaik sehingga dapat menemukan ukuran margin yang maksimal antara ruang input dengan ruang ciri menggunakan kaidah kernel [8]. 

2. METODE  PENELITIAN  
Untuk mempermudah pelaksanaan penelitian maka dibua t kerangka tahapan penelitian agar penelitian dapat dilakukan secara berurutan sehingga lebih efektif dan efisien karena penelitian dilakukan secara terstruktur [9], [10] . Kerangka tahapan penelitian ini dibuat dan disesuaikan dengan langkah -langkah proses Text Mining. Kerangka Tahapan Penelitian dapat dilihat pada Gambar 1. 
Gambar 1 Kerangka Penelitian  
Berikut ini merupakan penjelasan tahapan -tahapan dari kerangka penelitian diatas:  
1. Crawling Data , yaitu mencari data twitter berisi opini masyarakat yang mengandung unsur komentar positif maupun negatif terhadap vaksin Covid -19. 
Gambar 2 . Proses Crawling Data  
2. Labeling, pemberian label terhadap crawling data  pelabelan ini bertujuan untuk menentukan data yang akan diklasifikasikan kedalam beberapa kelas klasifikasi, label yang telah ditentukan yaitu Sentimen Positif dan Sentimen Negatif.  
Gambar 3 . Proses Labeling Craw ling Data   
3. Pre-Processing , melakukan Cleansing, Case Folding, Tokenizing, dan Stemming  untuk menghasilkan data bersih.    
Gambar 4 Proses Pre-proccessing   
4. Ekstrasi Fitur, melakukan perhitungan frekuensi relatif dari suatu kata yang muncul menggunakan Algoritma TF -IDF, Tahapan dimana memberikan pada setiap kata dengan menggunkan Algoritma Trem Frequensi  Invert Document Frequency    
Gambar 5 . Proses Ekstrasi   
Sampel data ter sebut selanjutnya akan dilakukan perhitungan frekuensi relatif dari suatu kata yang muncul pada setiap kelas/dokumen.  
Gambar 6 Proses Ekstrasi  
Berdasarkan gambar diatas dapat diketahui bahwa jumlah dokumen ada 5 yaitu D1, D2, D3, D4, dan D5. Sebelum me lakukan perhitungan TF-IDF kita akan mengitung frekuensi kemunculan kata dalam setiap dokumen. Berikut ini tabel kemunculan angka dalam setiap dokumen.  
Tabel 1 Proses TF-IDF  
Persamaan yang digunakan untuk menghitung TF-IDF adalah sebagai berikut:  
ð‘‡ð¹âˆ’ð¼ð·ð¹ (ð‘‘,ð‘¡)=ð‘‡ð¹(ð‘‘,ð‘¡)Ã—ð¼ð·ð¹ (ð‘¡) 
Keterangan:  
t = kata 
d = dokumen  
Dimana:  
ð‘‡ð¹(ð‘‘,ð‘¡)=ð‘—ð‘¢ð‘šð‘™ð‘Ž â„Ž ð‘˜ð‘Žð‘¡ð‘Ž  ð‘¡ ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘
ð‘¡ð‘œð‘¡ð‘Žð‘™  ð‘˜ð‘Žð‘¡ð‘Ž  ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘ 
ð¼ð·ð¹ (ð‘¡)=log (ð‘¡ð‘œð‘¡ð‘Žð‘™  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘
ð‘—ð‘¢ð‘šð‘™ð‘Ž â„Ž ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘¦ð‘Žð‘›ð‘”  ð‘šð‘’ð‘›ð‘”ð‘Žð‘›ð‘‘ð‘¢ð‘›ð‘”  ð‘˜ð‘Žð‘¡ð‘Ž  ð‘‘) 
a. Menghitung Nilai TF  
Pertama akan menghitung ni lai ð‘‡ð¹(ð‘‘,ð‘¡) kata per kata. Berikut ini merupakan perhitungan nilai ð‘‡ð¹(ð‘‘,ð‘¡): 
1) Kata â€œdaftarâ€   
Pada D1  
ð‘‡ð¹(ð‘‘,ð‘¡)=ð‘—ð‘¢ð‘šð‘™ð‘Ž â„Ž ð‘˜ð‘Žð‘¡ð‘Ž  ð‘¡ ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘
ð‘¡ð‘œð‘¡ð‘Žð‘™  ð‘˜ð‘Žð‘¡ð‘Ž  ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘=1
3=0.3333 
Pada D2  
ð‘‡ð¹(ð‘‘,ð‘¡)=ð‘—ð‘¢ð‘šð‘™ð‘Ž â„Ž ð‘˜ð‘Žð‘¡ð‘Ž  ð‘¡ ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘
ð‘¡ð‘œð‘¡ð‘Žð‘™  ð‘˜ð‘Žð‘¡ð‘Ž  ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘=0
3=0.00 
Pada D3  
ð‘‡ð¹(ð‘‘,ð‘¡)=ð‘—ð‘¢ð‘šð‘™ð‘Ž â„Ž ð‘˜ð‘Žð‘¡ð‘Ž  ð‘¡ ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘
ð‘¡ð‘œð‘¡ð‘Žð‘™  ð‘˜ð‘Žð‘¡ð‘Ž  ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘=0
7=0.00 
Pada D4  
ð‘‡ð¹(ð‘‘,ð‘¡)=ð‘—ð‘¢ð‘šð‘™ð‘Ž â„Ž ð‘˜ð‘Žð‘¡ð‘Ž  ð‘¡ ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘
ð‘¡ð‘œð‘¡ð‘Žð‘™  ð‘˜ð‘Žð‘¡ð‘Ž  ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘=0
12=0.00 
Pada D5  
ð‘‡ð¹(ð‘‘,ð‘¡)=ð‘—ð‘¢ð‘šð‘™ð‘Žâ„Ž ð‘˜ð‘Žð‘¡ð‘Ž  ð‘¡ ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘
ð‘¡ð‘œð‘¡ð‘Žð‘™  ð‘˜ð‘Žð‘¡ð‘Ž  ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘=0
10=0.00 
2) Kata â€œvaksinâ€  
Pada D1  
ð‘‡ð¹(ð‘‘,ð‘¡)=ð‘—ð‘¢ð‘šð‘™ð‘Ž â„Ž ð‘˜ð‘Žð‘¡ð‘Ž  ð‘¡ ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘
ð‘¡ð‘œð‘¡ð‘Žð‘™  ð‘˜ð‘Žð‘¡ð‘Ž  ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘=1
3=0.3333 
Pada D2  
ð‘‡ð¹(ð‘‘,ð‘¡)=ð‘—ð‘¢ð‘šð‘™ð‘Ž â„Ž ð‘˜ð‘Žð‘¡ð‘Ž  ð‘¡ ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘
ð‘¡ð‘œð‘¡ð‘Žð‘™  ð‘˜ð‘Žð‘¡ð‘Ž  ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘=1
3=0.3333 
Pada D3  
ð‘‡ð¹(ð‘‘,ð‘¡)=ð‘—ð‘¢ð‘šð‘™ð‘Ž â„Ž ð‘˜ð‘Žð‘¡ð‘Ž  ð‘¡ ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘
ð‘¡ð‘œð‘¡ð‘Žð‘™  ð‘˜ð‘Žð‘¡ð‘Ž  ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘=1
7=0.1429 
Pada D4  
ð‘‡ð¹(ð‘‘,ð‘¡)=ð‘—ð‘¢ð‘šð‘™ð‘Ž â„Ž ð‘˜ð‘Žð‘¡ð‘Ž  ð‘¡ ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘
ð‘¡ð‘œð‘¡ð‘Žð‘™  ð‘˜ð‘Žð‘¡ð‘Ž  ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘=1
12=0.0833 
Pada D5  
ð‘‡ð¹(ð‘‘,ð‘¡)=ð‘—ð‘¢ð‘šð‘™ð‘Ž â„Ž ð‘˜ð‘Žð‘¡ð‘Ž  ð‘¡ ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘
ð‘¡ð‘œð‘¡ð‘Žð‘™  ð‘˜ð‘Žð‘¡ð‘Ž  ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘=2
10=0.2000 
3) Kata â€œsekarangâ€  
Pada D1  
ð‘‡ð¹(ð‘‘,ð‘¡)=ð‘—ð‘¢ð‘šð‘™ð‘Ž â„Ž ð‘˜ð‘Žð‘¡ð‘Ž  ð‘¡ ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘
ð‘¡ð‘œð‘¡ð‘Žð‘™  ð‘˜ð‘Žð‘¡ð‘Ž  ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘=1
3=0.3333 
Pada D2  
ð‘‡ð¹(ð‘‘,ð‘¡)=ð‘—ð‘¢ð‘šð‘™ð‘Ž â„Ž ð‘˜ð‘Žð‘¡ð‘Ž  ð‘¡ ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘
ð‘¡ð‘œð‘¡ð‘Žð‘™  ð‘˜ð‘Žð‘¡ð‘Ž  ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘=0
3=0.0000 
Pada D3  
ð‘‡ð¹(ð‘‘,ð‘¡)=ð‘—ð‘¢ð‘šð‘™ð‘Ž â„Ž ð‘˜ð‘Žð‘¡ð‘Ž  ð‘¡ ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘
ð‘¡ð‘œð‘¡ð‘Žð‘™  ð‘˜ð‘Žð‘¡ð‘Ž  ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘=0
7=0.0000 
Pada D4  
ð‘‡ð¹(ð‘‘,ð‘¡)=ð‘—ð‘¢ð‘šð‘™ð‘Ž â„Ž ð‘˜ð‘Žð‘¡ð‘Ž  ð‘¡ ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘
ð‘¡ð‘œð‘¡ð‘Žð‘™  ð‘˜ð‘Žð‘¡ð‘Ž  ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘=0
12=0.0000 
Pada D5  
ð‘‡ð¹(ð‘‘,ð‘¡)=ð‘—ð‘¢ð‘šð‘™ð‘Ž â„Ž ð‘˜ð‘Žð‘¡ð‘Ž  ð‘¡ ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘
ð‘¡ð‘œð‘¡ð‘Žð‘™  ð‘˜ð‘Žð‘¡ð‘Ž  ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘=0
10=0.0000 
4) Kata â€œsegeraâ€  
Pada D1  
ð‘‡ð¹(ð‘‘,ð‘¡)=ð‘—ð‘¢ð‘šð‘™ð‘Ž â„Ž ð‘˜ð‘Žð‘¡ð‘Ž  ð‘¡ ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘
ð‘¡ð‘œð‘¡ð‘Žð‘™  ð‘˜ð‘Žð‘¡ð‘Ž  ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ ð‘¢ð‘šð‘’ð‘›  ð‘‘=0
3=0.0000 
Pada D2  
ð‘‡ð¹(ð‘‘,ð‘¡)=ð‘—ð‘¢ð‘šð‘™ð‘Ž â„Ž ð‘˜ð‘Žð‘¡ð‘Ž  ð‘¡ ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘
ð‘¡ð‘œð‘¡ð‘Žð‘™  ð‘˜ð‘Žð‘¡ð‘Ž  ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘=1
3=0.3333 
Pada D3  
ð‘‡ð¹(ð‘‘,ð‘¡)=ð‘—ð‘¢ð‘šð‘™ð‘Ž â„Ž ð‘˜ð‘Žð‘¡ð‘Ž  ð‘¡ ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘
ð‘¡ð‘œð‘¡ð‘Žð‘™  ð‘˜ð‘Žð‘¡ð‘Ž  ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ ð‘šð‘’ð‘› ð‘‘=0
7=0.0000 
Pada D4  
ð‘‡ð¹(ð‘‘,ð‘¡)=ð‘—ð‘¢ð‘šð‘™ð‘Ž â„Ž ð‘˜ð‘Žð‘¡ð‘Ž  ð‘¡ ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘
ð‘¡ð‘œð‘¡ð‘Žð‘™  ð‘˜ð‘Žð‘¡ð‘Ž  ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘=0
12=0.0000 
Pada D5  
ð‘‡ð¹(ð‘‘,ð‘¡)=ð‘—ð‘¢ð‘šð‘™ð‘Ž â„Ž ð‘˜ð‘Žð‘¡ð‘Ž  ð‘¡ ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘
ð‘¡ð‘œð‘¡ð‘Žð‘™  ð‘˜ð‘Žð‘¡ð‘Ž  ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘=0
10=0.0000 
5) Kata â€œmenyusulâ€  
Pada D1  
ð‘‡ð¹(ð‘‘,ð‘¡)=ð‘—ð‘¢ð‘šð‘™ð‘Ž â„Ž ð‘˜ð‘Žð‘¡ð‘Ž  ð‘¡ ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘
ð‘¡ð‘œð‘¡ð‘Žð‘™  ð‘˜ð‘Žð‘¡ð‘Ž  ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘=0
3=0.0000 
Pada D2 
ð‘‡ð¹(ð‘‘,ð‘¡)=ð‘—ð‘¢ð‘šð‘™ð‘Ž â„Ž ð‘˜ð‘Žð‘¡ð‘Ž  ð‘¡ ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘
ð‘¡ð‘œð‘¡ð‘Žð‘™  ð‘˜ð‘Žð‘¡ð‘Ž  ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘=1
3=0.3333 
Pada D3  
ð‘‡ð¹(ð‘‘,ð‘¡)=ð‘—ð‘¢ð‘šð‘™ð‘Ž â„Ž ð‘˜ð‘Žð‘¡ð‘Ž  ð‘¡ ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘
ð‘¡ð‘œð‘¡ð‘Žð‘™  ð‘˜ð‘Žð‘¡ð‘Ž  ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘=0
7=0.0000 
Pada D4  
ð‘‡ð¹(ð‘‘,ð‘¡)=ð‘—ð‘¢ð‘šð‘™ð‘Ž â„Ž ð‘˜ð‘Žð‘¡ð‘Ž  ð‘¡ ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘
ð‘¡ð‘œð‘¡ð‘Žð‘™  ð‘˜ð‘Žð‘¡ð‘Ž  ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘=0
12=0.0000 
Pada D5  
ð‘‡ð¹(ð‘‘,ð‘¡)=ð‘—ð‘¢ð‘šð‘™ð‘Ž â„Ž ð‘˜ð‘Žð‘¡ð‘Ž  ð‘¡ ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘
ð‘¡ð‘œð‘¡ð‘Žð‘™  ð‘˜ð‘Žð‘¡ð‘Ž  ð‘ð‘Žð‘‘ð‘Ž  ð‘‘ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘‘=0
10=0.0000 
Begitu seterusnya perhitungan nilai ð‘‡ð¹(ð‘‘,ð‘¡) untuk masing -masing kata. Untuk hasil 
seluruh perhitungan nilai ð‘‡ð¹(ð‘‘,ð‘¡) dapat dilihat pada tabel dibawah ini:  
Tabel  2. Hasil TF  
5. Klasifikasi data akan dilakukan ke dalam kelas Sentimen Positif dan Sentimen Negatif dengan menggunakan Algoritma Naive Bayes Classifier dan Support Vector Machine  Klasifikasi, melakukan penggelompokan tweet berdasarkan kelas klasifikasi 
yang ditentukan.  
Tabel 3 . Proses Klasikasi Data  
6. Pengujian, melakukan pengukuran performa kedua algoritma dengan menghitung Accuracy, Recall, dan Precision.  
7. Hasil dari pengujian performa kedua metode akan dibandingkan untuk melihat kemampuan kedua metode.  
 
3. HASIL  DAN  PEMBAHASAN  
Analisis sentimen dilakukan terhadap tanggapan pengguna Twitter yang diambil dengan cara crawling  menggunaan API. Selanjutnya seluruh isi tweet diberikan label Positif dan Negatif. Pemberian label ini dilakukan bersama Dosen Universitas Teknokrat Indonesia yaitu Bapak Auliya Rahman. Penerapan kedua metode pada penelitian ini menggunakan tools Rapid Miner. Data yang digunakan pada penelitian ini adalah data dengan format teks sehingga sebelum membentuk model pengujian pada tools akan dilakukan nor malisasi 
data menggunakan metode TF-IDF. Untuk melakukan proses TF -IDF pada Rapid Miner digunakan operator -operator sebagai berikut.  
Gambar 7 TF-IDF 
Setelah memilih metode TF -IDF klik dua kali pada operator Documents from Data  untuk masuk ke dalam preprocessing . 
Gambar 8 Pre-proccessing  
Untuk menerapkan dan melakukan pengujian sehingga terbentuk confusion matrix  dari pengujian data yang telah di preprocessing gunakan operator X-Validation. X -Validation atau sering dikenal sebagai cross validation disini merupakan metode pengujian klasifikasi yang dapat mengukur performa penerapan metode Naive Bayes Classifier dan Support Vector Machine . Cross Validation digunakan karena pengujian dilakukan kepada seluruh data sebanyak n-fold. Sehingga seluruh data berperan sebagai data training dan data testing. Pada pengujian ini dilakukan dalam 10 fold atau default dari Rapid Minner.  Langkah yang dilakukan adalah memasukkan operator X-Validation ke dalam process dan hubungkan connector dengan operator sebelumnya dan ke result seperti pada gambar 9.  
Gambar 9 Cross Validation  
Implementasi Naive Bayes Classifier  
Untuk menerapkan metode Naive Bayes Classifier dilakukan dengan double click pada operator X-Validation sehingga masuk ke halaman Validation. Pada tab Training masukkan operator dari metode Naive Bayes lalu hubungkan connector training dan connector model . Pada operator inilah data akan di training dengan metode Naive Bayes Classifier . Pada tab Testing masukkan operator Apply Model untuk membaca dan melakukan pengujian terhadap training model yang telah terbentuk dari Naive Bayes Classifier lalu hubungkan connector model dan connector testing . Selanjutnya masukkan operator Performace untuk mengukur dan menampilkan hasil performa meliputi accuracy, precision, dan recall dari pengujian yang dilakukan.  
Gambar 10 Naive Bayes Classifier  
Implementasi Support Vector Machine  
Untuk menerapkan metode Support Vector Machine dilakukan dengan double click pada operator X-Validation sehingga masuk ke halaman Validation. Pada tab Training masukkan operator dari metode Naive Bayes lalu hubungkan connector training dan connector model . Pada operator inilah data akan di training dengan metode Support Vector Machine . Pada tab Testing masukkan operator Apply Model untuk membaca dan melakukan pengujian 
terha dap training model yang telah terbentuk dari Support Vector Machine lalu hubungkan connector model dan connector testing . Selanjutnya masukkan operator Performace untuk mengukur dan menampilkan hasil performa meliputi accuracy, precision, dan recall dari pengujian yang dilakukan.  
Gambar 11 Support Vector Machine  
Setelah membentuk model dari kedua metode didapatkan hasil confusion matrix yang berbeda. Hal ini menunjukkan performa dari kedua metode tersebut pun memiliki perbedaan. Berikut ini merupakan performance vector dari metode Naive Bayes Classifier .  
Gambar 12 Performance Vector Naive Bayes  
Berikut ini merupakan performance vector dari metode Support Vector Machine . 
Gambar 13 Performance Vector Support Vector Machine  
Hasil performance vector dari algoritma Naive Bayes Classifier menunjukan bahwa algoritma ini mampu mengelompokkan data dengan ketepatan klasifikasi dan hasil pengujian data training mencapai nilai 72.88%. Nilai precision menunjukkan bahwa tingkat 
ketepatan informasi yang dihasilkan oleh algoritma Naive Bayes Classifier dengan klasifikasi sentimen yang diminta mencapai nilai 43.49% dan keberhasilan algoritma Naive Bayes Classifier dalam menemukan/mengklasifikasi data mencapai nilai 54.95%.  Sedangkan hasil performance vector dari algoritma Support Vector Machine 
menunju kan bahwa algoritma ini mampu mengelompokkan data dengan ketepatan klasifikasi dan hasil pengujian data training mencapai nilai 77.88%. Nilai precision menunjukkan bahwa tingkat ketepatan informasi yang dihasilkan oleh algoritma Support Vector Machine dengan klasifikasi sentimen yang diminta mencapai nilai 75.00% dan keberhasilan algoritma Support Vector Machine dalam menemukan/mengklasifikasi data mencapai nilai 7.70%.  
 
4. KESIMPULAN  
Pembahasan yang telah dilakukan diatas dapat ditarik kesimpulan dari penelitian ini. Dimana kesimpulan dari penelitian yang telah dilakukan antara lain analisis sentimen tweet menujukkan jumlah Sentimen Positif sebanyak 790 tweet  dan jumlah sentimen negatif 
sebanyak 361 tweet. Maka dikat akan bahwa lebih banyak pengguna Twitter yang memberikan respon pos itif terhadap kegiatan Vaksin Covid -19. Penerapan metode Naive Bayes Classifier  menunjukkan hasil performance vector dengan nilai accuracy 72.88%, precision 43.49% dan recall 54.95%.  Penera pan metode Support Vector Machine menunjukkan hasil pengujian dengan nilai Accuracy 77.88%, Precision 75.00% , dan Recall 7.70%. Metode Naive Bayes Classifier memiliki kemampuan yang lebih baik dalam menganalisis sentimen Twitter dengan nilai rata -rata perf ormance 57.10% dibandingkan dengan Support Vector Machine hanya mencapai rata-rata performance 40,77%.  
 
5. REFERENCES  
[1] R. I. Kemenkes, â€œPedoman Kesiapsiagaan Menghadapi Coronavirus Disease (COVID -19),â€ Direkorat Jenderal Pencegah dan Pengendali Penyakit , 2020.  
[2] U. Yaqub, N. Sharma, R. Pabreja, S. A. Chun, V. Atluri, and J. Vaidya, â€œLocation -based sentiment analyses and visualization of Twitter election data,â€ Digit. Gov. Res. Pract. , vol. 1, no. 2, pp. 1 â€“19, 2020.  
[3] D. Darwis, E. S. Pratiwi, and A. F. O. Pasaribu, â€œPenerapan Algoritma Svm Untuk Analisis Sentimen Pada Data Twitter Komisi Pemberantasan Korupsi Republik Indonesia,â€ Edutic -Scientific J. Informatics Educ. , vol. 7, no. 1, 2020.  
[4] R. R. SURYONO and B. Indra, â€œP2P Lending Sentiment Analysis in Indonesian Online,â€ 2020.  
[5] C. ColÃ³n -Ruiz, â€œSemi -Supervised Generative Adversarial Network for Sentiment Analysis of drug reviews.â€ Institute of Electrical and Electronics Engineers (IEEE), 2021, doi: 10.36227/techrxiv.17075054.  
[6] C. Du and L. Huang, â€œSentiment Analysis Method based on Piecewise Convolutional Neural Network and Generative Adversarial Network,â€ Intern ational Journal of Computers Communications & Control , vol. 14, no. 1. Agora University of Oradea, pp. 7â€“20, 2019, doi: 10.15837/ijccc.2019.1.3374.  
[7] I. Ahmad, H. Sulistiani, and H. Saputra, â€œThe Application Of Fuzzy K -Nearest Neighbour Methods for A Stu dent Graduation Rate,â€ Indones. J. Artif. Intell. Data Min., vol. 1, no. 1, pp. 47 â€“52, 2018.  
[8] D. Alita, Y. Fernando, and H. Sulistiani, â€œImplementasi Algoritma Multiclass SVM pada Opini Publik Berbahasa Indonesia di Twitter,â€ J. Tekno Kompak , vol. 14, n o. 2, pp. 86 â€“91, 2020.  
[9] S. Setiawansyah, Q. J. Adrian, and R. N. Devija, â€œPenerapan Sistem Informasi Administrasi Perpustakaan Menggunakan Model Desain User Experience,â€ J. Manaj. Inform. , vol. 11, no. 1, pp. 24 â€“36, 2021.  
[10] M. N. D. Satria, â€œApplicat ion of SAW in the Class Leader Selection Decision Support System,â€ Chain J. Comput. Technol. Comput. Eng. Informatics , vol. 1, no. 1, pp. 27 â€“31, 2023.  ",Sentimen Analisis,"Naive Bayes Classifier, Support Vector Machine",data twitter berisi opini masyarakat,"accuracy, precision, recall"
Sentimen Analisis Informasi Covid-19 menggunakan Support Vector Machine dan Naive Bayes,"Sentimen Analisis Informasi Covid-19 menggunakan Support Vector Machine dan Naive Bayes

Ratino1, Noor Hafidz2, Sita Anggraeni3, Windu Gata4

Abstrak
Informasi saat ini banyak disampaikan melalui media sosial . Salah satu media sosial yang saat ini banyak digunakan adalah instagram. Berbagai sentimen masyarakat disampaikan melalui komentar pada media sosial instagram terhadap info rmasi COVID-19. Maka dari itu
perlu dilakukan sentimen analisis untuk mengetahui sentim en dari setiap komentar. Adapaun algoritma klasifikasi yang digunakan yaitu NaÃ¯ve Bayes den gan hasil akurasi 78,02% dan AUC 0,714, sedangkan Support Vector Machine menghasilkan akur asi sebesar 80,23% dan AUC 0,904. Memiliki selisih akurasi 2,21%. Setelah di optimasi dengan operator Particle Swarm Optimization, algoritma Naive Bayes (PSO) menghasilkan ak urasi sebesar 79,07% dan AUC 0,729, sedangkan algoritma Support Vector Machine (PSO) me nghasilkan akurasi sebesar 81,16% dan AUC 0,903. Memiliki selisih akurasi sebesar 2,09 %. Hasil pengujian algoritma, Support Vector Machine berbasis PSO maupun tidak, selalu da pat menghasilkan akurasi yang lebih tinggi.

Kata kunci  Covid-19, Naive Bayes, Support Vector Machine, Particle Swarm Optimization.

Abstract
Information is now widely conveyed through social media. One of the social media that is currently widely used is Instagram. Various public senti ments were conveyed through comments on social media Instagram about information COVID -19. Therefore it is necessary to
do sentiment analysis to find out the sentiment of each comment. The classification algorithm used is Naive Bayes with the results of accuracy of 78,02% and AUC 0,714, while the Support Vector Machine produces an accuracy of 80,23% and AUC 0,904. Have accuracy differences 2.21%. After optimization with Particle Swarm Optimizatio n operator. Naive Bayes (PSO) algorithm produces accuracy 79,07% and AUC 0,729, while the Support Vector Machine (PSO) algorithm produces an accuracy of 81,16% and AUC 0,903. Have accuracy differences 2,09%. Algorithm test results, support vector machine with PSO or w ithout PSO, can always produce
higher accuracy

Keywords Covid-19, Naive Bayes, Support Vector Machine, Particle Swarm Optimization.

1. PENDAHULUAN
Organisasi kesehatan Dunia menyatakan virus baru bermunculan yang merupakan masalah bagi kesehatan masyarakat. Pada Desember 2019 sebu ah epidemi kasus pernafasan Orendah terdeteksi. World Health Organization (WHO) menyatakan penyakit tersebut disebabkan oleh coronavirus (CoV) baru. CoV baru ini adalah coronavirus 2019 (COVID-19) [1]. Virus COVID-19 ini telah menyebar dengan cepat hampir diseluruh d unia. Meskipun penyebarannya cepat diseluruh dunia, namun karakteristik penyakit pernafasan akut 2019-nCoV sebagian masih belum jelas [2]. Informasi dan cara pencegahan virus ini pun sudah tersebar di berbagai media sosial. Media sosial yang saat ini banyak digunakan salah satunya ad alah Instagram. Instagram merupakan media yang kerap digunakan sebagai sarana berbagi informasi tentang berbagai hal. Hal ini karena Instagram menjadi media yang populer saat ini [3]. Dengan berbagai pengguna dari berbagai dunia dari mulai anak-anak hingga orang dewasa turut serta dalam popularitas
Instagram. Analisis setimen adalah proses mengklasifikasi dokumen teks yang berupa opini berdasarkan sentimen untuk menentukan apakah suatu tangga pan tertentu bersifat positif, netral atau negatif [4]. Analisis sentimen juga merupakan proses memahami, mengekstrak dan mengolah data tekstual secara otomatis untuk mendapatkan informasi sentimen yang terkandung dalam suatu kalimat [5]. Algoritma yang digunakan dalam melakukan klasifikasi pada penelitian ini yaitu Support Vector Machine dan Naive Bayes . Kelebihan dari Algoritma Support Vector Machine yaitu mampu mengidentifikasi hyperplane terpisah yang memaksimalkan margin antara dua kelas yang berbeda [6]. Namun algoritma Support Vector Machine memiliki kekurangan yaitu pada masalah pemilihan fitur yang sesuai. Particle Swarm Optimization (PSO) ditambahkan
untuk meningkatkan kinerjanya. Pada Berbagai penelitian tentang analisis dokumen tekstual paling banyak adalah menggunakan metode Naive Bayes .Naive bayes merupakan algoritma yang populer karena kemudahan penggunannya [7]. Algoritma NaÃ¯ve Bayes telah terbukti bekerja dengan memuaskan dibanyak domain [8]. Penelitian terkait yang membahas tentang analisis sentime n dengan menggunakan algoritma-algoritma klasifikasi telah banyak dilakukan. Penelitian yang dilakukan oleh Rofiqoh dan kawan-kawan dengan topik tingkat kepuasan telekomunik asi seluler Indonesia, penelitian tersebut menggunakan algoritma Support Vector Machine dengan Luxicon Based Feature sebagai pembaharuan fiturnya [9].
Penelitian lain yang dilakukan oleh Siswanto dan kawan-kawan dengan topik Analisis Klasifikasi komentar menggunakan Support Vector Machine dan Naive Bayes . Penelitian tersebut menerapkan dua algoritma untuk menguji akurasinya. Hasil akurasi Support Vector Machine sebesar 95,59% dan Naive Bayes sebesar 93,00%. Penelitian tersebut menunjukan bahwa Support Vector Machine memiliki akurasi yang lebih baik [10]. Penelitian lain yang dilakukan Buntoro dan kawan-kawan den gan judul Anlisis Sentimen Calon Gubernur DKI Jakarta 2017 di Twitter, peneli tian tersebut menggunakan algoritma Naive Bayes dan Support Vector Machine dengan menggunakan preprocessing tokenisasi, cleansing dan filtering [5]. Algoritma Support Vector Machine dengan menggunakan Particle Swarm Optimization pernah dilakukan oleh Wahyudi dan Kristiyanti dengan topik ulasan produk smartphone. Hasil akurasi Support Vector Machine adalah 82,00%. Sementara Support Vector Machine berbasis Particle Swarm Optimization (PSO) memperoleh tingkat akurasi 94,50% [11].Ratino, Sentimen Analisis Informasi Covid-19 menggunakan Support Vector â€¦â€¦ â€¦3

2. METODE PENELITIAN
Pada penelitian ini menggunakan metode Support Vector Machine dan Naive Bayes dengan penambahan Particle Swarm Optimization (PSO) untuk menghasilkan akurasi terbaik dalam menganalisa komentar Instragram terhadap informasi berkaitan dengan COVID-19. Adapun kerangkan berfikir pada penelitian ini seperti pada gamabar berikut:
Gambar 1. Kerangka Berfikri
2.1. Pengumpulan Data
Data yang diperoleh merupakan sebuah data yang diambil dari komentar pengguna Instagram. Penggumpulan data komentar Instagram didapatkan melalu sebuah aplikasi Instragram Scraper.
2.2. Preprocessing
Preprocessing merupakan tahap awal yang diambil dalam pros es pelatihan. Tujuan dari preprocessing yaitu menghindari dari data yang kurang sempurna, gangguan pada data dan data-
data yang tidak konsisten [12].
2.3. Feature Selection
Setelah tahap preprocessing dan pelabelan, pada tahan selenjutnya adalah melakukan Feature Selection. Dalam tahap feature selection peneliti an ini menggunakan algoritma Particle Swarm Optimization (PSO). Particle Swartm Optimization ad alah metode optimisasi yang
diperkenalkan oleh Kennedy dan Eberhart pada tahun 1995 yang dimotifasi oleh perilaku cerdas dari beberapa kawanan hewan [13][14].
2.4. Algoritma Support Vector Machine
Support Vector Machine adlah algoritma untuk melakukan pre diksi dalam kasus klasifikasi maupun regresi [15]. Tingkat akurasi yang dihasilkan oleh SVM sangat bergantung terhadap pemilihan kernel dan parameter yang digunakan.
2.5. Algoritma Naive Bayes
Naive Bayes merupakan algoritma klasifikasi probabilistik berdasarkan teorima bayes [8]. Naive Bayes Clasification memiliki akurasi yang tinggi dan kecepatan yang tinggi saat diaplikasikan kedalam data yang besar.

3. HASIL DAN PEMBAHASAN
Pada bab ini akan menjelaskan proses yang dilakukan dalam pe nelitian ini. Adapun beberapa tahap yang dilakukan pada penelitian ini.
3.1. Pengumpulan Data
Dalam penelitian ini pengumpulan data mengambil dari Insta gram pada akun World Health Organization (WHO) dengan postingan berkisar tentang covid-19. Hasil Scrapping data berkstensi file csv. Data tersebut kemudian dirubah menjadi file excel untuk mempermudah pengolahan datanya pada aplikasi RapidMiner.
Gambar 2. Proses pengolahan data pada RapidMiner
Proses retrive yang berfungsi untuk mengimpor data dengan beberapa kriteria penilaian terhadap sentimen, tahap selanjutnya yaitu set role untuk menentukan label dan attribut. Dan dilanjutkan ke tahap map untuk merubah label yang bernilai true menjadi positif dan false menjadi negatif. Lalu melakukan konversi nominal to string dengan menggunakan operator nominal to text. Setelah terkonversi tahap selanjutnya yaitu melakukan preprocessing.
3.2. Preprocessing
Pada tahap preprocessing adalah proses untuk menyiapkan se buah data yang siap untuk dianalisa. Beberapa tahap preprocessing pada penelitian ini sebagai berikut.
a. Case Folding
Proses case folding adalah mengubah sebuah kalimat yang ter dapat huruf besar menjadi huruf kecil. Hal ini dilakukan agar terdapat keseragaman huruf. Data pada penelitian ini berseragaman membentuk huruf kecil.
Tabel1. Proses Case Folding
Sebelum Sesudah
STOP SMOKING NOW stop smoking now
b. Tokenisasi
Tokenisasi adalah proses memecah sebuah kalimat menjadi se buah kumpulan kata yang berdisi sendiri. Tokenisasi memecah teks yang semula kalim at menjadi beberapa kata.Tonisasi menghilangkan delimeter seperti titik(.), Koma( ,), spasi dan karakter angka pada kalimat tersebut. Ratino, Sentimen Analisis Informasi Covid-19 menggunakan Support Vector â€¦â€¦ â€¦5
Tabel 2. Proses Tokenisasi
Sebelum Sesudah
Thank you W.H.O thank you w h o
c. Tagging
Menghilangkan nama pengguna yang disebutkan didalam komen tar (@username), menghapus tanda hastag, menghapus karakter-karakter khusus seperti emoticon .
Tabel 3. Proses Tagging
Sebelum Sesudah
Only WHO could mess this message up
only who could mess this message up
@lchf_keto4lyfe @ichuzlife
@_thereal_coke Followfollow
3.3. Particle Swarm Optimization (PSO)
Setelah melalui preprocessing tahap selanjutnya adalah me lakukan pengoptimasian, diantaranya dengan meningkatkan bobot attribut terhadap semua attribut yang digunakan, menyeleksi attribut dan feature selection . PSO merupakan algoritma yang baik dan efektif dalam permasalahan optimasi, hal ini dikarenakan memiliki performa yang konsisten.
Gambar 4. Proses Optimasi
3.4. Proses Validasi
Pada proses validasi menggunakan operator cross validation dengan k-10 fold cross validation . Berikut operator yang digunakan pada aplikasi RapidMiner .
Gambar 5. Operator Cross Validation
Gambar 6. Parameter Cross Validation
Tujuannya adalah untuk menentukan nilai fungsi dari model y ang berhasil dilakukan ditahap sebelumnya. Didalam operator cross validation tersebut terdapat beberapa operasi diantaranya
sebagai berikut:
Gambar 7. Operator Cross Validation dengan algoritma SVM
Gambar 8. Operator Cros Validation dengan algoritma NB
3.5. Evaluasi
Pada penelitian ini menggunakan algoritma Support Vector Machine danNaive Bayes dalam melakukan sentimen, serta melakukan evaluasinya men ggunakan accuracy dan AUC (Area Under Curve ).
a. Support Vector Machine
Confusion matrik yang didapatkan dari hasil pemodelan dengan algoritma Supprt Vector Machine. Hasil akurasi yang didapat adalah 80,23%. Data negatif yang sesuai dengan prediksi negatif yaitu 268 data. Data Positif yang masuk prediksi negatif yaitu 30 data. Sedangkan data negatif yang masuk prediksi positif yaitu 140 data dan data positif yang sesuai prediksi positif yaitu 422 data.
Tabel 4. Hasil Akurasi Support Vector Machine
Accuracy : 80,23% +/- 5,05% (micro average : 80,23%
true negatif true positif class precision
prediksi negatif 268 30 89,93%
prediksi positif 140 422 75,09%
class recall 65,69% 93,36%
Kurva ROC hasil pemodelan dengan Support Vector Machine. Mendapatkan hasil dengan grafik Area Under Curve (AUC) sebesar 0,904. Ratino, Sentimen Analisis Informasi Covid-19 menggunakan Support Vector â€¦â€¦ â€¦7
Gambar 9. Grafik AUC Support Vector Machine
b. Naive bayes
Confusion matrik yang didapatkan dari hasil pemodelan dengan algoritma Naive Bayes . Hasil akurasi yang didapat adalah 78,02%. Data negatif yang sesuai dengan prediksi degatif yaitu 324 data. Data positif yang masuk prediksi neg atif yaitu 105 data.Sedangkan data negatif yang masuk prediksi positif yaitu 84 data dan positif yang sesuai prediksi positif yaitu 347 data.
Tabel 4. Hasil akurasi Naive Bayes
Accuracy : 78,02% +/- 5,66% (micro average : 78,02%
true negatif true positif class precision
prediksi negatif 324 105 75,52%
prediksi positif 84 347 80,51%
class recall 79,41% 76,77%
Kurva ROC hasil pemodelan dengan Support Vector Machine. Me ndapatkan hasil dengan grafik Area Under Curve (AUC) sebesar 0,714.
Gambar 10. Grafik AUV Naive Bayes
Sedangkan untuk akurasi dan AUC untuk algoritma Support Vector Machine danNaive bayes dengan tambahan Particle Swarm Optimization adalah sebagai berikut:
a.Support Vector Machine dengan Feature Selection
Confusion matrik yang didapatkan dari hasil pemodelan deng an algoritma Support Vector Machine berbasis Particle Swarm Optimization. Hasil akurasi yang didapat adalah 81,16%. Data negatif yang sesuai dengan prediksi neg atif yaitu 277 data. Data
Positif yang masuk prediksi negatif yaitu 31 data. Sedangkan data negatif yang masuk prediksi positif yaitu 131 data dan data positif yang sesuai prediksi positif yaitu 421 data.
Tabel 5. Akurasi SVM dengan Feature Selection
Accuracy : 81,16% +/- 3,46% (micro average : 81,16%
true false true true class precision
prediksi false 277 31 89,94%
prediksi true 131 421 76,27%
class recall 67,89% 93,14%
Kurva ROC hasil pemodelan dengan Support Vector Machine. Me ndapatkan hasil dengan grafik Area Under Curve (AUC) sebesar 0,903.
Gambar 11. Grafik AUC Support Vector Machine dengan Feature Selection
b.Naive Bayes dengan Feature Selection
Confusion matrik yang didapatkan dari hasil pemodelan dengan algoritma Naive Bayes berbasis Particle Swarm Optimization. Hasil akurasi yang didapat adalah 79,07%. Data negatif yang sesuai dengan prediksi negatif yaitu 324 data. Data positif yang masuk
prediksi negatif yaitu 97 data. Sedangkan data negatif yang masuk prediksi positif yaitu 83 data dan data positif yang sesuai prediksi positif yaitu 3 55 data. Ratino, Sentimen Analisis Informasi Covid-19 menggunakan Support Vector â€¦â€¦ â€¦9
Tabel 6. Akurasi Naive Bayes dengan Feature Selection
Accuracy : 79,07% +/- 3,99% (micro average : 79,07%
true false true true class precision
prediksi false 324 97 77,01%
prediksi true 83 355 81,05%
class recall 79,66% 78,54%
Kurva ROC hasil pemodelan dengan Naive Bayes. Mendapatkan h asil dengan grafik Area Under Curve (AUC) sebesar 0.729.
Gambar 12. Grafik AUC Naive Bayes dengan Feature Selection
Berdasarkan hasil penelitian, ada perbedaan nilai akurasi maupun AUC ketika membandingkan algoritma yang menggunakan particle Swarm Optimization (P SO) dengan algoritma tanpa PSO. Dimana algoritma yang ditambahakan PSO ada peningkatan aku rasi. Hasil pengujian dapat dilihat pada tabel berikut.
Tabel 7. Perbandingan akurasi dan AUC algoritma
NB SVM NB + PSO SVM + PSO
accuracy 78,02% 80,23% 79,07% 81,16%
AUC 0,714 0,904 0,729 0,903
Pada tabel 7 menunjukan bahwa algoritma Naive Bayes untuk data sejumlah 860 komentar Instagram, Menghasilkan akurasi sebesar 78,02% dan AUC 0,7 14. Sedangkan algoritma Support Vector Machine menghasilkan akurasi sebesar 80,23% dan AUC 0,904. Memiliki selisih akurasi sebesar 2,21%. Dan setelah dioptimasi dengan penambahan Particle Swarm Optimization untuk algoritma Naive Bayes menghasilkan akurasi sebesar 97,07% dan AUC 0,729. Sedangkan untuk Support Vector Machine menghasilkan akurasi sebesar 81,16% dan AUC 0,903. Sehingga didapatkan bahwa akurasi Support Vector Machine dengan penambahan Particle Swarm Optimization memiliki akurasi yang lebih tinggi dari algoritma yang lain .

4. KESIMPULAN
Dari hasil pembahasan dapat diambil beberapa kesimpulan se bagai berikut :
1.Support Vector Machine dan Naive Bayes dapat digunakan dalam menganalisa sentimen pada kolom komentar Instagram.
2. Analisis sentimen terhadap data komentar Instagram mengenai Covid-19 yang dilakukan dengan Support Vector Machine dengan nilai akurasi 80,23% dan Naive Bayes dengan nilai akurasi 78,02%. Dan hasil Support Vector Machine dengan Particle Swarm Optimization dengan nilai akurasi 81,16% dan Naive Bayes dengan
Particle Swarm Optimization dengan nilai akurasi 79,07%.
3. Hasil algoritma yang menggunakan Particle Swarm Optimization terbukti dapat meningkatkan nilai akurasi.
5. SARAN
Adapun saran untuk dapat dilakukan penelitinan selanjutny adalah:
1. Menggunakan algoritma K-NN atau Decision Tree untuk lebih banyak menguji algoritma.
2. Menggunakan metode Feature Selection yang lain, seperti Chi Square, Information Gain, Luxicon Based Feature, dan lain-lain agar dapat membandingkan hasilnya.

UCAPAN TERIMA KASIH
Penulis mengucapkan terima kasih kepada redaksi jurnal JUP ITER yang telah memberi kesempatan kepada penulis sehingga artikel ini dapat diter bitkan.

DAFTAR PUSTAKA
[1] M. Cascella, M. Rajnik, A. Cuomo, S. C, Dulebohn, and R. Di Napoli, â€œFeatures, Evaluation and Treatment Coronavirus (COVID-19).,â€ 2020, [Online]. Available: https://www.ncbi.nlm.nih.gov/pubmed/32150360.
[2] W. J. Guan et al. , â€œClinical Characteristics of Coronavirus Disease 2019 in China,â€ N.Engl. J. Med. , 2020, doi: 10.1056/NEJMoa2002032.
[3] W. A. Luqyana, I. Cholissodin, and R. S. Perdana, â€œAnalis is Sentimen Cyberbullying Pada Komentar Instagram dengan Metode Klasifikasi Support Vector Machine,â€ J. Pengemb. Teknol. Inf. dan Ilmu Komput. Univ. Brawijaya , 2018.
[4] S. Kurniawan, W. Gata, D. A. Puspitawati, N. -, M. Tabrani , and K. Novel, â€œPerbandingan Metode Klasifikasi Analisis Sentimen Tokoh Politik Pada Komentar Media Berita Online,â€ J. RESTI (Rekayasa Sist. dan Teknol. Informasi) , 2019, doi: 10.29207/resti.v3i2.935.
[5] G. A. Buntoro, â€œAnalisis Sentimen Calon Gubernur DKI Jakarta 2017 Di Twitter,â€Integer J. Maret , 2017.
[6] N. Yunita, â€œAnalisis Sentimen Berita Artis Dengan Menggunakan Algoritma Support Vector Machine dan Particle Swarm Optimization,â€ J. Sist. Inf. STMIK Antar Bangsa ,2016.
Ratino, Sentimen Analisis Informasi Covid-19 menggunakan Support Vector â€¦â€¦.11
[7] M. S. Hadna, P. I. Santosa, and W. W. Winarno, â€œStudi Liter atur Tentang Perbandingan Metode Untuk Proses Analisis Sentimen Di Twitter,â€ Semin. Nas. Teknol. Inf. dan Komun. , 2016.
[8] L. Dey, S. Chakraborty, A. Biswas, B. Bose, and S. Tiwari, â€œSentiment Analysis of Review Datasets Using NaÃ¯ve Bayesâ€˜ and K-NN Classifier,â€ Int. J. Inf. Eng. Electron. Bus., 2016, doi: 10.5815/ijieeb.2016.04.07.
[9] U. Rofiqoh, R. S. Perdana, and M. A. Fauzi, â€œAnalisis Sent imen Tingkat Kepuasan Pengguna Penyedia Layanan Telekomunikasi Seluler Indones ia Pada Twitter Dengan Metode Support Vector Machine dan Lexion Based Feature,â€ J. Pengemb. Teknol. Inf. dan Ilmu Komput. Univ. Brawijaya , 2017.
[10] Siswanto, Y. P. Wibawa, W. Gata, G. Gata, and N. Kusumawa rdhani, â€œClassification Analysis of MotoGP Comments on Media Social Twitter Using Al gorithm Support Vector Machine and Naive Bayes,â€ in Proceedings of ICAITI 2018 - 1st International
Conference on Applied Information Technology and Innovati on: Toward A New Paradigm for the Design of Assistive Technology in Smart Hom e Care , 2018, doi: 10.1109/ICAITI.2018.8686751.
[11] M. Wahyudi and D. A. Kristiyanti, â€œSentiment analysis o f smartphone product review using support vector machine algorithm-based particle swa rm optimization,â€ Journal of Theoretical and Applied Information Technology . 2016.
[12] S. Gusriani, K. D. K. Wardhani, and M. I. Zul, â€œAnalisis S entimen Terhadap Toko Online di Sosial Media Menggunakan Metode Klasifikasi Naive Bayes (Studi Kasus: Facebook Page BerryBenka),â€ 4th Appl. Bus. Eng. Conf. , 2016.
[13] M. R. Bonyadi and Z. Michalewicz, â€œParticle swarm optim ization for single objective continuous space problems: A review,â€ Evolutionary Computation . 2017, doi: 10.1162/EVCO_r_00180.
[14] D. Wang, D. Tan, and L. Liu, â€œParticle swarm optimizatio n algorithm: an overview,â€ Soft Comput. , 2018, doi: 10.1007/s00500-016-2474-6.
[15] N. Hafidz, Sfenrianto, Y. Pribadi, E. Fitri, and Ratino , â€œANN and SVM Algorithm in Divorce Predictor,â€ Int. J. Eng. Adv. Technol. , vol. 9, no. 3, pp. 2523â€“2527, Feb. 2020, doi: 10.35940/ijeat.C5902.029320.",Sentimen Analisis,"Naive Bayes, Support Vector Machine",data twitter berisi opini masyarakat yang mengandung unsur komentar positif maupun negatif terhadap vasin Covid -19,"accuracy, precision, recall"
"ANALISIS SENTIMEN MASYARAKAT TERHADAP PAYLATER  MENGGUNAKAN METODE NAIVE  BAYES CLASSIFIER  
","ANALISIS SENTIMEN MASYARAKAT TERHADAP PAYLATER  MENGGUNAKAN METODE NAIVE  BAYES CLASSIFIER  

Alfandi Safira1, Firman Noor Hasan2 

Abstrak  
Belanja online  begitu disukai masyarakat karena mudah dan nyaman saat dilakukan . Kemudahan belanja online  didukung dengan metode pembayaran melalui paylater . Namun, paylater   juga mengakibatkan perilaku yang buruk seperti  impulse buying. Tanggapan yang beraneka ragam dari masyarakat membuat peneliti melakukan penelitian untuk mengetahui pandangan masyarakat 
terhadap paylater . Metode yang digunakan dalam penelitian ini yaitu dengan menerapkan analisis sentimen menggunakan metode  Naive  Bayes Classifier  dan TextBlob  dari pustaka TetxBlob dengan bahasa pemrograman Python . Dataset  yang dikumpulkan melalui Twitter  menghasilkan 405 data . Analisis sentimen dengan metode  Naive  Bayes Classifier  menghasilkan sentimen negatif sebesar  
70,62% atau 286 data , sentimen positif yaitu 22,72% atau 92 data , sentimen netral sebesar 6,67% atau 27 data.  Sementara itu  dengan metode TextBlob  juga menghasilkan sentimen negatif yang lebih  
banyak yaitu sebesar 55,8% atau 226 data , sentimen positif yang berjumlah 33,09% atau 134 data , sentimen netral berjumlah 11,11% atau 45 data . Dengan demikian, dapat disimpulkan masyarakat 
merasakan kurang baik terhadap penggunaan paylater . Pada pengujian model dengan confussion matrix  menunjukan bahwa algoritma  Naive  Bayes Classifier  lebih  akurat dengan sebesar 91% dibanding TextBlob  yang hanya 61%.  

Kata kunci : Analisis Sentimen , Paylater,  Python,  Naive  Bayes Classifier, TextBlob  
 
Abstract  
Online shopping is so popular with the public because it is easy and convenient to do. The convenience of online shopping is supported by the payment method via paylater.  However, paylater also results in bad behavior such as impulse buying . Various responses from the community made researchers conduct research to find out the public's view of paylater . In this study, researchers tried 
to do sentiment analysis using the  Naive  Bayes Classifier and TextBlob methods from the TetxBlob library with the Python programming language.  From the dataset collected via Twitter, it produces 405 data. Sentiment analysis using the Naive  Bayes Classifier method produces a negative sentiment of 70.62% or 286 data , positive sentiment is 22 .72% or 92 data, neutral sentiment is 6.67% or 27 data. Meanwhile, using the TextBlob method also produced more negative sentiment, namely 55.8% 
or 226 data, positive sentiment collected 33.09% or 134 data, neutral sentiment amounted to 11.11% or 45 data.  Thus, it can be concluded that the community feels unfavorable towards the use of 
paylater . In testing the model with the confus sion matrix, it can be seen that the Naive  Bayes Classifier algorithm is more accurate by 91% compared to TextBlob which is only  61%.  

Keywords : Sentiment Analysis, Paylater,  Python , Naive  Bayes Classifier, TextBlob  
 
1. PENDAHULUAN  
Di era teknologi yang begitu canggih, banyak penemuan yang memberikan kemudahan bagi peradaban manusia. Salah satu yang paling sangat dirasakan manfaatnya adalah penemuan internet. Teknologi internet membantu masyarakat untuk menjalani kehidupan dengan lebih mudah, praktis, dan efisien  [1]. Pemanfaatan teknologi melalui internet salah satunya yaitu p embelajaran secara daring atau pembelajaran online  yang menjadi alternatif pembelajaran selama pandemi [2]. Selain pembelajaran online , perilaku lain yai tu belanja daring atau belanja online . Kemudian muncul istilah 
e-book , e-learning , e-laboratory , e-education , e-library , dan sebagainya [3]. Belanja online  memudahkan masyarakat untuk membeli sesuatu sesuai dengan kebu tuhan yang diinginkan. Belanja online  di Indonesia sudah dimulai  sejak 2012  [4]. Namun, saat itu kondisi internet belum begitu mudah untuk digunakan. Berbeda dengan saat ini, internet kini telah banyak digunakan oleh 
masyarakat dan membuat belanja online  sebagai hal yang biasa dilakukan oleh masyarakat.  Belanja online  disukai oleh masyarakat karena begitu sederhana dan harga barang relatif lebih murah [5]. Banyak kemudahan yang dirasakan ketika belanja online . Pembe li merasakan kenyaman karena dapat membeli dan bertransaksi hanya dengan duduk manis di rumah  [6]. Namun, karena begitu nyaman menyebabkan masyarakat menjadi kecanduan belanja online. Masyarakat perlu mengontrol diri agar dapat menghindari kecanduan belanja online  [7]. Kemudahan belanja online  didukung dengan banyaknya metode pembayaran yang dapat digunakan dalam bertransaksi. Tak terkecuali pembayaran dengan metode paylater . Paylater  adalah metode pembayaran ketika bertransaksi belanja online di mana pembeli dapat membayar secara angsuran atau lunas sesuai tanggal tempo yang telah ditetapkan [8]. Pembeli diberikan pinjaman dana untuk membeli produk yang diinginkan. Desakan ekonomi, gaya hidup, penggunaan cashless , kepuasan belanja, dan promo yang menarik jadi motif masyarakat menggunakan paylater  [9]. Selain itu, sistem pembayaran paylater  ini memberikan dampak perilaku yang kurang baik di masyarakat, 
yaitu perilaku impulse buying . Impulse buying  adalah perilaku membeli produk sesuai keinginan tanpa rencana dan alasan  [10]. 
Dengan kemudahan dan keuntungan menggunakan paylater  memberikan dampak yang beraneka ragam kepada masyarakat. Opini masyarakat juga bermacam-macam mengenai paylater . 
Untuk mengetahui opini yang beredar di masyarakat, sosial media seperti Twitter  sangat dapat diandalkan. Twitter  adalah media sosial sederhana yang penggunanya memungkinkan untuk menggungah pesan singkat atau twit dalam berbagai bentuk seperti teks, foto, audio, video, dan sebagainya  [11]. Twitter  merupakan aplikasi yang cukup banyak di gunakan oleh masyarakat Indonesia , khususnya dalam memberikan suatu pendapat  [12]. Akun autobase  yang ada di Twitter  dapat menjadi lahan informasi dalam mengetahui suatu opini masyarakat. Autobase  adalah akronim dari â€˜ automatic â€™ dan â€˜ fanbase â€™. Akun autobase  dapat diartikan sebagai akun yang men ampung pesan dari para pengikutnya yang dikirim melalui pesan langsung ( direct message ) dari akun autobase  yang 
kemudian akan diunggah di akun autobase  tanpa diketahui siapa pengirimnya [11]. Akun @worksfess adalah sal ah satu contoh akun autobase  yang membicarakan topik yang berkaitan tentang pekerjaan, memiliki pengikut 500 ribu dan masih aktif mengunggah twit hingga saat ini.  Twit para pengguna Twitter  diklasifikasikan dengan menggunakan metode analisis sentimen . Analisis sentimen adalah teknik yang secara otomatis mengidentifikasi, mengekstraksi, dan memproses informasi tekstual untuk menemukan informasi emosional dalam ekspresi pikiran [13]. Klasifikasi tersebut akan mengetahui apakah twit tersebut bersifat positif , netral, atau negatif. Pada penelitian kali ini analisis sentimen menggunakan algoritma  Naive  Bayes  untuk menentukan apakah sebuah twit bersifat positif, netral, atau negatif.  Melalui latar belakang yang telah dipaparkan pada sebelumnya, peneliti akan  melakukan penelitian tentang analisis sentimen terhadap masyarakat khususnya para pekerja melalui akun @worksfess mengenai paylater . Penelitian ini bertujuan untuk mengetahui efektifitas algoritma  Naive  Bayes  untuk melakukan analisis sentimen penggunaan paylater serta mengetahui pandangan masyarakat mengenai paylater . 
Gambar 1. Tahapan Penelitian  
Penelitian ini dimulai dengan pengumpulan data di mana data didapatkan melalui crawling di media sosial Twitter  dengan Python . Python  adalah bahasa pemrograman interpretatif yang mudah dipelajari dan dapat dijalankan pada berbagai platform dengan fokus utama pada keterbacaan kode [17]. Kemudian megeliminasi data yang bersifat duplikat. Data-data tersebut menjadi dataset  yang 
digunakan untuk penelitian.  Dataset  perlu melaui proses preprocessing  untuk menghapus data yang tidak dibutuhkan . Data perlu diolah agar dapat  digunakan  [18]. Setelah dilakukan preprocessing  maka dataset  siap diimplementasikan dengan beberapa model untuk analisis sentimen. Evaluasi pada model dilakukan untuk mengetahui seberapa akurat model yang digunakan untuk analisis sentimen.  
 
3. HASIL DAN PEMBAHASAN  
3.1 Pembahasan  
Sebelumnya telah ada beberapa penelitian ya ng berkaitan dengan analisis sentimen dengan menggunakan algoritma Naive  Bayes . Algoritma Naive Bayes  dipilih karena metode klasifikasi dengan formula sederhana dan mudah diterapkan serta memiliki akurasi yang cukup tinggi dibandingkan dengan metode lain  [14]. Naive Bayes  juga diyakini merupakan metode untuk melakukan pemisahan data terstruktur yang lebih unggul daripada metode pemisahan data terstruktur lainnya dalam hal akurasi dan kom putasi  [15]. Pada penelitian oleh Aldisa dan Maulana membandingkan antara algoritma Naive  Bayes , Decision  Tree, dan SVM menunjukkan bahwa presisi Naive Bayes  menempati urutan terbaik [16]. Penelitian lain yang dilakukan oleh  Hasan dan Dwijayanti menunjukkan bahwa akurasi dari algoritma Naive  Bayes  sangat baik yaitu 92,5%  [15]. Namun, pada penelitian tersebut memiliki beberapa kekurangan seperti pada pengumpulan data harus 
memilik i akun Twitter  untuk memperoleh Key Token  dan Key Access  sehingga data dibatasi oleh pihak Twitter . Penelitian tersebut menjadi referensi pada penelitian yang dilakukan  namun dengan perbedaan pada penelitian kali ini menggunakan pustaka snscrape  untuk peng umpulan data agar tidak terbatas untuk mendapatkan data dari Twitter .  
3.2 Hasil  
3.2.1 Pengumpulan Data  
Pada tahap ini peneliti menggunakan fitur advance search  pada Twitter  untuk mengumpulkan data yaitu kumpulan twit para pengguna yang membicarakan tentang paylater . Pada kolom fitur advance search ada beberapa kolom yang perlu diisi sesuai dengan kebutuhan.  
Gambar 2. Fitur Advance Search Twitter  
Pada Gambar 2 ketika kolom -kolom tersebut diisi maka akan menghasilkan sebuah query pencarian yang akan digunakan pada kode program Python . Query  adalah suatu perintah yang digunakan untuk menampilkan data  [19]. Pada penelitian kali ini peneliti mendapatkan query : â€˜paylater (pakai OR pake) ( to:worksfess) (@worksfess) â€™ 
Tabel 1.  Penjelasan Query  
No. Kata  Keterangan  
1 paylater  Twit harus mengandung kata â€˜ paylaterâ€™  
2 (pakai OR pake)  Twit harus mengandung minimal kata â€˜pakaiâ€™ atau â€˜pakeâ€™  
3 (to:worksfess)  Twit harus dikirim ke @worksfess  
4 (@worksfess)  Twit harus menyebutkan @worksfess  
Query  tersebut digunakan dalam kode Python  dengan bantuan pustaka snscrape  untuk mengumpulkan twit -twit yang sesuai untuk dijadikan dataset . 
Gambar 3 . Proses Pengumpulan Data  
Pada Gambar 3 adalah proses pengumpulan data di Twitter . Peneliti menggunakan Python  untuk mendapatkan twit. Pustaka snscrape  digunakan oleh peneliti untuk mendapatkan twit dan keterangan 
lainnya tanpa perlu login akun Twitter  terlebih dahulu. Snscrape  adalah sebuah pustaka pada Python  untuk mengumpulkan informasi layanan jejaring sosial seperti profil pengguna, tagar, atau unggahan yang relevan sesuai pencarian. Snscrape  memerlukan sebuah query  untuk mendapatkan twit yang diingkinkan. Pada sebelumnya peneliti telah mendapatkan query  yang siap digunakan melalui fitur advance search pada Twitter. Setelah itu kumpulan twit akan menjadi dataset  dalam bentuk file csv. Dari hasil pengumpulan data didapatkan sebanyak 405 data yang akan menjadi dataset . 
3.2.2 Remove Duplicates  
Pada tahap ini peneliti mengeliminasi twit duplikat agar data menjadi bersifat unik. Tahap ini mencegah penambahan bobot sampel dan sifat bias pada data.    
Gambar 4 . Proses Remove Duplicates   
Pada gambar 4 adalah kode program untuk menghapus data duplikat pada data twit yang telah dikumpulkan.  
3.2.3 Preprocessing  
Selanjutnya perlu dilakukan lagkah preprocessing  pada dataset dimana pada langkah ini terdiri dua tahapan seperti cleansing  dan transformasi ke bahasa formal ( transform ). 
3.2.3.1  Cleansing  
Pada bagian cleansing  atau pembersihan dilakukan dengan dua tahapan: pertama menghapus simbol mention  twit yang terkandung pada twit
Gambar 5 . Proses Cleansing  
Pada gambar 5 adalah kode program untuk proses cleansing  data untuk menghilangkan karakter-karakter yang tidak dibutuhkan. snscrape  query  
Tabel 2.  Hasil Proses Cleansing  
twit delete mention  delete url  
@worksfess Data bisa dipake buat paylater, yg ngga usah 
pake rekening yg sama, dengan nama pemegang ktp. Paylater kan ngga kirim dana ke rekening ya. Terus fermuk juga ngga seaman itu. Apalagi kalo yg mainin data orang dalem lembaganya. Mudah sekali memang. W salah 1 korban nih. https://t.co/OECgAseqB2  
Data bisa dipake buat paylater, yg ngga usah pake rekening  yg sama, dengan nama pemegang ktp. Paylater kan ngga kirim 
dana ke rekening ya. Terus fermuk juga ngga seaman itu. Apalagi kalo yg mainin data orang dalem lembaganya. Mudah sekali memang. W salah 1 korban nih. https ://t.co/OECgAseqB2  
Data bisa dipake buat paylater, yg ngga usah pake rekening yg sama, dengan nama pemegang ktp. Paylater kan ngga kirim dana ke 
rekening ya. Terus fermuk juga ngga seaman itu. Apalagi kalo yg mainin data orang dalem lembaganya. Mudah sekali memang. W salah 1 korban nih.   
3.2.3.2  Transform  
Pada bagian transform  yaitu mengubah kata yang tidak formal atau singkatan menjadi kata formal atau tidak disingkat. Pada bagian ini peneliti menggunakan database  untuk mengubah kata per kata.    
Gambar 6.  Proses Koneksi ke Database   
Pada gambar 6 adalah proses koneksi ke database  dengan mysql  untuk mengambil data dari database .  
Gambar 7.  Proses Transform   
Pada gambar 7 adalah logic perubahan kata per kata yang tidak formal atau disingkat menjadi formal atau tidak disingkat.  
Tabel 3.  Hasil Proses Transform  
delete url  transform  
Data bisa dipake buat paylater, yg ngga usah pake rekening yg sama, dengan nama pemegang ktp. Paylater kan ngga kirim 
dana ke rekening ya. Terus fermuk juga ngga seaman itu. Apalagi kalo yg mainin data orang dalem lembaganya. Mudah 
sekali memang. W salah 1 korban nih.  Data bisa dipakai buat paylater, yang enggak perlu pakai rekening yang sama, dengan nama pemegang ktp. Paylater kan enggak kirim dana ke rekening ya. Terus fermuk juga enggak seaman itu. Apalagi kalau yang mainkan data orang dalem lembaganya. Mudah sekali memang. gue salah 1 korban nih.  
3.2.4 Labeling  
Pada tahap ini pemberian label ( labeling ) dilakukan pada sebagian twit yang akan digunakan sebagai data testing pada implementasi algoritma  Naive  Bayes . Peneliti membagi data dengan perbandingan 70:30 untuk data training  dan data testing. Berikut sampel data testing  yang telah diberikan label.   
Tabel 4.  Proses Labeling  
twit label  
belanja tapi  pakai cc atau paylater, niscaya akan semangat kerja karena ingat punya cicilan  Positive  
masa sendiri, jangan pakai paylater atau cicilan, jangan hedon, catat pengeluaran apapun  Negative  
aku dikasi uang jajan 1.2 sebulan saja masih bisa nabung 450k nder kos di bdgÃ°Å¸Ëœâ€š 1. saya enggak pakai paylater. 2. uangnya dibagi dari awal, diperkirakan kebutuhan pokok bulanan apa aja. 3. saya nabung di bibit, jadi enggak mungkin bisa asal comot. 4. skincare banyak produk lokal yang murah  Neutral  
Alhamdulillah sampai sekarang enggak pernah pakai dan aktifkan paylater Ã°Å¸Ëœâ€š  Neutral  
3.2.5 Implementasi Algoritma  Naive  Bayes  
Untuk menentukan sentimen pada sebuah twit, peneliti menggunakan algoritma Naive  Bayes  dari pustaka TextBlob . Sebelumnya telah dibuat data testing  untuk melatih data training  yang akan diklasifikasikan.  
Gambar 8.  Proses Implementasi Algoritma  Naive  Bayes  
Pada gambar 8 adalah proses implementasi algoritma  Naive  Bayes  dengan menggunakan data testing yang telah diberi label.  Naive  Bayes  mempelajari data testing  yang telah diberi label kemudian 
memberikan label pada data training . 
Tabel 5.  Hasil Proses Klasifikasi Naive  Bayes  
twit label  sentiment  
belanja tapi pakai cc atau paylater, niscaya akan semangat kerja 
karena ingat punya cicilan  Positive  Positive masa sendiri, jangan pakai paylater atau cicilan, jangan hedon, catat pengeluaran apapun  Negative  Negative  
aku dikasi uang jajan 1.2 sebulan saja masih bisa nabung 450k 
nder kos di bdgÃ°Å¸Ëœâ€š 1. saya enggak pakai paylater. 2. uangnya dibagi dari awal, diperkirakan kebutuhan pokok bulanan apa aja. 3. saya nabung di bibit, jadi enggak mungkin bisa asal comot. 4. skincare banyak produk lokal yang murah  Neutral  Neutral  
Alhamdulillah sampai sekarang enggak pernah pakai dan aktifkan paylater Ã°Å¸Ëœâ€š  Neutral  Negative  
Gambar 9.  Distribusi Sentiment Algoritma  Naive  Bayes  
Pada gambar 9 adalah distribusi analisis sentimen menggunakan  Naive  Bayes  dengan didominasi sentimen negatif sebesar 70,62% atau 286 data. Kemudian disusul dengan sentimen positif yaitu 22,72% atau 92 data. Sedangkan  sentimen netral menjadi yang paling sedikit dengan hanya 6,67% atau 27 data.   
3.2.6 Implementasi TextBlob  
Dengan TextBlob  tidak memerlukan data testing  karena dalam prosesnya tidak membutuhkan data  testing . Dataset  yang telah siap diklasifikasikan hanya perlu diterjemahkan ke dalam bahasa Inggris. Jika telah diterjemahkan ke dalam bahasa Inggris, proses klasifikasi dilakukan untuk menentukan sentimen dari setiap twit pada dataset .   
Gambar 10. Proses  Optimasi TextBlob  
Pada gambar 10 adalah penerapan optimasi dengan menambahkan kata-kata khusus agar implementasi TextBlob  menjadi lebih akurat.  
Gambar 11. Proses  Implementasi TextBlob 
Pada gambar 11 adalah mengimplementasikan pustaka TextBlob  untuk analisis sentimen. Penerapan implementasi TextBlob  hanya dilakukan jika tidak terdapat kata -kata khusus yang pada twit. 
Tabel 6.  Hasil Klasifikasi TextBlob  
twit translate  score  label  sentiment  
belanja tapi pakai cc atau paylater, niscaya akan semangat kerja karena ingat punya cicilan  shopping but using CC or paylater, surely you will be enthusiastic about working because you remember that you have installments  0.55 Positive  Positive  
aku dikasi uang jajan 1.2 sebulan saja masih bisa nabung 450k kos di bdgÃ°Å¸Ëœâ€š 1. saya  enggak pakai paylater. 2. uangnya dibagi dari awal, diperkirakan kebutuhan pokok bulanan apa aja. 3. saya nabung di bibit, jadi enggak mungkin bisa asal comot. 4. skincare banyak produk lokal yang murah  I was given pocket money for just 1.2 a month and I was still able to save 450k nder boarding house at BDGÃ°Å¸Ëœâ€š 1. I don't use a paylater. 2. the money is divided from the beginning, it is estimated what the monthly basic needs are. 3. I saved on seeds, so it's impossible for it to get dirty as long as it's dirty. 4. There are lots of cheap local skincare products  -0.127  Neutral  Negative  
Gambar 12. Distribusi Sentiment TextBlob  
Pada gambar 12 adalah distribusi sentimen TextBlob  dengan sentimen negatif lebih dominan sebesar 55,8% atau 226 data. Disusul oleh sentimen positif yang berjumlah 33,09% atau 134 data. 
Sedangkan pada sentimen netral yang menjadi paling sedikit hanya berjumlah 11,11% atau 45 data.  
3.2.7 Evaluasi  
Setelah melakukan analisis sentimen, perlu dievaluasi atau diuji apakah model yang digunakan memiliki akurasi yang baik. Dalam pengujian ini peneliti menggunakan metode confusion matrix  
untuk mengujinya.  
Gambar 13. Confussion Matrix  Naive  Bayes  
Pada gambar 14 adalah gambar dari pengujian model TextBlob  menggunakan confussion matrix . True Negative  menjadi yang paling besar yaitu 51 data. Kemudian disusul oleh True Positive   berjumlah 40 data. Sedangkan True Neutral  hanya 24 data. Nilai akurasi pada  Naive  Bayes  memberikan nilai yang tinggi sebesar 96%.  
Gambar 14.  Confussion Matrix TextBlob  
Pada gambar 14 adalah gambar dari pengujian model  Naive  Bayes menggunakan confussion matrix . True Negative  menjadi yang paling besar yaitu 41 data. Kemudian disusul oleh True Positive  berjumlah 26 data. Sedangkan True Neutral  hanya 7 data. Nilai akurasi pada TextBlob tidak cukup tinggi yaitu hanya 61%. 
 
4. KESIMPULAN  
Dari hasil pengumpulan dataset yang didapatkan sebanyak 405 data mengenai paylater , dapat disimpulkan bahwa masyarakat merasa  kurang  baik dengan penggunaan paylater  dibuktikan hasil analisis sentimen yang lebih banyak mendapatkan sentimen negatif  daripada positif . Algoritma  Naive  Bayes  dari pustaka TextBlob  yang diterapkan pada pengujian model menggunakan confu ssion matrix  menghasilkan bahwa tingkat akurasi yang lebih besar yaitu 95% jika dibandingkan dengan menggunakan pustaka TextBlob  yang hanya senilai 61%.  
 
DAFTAR PUSTAKA  
[1] D. A. Karlina, A. N. Aeni, and A. A. Sy ahid, â€œMengenal Dampak Positif dan Negatif Internet untuk Anak pada Orang Tua,â€ 2020.  
[2] S. D. R.A, R. Hardianto, and H. Filtri, â€œAnalisa Tingkat Kepuasan Mahasiswa Terhadap Perkuliahan Daring Pada Era Pandemi Covid -19,â€ J. Sist. Inf. , vol. 3, no. 2, pp. 130â€“142, 
2021, [Online]. Available: https://journal.unilak.ac.id/index.php/zn/article/download/8353/3502  
[3] A. Hal, I. Suite, P. Mata, and P. Akidah, â€œPengembangan Media Pembelajaran Berbasis Android Dengan Pemanfaatan,â€ vol. 5, no. 4, pp. 1 â€“17, 2022.  
[4] R. Komala, â€œLiterasi Digital Untuk Perlindungan Data Privasi: Dibalik Kemudahan Belanja Daring,â€ J. Ilmu Sos. dan Pendidik. , vol. 6, no. 4, pp. 2598 â€“9944, 2022, doi: 10.36312/jisip.v6i4.3527/http.  
[5] M. Andika, S. Masithoh, Y. N. Kholiq, D. A. Nisa, and N. Rohmah, â€œEfektivitas Marketplace Shopee sebagai Marketplace Belanja Online yang Paling Disukai Mahasiswa,â€ 2021. [Online]. Available: http://jurnalilmiah.org/journal/index.php/jet  
[6] A. E. Permana, A. M. Reyhan, H. Rafli, and N. A. Rakhmawati, â€œAnalisa  Transaksi Belanja Online pada Masa Pandemi Covid -19,â€ J. Teknoinfo , vol. 15, no. 1, p. 32, Jan. 2021, doi: 10.33365/jti.v15i1.868.  
[7] P. Agung and F. Marisa, â€œAnalisis Statistik pada Dampak Negatif dari Sosial Media Terhadap Perilaku Manusia,â€ JOINTECS) J. Inf. Technol. Comput. Sci. , vol. 4, no. 1, pp. 2541 â€“3619, 2019, doi: 10.31328/jo.  
[8] V. Eviana and A. J. Saputra, â€œAnalisis Faktor -Faktor yang Memengaruhi Minat Penggunaan Sistem Pembayaran Pay Later,â€ J. Pendidik. Tambusai , vol. 6, no. 1, pp. 1968 â€“1977, 2022.  
[9] R. E. B. Hardhika and A. M. Huda, â€œPengalaman Pengguna Paylater Mahasiswa di Surabaya,â€ 2021.  
[10] R. Sari, â€œPengaruh Penggunaan Paylater Terhadap Perilaku Impulse Buying Pengguna E-Commerce di Indonesia,â€ J. Ris. Bisnis dan Investasi , vol. 7,  no. 1, pp. 44 â€“57, 2021.  
[11] L. Mardiana and A. Faâ€™zia Ziâ€™ni, â€œPengungkapan Diri Pengguna Akun Autobase Twitter @subtanyarl,â€ 2020.  
[12] I. R. Afandi, I. F. Hanif, F. N. Hasan, E. Sinduningrum, and Z. Halim, â€œAnalisis Sentimen Opini Masyarakat Terkait Pen yelenggaraan Sistem Elektronik Menggunakan Metode Logistic 
Regression,â€ vol. 5, no. 2, pp. 77 â€“84, 2022.  
[13] O. I. Gifari, M. Adha, I. Rifky Hendrawan, F. Freddy, and S. Durrand, â€œAnalisis Sentimen Review Film Menggunakan TF -IDF dan Support Vector Machine, â€ JIFOTECH (JOURNAL Inf. Technol. , vol. 2, no. 1, 2022.  
[14] A. Wibowo, F. Noor Hasan, R. Nurhayati, and A. Wibowo, â€œAnalisis Sentimen Opini Masyarakat Terhadap Keefektifan Pembelajaran Daring Selama Pandemi COVID -19 Menggunakan NaÃ¯ve Bayes Classifier,â€ J. Asiimetrik J. Ilm. Rekayasa Inov. , vol. 4, pp. 239 â€“248, 2022, doi: 10.35814/asiimetrik.v4i1.3577.  
[15] F. N. Hasan and M. Dwijayanti, â€œAnalisis Sentimen Ulasan Pelanggan Terhadap Layanan Grab Indonesia Menggunakan Multinominal NaÃ¯ve Bayes Classifier,â€ 202 1. 
[16] R. T. Aldisa and P. Maulana, â€œAnalisis Sentimen Opini Masyarakat Terhadap Vaksinasi Booster COVID -19 Dengan Perbandingan Metode Naive Bayes, Decision Tree dan SVM,â€ 
Technol. Sci. , vol. 4, no. 1, pp. 106 â€“109, 2022, doi: 10.47065/bits.v4i1.1581.  
[17] R. Wati and S. Ernawati, â€œAnalisis Sentimen Persepsi Publik Mengenai PPKM Pada Twitter Berbasis SVM Menggunakan Python,â€ 2021. [Online]. Available: https://netlytic.org  
[18] E. Sinduningrum, F. N. Hasan, A. R. Dzikrillah, A. B. Rossianiz, and D. Febriawan , â€œPeningkatan Kemampuan Data Analytic Melalui Pelatian ASEAN Data Science Explorers Menggunakan SAP Analytic,â€ vol. 6, pp. 1708 â€“1716, 2022.  
[19] H. Jurnal et al. , â€œAnalisa Perbandingan Kinerja Response Time Query MySQL dan MongoDB,â€ Juli, vol. 2, no. 2, p p. 158 â€“166, 2022.  ",Analisis Sentimen,"Naive Bayes Classifier, TextBlob",kumpulan twit para pengguna yang membicarakan tentang paylater,akurasi
Penerapan Algoritma Naive Bayes  untuk Analisis Sentimen Review  Data Twitter  BMKG Nasional,"Penerapan Algoritma Naive Bayes  untuk Analisis Sentimen Review  Data Twitter  BMKG Nasional

Dedi Darwis1, Nery Siskawati1, Zaenal Abidin1 

Abstrak
Pertumbuhan Twitter  terus meningkat setiap waktu, sehingga hal tersebut dimanfaatkan para pengguna Twitter untuk menyampaikan informasi berupa kritik maupun saran kepada pelayanan yang diberikan BMKG Nasional dengan lebih mudah. Metode yang digun akan dalam penelitian ini adalah klasifikasi data adalah Naive Bayes Classifier (NBC). Sistem yang dikembangkan dengan menggunakan  data internal yang diambil dari internet/ Twitter  untuk proses penentuan kalimat termasuk opini positif, netral atau negatif.  Penentuan tersebut digolongkan sebagai proses pengklasifikasian. Serta menggunakan Application Python 3.74. Hasil Penelitian ini masuk kedalam fined grained sentiment analysis yaitu analisis pada suatu kalimat komentar. Data tersebut akan diproses menggun akan text mining, kemudian dilanjutkan dengan mengklasifikasikan Tweet  ke dalam tiga kelas, yaitu positif, negatif, dan netral. Klasifikasi ini menggunakan algoritma naive bayes. Klasifikasi dapat memberikan kemudahan bagi pengguna untuk melihat opini positif, negatif, dan netral. Hasil uji akurasi pada metode naive bayes untuk klasifikasi yaitu 69.97%.  

Kata Kunci: Analisis Sentimen, Naive Bayes, Python 3.74, Twitter .  

Abstract
Twitter  growth continues to increase every time, so it is used by Twitter  users to convey information in the form of criticism and suggestions to the services provided by the National BMKG more easily. The method used in this study is the classification of data is the Naive Bayes Classifier (NBC). The system was developed using internal data taken from the internet / Twitter  for the process of determining sentences including positive, neutral or negative opinions. The determination is classified as a classification process. And using Python 3.74 application. The results of this study are included in the fined grained sentiment analysis, which is an analysis in a comment sentence. The data will be processed using text mining, then proceed with clas sifying Tweet s into three classes, namely positive, negative, and neutral. This classification uses the Naive Bayes algorithm. Classification can make it easy for users to see positive, negative and neutral opinions. The results of the  
accuracy test on the  Naive Bayes method for classification are 69.97%.  

Keywords : Sentiment Analysis, Naive Bayes, Python 3.74, Twitter . 

1. PENDAHULUAN  
1.1 Latar Belakang Masalah  
Perkembangan teknologi internet saat ini membawa dampak perubahan pada beberapa sektor kehidupan manusia, seperti hanya pada bidang pendidikan, perdagangan, pemerintahan hingga komunikasi social. Di era sekarang ini pertumbuhan internet dan media sosial telah berkembang pesat sehingga menyediakan berbagai informasi opini dari orang lain. Sebuah survey  yang dilakukan oleh Asosiasi Pengusaha Jasa Internet (APJII) pada tahun 2014 menunjukkan bahwa jumlah pengguna internet di Indonesia mengalami kenaikan dalam beberapa tahun terakhir. Pada tahun 2005, tercatat sebanyak 16 juta orang pengguna internet di Indonesia dan angka ini bertambah menjadi 20 juta orang pengguna internet pada tahun 2006. Penelitian ini juga memberikan hasil bahwa saat ini penggunaan internet paling banyak adalah akses ke situs media sosial (87,4% dari total responden), salah satu media  social pada zaman sekarang yaitu Twitter  [1]. Media sosial Twitter  adalah salah satu sebagau media penghubung yang diminati oleh seluruh masyarakat di dunia  [2]. Hal ini dapat dilihat dari jumlah peningkatan pengguna Twitter  yang tercatat di seluruh dunia salah satunya indonesia. Pada saat ini Twitter  memiliki jumlah pengguna aktif sebesar 313 juta per bulan pada tahun 2016  [3]. Pengguna Twitter  akan memberikan kabar terbaru atau komentar tentang hal yang sedang menjadi topik utama di dunia. Hal yang sedang menjadi topik utama dan banyak dan sering dikomentari oleh pengguna akan menimbulkan suatu masalah atau trending topik di media sos ial terutama Twitter . Pertumbuhan Twitter  terus meningkat setiap waktu [4], sehingga hal tersebut dimanfaatkan para pengguna Twitter  untuk menyampaikan informasi berupa komentar kritik maupun saran kepada pelayanan yang diberikan BMKG Nasional dapat dilaku kan dengan lebih mudah. Semakin banyak pendapat atau keluhan dari beberapa masyarakat dalam membentuk opini masyarakat, dan dapat dijadikan masukan terhadap suatu penilaian 
pelayanan yang diberikan BMKG Nasional. Pada pelayanan yang diberikan oleh salah sa tu petugas BMKG Nasional yang kurang baik maka akan menimbulkan banyak opini masyarakat tentang pelayanan BMKG Nasional. Analisis sentimen dapat membantu untuk memperoleh gambaran umum presepsi masyarakat dengan cara mengelompokkan jenis opini  menjadi kate gori positif, negatif, atau netral terhadap pelayanan pada BMKG Nasional. Algoritma Naive Bayes  adalah merupakan salah satu algoritma klasifikasi yang banyak digunakan pada Data Mining ataupun Text Mining [5]. Algoritma Naive Bayes  berdasarkan teorema Bayes  bahwa se mua kegiatan memberikan sebuah kontribusi yang sama penting atau saling bebas pada pemilihan kelas tertentu.  Salah satu metode klasifikasi untuk menentukan gambaran p ersepsi masyarakat di dalam Text Mining  adalah  metode Naive Bayes  yang sering disebut dengan Naive Bayes Classifier  [6], [7]. Penelitian yang dilakukan adalah tentang sentimen analisis untuk mengklasifikasikan Tweet  Review  BMKG Nasional. Penelitian ini termasuk kedalam sebuah penelitian yang bernama fined grained sentiment analysis  yaitu analisis pada suatu kalimat komentar. Data  dari Twitter  tersebut akan dapat diproses menggunakan text mining , kemudian dilanjutkan dengan mengklasifikasikan Tweet  ke dalam tiga kelas, yaitu positif, negatif, dan netral. Klasifikasi dapat memberikan kemudahan bagi semua pengguna untuk melihat kritik dan saran  [8], 
[9]. Tujuan penelitian ini adalah untuk melakukan pencarian komentar negatif, postif, dan netral dengan review  data Twitter  BMKG Nasional mengguna kan algoritma naive bayes , lalu melakukan perhitungan data negatif, postif, dan netral menggu nakan algoritma naive bayes, serta dapat  menghasilkan klasifikasi berdasarkan nilai yang didapat dengan algoritma naive bayes . Penelitian yang dilakukan difokuskan  kepada kritik dan saran dalam 
pelayanan BMKG Nasional yang ada di akun resmi Twitter  dengan menggunakan data pada tahun 2018 dan 2019. Proses pengambilan data dan klasifikasi sentimen analisis menggunakan bahasa pemrograman Python 3.74.  
1.2 Landasan Teori  
a. Analisis Sentiman  
Analisis Sentimen adalah salah satu cabang sebuah penelitian text mining, yang berkaitan dengan bidang yang lebih luas seperti pengolahan data kegiatan  tertentu [3]. 
b. Text Mining  
Text Mining  merupakan tahapan proses dari analisis dalam data yang berupa teks dimana sumber data didapatkan dari suatu dokumen seperti kalimat data kata, Konsep text mining biasanya digunakan dalam klasifikasi dokumen tekstual dimana dokumen-dokumen tersebut akan diklasifikasikan sesuai dengan topik dokumen tersebut [9]. 
c. Naive Bayes  
Salah satu tugas Data Mining adalah klasifikasi data, yaitu memetakan (mengklasifikasikan) data ke dalam satu kelas atau beberapa kelas yaang sudah didefinisikan sebelumnya. Salah satu metoda dalam klasifikasi data adalah Naive Bayes yaitu salah satu metode machine learning  yang memanfaatkan perhitungan probabilitas dan statistik yang dikemukakan oleh ilmuwan Inggris Thomas Bayes, cara kerja Naive Bayes yaitu memprediksi probabilitas di masa depan berdasarkan pengalaman di masa sebelumnya [7]. Dasar dari Naive Bayes yang dipakai dalam 
pemrograman adalah rumus Bayes seperti pada persamaan (1)  
P (A|B) = (P(B|A) * P(A))/P(B)           (1) 
Keterangan :  
Peluang kejadian A sebagai B ditentukan dari peluang B saat A, peluang A, dan peluang B.  
Pada pengaplikasiannya nanti rumus pada persamaan (1) berubah menjadi persamaan (2).  
P(Ci|D) = (P( D|Ci)*P(Ci)) / P(D)          (2)   
Naive Bayes atau bisa disebut sebagai Multinomial NaÃ¯ve Bayes merupakan model penyederhanaan dari Metoda Bayes yang cocok dalam pengklasifikasian teks atau dokumen. Pada persamaan (3) merupakan persamaan model penyederhanaan dari Metoda Bayes.  
VMAP = arg max P (Vj | a1 , a2 ,.......an)         (3)   
Berdasarkan  persamaan (3), maka persamaan (1) dapat ditulis seperti yang terdapat pada persamaan (4)  
VMAP = agr max (Vj eV)  ð‘ƒ (ð‘Ž1,ð‘Ž2â€¦â€¦ð‘Žð‘› | ð‘ƒ (ð‘‰ð‘—)|
ð‘ƒ (ð‘Ž1,ð‘Ž2â€¦.ð‘Žð‘›)         (4) 
2. METODE PENELITIAN  
2.1 Kerangka Penelitian  
Kerangka penelitian dibuat untuk membuat pola pikir penelitian menjadi lebih realistik. Pada penelitian yang dilakukan, gambaran tentang kerangka penelitian yang dibuat disajikan pada Gambar 1.  
Gambar 1 . Kerangka Penelitian  
Penjelasan pada Gambar 1.  
a. Crawling  Data, yaitu data Twitter  berisi opini masyarkat yang mengandung unsur komentar postif, netral, dan negatif pada BMKG dengan data tahun 2018 -2019 melalui aplikasi Twitter . Pada proses ini dimulai dari melakukan kunjungan Twitter  BMKG kemudian menuju ke folder clone  dan mulai melakukan penyaringan data dengan Python . 
b. Pelabelan sentimen Tweet  menjadi netral, positif atau negatif  
c. Preprocessing , dilakukan untuk menghasilkan data bersih. Preprocessing  meliputi: casefolding, filtering,tokenisasi, slang replacement dan stopwordremoval.  
d. Ekstraksi Fitur, meliputi: Unigram, Negation, TF  dan TF-IDF.  
e. Perancangan klasifikasi, dilakukan untuk mengelompokkan Tweet berdasarkan kelas yang ditentukan.  
f. Lebel ditemukan, digunakan untuk menemukan klasifikasi data baru menggunakan Naive Bayes . 
2.2 Tahapan Penelitian  
Tahapan penelitian dalam pengambilan data  sentimen analisis berupa Tweet  negatif, positif, dan netral  pada Twitter  BMKG, dapat dilihat pad a Gambar 2.  
Gambar 2.  Tahapan Peneli tian  
2.3 Cara Kerja Sentimen Analisis   
Proses klasifikasi menggunakan data pada tahun 2018 -2019 pada Twitter  BMKG. Tweet  dibagi ke dalam tiga kelas kata, yaitu positif, netral da n negatif. Setiap dokumen yang diklasifikasi akan di kategorikan ke dalam kelas yang paling dominan, berikut ini adalah tahapan yang dilakukan :  
a. Crawler Twitter  Akun BMKG  
Crawler merupakan sebuah alat untuk mengindeks dan mengunduh konten dari internet, la lu disimpan ke dalam database mesin pencari [10]. Berikut ini adalah hasil crawl Twitter  akun BMKG salah satudari 
komentar yang ada pada akun BMKG, sebagai contoh yaitu :  
b. Case Folding  
Case folding merupakan proses untuk mengubah kalimat atau menjadi huruf kecil [11]. Berikut ini adalah  contoh  hasil Case Folding akun BMKG salah satu dari komentar yang ada pada akun BMKG yaitu :  
c. Cleansing  
Data  cleansing adalah kegiatan menganalisa kualitas  data dengan cara memodifikasi, mengubah , atau menghapus data -data yang  dianggap tidak perlu, tidak lengkap, data tidak akurat , atau memiliki format  data atau file  yang salah dalam basis data guna menghasilkan data berkualitas tinggi. Data cleansing juga biasa disebut data cleaning atau data scrubbin g [12]. Berikut ini adalah contoh  Cleansing  akun  dengan mencantumkan komentar yang dilakukan tanpa adanya nama pengomentar. 
d. Stopword Removal  
Stopword removal disebut juga filtering, adalah tahap pemilihan kata-kata penting dari hasil token, yaitu kata-kata apa saja yang akan digunakan untuk mewakili dokumen  [13]. Berikut ini adalah stopword 
removal  yang dilakukan yaitu proses penyatuan dan pergantian emot yang dilakukan oleh pengomentar, dapat dilihat dibawah ini :  
e. Tokenisasi  
Tokenisasi adalah proses memisahkan deretan kata di dalam kalimat, paragraf atau halaman menjadi token atau potongan kata tunggal atau termmed word yang berdiri sendiri [14]. Berikut ini adalah contoh proses tekonesiasi  yaitu penyaringan kata yang dilakukan oleh pengomentar. ari10prasetyo @ BMKG @Awas aja kalau alat kayak gini masih ada  :) ari10prasetyo @ bmkg  @awas aja kalau alat kayak gini masih ada :)  awas aja kalau alat kayak gini masih ada :)  : Alat kayak gini masih ada, tapi emot senang  
 
 Jurnal TEKNO KOMPAK, Vol. 15,  No. 1 ,  P-ISSN: 1412 -9663, E -ISSN : 2656 -3525 , Hal. 131-145 
 
  
135
  
 
 
 
2.4 Metode Pengumpulan Data  
 
Pada penelitian ini  digunakan data  sekunder yang diambil dari akun Twitter  resmi BMKG Nasional. Data y ang 
diambil akan dijadikan sebagai data training untuk membuat kamus opini.  Pembuatan kamus data  opini  tersebut  
dengan  mengumpulkan  data  opini  melalui media data online. Kamus data  opini  yang  dikumpulkan  diklasifikasi 
menjadi kamus opini negatif d an  positif.  Untuk  melakukan  klarifikasi peneliti mengunakan bantuan  secara   
online  maupun  offline  untuk melakukan klarifikasi agar data kamus sesuai dan  meminimalkan subjektifitas.  
 
Aplikasi yang dikembangkan  menggunakan  data internal yang diambil dari internet/ Twitter  untuk proses 
penentuan kalimat termasuk opini positif, netral atau negatif. Penentuan tersebut digolongkan sebagai proses 
pengklasifikasian.  Pengklasifikasian  padasuatu  dokumen  termasuk   kelas   positif, kelas netralatau kelas ne gatif. 
Didalam pengumpulan data ini juga menggunakan study literature dengan data skunder yang didapat dari 
internet/ Twitter . 
 
2.5 Proses Twitter  Crawling  
 
Proses crawling pada Twitter  dilakukan dengan me manfaatkan fasilitas yang ada pada bahasa pemrograma n 
Python 3.74 yang telah disediakan. Dengan terlebih dahulu melakukan pengambilan data aplikasi pada Twitter  
Developer. Analisis sentiment pada penelitian ini dibatasi pada BMKG, dan menghasilkan pen yimpanan data 
dalam format CSV . Gambar 2 merupakan potong an source code untuk mengambil data pada Twitter . 
 
 
Gambar 3 . Potongan Source Code Crawling Data Twitter  
 
Dari data hasil crawling selan jutnya disimpan pada file dengan format CSV. Gambar 4  menunjukkan contoh data 
yang akan disimpan untuk proses pembentuk an model.  
 
Alat, kayak, gini, masih ada  
 Jurnal TEKNO KOMPAK, Vol. 15,  No. 1 ,  P-ISSN: 1412 -9663, E -ISSN : 2656 -3525 , Hal. 131-145 
 
  
136
  
Gambar 4.  Hasil Crawling Data Twitter  dalam Format CSV  
 
2.6 Skenario Pengujian  
 
Pada skenario pengujian ini jumlah data yang digunakan adalah 1179 data Tweet . Data dibagi menjadi dua bagian 
yaitu data training  dan data testing  dengan perbanding an 70:825 dimana data yang digunakan tersebut sudah 
diberi label. Oleh algoritma  Naive Bayes Classifier(NBC), data training  digunakan untuk membentuk tabel 
probabilitas, dan data testing digunakan untuk menguji tabel probabilitas yang telah terbentuk atau  dapat 
diasumsikan bahwa data training  adalah data yang digunakan sebagai acuan untuk membangun model klasifikasi, 
sedangkan data testing  adalah data yang digunakan untuk menguji performa dari model klasifikasi tersebut.  
Pada skenario pengujian ini data training  sudah dipersiapkan sebelumnya dan disimpan ke dalam dataset. Hasil 
data training  (pembelajaran) yang didapat akan diuji dengan data baru yang masih belum diketahui classtype  
kategorinya. Pada penelitian ini terdapat proses  preprocessing. Adapun tahapan ini adalah Normalisasi fitur, 
tokenizing, stop -words,  dan stemming.  Proses ini bertujuan untuk mendapatkan data training  yang sesuai harapan 
si analis. Disini penulis melakukan variasi pada tahap preprocessing  dengan menghilangkan salah satu tahapan 
preprocessing  yaitu tahap Normalisasi fitur. Pada tahapan ini penulis ingin mengetahui tingkat akurasi ketika 
salah satu tahapan dihilangkan apakah akan berpengaruh pada hasil akurasi atau tidak.  Tabel 1 merupakan 
pembagian data training dan data testing dal am proses pengujian.  
Tabel 1. Pembagian Data Training  dan Data Testing  
No Class  Data Training  Data Testing  
1 Positif  931 354 
2 Negatif  70 354 
3 Netral  178 354 
Total  1179  1179  
 
3. HASIL DAN PEMBAHASAN  
3.1 Menghitung Probabilitas Kata  
 
Menghitung probabilitas kata dilakukan untuk bertujuan mendapatkan term dengan nilai yang lebih penting dan 
dianggap relevan untuk dijadikan kata kunci. Proses pembobotan menggunakan algoritma Naive Bayes Classifier 
dalam proses perhitungan persamaan dapat  dilihat pada Tabel 2.  
Tabel 2.  Contoh Kemunculan Term Frekuensi  
Kata  Frekuensi kemunculan kata (W k) 
354 Tweet  
Positif  354Tweet  
Negatif  354 Tweet  
Netral  
Pagi 189 7 - 
Cuaca  7 3 5 
Baik  13 1 6 
Oke 5 3 - 
Hoak  1 1 - 
Jangan  6 1 1 
Salah  3 - - 
Bantu  2 - 1 
Mungkin  2 5 - 
Tumben - 2 - 
Selanjutnya  mencari probabilitas kata pagi, cuaca, baik, oke, hoak, jangan, salah, bantu, mungkin, tumben :  
Diketahui  : 
 nTweet  Positif  : 354  
 nTweet  Negatif  : 354  
 nTweet  Netral  : 354  
a. Kata Pagi  
 189+1   
P(Pagi|Positif)=  = 0,16 
 354+825   
  7+1  
P(Pagi|Negatif)=  = 0,006  
 354+825   
 0+1  
P(Pagi|Netral)=  = 0,0008  
 354+825   
b. Kata Cuaca  
 7+1  
P(Cuaca|Positif)=  = 0,006  
 354+825   
 3+1  
P(Cuaca|Negatif)=  = 0,003  
 354+825   
 5+1  
P(Cuaca |Netral)=  = 0,005  
 354+825   
c. Kata  Bai k 
 13+1   
P(baik|Positif)=  = 0,011  
 354+825   
 1+1  
P(baik|Negatif)=  = 0,0016  
 354+825   
 6+1  
P(baik|Netral)=  = 0,005  
 354+825   
 d. Kata oke  
 5+1  
P(Oke|Positif)=  = 0,005  
 354+825   
 3+1  
P(Oke|Negatif)=  = 0,003  
 354+825   
 0+1  
P(Oke|Net ral)=  = 0,0008  
 354+825   
e. Kata Hoak  
 1+1  
P(Hoak|Positif)=  = 0,0016  
 354+825   
 1+1  
P(Hoak|Negatif)=  = 0,0016  
 354+825   
 0+1  
P(Hoak|Netral)=  = 0,0008  
 354+825   
f. Kata Jangan  
 6+1  
P(jangan|Positif)=  = 0,0059  
 354+825   
  6+1  
P(jangan|Negatif)=  = 0,0059  
 354+825   
  1+1  
P(jangan|Netral)=  = 0,0016  
   354+825   
g. Kata Salah  
          3+1  
P(Salah|Positif)=  = 0,003  
       354+825   
           0+1  
P(Salah|Negatif)=  = 0,0008  
       354+825   
           0+1  
P(Salah|Netral)=  = 0,0008  
        354+825   
h. Kata Bantu  
            2+1  
P(Bantu|Positif)=  = 0,0025  
         354+825   
            0+1  
P(Bantu|Negatif)=  = 0,0008  
  354+825   
      1+1  
P(Bantu|Netral)=  = 0,0016  
         354+ 825  
i. Kata Mungkin  
           2+1  
P(Mungkin|Positif)=  = 0,0025  
          354+825   5+1  
P(Mungkin|Negatif)=  = 0,005  
 354+825   
     0+1  
P(Mungkin|Netral)=  = 0,0008  
 354+825   
j. Kata Tumben  
0+1  
P(Tumben|Positif)=  = 0,0008  
       354+825   
           2+1  
P(Tumben|Negatif)=  = 0,0025  
       354+825  
           0+1  
P(Tumben|Netral)=  = 0,0008  
       354+825  
Setelah mendapatkan hasil dari probabilitas  kata, kemudian akan menghitung probabilitas dari dokumen ( Tweet ) sampel ata u contoh. Diasumsikan P(V j) (probabilitas kategori dokumen) sama dengan docs j  (jumlah dokumen setiap kategori) dibagi dengan | contoh | (jumlah dokumen yang digunakan sebagai data training dari seluruh kategori). Diperoleh persamaan  (5). 
ð‘ƒ(ð‘£ð‘— )=|ð‘‘ð‘œð‘ð‘— |
|ð¶ð‘œð‘›ð‘¡ð‘œ â„Ž|           (5) 
 Perhitungan probabilitas Tweet dimana terdapat 1179 Tweet yang terbagi 354 Tweet  kelas positif, 354 Tweet  kelas 
negatif dan 354 Tweet  kelas netral :  
Data kata dari Tweet  nilai probabilitas d apat dilihat pada Tabel 3.  
354
P(Positif) =                                      = 0,3  
1179
354
P(Negatif) =                                     = 0,3  
1179
354
P(Netral) =                                     = 0,3  
Tabel 3.  Daftar Uji Kata  
No Kata  Prob positif V1  Prob Negatif V2  Prob Netral V3  
1 Pagi 0,16 0.006  0,0008  
2 Cuaca  0,006  0,003  0,005  
3 Baik  0,0011  0,0016  0,005  
4 Oke 0,005  0,003  0,0008  
5 Hoak  0,0016  0,0016  0,0008  
6 Jangan  0,0059  0,0059  0,0016  
7 Salah  0,003  0,0008  0,0008  
8 Bantu  0,0025 0,0008  0,0016  
9 Mungkin  0,0025  0,005  0,0008  
10 Tumben  0,0008  0,0025  0,0008  
Untuk mendapatkan nilai probabilitas nilai tertinggi langkah pertama yakni menghitung (P(W k1|Vj)P(V j)). P(V j) 
didapat probabilitas dokumen:  
Kata    (Pagi|Positif)   :  0,16 *0 ,3 = 0,048  
 (Pagi|Negatif)   :  0,006 *0,3  = 0,0018  
 (Pagi|Netral)   :  0,0008 *0,3  = 0,00024  
(Cuaca|Positif)   :  0,006 *0,3  = 0,0018  
 (Cuaca|Negatif)   :  0,003 *0,3  = 0,0009  
 (Cuaca|Netral)   :  0,005 *0,3  = 0,0015  
(Baik|Positif)   :  0,011*0,3  = 0,0033  
 (Baik|Negatif)   :  0,0016 *0,3  = 0,00048  
 (Baik|Netral)    : 0,0045*0,3  = 0,00135  
(Ok|Positif)   :  0,005*0,3  = 0,0015  
 (Ok|Negatif)   :  0,003 *0,3  = 0,0009  
 (Ok|Netral)   :  0,0008 *0,3  = 0,00024  
(Hoak|Positif)   :  0,0016 *0,3  = 0,00048  
 (Hoak|Negatif)   :  0,0016 *0,3  = 0,00048  
 (Hoak|Netral)   :  0,0008 *0,3  = 0,00024  
(Jangan|Positif)   :  0,0059 *0,3  = 0,0017  
 (Jangan|Negatif)   :  0,0059*0,3  = 0,0017  
 (Jangan|Netral)   :  0,0016 *0,3  = 0,0048  
(Salah|Positif)   :  0,003 *0,3  = 0,0009  
 (Salah|Negatif)   :  0,0008 *0,3  = 0,00024  
 (Salah|Netral)   :  0,0008 *0,3  = 0,00024  
(Bantu|Positif)   :  0,0025 *0,3  = 0,00075  
 (Bantu|Negatif)   :  0,0008 *0,3  = 0,00024  
 (Bantu|Netral)   :  0,0016*0,3  = 0,00048  
 (Mungkin|Positif)   :  0,0025*0,3  = 0,00075  
 (Mungkin|Negatif)  :  0,005 *0,3  = 0,0015  
 (Mungkin|Netral)   :  0,0008 *0,3  = 0,00024  
 (Tumben|Positif)   :  0,0008 *0,3    = 0,00024  
 (Tumben|Negatif)  :  0,0025 *0,3   = 0,00075  
 (Tumben|Netral)   :  0,0008 *0,3    = 0,00024  
 Setelah itu menghitung nilai probabilitas tertingg i dari masing -masing kategori.  
Probabilitas Positif Tertinggi   =  0,048 * 0,00 18 * 0,0033 * 0,0015 * 0,00048 *  0,0017 *  0,0009  * 0,00075 *  
0,00075  * 0.00024  =  4.24019059e -29 
 Probabilitas Negatif Tertinggi =  0,0018 * 0,0009 * 0,00048 * 0,00 0 * 0,00048 *0,00017 *0,00024 *0,00024 * 
0,0015  * 0,00075 = 3.70052997e -33 
Probabilitas Netral Tertinggi   =  0,00024 * 0,0015 * 0,00135 * 0,0 002 * 0,00024 *0,0004 8 * 0,00024 * 0,00048 
* 0,00024 * 0.00024  =  8.91610045e -35 
 Tabel 4 . Nilai Probabilitas  
Probabilitas Po sitif 
Tertinggi  Probabilitas Negatif 
Tertinggi  Probabilitas Netral 
Tertinggi  
4.24019059e -29 3.70052997e -33 8.91610045e -35 
 Dari perhitungan algoritma naive bayes yang dilakukan, kemudian dicari perbandingan nilai probabilitas tertinggi dari masing -masing  Tweet  sehingga Tweet  yang sudah di testing dapat di kategorikan kedalam dokumen Tweet  opini yang sesuai de ngan isi teksnya. Pada tabel 4  dapat dilihat hasil dari keseluruhan proses perhitungan 
probabilitas tertinggi dengan naive bayes . Pada tabel tersebut probabilitas positif memiliki nilai tertinggi.Sehingga dapat dipastikan Tweet  yang dipilih merupakan dokumen Tweet  positif.  
3.2 Pembahasan  
3.2.1 Hasil Pembagian Data  
Berikut adalah rekapan hasil pembangian d ata positif, netral, dan negatif dapat dilihat  pada Tabel 5, 6, 7 dan 8.  
Tabel 5. Kasus Data Training  Positif  
Tweet  Kalimat  Label 
Tweet 1 Dengarkan update informasi  Positif  
Tweet 2 baik, tunggu. terimakasih banyak  Positif  
Tweet 3 silakan kami sudah respon pesan terimakasih  Positif  
Tweet 4 Peringatan  dini cuaca wilayah Kalimantan Tengah  Positif  
Tweet 5 Selamat Pagi, mohon informasi yang akurat, terima kasih.  Positif  
Tweet 6 Cuaca di Jakarta hari ini (23/6) diperkirakan cerah dan 
berawan sepanjang hari.  Positif  
Tweet 7 Bahkan BMKG gak bikin peringatan dini buat Kepulauan 
Bangka Belitung  Positif  
Tweet 8 Utara Jawa dong min  Positif  
Tweet 9 Prediksi BMKG Jogja bisa mencapai suhu 8Ã‚Â°c  Positif  
Tweet 10 Aku selalu bilang sama oppung, ada terpasang info bmkg 
pung di hpku jd tau nnti kalo ada peringatan,tenang aja 
oppung. Bbrp bulan lalu, tiba tiba laut surut jauh. 
Seingatku kami ngungsi akhirnya sampe jam 5  Positif  
Tabel 6. Kasus Data Training  Negatif  
Tweet  Kalimat  Label 
Tweet 1 Awas aja, kalo alat ini masih ada  Negatif  
Tweet 2 Sini aju naik, sini aku naikin gajinya  Negatif  
Tweet 3 Setiap nebak pasti ditolak  Negatif  
Tweet 4 #Gempa Mag:3.2, 16 -Nov-18 02:00:36 WIB, Lok:2.99 
LS, 119.50 BT (Pusat gempa berada di darat 21 km 
Tenggara Mamasa), Kedlmn:10 Km Dirasakan (MMI) III 
Mamasa #BMKG...  Negatif  
Tweet 5 Dirasakan di Lombok Barat juga  Negatif  
Tweet 6 RT BpbdTrenggalek """"Prakiraan cuaca Kabupaten 
Trenggalek  Negatif  
Tweet 7 Yaudah sih, lagian ini juga BNPB bukan BMKG yg 
ngasih Info.  Negatif  
Tweet 8 Sumpah gue lagi tidur semalem kaya ada yg nyenggol 
jadi parno eh tau tau gempa  Negatif  
Tweet 9 Emang due kepala kok sok2an sambat ngelu ?  Negatif  
Tweet 10 Aku ga keroso i min  Negatif  
Tabel 7. Kasus Data Training  Netral  
Tweet  Kalimat  Label 
Tweet 1 Bmkg itu bakso malang karapitan group  Netral  
Tweet 2 Nggak ada yang d ibuat rebahan  Netral  
Tweet 3 Kenceng apanya Grid? Akhir bulan aku pulang.  Netral  
Tweet 4 Aku itu punya aplikasi @infoBMKG tiap ada gempa 
selalu ada info, sekecil apapun  Netral  
Tweet 5 Gempi mksd e?  Netral  
Tweet 6 Mosok ee, pengalaman ledome wkw  Netral  
Tweet7 Nyuci baju selesai dan hujan pun turun  Netral  
Tweet 8 Belum ada pak  Netral  
Tweet 9 Yo lek mbak e turu gk kerasa  Netral  
Tweet 10 Gk keroso min, turuku anteng paling, tangi2 wes adan 
subuh.  Netral  
Tweet 4 Aku itu punya aplikasi @infoBMKG tiap ada gempa 
selalu ada info, sekecil apapun  Netral  
Tweet 5 Gempi mksd e?  Netral  
Tweet 6 Mosok ee, pengalaman ledome wkw  Netral  
Tweet 7 Nyuci baju selesai dan hujan pun turun  Netral  
Tweet  Kalimat  Label 
Tweet 8 Belum ada pak  Netral  
Tweet 9 Yo lek mbak e turu gk kerasa  Netral  
Tweet 10 Gk ker oso min, turuku anteng paling, tangi2 wes adan 
subuh.  Netral  
Tweet 4 Aku itu punya aplikasi @infoBMKG tiap ada gempa 
selalu ada info, sekecil apapun  Netral  
Tweet 5 Gempi mksd e?  Netral  
Tweet 6 Mosok ee, pengalaman ledome wkw  Netral  
Tweet 7 Nyuci baju seles ai dan hujan pun turun  Netral  
Tweet 8 Belum ada pak  Netral  
Tweet 9 Yo lek mbak e turu gk kerasa  Netral  
Tweet 10 Gk keroso min, turuku anteng paling, tangi2 wes adan 
subuh.  Netral  
Tabel 8. Pembagian Data Training  
No Class  Data Training  
1 Positif  931 
2 Negatif  70 
3 Netral  178 
Total  1179  
Gambar 5.  Grafik Pembagian Data  
3.2.2 Akurasi Data  
Akurasi adalah penghitungan dari perbandingan antara jumlah data dokumen yang relevan dan jumlah 
keseluruhan dokumen  dalam database [15]. Menghitung akurasi dapat menggunakan persamaan 6.  02004006008001000
Positif Negatif Netral Grafik Pembagian Data
Data Training 
144
 ð´ð‘˜ð‘¢ð‘Ÿð‘Žð‘ ð‘– = ð½ð‘¢ð‘šð‘™ð‘Ž â„Ž ð·ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›  ð‘…ð‘’ð‘™ð‘’ð‘£ð‘Žð‘›  
ð½ð‘¢ð‘šð‘™ð‘Ž â„Ž ð¾ð‘’ð‘ ð‘’ð‘™ð‘¢ð‘Ÿð‘¢ â„Žð‘Žð‘› ð·ð‘œð‘˜ð‘¢ð‘šð‘’ð‘›        (6) 
ð´ð‘˜ð‘¢ð‘Ÿð‘Žð‘ ð‘– = 825
1179
ð´ð‘˜ð‘¢ð‘Ÿð‘Žð‘ ð‘– = 69,97%  
Berdasarkan hasil pembahasan, dari proses dan tahapan preprocessing  yang dilakukan Tweet  yang mengungkapkan sebuah eksprsi positif dan membuat Tweet  tersebut terbaca negatif karena kesalahan. Hal ini dikarenakan masih ada yang terbaca negatif meskipun Tweet  yang disertai me nununjukan Tweet  positif.  Tabel 9 menunjukkan contoh kesalahan Tweet  yang didapat.  
Tabel 9.  Contoh Kesalahan Tweet  
Tweet  Positif  Negatif  Netral  
Bantu pantau hilal jodoh saya min @infoBMKG (positif)    âˆš 
Wahwahh (netral)   âˆš  
Jalan ma aku aja (negatif)    âˆš 
Tidur min, mau temanin saya nonton bola? (negatif)  âˆš   
min ini bener atau hoax y? (positif)   âˆš  
Aku disemagati oleh diriku sendiri (positif)   âˆš  
Notif dari tadi gak ada notif WA atau line isi nya notif 
(positif)   âˆš  
Bahkan yang selalu serius pun butuh waktu rehat sejenak 
untuk menghela nafas, dan tersenyum (positif)   âˆš  
Dengan menghilangkan salah satu tahapan preprocessing  seperti yang penulis lakukan yaitu dengan menghilangkan tahapan Normalisa si fitur sangat berpengaruh dengan nilai akurasi yang dihasilkan karena dapat mengurangi hasil akurasi pada klasifikasi Tweet . 

4. KESIMPULAN  
Berdasarkan hasil penelitian dan pembahasan yang dilakukan, maka terdapat beberapa kesimpulan yaitu :  
1. Proses ekstraka si data dari Twitter  BMKG Nasional menggunakan Bahasa pemrograman Python 3.74 dengan tahapan Preprocessing yang meliputi casefolding, filtering, tokenisasi, slang replacement dan stopword  removal.  
2. Sentimen analisis yang dilakukan adalah membuat tiga kelas yaitu postif, negatif dan netral menggunakan algoritma klasifikasi Naive Bayes.  
3. Tingkat akurasi berdasarkan pengujian yang dilakukan adalah 68,97%.  
 
REFERENCES  
[1] Apji, â€œAsosiasi Pengusaha Jasa Internet Ind onesia,â€ Jakarta, 2014.  
[2] D. Darwis, E. S. Pratiwi, and A. F. O. Pasaribu, â€œDATA TWITTER  KOMISI PEMBERANTASAN KORUPSI 
REPUBLIK INDONESIA,â€ J. Ilm. Edutic , vol. 7, no. 1, pp. 1â€“11, 2020.  
[3] A. Samad, H. Basari, B. Hussin, I. G. Pramudya, and J. Zeniarja,  â€œOpinion Mining of Movie Review using Hybrid Method of Support Vector Machine and Particle Swarm Optimization Opinion Mining of Movie Review using Hybrid Method of Support Vector Machine and Particle Swarm Optimization,â€ Procedia Eng. , vol. 53, no. Decemb er, pp. 453â€“462, 2013, doi: 10.1016/j.proeng.2013.02.059.  
[4] M. A. Assuja and Saniati, â€œAnalisis Sentimen Tweet  Menggunakan,â€ J. Tek. , vol. 10, no. 2, pp. 23 â€“28, 2016.  
[5] A. P. Wijaya, H. A. Santoso, J. T. Informatika, U. Dian, and N. Semarang, â€œNaive Ba yes Classification pada Klasifikasi Dokumen Untuk Identifikasi Konten E -Government,â€ J. Appl. Intell. Syst. , vol. 1, no. 1, pp. 48 â€“55, 2016.  
[6] A. R. Isnain, A. Sihabuddin, and Y. Suyanto, â€œBidirectional Long Short Term Memory Method and Word2vec Extracti on Approach for Hate Speech Detection,â€ IJCCS (Indonesian J.Comput. Cybern. Syst. , vol. 14, no. 2, 2020. 
[7] A. Amolik, N. Jivane, M. Bhandari, and M. Venkatesan, â€œ Twitter  sentiment analysis of movie reviews using machine 
learning technique,â€ Int. J. Eng. Technol. , vol. 7, no. 6, pp. 2038 â€“2044, 2016.  
[8] A. Surahman, â€œPENGEMBANGAN MARKET SEGMENTASI UNTUK MENCAPAI KEUNGGULAN BERSAING PADA E -MARKETPLACE,â€ J. Komput. dan Inform. , vol. 15, no. 1, pp. 118 â€“126, 2020.  
[9] B. R. Feldman, â€œTechniques an d Applications for Sentiment Analysis,â€ Commun. Acm , vol. 58, no. 4, pp. 83 â€“89, 2013.  
[10] L. F. S. Coletta, N. F. F. da Silva, E. R. Hruschka, and E. R. H. Jr, â€œCombining classification and clustering for Tweet  sentiment analysis Combining Classification and Clustering for Tweet Sentiment Analysis,â€ in Brazilian Conference on Intelligent Systems , 2014, pp. 210 â€“2015, doi: 10.1109/BRACIS.2014.46.  
[11] I. D. I, I. Amirulloh, and D. Rosiyadi, â€œAnalisis Sentimen Media Sosial Opini Ujian Nasional Berbasis Komputer menggunakan Metoda Naive Bayes,â€ J. Electr. Electron. Eng. , vol. 1, no. 2, pp. 38 â€“45, 2016.  
[12] D. Alita, Y. Fernando, and H. Sulistiani, â€œImplementasi Algoritma Multiclass SVM pada Opini Publik Berbahasa Indonesia di Twitter ,â€ J. Tekno Kompak , vol. 14 , no. 2, pp. 86 â€“91, 2020.  
[13] J. Ling and T. B. Oka, â€œANALISIS SENTIMEN MENGGUNAKAN METODE NAÃVE BAYES CLASSIFIER DENGAN SELEKSI FITUR CHI SQUARE,â€ E-Jurnal Mat. , vol. 3, no. 3, pp. 92 â€“99, 2014.  
[14] A. Rahmawati, A. Marjuni, and J. Zeniarja, â€œAnalisis Sentimen Publik Pada Media Sosial Twitter  Terhadap Pelaksanaan Pilkada Serentak Menggunakan Algoritma Support Vector Machine,â€ CCIT J. , vol. 10, no. 2, pp. 197 â€“206, 2017.  
[15] A. Surahman, A. F. O. P. Pasaribu, and D. Darwis, â€œEkstraksi Data Produk e -Market place Sebagai Strategi Pengolahan Segmentasi Pasar Menggunakan Web Crawler,â€ Sist. J. Sist. Inf. , vol. 9, no. 1, pp. 73 â€“81, 2020.  ",Analisis Sentimen,naive bayes,data internal yang diambil dari internet/ Twitter,akurasi
Analisis Sentimen Calon Presiden 2024 Menggunakan Algoritma SVM  Pada Media Sosial Twitter ,"Analisis Sentimen Calon Presiden 2024 Menggunakan Algoritma SVM  Pada Media Sosial Twitter  

Aprilia Putri Nardi lasari1, April Lia Hananto2*, Shofa Shofia Hilabi3, Tukino4, Bayu Priyatna5 

Abstract                                                                  
Stakeholders widely use sentiment analysis in assessing sentiment towards an object. In this research, the object to be taken  is sentiment analysis of political figures for the 2024 presidential candidate which is being widely discussed by netizens, especi ally on Twitter. The issues raised are regarding the performance measurement of an algorithm in classifying sentiments, some algorithms often need a higher level of accuracy. This study aims to improve performance measures from previous studies using the Naive Bayes algorithm which has a fairly low level of accuracy, and in this study the SVM algorithm was used. This study takes Twitter data related to presidential candidates to see public opinion for each presidential candidate. The data taken was Twitter data with the keywords Ganjar, Anies, Prabowo totaling 8,959 data taken on October 17 -25 2022. The results the test concluded that the SVM algorithm has a performance measure or quite high accuracy compared to the Naive algorithm in previous studi es only of 73.86% while the SVM algorithm gets an average accuracy value of 98.61%, namely the                                                                 Ganjar Pranowo dataset, then 98.81% precision, 99.79% recall. And for the proportion of sentiment, the positive obtained by Ganjar was higher than the other presidential candidates, namely 55%, Prabowo 30% and Anies 15%, Anies' negative sentiment was 89% higher than Ganjar 8% and Prabowo 3%.                                                                  
Keywords:  capres, pilpres, sentiment analysis, SVM, twitter.                                 
Abstrak                                                                  
Analisis Sentimen banyak digunakan pemangku kepentingan dalam menilai sentimen terhadap suatu objek. Pada penelitan objek yang akan diambil yaitu analisis sentimen terhadap  tokoh politik  calon presiden 2024 yang sedang diperbincangkan oleh warganet, khususnya di twitter. Adapun permasalahan yang diangkat yaitu mengenai ukuran kinerja suatu algoritma dalam melakukan klasifikasi sentimen, beberapa algoritma kerap memiliki tingkat akurasi yang rendah. Penelitian ini bertujuan untuk meningkatkan perfo rmance measure  dari penelitian sebelumnya dengan menggunakan algoritma Naive Bayes yang memiliki tingkat akurasi cukup rendah, dan pada penelitian ini digunakan algoritma SVM. Penelitian ini mengambil data Twitter yang berhubungan terhadap calon presiden u ntuk melihat opini masyarakat kepada setiap calon presiden. Data yang diambil yaitu data t witter dengan kata kunci Ganjar, Anies, Prabowo sebanyak 8.959 data yang diambil pada tanggal 17 -25 Oktober 2022. Hasil dari pengujian mendapatkan kesimpulan algoritm a SVM mempunyai performance measure  atau akurasi cukup tinggi dibandingkan dengan algoritma Naive Bayes pada penelitian sebelumnya hanya sebesar 73, 86% sementara algoritma SVM mendapat nilai rata -rata accuracy  mencapai 98,61% yaitu dataset Ganjar Pranowo , lalu precision  98,81%, recall  99,79%. Dan untuk proporsi sentimen menunjukan sentimen positif yang diperoleh Ganjar lebih tinggi daripada calon presiden lainnya yaitu 55%, Prabowo 30% dan Anies 15%, Sementara sentimen negatif Anies lebih tinggi 89% daripada Ganjar 8% dan Prabowo 3%.                                                                  
Kata kunci:  capres, pilpres, analisis sentiment, SVM, twitter .                                                                                                   
1. Pendahuluan                                                                  
Pemilihan calon presiden yang diselenggarakan setiap 5 tahun sekali merupakan bagian dari proses demokrasi khususnya di Negara Indonesia. Seorang politisi yang ingin mencalonkan diri sebagai presiden tentu akan memeriksa atau mempertimbangkan popularitasnya berdasarkan opini publik. Media sosial yang marak dikenal oleh masyarakat untuk mengajukan pendapatnya dikenal dengan Twitter. Twitter adalah sosial media yang didirikan oleh Jack Dorsey pada tahun 2006. Pada tahun 2019, terdapat 500 juta kicauan atau tweet oleh pengguna Twitter per hari, menurut siaran pers Twitter. Lebih dari 500 juta Tweet telah digunakan untuk memposting dan berbagi informasi tentang pengguna, dan juga konten Tweet dapat mengekspresikan perasaan . Twitter merupakan situs web yang mempunyai layanan menyediakan kumpulan data opini dari orang-orang di seluruh dunia. Hasil dari penyaluran opini dan komentar, Tweet merupakan sumber informasi yang dapat digunakan untuk menganalisis opini publik terhadap institusi dan individu.  Opini pada tweet ini dapat digunakan untuk melihat bagaimana sentimen berjalan. Salah satunya adalah tentang pendapat seseorang tentang politisi yang mencalonkan diri sebagai presiden Indonesia pada tahun 2024  [1]. Kemajuan teknologi telah mempermudah masyarakat dalam mendapatkan sebuah informasi dengan sangat cepat, internet adalah sebuah bukti dari perkembangan                                                                 teknologi yang saat ini banyak memberikan pengaruh terhadap masyarakat  [2][3]. Internet memberikan peranan yang sangat penting pula dalam proses penyaluran sebuah informasi. Banyak orang yang mengungkapkan pendapatnya di media sosial,                                                                 khususnya Twitter  [4]. Hal tersebut meningkatkan kemampuan kita untuk memahami pandangan politik dari komunitas pengguna media sosial. Sejumlah besar pengguna media sosial memungkinkan para peneliti untuk menggunakan status seseorang menjadi data sentimen untuk diproses dan dianalisis. Analisis sentimen dari pengolahan status atau tweet dari pengguna Twitter menunjukkan opini masyarakat kepada pemilihan calon presiden dan calon wakil presiden. Sentiment analysis  berguna dalam mengembangkan sistem untuk menganalisis, mengidentifikasi, dan                                                                 mengungkapkan pendapat dalam bentuk teks dan juga merupakan proses yang berfungsi untuk mengidentifikasi berupa opini atau sentimen dari isi dataset, berupa teks tentang topik atau peristiwa positif dan negatif [5][6]. Informasi berbentuk teks kini tersebar luas di internet dalam bentuk  blog, forum , sosial media, dan situs berisi  ulasan  [7]. Sentimen  positif atau negatifnya sebuah  opini bisa diproses  dengan cara                                                                  manual, namun tentunya semakin besar  jumlah  sumber opini akan  bertambah  banyak  pula waktu dan tenaga yang diperlukan  dalam  pengklasifikasian  polaritas opini tersebut. Maka  dari itu, diusulkan  penerapan metode pembelajaran mesin untuk mengklasifikasi kan polaritas opini dari sumber data yang berjumlah banyak dengan memanfaatkan  fungsi dari text mining  [8]. Pada penelitian sebelumnya yang dilakukan Muhammad Raihan Fais Syaâ€™bani  mengenai Analisis Sentimen Terhadap Bakal Calon Presiden 2024 dengan Algoritma Naive Ba yes telah dilakukan analisis  sentimen                                                                 menggunakan metode Naive Bayes. Dalam penelitian tersebut berhasil meng hasilkan evaluasi dari algoritma Naive Bayes yaitu akurasi sebesar 73,68%. Dalam hal ini terlihat bahwa algoritma Naive Bayes dirasa masih memperol eh tingkat akurasi yang cukup rendah  [9]. Algoritma klasifikasi mempunyai kelebihan dan kelemahannya tersendiri untuk pengklasifikasian data teks. Penentuan algoritma Support Vector Machine  pada                                                                 penelitian ini karena mempunyai kemampuan dalam menggeneralisasi ke tingkat akurasi yang cukup tinggi dalam mengklasifikasikan sebuah pola  [10]. SVM adalah suatu metode untuk menganalisis data dan mengenali pola. Algoritma ini bisa berfungsi dalam analisis klasifikasi dan regresi. Algoritma SVM juga dapat membuat prediksi dan penilaian mengenai sistem. SVM bertuju an untuk memberi nilai frekuensi kata untuk mengklasifikasikan kalimat dengan pelabelalan positif dan negatif [11]. Adapun penelitian ini bertujuan dalam meningkatkan perfo rmance measure penelitian sebelumnya yang menggunakan algoritma Naive Bayes dengan menggunakan algoritma SVM.                                                                  
2. Metode  Penelitian                                                                  
Pada tahap ini akan dijelaskan yaitu mengenai metode yang digunakan pada penelitian ini. Metode penelitian melewati beberapa tahapan yang dimulai dari mengumpulkan data, pengumpulan data dilakukan melalui crawling  data twitter dan didukung dengan data kepustakaan sebagai sumber pustaka. Selanjutnya pengolahan data yang dilakukan pada tahap preprocessing. Tahap preprocessing  terdiri dari cleansing, case folding, tokenize  dan filter stopwords . Kemudian klasifikasi teks dan hasil klasifikasi . Gambar 1 menunjukkan tahapan alur pada penelitian ini.                                                                  
2.1. Metode Pengumpulan Data                                                                  
Penelitian ini mengambil data tweet dan komentar retwitt pengguna aplikasi sosial media Twitter. Data tweet dilakukan melalui cara Crawling  pada twitter. Data yang diperoleh berjumlah 8.959 tweet dengan kata kunci Anies, Ganjar, dan Prabowo. Pengumpulan data tweet ini dilakukan mulai pada tanggal 17 Oktober 2022                                                              sampai dengan 25 Oktober 2022. Untuk mengumpulkan data menggunakan metode kepustakaan dilakukan melalui pengumpulan literature  untuk menghasilkan data sekunder seperti jurnal, buku, makalah, dan situs media online sebagai sumber pustaka [12][13][14] yang relevan dengan topik penulisan yaitu analisis sentimen menggunakan algoritma SVM.  
Gambar 1. Tahap Penelitian                                                                  
2.2. Tahap Preprocessing                                                                  
Pertama Cleansing  yaitu proses membersihkan data teks dengan menghapuskan data yang tidak relevan dan tidak konsisten. Clean sing berfungsi untuk menghilangkan                                                                 karakter yang bersifat tidak penting seperti hashtag  (#), angka,  username  (@), URL, tanda baca (punctuation), dan emoticon.  Selanjutnya Case folding  merupakan                                                                 proses mengubah bentuk kata sebuah karakter agar menjadi seragam (lower case)  [15].                                                                 Kemudian Tokenize  adalah tahapan untuk membagi teks menjadi bagian -bagian token. Tahap awal dari prepocessing text  adalah Tokenization  yaitu sebuah tools untuk memecahkan teks menjadi bagian yang lebih kecil (kalimat, kata dan bigrams) [16]. Dan Filter StopWord adalah proses menghilangkan kata-kata dengan bahasa indonesia. Remove stopwords  untuk menghilangkan atau sebagai penghapus setiap kata yang bisa diabaikan. Filter StopWord  digunakan kamus stopwords Bahasa                                                                 
Indonesia  [15].                                                                 
2.3. Model Klasifikasi SVM                                                                  
Proses klasifikasi menggunakan Aplikasi Rapidminer. Metode klasifikasi yang diimplementasikan  dalam penelitian ini adalah Support Vector Machine  (SVM). Support Vector Mac hine (SVM) merupakan  sebuah metode pembelajaran terpandu  untuk  menganalisis data dan mengenali pola, digunakan dalam analisis  klasifikasi                                                                 dan regresi  [17]. Berikut merupakan ilustrasi Hyperlane pada SVM yang ditunjukkan pada Gambar 2. Proses pengklasifikasian data uji memakai metode 10 - fold cross validation. Oleh karena itu, dataset membagi menjadi dua bagian,  9/10 bagian sebagai  proses pelatihan dan 1/10 bagian sebagai  proses pengujian. Iterasi dilakukan seba nyak 10 kali menggunakan data latih dan uji yang berbeda dengan memakai  gabungan  10 irisan data  [18]. Ilust rasi 10 fold cross validation dituntukkan pada Gambar 3.                                                                   Gambar 2. Ilustrasi Hyperplane  pada SVM                                                                  
Gambar 3 . Ilustrasi 10 fold cross validation                                                                  
2.4. Evaluasi dan Hasil Akurasi                                                                  
Evaluasi sebuah model klasifikasi dapat dilakukan terhadap suatu data  uji yang mempunyai nilai tertentu dan tidak dipakai untuk data  latih. Klasifikasi model yaitu membuat penggambaran dari sebuah baris data dengan keluaran suatu prediksi target atau kelas data tersebut. Klasifikasi yang mempunyai keluaran dua kelas disebut klasifikasi biner. Kedua kelas digambarkan dalam {positif, negatif}. Berikut empat kemungkinan proses klasifikasi suatu baris data True Positive Negative False Positive         False Negative . Pengukuran  yang digunakan  dalam  pengevaluasian model klasifikasi, yaitu  Accuracy . Accuracy  merupakan jumlah rasio  prediksi yang benar.  Evaluasi ini  berfungsi untuk mengukur nilai akurasi  dengan  menggunakan K-fold cross validation . Proses evaluasi menggunakan confusion matrix . Proses Evaluasi ini berfungsi  untuk                                                                 melihat  performa  dari model klasifikasi yang sudah diproses  dan menentukan  akurasinya . Berikut merupakan rumus dari setiap proses klasifikasi sentimen. Accuracy  adalah proporsi dari total prediksi true dari semua data , perhitungan accuracy  dapat dilihat pada rumus 1. Precision  adalah ukuran ketepatan dari hasil suatu model. Persamaannya adalah perbandingan antara true positive  dengan total data dengan label positive, perhitungan precision  dapat dilihat pada rumus 2. Dan recall  adalah ukuran kelengkapan dari sebuah model. Persamaan recall  perbandingan antara true                                                                 positive  terhadap total contoh yang benar -benar positive . Perhitungan recall  dapat dilihat pada rumus 3 . [19]                                                                 
Accuracy  = ð‘‡ð‘ƒ+ð‘‡ð‘                                                                
ð‘‡ð‘ƒ+ð¹ð‘ƒ+ð‘‡ð‘+ð¹ð‘                                               (1)                                                                 
Precision  = ð‘‡ð‘ƒ                                                                
ð‘‡ð‘ƒ+ð¹ð‘ƒ                                                       (2)                                                                 
Recall  = ð‘‡ð‘ƒ                                                                
ð‘‡ð‘ƒ+ð¹ð‘                                                            (3)                                                                 
Mulai                                                                  
Pengumpulan Dataset (Data Dari Twitter)                                                                  
Tahap Preprocessing                                                                  
Klasifikasi SVM                                                                  
Evaluasi  dan Hasil Akurasi                                                                  
Hasil & Kesimpulan  
 True Positive  (TP) merupakan jumlah data yang bernilai positif dan diprediksi benar sebagai positif. Kemudian False Positive  (FP) yaitu jumlah data yang bernilai negatif tetapi diprediksi sebagai p ositif. Sedangkan False Negative  (FN) adalah jumlah data yang bernilai positif tetapi diprediksi sebagai negatif. Dan True Negative  (TN) yaitu jumlah data yang bernilai negatif dan diprediksi benar sebagai negatif.                                                                  
3.  Hasil dan Pembahasan                                                                  
3.1. Pengumpulan Data                                                                  
Pengumpulan data untuk penelitian ini diambil melalui crawling  data twitter dengan menggunakan aplikasi Rapidminer  dengan keyword  yang mengandung kata para calon presiden seperti Anies, Ganjar, dan Prabowo. Pengumpulan data ini dilakukan pada rentang waktu cuitan mulai dari tanggal 17 â€“ 25 Oktober 2022 dengan jumlah sebanyak 8. 959. Tabel 1 menunjukkan Jumlah hasil  data crawling dari t witter . Tabel 2 merupakan contoh data hasil crawling . Dan untuk persiapan crawling  data dapat dilihat pada Gambar 4.                                                                  
Tabel 1. Hasil Pengumpulan Data                                                                  
Dataset  Jumlah Data                                                                  
Anies Baswedan  1.589                                                                  
Ganjar Pranowo  4.732                                                                  
Prabowo Subianto   2.683                                                                  
Tabel 2. Contoh Data Hasil Crawling                                                                  
No Tweet                                                                  
1 RT @NasDem: NasDem tak sembrono memilih Anies Baswedan  sebagai capres 2024 Hal tersebut ditegaskan langsung oleh Ketua Umum Partai NasDemâ€¦                                                                  
2 RT @lilandy157: DKI Jakarta sangat mendukung Ganjar Pranowo, semakin terdepan                                                                  
3 """"Itu sebabnya Prabowo adalah capres yang paling tepat untuk melanjutkan estafet kepemimpinan ke depan,"""" kata Muzani h ttps://t.co/c8JhqWH4sI @prabowo                                                                 
Gambar 4. Persiapan Crawling  Data                                                                 
3.2. Preprocessing  Data                                                                  
Tahap selanjutnya adalah preprocessing. Adapun tahap yang dilakukan pada proses preprocessing adalah cleansing, tokenize, transform case , dan filter stopword . Berikut merupakan tahapan preprocessing  data yang ditunjukkan pada Gambar 5.                                                                  
Gambar 5. Preprocessing  Data                                                                 
Pada proses ini dilakukan tahap pembersihan data yang sebelumnya telah dijelaskan pada metodologi penelitian. Hasil clean sing dari proses ini ditunjukkan dalam bentuk                                                                 tabel. Pada tahapan cleansing dari awal hingga pembersihan perbaikan ejaan ditunjukkan pada Tabel 3.                                                                  
Tabel 3. Contoh Data Hasil Clean sing                                                                 
Text Cleansing                                                                 
RT @NasDem: NasDem tak sembrono memilih Anies Baswedan  sebagai capres 2024                                                                 
Hal tersebut ditegaskan langsung oleh Ketua Umum Partai NasDemâ€¦  NasDem tak sembrono memilih Anies Baswedan sebagai capres 2024 Hal tersebut ditegaskan                                                                 langsung oleh Ketua Umum Partai NasDemâ€¦                                                                  
RT @lilandy157: DKI Jakarta sangat mendukung Ganjar Pranowo, semakin terdepan                                                                  mendukung Ganjar Pranowo semakin terdepan                                                                  
Itu sebabnya Prabowo adalah capres yang paling tepat untuk melanjutkan estafet                                                                 kepemimpinan ke depan,"""" kata Muzani https://t.co/c8JhqWH4sI                                                                 
@prabowo #MendingPrabowo capres yang paling tepat untuk melanjutkan estafet                                                                 kepemimpinan ke depan kata Muzani                                                                  
Tabel 4. Contoh Data Hasil Case Folding                                                                  
Text Case Folding                                                                  
NasDem tak sembrono memilih Anies Baswedan  sebagai capres 2024 Hal tersebut ditegaskan langsung oleh Ketua Umum Partai NasDemâ€¦  nasdem tak sembrono                                                                 memilih anies baswedan sebagai capres 2024 hal tersebut ditegaskan langsung oleh ketua umum partai nasdemâ€¦                                                                  
DKI Jakarta sangat mendukung Ganjar Pranowo semakin terdepan  dki jakarta sangat mendukung ganjar pranowo semakin terdepan                                                                  
Itu sebabnya Prabowo adalah capres yang paling tepat untuk melanjutkan estafet                                                                 kepemimpinan ke depan kata Muzani  itu sebabnya prabowo adalah capres yang paling                                                                 tepat untuk melanjutkan estafet kepemimpinan ke depan kata muzani                                                                   
Selanjutnya tahap case folding , yaitu proses mengubah bentuk kata -kata tweet  agar menjadi seragam atau menjadi huruf kecil (lower case ). Hasil case folding  dari tahap ini ditampilkan dalam bentuk tabel. Berikut merupakan contoh data hasil case folding  yang ditampilkan pada Tabel 4. Pada tahap selanjutnya yaitu tokenize . Tokenize merupakan proses untuk membagi teks menjadi bagian-bagian token. Hasil tokenize  dari tahap ini ditunjukkan dalam bentuk tabel. Berikut merupakan contoh data hasil                                                                 tokenize  yang terlihat  pada Tabel 5.                                                                  
Tabel 5. Contoh Data Hasil Tokenize                                                                  
Text Tokenize                                                                  
nasdem tak sembrono memilih anies baswedan  sebagai capres 2024 hal tersebut ditegaskan langsung oleh ketua umum partai nasdemâ€¦  [nasdem', 'tak', 'sembrono',                                                                 'memilih', 'anies', 'baswedan', 'sebagai', 'capres', '2024', 'hal', 'tersebut', 'ditegaskan',                                                                 'langsung', 'oleh', 'ketua', 'umum', 'partai', ' nasdem']                                                                  
dki jakarta sangat mendukung ganjar pranowo semakin terdepan  ['dki', 'jakarta', 'sangat', 'mendukung', 'ganjar', 'pranowo', 'semakin', 'terdepan'] itu sebabnya prabowo                                                                 adalah capres yang paling tepat untuk melanjutkan estafet kepemimpinan ke depan kata  ['itu', 'sebabnya', 'prabowo', 'adalah', 'capres', 'yang', 'paling', 'tepat, 'untuk', 'melanjutkan', 'estafet', 'kepemimpinan', 'ke', 'depan', 'kata', 'muzani']                                                                  
Tabel 6. Contoh Data Hasil Remove Stopwords                                                                  
Text Remove Stopwords                                                                  
[nasdem', 'tak', 'sembrono', 'memilih', 'anies', 'baswedan', 'sebagai', 'capres', '2024', 'hal',                                                                 'tersebut', 'ditegaskan', 'langsung', 'oleh', 'ketua', 'umum', 'partai', 'nasdem']  [nasdem', 'sembrono', 'memilih', 'anies', 'baswedan', 'capres', ' 2024', 'ditegaskan', 'ketua', 'umum',                                                                 'partai', 'nasdem']                                                                  
 ['dki', 'jakarta', 'sangat', 'mendukung', 'ganjar', 'pranowo', 'semakin', 'terdepan']  ['dki', 'jakarta', 'mendukung', 'ganjar', 'pranowo', 'semakin', 'terdepan']                                                                  
['itu', 'sebabnya', ' prabowo', 'adalah', 'capres', 'yang', 'paling', 'tepat, 'untuk', 'melanjutkan', 'estafet', 'kepemimpinan', 'ke', 'depan', 'kata', 'muzani'] 
['prabowo', 'capres', 'tepat, 'melanjutkan', 'estafet', 'kepemimpinan', 'muzani']                                                                  
Pada tahap ini dilakukan remove stopwords . Remove stopwords  merupakan proses menghilangkan kata dengan kamus bahasa Indonesia.  Remove stopwords yaitu tahap pemilihan kata-kata apa saja yang akan digunakan dan hanya mengambil kata penting saja dari hasil token untuk mewakili dokumen.  Berikut merupakan tampilan contoh data hasil remove stopwords yang ditunjukkan pada Tabel 6.  3.3. Model Klasifikasi Setelah proses preproccessing  data kemudian dilakukan analisa menggunakan algoritma SVM. Pada proses ini diguna kan teknik data mining . Model  klasifikasi yang                                                                 digunakan dalam penelitian ini adalah Support Vector Machine  (SVM).  Desain model dalam klasifikasi  dengan menggunakan aplikasi RapidMiner dapat dilihat pada Gambar 6 .                                                                  
Gambar 6. Model Klas ifikasi SVM                                                                  
3.4 Evaluasi dan Hasil Akurasi                                                                  
Pada tahap evaluasi dan hasil akurasi yaitu dilakukan penentuan nilai klasifikasi yang sudah berhasil dibangun di proses model klasifikasi sebelumnya. Metode evaluasi yang digunakan yaitu metode 10 K-fold validation . Berikut merupakan tampilan proses validasi dan parameter cross validation  pada RapidMiner  yang ditunjukkan pada Gambar 7.  Dan untuk proses dalam operator validasi sendiri ditunjukkan pada Gambar 8.                                                                  
Gambar 7. Tampilan proses validasi dan parameter cross  validation pada RapidMiner                                                                  
Gambar 8. Proses dalam operator Validasi Dalam menentukan hasil akurasi dibutuhkan suatu pengukuran evaluasi yang disebut confusion matrix. Confusion matrix adalah suatu  tabel termasuk sejumlah besar data pengujian yang diprediksi secara kuat dan lemah oleh model klasifikasi yang dipakai  dalam penentuan  performa  sebuah  model klasifikasi yang dapat menghasilkan recall, precision dan accuracy  [20]. Tabel 7 menunjukkan hasil klasifikasi algoritma SVM dari masing -masing calon presiden. Dan Tabel 8 menunjukkan has il klasifikasi algoritma Naive B ayes. Terlihat pada kedua tabel perbangingan bahwa algoritma SVM memiliki performance measure  yang cukup tinggi                                                                 dibandingkan dengan algoritma Naive Bayes.                                                                  
Tabel 7. Hasil Klasfikasi Algoritma  SVM                                                                  
Calon Presiden  Accuracy                                                                  
Ganjar  98,61%                                                                  
Prabowo  94,65%                                                                  
Anies  81,75%                                                                  
Tabel 8 . Hasil Klasfikasi Algoritma  Naive Bayes  [9]                                                                 
Calon Presiden  Accuracy                                                                  
Ganjar  73,68%                                                                  
Prabowo    60%                                                                 
Anies  71,43%                                                                  
Dan untuk hasil klasifikasi  algoritma SVM digambarkan dengan data grafik yang dapat dilihat pada Gambar 9. Hasil dari pengujian ini mendapatkan kesimpulan algoritma SVM  yang  memiliki accuracy  tertinggi untuk klasifikasi data yaitu dataset Ganjar Pranowo dengan nilai rata -rata accuracy  mencapai 98,61% , precision 98,81%, recall 99,79%. Dan pada Gambar 10 merupakan proporsi sentimen positif dan negatif dari                                                                 masing -masing calon presiden.                                                                  
Gambar 9. Grafik Hasil Algoritma Klasifikasi                                                                  
Gambar 10. Grafik Proporsi Sentimen Nama Calon Presiden  
4.  Kesimpulan                                                                  
Berdasarkan penelitian yang sudah selesai dilakukan, dapat ditarik kesimpulan bahwa analisis sentimen menggunakan algoritma SVM dapat di implementasikan dalam klasifikasi sentimen terhadap calon presiden 2024. Penelitian ini bertujuan dalam meningkatkan performance measure  pada penelitian sebelumnya yaitu menggunakan algoritma Naive Bayes lalu pada penelitian ini dilakukan klasifikasi sentimen menggunakan  algoritma SVM. Hasil dari pengujian mendapatkan kesimpulan algoritma SVM mempunyai performance measure  atau akurasi cukup tinggi dibandingkan dengan algoritma Naive Bayes pada penelit ian sebelumnya hanya sebesar 73, 86% sementara                                                                 
algoritma SVM mendapat nilai rata-rata accuracy mencapai 98,61% yaitu dataset Ganjar Pranowo, lalu precision  98,81%, recall  99,79%. Dan untuk proporsi sentimen menunjukan sentimen positif yang diperoleh Ganjar  lebih tinggi daripada calon presiden lainnya yaitu 55%, Prabowo 30% dan Anies 15%, Sementara sentimen negatif Anies lebih tinggi 89% dar ipada Ganjar 8% dan Prabowo 3%.                                                                  
Daftar Pustaka                                                                  
[1] D. Duei Putri, G. F. Nama, and W. E. Sulistiono, â€œAnalisis Sentimen Kinerja Dewan Perwakilan Rakyat (DPR) Pada Twitter Menggunakan Metode Naive Bayes Classifier,â€ J. Inform. dan Tek. Elektro Terap. , vol. 10,  no. 1, pp. 34 â€“40, 2022, doi: 10.23960/jitet.v10i1.2262.                                                                  
[2] B. Huda and B. Priyatna, â€œPenggunaan Aplikasi Content Management System (CMS) Untuk Pengembangan Bisnis Berbasis E -commerce,â€ Systematics , vol. 1, no. 2, p. 81, 2019, doi: 10.35706/sys.v1i2.2076.                                                                  
[3] A. Voutama and E. Novalia, â€œPerancangan Aplikasi M -Magazine Berbasis Android Sebagai Sarana Mading Sekolah Menengah Atas,â€ J. Tekno Kompak , vol. 15, no. 1, p. 104, 2021, doi: 10.33365/jtk.v15i1.920.                                                                  
[4] A. C. M. Alvionita Mila Anjani, Ahmad Abdul Cham id, â€œAnalisis Sentimen Kaum Lgbt Pada Media Sosial Twitter Menggunakan Algoritma NaÃ¯ve Bayes,â€ J. Inform. , vol. 1, no. 2, pp. 1 â€“8, 2022, doi: https://doi.org/10.02220/jtinfo.v1i2.259.                                                                  
[5] M. I. Fikri, T. S. Sabrila, and Y. Azhar, â€œPerbandingan Metode NaÃ¯ve  Bayes dan Support Vector Machine pada Analisis Sentimen Twitter,â€ Smatika J. , vol. 10, no. 02, pp. 71 â€“76, 2020, doi: 10.32664/smatika.v10i02.455.                                                                  
[6] D. R. Berliana and B. Santoso, â€œElektabilitas Ridwan Kamil Dan Anies Baswedan Dalam Simulasi Pilpres 2024  Di Twitter ( Analisis Jaringan Media Sosial Dan Analisis Sentimen Pengguna Twitter Terhadap # Ridwankamil Dan,â€ 0%50%100% Accuracy Precision RecallPresentase dalam %Hasil Klasifikasi Ganjar Prabowo Anies  8% 89% 3%Sentimen Negatif Ganjar Anies Prabowo 55% 15% 30%Sentimen Positif Ganjar                                                                Anies PrabowoAprilia Putri Nardilasari, April Li a Hananto, Shofa Shofia Hilabi , Tukino , Bayu Priyatna (JOINTECS ) Journal of Information Technology and Computer Science Vol  . 8 No. 1 (2023) 11 â€“ 18 vol. 6, no. 2, pp. 150 â€“162, 2024, doi: http://dx.doi.org/10.35760/mkm.2022.v6i2.6962.                                                                  
[7] F. Fathonah and A. Herliana, â€œPenerapan Text Mining A nalisis Sentimen Mengenai Vaksin Covid - 19 Menggunakan Metode NaÃ¯ve Bayes,â€ J. Sains dan Inform. , vol. 7, no. 2, pp. 155 â€“164, 2021, doi: 10.34128/jsi.v7i2.331.                                                                  
[8] J. W. Iskandar and Y. Nataliani, â€œPerbandingan NaÃ¯ve Bayes, SVM, dan k -NN untuk Analisis Sentimen Gadget Berbasis Aspek,â€ J. RESTI (Rekayasa Sist. dan Teknol. Informasi) , vol. 5, no. 6, pp. 1120 â€“1126, 2021, doi: 10.29207/resti.v5i6.3588.                                                                  
[9] M. Raihan, F. Syaâ€™ Bani |, F. Syaâ€™ Bani, U. Enri, and T. N. Padilah, â€œAnalisis Sentimen Terhadap Bakal Calon Presiden 2024 dengan Algoritma NaÃ¯ve Bayes,â€ J. Ris. Komputer) , vol. 9, no. 2, pp. 2407 â€“389, 2022, doi: 10.30865/jurikom.v9i2.3989.                                                                  
[10] B. P. Zen,  D. Wicaksana, and H. Alfidzar, â€œAnalisis Sentimen Tweet Vaksin Covid 19 Sinovac Menggunakan Metode Support Vecor Machine,â€ Jdmsi , vol. 3, no. 2, pp. 21 â€“27, 2022, doi: https://doi.org/10.33365/jdmsi.v3i2.1926.                                                                  
[11] A. P. Giovani, A. Ardiansyah, T. Haryanti , L. Kurniawati, and W. Gata, â€œAnalisis Sentimen Aplikasi Ruang Guru Di Twitter Menggunakan Algoritma Klasifikasi,â€ J. Teknoinfo , vol. 14, no. 2, p. 115, 2020, doi: 10.33365/jti.v14i2.679.                                                                  
[12] A. L. Hananto, B. Priyatna, and A. Y. Rahman, â€œPenerapan Algor itma Djikstra Pada Sistem Monitoring Petugas Lapangan Pemkab Bekasi Berbasis Android,â€ JOINTECS (Journal Inf. Technol. Comput. Sci. , vol. 4, no. 3, p. 95, 2019, doi: 10.31328/jointecs.v4i3.1078.                                                                  
[13] B. Priyatna, â€œPenerapan Metode User Centered Design (Ucd ) Pada Sistem Pemesanan Menu Kuliner Nusantara Berbasis Mobile Android,â€ AIMS J. Account. Inf. Syst. , vol. 2, no. 1, pp. 1 â€“14, 2019, doi: 10.32627/aims.v2i1.55.                                                                  
[14] A. Y. Rahman, B. Setyawan, F. W. Setiawan, and  A. L. Hananto, â€œModel Supply Chain Manageme nt (SCM) Pada Pupuk Organik Berbahan Cacing,â€ JOINTECS (Journal Inf. Technol. Comput. Sci. , vol. 5, no. 1, p. 33, 2020, doi: 10.31328/jointecs.v5i1.1198.                                                                  
[15] I. Kurniawan and A. Susanto, â€œImplementasi  Metode K -Means dan NaÃ¯ve Bayes Classifier untuk Analis is Sentimen Pemilihan Presiden (Pilpres) 2019,â€ Eksplora Inform. , vol. 9, no. 1, pp. 1 â€“10, 2019, doi: 10.30864/eksplora.v9i1.237.                                                                  
[16] I. Santoso, Windu Gata, and Atik Budi Paryanti, â€œPenggunaan Feature Selection di Algoritma Support Vector Machine untuk Sentimen Analisis Komisi Pemilihan Umum,â€ J. RESTI (Rekayasa Sist. dan Teknol. Informasi) , vol. 3, no. 3, pp. 364 â€“                                                                370, 2019, doi: 10.29207/resti.v3i3.1084.                                                                  
[17] J. Jtik et al. , â€œSentimen Analisis Masyarakat Indonesia Terhadap Presiden Rusia Pada Komentar Media Berita Online,â€ vol. 7, no. 1, 2023, doi: https://doi.org/10.35870/jtik.v7i1.698.                                                                  
[18] D. Apriliani, A. Susanto, M. F. Hidayattullah, and G. W. Sasmito, â€œSentimen Analisis Pandangan Masyarakat Terhadap Vaksinasi Covid 19 Menggunakan K -Nearest Neighbors ,â€ vol. 8, no. 1, pp. 34 â€“37, 2023, doi: http://dx.doi.org/10.30591/jpit.v8i1.4759.                                                                  
[19] M. R. A. Nasution and M. Hayaty, â€œPerbandingan Akurasi dan Waktu Proses Algoritma K -NN dan SVM dalam Analisis Sentimen Twitter,â€ J. Inform. , vol. 6, no. 2, pp. 226 â€“235, 2019, doi: 10.31311/ji.v6i2.5129.                                                                  
[20] S. N. J. Fitriyyah, N. Safriadi, and E. E. Pratama, â€œAnalisis Sentimen Calon Presiden Indonesia 2019  dari Media Sosial Twitter Menggunakan Metode Naive Bayes,â€ J. Edukasi dan Penelit. Inform. , vol. 5, no. 3, p. 279, 2019, doi: 10.26418/jp.v5i3.34368.                                                                  ",Analisis Sentimen,"Naive Bayes, SVM, Support Vector Machine",data twitter yang berhubungan terhadap calon presiden,"accuracy, precision, recall"
PENERAPAN ANALISIS SENTIMEN PADA PENGGUNA TWITTER MENGGUNAKAN METODE K-NEAREST NEIGHBOR,"PENERAPAN ANALISIS SENTIMEN PADA PENGGUNA TWITTER MENGGUNAKAN METODE K-NEAREST NEIGHBOR

Akhmad Deviyanto (1), M. Didik R. Wahyudi (2) 

Abstract                                                                                
This research is made to implement the KNN (K-Nearest Neighbor) algorithm for sentiment analysis Twitter about Jakarta Governor Election 2017. The object is 2000 data tweets in Indonesia  collected  from  Twitter  during  Januari  2017  using  Python  package  called Twitterscraper. The methode used in sentiment analysis  system is KNN with TF-IDF term weighting and Cosine similarity measure. As the test result, the highest accuracy is 67,2% when k=5, the highest precision is 56,94% with k=5, and the highest recall 78,24% with k=15.                        
Keywords : K-Nearest Neighbor, Twitterscraper, TF-IDF, Cosine Similarity                        

Abstrak                                                                                
Penelitian ini dibuat untuk mengimplementasikan algoritma KNN (K-Nearest Neighbor ) dalam        analisis sentimen pengguna Twitter tentang topik Pilkada DKI 2017. Data tweet yang digunakan adalah  sebanyak  2000  data  tweet  berbahasa  Indonesia  yang  dikumpulkan  selama  bulan Januari 2017 menggunakan package Python bernama Twitterscraper. Menggunakan algoritma KNN  dengan  pembobotan  kata  TF-IDF  dan  fungsi  Cosine  Similarity,  akan  dilakukan pengklasifikasian nilai sentimen ke dalam dua kelas : positif dan negatif. Dari hasil pengujian diketahui bahwa nilai akurasi terbesar adalah 67,2% ketika k=5, presisi tertinggi 56,94% ketika        k=5, dan recall 78,24% dengan k=15.                                                        
Kata Kunci : K-Nearest Neighbor, Twitterscraper, TF-IDF, Cosine Similarity                        

1.PENDAHULUAN                                                                         
Asosiasi Penyelenggara Jasa Internet Indonesia (APJII) telah melakukan survei pada tahun 2016. Ada sekitar 132,7 juta pengguna internet di Indonesia (naik secara signifikan dari tahun 2014 sebanyak 88 juta pengguna). Dari jumlah tersebut, sebanyak 97,4% (129,2 juta) adalah pengguna  yang menggunakan  internet  untuk  mengakses  media  sosial.  Lima  media  sosial dengan pengguna terbanyak adalah Facebook, Instagram, Youtube, Google Plus, dan Twitter. Social media Twitter memiliki 7,2 juta pengguna di Indonesia. Setiap harinya, paling tidak ada 4,1 juta tweet yang berasal dari Indonesia (CNN Indonesia, 2016). Jumlah yang cukup besar tersebut  merupakan  cuitan  para  penggunanya  tentang  banyak  hal:  pendidikan,  hiburan, pekerjaan, dan termasuk juga politik. Salah satu isu politik yang menjadi trending topic di Twitter pada tahun 2017 adalah tentang pemilihan gubernur Jakarta (Pilkada DKI). Terdapat tiga pasangan calon pada Pilkada DKI 2017.  Ketiga  paslon  tersebut  adalah  Agus  Harimurti  Yudhoyono  -  Sylviana  Murni,  Basuki Tjahaja Purnama - Djarot Saiful Hidayat, Anies Rasyid Baswedan - Sandiaga Salahuddin Uno. Sentimen Analisis atau opinion mining adalah jenis natural language yaitu pengolahan kata untuk melacak mood masyarakat tentang produk atau topik tertentu. Analisis sentimen, disebut        opinion mining. (G.Vinodhini, M.Chandrasekaran 2012). Penulis pada penelitian ini akan melakukan analisis sentimen para pengguna Twitter terhadap        ketiga pasangan kandidat pada Pilkada DKI 2017. Dengan input berupa data tweet dalam Bahasa  Indonesia,  akan  dilakukan  klasifikasi dengan  algoritma  KNN (K-Nearest  Neighbor) untuk menentukan apakah tweet tersebut bersentimen positif atau negatif.
                                
2.METODE PENELITIAN        
Secara garis besar, ada dua proses utama dalam penelitian ini yaitu pengambilan data dari Twitter dan proses analisis sentimen. Pengambilan data dari Twitter        Untuk  mengambil  data  tweets  yang  diperlukan,  digunakan  package  Twitterscraper  yang merupakan salah satu package Python. Berikut alur pengambilan data dari Twitter dengan menggunakan Twitterscraper :                        
Gambar 1. Alur Pengambilan Data Tweet                        
Agar dapat melakukan scraping data dari Twitter, harus ditentukan terlebih dahulu query untuk Twitterscraper.  Query  ini  didapat  dari  halaman  pencarian  lanjutan  Twitter        (https://twitter.com/search-advanced ).        URL untuk mencari data tweets yang mengandung kata â€˜AHYâ€™ dari mulai tanggal 1 Januari 2017 sampai dengan 31 Januari 2017 adalah : https://twitter.com/search?l=id&q=AHY%20since%3A2017-01-01%20until%3A2017-01-31&src=typd        
Query yang dibutuhkan Twitterscraper untuk melakukan scraping data dari URL tersebut adalah AHY%20since 3A2017-01-01%20until%3A2017-01-31  sehingga  command yang diinputkan ketika menjalankan Twitterscraper adalah sebagai berikut : twitterscraper AHY%20since%3A2017-01-01%20until%3A2017-01-31 -o ahy.json3     â– : 10 â€“ 22
Nama output file dari perintah di atas adalah ahy.json dan otomatis tersimpan pada direktori C:\\Users\\Namauser.
Gambar 2. Tampilan Running Twitterscraper pada Command Prompt                                
Gambar 3. Tampilan File JSON pada MS Excel        
Kemudian, ulangi lagi running Twitterscraper untuk mengambil data tweets yang mengandung keyword â€˜ahokâ€™ dan â€˜aniesâ€™. Perintahnya adalah sebagai berikut :                
- twitterscraper ahok%20since%3A2017-01-01%20until%3A2017-01-31 -o ahok.json                        
-  twitterscraper  Anies%20since%3A2017-01-01%20until%3A2017-01-31  -o Anies.json                        
Setelah data selesai diambil, selanjutnya dilakukan filter data dengan bantuan fitur â€˜Remove Duplicateâ€™ dari Microsoft Excel. Pertama, hilangkan duplikasi data berdasarkan kolom â€˜userâ€™. Selanjutnya hilangkan duplikasi data berdasarkan kolom â€˜textâ€™. Lalu, pilih data dan tentukan nilai        sentimen setiap data tweets yang akan dimasukkan ke dalam sistem  secara manual. Data yang dipakai dalam penelitian ini  berjumlah 2000 data tweets dengan perincian 1500 sebagai data latih dan 500 sebagai data uji. Setelah terpilih, data kemudian disimpan dalam bentuk CSV untuk kemudian diimport ke dalam database.
Proses Analisis Sentimen                        
Dalam  proses  sentimen  analisis  ada  dua  tahap  yaitu  preprocessing  dan  proses  analisis                
sentimen.
1.Text preprocessing                                
Merupakan tahapan pemrosesan data agar menjadi data yang siap untuk dianalisis. Setelah  data  terstruktur  maka  dapat  diolah  lebih  lanjut.  Beberapa  proses  yang dilakukan pada tahap ini adalah sebagai berikut :
a.Case folding                                        
Merupakan proses perubahan semua huruf pada dokumen tweet menjadi huruf kecil. Hanya huruf a sampai z yang diproses. Karakter selain huruf akan dibiarkan.                        
b.Tokenizing                                                
Pada  tahap  ini,  kalimat  dipotong  atau  dipecah berdasarkan  tiap  kata  yang menyusunnya.        
c.Stopword Removal                                
Merupakan tahap pembuangan kata-kata yang dianggap tidak penting. Langkah ini dilakukan  supaya  perhitungan  lebih  berfokus  pada  kata-kata  yang  jauh  lebih penting.
d.Stemming                                        
Tahap stemming adalah tahap mencari root (bentuk dasar) dari tiap kata. Pada        tahap ini, dilakukan proses pengembalian berbagai bentukan kata ke dalam suatu reprsentasi yang sama.
2.Analisis Sentimen dengan K-Nearest Neighbor        
Setelah  data  melalui  tahap  pre-processing  maka  data  telah  siap  untuk  diolah menggunakan metode K-Nearest Neighbor. Metode K-Nearest Neighbor adalah proses untuk mengelompokkan data ke dalam kelas-kelas yang telah ditentukan sebelumnya berdasarkan jarak terdekat / tingkat kemiripan data tersebut dengan dataset / data latih yang ada. Nantinya data akan dikelompokkan ke dalam suatu kelas dengan melihat sejumlah â€œkâ€ nilai jarak terdekat nya dengan data latih. Dalam penelitian ini, proses K-Nearest Neighbor meliputi 3 proses, yaitu :                
a.Menghitung Bobot Kata (TF-IDF)                
Lakukan penghitungan bobot kata (term) dari data ada menggunakan metode TF-IDF (Term Frequency-Inverse Document Frequency ). Term frequency menyatakan frekuensi  (tingkat  keseringan)  munculnya  suatu  term dalam  suatu  dokumen. Sedangkan  document  frequency  adalah  banyaknya  jumlah  dokumen  dimana        sebuah term itu muncul.                
Rumus dari TF-IDF adalah sebagai berikut : Dimana tf menyatakan nilai term frequency dan log (N/df) menyatakan nilai IDF dengan N adalah jumlah banyaknya data. Sebagai contoh, misal ada 7 data  tweet. Akan dicari bobot kata â€œpolitikâ€ pada dokumen pertama. Kata politik muncul sebanyak satu kali pada dokumen pertama.5 Dari ketujuh dokumen tersebut, kata politik terulang pada dua dokumen. Maka hasil perhitungannya adalah :                        
tf=1df=2idf=log(7 2)=0,544                        
Sehingga : w=1âˆ—0,544=0,544                        
b.Menghitung Tingkat Kemiripan ( Cosine Similarity)        
Dari langkah sebelumnya telah diketahui bobot tiap kata. Langkah selanjutnya adalah menghitung jarak atau tingkat kemiripan data dengan setiap data latih yang ada menggunakan rumus jarak Cosine Similarity. Lalu, sistem akan mengurutkan nilai jarak dari yang tertinggi sampai terendah. Tahapan pada Cosine similarity adalah sebagai berikut :        
i.Kalikan  bobot  dari  setiap  term  pada  D 1 dengan  setiap  term  dari  semua dokumen data latih yang ada..
ii.Hasil perkalian D1 dengan setiap dokumen kemudian dijumlahkan.                                
iii.Hitung  hasil  kuadrat  dari  masing-masing  term  dalam  setiap  dokumen (termasuk D1) kemudian jumlahkan lalu diakarkan.                                                
iv.Lakukan pembagian antara hasil dari langkah nomor 2 dengan langkah nomor                        
3. Maka, didapatkan nilai Cosine Similarity.        
c.Menentukan Nilai Sentimen                        
Setelah diketahui jarak yang tertinggi sampai terendah, akan diambil sebanyak k data tertinggi. Dari k data tersebut akan dilihat nilai sentimen mana yang paling        banyak muncul. Kelas sentimen yang paling banyak muncul kelas/nilai sentiment untuk data yang sedang dihitung.                                                        
3.HASIL DAN PEMBAHASAN                                
Proses analisis sentimen dalam penelitian ini dapat digambarkan dengan diagram sebagai                
berikut :                                        
Gambar 4. Flowchart Sistem Analisis Sentimen        
Misal dari tahap pengambilan data dari Twitter didapatkan data sebagai berikut :
Tabel 1. Data Tweet                                
No.Tweet Sentimen                                
1Anies optimis Partai Gerindra akan menang di Pilkada 2017.?? (akan dicari)                                
2Tokoh politik dari berbagai partai mengadakan rapat untuk membahas koalisi baru menjelang        pilkada 2017 dan pilpres 2019.Positif                                        
3Partai  politik  sudah  tidak  dapat  dipercaya. Sebagian  besar  partai  mengutamakan kepentingan partai daripada kebutuhan rakyat.Negatif                        
4PDIP memenangkan Pilkada 2012 karena figure Jokowi.  Partai  Gerindra  berusaha  menang pada 2017. Pertandingan 2 partai ini akan seru.Positif                                
5Mengejek  Jokowi  yang  produk  demokrasi rakyat,  tapi menjilat  AHY yang  jelas2  produk dinasti politik, malumu ditaruh di mana kawan?                                
6Suap  menyuap  sudah  lazim  di  negeri  Ini. Pemilu ada suap. Pilkada juga suap. Mungkin pula saat Pilpres.Negatif
Setelah melalui tahap preprocessing, akan diperoleh data sebagai berikut : 
Tabel 2. Hasil Tahap Preprocessing        
No. Tweet Hasil                                        
1Anies  optimis  Partai  Gerindra  akan  menang  di Pilkada 2017.anies  optimis  partai  gerindra menang pilkada
2Tokoh politik dari berbagai partai mengadakan rapat untuk  membahas  koalisi  baru  menjelang  pilkada 2017 dan pilpres 2019.tokoh politik partai rapat bahas koalisi jelang pilkada pilpres                                                        
3Partai politik sudah tidak dapat dipercaya. Sebagian besar  partai  mengutamakan  kepentingan  partai daripada kebutuhan rakyat.partai  politik  percaya  partai        utama  penting  partai  butuh rakyat                                
4PDIP  memenangkan  Pilkada  2012  karena  figure Jokowi.  Partai  Gerindra  berusaha  menang  pada 2017. Pertandingan 2 partai ini akan seru.pdip  menang  pilkada  figure jokowi  partai  gerindra  usaha        menang tanding partai seru
5Mengejek Jokowi yang produk demokrasi rakyat, tapi menjilat  AHY  yang  jelas2  produk  dinasti  politik, malumu ditaruh di mana kawan? #kamiahokejek  jokowi  produk  demokrasi rakyat  jilat  ahy  produk  dinasti politik malu taruh kawan
6Suap menyuap sudah lazim di negeri Ini. Pemilu ada suap. Pilkada juga suap. Mungkin pula saat Pilpres.suap suap lazim negeri pemilu suap pilkada pilpres                
Kemudian setiap term dari hasil preprocessing di atas akan dihitung bobotnya dengan TF-IDF.                
Berikut adalah hasilnya : 7                         
Tabel 3. Hasil Perhitungan TF-IDF                        
termTfdfIdf Bobot (W) = tf * idf                        
D1D2D3D4D5D6 D1D2D3D4D5D6                                
anies1 10,778151250,7781512500000                        
optimis1    10,778151250,7781512500000                        
partai1132 40,1760912590,1760912590,1760912590,5282737770,35218251800
gerindra1 1  20,4771212550,477121255000,47712125500        
menang1 2  20,4771212550,477121255000,95424250900
pilkada111 140,1760912590,1760912590,17609125900,17609125900,176091259
tokoh 1   10,7781512500,778151250000                
politik 11 1 30,30102999600,3010299960,30102999600,3010299960
rapat 1   10,7781512500,778151250000                
bahas 1   10,7781512500,778151250000                
koalisi 1   10,7781512500,778151250000                
jelang 1   10,7781512500,778151250000                
pilpres 1  120,47712125500,4771212550000,477121255
percaya  1   10,77815125000,77815125000                
utama 1   10,77815125000,77815125000                
penting 1   10,77815125000,77815125000                
butuh 1   10,77815125000,77815125000                
rakyat 1 1 20,477121255000,47712125500,4771212550        
pdip  1  10,778151250000,7781512500                
figur  1  10,778151250000,7781512500                
jokowi  11 20,4771212550000,4771212550,4771212550
usaha  1  10,778151250000,7781512500JISKa                     tanding  1  10,778151250000,7781512500
Tabel 3. Hasil Perhitungan TF-IDF (Lanjutan)
termTfdfIdfBobot (W) = tf * idf                        
D1D2D3D4D5D6 D1D2D3D4D5D6                                
seru 110,778151250000,7781512500                        
ejek 110,7781512500000,778151250                
produk 210,7781512500001,5563025010                
demokrasi 110,7781512500000,778151250                
jilat 110,7781512500000,778151250                        
ahy 110,7781512500000,778151250                        
dinasti 110,7781512500000,778151250                        
malu 110,7781512500000,778151250                
taruh 110,7781512500000,778151250                
kawan 110,7781512500000,778151250                        
suap 310,77815125000002,334453751                
lazim 110,77815125000000,77815125                
negeri 110,77815125000000,77815125        
pemilu 110,77815125000000,7781512510      
Berikutnya adalah tahap Cosine Similarity. Karena yang akan dicari adalah nilai sentimen dari data tweet pertama, maka data tweet pertama (D1) dihitung similaritynya dengan semua data yang ada. Hasilnya adalah sebagai berikut :
Tabel 4. Hasil Cosine Similarity (Langkah 2)                
WD1 * WDn                                                
WD1 * WD2WD1 * WD3WD1 * WD4WD1 * WD5WD1 * WD6        
00000                                                
00000                                                
0,031008                                        
20,09302                                        
50,06202                                                
300                                                
000,22764469                                                
200                                
000,45528938                                                
300                                                
0,031008                                        
200,031                                                
200,031                                                        
2                                        
00000                                                
00000                        
00000                                                
00000                                                
00000                                                
00000                                                
00000                                                
00000                                                
00000                                                
00000                                                
00000                                                
00000                                                
00000                                                
00000                                                
00000                                                
00000                                                
00000                                                
00000                                                
00000                                                
00000                                                
00000                                                
00000        
00000                                                
00000                                                
00000                                                
00000                                                        
00000                                                
00000                                                
00000                                                        
00000                                                
0000011                             
âˆ‘WD1 *                                
WDn0,06201626                                        
30,09302                        
50,7759584700,03100813                                        
2                                                
Tabel 5. Hasil Cosine Similarity (Langkah 3)                
Wn2                                
WD12WD22WD32WD42WD52WD62                        
0,60551                                                
900000                                                
0,60551                                                
900000                                                
0,031                                                
80,031                                                
80,27907                                        
30,12403                                                
300                                                
0,22764                                                
5000,228                                                
500                                                
0,22764                                                
5000,911                                                
900                                                
0,031                                                
80,031                                                
800,031                                                
800,031                                                
8                                                
00,60551                                        
90000                                                
00,09061                                                
90,09061                                                
900,0906                                                
90                                                
00,60551                                        
90000                                        
00,60551                                        
90000                                                
00,60551                                        
90000                                        
00,60551                                        
90000                                                
00,22764                                        
50000,23                                        
5                                                
000,60551                                                
9000                                                
000,60551                                        
9000                                                
000,60551                                                
9000                                                
000,60551                                                
9000                                                
000,22764                                        
500,2276                                                
50                                                
0000,60551                                                
900                                                
0000,60551                                                
900                                                
0000,22764                                        
50,22764                                                
50                                                
0000,60551                                                
900                                                
0000,60551                                        
900        
0000,60551                                                
900                                                        
00000,60551                                                
90                                                        
00002,42207                                                
70                                                        
00000,60551                                                
90                                                        
00000,60551                                                
90                                                
00000,60551                                                
90                                                        
00000,60551                                                
90                                                        
00000,60551                                                
90                                                        
00000,60551                                                
90                                                        
00000,60551                                                
90                                                        
000005,44967                                                
4                                                        
000000,60551                                                
9                                                        
000000,60551                                                
9                                                        
000000,60551                                                
9                                                        
âˆ‘Wn21,72834                                                
43,40787                                                
73,01941                                                
44,5485                                                        
67,81214                                                
17,52488                                                
5                                                
âˆš                                                        
âˆ‘Wn21,31466                                                
51,84604                                                
41,73764                                                
62,13272                                                
32,79502                                                
12,74315                                                
2                                                        
Tabel 6. Hasil Cosine Similarity (Langkah 4)        
Cosine Similarity                                        
Cos (D1,D2)Cos (D1,D3)Cos (D1,D4)Cos (D1,D5)Cos (D1,D6)
0,025553                                                
90,040721180,27675085                                        
200,0086                                                
Dari hasil tersebut dapat diurutkan nilai similarity D 1 dari yang tertinggi ke yang terendah yaitu :                
1.D4 (Positif)                                                
2.D3 (Negatif)                                                
3.D2 (Positif)                                                
4.D6 (Negatif)                                                
5.D5 (Negatif)                                                
Jika dipilih nilai k untuk KNN adalah 3 maka akan dipilih 3 nilai similarity yang tertinggi. Dari 3        nilai tertinggi terrsebut, kelas sentimen yang paling banyak muncul adalah positif sehingga sistem akan mengklasifikasikan D 1 ke dalam sentimen Positif.
                                        
4.KESIMPULAN                                                
Dari hasil pengujian sistem didapatkan hasil sebagai berikut :13                                                  
Gambar 5. Nilai Confusion Matrix Sistem        
3579154050607080 Nilai Confusion Matrix Sistem Presisi Recall Akurasi Nilai kpersentase (%)        
Gambar 6. Grafik Nilai Confusion Matrix Sistem        
Berdasarkan  penelitian  yang  telah  dilakukan,  diperoleh  kesimpulan  bahwa penelitian tentang analisis sentimen pengguna Twitter terhadap topik Pilkada DKI 2017 dengan  menggunakan  metode  K  Nearest  Neighbor  telah  berhasil  dilakukan.  Hasil akurasi  terbesar  adalah  67,2%  dengan  nilai  k=5.  Sedangkan  nilai  presisi  tertinggi sebesar 56,94% saat k=5 dan recall terbesar 78,24 % ketika k=15.

DAFTAR PUSTAKA                                                
Bukhari, Varian Habbie. 2015. Sentiment Analysis Menggunakan K-Nearest Neighbor dengan                
Perbandingan  Fungsi  Jarak  (Studi Kasus  :  Twitter  Indosat  dan  Telkomsel) ,  Skripsi                        
Universitas Widyatama Bandung.                                
Ilyas,  Husni.  2017.  Cosine  Similarity  Antar  Dokumen:  Sebuah  Contoh .                                
https://komputasi.files.wordpress.com/2011/01/cosine-similarity-antar-dokumen-sebuah-                
contoh.pdf.                                                
Liu, B. (2012).  Sentiment Analysis and Subjectivity. Synthesis Lectures on Human Language                
Technologies. USA: editor: Graeme Hirst Morgan & Claypool Publishers.                                
Marpaung, Fransiska Humida. 2017.  Analisis Sentimen Opini Masyarakat Indonesia Mengenai                
Calon  Gubernur  Dki  Jakarta  2017  Menggunakan  NaÃ¯ve  Bayes  Classifier  ,  Skripsi                        
Universitas Atma Jaya Yogyakarta.                        
Rosdiansyah, Defri. 2014. Analisis Sentimen Twitter Menggunakan Metode K-Nearest Neighbor                
dan  Pendekatan  Lexicon,  Skripsi,  Universitas  Islam  Negeri  Sultan  Syarif  Kasim                        
Pekanbaru.                                                
Saridewi, Ayu Indah. 2015.  Perancangan Dan Implementasi Sistem Peminatan Siswa Sma                
Dengan Algoritma C4.5 Pada Smak Harapan Denpasar , Skripsi Universitas Udayana                        
Bali.                                                        
Taspinar, Ahmet dan Lasse Schuirmann. 2017.  Twitterscraper 0.2.7 : Python Package Index .                
https://pypi.python.org/pypi/twitterscraper/0.2.7
Vinodhini, G., & Chandrasekaran, RM., 2012. Sentiment Analysis and Opinion Mining: A Survey,                
International  Journal  of  Advanced  Research  in  Computer  Science  and  Software                        
Engineering Vol. 2, Issue 6, pp. 1""                        
",Analisis Sentimen,"KNN, K-Nearest Neighbor, TF-IDF, Cosine Similarity",data tweet berbahasa Indonesia yang dikumpulkan selama bulan Januari 2017,"akurasi, presisis, recall"
Komparasi Algoritma Naive Bayes  dan Logistic Regression Untuk Analisis Sentimen Metaverse,"Komparasi Algoritma Naive Bayes  dan Logistic Regression Untuk Analisis Sentimen Metaverse  

Bagus Ramadhani, Ryan Randy Suryono 

Abstrak
Transformasi digital membuat dunia berubah dengan cepat, terutama pada perkembangan teknologi metaverse. Perkembangan teknologi metaverse mendapatkan respon positif dan negatif dari masyarakat sehingga perlu dilakukan analisis apakah opini masyarakat menerima perkembangan teknologi metaverse atau malah sebaliknya. Penelitian ini bertujuan untuk menganalisis 6728 data komentar masyarakat terkait metaverse pada media sosial X dengan pendekatan text mining. Dengan 
melakukan komparasi model algorima text mining,  eksperimen ini berupaya menemukan algoritma terbaik untuk analisis 
sentimen metaverse, sehingga memberikan wawasan kepada pelaku industri yang terlibat dalam pengembangan metaverse.  
Eksperimen penelitian ini menggunakan komparasi dua algoritma yaitu NaÃ¯ve  Bayes  dan Logistic Regression. Hasil komparasi pada algoritma Naive Bayes memiliki  nilai akurasi 90% dan Logistic Regression 91%, namun hasil precision, recall, F1-Score rendah. Hal ini menandakan bahwa mesin dominan belajar sentimen positif dikarenakan sentimen tersebut memiliki label majority yaitu sebanyak 5799 data sentimen positif, sedangkan sentimen negatif menjadi label minority sebanyak 795 data. Untuk mengatasi permasalahan  data yang tidak seimbang ( Imbalance)  dalam penelitian ini menggunakan optimasi SMOTE. Hasil dari optimasi SMOTE memiliki  nilai yang lebih unggul pada algoritma Logistic Regression  nilai akurasi 95% mengalami peningkatan juga pada confusion matrix  yaitu pada nilai precision 94%, recall 93% dan F1 -Score 95%. Sedangkan pada algoritma NaÃ¯ve Bayes  memiliki nilai yang lebih kecil yaitu akurasi 91%, confusion matrix sentimen negatif mengalami peningkatan menjadi precision 87%, recall  97% dan F1 -Score 92%, sehingga nilai akurasi dan confusion matrix memiliki 
performa yang lebih baik. 
 
Kata Kunci : Naive Bayes 

Abstract
Digital transformation makes the world change rapidly, especially in the development of metaverse technology. The 
development of metaverse technology has received p ositive and negative responses from the public, so it is necessary to analyze whether public opinion accepts the development of metaverse technology or vice versa. This research aims to analyze 6728 public comment data regarding the metaverse on social media X using a text mining approach. By comparing text mining algorithm models, this experiment seeks to find the best algorithm for metaverse sentiment analysis, thereby providing insight to industry players involved in metaverse development. This research experiment uses a comparison of two algorithms, namely Naive Bayes and Logistic Regression. The comparison results for the Naive Bayes algorithm have an accuracy value of 90% and Logistic Regression of 91%, but the precision, recall, and F1 -Score results a re low. This indicates that the machine predominantly learns positive sentiment because this sentiment has a majority label, namely 5799 positive sentiment data, while negative sentiment is a minority label with 795 data. To overcome the problem of unbalan ced data (Imbalance) in this research, SMOTE optimization was used. The results of SMOTE optimization have a superior value in the Logistic Regression algorithm, the accuracy value of 95% has also increased in the confusion matrix, namely the precision val ue of 94%, recall of 93%, and F1 -Score of 95%. Meanwhile, the Naive Bayes algorithm has a smaller value, namely 91% accuracy, and the negative sentiment confusion matrix has increased to 87% precision, 97% recall, and 92% F1 -Score, so the accuracy and conf usion matrix values have better performance.  

Keywords : Naive Bayes

1. PENDAHULUAN  
Istilah metaverse diperkenalkan pertama kali oleh karya fiksi spekulatif yang ditulis oleh Neal Stephenson pada 
tahun 1992 yang berjudul Snow Crash , metaverse terbentuk dari berbagai elemen teknologi, termasuk media sosial, Augmented Reality  (AR), Virtual Reality  (VR), Cryptocurrency  dan permainan daring  [1]. Metaverse 
menawarkan partisipasi dalam pengalaman bersama dalam lingkungan 3D virtual , yang mana setiap pengguna 
berinteraksi sebagai avatar  satu sama lain. [2] Penerapan Metaverse di Indonesia sudah bergerak di beberapa sektor 
industri seperti dunia pendidikan yang menyediakan pembelajaran online  menggunakan Virtual Reality  (VR)  dan 
industri bisnis seperti pariwisata yang menggunakan virtual  3 dimensi  [2], [3], [4]. Seiring berkembang nya teknologi metaverse pada beberapa sektor industri menimbulkan beberapa opini masyarakat. Melalui opini tersebut perlu dilakukan analisis untuk mengetahui lebih lanjut apakah penerapan teknologi metaverse banyak diminati  oleh masyarakat Indonesia  atau malah sebaliknya. Opini masyarakat Indonesia tersebut pada umumnya disampaikan melalui platfrom  media sosial. Media sosial adalah media online  yang dapat digunakan untuk berpartisipasi, bertukar dan membuat konten 
dengan mudah. Dengan adanya media sosial menjadi tempat untuk masyarakat memberikan opini mengenai suatu topik. Salah satu media sosial yang terkenal di dunia dan sering digunakan oleh masyarakat untuk mengutarakan opini adalah X  [5]. Dimana saat ini topik yang tengah ramai dibicarakan pada platfrom  X adalah metaverse, sehingga perlu dilakukan analisis sentimen mengenai topik tersebut. opini  beberapa orang atau masyarakat  yang biasanya melalui bentuk komentar atau tulisan  [6]. Dengan melakukan analisis  sentimen dapat menemukan informasi yang berharga dari sebuah data yang tidak terstruktur, dimana informasi yang diberikan berupa opini  tersebut  dapat diklasifikasi ke dalam  sentimen  positif  atau negatif berdasarkan emosional dari  opini yang diberikan  [6], [7]. Pengelompokan sentimen tersebut dapat dilakukan menggunakan  klasifikasi  teks. Dalam tahapan analisis sentimen terdapat metode klasifikasi yang umum digunakan adalah Algoritma Naive Bayes  Classifier  dan Logistic Regression. Naive Bayes  Classifier  merupakan algoritma yang digunakan dengan teknik data mining yang berasal dari teorema bayes. Berdasarkan konsep yang dikemukakan  oleh ilmuan Inggris yaitu Thomas Bayes bahwa teknik pendekatan ini menggunakan probabilitas dan statistic  [8]. Dimana algoritma Naive Bayes  mencari nilai dengan probabilitas tertinggi agar dapat mengelompokan data uji dengan kategori yang tepat  [9]. Selain itu terdapat metode Logistic Regression  merupakan suatu metode klasifikasi yang 
dipakai untuk membentuk model hubungan antar variabe l independent  dan variabel  dependen  [10], [11]. Pada 
algoritma klasifikasi ini berfungsi untuk mencari hubungan antara input dengan probabilitas hasil output dimana 
input bisa berupa variabel diskrit  atau kontinu sedangkan probabilitas hasil output  dari Logistic Regression  
memiliki karakteristik biner  (dua kelas) seperti  positif atau negatif  [12]. Dengan melakukan perbandingan  klasifikasi  Naive Bayyes Calssifier  dan Logistic Regression  diharapkan peneliti mampu menentukan klasifikasi  dengan akurasi terbaik untuk analisis sentimen pada topik metaverse. sehingga harapan peneliti selain mengetahui algoritma dengan klasifikasi yang terbaik , Peneliti juga berharap mengetahui opini masyarakat Indonesia terhadap metaverse sehingga mendapatk an informasi mengenai 
kecend erungan opini masyarakat Indonesia apakah dominan positif atau negatif. Berdasarkan penelitian terdahulu  pada  tahun 2021  yang membahas tentang topik  wacana pemindahan ibu kota Indonesia menggunakan Algoritma Support Vector Machine  (SVM) dimana data di dapatkan melalui platfrom  twitter  diperoleh akurasi  96.68% dengan precision   92.82% dan recall  = 94.04%  [13]. Pada penelitian selanjutnya yang dilakukan pada tahun 2020 yang berjudul analisis sentimen terhadap layanan Indihome menggunakan metode klasifikasi Support Vector Machine  (SVM)  menghasilkan akurasi 87%, recall  95%, eror rate 13% dan f1 -Score 90%. Data dalam penelitian ini diambil berdasarkan opini pengguna layanan Indihome pada platfrom  twitter  [14]. Penelitian yang dilakukan pada tahun 2022 dengan topik penelitian analisis sentimen  pengguna twitter terhadap pemilu 2024 berbasis model XLM -T menghasilkan akurasi model sebesar 68%  [15]. 
Topik penelitian mengenai Analisis Sentimen Dokumen Twitter Mengenai Dampak Virus Corona Menggunakan Metode Naive Bayes  Classifier  pada tahun 2020 menghasilkan tingkat akurasi sebesar 67%  dan error rate  sebesar 33% [16]. Pada tahun 2023 dilakukan penelitian mengenai studi komparasi metode analisis sentiment Naive Bayes , Suport Vector Machine  dan Logistic Regression  pada piala dunia 2022 . Pada metode Bernouli Naive Bayes menghasilkan nilai akurasi 76%, precision 71% dan recall  99%, sedangkan pada metode Support Vector Machine menghasilkan nilai parameter dengan akurasi 92%, precision 94% dan recall  93%, lalu untuk metode terakhir yaitu menggunakan metode Logistic Regression  menghasilkan nilai akurasi 92%, precision  93% dan recall  93% [17]. Pada penelitian terdahulu yang dijadikan sebagai referensi dan acuan untuk menulis jurnal penelitian saat 
ini, dimana penelitian sebelumnya sudah menggunakan klasifikasi  Naive Bayes, namun pada penelitian sebelumnya  masih  sedikit peneliti yang  melakukan komparasi dengan beberapa algoritma, selain itu pada peneliti an sebelumnya juga belum melakukan optimasi pada setiap klasifikasi  yang digunakan  sehingga performa dari setiap  klasifikasi  yang digunakan belum maksimal. Tujuan dari penelitian ini adalah untuk mengetahui  opini masyarakat terkait perkembangan tekonologi metaverse, apakah masyarakat  tersebut  menerima baik perkembangan teknologi metaverse atau malah sebaliknya. 
Selanjutnya melalui serangkaian penelitian terdahulu yang telah dilakukan, penelitian ini memliki  tujuan  untuk 
melakukan komparasi menggunakan dua metode klasifikasi yaitu Naive Bayes  dan Logistic Regression. Selain melakukan komparasi dengan dua metode klasifikasi untuk menentukan yang terbaik, penelitian ini juga melakukan optimasi menggunakan Synthetic Minority Over-sampling Technique  (SMOTE) sehingga performa dari setiap klasifikasi yang dilatih akan jauh lebih baik. Penelitian ini diharapkan memberikan kontribusi berarti dalam pengembangan pemahaman tentang opini masyarakat Indonesia terkait metaverse, dengan mengetahui opini masyarakat tersebut dapat memberikan 
wawasan yang mendalam tentang bagaimana masyarakat merespon perkembangan teknologi metaverse  sehingga dapat menjadikan sumber referensi dibidang tekn ologi dan inovasi khususnya di Indonesia. Selain itu, penelitian ini berharap membantu penelitian selanjutnya dalam menentukan klasifikasi terbaik  antara Naive Bayes  dan Logistic Regression  dengan mempertimbangkan beberapa aspek seperti akurasi dan confusi on matrix, dimana setiap algoritma juga dilakukan optimasi menggunakan SMOTE agar menghasilkan performa yang optimal.
  
2. METODOLOGI PENELITIAN  
2.1 Tahapan Penelitian  
Penelitian ini dilakukan melalui beberapa tahapan , sehigga penelitian ini memiliki alur kerja dari awal hingga 
akhir. Tahapan penelitian ini dapat dilihat pada gambar 1 sebagai berikut:    
Gambar 1. Tahapan Penelitian  
Penelitian ini di awali dengan tahapan Data Collection  atau pengumpulan data dari media sosial X tentang 
topik metaverse. Setelah data berhasil dikumpulkan  peneliti harus memahami data tersebut, tahapan ini bisa disebut sebagai data understanding . Selanjutnya data akan di proses untuk dibersihkan (preprocessing  data)  sehingga data siap untuk digunakan pada  Data Visualisasi dan  modelling . Untuk melihat data agar lebih mudah di mengerti maka perlu adanya data visualization, ketika data sudah melalui tahapan preprocessing dan visualisasi maka akan dilakukan  modelli ng menggunakan dua algoritma  klasifikasi  Naive Bayes  dan Logistic Regression. Penerapan metode yang menggunakan dua algoritma berfungsi untuk melakukan perbandingan sehingga dapat mengetahui algoritma yang memiliki performa terbaik [18]. Setelah mendapatkan akurasi dari setiap model, maka 
perlu dilakukan optimasi  menggunakan SMOTE untuk meningkatkan performa dari setiap  model  klasifikasi, 
selanjutnya peneliti akan melakukan evaluasi dari setiap klasifikasi yang dihasilkan.  
2.2 Data Collection  
Proses Data  Collection  dilakukan melalui beberapa tahapan  yang dapat dilihat pada gambar 2  sebagai berikut : 
Gambar 2. Proses Data Collection  
Data collection  adalah sebuah metode yang digunakan untuk mengumpulkan data dari server menggunakan bantuan Application Programming Interface  (API)  [19], [20]. API digunakan untuk menghubungkan dua komponen perangkat lunak untuk saling berkomunikasi, dimana salah satunya sebagai klien yang mengirimkan permintaan dan server yang mengirimkan output  kembali ke klien sesuai permintaan. Dalam penelitian ini proses pengumpulan data dilakukan pada platfrom  media sosial X. Ketika melakukan pengambilan data, proses crawling hanya dapat mengambil maksimal 200 tweet dalam satu kali crawling . Sehingga pada penelitian ini memerlukan lebih dari satu kali proses crawling  data. Proses crawling membutuhkan Auth Token  dari media sosial X yang dapat di proses menggunakan library Harvest  pada bahasa pemrograman python. Kata kunci yang digunakan untuk 
mencari twit yang relevan pada penelitian ini yaitu â€œmetaverseâ€. Selain itu dilakukan penambahan filter bahasa Indonesia (lang:id) sehingga data yang dihasilkan sesuai dengan kebutuhan peneliti saat ini. Untuk data yang 
berhasil dikumpulkan dapat dilihat pada tab el 1 sebagai berikut:  
Tabel 1. Menampilkan Data Teratas  
Number  Tweet_text  Date  
0 Metaverse didesain sejak awal dengan orientasi """"ekonomi berjalan"""".. Uang bisa berputar.. Sedangkan aplikasi besar saat ini berorientasi kepada akses global & amp 15:09
1 Halo Sobat IndiHome,  15/04/2023 17:50  Istilah Metaverse bukan merupaka hal yang baru. Ide Metaverse ini berguna dan 
memiliki kemungkinan akan bersama kita untuk beberapa waktu. Konsep metaverse sangat layak dipahami, apalagi yang ingin berevolusi ke era digital.  
Berdasarkan tabel 1 peneliti berhasil mengumpulkan data  sebanyak 6728 data twit , dimana rentang waktu 
yang di ambil dari bulan Agustus tahun 2022 sampai  bulan April  2023.  Isi dari Tweet text berupa komentar dari 
masyarakat Indonesia terkait metaverse, dimana komentar masyarakat tersebut yang akan digunakan untuk simpan dalam bentuk  Comma Separated Values (CSV)  agar data tersebut mudah untuk diolah menggunakan python.  
2.3 Data Understanding  
Data understanding  merupakan suatu tahapan dalam analisis sentimen dimana peneliti harus memahami terlebih 
dahulu mengenai data yang ada. Melalui data yang ada, peneliti bisa memecahkan suatu masalah  sesuai dengan 
tujuan yang telah ditentukan.  Pada tahap data understanding  peneliti melakukan pemahaman terkait data yang telah 
dikumpulkan. Dengan melakukan pemahaman yang lebih dalam terkait data yang telah dikumpulkan, peneliti dapat menentukan apa saja langkah yang diperlukan untuk memecahkan suatu masalah di dalam sebuah penelitian.    
2.4 Preprocessing  Data  
Preprocessing  Data adalah suatu metode di dalam data mining yang berfungsi untuk membuat data lebih mudah diolah sehingga meningkatkan hasil dari suatu analisis  data [21]. Tahapan yang dilakukan di dalam preprocessing data dapat dilihat sebagai berikut:  
2.4.1 Cleaning  dan Case  Folding  
Cleaning  merupakan salah satu tahapan dalam preprocessing  data, dimana tahapan ini berfungsi untuk membersihkan data se perti menghapus data duplikat, menghapus data kosong,  menghapus karakter maupun tanda baca, menghapus Uniform Resource Locator (URL ), menghapus HyperText Markup Language (HTML ), serta menghapus emoticon  dan mention  yang tidak relevan  [22], [23] . Untuk hasil pada tahapan ini dapat dilihat pada tabel 2 sebagai berikut:  
Tabel 2. Cleaning Data  dan Case Folding  
Tweet_text  Cleansing  Casefolding  
Metaverse didesain sejak awal dengan orientasi """"ekonomi berjalan"""".. Uang bisa berputar.. Sedangkan aplikasi besar saat ini berorientasi kepada akses global &amp pembayaran perlahan..  Metaverse didesain sejak awal dengan orientasi ekonomi berjalan Uang bisa berputar Sedangkan aplikasi besar saat ini kepada akses global amp perlahan  metaverse didesain sejak awal dengan orientasi ekonomi berjalan uang bisa berputar  sedangkan aplikasi besar saat ini  kepada 
akses global amp  perlahan  
Halo Sobat IndiHome, Istilah Metaverse bukan merupaka hal yang baru. Ide Metaverse ini berguna dan memiliki kemungkinan akan bersama kita untuk beberapa waktu. Konsep metaverse sangat layak dipahami, apalagi yang ingin berevolusi ke era digital.  Halo Sobat IndiHome  Istilah 
Metaverse bukan merupaka hal  baru Ide Metaverse ini berguna  
memiliki  akan bersama kita untuk beberapa waktu Konsep 
metaverse sangat layak dipahami apalagi  ingin  ke era digital  halo sobat indihome  istilah metaverse bukan merupaka hal  baru ide metaverse ini berguna  memiliki  akan bersama kita untuk beberapa waktu konsep metaverse sangat layak dipahami apalagi  ingin  ke era digital  
Dalam penelitian ini proses cleaning  memerlukan library  python yaitu regex dan pandas.  Ketika data sudah 
berhasil di cleansing  maka perlu dilakukan case folding. Case folding  merupakan suatu tahapan untuk melakukan 
keseragaman huruf dimana proses ini akan mengubah huruf yang awalnya kapital atau huruf besar menjadi huruf kecil  [24]. 
2.4.2 Tokenizing  dan Removal  Stopwoard  atau Filtering  
Setelah data sudah melalui tahapan pada  tabel 1, tahapan selanjutnya adalah tokenizing  dan Filtering. Tokenizing  
merupakan suatu proses yang berfungsi untuk  memecah suatu kalimat atau paragraf menjadi kata -kata individu atau token. Dimana pada proses ini mengandalkan karakter spasi untuk melakukan pemotong an setiap kata dalam sebuah kalimat atau paragraf  [25]. Tahapan ini menggunakan perintah di dalam python yaitu split()  untuk memisahkan setiap kata dengan tanda koma.  Stopwoard  atau filtering  merupakan p roses di dalam  data mining  yang berfungsi untuk menghapus kata-kata tidak penting yang terdapat di dalam daftar stopword, sehingga kata-kata tersebut tidak akan ada di dalam  analisis teks. Umumnya sekumpulan kata yang akan dihapus merupakan kata konjungsi atau kata penghubung seperti â€œdan, atau, tetapi, sehingga dan sebagainyaâ€  [26]. Hasil dari tahapan ini dapat dilihat pada tab el 3 sebagai berikut:  
Tabel 3. Tokenizing  dan Filtering  
Tokenizing  Filtering  
['metaverse', 'didesain', 'sejak', 'awal', 'dengan', 'orientasi', 'ekonomi', 'berjalan', 'uang', 'bisa', 'berputar', 'sedangkan', 'aplikasi', 'besar', 'saat', 'ini', 
'kepada', 'akses', 'global', 'amp', 'perlahan']  ['metaverse', 'didesain', 'sejak', 'awal', 'orientasi', 
'ekonomi', 'berjalan', 'uang', 'bisa', 'berputar', 
'sedangkan', 'aplikasi', 'besar', 'saat', 'kepada', 'akses', 
'global', 'amp', 'perlahan']  
['halo', 'sobat', 'indihome', 'istilah', 'metaverse', 'buk an', 'merupaka', 'hal', 'baru', 'ide', 'metaverse', 'ini', 
'berguna', 'memiliki', 'akan', 'bersama', 'kita', 'untuk', 
'beberapa', 'waktu', 'konsep', 'metaverse', 'sangat', 
'layak', 'dipahami', 'apalagi', 'ingin', 'ke', 'era', 'digital']  ['halo', 'sobat', ' indihome', 'istilah', 'metaverse', 'bukan', 'merupaka', 'hal', 'baru', 'ide', 'metaverse', 'berguna', 'memiliki', 'waktu', 'konsep', 'metaverse', 'sangat', 'layak', 'dipahami', 'apalagi', 'ingin', 'era', 'digital']  
Berdasarkan tabel 3  proses stopwoard  atau filtering   menggunakan  package  Natural Language Toolkit  (NLTK) corpus  untuk menghapus kata-kata yang sangat umum dan melakukan filtering  data dengan menghapus daftar kata -kata di dalam sebuah list yang tidak memiliki makna.  Sehingga output  dari taha pan ini berupa kata-kata individu atau token yang berasal dari pemotongan setiap kata dalam sebuah kalimat.  
2.4.3 Stemming  dan Labelling  
Stemming  merupakan proses untuk mengubah suatu kata yang memiliki imbuh an menjadi bentuk kata dasar  [27]. Pada proses stemming  data memerlukan sebuah package  yang bernama Natural Language Toolkit  (NLTK) yang berfungsi sebagai alat untuk pemrosesan bahasa alami.  Pelabelan dilakukan untuk mengelompokan suatu data ke dalam dua kelas, yaitu kelompok dengan label positif dan label negatif  [28]. Dalam proses labelling  ada dua metode yang dapat digunakan, labelling secara manual dimana teknik ini dilakukan oleh anatator  yang umumnya terdiri dari 3 orang dan labelling  secara otomatis menggunakan machine learning  dimana proses ini dilakukan untuk data dalam skala jumlah besar.  Hasil pada tahapan ini dapat dilihat pada tabe l 4 sebagai berikut:  
Tabel 4. Stemming  dan Labelling  
Stemming  Labelling  
metaverse desain sejak awal orientasi ekonomi jalan uang bisa putar sedang aplikasi besar saat kepada akses global amp perlahan  positif  
halo sobat indihome istilah metaverse bukan merupaka hal baru ide metaverse guna milik waktu konsep metaverse sangat layak paham apalagi ingin era digital  positif  
Berdasarkan tabel 4 pada  tahapan stemming  peneliti menggunakan bantuan library Sastrawi  untuk mengolah kata yang memiliki imbuhan agar dapat diubah ke dalam bentuk kata dasar.  Sehingga hasil dari stemming berupa suatu kalimat dari setiap kata yang sudah tidak memiliki imbuhan . Pada tahapan  Labelling  dilakukan oleh mesin menggunakan package  NLTK dimana peneliti memakai library Valence Aware Dictionary and sEntiment Reasoner  (VADER) lexicon  untuk menentukan skor polaritas dalam suatu kata , sehingga 
menghasilkan data dengan sentiment positif sebanyak 5799 dan negatif 795 . Dalam penelitian ini proses stemming  dan labelling menjadi tahapan terakhir dalam preprocessing  data.  
2.5 Feature  Extraction  (TF-IDF)  
Term Frequency -Inverse Document Frequency  (TF-IDF)merupakan algoritma yang digunakan untuk melakukan pembobotan kata dalam suatu teks. Dalam algoritma ini nilai Term Frequency  (TF) dan Inverse Document Frequency  (IDF) akan dihitung berdasarkan dokumen yang telah ditentukan pada korpus  [29]. Dalam melakukan pembobotan kata TF dan IDF memiliki rumus dan cara kerja yang berbeda seperti yang terlihat pada persamaan-persamaan dibawah ini . 
2.5.1 Term Frequency  (TF)  
Term Frequency  (TF) berfungsi untuk mengukur jumlah kemunculan suatu kata atau term di dalam dokumen berdasarkan kata kunci yang telah ditentukan sebelumnya. TF memiliki perhitungan yang mana dapat dilihat pada persamaan 1 seperti berikut:  
ð‘¡ð‘“ð‘¡,ð‘‘= ð‘›ð‘¡,ð‘‘
(ð‘‡ð‘œð‘¡ð‘Žð‘™  ð‘›ð‘¢ð‘šð‘ð‘’ð‘Ÿ  ð‘œð‘“ ð‘¡ð‘’ð‘Ÿð‘š  ð‘–ð‘› ð‘‘ð‘œð‘ð‘¢ð‘šð‘’ð‘›ð‘¡ ) (1) 
Keterangan dari  ð‘¡ð‘“ð‘¡,ð‘‘  yaitu untuk menghitung kata atau term tertentu dari suatu kata kunci. Lalu untuk 
keterangan dari ð‘‘ berisi  suatu  dokumen , dimana dokumen tersebut berisi data yang akan dicocokan berdasarkan kata kunci . Dimana dalam perhitungan tersebut untuk mencari TF akan diperlukan mengehitung banyaknya dari suatu kata yang muncul dalam sebuah dokumen lalu dibagi dengan total dari kata yang ada di dalam dokumen tersebut . 
2.5.2 Inverse Document Frequency  (IDF)  
Inverse Document Frequency  (IDF) digunakan untuk menghitung jumlah dokumen yang ada di dalam  suatu korpus atau koleksi.  Berikut ini persamaan dari IDF yang dapat dilihat pada persamaan 2 sebagai berikut:  
(ð‘‡ð‘œð‘¡ð‘Žð‘™  ð‘›ð‘¢ð‘šð‘ð‘’ð‘Ÿ  ð‘œð‘“ ð‘¡ð‘’ð‘Ÿð‘š  ð‘–ð‘› ð‘‘ð‘œð‘ð‘¢ð‘šð‘’ð‘›ð‘¡ ) (2) 
Dalam persamaan untuk mencari nilai  ð‘–ð‘‘ð‘“ð‘‘ menggunakan logarithm , dimana pada perhitungan ini akan menghitung  jumlah dokumen yang ada di dalam korpus dan akan dibagi  dengan jumlah dokumen yang mengandung term tertentu.  
2.5.3 Term Frequency â€“ Inverse Document Frequency  (TF-IDF)  
Untuk mendapatkan pembobotan pada setiap kata atau yang disebut juga TF -IDF maka diperlukan perhitungan seperti yang terlihat pada persamaan  3 seperti berikut ini:   
ð‘¡ð‘“ð‘–ð‘‘ ð‘“ð‘‘=ð‘¡ð‘“ð‘¡,ð‘‘ ð‘‹ ð‘–ð‘‘ð‘“ð‘‘ (3) 
Pada persamaan 3 tersebut menjelaskan bahwa pembobotan TF -IDF dihasilkan dari perkalian antara 
ð‘¡ð‘“ð‘¡,ð‘‘ dikali dengan ð‘–ð‘‘ð‘“ð‘‘. Sehingga hasil dari perkalian  antara ð‘¡ð‘“ð‘¡,ð‘‘   dan ð‘–ð‘‘ð‘“ð‘‘ mempresentasikan pembobotan pada setiap kata.  Pembobotan setiap kata ini akan menghitung  pembobotan dengan jumlah kata yang sama, sehingga hasil dari TF -IDF dapat digunakan tahapan Visualization  dan modelling . 
2.6 Modelling Menggunakan Klasifikasi NaÃ¯ve Bayes  dan Logistic Regression  Ketika data sudah  di labeling dan juga sudah dilakukan pembobotan kata menggunakan TF -IDF maka selanjutnya membuat klasifikasi  model  menggunakan NaÃ¯ve Bayes  dan Logistic Regression . 
2.6.1 NaÃ¯ve Bayes  Classifier  
Naive Bayes Classifier  merupakan algoritma yang dikemukakan oleh ilmuan Inggris Thomas Bayes yang mana teknik ini menggunakan probabilitas dan statistik yang berasal dari teorema bayes. Keuntungan dari menggunakan Naive Bayes  Classifier  adalah metode ini hanya memerlukan sedikit data training  yang diperlukan untuk proses klasifikasi  [30]. Untuk mencari  algoritma Naive Bayes  dapat dilihat pada  persamaan  4 sebagai berikut : 
ð‘ƒ(ð‘|ð‘¥)= ð‘ƒ(ð‘¥|ð‘)ð‘ƒ(ð‘)
ð‘ƒ(ð‘¥) (4) 
Pada persamaan 4 di jelaskan bahwa perlu mencari nilai probabilitas class  berdasarkan vector  input yang 
diketahui atau yang disebut posterior  probability  ð‘ƒ(ð‘|ð‘¥), dalam mencari posterior probability  diperlukan mencari terlebih dahulu nilai probabilitas tiap input berdasarkan kondisi pada class  dengan nilai tertentu ð‘ƒ(ð‘¥|ð‘) yang akan dikalikan dengan class  pada suatu nilai yang telah dibagi dengan total data atau disebut prior probability  ð‘ƒ(ð‘). Hasil dari perkalian a ntara posterior probability  dan prior probability  akan dibagi dengan nilai predictor prior probability  ð‘ƒ(ð‘¥) dimana nilai ini merupakan probabilitas suatu input dari keseluruhan data.  
2.6.2 Logistic Regression  
Teknik Logistic Regression  merupakan sebuah metode statistik  yang bekerja berdasarkan hubungan antara variabel satu atau lebih. Teknik ini dapat digunakan untuk mengklasifikasi kalimat sebagai positif dan negati f [31]. 
Dalam Logistic Regression  dimana memiliki suatu variabel  terikat ð‘ƒ(ð‘Œ) yang skala pengukuran nya nominal atau 
kategorik dimana nilai dari ð‘ƒ(ð‘Œ) hanya bernilai 0 dan 1.  
ð‘ƒ(ð‘Œ)=1
1+ð‘’âˆ’(ð‘0+ð‘1ð‘‹1+ð‘2ð‘‹2+â‹¯+ð‘ð‘˜ð‘‹ð‘˜) (5) 
Keterangan dari persamaan 5 yaitu menjelaskan bahwa pada perhitungan Logistic Regression menggunakan sigmoid function dimana hasil  nilai output  dari fungsi ð‘ƒ(ð‘Œ) hanya bernilai bilangan biner yaitu 0 dan 1 . 
2.7 Optimasi SMOTE  
Optimasi SMOTE adalah salah satu teknik untuk mengambil sebuah sampel data dengan jumlah klasifikasi terendah sehingga dapat membuat keseimbangan dengan jumlah klasifikasi tertinggi dalam suatu data. Dengan adanya optimasi SMOTE mesin akan belajar dengan lebih optimal, dimana mesin tidak hanya mengenali kata-kata dengan juml ah klasifikasi tertinggi saja tetapi mesin mampu mengenali kata meskipun kata tersebut berasal dari klasifikasi terendah.  
2.8 Evaluasi  
Pada tahapan ini akan dilakukan evaluasi yang berguna untuk menentukan apakah model mampu memprediksi suatu sentimen deng an baik atau tidak. Kemampuan memprediksi tersebut diukur berdasarkan nilai dari Consufion Matrix , akurasi, precision , recall , dan F1-Score . Nilai Confusion matrix dihasilkan dari data yang sudah dilakukan prediksi d engan  data sebenarnya , yang mana output dari confusion matrix berupa matrik yang berbentuk tabel  [32]. Untuk gambaran confusion matrix dapat dilihat pada tabel 5 sebagai berikut:  
Class  Classified as Positive  Classified as  Negatif  
Positif  True Positive  (TP) False Negative  (FN)  
Negatif  False Positive  (FP) True Negative  (TN)  
Pada tabel 5 menjelaskan bahwa matrik tersebut terdiri dari True Positif (TP) memiliki arti bahwa jumlah data yang telah di uji oleh model berhasil terklasifikasi benar sebagai data positif, lalu untuk True Negati f (TN) bahwa data yang berhasil dibaca oleh mesin sebagai benar kata negati f, False Positif  (FP) bahwa mesin mempred iksi kata positif sebagai kata negati f, dan yang terakhir False  Negatif  (FN)  bahwa mesin memprediksi kata negatif sebagai kata positif.  Dalam menentukan model terbaik, peneliti an ini harus menganalisis nilai  classification report , di dalam  
classification report terdapat nilai akurasi, precision, recall, F1-Score yang dapat dijadikan acuan u ntuk 
menentukan model terbaik. Dalam menentukan classification report  terdapat persamaan yang dapat dilihat pada 
tabel 6 sebagai berikut:   
Tabel 6. Classification Report  
Measurement  Definition  Formula  
Accuracy  (A) Akurasi digunakan untuk mengetahui 
seberapa baik sistem dapat mengklasifikasi data dengan benar  ð´= ð‘‡ð‘ƒ+ð‘‡ð‘
(ð‘‡ð‘œð‘¡ð‘Žð‘™  ð‘›ð‘¢ð‘šð‘ð‘’ð‘Ÿð‘   ð‘œð‘“ ð‘ ð‘Žð‘šð‘ð‘’ð‘™ð‘  ) 
Precision  (P) Seberapa akurat suatu model dapat mengidentifikasi suatu sentimen  ð‘ƒ= ð‘‡ð‘ƒ
ð‘‡ð‘ƒ+ð¹ð‘ƒ 
Recall  (R) Seberapa baik model menemukan dan mengenali suatu sentimen  ð‘…= ð‘‡ð‘ƒ
ð‘‡ð‘ƒ+ð¹ð‘ 
F1-Score  (F) Gabungan dari Precision  dan Recall  dimana untuk mengukur performa sebauh sistem  F=2 x P x R P+R 
Pada tabel 6 menjelaskan bahwa terdapat beberapa hal yang harus diperhatikan dalam sebuah classification report yaitu nilai accuracy, precision, recall, dan F1 -Score . Pada masing -masing penilaian memiliki fungsi yang berbeda, dimana nilai accuracy digunakan untuk mengetahui seberapa baik algoritma mampu mengklasifikasikan data dengan benar , akan tetapi jika nilai akurasi tinggi tidak menjadi acuan suatu algoritma itu bagus, oleh karena itu diperlukan adanya perhitungan precision, recall dan F1 -Score  dimana kebutuhan pengukuran suatu algoritma tergantung dari karakter suatu data, sehingga dengan adanya beberapa perhitungan tersebut akan membuat keputusan yang lebih baik dalam menentukan model algoritma.  

3. HASIL DAN PEMBAHASAN  
3.1 Perbandingan Akurasi  
Dalam penelitian ini  jumlah data yang dihasilkan  setelah melalui tahapan preprocessing  pada  sentimen positif 
menghasilkan  5799 data, lalu data dengan sentimen negatif sebanyak 795 data. Dikarenakan data sentimen positif dan negatif tidak seimbang , maka menyebabkan model  algoritma Naive Bayes dan Logistic Regression  hanya dominan berlatih untuk kata positif . Sehingga akurasi dan performa klasifikasi untuk kelas positif akan tinggi. Dengan adanya data yang tidak seimbang tersebut  hasil eksperimen tid ak hanya berfokus pada nilai akurasi untuk menilai suatu model  algoritma . Sehinga  dalam eksperimen  ini menentukan model  algoritma  Naive Bayes atau Logistic Regression  yang memiliki performa terbaik perlu melihat nilai dari classification report  sepert i precision, recall dan F1 -Score. Pada penelitian ini dalam mengatasi data yang tidak seimbang diperlukan optimasi SMOTE, sehingga model  algoritma  tidak akan dominan  belajar ke salah satu sentimen. Ketika optimasi SMOTE diterapkan , maka data minority  akan memiliki jumlah yang sama  dengan data majority . Hasil dari eksperimen optimasi SMOTE dapat dilihat pada gambar 3 sebagai berikut:  
Gambar 3. Optimasi SMOTE  
SMOTE dan sesudah dilakukan optimasi SMOTE. Ketika data dilakukan optimasi SMOTE maka jumlah data pada setiap sentimen akan sama, sehingga dalam eksperimen ini jumlah data positif dan negatif  sebanyak 5799 data. Dengan dilakukan optimasi SMOTE ini model algoritma akan lebih seimbang dalam mempelajari suatu sentimen sehingga tidak ada lagi data yang memiliki jumlah yang sedikit (minority) dan jumlah data dengan sentimen tertinggi ( minority) . Setelah data sudah seimbang maka perlu dilakukan data training dan testing  agar model algoritma dapat belajar dengan data baru yang telah di optimasi SMOTE. Dalam penelitian ini setiap model algoritma Naive Bayes  dan Logistic Regression  menggunakan 70% data training dan 30% data testing . Data yang digunakan dalam penerapan model  algoritma  ini menggunakan data sebelum dilakukan optimasi SMOTE dan sesudah dilakukan optimasi SMOTE. Sehingga hasil dari setiap 
algoritma akan dibandingkan untu k mencari model dengan performa terbaik. Untuk  informasi  lebih detail mengenai hasil dari model algoritma dapat dilihat pada tabel 7 sebagai berikut:  
Tabel 7. Modelling  Before  SMOTE dan After  SMOTE  
Modelling  BEFORE  SMOTE  AFTER  SMOTE  
Accuracy  Precision  Recall  F1-Score  Accuracy  Precision  Recall  F1-Score  
Naive Bayes  Negatif  90% 73% 36% 48% 91% 87% 97% 92% 
Positif  91% 98% 95% 97% 85% 91% 
Logistic Regression  Negatif  91% 81% 36% 50% 95% 94% 93% 95% 
Positif  91% 99% 95% 96% 93% 95% 
Dari hasil perbandingan antara 70% data training  dan 30% data testing  sebelum dilakukan optimasi SMOTE menunjukan bahwa, model algoritma Naive Bayes dan Logistic Regression menghasilkan akurasi yang cukup tinggi. Pada model algoritma Naive Bayes menghasilkan akurasi 90% dan Logistic Regression  menghasilkan akurasi 91%. Dalam penelitian ini nilai dari akurasi tersebut belum bisa dijadikan acuan untuk menilai suatu model mampu membedakan kata positif dan negatif, sehingga perlu melihat kinerja dari nilai precision, recall, dan F1-Score. Hasil eksperimen setelah menguji model menggunakan optimasi SMOTE, nilai akurasi dari kedua 
algoritma mengalami peningkatan. Algoritma Naive Bayes  mengalami peningkatan  nilai accuracy dari 90% menjadi 91% . Pada senti men negatif nilai precision 73%mengalami peningkatan menjadi 87%, nilai recall  36% menjadi 97% dan nilai F1 -Score 48% menjadi 92%. Peningkatan nilai tidak hanya terjadi pada algoritma Naive Bayes, pada algoritma Logistic Regression juga mengalami peningka tan pada nilai akurasi 91% menjadi 95% dan juga peningkatan dalam eksperimen ini terjadi pada nilai classification report  yang mana hasil dari optimasi SMOTE tersebut berhasil meningkatkan nilai precision 81% menjadi 94%, recall 36% menjadi 93% dan F1-Score 50% menjadi 95%. Untuk menentukan model yang terbaik, peneliti melakukan eksperimen dengan melakukan komparasi dengan acuan perbandingan nilai confusion matrix pada kedua  algoritma. Berikut ini hasil dari confusion matrix untuk setiap model algoritma  dapat dilihat pada gambar 4 sebagai berikut:  
Gambar 4. Confusion Matrix  
membedakan kata negatif secara optimal, sehingga pada kedua algoritma kata negatif tersebut diklasifikasikan sebagai kata positif karena mesin dominan mempelaja ri sentimen positif. Setelah dilakukan eksperimen dilakukan optimasi SMOTE setiap algoritma lebih optimal dalam memprediksi setiap kata, dimana hasil dari eksperimen tersebut mampu memberikan peningkatan kepada kedua algoritma terutama dalam nilai True Negatif. Setelah dilakukan optimasi SMOTE nilai Ture Negative pada algoritma Naive Bayes mengalami peningkatan dari 89 data menjadi 983 data, lalu pada algoritma Logistic Regression  menghasilkan peningkatan pada True Negative  dari 89 data menjadi 1076 data. Hasil eksperimen dalam penelitian ini menunjukkan bahwa model algoritma Logistic Regression  menjadi algoritma yang terbaik. Hasil tersebut  dibuktikan dengan perbandingan dari confussion matrix kedua algoritma. Dimana nilai akurasi dari algoritma Logistic R egression  ketika dilakukan optimasi SMOTE menghasilkan akurasi tertinggi yaitu sebesar 95%, lalu dilakukan analisis kembali bahwa dalam eksperimen ini pada kedua algoritma memiliki keunggulan pada precision  dan recall  baik dalam kelas sentimen positif maupun negatif.  Sehingga dalam eksperimen penelitian ini F1-Score  menjadi acuan untuk menentukan performa suatu model, dimana nilai dari F1-Score  dihasilkan dari perhitungan antara precision dan recall. Pada algoritma Logistic Regression  menghasilkan nilai F1 -Score yaitu sebesar 95% hal tersebut menunjukan algoritma tersebut memiliki performa yang sangat baik.  
3.2 Visualisasi Data  
Pada penelitian ini dilakukan eksperimen menggunakan  visualisasi wordcloud  untuk menganalisis data teks. Wordcloud  akan menampilkan semua kata yang ada di  dalam teks, sehingga kata yan g mem punyai  frekuensi tertinggi akan memiliki  ukuran font lebih besar  di dalam visualisasi wordcloud. Pada penelitian ini hasil dari wordcloud  untuk seluruh data mengenai topik metaverse dapat dilihat pada gambar 5 sebagai berikut:  
Gambar 5. Wordcloud Metaverse  
Dari hasil wordcloud  kata metaverse sering disebut dalam komentar, selanjutnya kata yang sering dibahas tentang metaverse yaitu â€œmetaverseâ€,â€ teknologi â€, â€œgame â€, â€œdunia â€, â€œvirtual â€, â€œmasa depan â€ dan sebagainya.  Hal ini menunjukan bahwa masyarakat Indonesia banyak membahas metaverse dengan beberapa kata kunci tersebut, sehingga perlu dilakukan analisis apakah kata kunci tersebut masuk ke dalam komentar positif atau negatif. Berikut ini wordcloud  dari data  komentar  positif dan negatif mengenai metaverse yang dapat dilihat pada gambar 6 sebagai berikut :  
Gambar 6. Word cloud  Sentimen Positif dan Negatif  
muncul diantaranya â€œmetaverse â€, â€œaiâ€, â€œktpâ€, â€œpaham â€, â€œteknologi â€, â€œnftâ€, â€œkerja â€ dan sebagainya. Hasil analisis dari wordcloud  dengan sentimen negatif  pada penelitian ini dapat disimpulkan bahwa , konsep metaverse  menerapkan teknologi Artificial Intelligence (AI) sehingga memberikan suatu opini negatif terhadap masyarakat bahwa beberapa sektor pekerjaan akan tergantikan oleh AI [33]. Selanjutnya salah satu kata yang memiliki frekuensi  yang cukup tinggi yaitu ktp . KTP merupakan singkatan dari Kartu Tanda Penduduk  yang dipergunakan sebagai identitas warga negara Indonesia.  Suatu registrasi terkadang membutuhkan KTP, dari hasil analisis bahwa masyarakat memberikan opini tentang keraguan terhadap metaverse dari keamanan data. Keraguan dari 
masyarakat muncul ketika sistem mengalami bug maka bukan tidak mungkin akan terjadi suatu kebocoran data, kebocoran data tersebut dapat digunakan untuk suatu tindakan kri minal oleh pihak yang tidak bertanggung jawab [34]. Dari sebagian  masyarakat Indonesia yang memberikan komentar negatif dapat disimpulkan bahwa, masyarakat masih takut dengan adanya perkembangan teknologi ini dikarenakan pekerjaan dapat tergantikan oleh AI dan akan menyebabkan angka pengangguran yang tinggi, selain itu masyarakat masih memiliki keraguan dalam keamanan data jika terjadi bug sehingga menyebabkan kebocoran data. Berdasarkan hasil dari visualisasi wordcloud  dalam klasifikasi komentar positif terdapat kata â€œdunia â€, â€œteknologi â€, â€œgame â€, â€œethâ€, â€œvirtual â€, dan â€œdigital â€. Dari Kumpulan kata yang memiliki frekuensi terbanyak tersebut dapat disimpulkan bahwa metaverse menjadi teknologi yang canggih dimana teknologi  ini dapat membuat dunia virtual, di  dalam dunia virtual tersebut pengguna bisa berinteraksi dan juga pengguna dapat bermain game dan melakukan kegiatan seperti di dunia nyata.   
Frekuensi kata digunakan untuk melihat seberapa banyak kata tersebut dibahas di dalam suatu analisis sentimen.  Untuk lebih detail mengenai frekuensi kata  yang memiliki nilai tertinggi  dapat dilihat pada gambar 7 sebagai berikut:  
Gambar 7 . Frekuensi Kata   
Berdasarkan gambar 7 dapat dilihat 10 frekuensi kata tertinggi, dimana f rekuensi kata yang sering muncul yaitu kata â€œmetaverse â€, â€œdunia â€, â€œbisaâ€, €œIndonesia â€ dan sebagainya.  Sehingga dapat disimpulkan bahwa masyarakat Indonesia sering membahas topik metaverse terkait teknologi yang digunakan untuk penerapan konsep dunia virtual. 

4. KESIMPULAN  
Berdasarkan hasil  dari penelitian ini telah dilakukan analisis sentimen terhadap opini masyarakat Indonesia 
mengenai perkembangan metaverse di media sosial X. Data dalam penelitian ini menggunakan  6728 data  mengenai metaverse. Dalam penelitian ini dilakukan komparasi model algoritma Naive Bayes dan Logistic Regression. Hasil dari komparasi tersebut mendapatkan nilai algoritma NaÃ¯ve Bayes menghasilkan akurasi 90% dan algoritma Logistic Regression  menghasilkan akurasi 91%.  Berdasa rkan eksperimen yang telah dilakukan model tersebut masih dominan belajar lebih banyak data dengan sentimen positif sehingga terjadi ke tidak seimbangan data.  Untuk mengatasi data yang tidak seimbang dilakukan optimasi SMOTE agar data minority  dapat 
memiliki jumlah data yang sama dengan data majority . Hasil eksperimen setelah dilakukan optimasi SMOTE, kedua algoritma mengalami kenaikan pada kedua sentimen, terutama sentimen  negatif, hal ini menandakan bahwa model telah berhasil mempelajari data  dengan baik pada setiap sentimen , sehingga model tidak lagi dominan mempelajari data dengan sentimen positif.  Setelah dilakukan optimasi SMOTE pada penelitian ini, algoritma Score 95%.  Penelitian  ini memiliki keterbatasan menggunakan dua algoritma klasifikasi teks yaitu Naive Bayes dan Logistic Regression.  Sehingga penelitian selanjutnya dapat membandingkan algoritma klasifikasi teks lainnya yang lebih variatif untuk mendapatkan nilai akurasi, precision, recall, dan F1-Score  yang lebih baik.  

UCAPAN TERIMAKASIH  
Terima kasih kepada Universitas Teknokrat Indonesia yang telah memfasilitasi lab riset untuk menyelesaikan eksperimen ini.
  
REFERENCES  
[1] G. A. Kaya, â€œSentiment Analysis on the Metaverse: Twitter Data,â€ SAKARYA UNIVERSITY JOURNAL OF COMPUTER AND INFORMATION SCIENCES, vol. 5,  no. 2, 2022, doi: 10.35377/saucis.04.01.  
[2] B. Yu, Y. Liu, S. Ren, Z. Zhou, and J. Liu, â€œMETAseen: Analyzing network traffic and privacy policies in Web 3.0 based Metaverse,â€ Digital Communications and Networks, Dec. 2023, doi: 10.1016/j.dcan.2023.11.006 . 
[3] A. Nur and Y. D. Putra, â€œMANAJEMEN RISIKO EKONOMI PADA PENERAPAN METAVERSE DI INDONESIA,â€ 2022.  
[4] S. Yang, H. Joo, and J. Kim, â€œMetaverse search system: Architecture, challenges, and potential applications,â€ ICT Express, Dec. 2023, doi: 10.1016/j.i cte.2023.12.006.  
[5] F. F. Rachman and S. Pramana, â€œAnalisis sentimen pro dan kontra masyarakat Indonesia tentang vaksin COVID -19 pada media sosial Twitter,â€ Indonesian of Health Information Management Journal (INOHIM), vol. 8, no. 2, pp. 100 â€“109, 2020.  
[6] R. N. Ikhsani and F. F. Abdulloh, â€œOptimasi SVM dan Decision Tree Menggunakan SMOTE Untuk Mengklasifikasi 
Sentimen Masyarakat Mengenai Pinjaman Online,â€ JURNAL MEDIA INFORMATIKA BUDIDARMA, vol. 7, no. 4, pp. 1667 â€“1677, 2023.  
[7] T. Mustaqim, K. Umam, a nd M. A. Muslim, â€œTwitter text mining for sentiment analysis on governmentâ€™s response to 
forest fires with vader lexicon polarity detection and k -nearest neighbor algorithm,â€ J Phys Conf Ser, vol. 1567, no. 3, p. 
032024, Jun. 2020, doi: 10.1088/1742 -6596/1 567/3/032024.  
[8] A. F. Watratan and D. Moeis, â€œImplementasi Algoritma Naive Bayes Untuk Memprediksi Tingkat Penyebaran Covid -19 
Di Indonesia,â€ Journal of Applied Computer Science and Technology, vol. 1, no. 1, pp. 7 â€“14, 2020.  
[9] R. Novendri, A. S. Callis ta, D. N. Pratama, and C. E. Puspita, â€œSentiment Analysis of YouTube Movie Trailer Comments Using NaÃ¯ve Bayes,â€ Bulletin of Computer Science and Electrical Engineering, vol. 1, no. 1, pp. 26 â€“32, Jun. 2020, doi: 10.25008/bcsee.v1i1.5.  
[10] P. Rajendra and S . Latifi, â€œPrediction of diabetes using logistic regression and ensemble techniques,â€ Computer Methods and Programs in Biomedicine Update, vol. 1, p. 100032, 2021, doi: 10.1016/j.cmpbup.2021.100032.  
[11] T. Ciu and R. S. Oetama, â€œLogistic Regression Predic tion Model for Cardiovascular Disease,â€ vol. VII, no. 1, p. 33, 2020, [Online]. Available: https://www.kaggle.com/ronitf/heart - 
[12] S. A. Assaidi and F. Amin, â€œAnalisis Sentimen Evaluasi Pembelajaran Tatap Muka 100 Persen pada Pengguna Twitter menggunakan  Metode Logistic Regression,â€ Jurnal Pendidikan Tambusai, vol. 6, no. 2, pp. 13217 â€“13227, 2022.  
[13] P. Arsi and R. Waluyo, â€œAnalisis Sentimen Wacana Pemindahan Ibu Kota Indonesia Menggunakan Algoritma Support 
Vector Machine (SVM),â€ J. Teknol. Inf. dan Ilm u Komput, vol. 8, no. 1, p. 147, 2021.  
[14] R. Tineges, A. Triayudi, and I. D. Sholihati, â€œAnalisis Sentimen Terhadap Layanan Indihome Berdasarkan Twitter Dengan Metode Klasifikasi Support Vector Machine (SVM),â€ JURNAL MEDIA INFORMATIKA BUDIDARMA, vol. 4, no. 3, 
p. 650, Jul. 2020, doi: 10.30865/mib.v4i3.2181.  
[15] M. R. Ghufron, M. F. M. Arsyada, M. R. Lukman, Y. A. H. Putra, and N. A. Rakhmawati, â€œAnalisis Sentimen Pengguna 
Twitter Terhadap Pemilu 2024 Berbasis Model XLM -T,â€ J -INTECH (Journal of Informatio n and Technology), vol. 11, 
no. 2, pp. 307 â€“315, 2023.  
[16] N. M. A. J. Astari, Dewa Gede Hendra Divayana, and Gede Indrawan, â€œAnalisis Sentimen Dokumen Twitter Mengenai 
Dampak Virus Corona Menggunakan Metode Naive Bayes Classifier,â€ Jurnal Sistem dan Infor matika (JSI), vol. 15, no. 1, pp. 27 â€“29, Nov. 2020, doi: 10.30864/jsi.v15i1.332.  
[17] M. Z. Anbari and B. Sugiantoro, â€œStudi Komparasi Metode Analisis Sentimen NaÃ¯ve Bayes, SVM, dan Logistic 
Regression Pada Piala Dunia 2022,â€ JURNAL MEDIA INFORMATIKA BUDID ARMA, vol. 7, no. 2, pp. 688 â€“695, 
2023.  
[18] D. Gunawan, D. Riana, D. Ardiansyah, F. Akbar, and S. Alfarizi, â€œKomparasi Algoritma Support Vector Machine Dan 
NaÃ¯ve Bayes Dengan Algoritma Genetika Pada Analisis Sentimen Calon Gubernur Jabar 2018 -2023â€, doi: 
10.31294/jtk.v4i2.  
[19] T. D. Dikiyanti, A. M. Rukmi, and M. I. Irawan, â€œSentiment analysis and topic modeling of BPJS Kesehatan based on twitter crawling data using Indonesian Sentiment Lexicon and Latent Dirichlet Allocation algorithm,â€ J Phys Conf Ser, vol. 1821, no. 1, p. 012054, Mar. 2021, doi: 10.1088/1742 -6596/1821/1/012054.  
[20] S. S. Sari, U. K. Ulfa, P. E. P. U. Pradita, and T. S. Tri, â€œAnalisis Sentimen Terhadap Komentar Beauty Shaming Di Media Sosial Twitter Menggunakan Algoritma SentiStrength,â€  Indonesian Journal of Informatic Research and Software Engineering (IJIRSE), vol. 1, no. 1, pp. 71 â€“78, Apr. 2021, doi: 10.57152/ijirse.v1i1.55.  
[21] J. F. Sianipar, Y. R. Ramadhan, and I. Jaelani, â€œAnalisis Sentimen Pembangunan Kereta Cepat Jakarta -Bandung di Media Sosial Twitter Menggunakan Metode Naive Bayes,â€ KLIK: Kajian Ilmiah Informatika dan Komputer, vol. 4, no. 1, pp. 360â€“367, 2023. analysis of the relocation of the Indonesian capital,â€ Jurnal Mantik, vol. 7, no. 1, pp. 185 â€“193, 2023.  
[23] S. K. M. P. Fitri Marisa, S. T. M. S. M. M. T. Anastasia Lidya Maukar, and S. S. M. M. S. I. Dr. Tubagus Mohammad Akhriza, Data Mining Konsep Dan Penerapannya. Deepublish, 2021. [Online]. Available: https://books.google.co.id/books?id=BtlVEAAAQBAJ  
[24] M. I. Ahmadi, F. Apriani, M. Kurniasari, S. Handayani, and D. Gustian, â€œSentiment Analysis Online Shop on the Play Store Using Method Support Vec tor Machine (Svm),â€ in Seminar Nasional Informatika (SEMNASIF), 2020, pp. 196 â€“
203. 
[25] T. Astuti and Y. Astuti, â€œAnalisis Sentimen Review Produk Skincare Dengan NaÃ¯ve Bayes Classifier Berbasis Particle Swarm Optimization (PSO),â€ JURNAL MEDIA INFORMATIKA B UDIDARMA, vol. 6, no. 4, p. 1806, Oct. 2022, doi: 10.30865/mib.v6i4.4119.  
[26] S. Styawati, A. R. Isnain, N. Hendrastuty, and L. Andraini, â€œComparison of Support Vector Machine and NaÃ¯ve Bayes on Twitter Data Sentiment Analysis,â€ Jurnal Informatika: Jurnal  Pengembangan IT, vol. 6, no. 1, pp. 56 â€“60, 2021.  
[27] D. N. Fitriana and Y. Sibaroni, â€œSentiment analysis on kai twitter post using multiclass support vector machine (svm),â€ Jurnal RESTI (Rekayasa Sistem Dan Teknologi Informasi), vol. 4, no. 5, pp. 846 â€“853, 2020.  
[28] D. Apriliani, A. Susanto, M. F. Hidayattullah, and G. W. Sasmito, â€œSentimen Analisis Pandangan Masyarakat Terhadap Vaksinasi Covid 19 Menggunakan K -Nearest Neighbors,â€ Jurnal Informatika: Jurnal Pengembangan IT, vol. 8, no. 1, pp. 34â€“37, 2023 . 
[29] L. MartÃ­nez -VillaseÃ±or, O. Herrera -AlcÃ¡ntara, H. Ponce, and F. A. Castro -Espinoza, Advances in Computational 
Intelligence: 19th Mexican International Conference on Artificial Intelligence, MICAI 2020, Mexico City, Mexico, 
October 12 â€“17, 2020, Procee dings, Part II. in Lecture Notes in Computer Science. Springer International Publishing, 2020. [Online]. Available: https://books.google.co.id/books?id=b4oBEAAAQBAJ  
[30] A. Damayunita, R. S. Fuadi, and C. Juliane, â€œComparative Analysis of Naive Bayes, K -Nearest Neighbors (KNN), and Support Vector Machine (SVM) Algorithms for Classification of Heart Disease Patients,â€ Jurnal Online Informatika, vol. 7, no. 2, pp. 219 â€“225, Dec. 2022, doi: 10.15575/join.v7i2.919.  
[31] I. Rahmawati, T. R. Fitriani, A. Noâ€™eman, and A. Y. P. Yusuf, â€œAnalisis Sentimen Menggunakan Algoritma Logistic Regression Pada Penerbangan Lion Air berdasarkan Ulasan Platform Online,â€ Jurnal Riset Informatika dan Teknologi Informasi, vol. 1, no. 1, pp. 11 â€“16, 2023.  
[32] I. Werdiningsih, D. C. R.  Novitasari, and D. Z. Haq, Pengelolaan Data Mining dengan Pemrograman Matlab. Airlangga 
University Press, 2022. [Online]. Available: https://books.google.co.id/books?id=CgOdEAAAQBAJ  
[33] S. Masrichah, â€œAncaman Dan Peluang Artificial Intelligence (AI),â€ Khatulistiwa: Jurnal Pendidikan dan Sosial Humaniora, vol. 3, no. 3, pp. 83 â€“101, 2023.  
[34] E. S. Priowirjanto, â€œUrgensi Pengaturan Mengenai Artificial Intelligence Pada Sektor Bisnis Daring Dalam Masa Pandemi Covid-19 di Indonesia,â€ Jurnal Bina Mulia Huku m, vol. 6, no. 2, pp. 254 â€“272, 2022.  
",Analisis Sentimen,"Naive Bayes, Logistic Regression",data komentar masyarakat terkait metaverse pada media sosial X,"akurasi, precision, recall, F1-Score"
Analisis Sentimen Masyarakat terhadap Tindakan Vaksinasi  dalam  Upaya  Mengatasi  Pandemi Covid-19 ,"Analisis Sentimen Masyarakat terhadap Tindakan Vaksinasi  dalam  Upaya  Mengatasi  Pandemi Covid-19 

Brian Laurensz1, Eko Sediyono2 

Abstract 
Coronavirus has become a global pandemic and has 
spread almost all over the world, including Indonesia. Many 
negative impacts resulted from the spread of COVID -19 in 
Indonesia, so the government made vaccination measures to 
reduce the rate of spread of COVID -19. Responses from the public to vaccination measures are quite diverse on social media Twitter. Some are supportive and some disagree.  The purp ose of this study is to find out how people's sentiment towards vaccination measures. The data used 845 tweets, using two keywords, vaksinmerahputih """" and """"vaksinsinovac."""" The data is then divided into 253 training data and 592 testing  data . The classification will use the SVM and Naive Bayes methods. The classification result of the Naive Bayes method received an average accuracy of 85.59%, while SMV of 84.41%. Sentiment 
results on Naive Bayes method with keyword""""vaksinsinovac"""" gets positive sentiment of 66% and negative sentiment of 34%, while vaksinmerahputih """" obtains 89% and 11%  for positive  and negative  sentiment, respectively . SVM method with keyword vaksinsinovac"""" gets 96% positive and 4% negative , while vaksinmerahputih """" obtains 98% positive and 2% negative. It can be concluded that the results of public sentiment towards vaccination measures received a positive response.  
 
Intisari 
Virus corona  telah menjadi pandemi dunia dan sudah menyebar hampir ke seluruh dunia, termasuk Indonesia. Banyak dampak negatif yang diakibatkan oleh penyebaran  COVID -19 di 
Indonesia, sehingga  pemerintah mengambil tindakan vaksinasi  agar  dapat me nekan  tingkat  penyebaran COVID-19.Tanggapan dari masyarakat  terhadap tindakan  vaksinasi  cukup  beragam  di media sosial Twitter , ada yang mendukung dan ada juga yang tidak setuju. Makalah ini bertujuan untuk mengetahui  sentimen masyarakat terhadap tindakan  vaksinasi . Data yang digunakan sebanyak 845 tweet , dengan menggunakan dua kata kunci , yaitu â€œvaksinmerahputih â€ dan â€œvaksinsinovacâ€. Data kemudian  dibagi menjadi 253 data latih  dan 592 data uji. Klasifikasi  dilakukan  
menggunakan metode SVM dan  Naive Bayes . Hasil klasifikasi dari metode NaÃ¯ve Bayes  mendapatkan rata -rata akurasi  85,59%, sedangkan SMV  sebesar 84 ,41%.  Hasil sentimen pada metode Naive Bayes  dengan kata kunci â€œvaksinsinovacâ€ mendapatkan sentimen positif 66% dan negatif 34% , sedangkan 
â€œvaksinmerahputihâ€  memperoleh sentimen positif 89% dan 
negatif 11%. Metode SVM dengan kata kunci â€œvaksinsinovacâ€ mendapatkan sentimen positif 96% dan negatif 4%, sedangkan â€œvaksinmerahputihâ€ mendapatkan sentimen positif 98% dan negatif 2% . Dapat disimpulkan bahwa hasil sentimen masyarakat terhadap tindakan  vaksinasi mendapa t respons yang positif.  
 
Kata Kunci Virus Corona , Indonesia, Vaksin, Sentimen, SVM, Naive Bayes.
 
I. PENDAHULUAN  
Virus corona mulai menjadi wabah pada bulan November -
Desember 2019 di kota Wuhan , China.  Virus ini merupakan 
salah satu virus yang sangat berbahaya karena tingkat 
penyebara nnya yang tinggi sehingga meluas  dengan cepat  ke 
seluruh dunia . Menurut catatan WHO , pada tahun 2020 sudah 
banyak laporan dari berbagai negara yang  mengonfirmasi  
terjangkit virus corona  atau COVID-19 [1]. Di Indonesia  pertama kali  terdeteksi adanya warga yang terjangkit virus corona  pada tanggal  2 maret 2020 , yang terjadi pada dua orang warga Depok, Jawa Barat  [2]. Semenjak saat itu, dari catatan satgas pemulihan COVID -19, diketahui semakin banyak kasus yang terkonfi rmasi positif dari bulan ke bulan. Kondisi penyebaran virus yang semakin meluas di Indonesia  ini menimbulkan masalah bukan hanya di bidang kesehatan saja, tetapi juga ekonomi, pendidikan , dan lainnya, 
yang ikut terkena dampak  Upaya pemerintah Indonesia sudah di lakukan untuk menekan tingkat penyebaran virus corona  supaya dampak negatif yang ditimbulkan dapat dikendalika n, di antaranya dengan melakukan tindakan vaksinasi. Terdapat dua jenis vaksin yang dipakai oleh pemerintah Indonesia , yaitu  vaksin Sinovac  dan va ksin merah-putih. Penggunaan kedua vaksin ini mendapatkan berbagai macam tanggapan dan pendapat dari masyarakat.  Pendapat yang disampaikan ada yang baik dan membangun, tetapi ada juga yang bertentangan dan menolak.  Media sosial Twitter menjadi salah satu tempat masyarakat dapat dengan bebas menyampaikan pendapat [3].  
Banyak metode analisis yang dapat digunakan untuk 
menganalisis pendapat masyarakat  berdasarkan informasi yang ada pada media sosial semacam Twitter. Salah satu di  antaranya adalah metode  analisis  sentimen . Metode  analisis sentimen merupakan  salah satu metode untuk menganalisis data yang didapatkan dari in ternet sehingga dapat  diketahui polaritas dari data tersebut [4]. Dengan menggunakan analisis sentimen, polaritas dari opini yang ada dapat dikumpulkan , sehingga akan  dapat digunakan untuk memprediksi  suasana publik  atau gambaran perasaan netizen  bersifat negatif atau pos itif [4]. Beberapa penelitian tentang klasifikasi sentimen pada konten media sudah dilakukan  sebelumnya . Dalam sebuah penelitian , dilakukan prediksi penyebaran COVID-19 di  1,2 Program Studi Magister Sistem Informasi, Universitas Kristen Satya Wacana, Jl. Dr . O. Notohamidjodjo, Kot a Salatiga, INDONESIA,  50715 (e -mail: Brianlaurensz@gmail.com, Ekosed1@yahoo.com ) Indonesia  dengan menggunakan algoritme Naive Bayes  [1]. Data yang digunakan  dikumpulkan secara kuan titatif dengan fokus pada penggunaan tabel, angka, dan grafik . Algoritme yang digunakan untuk melakukan analisis adalah Naive Bayes, 
dengan data yang didapatkan  akan  diproses untuk menghasilkan  nilai proba bilitas yang berbeda-beda  pada  setiap kriteria  class . Nilai pro babilitas yang didapatkan digunakan untuk memprediksi tingkat penyebaran COVID -19. Hasil nya menunjuk kan bahwa tingkat keakuratan klasifikasi sentimen dengan menggunakan Naive Bayes mendapatkan  persentase akurasi  48,48%, dengan enam belas  data berhasil dikl asifikasi dengan benar dari total 33 data yang  digunakan . Hasil dari penelitian ini digunakan untuk me lihat tingkat penyebaran COVID -19 di Indonesia [1].  Dalam penelitian lain, dilakukan analisis sentimen terhadap pengguna jasa transportasi daring ( online ) di Indonesia dengan menggunakan metode Support Vector Machine  (SVM) 
berbasis Particle Swarm Optimization  (PSO) [4] . Data yang 
digunakan sebanyak 1.852 tweet  dan dibagi menjadi data latih (training ) dan data uji (testing ). Tujuan dari penelitian ini yaitu untuk mengetahui  sentimen pengguna  transportasi daring  di Indonesia serta  memband ingkan tingkat akurasi  dari SVM dan SVM-PSO.  Penggunaan nilai default k-fold atau 10 k-fold dalam penelitian ini mendapatkan hasil akurasi  SVM  95,46% serta nilai AUC 0,9 79, sedangkan untuk akurasi , SVM-PSO mendapatkan nilai akurasi  sebesar 96,04% serta AUC 0,993 . Algoritme SVM berbasis PSO dalam penelitian ini mempunyai tingkat akurasi  yang lebih baik dari algoritme SVM biasa . Hasil dari penelitian ini digunakan untuk melihat tanggapan masyarakat Indonesia terhadap pelayanan yang didapat dari jasa transportasi daring  [4].  Telah dilakukan juga penelitian yang membahas tentang   analisis sentimen publik terhadap  kebijakan yang dibuat oleh presiden  Joko Widodo untuk meng hadapi  wabah  COVID-19 [5]. Dalam penelitian ini , data diambil menggunakan metode  web scraping  dengan kata kunci â€œJokowiâ€ dan â€œcovidâ€.  Proses klasifikasi data dalam penelitian ini menggunakan metode Naive Bayes , k-NN, dan SVM.  Hasil dari penelitian ini menunjuk kan bahwa SVM  mempunyai rata-rata nilai terbaik dibandingkan dengan metode lain yang digunakan dalam penelitian ini, dengan  tingkat  persentase akurasi sebesar 84,58%,  recall  85,82%, dan presisi  82,14%. Tujuan penelitian ini yaitu  untuk mengklasifikasikan sentimen dari media sosial Twitter  sesuai dengan  kata kunci yang dipakai . Hasil dari 
penelitian ini  digunakan sebagai indikator keberhasilan 
kebijakan yang dibuat oleh pemerintah  [5]. Beberapa penelitian yang sudah dilakukan sebelumnya dapat membuktikan bahwa untuk mengetahui sentimen masyarakat terhadap sebuah masalah yang terjadi dan menjadi topik pembicaraan di sosial media , dapat dilakukan analisis sentimen menggunakan machine learn ing. Berdasarkan hal tersebut dan latar belakang masalah yang terjadi, dilakukan penelitian tentang  analisis sentimen masyarakat di media sosial Twitter terhadap  tindakan  vaksinasi yang dibuat  oleh pemerintah . Proses klasifikasi dalam makalah ini menggunakan metode 
Naive Bayes  dan SVM .  Fokus pada  makalah ini yaitu melakukan  perbandingan hasil analisis sentimen dari vaksin Sinovac  dan vaksin merah-putih. Jika sentimen yang dihasilkan positif , tindakan vaksinasi  yang dibuat dinilai sangat tepat oleh masyarakat, dan apabila sentimen negatif , berarti masyarakat tidak setuju atau banyak yang menolak vaksinasi  tersebut. Dalam makalah ini dibandingkan  tingkat akurasi  dari kedua algoritme yang digunakan . Pengujian vali dasi dilakukan dengan nilai 10 k-fold cross validation . 

II. KONTEN UTAMA . 
A. Analisis Sentimen .  
Analisis sentimen atau opini on mining  merupakan  cabang 
ilmu dar i data mining  yang biasanya digunakan untuk 
menganalisis data tekstual berupa  sebuah opini  yang 
mengandung polaritas sehingga nantinya menghasilkan sebuah 
informasi yang memil iki nilai positif, negatif, atau netral  [4], [6],  [7].  Di dalam proses klasifikasi terdapat tiga mÃ©tode yang digunakan, yaitu lexicon base , hybrid approach , dan machine learning  [4], [7]. Metode machine learning  digunakan dalam makalah ini karena dengan metode ini dapat diprediksi polaritas sentimen dari data yang digunakan  [4], [7], [8]. 
B. Support Vector Machine (SVM ).  
SVM  adalah  teknik supervised learning  yang mempunyai 
tingkat akurasi  dan kualitas yang baik sehingga membua tnya 
menjadi sangat diminati di antara algoritme  yang lainnya . Akan tetapi , untuk implement asinya diperlukan tahap pelatihan sequen tial training  dan harus melalui proses pengujian  [4], [9].  Proses analisis akan dimulai dengan mengubah data  teks yang ada  menjadi  sebuah  data vektor , kemudian akan  dikombinasikan  dengan meng gunakan Term Frequency Inverse Document Frequency  (TF-IDF) untuk dilakukan pembobotan  [7]. Kelebihan metode SVM adalah 
kemampuannya  mengidentifikasi hyperplane  yang terpisah 
sehingga bisa memaksimalkan margin dari kelas yang berbeda.  
Metode SVM juga memil iki kekurangan , yaitu pada masalah 
yang mempunyai fitur yang sama dapat memengaruhi tingkat 
akurasi  secara signifikan  [10]âˆ’[12]. 
C. Naive Bayes  
Naive Bayes adalah  metode proba bilitas yang pertama kali 
diperkenalkan  oleh seorang ilmuwan  asal Inggris , yaitu 
Thomas Bayes . Naive Bayes digunakan  untuk memprediksi 
peluang di masa depan dengan menggunakan pengalaman yang 
ada di masa lalu  [7], [6], [13]. Penerapan Naive Bayes  ke dalam analisis sentimen harus mempunyai dua proses penting , yaitu pelatihan  dan pengujian [4], [7]. Kelebihan Naive Bayes terletak pada kecil nya jumlah data latih yang digunakan sehingga perhitungan  dapat dilakukan lebih cepat dan efisien  [1]. Adapun kelemahan Naive Bayes yaitu  jika pada pemilihan fitur terjadi kesalahan , tingkat akurasi  akan menurun dan waktu perhitungan akan semakin bertambah  [5] . 
D. Pre-processing  
Data teks  yang diambil  dari med ia sosial Twitter  terkadang memberikan tantang an tersendiri  karena terdapatnya  kata yang tidak baku, penggunaan bahasa daerah , atau singkatan yang tidak ada di dalam Kamus Besar Bahasa Indonesia (KBBI ) [7]. Untuk membuat data menjadi lebih terstruktur , diperlukan pre-processing . Proses ini dilakukan untuk  membuat sebanyak mungkin bahasa yang tidak baku menjadi bahasa baku dan  untuk membersihkan data  dari noise  yang ada  sehingga data menjadi lebih terst ruktur sehingga siap untuk dianalisis  [4], [13]. Terdapat bebera pa proses dalam pre-processing , yaitu sebagai berikut . 
1)  Tran sform Cases:  Kata-kata yang tidak berhubungan  
akan di ubah . Misalnya , kata yang mengandung huruf besar 
akan diubah semuanya menjadi huruf kecil atau lower case . 
2)  Tokenize:  Dalam proses ini , tanda baca, karakter khusus, simbol , atau karakter yang bukan termasuk huruf akan dihapus  
3)  Filter Token  (By Length): Kata-kata yang lebih pendek 
dari empat  huruf atau lebih dari 25 huruf akan dihapus, 
misal nya â€˜tdkâ€™, â€˜ygâ€™, dan â€˜ ganâ€™. 
4)  Stopword Removal:  Kata atau konjungsi  yang tidak 
relevan , misalnya  tetapi, dengan, untuk, yang, dan kaya 
sambung lainnya , akan dihapus  
5)  Stemming : Kata yang berimbuhan , seperti mem -, me -, 
meny -, meng -, per -, dan ber-, akan diseleksi dan diubah 
menjadi kata dasar . 
6)  Generate n -Gram s: Untuk menyelesaikan masalah  
dalam  proses klasifikasi , n-grams  akan digunakan . Kesalahan yang biasanya terjadi adalah pengg unaan term tungga l. Contohnya , kata â€˜buruk â€™ termasuk dalam sentimen negatif , tetapi  jika disandingkan dengan kata negasi akan menjadi sentimen positif , misalnya  â€˜tidak buruk â€™. 
E. Term Weighting  
Terhadap k ata-kata yang sudah mela lui pre-processing  dan 
sudah berbentuk data numerik akan dilakukan pembobotan [5]. 
Term weighting merupakan tahap pembobotan untuk setiap 
kata sehingga kemampuan dalam proses analisis  sentimen 
menjadi meningkat [4], [7]. Dalam makalah ini, pembobotan 
dilakukan menggunakan  TF-IDF. Dalam metode ini , pembobotan  mengombinasikan frekuensi kata dan frekuensi dokumen [5], [7].  

III. METODOLOGI â€¦ 
Pada  makalah ini, ada beberapa tahapan yang perlu 
dilakuk an agar diperoleh hasil yang terbaik . Tahap -tahap ini terdiri atas pengumpulan data dan pel abelan data, kemudian dilanjutkan dengan  pre-processing . Data yang sudah melalui pre-processing  akan diklasifikasi dengan menggun akan algoritme  Naive Bayes  dan SVM . Proses pengujian akan dilakukan dengan metode k-Fold Cross Validation . Gbr. 1 menunju kkan tahapan -tahapan  yang dilakukan.  
A. Pengumpulan Data â€¦ 
Prose pengumpulan data  menggunakan  teknik web scraping  
dengan  tools  Octoparse . Data diambil dari bulan November 2020 sampai Februari 2021, berdasarkan kata kunci â€œvaksinsinovacâ€ dan â€œvaksinmerahputihâ€. Data yang berhasil dikumpulkan  sebanyak  845 tweet  dari setiap kata kunci.  Data tweet  yang dipakai ini merupakan campuran dari tweet  berita dan tweet  tanggapan masyarakat . Data tersebut kemudian dipersiapkan untuk dibagi ke dalam  data latih sebanyak  253 dan data uji sebanyak  592 tweet . Selanjutnya , data yang sudah dikumpulkan di beri label secara manual menurut ahli bahasa menjadi sentimen negatif atau positif.  
B. Pre-processing  
Data-data yang sudah dikumpulkan dan dibagi menjadi data 
uji dan latih akan melalui tahap pre-processing menggunakan 
tools RapidMinerStudio. Proses ini bertujuan agar data dapat 
diklasifikasi dan untuk mempermudah proses analisis . 
C. Pembobotan TF/IDF â€¦. 
Tahap selanjutnya  adalah melakukan  pembobotan terhadap  
setiap  kata berdasarkan frekuensi dari term atau istilah yang muncul pada dokumen . Pada  makalah ini, pembobotan 
dilakukan dengan metode TF -IDF. 
D. Klasifikasi â€¦ 
Proses klasifikasi  dilakukan menggunakan algoritme  NaÃ¯ve 
Bayes dan SVM.  Proses ini dilakuk an setelah data yang 
digunakan melalui proses pembobotan . 
E. Validasi  
Data yang sudah selesai diklasifikasikan divalidasi dengan  
menggunakan  k-fold Cross Validation . K-fold Cross Validation   
Gbr. 1 Tahapan penelitian.  
merupakan metode  untuk memisahkan data secara acak ke 
dalam K atau â€œ foldâ€, serta menghilangkan noise  atau bias pada kata sehingga dapat diperoleh tingkat akurasi  yang tinggi . K-fold berfungsi untuk mengacak data ke  dalam beberapa bagian, tetapi mekanisme ini biasanya menyebabkan rata -rata akurasi  yang didap atkan menjadi tidak konstan [4], [7], [14].  

IV. HASIL  DAN PEMBAHASAN  
Dalam makalah ini, proses analisis dilakukan menggunakan 
tools  RapidMiner . Data latih dari setiap kata kunci yang 
digunakan dibagi secara manual sesuai dengan kelasnya , yaitu positif atau negatif , seperti yang ditunjuk kan pada Tabel I. Selanjutnya , proses yang dilakukan adalah pre-processing . Tabel II merupakan contoh proses dalam pre-processing . Diambil dua tweet  yang dianggap dapat mewakili proses dalam pre-processing . Total data latih yang digunakan yaitu 253 tweet . Setelah melalui pre-processing, data latih akan ditentukan sebagai kelas positif atau negatif berdasarkan perhitungan SVM dan Naive Bayes . Jika hasil confidence  positif lebih besar daripada  confidence  negatif, maka hasil  prediction  dari kalimat tersebut positif . Sebaliknya , jika confidence  negatif lebih besar 
daripada  confidence  positif, maka hasil prediction  menjadi negatif. Pada Tabel III  ditampilkan contoh hasil prediksi label  data latih. Nantinya , data latih akan menjadi bahan pembelajaran untuk proses klasifikasi dengan menggunakan data uji. 
A. Analisis Data Menggunakan Naive Bayes  
Data latih yang sudah melewati pre-processing  akan menjadi 
bahan pembelajaran untuk proses klasifikasi data uji 
menggunakan algoritme  Naive B ayes. Pengujian dengan Naive 
Bayes menggunakan  nilai 10 k-fold, dengan total dari data yang digunakan akan dibagi menjadi sepuluh bagian secara acak dan  akan  diulang-ulang  sebanyak jumlah kelompok yang sudah ditentukan . Hasil dari pengujia n data  latih menggunakan Naive Bayes diperlihatkan pada  Tabel IV. 
Berdasarkan hasil pengujian pada Tabel I V, dapat dilihat 
bahwa  analisis menggunakan metode NaÃ¯ve Bayes  pada kata 
kunci â€œVaksin Sinovacâ€ mendapatkan tingkat akurasi  sebesar 78,68%, presisi  68,17%, dan recall  70,83%, sedangkan pada kata kunci  â€œVaksin Merahputihâ€ , diperoleh tingkat  akurasi  sebesar 92,50%, presisi  61,66%, dan recall  65,00%. Untuk nilai rata-rata tingkat akurasi  dengan metode NaÃ¯ve Bayes , diperoleh persentase sebesar 85,59%.  
TABEL I SENTIMEN DATA LATIH  
Kata Kunci Positif  Negatif  Jumlah  â€œVaksin  Sinovacâ€  171 (68%)  82 (32%)  253 (100%)  â€œVaksin merahputihâ€  227 (90%)  26 (10%)  253 (100%)  
TABEL II CONTOH HASIL PRE-PROCESSING  
Tahapan Pre-processing  Hasil  
Kalimat asli  T1: Kami sangat mendukung langkah pak Erick 
lakukan membuat vaksin buatan Merah putih agar tidak ketergantungan impor. Semoga ditahun 2022 vaksin terealisasi dengan baik dan cepat VaksinMerahPutih  
T2: H+1 pasca VaksinSinovac , badan pegel2 kek abis workout. Lengan nyeri bgt di sekitaran bekas suntikan, ternyata ijo  
Cases folding  T1: kami sangat mendukung langkah pak erick 
lakukan membuat vaksin buatan merah putih agar tidak ketergantungan impor. semoga ditahun 2022 vaksin terealisasi dengan baik dan cepat vaksinmerahputih  
T2: h+1 pasca vaksinsinovac, badan pegel2 kek abis workout. lengan nyeri bgt di sekitaran bekas suntikan, ternyata ijo  
Tokenizing  T1: kami sngt mendukung langkah pak erick lakukan membuat vaksin buatan merah putih agar tidak ketergantungan impor semoga ditahun vaksin terealisasi dengan baik dan cepat vaksinmerahpu tih 
T2: h pasca vaksinsinovac badan pegel kek abis workout lengan nyeri bgt di sekitaran bekas suntikan ternyata ijo  
Filter token ( by length)  T1: kami sngt mendukung langkah erick lakukan membuat vaksin buatan merah putih agar tidak 
ketergantungan impor semoga ditahun vaksin terealisasi dengan baik cepat vaksinmerahputih  
T2: pasca vaksinsinovac badan pegel abis workout lengan nyeri sekitaran bekas suntikan ternyata  
Stopword 
removal  T1: sngt mendukung langkah erick lakukan vaksin buatan merah putih ketergantungan impor semoga ditahun vaksin terealisasi cepat vaksinmerahputih  
T2: pasca vaksinsinovac badan pegel abis workout lengan nyeri sekitaran bekas suntikan  
Stemming  T1: sngt mendukung langkah erick lakukan vaksin buatan merah putih ketergantungan impor semoga ditahun vaksin terealisasi cepat vaksinmerahputih  
T2: pasca vaksinsinovac badan pegel abis workout lengan nyeri sekitaran bekas suntikan  
TABEL III 
CONTOH HASIL PREDICTION DATA LATIH  
Row Sentimen  Prediction 
(Sentimen)  Confidence  
(Positif)  Confidence  
(Negatif)  
1 Negatif  Negatif  0,428  0,572  
2 Negatif  Positif  0,608  0,392  
3 Positif  Positif  0,702  0,298  
4 Positif  Positif  0,748  0,252  
5 Negatif  Positif  0,696  0,304  
TABEL IV 
PERSENTASE HASIL PENGUJIAN MENGGUNAKAN NAÃVE BAYES 
Kata Kunci  Akurasi  Presisi  Recall  
Vaksin Sinovac  78,68%  68,17%  70,83%  
Vaksin Merahputih  92,50%  61,66%  65,00%  
Rata-rata 85,59%  64,92%  67,92%  
 
B. Analisis Data Menggunakan SVM â€¦ 
Pengujian dengan SVM menggunakan data  latih dan proses 
pengujian yang sama dengan yang digunakan pada metode 
Naive Bayes. Sebelumnya , data yang akan diproses  diubah dari polinomial  ke binomial  agar dapat dianalisis dengan  metode  SVM.  Hasil pengujian menggunakan SVM  ditunjukkan pada Tabel V.  Berdasarkan hasil pengujian pada Tabel V, dapat dilihat bahwa hasil analisis dengan menggunakan metode SVM pada kata kunci â€œVaksin Sinovacâ€ mendapatkan tingkat akurasi  sebesar  77,05%, presisi  99,05%, dan recall  32,56%. Pada kata kunci â€œVaksin Merahputihâ€ tingkat akurasi  yang didapatkan sebesar 91,77%, presisi  97,14%, dan recall  28,93%. Untuk nilai rata-rata tingkat akurasi  dengan menggunakan metode  SVM , diperoleh persentase sebesar 8 4,41%.  
C. Anal isis Sentimen  Menggunakan Naive Bayes dan SVM  
Hasil analisis sentimen  dengan menggunakan NaÃ¯ve Bayes 
pada kata kunci â€œVaksin Sinovacâ€ dan â€œVaksin Merahputihâ€ ditunjukkan pada  Gbr. 2 dan Gbr. 3. Gambar tersebut merupakan hasil sentimen yang dilakukan terhadap 592  tweet  data uji dengan menggunakan metode Naive Bayes. Sentimen positif menjadi sentimen yang paling mendominasi pada kedua kata kunci , dengan persentase 66% pada â€œvaksinsinovacâ€ dan 89% pada â€œvaksinmerahputihâ€ , sedangkan untuk sentimen negatif , dihasilkan persentase sebesar 34% pada kata kunci â€œvaksinsinovac â€ dan 11% â€œvaksinmerahputihâ€. Selanjutnya, hasil analisis  sentimen  menggunakan  metode SVM diperlihatkan pada Gbr. 4 dan Gbr. 5. Total data yang digunakan sama dengan yang dipakai pada metode Naive Bayes, yaitu 592 tweet . Pada metode SVM , sentimen positif yang dihasilkan lebih banyak dari pada  metode Naive Bayes. Persentase sentimen positif pada kata kunci â€œvaksinsinovacâ€ adalah sebesar 96% dan sentimen negatif sebesar 4%. Nilai persentase sentimen positif yang didapatkan pada kata kunci â€œvaksinmerahputihâ€ yaitu sebesar 98% dan sentiment negatif sebesar 2%.
  
V. KESIMPULAN â€¦ 
Hasil penelitian  yang  telah dilakukan dapat menunjuk kan 
sentimen masyarakat terhadap tindakan  vaksinasi yang dibuat 
oleh pemerintah  Indonesia  untuk menekan tingkat penyebaran 
COVID-19. Hasil analisis  sentimen dengan metode Naive Bayes  menggunakan kata kunci â€œvaksinsinovacâ€ mendapatkan nilai sentimen positif sebesar 66% dan negatif 34% , sedangkan 
TABEL V PERSENTASE HASIL PENGUJIAN MENGGUNAKAN SVM 
Kata Kunci  Akurasi  Presisi  Recall  
Vaksin Sinovac  77,05%  99,05%  32,56%  
Vaksin Merahputih  91,77%  97,14%  28,93%  
Rata-rata 84,41%  98,10%  30,75%  
Gbr. 2 Hasil analisis  sentimen  menggunakan NaÃ¯ve Bayes pada kata kunci â€œVaksin Sinovacâ€ .  
Gbr. 3 Hasil analisis  sentimen  menggunakan Naive Bayes pada kata kunci â€œVaksin Merahputihâ€ . 
Positif
66%Negatif
34%VAKSIN SINOVAC
Positif
Negatif
Positif
89%Negatif
11%VAKSIN MERAHPUTIH
Positif
Negatif 
Gbr. 4 Hasil analisis  sentimen  menggunakan  SVM  pada kata kunci â€œVaksin Sinovacâ€ .  
Gbr. 5 Hasil analisis  sentimen  menggunakan  SVM  pada kata kunci â€œVaksin 
Merahputihâ€ . 
Positif
96%Negatif
4%VAKSIN SINOVAC
Positif
Negatif
Positif
98%Negatif
2%VAKSIN MERAHPUTIH
Positif
Negatif
kata kunci â€œvaksin merahputih â€ menghasilkan sentimen positif 89% dan negatif 11% . Hasil sentimen pada metode SVM 
menggunakan kata kunci  â€œvaksinsinovacâ€ mendapatkan 
persentase positif sebesar 96% dan negatif 4% , sedangkan 
persentase sentimen positif pada kata kunci â€œvaksinmerahputihâ€ sebesar 98% dan negatif 2%.  Dari hasil ini dapat disimpulkan bahwa  sentimen positif menjadi sentimen yang paling mendominasi pada kedua metode yang digunakan, dengan  kata kunci â€œvaksinmerahputihâ€ yang paling banyak mendapat kan sentimen positif. Oleh karena itu, dapat dinilai bahwa tindakan vaksinasi yang dibuat mendapat respons positif dari masyarakat. Faktor-faktor yang memengaruhi sentimen positif pada masyarakat adalah kesadaran masyarakat akan dampak yang disebabkan oleh pandemi COVID-19 sehingga tindakan vaksinasi dinilai sangat membantu dalam menekan tingkat penyebaran COVID-19, sedangkan sentimen negatif dihasilkan dari banyaknya berita hoaks yang beredar di masyarakat tentang vaksinasi, terlebih untuk vaksin Sinovac  yang merupakan produksi China sehingga membuat masyarakat banyak berpendapat negatif.  Penelitian ini juga  menunjuk kan bahwa hasil klasifikasi dengan menggunakan metode Naive Bayes  mempunyai rata-rata tingkat akurasi  lebih besar dengan persentase sebesar 85,59%, sedangkan metode SVM 84,41%. Dari hasil tersebut dapat diasumsikan bahwa metode klasifikasi dengan menggunakan NaÃ¯ve Bayes  adalah yang terbaik pada kasus ini.â€¦ Pengembangan selanjutnya  dari penelitian  ini yaitu perlunya dilakukan pre-processing yang lebih baik lagi sehingga data yang dian alisis menjadi lebih baik  dan akan menamba h tingkat akurasi . Selain itu, perlu dit ambahkan sumber data dari media sosial yang lain, misalnya Facebook, sehingga data yang didapatkan lebih beragam . Perlu juga dilakukan peng ujian dengan algoritme  yang lain sehin gga dapat di cari algoritme yang tepat untuk menganalis is kasus ini. 

REFERENSI  
[1] A.F. Watratan, A.  Puspita B., dan D. Moeis, â€œImplementasi Algoritma Naive Bayes untuk Memprediksi Tingkat Penyebaran Covid -19 di Indonesia,â€ Journal of Applied Computer Science and Technology , Vol. 1, No. 1, hal. 7â€“14, 2020.  [2] A. Susilo, C.M. Rumende, C.W. Pitoyo, W.D. Santoso, M. Yulianti, dkk.,  
â€œCoronavirus Disease 2019: Tinjauan Literatur Terkini,â€ Jurnal Penyakit Dalam Indonesia , Vol. 7, No. 1, hal. 45-67, 2020.  
[3] V.N. Setiaw an (2020)  â€œRiset Medsos: Publik Lihat Negatif Kebijakan Pemerintah Atasi Corona ,â€ [Online], https://katadata.co.id/agungjatmiko/berita/5ea5c764827c4/riset -medsos -publik -lihat-negatif -kebijakan -peemerintah -atasi-corona, tanggal akses : 30-Sep-2020.  
[4] V.K.S. Que, A. Iriani, dan H.D. Purnomo, â€œAnalisis Sentimen Transportasi Online Menggunakan Support Vector Machine Berbasis Particle Swarm Optimization,â€ Jurnal Nasional Teknik Elektro dan Teknologi Informasi , Vol. 9, No. 2, hal. 162 â€“170, 2020.  
[5] S. Hikmawa n, A. Pardamean, dan S.N. Khasanah, â€œSentimen Analisis Publik terhadap Joko Widodo terhadap Wabah Covid -19 Menggunakan Metode Machine Learning,â€ Jurnal Kajian Ilmiah , Vol. 20, No. 2, hal. 167â€“176, 2020.  
[6] N.D. Susanti, E. Sediyono, dan I. Sembiring, â€œUji  Perbandingan Akurasi Analisis Sentimen Pariwisata Menggunakan Algoritma Support Vektor Machine dan Naive Bayes,â€ Nusantara of Engineering , Vol. 3, No. 2, hal. 26â€“33, 2016.  
[7] H. Tuhuteru dan A. Iriani, â€œAnalisis Sentimen Perusahaan Listrik Negara 
Cabang Ambon Menggunakan Metode Support Vector Machine dan 
Naive Bayes Classifier,â€ Jurnal Informatika: Jurnal Pengembangan IT , Vol. 3, No. 3, hal. 394 â€“401, 2018.  
[8] A. Dâ€™Andrea, F. Ferri, P. Grifon i, dan T. Guzzo, â€œApproaches, Tools and Applications for Sentiment Analysis Implementation,â€ International Journal of Computer Applications , Vol. 125, No. 3, hal. 26â€“33, 2015.  
[9] R. Moraes, J.F. Valiati, dan W.P.G . Neto, â€œDocument -level Sentiment Classifi cation : An Empirical Comparison Between SVM and ANN,â€ Expert Systems with Applications , Vol. 40, No. 2, hal. 621 â€“633, 2013.  
[10] N. Yunita, â€œAnalisis Sentimen Berita Artis dengan Menggunakan Algoritma Support Vector Machine dan Particle Swarm Optimization, â€ Jurnal Sistem Informasi STMIK Antar Bangsa , Vol. 5, No. 2, hal. 104 â€“112, 2016.  
[11] J.S. Chou, M.Y. Cheng, Y.W. Wu, dan A.D. Pham, â€œOptimizing Parameters of Support Vector Machine Using Fast Messy Genetic Algorithm for Dispute Classification ,â€ Expert Sys tems with Applications, Vol. 41, No. 8, hal. 3955 â€“3964, 2014.  
[12] A.S.H. Basari, B. Hussin, I.G.P. Ananta, dan J. Zeniarja, â€œOpinion Mining of Movie Review Using Hybrid Method of Support Vector 
Machine and Particle Swarm Optimization ,â€ Procedia Engineering , Vol. 53, hal. 453 â€“462, 2013.  
[13] H. Irsyad, A. Farisi, dan M.R. Pribadi, â€œKlasifikasi Opini Masyarakat terhadap Jasa ISP MyRepublic dengan NaÃ¯ve Bayes,â€ Jurnal Nasional Teknik Elektro dan Teknologi Informasi (JNTETI) , Vol. 8, No. 1, hal. 30-34, 2019.  
[14] E. Indrayuni, â€œAnalisa Sentimen Review Hotel Menggunakan Algoritma Support Vector Machine Berbasis Particle Swarm Optimization,â€ Jurnal Evolusi , Vol. 4, No. 2, hal. 20â€“27, 2016.  
",Analisis Sentimen,"SVM, Support Vector Machine, Naive Bayes",data tweet,"akurasi, presisi, recall"
Analisis Sentimen Masyarakat Terhadap Penggunaan E-Commerce Menggunakan Algoritma K- Nearest Neighbor  ,"Analisis Sentimen Masyarakat Terhadap Penggunaan E-Commerce Menggunakan Algoritma K-Nearest Neighbor  

Ikhsan Habib Kusuma1*), Nuri Cahyono2 

Abstract
E-commerce's rapid growth has resulted in an increase in online transactions and shifts in consumer behavior. In Indonesia, the use of e-commerce has grown rapidly, with 
many online platforms emerging. Understanding public sentiment towards e-commerce in Indonesia is crucial for 
businesses to improve their services and maintain customer 
satisfaction. In this review, study  propose a methodology for feeling investigation of popular assessment on the utilization of web-based business in Indonesia, utilizing directed learning calculations.  The study involved collecting data from  the website Google Play Store . The stud y performed data preprocessing, including removing stop words, tokenization, and stemming, before applying the K -Nearest Neighbor (K-NN) algorithm to classify sentiments into positive  or negative. The evaluation was conducted using confusion matrix and classification report. The results showed that the proposed approach was effective in analyzing public sentiment towards e -commerce in Indonesia, 
with an accuracy rate of 82%. The study conclu ded that the 
proposed strategy c ould help businesses enhance their services and better satisfy customers' requirements and expectations.  
 
Keywords Sentiment Analysis, E-Commerce, Supervised 
Learning, Machine Learning, NLP, KNN.  
 
Abstrak
Perkembangan e-commerce yang pesat telah menyebabkan peningkatan transaksi online dan perubahan perilaku konsumen. Di Indonesia, penggunaan e-commerce tumbuh pesat dengan banyak platform online bermunculan. Memahami sentimen masyarakat terhadap e-commerce di Indonesia sangat penting bagi bisnis untuk meningkatkan layanan dan menjaga kepuasan pelanggan. Oleh karena itu, dalam penelitian ini peneliti  mengusulkan sebuah pendekatan untuk melakukan analisis sentimen opini publik mengenai penggunaan salah satu e-commerce di Indonesia dengan menggunakan algoritma K-Nearest Neighbor. Pengumpulan data dilakukan dari  website Google Play Store  dengan tujuan untuk memperoleh  pandangan dan pengalaman masyarakat terkait penggunaan salah satu e-commerce di Indonesia . Setelah data terkumpul, dilakukan proses preprocessing untuk membersihkan data, termasuk menghilangkan stopwords , tokenisasi, dan stemming . Setelah itu, algoritma K-Nearest Neighbor (K-NN) digunakan untuk mengklasifikasikan sentimen menjadi positif  atau  negatif. Evaluasi dilakukan dengan menggunakan confusion matrix  dan classification report  untuk menilai keakuratan algoritma.  Hasil penelitian menunjukan bahwa pendekatan yang diusulkan efektif dalam menganalisis sentimen masyarakat terhadap e-commerce di Indonesia, dengan tingkat akurasi 82%. Penelitian ini memiliki implikasi penting bagi bisnis e-commerce di Indonesia dalam meningkatkan layanan dan memenuhi kebutuhan serta harapan pelanggan secara lebih baik.  
 
Kata Kunci Sentimen Analisis, E -Commerce, Supervised 
Learning, Machine Learning, NLP, KNN. 
 
I. PENDAHULUAN 
Di Indonesia, penggunaan e-commerce berkembang pesat seiring dengan pergeseran perilaku konsumen, dengan semakin banyaknya orang yang melakukan pembelian secara online. Menurut laporan terbaru We Are Social, sekitar 178,9 juta orang Indonesia telah terlibat dalam belanja online dari awal tahun 2022 hingga akhir tahun 2023, menunjukkan 
pertumbuhan sebesar 12,8% dari tahun ke tahun. Hal ini juga 
didukung oleh perkiraan belanja online penduduk Indonesia yang mencapai US$55,97 juta atau sekitar Rp 851 triliun pada 
tahun yang sama.  Namun, mempertahankan basis pengguna dan 
meningkatkan kualitas layanan platform e-commerce bergantung pada kepuasan pelanggan.  Contoh-contoh platform e-commerce yang dapat dijadikan rujukan meliputi Shopee, Tokopedia, Lazada, Bukalapak, dan Blibli. Alasan pemilihan Shopee sebagai objek penelitian dalam konteks analisis sentimen masyarakat adalah karena popularitasnya yang mendominasi pasar e-commerce di Indonesia. Oleh karena itu, untuk memahami tingkat kepuasan dan kepercayaan pengguna 
terhadap platform ini, perlu dilakukan analisis sentimen publik terkait penggunaannya.  Dalam penelitian ini, peneliti mengusulkan pendekatan untuk melakukan analisis sentimen terhadap opini publik terhadap penggunaan Shopee dengan menggunakan algoritma K-Nearest Neighbor . Peneliti  mengumpulkan data dari website google playstore dengan Teknik web scraping  untuk  kemudian dilakukan preprocessing data seperti penghapusan stopwords, tokenization , dan stemming  sebelum menerapkan algoritma K-Nearest Neighbor  (K-NN) dan Natural Language Processing (NLP) untuk mengklasifikasikan sentimen menjadi posit if atau negatif. Evaluasi dilakukan dengan menggunakan confusion matrix  dan classification report[1]. 

II. PENELITIAN  YANG  TERKAIT 
Beberapa penelitian yang terkait memiliki kaitan dengan 
penelitian ini yang pertama  adalah Jurnal """" Analisis Sentimen pada Ulasan Pembelian Produk di Marketplace Shopee 
Menggunakan Pendekatan Natural Language Processing """" 
yang ditulis oleh Muktafin E, Kusrini K, dan Luthfi E 
menyediakan pandangan berharga dalam bidang analisis 
sentimen produk di lingkungan e -commerce. Penelitian ini 
bertujuan untuk mengotomatiskan klasifikasi sentimen 
terhadap ulasan produk, memungkinkan penjual dan pengguna 
untuk memahami pendapat pe mbeli mengenai produk yang 
ditawarkan.  Hasil penelitian menunjukkan bahwa penerapan 
algoritma K-Nearest Neighbor  (KNN) dan Natural Language 
Processing  (NLP) menghasilkan tingkat akurasi yang 
memuaskan, mencapai 76,92%. Ini meningkatkan presisi dan recall, masing -masing sekitar 80,00% dan 74,07%, dalam 
perbandingan dengan analisis tanpa NLP. Hasil ini 
menegaskan peran krusial NLP dalam meningkatkan kuali tas 
analisis sentimen. Dalam pengembangan penelitian ini, sebaiknya variasi produk yang dianalisis diperluas, yang dapat memberikan wawasan lebih luas tentang perilaku konsumen di platform Shopee. Terlebih lagi, jurnal ini memberikan sumbangan berharga untuk penelitian terkait, khususnya bagi mereka yang memerlukan informasi tentang bagaimana NLP dapat memengaruhi analisis sentimen ulasan produk e-commerce. Hal ini memungkinkan pemahaman yang lebih baik tentang cara pelanggan berinteraksi dalam e- commerce, yang dapat membantu dalam pengambilan keputusan bisnis online [1]. Selanjutnya , penelitian oleh Meishita Inelza Putri dan Iqbal Kharisudin (2022) tentang """" Analisis Sentimen Pengguna Aplikasi Marketplace Tokopedia Pada Situs Google Play Menggunakan Support Vector Machine (SVM), Naive Bayes, dan Logistic Regression """". Hasilnya , data yang digunakan penulis berasal dari review aplikasi Tokopedia di Google Play, dengan total 3.125 review. Tujuan dari penelitian ini adalah menganalisis umpan balik pengguna menggunakan aplikasi Tokopedia dan menggabungkan hasil dari tiga metode klasifikasi yang berbeda.  Berdasarkan hasil penelitian, penggunaan metode SVM dalam klasifikasi sentimen pengguna pada aplikasi Tokopedia menunjukkan performa terbaik, dengan tingkat akurasi mencapai 90%.  Selain itu, penulis menemukan bahwa 69% pengguna memiliki kesan positif terhadap aplikasi Tokopedia.  Meskipun demikian, penelitian Meishita Inelza Putri dan Iqbal Kharisudin (2022) tidak membahas secara khusus tentang analisis sentimen masyarakat terhadap penggunaan e-commerce secara umum [2].  Dalam penelitian sebelumnya yang dilakukan oleh Utami E (2023), berjudul """" Optimizing Sentiment Analysis of Product 
Reviews on Marketplace Using a Combination of Preprocessing Techniques, Word2Vec, and Convolutional Neural Network ."""" adalah pada analisis review produk di platform marketplace. Penelitian ini menggunakan teknik Word2Vec,  Convolutional Neural Network  (CNN), dan preprocessing untuk menganalisis 20.986 review produk dari 720 produk di marketplace Shopee.  
Tingkat akurasi tertinggi sebesar 99,00%, persentase presisi tertinggi sebesar 98,96%, dan tingkat recall tertinggi sebesar 98,96%.  Hal ini menggambarkan keberhasilan dalam menerapkan teknologi NLP dan pengolahan data dalam analisis sentimen pada ulasan e-commerce . Oleh karena itu, penelitian yang terkait dengan judul jurnal """" Analisis Sentimen Masyarakat terhadap penggunaan E-Commerce Menggunakan Algoritma K -Nearest Neighbor """" perlu dilakukan untuk lebih memperdalam pemahaman tentang sentimen masyarakat terh adap penggunaan e -commerce di Indonesia [3]. 

III. METODE PENELITIAN  
A. Web Scraping 
Pada alur penelitian ini, dilakukan web scraping 
menggunakan WebHarvy pada platform Google Play Store dari google khususnya untuk aplikasi Shopee. Alur dimulai dengan memasukkan link ke halaman Shopee di Google Play Store yang ingin diambil data ulasan dan ratingnya.  
Gbr. 1 Proses memulai web scraping dengan menyalin link ke WebHarvy . 
Setelah memasukkan link, WebHarvy akan melakukan scraping secara otomatis untuk mengumpulkan ulasan pengguna dan rating yang terdapat pada halaman tersebut.  
Gbr. 2 Proses peng umpulan  dataset dengan Teknik web scraping.  
Data ulasan dan rating ini kemudian disimpan dalam format Excel untuk memudahkan pengolahan dan analisis selanjutnya [3]. 
Gbr. 3 Proses menyimpa n dan preprocessing dataset  hasil scra ping . 
Setelah  proses  scraping selesai, dilakukan tahap 
preprocessing data di Excel. Pada tahap ini, data ulasan dan  
rating akan diproses untuk mendapatkan sentimen positif dan 
negatif berdasarkan rating yang diberikan oleh pengguna. 
Misalnya, rating 4 atau 5 akan dianggap sebagai sentimen 
positif, sedangkan rating 1 atau 2 akan dianggap sebagai sentimen negatif. Dalam tahap preprocessing ini, dilakukan 
pengelompokan rating menjadi dua kategori sentimen, yaitu 
positif dan negatif. Kemudian, data ulasan dan rating akan 
dibersihkan dari karakter -karakter yang tidak relevan dan 
dilakukan pembersihan data lainnya. Hal ini bertujuan untuk 
memastikan data yang digunakan dalam analisis sentimen sudah siap dan terstruktur dengan baik[4].  Setelah memberikan sentimen positif dan negatif berdasarkan rating di Excel pada dataset hasil web scraping dari Google Play Store Shopee, langkah selanjutnya adalah mengatasi ketidakseimbangan kelas. Undersampling digunakan untuk mengurangi jumlah sampel pada kelas mayoritas agar seimbang dengan jumlah sampel pada kelas minoritas [5]. 
B. Dataset  
Penelitian ini menggunakan teknik web scraping untuk 
mengambil dataset dari website Google Playstore menggunakan software Webharvy khususnya aplikasi Shopee.  Setelah dataset berhasil diambil, peneliti menggunakan library Pandas pada bahasa pemrograman Python untuk melakukan 
proses pembacaan dan penampilan dataset dalam bentuk tabel. 
Proses ini dilakukan untuk mendapatkan data yang dibutuhkan dan dapat digunakan  dalam analisis sentimen masyarakat 
terhadap penggunaan e -commerce dengan menggunakan algoritma K-Nearest Neighbor [6]. Selanjutnya, dataset tersebut dilakukan  proses undersampling untuk menjaga keseimbangan antara kategori positif dan negatif. Setelah dilakukan undersampling, dataset final terdiri dari 895 data, dengan 469 data yang diklasifikasikan sebagai sentimen positif dan 426 data yang diklasifikasikan se bagai sentimen negatif. Hal ini penting untuk memastikan keberimbangan dalam jumlah data pada setiap kategori sentimen, sehingga analisis dan evaluasi yang dilakukan dapat lebih objektif dan akurat.  
C. Preprocessing Dataset  
Dalam alur text processing untuk membersihkan data, terdapat beberapa tahapan yang dilakukan. Tahap pertama adalah lowercase folding , di mana seluruh teks akan diubah menjadi huruf kecil agar tidak ada perbedaan dalam memproses kata yang sama dengan huruf besar dan huruf kecil.  
Gbr. 4 Tahap pra -pemrosesan NLP dengan cleaning simbol dataset.  
Tahap berikutnya adalah menghilangkan tanda baca dan angka dari teks. Hal ini dikarenakan  sering kali tidak memberikan kontribusi signifikan dalam analisis teks dan dapat mengganggu proses tokenisasi dan normalisasi kata. Dengan menghapus tanda baca dan angka, teks menjadi lebih bersih dan fokus pada kata -kata penting.  Setelah tahap penghapusan tanda baca dan angka dalam alur text processing, terdapat tahap penanganan tag dalam teks. Tag dalam teks dapat berupa tag HTML, XML, atau tag khusus lainnya yang terdapat dalam data yang diambil. Penanganan tag penting untuk meng hilangkan elemen-elemen yang tidak diperlukan dan memastikan hanya teks yang relevan yang diproses [7]. Setelah itu, dilakukan tahap word tokenization, di mana teks akan dipisahkan menjadi token- token kata. Ini memungkinkan pemrosesan kata per kata untuk analisis selanjutnya. Berikut nya, dilakukan tahap word normalization untuk memperoleh bentuk dasar dari kata -kata tersebut. Misalnya, kata """"berlari"""" akan dinormalisasi menjadi """"lari"""" agar dapat dianggap sebagai bentuk yang sama.  
Gbr. 5 Tahap pra -pemrosesan NLP dengan cleaning word dataset.  
Selanjutnya, dilakukan tahap penghapusan stopwords , yaitu kata -kata umum yang sering muncul dalam teks namun tidak memberikan makna yang signifikan. Stopwords  seperti dan"""", """"di"""", atau """"untuk"""" akan dihapus agar fokus pada kata -
kata kunci yang lebih informatif.  Terakhir, dilakukan stemming  untuk mengubah kata-kata menjadi bentuk dasar atau kata akar. Kata-kata yang memiliki akar yang sama, seperti """"membaca"""" dan """"membacakan"""", dapat diubah menjadi """"baca"""" melalui stemming . Dengan mengikuti alur text processing yang mencakup lowercase folding , penghapusan tanda baca dan angka, word tokenization , word normalization, penghapusan stopwords , dan stemming , data teks menjadi lebih terstruktur dan siap untuk dilakukan analisis lebih lanjut seperti analisis sentimen.  Proses ini memastikan bahwa data penelitian telah melalui prosedur pembersihan yang sesuai untuk menghasilkan data yang lebih relevan dan akurat [8]. Pada tahap feature extraction  dilakukan ekstraksi fitur (feature) dari data yang telah diproses pada tahap sebelumnya. Beberapa fitur yang dapat diekstraksi meliputi kata -kata ( term frequency), bobot kata TF-IDF (term weighting ), dan kategori kata ( part of speech tagging ). Pada tahap pelatihan model, model machine learning dilatih menggunakan data training.  Pada tahap evaluasi, model yang telah dilatih dinilai menggunakan metrik seperti akurasi, presisi, recall, F1-score, dan confusion matrix. Evaluasi ini membantu dalam mengukur kinerja dan efektivitas model yang telah dilatih.  Terakhir pada tahap deployment, m odel yang telah terlatih dapat 
diintegrasikan ke dalam aplikasi atau sistem yang digunakan untuk memantau sentimen pelanggan terhadap produk atau layanan [9]. 
D. Algoritma  
NLP ( Natural Language Processing ) adalah cabang kecerdasan buatan yang berfokus pada pemahaman, pengolahan, dan generasi bahasa manusia oleh komputer.  Pada tahap ini, teks diubah menjadi lowercase , tanda baca dan angka dihilangkan, dan kata- kata dipisahkan menjadi token. Hal ini mempersiapkan data teks agar dapat diolah lebih lanjut [10]. 
Teknik TF-IDF ( Term Frequency -Inverse Document Frequency ) memperkirakan seberapa penting sebuah kata dalam dokumen  atau koleksi dokumen. Rumus kalkulasi TF-IDF menggabungkan frekuensi kata dalam dokumen dengan inversi frekuensi kata dalam keseluruhan dokumen, sehingga memberikan bobot yang lebih tinggi pada kata-kata yang jarang muncul tapi memiliki makna penting [11]. 
 ð‘Šð‘Šð‘–ð‘–,ð‘—ð‘—=ð‘¡ð‘¡ð‘¡ð‘¡ð‘–ð‘–,ð‘—ð‘—Ã—log(ð‘ð‘
ð‘‘ð‘‘ð‘‘ð‘‘ð‘–ð‘–)    (1) 
Keterangan: 
ð‘¡ð‘¡ð‘¡ð‘¡ð‘–ð‘–,ð‘—ð‘— = banyaknya kata-i pada dokumen ke -j 
ð‘ð‘ = total dokumen 
ð‘‘ð‘‘ð‘¡ð‘¡ð‘–ð‘– = banyaknya dokumen yang mengandung kata ke-i 
Selanjutnya, terdapat metode Cosine Similarity  yang 
digunakan untuk mengukur sejauh mana dua teks mirip satu sama lain. Metode ini menghitung kemiripan antara dua vektor representasi teks dengan menggunakan rumus kalkulasi cosine 
similarity . Semakin tinggi nilai cosine similarity , semakin mirip kedua teks tersebut.  K-Nearest Neighbors  (KNN) digunakan sebagai algoritma supervised learning  untuk melakukan klasifikasi sentimen positif dan negatif dari komentar masyarakat terhadap penggunaan e-commerce. KNN adalah algoritma klasifikasi yang sederhana namun efektif, yang berdasarkan pada konsep bahwa data dengan atribut yang mirip cenderung memiliki label kelas yang sama [12]. Proses KNN dimulai dengan memilih sebuah titik atau observasi dari data training yang telah dilabeli. Kemudian, KNN mencari K tetangga terdekat dari titik yang dipilih, di mana K adalah nilai yang ditentukan sebelumnya oleh pengguna. Setelah itu, algoritma KNN akan menghitung jarak antara titik yang dipilih dengan K tetangga terdekat menggunakan metrik jarak tertentu seperti Euclidean distance  atau Manhattan distance . Akhirnya, label kelas yang paling sering muncul dari K tetangga terdekat akan diambil sebagai label kelas untuk titik yang dipilih.  Setelah dilakukan preprocessing data, KNN dilatih dengan data training untuk menentukan nilai K dan membangun model klasifikasi. Setelah model dibangun, data testing digunakan untuk menguji akurasi model. Setelah itu, model dapat digunakan untuk mengkategorikan data yang belum dilihat [13] . Untuk mengevaluasi performa model klasifikasi, terdapat 
confusion matrix  yang membandingkan hasil klasifikasi aktual dengan prediksi yang diberikan oleh model. Ada empat nilai penting dalam matrix confusion : Nilai Positif  Benar (TP), Nilai Negatif Benar (TN), Nilai Negatif Benar (FP), dan Nilai Negatif Benar (FN) [14]. 
ð´ð´ð´ð´ð´ð´ð´ð´ð´ð´ð´ð´ð´ð´ð´ð´ =ð‘‡ð‘‡ð‘‡ð‘‡+ð‘‡ð‘‡ð‘ð‘
ð‘‡ð‘‡ð‘‡ð‘‡+ð‘‡ð‘‡
ð‘ð‘+ð¹ð¹
ð‘‡ð‘‡+ð¹ð¹ð‘ð‘Ã—100%   (2) 
ð‘ƒð‘ƒð´ð´ð‘ƒð‘ƒð´ð´ð‘ƒð‘ƒð‘ƒð‘ƒ
ð‘ƒð‘ƒð‘ƒð‘ƒð‘ƒð‘ƒ =ð‘‡ð‘‡ð‘‡ð‘‡
ð¹ð¹
ð‘‡ð‘‡+ð‘‡ð‘‡ð‘‡ð‘‡Ã—100%    (3) 
ð‘…ð‘…
ð‘ƒð‘ƒð´ð´ð´ð´ð‘…ð‘…
ð‘…ð‘…=ð‘‡ð‘‡ð‘‡ð‘‡
ð¹ð¹
ð‘ð‘+ð‘‡ð‘‡ð‘‡ð‘‡Ã—100%    (4) 
E. Evaluasi  
Confusion matrix digunakan untuk mengevaluasi kinerja 
dari algoritma klasifikasi yang digunakan untuk melakukan analisis sentimen.  Matrix confusion  terdiri dari empat bagian: 
Nilai Positif Benar (TP) adalah jumlah prediksi yang benar dan nilai aktualnya juga benar
Nilai Negatif Benar (FN) adalah jumlah prediks i yang salah 
dan nilai aktualnya juga benar
adalah jumlah prediksi yang salah dan nilai aktualn ya juga 
benar [15]. 
TABLE  I  
CONFUSION M ATRIX 
Confusion Matrix  Hasil Klasifikasi  
True Positif  75 
False Negatif  19 
False Positif  12 
True Negatif  73 
Accuracy , Precision , Recall , F1-Score , dan Support  
adalah metrik evaluasi penting dalam tugas klasifikasi. 
Precision  mengukur persentase instance positif yang benar 
diklasifikasikan oleh model, recall  mengukur persentase 
instance positif yang berhasil ditemukan, dan F1-Score  adalah gabungan dari precision dan recall. Support  adalah jumlah kemunculan aktual dari setiap kelas dalam dataset.  Metrik-metrik ini memberikan gambaran tentang performa model dalam mengklasifikasikan data dengan akurat dan seimbang.  
TABLE  II  
METRIK  EVALUASI  
Precision  Recall  F1-Score  Support  
Negatif  0.79 0.86 0.82 85 
Positif  0.86 0.80 0.83 94 
Accuracy    0.83 179 
Macro Avg  0.83 0.83 0.83 179 
Weighted Avg  0.83 0.83 0.83 179 
ð´ð´ð´ð´ð´ð´ð´ð´ð´ð´ð´ð´ð´ð´ð´ð´ :  0.8268156424581006  
 ð‘ƒð‘ƒð´ð´ð‘ƒð‘ƒð´ð´ð‘ƒð‘ƒð‘ƒð‘ƒð‘ƒð‘ƒð‘ƒð‘ƒð‘ƒð‘ƒ :  0.8620689655172413  
 ð‘…ð‘…ð‘ƒð‘ƒð´ð´ð´ð´ð‘…ð‘…ð‘…ð‘… :  0.7978723404255319  
 ð¹ð¹1 ð‘†ð‘†ð´ð´ð‘ƒð‘ƒð´ð´ð‘ƒð‘ƒ :  0.8287292817679558  
 ð¸ð¸ð´ð´ð´ð´ð‘ƒð‘ƒð´ð´ ð‘…ð‘…ð´ð´ð‘¡ð‘¡ð‘ƒð‘ƒ:  0.17318435754189943  
Metode Cross Validation Score  adalah  untuk 
memperkirakan bagaimana model akan generalisasi terhadap 
data yang belum pernah dilihat sebelumnya.  Dalam Cross 
Validation , dataset yang ada akan dibagi menjadi beberapa 
subset yang saling bertumpuk dan bergeser, lalu model akan dilatih pada subset yang lebih besar dan diuji pada subset yang lebih kecil. Pada umumnya, teknik yang digunakan adalah K-Fold Cross Validation , di mana dataset dibagi menjadi k subset yang sama ukurannya.  Dataset harus dibagi menjadi k bagian yang sama ukurannya untuk menerapkan validasi cross- fold K-fold. Setelah itu, model akan dilatih pada bagian k-1 dan diuji pada bagian yang tersisa. Proses ini akan diulang sebanyak k kali, dengan setiap bagian berfungsi sebagai bagian uji tepat sekali. Hasil akhir pengujian cross validation adalah akurasi rata-rata dari setiap iterasi pengujian cross-fold K-Fold . Teknik ini memungkinkan pengujian model dengan lebih akurat, membuatnya lebih dapat diandalkan saat membuat  keputusan.  
 
IV. HASIL DAN  PEMBAHASAN 
A. Deskripsi Data  
Data yang digunakan dalam penelitian ini adalah  dataset 
review pengguna aplikasi Shopee yang diambil dari Google 
Play Store menggunakan teknik web scraping  dengan software 
WebHarvy. Data ini terdiri dari 895 baris  dengan  kolom  
Review  dan Sentimen.  
B. Preprocessing Data 
Proses pembersihan data dilakukan pada tahap preprocessing data dengan mengubah lowercase folding , menghilangkan tanda baca, dan menghilangkan karakter yang tidak diperlukan. Kemudian, interaksi tokenisasi selesai, khususnya memecah kalimat menjadi token atau kata. Selain itu, stopword removal  dan stemming  digunakan untuk  membuat kata- kata dasar yang relevan.  
C. Model Sentiment Analysis  
Model Sentiment Analysis  menggunakan algoritma NLP dan KNN dalam penelitian ini. Proses training dibagi menjadi dua bagian, yaitu training set dan testing set dengan proporsi 80:20. Selanjutnya, dilakukan ekstraksi elemen dengan teknik 
TF-IDF untuk menghitung bobot setiap kata dalam laporan. 
Pada tahap training, algoritma KNN digunakan untuk mengklasifikasikan setiap dokumen ke dalam kelas sentimen positif atau negatif. Dari hasil pen elitian, disimpulkan bahwa model ini dapat melakukan analisis sentimen pada dataset review pengguna aplikasi Shopee dengan akurasi sebesar 82% dan nilai cross validation score  sebesar 80%. Hal ini menandakan bahwa kombinasi algoritma NLP dan KNN dapat menghasilkan hasil analisis sentimen yang baik.  
D. Evaluasi Model  
Untuk mengevaluasi model yang telah dibuat, digunakan 
metode confusion matrix  dan cross validation score . Confusion matrix  digunakan untuk menunjukkan jumlah hasil klasifikasi yang benar dan salah dari model. Sedangkan, cross validation score  digunakan untuk mengukur seberapa baik model yang dibuat dalam memprediksi data yang belum dilihat sebelumnya.  
E. Visualisasi 
Pada peneli tian ini, dilakukan visualisasi data menggunakan wordcloud untuk menganalisis frekuensi  tentang kata-kata yang paling dominan dalam ulasan pengguna, sehingga memudahkan pemahaman mengenai preferensi dan pengalaman pengguna terkait dengan penggunaan e-commerce. Visualisasi wordcloud ini membantu dalam mengidentifikasi kata -kata kunci yang paling signifikan dan memperoleh wawasan yang berguna dalam analisis sentimen pada dataset tersebut.  
Gambar 1. Wordcloud frekuensi kata y ang sering muncul  
 
V. KESIMPULAN 
Dari hasil penelitian, dapat disimpulkan bahwa model Sentiment Analysis  yang dikembangkan menggunakan algoritma NLP dan KNN menunjukkan kinerja yang memuaskan. Akurasi model mencapai 82%, dan nilai dari cross-validation score  sebesar 80%. Evaluasi lainnya juga memberikan hasil yang positif, menandakan bahwa model ini efektif dalam melakukan analisis sentimen pada dataset ulasan pengguna aplikasi Shopee. Hasil ini memberikan keyakinan bahwa kombinasi algoritma NLP dan KNN dapat  diandalkan untuk tugas analisis sentimen pada dataset yang relevan.  Namun, terdapat beberapa faktor yang dapat mempengaruhi akurasi model, seperti kualitas data, pemilihan fitur, dan parameter pada algoritma. Oleh karena itu, untuk meningkatkan akurasi model, penelitian selanjutnya dapat dilakukan dengan meningkatkan aspek- aspek tersebut.  Selain itu, eksplorasi lebih lanjut dapat diselesaikan dengan menggunakan teknik yang lebih rumit, seperti deep learning , untuk meningkatkan akurasi dan performa dari model. Metode ini dapat digunakan untuk melakukan ekstraksi fitur yang lebih kompleks dan dapat memperbaiki hasil analisis sentimen yang dihasilkan.  
 
UCAPAN TERIMA  KASIH 
Penulis ingin menyampaikan rasa terima kasih yang tulus 
kepada semua orang yang membantu, terutama dari universitas 
dan pembimbing.  Kontribusi mereka sangat dihargai dan 
berperan penting dalam kesuksesan penulisan ini.  Semua 
kontribusi ini menjadi pilar penting dalam keberhasilan 
penelitian ini, dan penulis sangat menghargai semua bantuan 
yang diberikan.  
 
DAFTAR  PUSTAKA 
[1] E. H. Muktafin, K. Kusrini, and E. T. Luthfi, â€œAnalisis Sentimen pada Ulasan Pembelian Produk di Marketplace Shopee Menggunakan Pendekatan Natural Language Processing,â€ Jurnal Eksplora Informatika, vol. 10, no. 1, pp. 32â€“ 42, Sep. 2020, doi: 10.30864/eksplora.v10i1.390.
[2] M. I. Putri and I. Kharisudin, â€œPenerapan Synthetic Minority Oversampling Technique (SMOTE) Terhadap Analisis Sentimen Data Review Pengguna Aplikasi Marketplace Tokopedia,â€ PRISMA, Prosiding Seminar Nasional Matematika , vol. 5, pp. 759â€“ 766, 2022, [Online]. Available: https://journal.unnes.ac.id/sju/index.php/prisma/  
[3] E. Utami, â€œOPTIMIZING SENTIMENT ANALYSIS OF PRODUCT REVIEWS ON MARKETPLACE USING A COMBINATION OF PREPROCESSING 
TECHNIQUES, WORD2VEC, AND CONVOLUTIONAL NEURAL NETWORK 
OPTIMISASI ANALISIS SENTIMEN ULASAN PRODUK PADA MARKETPLACE DENGAN KOMBINASI TEKNIK P REPROCESSING, WORD2VEC, DAN CONVOLUTIONAL NEURAL NETWORK,â€ Jurnal Teknik Informatika (JUTIF) , vol. 4, no. 1, pp. 101â€“ 107, 2023, doi: 
10.20884/1.jutif.2023.4.1.815.  
[4] I. M. Wiryana, S. Harmanto, A. Fauzi, I. B. Qisthi, and Z. N. Utami, â€œStore product classification using convolutional neural network,â€ IAES International 
Journal of Artificial Intelligence , vol. 12, no. 3, pp. 1439â€“ 1447, Sep. 2023, doi: 10.11591/ijece.v12i3.pp1439- 1447.  
[5] A. Sri Widagdo, B. W. Soedijono A, and A. Nasiri, â€œAnalisis Tingkat Kepopuleran E -Commerce Di Indonesia Berdasarkan Sentimen Sosial Media Menggunakan Metode NaÃ¯ve Bayes,â€ 2020.  
[6] S. Hardani and D. Ajeng Kristiyanti, â€œSystematic 
Literature Review: Analisa Sentimen Penerimaan Masyarakat Terhadap Jenis Vaksin Covid- 19 di Dunia.â€ [Online]. Available: https://journals.upi -yai.ac.id/index.php/ikraith- informatika/issue/archive  [7] J. Mantik, Y. R. Saputri, and H. Februariyanti, â€œSENTIMENT ANALYSIS ON SHOPEE E -COMMERCE USING THE NAÃVE BAYES 
CLASSIFIER ALGORITHM,â€ 2022.  
[8] B. Z. Ramadhan, I. Riza, and I. Maulana, â€œAnalisis Sentimen Ulasan Pada Aplikasi E -Commerce Dengan Menggunakan Algoritma NaÃ¯ve Bayes,â€ 2022. [Online]. Available: 
http://jurnal.polibatam.ac.id/index.php/JAIC  
[9] M. Demircan, A. Seller, F. Abut, and M. F. Akay, 
â€œDeveloping Turkish sentiment analysis models using 
machine learning and e-commerce data,â€ International Journal of Cognitive Computing in Engineering , vol. 2, pp. 202â€“ 207, Jun. 2021, doi: 10.1016/j.ijcce.2021.11.003.  
[10] N. Khotimah, M. Yamin Darsyah, and I. M. Nur, â€œANALISIS SENTIMEN TERHADAP REVIEW E-COMMERCE DENGAN METODE STOCHASTIC GRADIENT DESCENT.â€ [Online]. Available: http://repository.unimus.ac.id  
[11] F. D. Ananda and Y. Pristyanto, â€œAnalisis Sentimen Pengguna Twitter Terhadap Layanan Internet Provider 
Menggunakan Algoritma Support Vector Machine,â€ MATRIKâ€¯: Jurnal Manajemen, Teknik Informatika dan Rekayasa Komputer , vol. 20, no. 2, pp. 407â€“ 416, May 
021, doi: 10.30812/matrik.v20i2.1130.  
[12] A. Bisri and M. Man, â€œINTERNATIONAL JOURNAL ON INFORMATICS VISUALIZATION journal homepageâ€¯: www.joiv.org/index.php/joiv INTERNATIONAL JOURNAL ON INFORMATICS VISUALIZATION Machine Learning Algorithms 
Based on Sampling Techniques for Raisin Grains Class ification,â€ 2023. [Online]. Available: www.joiv.org/index.php/joiv 
[13] Junadhi, Agustin, M. Rifqi, and M. K. Anam, â€œSentiment Analysis of Online Lectures using K-Nearest Neighbors based on Feature Selection,â€ Jurnal Nasional Pendidikan Teknik Informatika (JANAPATI) , vol. 11, no. 3, pp. 216â€“ 225, Dec. 2022, doi: 10.23887/janapati.v11i3.51531.  
[14] Y. Dani and M. A. Ginting, â€œINTERNATIONAL 
JOURNAL ON INFORMATICS VISUALIZATION journal homepageâ€¯: www.joiv.org/index.php/joiv INTERNATIONAL JOURNAL ON INFORMATICS VISUALIZATION Classification of Predicting Customer Ad Clicks Using Logistic Regression and k-Nearest Neighbors,â€ 2023. [Online]. Available: www.joiv.org/index.php/joiv 
[15] â€œSentiment Analysis of OYO App Reviews Using the Support Vector Machine Algorithm Analisis Sentimen terhadap Ulasan Aplikasi OYO menggunakan Algoritma Support Vector Machine Zaenal, Ika Ratna Indra Astutik.â€  ",Analisis Sentimen,K-Nearest Neighbor,data ulasan dan ratingnya,"akurasi, cross validation score"
Implementasi Naive Bayes Classifier Dan Confusion Matrix  Pada Analisis Sentimen Berbasis Teks Pada Twitter ,"Implementasi Naive Bayes Classifier Dan Confusion Matrix  Pada Analisis Sentimen Berbasis Teks Pada Twitter 

Dwi Normawati1, Surya Allit Prayogi2 

Abstract  
Twitter is one of the social media that is currently in great demand by internet users. The number of tweets circulating on Twitter is not yet known whether these tweets contain  more positive, negative, and neutral opinions. For that we need a system that can process data by applying sentiment analysis. This study uses the Naive Bayes Classifier (NBC) method to analyze the level of sentiment towards data carried out by crawling o n Twitter. The data studied as a simple case study uses only 8 tweet data which is divided into 5 training data and 3 test data. The data is processed using the preprocessing stage, then classified using the NBC method, the calculation of performance uses confusion matrix techniques. This study resulted in a 
structured exposure to the process and results of NBC implementation and performance testing using the confusion matrix which obtained 82% accuracy, 93% precision, and 52% recall. However, these results  are more focused on ease explaining for each stage and process in more detail, not on the numbers obtained. Research with larger data will be carried out later by developing a computer -based application system.  
 
Keywords : Naive Bayes Classifier, Confusion  Matrix, Text Clasification, Twitter 
 
Abstrak  
Twitter adalah salah satu media sosial yang saat ini sangat diminati oleh pengguna internet. Banyaknya cuitan yang beredar di Twitter belum dapat diketahui apakah cuitan tersebut lebih banyak mengandung opini positif, negatif, dan netral. Untuk itu diperlukan sistem yang dapat mengolah data dengan menerapkan analisis sentimen. Penelitian ini menggunakan metode Naive Bayes Classifier (NBC) untuk menganalisis tingkat sentimen terhadap  data yang 
dilakukan dengan teknik crawling pada Twitter. Data yang diteliti sebagai studi kasus sederhana hanya menggunakan sebanyak 8  data cuitan yang dibagi menjadi 5 data latih dan  3 data uji. Data tersebut diolah dengan tahap preprocessing, lalu diklasifikasi menggunakan metode NBC, perhitungan performa  menggunakan teknik confusion matrix. Penelitian ini menghasilkan pemaparan yang terstruktur pada proses dan hasil implementasi NBC dan pengujian performa menggunakan confusion matrix yang didapatkan  akurasi sebesar 82%, 
presisi 93% , dan recall sebesar 52%. Namun demikian hasil ini lebih difokuskan untuk kemudahan penjelasan setiap tahapan dan proses secara lebih detil, bukan fokus pada angka-angka yang didapatkan. Penelitian dengan data yang lebih besar dilakukan kemudian menggunakan sistem aplikasi berbasis komputer.  
 
Kata Kunci : Naive Bayes Classifier, Confusion Matrix, Klasifikasi  Teks, Twitter  
 
1. PENDAHULUAN  
Media sosial Twitter  saat ini menjadi aplikasi yang diminati oleh pengguna internet. Riset per November 2019  menyebutkan bahwa di Indonesia tercatat sebanyak 78 juta pengguna Twitter  [1]. Banyaknya netizen memberikan opini melalui cuitan, komentar, atau kritikan terhadap Isu-isu  yang sedang hangat menjadi berita yang trending. Salah satu berita yang yang sering muncul menjadi trending topic  di Twitter  adalah kontroversi tentang Ahok. Ahok terbukti bersalah melanggar Pasal 156a KUHP tentang penodaan agama [2]. Ahok dibebaskan dari penjara pada tanggal 24 Januari 2019 namun tak lama kemudian masyarakat Indonesia dihebohkan deng an berita Ahok diangkat sebagai Komisaris Utama Pertamina  [3]. Berita tersebut menjadi viral  di berbagai media sosial khususnya Twitter.  Banyak cuitan dari netizen  namun belum dapat diketahui apakah cuitan tersebut lebih banyak mengandung opini positif, negatif, ataupun netral. Untuk itu diperlukan sistem yang dapat mengolah data dengan menerapkan analisis sentimen.  Analisis sentimen adalah penambangan teks yang menganalisis dan mengekstraksi informasi yang bersifat subjektif dan dapat membantu pihak 
yang membutuhkan [4]. Penelitian tentang analisis sentimen ini  sebelumnya  pernah dilakukan seperti Analisis Sentimen Calon Gubernur DKI Jakarta 2017 di Twitter  Menggunakan Metode Lexicon Based, Support Vector Machine  (SVM), dan Naive Bayes Classifier NBC  [5]. Pe nelitian ini melakukan riset tentang opini masyarakat yang mengandung sentimen positif, netral, atau negatif Calon Gubernur DKI Jakarta 2017 di Twitter . Akurasi paling tinggi ketika menggunakan metode klasifikasi NBC dengan rata-rata akurasi mencapai 95%, presisi 95%, recall  95%, True Positive  (TP) rate  96,8%, dan True Negative  (TN) rate  84,6%. Pada SVM didapatkan rata-rata akurasi 90%, presisi 89,9%, recall 90%, TP rate  98,4%, dan TN rate  38,5%.  Penelitian ini mengambil contoh studi kasus yang bertujuan untuk 
mengetahui opini masyarakat terhadap berita kontroversi Ahok di Twitter  berdasarkan tiga klasifikasi, yaitu komentar positif, netral, dan negatif. Metode NBC dipilih karena tingkat akurasi yang tinggi, mudah untuk dipahami, dan memiliki cepat dalam me ngklasifikasi data [6]. Penelitian ini ini diharapkan mampu me njelaskan langkah -langkah secara terstruktur dalam mengimplementasikan metode NBC dalam m engklasifikasi teks.  Analisis Sentimen Masyarakat terhadap Calon Presiden Indonesia 2014 berdasarkan Opini dari Twitter  Menggunakan Metode  Naive Bayes Classifier 
(NBC)  melakukan klasifikasi sentimen analisis terhadap komentar atau cuitan dari masyarakat terhadap Calon Presiden Indonesia Tahun 2014. Komentar tersebut diambil melalui Twitter  dengan beberapa tahapan, yaitu pengumpulan data, preprocesing  data, POS Tagging , ekstrasi opini menggunakan rule based,  dan klasifikasi opini . Jumlah percakapan pada 
pasangan Prabowo â€“Hatta Rajasa lebih unggul sebesar 53% dibandingkan Jokowi â€“Jusuf Kalla sebesar  47%. Hasil dari pengamatan polaritas sentimen masyarakat menunjukkan Prabowo â€“Hatta Rajasa mendapatkan 47,7% sentimen positif, 26,4% negati f, dan 25,9% netral. Sedangkan pasangan Jokowi â€“Jusuf Kalla mendapatkan 37,6% sentimen positif, 34,4% negatif, dan 27,9% netral. Dari hal ini disimpulkan bahwa Prabowo â€“Hatta Rajasa lebih unggul dalam hal jumlah percakapan dan sentimen positif pada Twitter [6]. Analisis sentimen data presiden Jokowi dengan Preprocessing  Normalisasi dan Stemming  Menggunakan Metode NBC dan Support Vector Machine (SVM) [7] melakukan klasifikasi sentimen analisis terhadap komentar masyarakat terhadap Presiden Jokowi. Komentar tersebut diambil melalui media  sosial dan beberapa blog politik menggunakan teknik search techniques. Data yang telah didapat dievaluasi melalui  prep rocessing , yaitu normalisasi dan stemming  dengan bantuan aplikasi Sastrawi Master. Tahap selanjutnya adalah tokenisasi N-Gram, Unigram, Bigram , dan Trigram  terhadap kalimat, kemudian menghilangkan kata-kata yang umum digunakan dan tidak memiliki  informasi yang berharga pada konteks atau disebut 
stopword removal , dan mempertahankan emoticon sebagai  simbol ekspresi dalam tulisan. Akurasi yang  terbaik pada penelitian ini adalah dengan melakukan normalisasi dan stemming pada data sebesar 89,2655% menggunakan SVM.  Analisis Sentimen Opini Publik Berita Kebakaran Hutan melalui Komparasi Algoritma Support Vector Machine  dan K-Nearest Neighbor berbas is Particle Swarm Optimization  [8] melakukan klasifikasi sentimen pada pengguna sosial media yang memberikan komentar positif dan negatif terhadap berita kebakaran hutan yang berdampak kabut asap. Pengujian dilakukan terhadap review opini publik berita keb akaran hutan yang dikumpulkan melalui online news didapatkan 360 data (180 positif dan 180 negatif) menggunakan metode SVM, SVM  berbasis PSO  (SVM+PSO), k-NN, dan k-NN berbasis PSO  (k-NN+PSO). SVM memiliki akurasi 80,83% dan Area Under The Curve  (AUC) sebes ar 0,947, sedangkan SVM+PSO menghasilkan 
akurasi 86,11% dan AUC sebesar 0,922.  Text Mining  Dalam Analisis Sentimen Asuransi pada Media Sosial Facebook Menggunakan Metode Naive Bayes Classifier [9] melakukan 
klasifikasi analisis sentimen pada pengguna yang memberikan tanggapan terhadap kepuasan pelayanan pada sebuah perusahaan Asuransi melalui  media sosial opini publik yang ada pada komentar media sosial Facebook. Penelitian ini telah menghasilkan sistem analisis sentimen asuransi yang mampu mentransformasi sentimen berupa teks ulasan pada fanpage  
sehingga dapat menampilkan informasi sentimen masyarakat yang bersifat positif dan negatif. Akurasi pada sistem yang dibangun mencapai 95%.  
 
2. METODOLOGI  PENELITIAN  
Penelitian ini lebih fokus pada tahapan -tahapan p roses implementasi dan hasil pada preprocessing, NBC, dan confusion matrix. Sebagai studi kasus hanya disampaian data terbatas untuk kemudahan pemahaman sehingga secara konsep lebih mudah dipahami. Implementasi dengan data yang besar akan dilakukan pada penelitian selanjutnya.  
2.1.  Preprocessing  
Text mining  merupakan teknik penambangan data untuk melakukan analisis pada opini di dalam teks tertulis. Media sosial adalah salah satu media yang dapat diterapkan teknik ini dengan tujuan untuk evaluasi dan menunjang organisasi untuk penyampaian informasi  [9]. Analisis sentimen  adalah penambangan teks dengan menganalisis, memahami, mengolah, dan mengekstrak data tekstual yang bersifat opini, emosi, dan sikap terhadap suatu objek. Teks yang ditambang adalah data yang  akan diteliti. Data diambil dari komentar, ulasan, atau testimoni dari produk yang akan diteliti dengan 
tujuan untuk mengetahui secara umum opini masyarakat terhadap objek yang dianalisis. Klasifikasi analisis sentimen dibagi menjadi tiga kelas, yaitu positif, negatif, dan netral. Tahap ini merupakan proses yang penting untuk 
menentukan dokumen yang memiliki dan menyimpulkan opini bernilai positif, negatif, atau netral  [6]. Crawling  merupakan pengunduhan atau pengambilan data dengan tujuan untuk mengumpulk an data dari suatu database , misalnya data yang diunduh dari server Twitter  berupa user  dan tweet  termasuk atributnya menggunakan fasilitas add-one Twitter archiver  yang disediakan oleh Google  pada Spreadsheet  [10]. Pre-processing bertujuan untuk menghilangkan noise  
dan menyeragamkan bentuk kata untuk mengurangi volume  kosakata [11] Langkah-langkah preprocessing  adalah sebagai berikut   
1) Cleaning adalah menghilangkan karakter pada teks berupa hastag , url, mention , dan symbol  sehingga menghasilkan data cuitan  yang asli.  
2) Tokenizing adalah memotong setiap kata pada dokumen yang bertujuan untuk mengubah huruf kapital menjadi huruf kecil. Tahap ini hanya memproses huruf sehingga  karakter atau tanda baca lainnya dihapus. 
Hanya huruf â€˜aâ€™ sampai dengan â€˜zâ€™ yang dite rima.  
3) Filtering atau stopword adalah proses mengambil kata penting dari hasil tokenizing . Terdapat algoritma stoplist  didalamnya yang bertujuan untuk membuang kata-kata yang tidak penting dan wordlist  yang berfungsi sebagai tempat menyimpan kata-kata penting. Kata yang dibuang adalah kata yang tidak deskriptif, contohnya yang, dan, di, dan dari.  
4) Stemming adalah proses mengubah kata hasil dari filtering  ke bentuk dasarnya dengan cara menghilangkan imbuhan-imbuhan pada kata dalam dokumen , misal membela menja di bela, menguatkan menjadi menguat, menjaga menjadi jaga, dikatakan menjadi kata, dan lain-lain. TF*ID merupakan metode untuk mencari bobot suatu kata dalam dokumen kunci di setiap kategori dan mencari kata kunci yang hampir mirip dengan kategori yang ter sedia. Pembobotan ini menggunakan teknik Term Frequency  and Inverse Document Frequency  (TF*IDF ) untuk mengekstraksi ciri dari suatu teks dengan cara menggabungkan metode TF d an IDF [12] dengan persamaan berikut.  
âˆ‘       (1) 
Kelemahan metode TF adalah jika suatu kata muncul pada semua dokumen maka tidak bisa dipastikan bahwa kata tersebut memiliki makna khusus yang relevan  sehingga digunakan IDF  untuk menghitung jumlah dokumen yang mengandung kata yang dimaksud, kemudian dibagi dengan total dokumen yang ada [12]. Dengan tujuan mendapatkan pembobotan yang sesuai untuk tiap term  dalam tiap dokumen, maka di lakukan  kombinasi metode  TF d an IDF [12]. 
2.1 Klasifikasi Menggunakan Naive Bayes Classifier  
NBC  adalah salah satu metode untuk mengklasifikasi data dengan probabilitas sederhana yang mengaplikasikan teorema bayes  dengan karakter independen  yang tinggi. Metode ini sesuai untuk banyak dataset dengan  performa yang cepat dalam mengklasifikasi data  dan memiliki akurasi tinggi  [6]. Dasar dari Naive Bayes  yang dipakai dalam  pemrograman adalah rumus Bayes, yaitu peluang kejadian A sebagai B ditentukan dari peluang B saat A, pelua ng A, dan peluang B seperti per samaan berikut.  
  (   )  ( (   )    ( ))
 ( )   (4) 
Pada aplikasianya rumus ini berubah menjadi:  
 (    )  
 ( (    )  (  )) 
 ( )   (5) 
NBC bisa disebut sebagai Multinomial Naive Bayes  merupakan model penyederhanaan Metode  Bayes yang cocok dalam klasifikasi  teks atau dokumen  dengan persamaan  berikut.  
                (                    )  (6) 
Menurut persamaan (3) maka persamaan (6) dapat ditulis:         
        (              ) (  )
  (           )   (7) 
dan dapat diturunkan menjadi:  
        (              ) (  )  (8) 
Karena P(a1 , a2,â€¦. . an | vj) sulit untuk dihitung  maka diasumsikan bahwa setiap kata di dalam dokumen tidak memiliki keterkaitan . 
Rumus pengujian sentiment adalah sebagai berikut.   
            
        (    )   (  )  (9)  
Rumus hitung d ata uji:  
 (  )        
-10
 (     )      
-11
Keterangan:  
 (  ) = probabi litas setiap dokumen pada sekumpulan dokumen  
 (  |  ) = probabilitas kemunculan kata    pada suatu dokumen 
dengan kategori kelas    
       = frekuensi dokumen pada setiap kategori  
           = jumlah dokumen training  yang ada  
   = frekuensi kata ke-k pada setiap kategori  
           = jumlah kosakata yang ada pada dokumen uji  
2.2. Evaluasi Performa Menggunakan Confusion Matrix  
Confusion matrix  adalah tabel yang menyatakan klasifikasi jumlah data uji yang benar dan jumlah data uji yang salah. Contoh confusion matrix  untuk klasifikasi biner ditunjukkan pada Tabel 1 [13]. 
Tabel 1. Confusion matrix  
Kelas Prediksi  
1 0 Kelas 
Sebenarnya  
1 TP FN 
0 FP TN 
Keterangan:  
TP ( True Positive ) =  jumlah dokumen dari ke las 1 yang benar 
diklasifikasikan sebagai kelas 1  
TN (True Negative ) =  jumlah dokumen dari kelas 0 yang benar 
diklasifikasikan sebagai kelas 0  
FP ( False Positive ) =  jumlah dokumen dari kelas 0 yang salah 
diklasifikasikan sebagai kelas 1  
FN ( False Nega tive) =  jumlah dokumen dari kelas 1yang salah 
diklasifikasikan sebagai kelas 0  
Rumus confusion matrix  untuk menghitung accuracy, precision, dan recall  seperti berikut.              
-12                        
-13       
-14
3. HASIL DAN PEMBAHASAN  
Setelah mendapatkan kepahaman pada landasan teori maka 
selanjutnya melakukan perhitungan  pada studi kasus dengan lima  data cuitan yang diambil dari crawling  pada Twitter yang akan diklasifikasi dengan metode Naive Bayes Classifier  (NBC) . Untuk pembahasan yang lebih terstruktur dan mudah dipahami, pembahasan dilakukan dengan beberapa sub bab dibuat berurutan dari proses dan hasil  preprocessing , implementasi dan hasil NBC, serta evaluasi  performa.  
3.1. Proses dan Hasil Preprocessing   
Data penelitian sebagai studi kasus diambil lima data cuitan yang bersifat mentah dan terdapat karakter, simbol , singkatan, dan bahasa asing yang perlu diolah terlebih dahulu  seperti pada Tabel 2  berupa cuitan atau data mentah hasil crawling . 
Tabel 2. Data mentah hasil crawling  
Dokumen  Cuitan  
1 @hanny_tiwa Selamat Bekerja pak ahok @basuki_btp 
2 @bintangku20 6 AHOK itu penista Tapi Ahok Dilindungi  
3 @jihyunpetzie Selamat bertugas ya pak @basuki_btp 
4 @vivanewscom Ahok Tidak Pantas Dikasih Jabatan  #vivanews  
5 @muit1924 Penista bisa jadi pejabat.  
Tabel 3. Proses dan hasil preprocessing  
Case fold ing  Cleaning  Tokenizing  Filtering  Stemming  
@hanny_tiwa selamat bekerja pak ahok @basuki_btp 
bekerja pak ahok  
selamat, bekerja, pak, ahok  
selamat, bekerja, ahok  
selamat, kerja, ahok  
@bintangku206 ahok itu penista tapi ahok dilindungi 
ahok itu penista tapi ahok dilindungi  
ahok, itu, penista, tapi, ahok, dilindungi  
ahok, penista, lindung  ahok, 
nista, lindung  
@jihyunpetzie selamat bertugas ya pak @basuki_btp 
bertugas ya pak 
selamat, bertugas, ya, pak 
selamat, bertugas  
selamat, tugas  
@vivanewscom ahok tidak pantas dikasih jabatan bekasi 
ahok tidak pantas dikasih jabatan  
ahok, tidak, pantas, dikasih, jabatan  
ahok, tidak, pantas, dikasih, jabatan  
jawara, bekasi, ahok, tidak, pantas, kasih, jabatan  
@muit1924 penista jadi pejabat.  
penista jadi pejabat  
penista, jadi, pejabat  
penista, jadi, pejabat  
nista, jadi, pejabat  
Data mentah hasil crawling  yang memiliki huruf kapital diubah menjadi huruf kecil melalui proses case folding, kemudian dilakukan  cleaning atau penghilangan karakter, URL, mention, dan hastag  sehingga didapatkan cuitan 
yang sebenarnya. Selanjutnya proses tokenizing dilakukan pemotongan atau pemenggalan kata pada data cuitan yang selanjutnya dipisahkan dengan tanda koma (,). Filtering kemudian dilakukan untuk pengambilan kata-kata penting setelah proses tokenizing . Stemming sebagai proses akhir 
preprocessing  memastikan data yang masih mengandung kata imbuhan dihilangkan untuk mendapatkan kumpulan data yang berisi kata dasar ( root ). Proses dan hasil dari case folding  hingga stemming  dapat dilihat pada Tabel 3 .  
3.2. Implementasi  dan Hasil NBC    
Setelah melakukan tahapan preprocessing  selanjutnya adalah 
implementasi NBC. Proses diawali dengan memberikan label pada setiap hasil  stemming  dengan  tiga kelas sentimen yang diberikan kode 0 adalah positif, 1 adalah negatif, dan 2 adalah netral  seperti pada Tabel 4. Kemunculan setiap kata dalam dokumen di identifikasi kemunculannya sepertipada Tabel 5 . 
Tabel 4. Hasil labelling  
Dokumen  Cuitan  Kelas Sen timen  
1 selamat, kerja, ahok  0 
2 ahok, nista, lindung  1 
3 selamat, tugas  0 
4 ahok, tidak, pantas, kasih, jabatan  1 
5 nista, jadi, pejabat  1 
Tabel 5. Kata yang muncul dalam dokumen  Dokumen  
selamat  
kerja  
ahok  
nista  
lindung  
tugas  
tidak  
pantas  
kasih  
jabatan  
jadi 
pejabat  
Kelas sentimen  
1 1 1 1 0 0 0 0 0 0 0 0 0 + 
2 0 0 1 1 1 0 0 0 0 0 0 0 - 
3 1 0 0 0 0 1 0 0 0 0 0 0 + 
4 0 0 1 0 0 0 1 1 1 1 0 0 - 
5 0 0 0 1 0 0 0 0 0 0 1 1 - 
Dokumen kelas positif seperti pada Tabel 6  terdapat pada Dokumen  1 dan 3. Selanjutnya  probabilitas pada kata yang mengandung sentimen negatif seperti pada T abel 7  yang terdapat pada Dokumen 2, 4, dan 5.  
Tabel 6. Dokumen kelas  sentimen  positif  Dok 
selamat  
Kerja  
Ahok  
Nista  
Lindung  
Tugas  
Tidak  
Pantas  
Kasih  
Jabatan  
Jadi 
Pejabat  
Kelas  
sentimen  
1 1 1 1 0 0 0 0 0 0 0 0 0 + 
3 1 0 0 0 0 1 0 0 0 0 0 0 + 
sum  2 1 1 0 0 1 0 0 0 0 0 0 5 
Tabel 7. Dokumen kelas sentimen negatif  Dokumen  
selamat  
kerja  
ahok  
nista  
lindung  
tugas  
tidak  
pantas  
kasih  
jabatan  
jadi 
pejabat  
Kelas sentimen  
2 0 0 1 1 1 0 0 0 0 0 0 0 - 
4 0 0 1 0 0 0 1 1 1 1 0 0 - 
5 0 0 0 1 0 0 0 0 0 0 1 1 - 
sum  0 0 2 2 1 0 1 1 1 1 1 1 11 
Nilai probabi litas kelas sentimen positif  dan probabilitas kelas sentimen 
negative dihitung dengan persamaan (10) . 
 (  )       
 (  )    
Nilai p robabilitas setiap kata pada kelas sentimen positif maupun negatif 
dihitung menggunakan persamaan (11)  didapatkan seperti pada Tabel 8 dan 
Tabel 9 . 
Tabel 8 . Probabilitas kata pada kelas sentimen positif  
Kata  Probabilitas  Probabil itas  
selamat   (            ) 
           (            ) 
kerja   (       |  ) 
           (       |  ) 
ahok   (         ) 
           (         ) 
tugas   (       |  ) 
           (       |  ) 
Tabel 9 . Probabilitas kata pada kelas sentimen negatif  
Kata  Probabilitas  Probabilitas  
ahok   (         ) 
           (         )   
nista   (          )   
         (          )   
lindung   (            )   
           (            )    
tidak   (          )   
           (          )   
pantas   (        |  )   
           (        |  )   
kasih   (          )   
             (          )   
jabatan   (            )   
           (            )           
jadi  (     |  )   
            (     |  )   
pejabat   (            )   
          (            )    
3.3. Implementasi Data Uji dan Evaluasi Performa  
Tabel 10 adalah data yang akan dilakukan pengujian untuk 
menentukan kelas sentiman setiap dokumen . 
Tabel 10. Data uji  
Dokumen  Cuitan  Kelas Sentimen  
6 selamat, tugas, ahok, komut, pertamina  ? 
7 mantap  ? 
8 fadli, zon, sebut, ahok, tidak, pantas, jadi, ? 
Dokumen  Cuitan  Kelas Sentimen  
komisaris, utama pertamina  
Data uji dihitung probabilitas  dan dicari probabilitas tertinggi menggunakan 
persamaan (9) . 
 (       ) 
  (            )  (       |  )  
    (         )  (          )  
   (             )  (  )  
 (       ) 
  (            )  (       |  )  
     (         )  (          )  
     (             )  (  )  
    (       )  
  (           )  (  )  
 (       )  
  (           )  (  )  
  (       )  
  (          )  (        )  (          )  (         )  (         ) 
 (          )  (        )  (             )  (         )  (  )  
 (       )  
  (       |  )  (        )  
      (          )  (         )  
      (         )  (       |  )  
      (     |  )  (             )  
      (         )  (  )  
Nilai probabilitas dari setiap data uji yang diperoleh dirangkum pada Tabel 11. Dok umen 6 menghasilkan sentimen positif, sedangkan Dokumen 7 dan Dokumen 8 menghasilkan sentimen negatif.  
Tabel 11. Hasil dari perhitungan probabilitas  
Dokumen  Probabilitas  Kelas sentimen  
Positif  Negatif  
6                + 
7         - 
8                        - 
Setelah melakukan pengujian data maka selanjutnya melakukan 
pengujian evaluasi performa menggunakan confusion matrix  untuk mengukur performa berupa akurasi, presisi, dan recall . Hasil klasifikasi menggunakan metode NBC ditunjukan pada Tabel 12 sehingga menghasilkan perhitungan yang telah diklasifikasi dan diberi kode untuk kelas Positif (0), kelas Negati f (1), dan kelas Netral (2) seperti ditunjukkan pada Tabel 12 dan Tabel 13. 
Tabel 12. Hasil klasifikasi data uji  
Dokumen  Kelas Sebenarnya  Kelas Prediksi  
6 (+) (+) 
7 (+) (-) 
8 (-) (-) 
Tabel 13. Perhitungan confusion matrix  Kelas Sebenarnya  Kelas Prediks i Jumlah   0 1 2 
0 1 
TPP  1 
PFNeg  0 
PFNet  2 
J4 
1 0 
NegFP  1 
TNegNeg  0 
NegFNet  1 
J5 
2 0 
NetFP  0 
NetFNeg  0 
TNetNet  0 
J6 
Jumlah  1 
J1 2 
J2 0 
J3 Total = 
3
Keterangan:  
TPP (True Possitive Possitive)  =  jumlah dokumen dari kelas 0 yang benar diklasifikasikan sebagai kelas 0
TNegNeg (True Negative Negative ) =  jumlah dokumen dari kelas 1 yang benar diklasifikasikan sebagai kelas 1
TNetNet (True Netral Netral ) =  jumlah dokumen dari kelas 2 yang benar diklasifikasikan sebagai kelas 2
PFNeg ( Positive  False Negatif)  =  jumlah dokumen dari kelas 0 yang salah diklasifikasikan sebagai kelas 1
NegFP (Negatif False =  jumlah dokumen dari kelas 1 yang Positive ) salah di klasifikasikan sebagai kelas 0
PFNet (Positive False Netral ) =  jumlah dokumen dari kelas 0 yang salah diklasifikasikan sebagai kelas 2
NetFP( Netral  False Positive)  =  jumlah dokumen dari kelas 2 yang salah diklasifikasikan sebagai kelas 0
NetFNeg( Netral  False Negatif)  = jumlah dokumen dari kelas 2 yang salah diklasifikasikan sebagai kelas 1
NegFNet(Negatif  False Netral ) = jumlah dokumen dari kelas 1 yang salah diklasifikasikan sebagai kelas 2
Pada Tabel 12 dan 13 terdapat kelas prediksi dan kelas sebenarnya. 
Kelas prediksi adalah kelas hasil prediksi dari proses klasifikasi menggunakan NBC, sedangkan kelas sebenarnya adalah kelas yang sebelumnya sudah ditentukan sentimennya. Setelah itu diperoleh nilai dan. Accuracy, precision, dan recall masing-masing dihitung menggunakan persamaan (1 2), (13), dan (14).           
Jadi pada pengujian akurasi yang diperoleh dengan menggunakan 8 data yang terdiri dari 5 data latih dan 3 data uji menghasilkan akurasi 60%, presisi 100%, dan recall 50%.  
 
4.  SIMPULAN  
Berdasarkan hasil dari penelitian yang telah  dilakukan maka sistem analisis sentimen pada T witter  menggunakan m etode NBC telah berhasil dibangun dan mampu memberikan informasi yang sangat bermakna untuk mengetahui pendapat atau opini masyarakat. Performa  yang di evaluasi menggunakan metode confusion matrix memiliki akurasi 60 %, presisi 100 %, 
dan recall  50%. Hasil tersebut didapat dari hasil analisis 5 data latih dan 3 data uji  sebagai studi kasus untuk kemudahan dalam pemahaman implementasi dan perhitungan secara terstruktur . Metode NBC  pada penelitian ini menghasilkan klasifikasi yang baik dengan nilai akurasi yang 
tinggi sehingga cocok untuk memprediksi tingkat sentimen analisis. Selanjutnya akan dikembangkan dan diimplementasikan dengan data yang lebih besar menggunakan sistem aplikasi berbasis komp uter sehingga lebih mudah dan cepat.  
 
DAFTAR PUSTAKA  
[1] Muhammad Sufya n Abdurrahman (2020) Penetrasi Internet Indonesia pada 2020, alenia.id. Tersedia pada: 
https://www.alinea.id/kolom/tantangan -penetrasi -internet -indonesia -pada -2020 -b1ZJC9smS (Diakses:  7 Agustus 2020).  
[2] Priska Sari Pratiwi (2017) Ahok Divonis Dua Tahun Penjara, CNN Indonesia. Tersedia pada: https://www.cnnindonesia.com/nasional/20170509080949 -12-
213328/ahok -divonis -dua-tahun -penjara (Diakses: 13 Maret 2020).  
[3] Dewan Komisaris | PT Pertamina (Persero) (2019). Tersedia pada: https://www.pertamina.com/id/dewan -komisaris (Diakses: 25 November 2019).  
[4] Rahmat Burhanudin (2018) Mengenal Sentiment Analysis, 
https://mamat.co/. Tersedia pada: https://mamat.co/mengenal -
sentiment -analysis/ ( Diakses: 24 September 2019).  
[5] Buntoro, G. A. (2017) â€œAnalisis Sentimen Calon Gubernur DKI Jakarta 2017 Di Twitter,â€ Integer Journal, 2(1), hal. 32 â€“41. 
[6] Nurhuda, F., Widya Sihwi, S. dan Doewes, A. (2016) â€œAnalisis Sentimen Masyarakat terhadap Calon P residen Indonesia 2014 berdasarkan Opini dari Twitter Menggunakan Metode Naive Bayes Classifier ,â€ Jurnal 
Teknologi & Informasi ITSmart, 2(2), hal. 35.  
[7] Nurirwan Saputra, Teguh Bharata Adji, A. E. P. (2015) â€œAnalisis  Sentimen Data Presiden Jokowi d engan Pre-Processing  Normalisasi d an Stemming  Menggunakan Metode Naive Bayes  dan SVM,â€ Jurnal Dinamika Informatika, 5(November), hal. 12.  
[8] Utami, L. A. (2017) â€œMelalui Komparasi Algoritma Support Vector Machine  dan K-Nearest Neighbor  Berbasis Particle Swarm Optimization ,â€ Jurnal Pilar Nusa Mandiri, 13(1), hal. 103 â€“112.  
[9] Oktasari, L., Chrisnanto, Y. H. dan Yuniarti, R. (2016) â€œ Text Mining  dalam Analisis Sentimen Asuransi Menggunakan Metode Niave Bayes Classifier ,â€ Prosiding SNST, 7, hal. 37 â€“42. 
[10] Eka Sem bodo, J., Budi Setiawan, E. dan Abdurahman Baizal, Z. (2016) â€œData Crawling  Otomatis pada Twitter,â€ (September), hal. 11 â€“16. doi: 10.21108/indosc.2016.111.  
[11] Yusnitasari, T. et al. (2017) â€œAnalisis Sentimen Terhadap Review  Restoran Fish Streat pada Apli kasi Zomato Menggunakan Stemming Nazief Adriani dan Naive Bayes Classifier ,â€ Prosiding Setrinov, 3, hal. 163 â€“174.  
[12] Saputro, P. H., Aristin, M. dan Tyas, Dy. L. (2017) â€œKlasifikasi Lagu Daerah Indonesia Berdasarkan Lirik Menggunakan Metode  TF-IDF dan Naive Bayes Classifier ,â€ Jurnal Teknoloi Informatika dan Terapan, 4(1), hal. 45 â€“50. 
[13] Putra, D. dan Wibowo, A. (2020) â€œPrediksi Keputusan Minat Penjurusan Siswa SMA Yadika 5 Menggunakan Algoritma NaÃ¯ve Bayes ,â€ 2, hal. 84 â€“92. 
",Analisis Sentimen,"Naive Bayes Classifier, TextBlob",Opini dari twitter,"akurasi, presisi, recall"
ANALISIS SENTIMEN TWEET  MENGGUNAKAN  BACKPROPAGATION NEURAL NETWORK ,"ANALISIS SENTIMEN TWEET  MENGGUNAKAN BACKPROPAGATION NEURAL NETWORK 

Maulana Aziz Assuja1), Saniati2) 

Abstrak  
Analisis sentimen tweet berkembang sebagai sebuah kajian pada bidang Pengolahan Bahasa Alami yang bermanfaat mengetahui opini masyarakat terhadap sebuah topik tertentu secara otomatis. Pada penelitian ini kami mengajukan teknik analisis tweet kedalam tiga kelas (positif, negatif dan netral) menggunakan algoritma Backpropagation Neural Network. Input jaringan merupakan sejumlah kata terpilih yang dirangking mengunakan skor TF*IDF. Variasi praproses term dilakukan untuk menguji performa klasifikasi sentimen. 
Hasil pengujian menunjukkan metode yang kami ajukan berhasil melakukan klasifikasi dengan hasil terbaik dengan akurasi 78.34% dan presisi 84.21%.  

Kata kunci:  Analisis sentimen, Tweet,  Backpropagation, Neural Network  

I. Pendahuluan  
Twitter  merupakan microblog  yang banyak digunakan oleh penggunanya untuk berkomunikasi dan mengungkapkan pendapatnya ( tweet ) tentang topik tertentu. Berdasarkan tweet-tweet  komentar yang dihasilkan, dapat ditangkap beberapa opini dari tweeter, baik berupa pernyataan positif, negatif atau bahkan netral (non opini). Dengan jumlah data yang relativ banyak, tweeter  yang berasal dari berbagai sumber (terdistribusi), dan waktu penyajian yang realtime , maka pendapat/sentimen dari para tweeter  ini dapat dimanfaatkan untuk berbagai hal, diantaranya mengetahui 
kepuasan atau keluhan user terhadap suatu produk atau layanan, menganalisa tren produk yang populer, melihat tingkat popularitas artis/politikus/to koh, dsb.  Berdasarkan manfaat -manfaat tersebut maka penelitian tentang sentimen analisis pun banyak dilakukan yang sejak lebih kurang tahun 2002 [4][13]  dan menjadi pembahasan penting pada bidang Pengolahan Bahasa Alami. Sentiment  analysis  atau biasa disebut juga opinion  mining  bertujuan mempelajari tentang pendapat, sentimen dan emosi yang diekspresikan pada teks [3].  Banyak metode yang digunakan untuk menerapkan sentiment analisis diantaranya dengan pendekatan supervised learning seperti Naive Bayes  [9][4][2][12], Support Vector Machine  (SVM) [1][12][4][2][11], 
Maximum Entrophy [4] [2], Neural Network  [5][14] dan unsupervised learning [13][17][6].  Task  utama dalam sentimen analisis yaitu mengklasifikasi teks tweet  kedalam salah satu kelas yaitu positif, negatif atau netral. Pada penelitian ini digunakan pendekatan supervised learning  dengan algoritma Backpropagatiaon Neural Network  (BNN) yang merupakan varian dari Artificial Neural Network dan telah banyak berhasil diaplikasikan termasuk pada masalah klasifikasi [16]. BNN melakukan pembelajaran  dengan menyesuaikan bobot dari tiap perceptron jaringannya sehingga sesuai (menggunakan batas toleransi atau iterasi) dengan data training nya. Klasifikasi pada teks umumnya menggunakan 
beberapa fitur yang mampu menjadi ciri pengelompokan yang baik seper ti leksikon atau term[4][10][2][5] baik secara unigram, bigram , emoticon [12][17], POS tag[4][2][1], hash tag [1] dan lain sebagainya. Leksikon atau term dalam teks merupakan fitur yang paling banyak digunakan, namun pemilihannya sebagai representasi tiap kelas target menjadi tidak konsisten jika jumlah data trainingnya berubah. Untuk mendapatkan term-term yang paling relevan tersebut dengan jumlah yang konsisten, maka pada penelitian digunakan perangkingan term terbaik menggunakan teknik TF*IDF ( Term Frequency Invers Document Frequency ) seperti pada beberapa 
penelitian sebelumnya [10][12]. 
 
II. Tinjauan Pustaka  
2.1. Sentimen Analisis  
Sentimen  analisis atau opinion mining  didefinisikan sebagai bidang ilmu yang mempelajari bagaimana mengekspresikan sentimen, opini atau pendapat dan emosi yang diekpresikan didalam teks [3].  Terdapat beberapa topik pembahasan dalam sentimen analisis, salah satu yang paling sering diteliti yaitu klasifikasi sentimen. Topik ini berfokus pada kegiatan pengelompokan sentimen berdasarkan teks opini terhadap pembahasan masalah tertentu ( movie , produk, tokoh, kejadian, dsb).  Beberapa penelitian melakukan pengelompok-an menjadi beberapa jenis kelas target, 1)dengan dua kelas (positif dan negatif) [4][2][6][11] [5](positif, negatif dan netral) [7][1][12], dan 3)lima kelas (sangat negatif, negatif, netral, positif dan sangat 
positif)[5]. Namun menurut riset Go [2] yang melakukan 
klasifikasi kedalam kelas negatif dan positif saja, menyimpulkan jika pengelompokan kedalam kelas netral tetap perlu dilakukan, karena pada beberapa tweet ditemukan sentimen yang tidak cenderung bernilai positif maupun negatif.  
2.2. Tweets  
Sentimen analisis dilakukan terhadap opini yang diberikan terhadap review pembahasan tertentu, yang pada masa kekinian, banyak orang mengomentari banyak hal dengan memanfaatkan media sosial online  seperti twitter. Pada twitter tiap orang yang terdaftar dapat mengirimkan dan membaca teks pendek yang biasa disebut tweet . Tweet  memiliki karakteristik yang unik berdasarkan laporan analisis Go [2] baik pada panjang teks, ketersediaan data, model bahasa, dan do main. Panjang teks pada tweet  maksimum 140 karakter dengan rata-rata tweet  terdiri dari 14 kata atau 78 karakter. Ketersediaan data, dengan Twitter API dapat dikumpulkan begitu banyak tweet  sebagai data set. Model bahasa pada tweet  tidak terstruktur bahkan  terkadang ada kesalahan pengetikan. Serta domain pembahasan pada twitter sangat luas terhadap banyak sekali topik apapun, berbeda dengan penelitian lain pada domain terbatas seperti review movie . 
2.3. TF*IDF ( Term Frequency Invers Document 
Frequency ) 
TF*I DF merupakan teknik pembobotan kata yang berbasis pada statistik kemunculan kata dan tingkat kepentingan dokumen yang mengandungnya. Pembobotan yang diadaptasi dari pendekatan temu-kembali informasi ( information retrieval )[8] ini merupakan hasil dari perkalian term frequency dan 
inverse document frequency  yang tiap nilainya didapatkan dengan persamaan (1).  
)( *),( *i i w IDFdwTF IDF TFï€½
-1
Dimana:  
wi = kata ke i  
d = dokumen  
TF(w i, d)=jumlah kemunculan kata w i pada dokumen d  
IDF (w i)= Invers Document Frequency  dari kata w i. Pembobotan dihitung untuk tiap kata, Term 
Frequency  menunjukkan bahwa semakin tinggi kemunculan kata pada sebuah dokumen maka semakin penting kata tersebut mewakili dokumen.  Nilai Inverse Document Frequency  memberikan indikasi bahwa jika kemunculan sebuah kata mempunyai frekuensi yang tinggi pada dokumen tertentu saja maka kata tersebut menjadi ciri penting dan mewakili dokumen tersebut. Sedangkan jika kata muncul pada seluruh dokumen maka kata tersebut bersifat umum atau tidak mewakili dokumen 
manapun dan memiliki nilai IDF 0. Dimana nilai IDF dapat didapatkan dengan persamaan (2).  
IDF(w i) = log          |D|        (2)      
                      DF (w i) Dimana:  
wi = kata ke i  
|D| = jumlah seluruh dokumen  
IDF (w i)= jumlah dokumen yang mengandung kata w i. 
Pada penelitian sentimen analisis, penggunaan dokumen pada persamaan diwakili oleh tweet yang digunakan. Pembobotan TF*IDF membantu mengambil kata-kata dari tweet  yang paling mewakili kelasnya.  
2.4. Neural Network  
Penelitian sentimen analisis dengan pendekatan supervised learning  dengan varian metode Artificial  Neural Network  [5][14] menunjukkan hasil yang baik lebih dari 80% bahkan mencapai 86% [5]. Pada penelitian klasifikasi lainnya (kelas gramatical  dan ungramatical )[15] juga menunjukkan hasil yang mencapai lebih dari 95%. Hal ini menunjukkan jika 
pendekatan Artificial  Neural Network  memberikan hasil yang memuaskan karena termasuk metode mampu menangani training  sample dengan noise  yang banyak (kebutuhan akan sistem yang robust  terhadap noise )[16]. Backpropagation Neural Network  (BNN) adalah versi modifikasi Artificial Neural Network  yang menambahkan propagasi error  dengan bergerak mundur  
(dari lapisan output  menuju lapisan input ). Penggunaan 
propagasi balik dapat mempercepat konvergensi sehingga 
model dengan jumlah data input yang banyak pun dapat dengan cepat didapatkan. Hal ini berkaitan dengan jumlah layer dan jumlah data input pada arsitektur klasifikasi yang digunakan, karena penelitian sebelumnya data input dapat berjumlah banyak tergantung levelnya.  
Gambar 1. Arsitektur dengan input  level kata [15] 
Ada yang input layernya menggunakan level kata[15][5][14] dengan arsitektur seperti pada gambar 1. bahkan pada level karakter [5] seperti pada gambar 2.  
Gambar 2. Arsitektur dengan input  level karakter [9] 

III. Analisis Sentimen Tweet Menggunakan Backpropagation Neural Network  
Pada peneliti an sentimen analisis tweet  ini digunakan 
arsitektur rancangan yang terlihat pada gambar 3.  
Gambar 3. Arsitektur rancangan Sentimen Analisis Twitter menggunakan Backpropagation Neural Network  Berdasarkan gambaran rancangan arsitektur, ada dua bagian utama pada penelitian ini yaitu fase Training  dan Testing . Pada fase training , data set berlabel melewati 4 proses diantaranya yaitu pra -proses, tokenisasi, ekstraksi fitur dengan TFIDF dan supervised learning  dengan Backpropagation Neural Network  sehingga men ghasilkan model. Pada fase testing , data uji akan melewati beberapa proses seperti praprosess, tokenisasi dan inferensi menggunakan Backpropagation  Neural Network  yang membutuhkan data model serta menghasilkan data 
berlabel. Berikut dibahas lebih detil unt uk bagian pada 
tiap fase.  
A.  Praproses  
Pada pengolahan teks, umumnya dilakukan tahap praproses yang ditujukan untuk membersihkan dan menyamakan format teks sehingga pada proses pengolahan berikutnya lebih terstruktur. Tahap praproses ini digunakan baik pada fase training  (untuk data berlabel) maupun pada fase testing  (untuk data uji). Beberapa praproses yang dilakukan yaitu tansformasi kata/ term gaul, cleaning  dan normalization , stopword removal, stemming , soundex dan tokenisasi.  Transformasi kata gaul dilaku kan karena tweet  ditulis sebagai teks yang tidak baku, sehingga banyak ditemukan kata-kata yang tidak formal/gaul yang perlu dinormalisasi ke dalam kata yang sesuai dengan KBBI (Kamus Besar Bahasa Indonesia). Pada proses ini, digunakan kamus bahasa gaul dari situs http://www.snipertechno.com/2012/12/kamus -alay-
terbaru -2013.html  dan http://adhit ezt12.blogspot.com/2012/12/kamus -bahasa -alay-lengkap.html  untuk melakukan transformasi ke penulisan kata yang baku.  Cleaning  dan normalization  dilakukan untuk menghapus â€œmentionâ€ (@), â€œretweetâ€(RT) dan digit pada data set yang dianggap tidak memiliki peran dalam penentuan kelas dari tweet . Normalisasi dilakukan dengan me-lower case  kan semua huruf untuk mendapatkan format yang seragam, serta penggantian semua kata-kata tidak sopan dengan kata â€œmakianâ€ untuk mengelompokkan ungkapan -ungkapan kekesalan tersebut. Stopword  merupakan kata -kata yang tidak memiliki arti seperti â€œituâ€, â€œiniâ€, â€œdanâ€, â€œyangâ€, dst. Stopword removal  atau penghapusan stopword dilakukan karena frekuensi kemunculannya yang tinggi namun tidak memiliki kontribusi, dikhawatirkan dapat menggangu 
proses klasifikasi. Daftar stopword  didapatkan dari 
http://yudiwbs.wordpress.com/2008/07/23/stop -words -untuk -bahasa -indonesia/ , juga dilakukan beberapa penambahan  kata-kata yang dianggap perlu seperti â€œsihâ€, â€œnahâ€, â€kokâ€,dsb.  Stemming  atau penghilangan imbuhan dilakukan untuk mengambil bentuk dasar dari sebuah kata yang telah mengalami morphology karna penambahan imbuhan. Misalnya â€žmembeliâ€Ÿ dan â€žbelikanâ€Ÿ menjadi  â€žbeliâ€Ÿ. Tujuan dari tahap ini yaitu menangani jika ada dua atau lebih kata berbeda namun memiliki makna yang hampir sama tetap diperlakukan sebagai 1 kata yang sama.  Soundex  dilakukan untuk mengubah kata kedalam bentuk kode suara, sehingga untuk kata-kata yang pengucapannya mirip akan memiliki kode yang sama. Pada soundex  juga hanya mengolah huruf-huruf konsonan dari kata, sedangkan huruf vokal dihilangkan. Berdasarkan analisa data, langkah ini dianggap perlu karena banyak kata -kata dalam data set yang ditul iskan secara tidak lengkap/disingkat seperti â€ždapatâ€Ÿ ditulis â€ždptâ€Ÿ.  Ada juga beberapa kata yang sama namun ditulis secara berbeda seperti â€žmalasâ€Ÿ dan â€žmalesâ€Ÿ. Langkah ini  akan menghasilkan kode yang sama baik untuk kata disingkat maupun kata sama yang dit ulis sedikit berbeda.  Tokenisasi dilakukan untuk memenggal tiap kata atau term yang terpisah oleh tanda baca seperti spasi, titik, koma, tanda tanya, dsb. Term-term atau token -token tersebut dipilih kembali sebagai kata yang paling mewakili tiap label sent imen pada tahap ekstraksi fitur untuk fase training . Sedangkan pada fase testing , term selanjutnya diinferensi dengan algoritma Backpropagation Neural Network.  
B. Ekstraksi Fitur dengan TF*IDF  
Keluaran dari praposes dan tokenisasi menghasilkan jumlah term yang banyaknya sesuai dengan data set masukannya. Term -term tersebut akan mewakili atau menjadi fitur pada text classification  menggunakan backpropagation . Namun tidak semua term dijadikan fitur, fitur didapatkan dengan cara mengambil 50 kata/ term terbaik dar i data training  yang mewakili tiap kelas target (netral, positif, dan negatif). Dari setiap kelompok tweet  berdasarkan kelas target akan memiliki 50 term yang masing -masing akan di merge  secara distinct . Total term yang didapatkan akan menjadi fitur (input perceptron ) pada jaringan backpropagation .  Perhitungan yang digunakan untuk mendapatkan top 50 term terbaik dari tiap  kelompok tweet  menggunakan pembobotan TF*IDF ( Term Frequency â€“Inverse 
Document Frequency ). Nilai TF*IDF yang tinggi menggambarkan bahwa term tersebut merupakan term yang penting dari suatu kelompok tweet  (kelompok berdasar kelas target), dilihat dari kemunculannya yang intens dalam kelompoknya namun tidak umum untuk kelompok lain. Misalnya, kata â€œmakianâ€ akan menjadi penting untuk kelas neg atif tetapi tidak banyak dijumpai pada kelas lainnya.  
C. Supervised Learning Backpropagation  Neural Network  
Pada penelitian sentiment analisis ini, digunakan metode pembelajaran terbimbing dengan algoritma Backpropagation Neural Network  (BNN) dengan arsitektur seperti gambar 4. Fungsi aktivasi untuk setiap perceptron  yang dipilih ialah sigmoid.  
Gambar 4 . Arsitektur BNN untuk Sentimen  
Analisis Tweet  Setiap node pada input merepresentasikan satu buah kata atau term yang dijadikan fitur. Sehingga jika terdapat 50 term yang akan dijadikan fitur, maka input pada BNN merupakan array double sejumlah 50 elemen. Pada fase 
training , term-term tiap tweet  dipetakan sesuai dengan 50 
term terpilih pada node input, jika terdapat term yang sama maka akan bernilai 1 d an 0 jika sebaliknya. Selain itu, tiap-tiap tweet  juga telah terlabeli sesuai kelasnya 
(negatif, positif atau netral). Berdasarkan data set berlabel tersebut akan dilakukan pembelajaran terbimbing 
sehingga diakhir didapatkan bobot yang sesuai dengan data pembelajaran yang kemudian disimpan sebagai model.  
D. Ekstraksi Fitur  
Tahap ekstraksi fitur ini dilakukan terhadap data uji (tweet  tidak berlabel) dengan cara menyamakan term yang dihasilkan dari praproses dengan daftar term yang sudah diekstraksi dari fase training menggunakan TFIDF. Jika ada term yang sama maka elemen fitur bernilai 1, jika tidak maka bernilai 0.  
E. Inferensi dengan Backpropagation Neural Network  
Proses ini dilakukan untuk menginferensi atau mengklasifikasi fitur dari data uji, terhadap tiga kelas yang ada. Tahap ini membutuhkan model dari BNN dari hasil training. Pada tahap ini model mengandung bobot yang sudah sesuai dengan hasil training , yang kemudian fitur input dihitung terhadap bobot-bobot ditiap layer sehingga output nya merepresentasikan kelas dari data uji. Jika hasil akhir output  secara berurutan ialah 100 maka data uji berlabel kelas negatif, 010 kelas positif dan 001 kelas netral.  
 
IV. Hasil  dan P embahasan  
4.1. Skenario Eksperimen  
Ketentuan penggunaan Backpropagation  Neural Network  pada eksperimen ini yaitu, misal  
1. jumlah term yang diekstraksi fitur dengan TF*IDF (N) = 90  
2. input  Layer ïƒ  N = 90 (+ 1 Bias Unit) = 91 Perceptron  
3. hidden Layer  ïƒ N x 3 = 90 * 3 (+ 1 Bias Unit) = 271 Perceptron   
4. ouput Layer  ïƒ M = 3 (Negatif, Positif, Netral)  
5. learning  rateïƒ  0.1 
6. stopping criterion  untuk training  menggunakan BNN adalah dengan galat 10% atau maksimal iterasi 500.  
Pada eksperimen ini total data set yang digunakan 
yaitu 944 tweet  dimana tweet -tweet  tersebut terdiri dari 
kelas netral  (500 tweet ), positif  (254 tweet ), dan negatif  (190 tweet ). Seluruh tweet  kemudian dibagi menjadi 2 bagian, 2/3 untuk data training  (630 tweet ) dan 1/3 untuk data testing  (314 tweet ).  Pada pengujian dilakukan uji coba terhadap beberapa jumlah fitur term yang diambil yaitu sebany ak 30, 50, 70 dan 100 term per kelas target. Skema selanjutnya yaitu kedua data training  dan data testing  akan dibagi menjadi 
5 grup yaitu:  
Grup I  :data hanya di tokenisasi, tanpa praproses lain.  
Grup II  :data dengan praproses transformasi kata gaul, cleaning & normalization , tokenisasi.  
Grup III  :data dengan praproses transformasi kata gaul, cleaning  & normalization , stopword removal , tokenisasi.  
GrupVI  :data dengan praproses transformasi kata gaul, cleaning  & normalization , stopword removal, stemming , 
tokenisasi.  
Grup V  :data dengan praproses transformasi kata gaul, cleaning & normalization, stopword removal, stemming, soundex , tokenisasi.  
Eksperimen ini diukur menggunakan 3 jenis 
pengukuran yaitu:  
1. Correct classified  (C), didapatkan dari prosentase 
hasil kata yang terlabeli dengan benar dibagi total seluruh kata yang diuji.  
2. Precision  (P), didapatkan dari prosentase penjumlahan precision  semua kelas dibagi total kelas. Sedangkan nilai precision  tiap kelas didapatkan dengan menghitung jumlah kata yang terklasifikasi benar terhadap sebuah kelas dibagi total kata yang terklasifikasi kekelas tersebut.  
3. Recall  (R), didapatkan dari prosentase penjumlahan recall  semua kelas dibagi total kelas. Sedangkan nilai recall  tiap kelas didapatkan dengan menghitung jumlah kata yang terklasifikasi benar terhadap sebuah kelas dibagi jumlah kata yang sebenarnya merupakan member  dari kelas tersebut.  
4.2. Hasil  
Setelah dilakukan eksperimen didapatkan hasil untuk tiap grup dengan variasi jumlah term perkelas target seperti pada tabel-tabel berikut.  
Tabel 1. Hasil pengujian Grup I  
30
term 
/kelas 
target 
(%) 50 
term 
/kelas 
target 
(%) 70 
term 
/kelas 
target 
(%) 100 
term 
/kelas 
target 
(%) rata-
rata 
(%) 
C 60.82  69.11  68.47  73.56  67.99  
P 59.81  72.04  68.17  76.99  69.25  
R 57.08  62.24  63.28  66.73  62.33  
Tabel 1. adalah hasil pengukuran untuk Grup I dimana semua data set tidak dilakukan praproses kecuali tokenisasi. Dari tabel tersebut terlihat jika hasil pengukuran terbaik terjadi pada pengujian dengan 100 term/kelas target. Sedang hasil terendah dari pengujian dengan 30 term/ kelas target.  Tabel 2. Hasil pengujian Grup II  
30
term 
/kelas 
target 
(%) 50 
term 
/kelas 
target 
(%) 70 
term 
/kelas 
target 
(%) 100 term 
/kelas 
target 
(%) rata-
rata 
(%) 
C 72.61  78.34  77.07  77.07  76.27 
P 72.12  84.21  82.93  83.73  80.74  
R 68.26  72.63  70.54  70.63  70.51  
Hasil pengukuran untuk pengujian Grup II dimana data set melewati tahap praproses transformasi kata gaul, cleaning  & normalization , tokenisasi ada pada tabel 2. Secara rata -rata hasil pada Grup II lebih baik dibandingkan dengan Grup I, dengan hasil paling baik dengan perbedaan tipis ditujukan pada pengujian dengan 50 term/kelas target.   
Tabel 3. Hasil pengujian Grup III  
30
term 
/kelas 
target 
(%) 50 
term 
/kelas 
target 
(%) 70 
term 
/kelas 
target 
(%) 100 
term 
/kelas 
target 
(%) ata-
rata 
(%) 
C 76.43  74.20  78.98  75.15  76.19  
P 80.99  79.73  81.22  80.98  80.73  
R 71.01  67.72  75.35  68.43  70.62  
Skenario untuk Group III hampir sama dengan Grup II dengan penambahan praproses stopword remo val. Hasil pengukuran secara umum pada Grup III tidak jauh berbeda dengan Grup II. Dimana hasil terbaik diperoleh pada pengujian 70 term/ kelas target.  
Tabel 4. Hasil pengujian Grup IV  
 30 term 
/kelas 
target 
(%) 50 
term 
/kelas 
target 
(%) 70 
term 
/kelas 
target 
(%) 100term 
/kelas 
target 
(%) rata-
rata 
(%) 
C 76.43  75.47  76.11  78.02  76.5 
P 80.86  81.71  81.13  80.03  80.93  
R 71.10  68.73  69.71  74.15  70.92  
Pada eksperimen untuk Grup IV juga masih memiliki rata-rata hasil pengukuran yang mirip dengan Grup II dan III. Data set pada Grup IV  melalui tahap praproses transformasi kata gaul, cleaning  & normalization , stopword removal , stemming , dan tokenisasi. Hasil dengan correct classified  dan recall  terbaik yaitu pengujian untuk 100 term/kelas target.  
Tabel 5. Hasi l pengujian Grup V  
30
term 
/kelas 
target 
(%) 50 
term 
/kelas 
target 
(%) 70 
term 
/kelas 
target 
(%) 100term 
/kelas 
target 
(%) rata-
rata 
(%) Jurnal TEKNOINFO, Vol. 10, No. 2, 2016, 23-28. ISSN: 1693 -0010 (print)  
28
 C 71.33  72.93  71.33  72.61  72.05  
P 73.13  73.64  74.05  76.53  74.33  
R 66.38  69.43  66.47  66.43  67.17  
Pengujian Grup  terakhir pada tabel 5. mengalami 
penurunan hasil pengukuran, dimana data set mengalami 
semua praproses yaitu transformasi kata gaul, cleaning & 
normalization, stopword removal, stemming, soundex . 
V. Simpulan  
Hasil pengujian pada sentimen analisis menunjukkan jika tahap praproses diperlukan untuk meningkatkan akurasi hasil klasifikasi. Sedangkan bentuk praproses yang paling baik ditunjukkan oleh penggunaan transformasi kata gaul, cleaning  (retweet  dan mention) dan normalisasi ( case folding  dan perubahan makian). Sedangkan praproses soundex  memberikan dampak penurunan akurasi. Sementara jumlah fitur atau term 
sebagai data input  tidak banyak berpengaruh terhadap hasil. Secara keseluruhan, metode Backpropagation Neural Network  memberikan performa yang baik.  
Daftar Pustaka  
[1]  A. Agarwal, B. Xie, I. Vovsha, O. Rambow, and R. Passonneau, â€œSentiment analysis of Twitter data,â€ Assoc. Comput. Linguist. , 2011.  
[2]  A. Go, R. Bhayani, and L. Huang, â€œTwitter Sentiment Classification using Distant Supervision,â€ 2009.  
[3] B. Liu, â€œSentiment Analysis and Subjectivity,â€ 
2010.  
[4]  B. Pang, L. Lee, H. Rd, and S. Jose, â€œThumbs upâ€¯? Sentiment Classification using Machine Learning Techniques,â€ 2002.  
[5]  C. N. dos Santos and M. Gatti, â€œDeep Convolutional Neural Networks for Sentiment Analysis of Short Texts,â€ Coling -2014 , 2014.  
[6]  C. Scheible, â€œUnsupervised Sentiment Analysis with a Simple and Fast Bayesian Model using Part-of-Speech Feature Selection,â€ vol. 2012, 2012.  
[7]  E. Kouloumpis, T. Wilson, and J. Moore, â€œTwitter sentiment analysis: The good the bad and the omg!,â€ Proc. Fifth Int. AAAI Conf. Weblogs Soc. Media (ICWSM 11) , 2011.  
[8]  G. Salton and M. McGill, Introduction to modern Information Retrieval . McGraw -Hill, 1983.  
[9]  I. F. Rozi, S. Hadi, and E. Achmad, â€œImplementasi Opinion Mining ( Analisis Sentimen ) untuk Ekstraksi Data Opini Publik pada Perguruan Tinggi,â€ vol. 6, no. 1, 2012.  
[10] J. Martineau, J. Martineau, T. Finin, T. Finin, C. 
Fink, C. Fink, C. Piatko, C. Piatko, J. Mayfield, J. Mayfield, Z. Syed, Z . Syed, Others, and Others, â€œDelta TFIDF: An Improved Feature Space for Sentiment Analysis,â€ Proc. Second Int. Conf. Weblogs Soc. Media (ICWSM , vol. 29, no. May, 2008.  
[11] K. Ghag, â€œSentiTFIDF â€“ Sentiment Classification 
using Relative Term Frequency Inverse Document Frequency,â€ vol. 5, no. 2, 2014.  
[12] P. Aliandu, â€œSentiment analysis on indonesian tweet,â€ 2013.  
[13] P. D. Turney, â€œThumbs Up or Thumbs Downâ€¯? Semantic Orientation Applied to Unsupervised Classification of Reviews,â€ no. July, 2002.  
[14] R. So cher, A. Perelygin, J. Y. Wu, J. Chuang, C. D. Manning, A. Y. Ng, and C. Potts, â€œRecursive Deep Models for Semantic Compositionality Over a Sentiment Treebank,â€ 2013.  
[15] S. Roa and F. Nino, â€œClassification of Natural Language Sentences using Neural Netwo rks,â€ 2003.  
[16] T. M. Mitchell, Machine Learning . McGraw -Hill, 1997.  
[17] X. Hu, J. Tang, H. Gao, and H. Liu, â€œUnsupervised Sentiment Analysis with Emotional Signals,â€ 2013.  
 
Maulana Aziz Assuja , lahir di Sindang Anom, 24 Nopember 1986 . Memperoleh gelar D4 di Program Studi Teknik Informatika, Institut Teknologi Sepuluh November di Surabaya pada tahu n 2009. Kemudian pada tahun 2015  memperoleh gelar S2 di Program Studi Informatika,  Institut Teknologi Bandung . Saat ini bekerja aktif sebagai staf pengajar di STMIK -AMIK Teknokrat Lampung.  
Saniati , lahir di Tarakan, 14 Februari 1988. Memperoleh gelar D4 di Program Studi Teknik Informatika, Institut Teknologi Sepuluh November di Surabaya pada tahun 2009. Kemudian pada tahun 2014 memperoleh gelar S2 di Program Studi Informatika, Institut Teknologi Bandung. Saat ini bekerja aktif sebagai staf pengajar di STMIK -AMIK Teknokrat Lampung.",Analisis Sentimen,Backpropagation Neural Network,tweet,"akurasi, presisi"
Analisis Sentimen Masyarakat Terhadap Program Kartu Prakerja Pada Twitter Dengan Metode Support Vector Machine,"Analisis Sentimen Masyarakat Terhadap Program Kartu Prakerja Pada Twitter Dengan Metode Support Vector Machine

Styawati1, Nirwana Hendrastuty2, Auliya Rahman Isnain3, Ari Yanti Rahmadhani4

Abstract 
The Kartu Prakerja program was launched in 2020 through Presidential Regulation Num ber 36 of 2020 concerning the Development of Work Competencies through the Pre-Employment Card Program. The discussion of the pre-employment card program on Twitter made the writer interested in analyzing 
the sentiments of the Indonesian people towards the  Pre-Employment Card Program regarding the government's efforts to overcome unemployment and victims of labor layoffs with the keyword """"pre -employment"""". The sentiments used are positive, negative, and neutral. The method used to analyze public opinion with data obtained on social media twitter using the Support Vector Machine (SVM). Meanwhile, to measure the performance of SVM classification using the Confusion Matrix method. In this study, a comparison of two kernels was carried out, namely linear with RBF. The results of the evaluation carried out on the linear kernel accuracy value of 98.67%, precision 98%, recall 99%, and F1-Score 98%, while the RBF kernel accuracy value is 98.34%, precision 97%, recall 98%, F1-Score 98%, The key is that public sentiment from twitter users towards the pre -employment card program during the pandemic tends to be neutral by 98.34%. Based on the results of the evaluation carried out on the accuracy value of the linear kernel, it produces an accuracy value of 98.67%, while the  RBF kernel produces an accuracy of 98.34%. So in terms of accuracy the linear kernel is more accurate than the RBF kernel.  
 
Keywords Kartu Prakerja Program, Twitter Social Media, SVM, 
Confusion Matrix, Kernel Linear, Kernel RBF.  
 
Abstrak 
Program  kartu prakerja diluncurkan pada tahun 2020 melalui peraturan Presiden Nomor 36 tahun 2020 tentang  Pengembangan Kompetensi Kerja melalui Program Kartu Pra-Kerja . Maraknya pemba hasan program kartu prakerja di twitter membuat penulis tertarik untuk menganalisa sentimen  masyarakat Indonesia terhadap Program kartu Prakerja tentang trobosan upaya pemerintah mengatasi penganguran dan korban PHK tenaga kerja dengan keyword â€œprakerjaâ€. Sentimen yang digunakan adalah positif, negatif, dan netral. Metode yang digunakan untuk menganalisis opini masyarakat dengan data yang diperoleh pada sosial media twitter menggunakan Support Vector Machine  (SVM) . Sedangkan  untuk mengukur kinerja klasifikasi SVM menggunakan metode  Confusion Matrix. Pada penelitian ini dilakukan perbandingan dua ke rnel yaitu linear dengan RBF. Hasil evaluasi yang dilakukan pada nilai akurasi kernel linear 98.67%, precission 98%, recall 99%, dan F1-Score 98%, sedangkan pada nilai akurasi kernel RBF 98.34%, precission 97%, recall 98%, F1-Score 98%, dapat disimpulkan bahwa sentimen masyarakat dari pengguna twitter terhadap program kartu prakerja dimasa pandemi lebih condong ke netral sebesar 98,34%. Berdasarkan hasil evaluasi yang dilakukan pada nilai akurasi kernel linear menghasilkan nilai akurasi 98.67%, sedangkan kernel RBF menghasilkan akurasi 98.34%. Maka dari sisi akurasi kernel linear lebih akurat  dari pada kernel RBF.  
 
Kata Kunci Program Kartu Prakerja, Media Sosial Twitter, 
SVM, Confusion Matrix, Kernel Linear, Kernel RBF.  

I. PENDAHULUAN  
Dunia sedang menghadapi permasalahan yang disebabkan oleh Corona virus, diduga untuk pertama kalinya ditemukan di kota Wuhan, Cina, pada akhir Desember 2019. Corona virus merupakan  penyakit yang menyebabkan gangguan pernafasan pada manusia[1] . Corona virus  diklaim dapat menularkan virus dengan cepat dan telah menyebar ke wilayah lain di Cina dan beberapa negara, termasuk Indonesia [2]. International Labour Organization (ILO) memprediksi bahwa setiap orang akan dipaksa mengalami kehilangan pekerjaan kurang lebih  25 juta pekerjaan di dunia . Hilangnya pekerjaan tersebut disebabkan oleh   pandemi covid- 19[3] . Selanjutnya pada triwulan  kedua tahun 2020 ILO memperkirakan jam kerja pegawai  akan  menurun 10,5 persen 
atau sebanding  dengan 305 juta peker ja penuh waktu dengan 
asumsi waktu  kerja penuh adalah 48 jam perminggu [4] . Dampak yang ditimbulkan oleh Corona virus menyebabkan hampir setengah dari seluruh aktivitas negara-negara bagian yang terdampak menjadi lumpuh, salah satunya Indonesia. Upaya yang dikeluarkan pemerintah, seperti, memberikan bantuan sosial tunai kepada masyarakat yang berdampak pandemi, kartu Prakerja, Insentif untuk korban PHK, Menerbitkan surat utang, insentif untuk pekerja medis,dan  kepastian THR. Trobosan upaya dari pemerintah dalam merealisasikan program kartu Prakerja dapat diakses secara online. Program ini diprioritaskan bagi masyarakat yang berstatus pengangguran dan korban PHK. Dengan demikian, dapat dilihat berapa banyak masyarakat yang mendukung, menolak dan tidak memperdulikan terhadap program trobosan yang dilakukan oleh pemerintah melalui Twitter. Dari opini -opini yang bersumber dari topik pembahasan tertentu bisa dikatakan sebagai opini positif, negatif dan bisa dikatakan netral [5][6]. Penelitian  ini akan menganalisis sentimen  masyarakat Indonesia terhadap Program kartu Prakerja tentang trobosan upaya pemerintah mengatasi penganguran dan korban PHK tenaga kerja. Metode yang digunakan untuk menganalisis opini masyarakat dengan  data yang diperoleh pada sosial media Twitter  menggunakan 
Support Vector Machines  dalam mengukur tingkat keakuratan 
pada teknik metode yang digunakan.   

II. PENELITIAN  YANG  TERKAIT  
Twitter adalah media sosial gratis dan terpopuler  serta 
menyediakan layanan jaringan yang memungkinkan pengguna untuk berbagi pendapat melalui pesan singkat atau sering dikenal dengan tweet  [7]. Ulasan dari twitter dapat diklasifikasikan ke dalam beberapa sentimen. Seperti penelitian yang dilakukan oleh [8]  opini masyarakat terkait film diklasifikasikan ke dalam dua sentimen yaitu positif dan negatif. Terdapat banyak metode untuk melakukan proses 
klasifikasi data, salah satunya adalah Support Vector Machine (SVM). Metode SVM dapat melakukan proses klasifikasi data ulasan dari twitter dengan baik [9] . Penelitian lain juga mengatakan bahwa hasil terbaik untuk mendeteksi sentimen dari Twitter berbahasa Indonesia dapat dicapai dengan menggunakan metode SVM [10].   Menurut [11] SVM dapat 
melakukan klasifikasi data opini dari twitter dengan hasil 
akurasi 91.67%. Berdasarkan pada penelitian terdahulu, penelitian ini akan menganalisa sentimen masyarakat terhadap program kartu prakerja pada sosi al media menggunakan metode support vector machine  (SVM).  

III. METODE PENELITIAN  
A. Tahapan Penelitian  
Tahapan pertama pada penelitian ini yaitu pengambilan data dari Twitter dengan kata kunci â€œPrakerjaâ€ kemudian akan diperoleh data komentar masyarakat ter kait program kartu Prak erja yang rilis di masa pandemi. Setelah itu data yang diperoleh dilakukan preprocessing data. Setelah melalui pra proses data, kemudian data diberi label secara manual. Setelah itu dilakukan klasifikasi data menggunakan algoritma 
Support Vector Machine  (SVM) . Data yang sudah didapatkan 
akan diklasifikasikan menjadi tiga kategori kelas yaitu positif, negatif, dan netral . 
B. Skema Pemodelan SVM  
Proses klasifikasi data menggunakan metode SVM Multiclass  dapat dilihat pada gambar 1  
Gambar 1 Proses Klasifikasi SVM Multiclass  
C. Support Vector Machine  
Teknik Support Vector Machine  (SVM)  bertujuan untuk menemukan fungsi pemisah terbaik di antara fungsi yang ada  untuk memisahkan dua macam obyek. Penyelesaian klasifikasi dua kelas dapat menggunakan persamaan  berikut  
-1
Pada awalnya SVM digunakan untuk klasifikasi data dalam 
dua kelas. Pada perkembangannya, Support Vector Machine dapat diperluas untuk klasifikasi multi kelas. Jika dalam dua dimensi pemisah tersebut berupa garis, dalam tiga dimensi berupa plane, dan dalam dimensi lebih dari tiga disebut dengan hyperplane.  Pada awalnya SVM digunakan untuk klasifikasi data dalam dua kelas. Pada perkembangannya, SVM dapat diperluas untuk klasifikasi multi kelas.  SVM multi ke las diperlukan pendekatan yang berbeda dengan kasus dua kelas.  Ada beberapa metode SVM Multi Kelas yaitu salah satunya metode SVM Muti Kelas One-Against-One[12]. Pada metode One-Again-One, dengan cara membangun sejumlah model  SVM biner yang nanti nya akan dibandingkan satu kelas dengan kelas lainnya. Untuk  mengklasifikasikan data ke k -kelas, maka harus membangun sejumlah k(k-1)/2 model SVM biner . 
D. Teknik Kernel  
Teknik data mining atau machine learning banyak dikembangkan dengan asumsi linieritas . Sehingga algoritma yang dihasilkan lebih untuk kasus -kasus yang linier. Umumnya kasus -kasus yang sering terjadi bukanlah kasus yang linier. Untuk mengatasi sifat yang tidak linier tersebut dapat menggunakan metode kernel. Dengan metode kernel  suatu data x input space  di mapping  ke feature space F  dengan dimensi  yang lebih tinggi . Adapun fungsi kernel yang biasanya digunakan dalam SVM  yaitu:  Kernel linear  : (2)  Kernel polynomial:  
-3
Kernel RBF:  2)    (4)  
E. Confusion Matrix  
Evaluasi klasifikasi pada penelitian ini menggunakan metode Confusion Matrix . Cara kerja metode ini yaitu matriks dari prediksi akan dibandingkan dengan kelas asli yang berisi informasi nyata  dan prediksi nilai klasifikasi. Setelah sistem berhasil melakukan klasifikasi tweet , dibutuhkan ukuran untuk menentukan seberapa benar  atau tepat klasifikasi yang telah dibuat oleh sistem.  Kondisi untuk melakukan pengujian klasifikasi menggunakan metode Confusion Matrix  dapat dilihat pada gambar2.  
Gambar 2 Confusion Matrix   

IV. HASIL  DAN  PEMBAHASAN  
A. Pengumpulan Data  
Penelitian ini meng gunakan data sekunder. Dataset berisi 
teks berbahasa Indonesia yang diperoleh dari media sosial 
Twitter , dengan menggunakan bahasa pemrograman Python. Untuk melakukan steam twitter  API dibutuhkan sebuah key dan access token  sebagai bukti autentifikasi dengan cara developer twitter . Dalam pencarian data menggunakan sebuah 
kata kunci â€œPrakerjaâ€. Data yang didapat adalah seluruh opini masyarakat tentang program yang diluncurkan pemerintah di masa pandemi. Pengumpulan data dilakukan pada rentang 
tanggal 22 Apri l sampai 29 April 2021 diperoleh sebanyak 
2000 data. Data yang telah berhasil diambil akan disimpan di excel dengan format .csv. Contoh data yang diperoleh dari 
twitter  dapat dilihat pada gambar 3 . 
Gambar 3 Contoh data dari twitter  
B. Preprocessing Data 
Preprocessing merupakan tahap dimana data yang diperoleh dengan cara crawling sebanyak 2000 data selanjutnya dilakukan pra -proses data . Teknik yang digunakan untuk pra-proses data yaitu Cleansing, Case Folding, Tokenizing, Filtering, Stemming .  
C. Cleansing  
Cleansing merupakan tahapan yang bertujuan menghilangkan karakter atau symbol link url (http://situs.com), username atau mention(@username), hastage(#), retweet, dan emoticon.  Hasil data setelah melalu proses cleansing dapat dilihat pada tabel I . 
Tabel I  Hasil data setelah proses cleansing  
No Data Mentah  Hasil Cleansing  
1 RT @tokopedia: Pengen buka usaha tapi belum ada modal? Menangkan hadiah modal usaha total 400jt di Kompetisi """"Kisahku Bersama Kartu Prakerâ€¦  Pengen buka usaha tapi belum ada modal Menangkan hadiah modal usaha total 400jt  Kompetisi Kisahku Bersama Kartu Praker  
2 RT @dede_soccerboy: NKCTHI ( Nanti Kita Cerita Tentang Bundaran HI )  Disiksa Jepang.  Ardhito Prakerja.  Nanti Kita Cerita Tentang Bundaran HI Disiksa Jepang Ardhito 
Prakerja BukanyaStandupindo  
3 RT @aewin86: Yang lebih seru lagi, kampanye anti masker, 
sebut covid hoax, sambil nikmati kartu prakerja, insentif pajak, BLT, Bansos, Subsâ€¦  Lebih seru lagi kampanye anti masker sebut covid hoax sambil nikmati kartu prakerja insentif pajak BLT Bansos Subs  
4 RT @kompascom: Menteri Keuangan (Menkeu), Sri Mulyani Indrawati, buka-bukaan soal sunat THR PNS 2021 demi Kartu 
Prakerja, BLT, dan programâ€¦  Menteri Keuangan Menkeu Sri Mulyani Indrawati buka buka soal sunat THR PNS 2021 demi Kartu Prakerja BLT dan program  
5 @maulmalik_ GAUSAH NUNGGU SI NGARET ALIAS PRAKERJA BUAT BAYAR UTANGMU WKWKKWKW tunggu disend dr ini ajah  GAUSAH NUNGGU SI NGARET ALIAS PRAKERJA BUAT BAYAR UTANGMU tunggu disend ini ajah  
D. Case Folding Case Folding merupakan tahapan mengganti seluruh case dalam sebuah dokumen menjadi bentuk standar  (huruf kecil) . Sedangkan karakter lainnya dianggap sebagai delimiter atau pembatas.  Hasil data setelah melalui proses case folding dapat dilihat pada tabel II. 
Tabel II  Hasil data setelah proses case folding  
No Hasil Cleaning  Hasil Case Folding  
1 Pengen buka usaha tapi belum ada modal Menangkan hadiah modal usaha total 400jt Kompetisi Kisahku Bersama Kartu Praker  pengen buka usaha tapi belum ada modal menangkan hadiah modal usaha total 400jt kompetisi kisahku bersama  kartu praker  
2 soccerboy NKCTHI Nanti Kita Cerita Tentang Bundaran HI siksa Jepang Ardhito Prakerja BukanyaStandupindo  soccerboy nkcthi nanti kita cerita tentang bundaran hi siksa jepang ardhito prakerja bukanyastandupindo  
3 lebih seru lagi kampanye anti masker sebut covid hoax sambil nikmati kartu prakerja insentif pajak BLT Bansos  lebih seru lagi kampanye anti masker sebut covid hoax sambil nikmati kartu prakerja insentif pajak blt bansos  
4 Menteri Keuangan Menkeu Sri Mulyani Indrawati buka buka soal sunat THR PNS 2021 demi Kartu Prakerja BLT dan program  menteri keuangan menkeu sri mulyani indrawati buka buka 
soal sunat thr pns 2021 demi kartu prakerja blt dan program  
5 GAUSAH NUNGGU SI NGARET  ALIAS PRAKERJA BUAT BAYAR UTANGMU 
tunggu disend ini ajah  gausah nunggu si ngaret alias prakerja buat bayar utangmu tunggu disend  ini ajah   
E. Tokenizing 
Tokenizing merupakan tahap setelah proses case folding. Data akan di proses dimana tanda baca akan di hilangkan sehingga menghasilkan sebuah kalimat/kata yang berdiri sendiri. Hasil data setelah melalui proses tokenizing  dapat dilihat pada tabel III . 
Tabel III Hasil data setelah melalui proses tokenizing  
No Hasil Case Folding  Hasil Tokenizing  
1 pengen buka usaha tapi belum ada modal menangkan hadiah modal usaha total 400jt kompetisi kisahku bersama kartu praker  pengen buka usaha tapi belum ada modal menang hadiah 
modal usaha total 400 kompetisi kisah bersama kartu praker  
2 soccerboy nkcthi nanti kita cerita tentang bundaran hi 
siksa jepang ardhito prakerja bukanyastandupindo  soccerboy nkcthi nanti kita cerita tentang bundaran hi siksa jepang ardhito prakerja bukanya standupindo  
3 lebih seru lagi kampanye anti masker sebut covid 
hoax sambil nikmati kartu prakerja insentif pajak blt 
bansos  lebih seru kampanye anti masker sebut covid hoax sambil nikmati kartu prakerja insentif pajak blt bansos  
4 menteri keuangan menkeu sri mulyani indrawati buka buka soal sunat thr pns 2021 demi kartu prakerja blt dan menteri keuangan menkeu sri mulyani indrawati buka buka soal program sunat thr pns 2021 demi kartu prakerja blt dan program  
5 gausah nunggu si ngaret alias prakerja buat bayar utangmu tunggu disend  ini ajah gausah nunggu  ngaret alias prakerja buat bayar utangmu tunggu disend ini ajah 
 F. Filtering  
Filtering  merupakan tahapan yang bertujuan untuk menghilangkan kata umum yang biasa sering muncul dalam jumlah banyak dan tidak memiliki makna menggunakan algoritma stoplist (membuang kata yang kurang penting) atau wordlist  (Menyimpan kata penting) . Hasil data setelah melalui proses Filtering  dapat dilihat pada tabel  IV. 
Tabel I V Hasil data setelah proses Filtering  
No Hasil Tokenizing  Hasil Filtering  
1 pengen buka usaha tapi belum ada modal menang hadiah modal 
usaha total 400 kompetisi kisah bersama kartu praker  pengen buka usaha tapi belum ada modal menang hadiah modal 
usaha total 400 kompetisi kisah kartu 
praker  2 soccerboy nkcthi nanti kita cerita tentang bundaran hi siksa jepang ardhito prakerja bukanya standupindo soccerboy nkcthi cerita bundaran hi siksa jepang ardhito prakerja bukanya standupindo 
3 lebih seru kampanye anti masker sebut covid hoax 
sambil nikmati kartu prakerja insentif pajak blt bansos  seru kampanye anti masker covid hoax nikmati  kartu prakerja  
insentif' pajak blt bansos  
4 menteri keuangan menkeu sri mulyani indrawati buka buka soal sunat thr pns 2021 demi kartu prakerja blt dan 
program  menteri keuangan menkeu sri mulyani indrawati buka buka sunat thr pns 2021 kartu prakerja blt  program  
5 gausah nunggu  ngaret alias prakerja buat bayar 
utangmu tunggu disend ini ajah  gausah nunggu ngaret 
alias prakerja bayar utangmu tunggu disend ajah 
G. Stemming  
Stemming  merupakan tahapan setiap kata akan diubah dari 
kata berimbuhan menjadi kata dasar. Stemming  yang digunakan adalah algoritma Nazief dan Adriani yang terdapat pada library  sastrawi . Hasil data setelah melalui proses Stemming  dapat dilihat pada tabel V.  
Tabel V Hasil data setelah proses stemming  
No Hasil Filtering  Hasil Stemming  
1 pengen buka usaha tapi belum ada modal menang hadiah modal usaha total 400 kompetisi kisah kartu praker  buka usaha belum ada modal menang hadiah modal usaha total 400 kompetisi kisah kartu praker  
2 soccerboy nkcthi cerita bundaran hi siksa jepang 
ardhito prakerja bukanya  standupindo soccerboy nkcthi cerita bundar hi siksa jepang ardhito prakerja buka standupindo  
3 seru kampanye anti masker covid hoax nikmati  kartu prakerja insentif' pajak blt bansos  seru kampanye anti masker  covid hoax nikmat kartu prakerja insentif pajak blt bansos  
4 menteri keuangan menkeu sri mulyani indrawati buka buka sunat thr pns 2021 kartu prakerja blt  program  menteri uang menkeu sri mulyani indrawati buka buka sunat thr pns 2021 kartu prakerja blt program  
5 gausah nunggu ngaret alias prakerja bayar utangmu tunggu disend ajah gausah nunggu prakerja bayar utang tunggu send ajah 
H. Pelabelan Manual  
Sebelum masuk dal am proses klasifikasi data, peniliti menggunakan pelabelan dataset manual yang melibatkan ahli bahasa dalam menentukan label tweet . Label data pada penelitian ini dibagi ke dalam tiga kategori yaitu label positif, label negatif dan label netral. Contoh hasil pelabelan manual dapat dilihat pada tabel V I. 
Tabel V I Contoh hasil pelabelan manual  
No Tweet  Kelas  
1 pengen buka usaha tapi belum ada modal menangkan hadiah modal usaha total 400jt kompetisi kisahku bersama kartu praker  Positif  
2 soccerboy nkcthi nanti kita cerita tentang bundaran hi disiksa jepang ardhito prakerja bukanyastandupindo  Netral  
3 lebih seru kampanye anti masker sebut  covid hoax sambil nikmati kartu prakerja insentif pajak blt bansos  Positif  
4 menteri keuangan menkeu sri mulyani indrawati buka buka soal sunat thr pns 2021 demi kartu prakerja blt dan program  Netral  
5 gausah nunggu ngaret alias prakerja buat bayar utan gmu 
tunggu disend dr ini ajah  Positif  
I. Pembobotan 
Tahap pembobotan merupakan tahap dimana pemberian bobot pada setiap kata dengan menggunkan perhitungan Term Frequency â€“Invert Document Frequency (TF-IDF) . Alur pembobotan TF -IDF dapat dilihat pada gambar  4. 
Gambar 4 Alur pembobotan TF -IDF 
J. Implementasi Support Vector Machine Kernel Linear  
Implementasi Support Vector Machine  (SVM ) dalam 
penelitian ini menggunakan bahasa pemrograman python. Python memiliki library Sklearn yang dapat digunakan untuk 
mengimplementasikan  SVM . Baris code implementasi S VM 
dapat dilihat  pada gambar 5 . 
Gambar 5  SVM kernel linier  
Dimulai dari baris code SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto') pada kernel linear. 
Baris code SVM.fit(Train_X_Tfidf,Train_Y  pembuatan model Support Vector Machine. Lalu, dilakukan penerapan model yang telah dibuat pada baris code predictions_SVM SVM.predict(Test_X_Tfidf). Untuk menghitung nilai akurasinya prediksi diterapkan pada  baris code print(""""SVM Accuracy Score kernel linear -> ,accuracy_score(predictions_SVM, Test_Y)*100).  
K. Implementasi Support Vector Machine Pada Kernel RBF 
Implementasi Support Vector Machine (SVM)  pada kernel RBF ( Radial Basis Function )  dalam penelitian ini menggunakan bahasa pemrograman python. Python memiliki library Sklearn yang dapat digunakan untuk mengimplementasikan SVM . Baris code implementasi SVM  pada  kernel  RBF  dapat dilihat pada gambar 6 . 
Gambar  6 SVM kernel RBF  
Dimulai dari baris code SVM = svm.SVC(C=1.0, kernel='rbf', degree=3, gamma='auto') pada kernel rbf. Baris code SVM.fit(Train_X_Tfidf,Train_Y  pembuatan model Support Vector Machine. Lalu, dilakukan penerapan model yang telah dibuat pada baris code predictions_SVM = SVM.predict(Test_X_Tfidf). Untuk menghitung nilai akurasinya prediksi diterapkan pada baris code print(""""SVM Accuracy Score kernel linear -> ,accuracy_score(predictions_SVM, Test_Y)*100).   
L. Hasil Perbandingan Kernel Linear dan RBF Hasil yang diperoleh dari pengujian SVM dengan kernel linier dan  RBF  dapat d ilihat pada tabel VII . 
Tabel VII  Perbandingan kernel linier dan RBF  
Kernel  Accuracy  Precision  Recall  F1-score  
Linear  98.67%  98% 99% 98% 
RBF  98.34%  97% 98% 98% 
Berdasarkan pada tabel IX, kernel linier menghasilkan 
accuracy 98.67549668874173 sedangkan ke rnel RBF menghasilkan accuracy 98.34437086092716. Dari kedua pengujian yang telah dilakukan dapat dilihat bahwa kernel linier lebih unggul dibandingkan dengan kernel RBF berdasarkan akurasi.  
M. Evaluasi  
Pengujian dilakukan menggunakan confusion matrix  melalui 
library  SVM, dari data uji sebanyak 302 data yang sebelumnya telah dilakukan proses klasifikasi. Hingga menghasilkan matrik dengan ordo 3x3 sebagai representatif dari kelas aktual dan kelas prediksi. Adapun hasil yang 
diperoleh dari pengujian yang dilakukan kernel linear menghasilkan akurasi 98.67%, presision 98%, recall 99%, dan F1-Score 98%, sedangkan kernel RBF menghasilkan akurasi 98.34%, presision 97%, recall 98%, dan F1- Score 98%. Maka dari sisi akurasi kernel linear lebih baik dari pada RBF.  

V. KESIMPULAN 
Pada penelitian ini kesimpulan yang didapatkan yaitu:  
1. Hasil dari klasifikasi menggunakan metode Support Vector Machine yang dibagi dalam tiga kelas netral sebanyak 98,34%, kelas negatif sebanyak 0,99%, dan kelas positif sebanyak 0,66%.  
2. Hasil evaluasi yang dilakukan pada nilai akurasi kernel linear 98.67%, precission 98%, recall 99%, dan F1-Score 
98%, sedangkan pada nilai akurasi kernel RBF 98.34%, precission 97%, recall 98%, F1- Score 98%, dapat disimpulkan bahwa sentiment masyarakat dari pengguna twitter terhadap program kartu prakerja dimasa pandemi lebih condong ke netral sebesar 98,34%.  

DAFTAR PUSTAKA 
[1] S. Styawati and F. Ariany, â€œSistem Monitoring Tumbuh Kembang Balita/Batita di Tengah Covid- 19 Berbasis Mobile,â€ J. Inform. Univ. Pamulang, vol. 5, no. 4, p. 490, 2021, doi: 10.32493/informatika.v5i4.7067.  
[2] D. Herdiana, â€œJurnal Ilmu Administrasi Social Distancingâ€¯: Indonesian Policy Reponse To The Corona Virus,â€ J. Ilmu Adm. , vol. 17, no. 1, pp. 93â€“ 110, 2020.  
[3] N. Ngadi, â€œDampak Pandemi Covid- 19 Terhadap Phk Dan Pendapatan Pekerja Di Indonesia.â€ pp. 43 â€“48, 2020.  
[4] I. ILO, â€œILO Monitorâ€¯: COVID -19 and the world of work . Third edition Updated estimates and analysis Enterprises at risk Contextâ€¯: Lockdown continues to severely impact enterprises,â€ no. April, pp. 1 â€“23, 2020.  
[5] S. Zahoor, â€œTwitter Sentiment Analysis using Machine Learning Algorithmsâ€¯: A Case Study,â€ pp. 194â€“199, 2020.  
[6] R. Joshi, â€œComparative Analysis Of Twitter Data Using Supervised Classifiers.â€  
[7] D. K. Zala, â€œA Review on Basic Methodology of Twitter Base Prediction System,â€ pp. 447 â€“451, 2018.  
[8] S. Styawati and K. Mustofa, â€œA Support Vector Machine -Firefly Algorithm for Movie Opinion Data Classification,â€ IJCCS (Indonesian J. Com put. Cybern. Syst. , vol. 13, no. 3, p. 219, 2019, doi: 10.22146/ijccs.41302.  
[9] S. Naz, A. Sharan, and N. Malik, â€œSentiment Classification on Twitter Data Using Support Vector Machine,â€ Proc. - 2018 IEEE/WIC/ACM Int. Conf. Web Intell. WI 2018 , pp. 676â€“679, 2019, doi: 10.1109/WI.2018.00- 13. 
[10] D. A. Kristiyanti, Normah, and A. H. Umam, â€œPrediction of Indonesia presidential election results 
for the 2019- 2024 period using twitter sentiment analysis,â€ Proc. 2019 5th Int. Conf. New Media Stud. CONMEDIA 2019 , pp. 36â€“42, 2019, doi: 10.1109/CONMEDIA46929.2019.8981823.  
[11] D. Radhi, D, â€œSentiment analysis of twitter data,â€ 
Proc. - 2018 Int. Conf. Comput. Sci. Comput. Intell. CSCI 2018, no. Iciccs, pp. 1301â€“1302, 2018, doi: 10.1109/CSCI46756.2018.00252.  
[12] S. Suyanto, Machine Learning tingkat Dasar Dan Lanjut . Informatika Bandung, 2018.  ",Analisis Sentimen,Support Vector Machine,data dari twitter,"akurasi, precission, recall, F1-Score"
Analisis Sentimen  Pembelajaran Campuran Pada Twitter Data Menggunakan  Algoritma Naive Bayes,"Analisis Sentimen  Pembelajaran Campuran Pada Twitter Data Menggunakan  Algoritma Naive Bayes

Ronal Watrianthos1, Muhammad Giatman2, Wakhinuddin Simatupang2, Rahmi Syafriyeti3, Nelly Khairani Daulay4 

Abstrak
Ketika berbicara tentang belajar mandiri, pendekatan pembelajaran campuran telah diperdebatkan dalam hal kualitas 
pendidikan. Pendidik  memiliki beberapa kendala dalam membuat pembelajaran campuran  bekerja karena mereka harus  menyesuaikan diri dengan mengaj ar sambil juga meningkatkan kemampuan teknis mereka. Model  pembelajaran campuran yang banyak digunakan di berbagai  institusi Pendidikan berpotensi  menyebabkan banyak masalah bagi peserta didik . Tujuan artikel ini adalah untuk menemukan pendapat pembelajaran jarak jauh  berdasarkan komentar media sosial. Penelitian ini membuat model klasifikasi  menggunakan  algoritma Naive Bayes pada  data twit dari Twitter dengan  mengevaluasi persepsi dan penerimaan publik  terhadap model pembelajaran campuran . Dalam menggali p endapat tentang model ini, hasilnya klasifikasi twit apakah positif atau negatif  menggunakan metode Twitter sentimen  analisis.  Hasil penelitian menunjukkan polarisasi sikap positif dan negatif hampir seimbang  dengan 44,51 persen positif dan 45,80 persen negatif. Studi lebih lanjut  dapat  dilakukan untuk menyelidiki sentimen tidak hanya di Twitter tetapi juga di platform media sosial lainnya untuk meningkatkan akurasi opini  publik mengenai pembelajaran campuran dalam situasi pandemi  

Kata Kunci : Analisis Sentimen, Pembelajaran Campuran, Blended Learning, Twitter, Analisis Opini 

Abstract
Mixed learning methodologies have been disputed in terms of educational quality when it comes to self-study. Educators face specific challenges when making hybrid learning work since they must adjust to teaching while also strengthening their technological abilities. The blended learning paradigm, which is commonly adopted in many educational institutions, can produce a slew of  issues for students. The goal of this essay is to gather thoughts about distance learning based on social media comments. This study creates a classification model using Twitter tweet data by assessing public perceptions and acceptance of the mixed learning model. The findings of examining thoughts regarding this model include categorizing tweets as favorable or unfavorable using the Twitter sentiment analysis approach. The results revealed an almost equal polarization of positive and negative sentiments, with 44.51 percent positive and 45.80 percent negative. More research can be done to analyze attitudes not just on Twitter but also on other social media platforms to improve public opinion accuracy about mixed learning in a pandemic crisis.  

Keywords : Sentiment Analysis 

1. PENDAHULUAN  
Pembelajaran Campuran  merupakan paradigma pembelajaran yang memadukan pendidikan online dengan metode kelas berbasis tradisional (tatap muka). Walaupun siswa masih mendatangi sekolah secara fisik bersama  pengajar, kelas tatap muka ini dikombinasikan dengan konten serta penyamp aian yang dimediasi oleh perangkat elektronik untuk meningkatkan pengalaman belajar mengajar [1]. Model ini mengombinasikan  pembelajaran tatap muka pada lokasi fisik yang sama dengan pembelajaran online  dan memerlukan keseimbangan yang tepat [2].  Sejak terjadinya pandemi COVID-19, memaksa proses Pendidikan menerapkan hal -hal baru dalam pembelajaran campuran seperti siswa belajar dari rumah. Perhatian kemudian dialihkan kepada Pendidikan online serta digital di masa krisis pandemi [3][4]. Berbagai penemuan dari bermacam riset tentang pendidikan kooperatif serta transformatif, metode belajar baru, serta visualisasi dengan mempraktikkan teknologi yang bisa diakses, fleksibel, serta ter jangkau dalam pembelajaran dan mengintegrasikan kegiatan offline serta online menjadi prioritas utama dalam pembelajaran campuran [5]. Pembelajaran  campuran sendiri dianggap sebagai solusi yang paling ideal pada saat pandemi sebagai 
pengganti desain pembelajaran. Hal ini didukung dengan pendidikan berbasis praktik yang substansial adalah desain instruksional yang sukses. Pembelajaran campuran juga se jalan dengan kecenderungan alami manusia untuk belajar dari berbagai sumber walaupun  tingkat kebaruannya terlalu bervariasi serta infrastrukturnya  yang berkembang teramat pesat [6]. Namun  pembelajaran campuran dalam pendidikan berkembang pesat saat terjadi pandemi. Transisi ini menjadi pekerjaan yang menantang, terutama di masyarakat yang kurang mampu di mana sumber dayanya sedikit dan lembaganya tidak dilengkapi dengan baik untuk melakukan perubahan [7][8].  Menurut penelitian di India, teknologi berbasis teknologi informasi dan komunikasi (TIK) telah mengubah seluruh metodologi pengajaran menjadi pedagogi yang berpusat pada peserta didik, di mana keterampilan teknologi harus menjadi kualifikasi penting bagi guru/pendidik dan peserta didik. Pembelajaran campuran dapat menjadi pilihan yang layak untuk memberikan pendidikan dalam konteks India abad ke -21. Selama pandemi, telah membuka pikiran orang terhadap informasi pembelajaran campuran [5]. Menurut penelitian lain, pembelajaran online harus dikemas dengan cara yang sama seperti pembelajaran di kelas tradisional , alternatifnya beralih ke pembelajaran campuran dengan beberapa modifikasi seperti pertemuan tatap muka melalui konferensi video. Membangun saluran komunikasi yang aktif dan menarik akan membantu proses pengajaran. Proses dan evaluasi diri keduanya dipertimbangkan saat mengevaluasi  pembelajaran. Ketika dilakukan di perangkat seluler atau smartphone yang terhubung ke internet, proses pembelajaran ini harus seefektif mungkin [9]. Pendekatan pembelajaran campuran telah diperdebatkan dalam hal kualitas pendidikan. Pengajar memiliki beberapa masalah dalam pembelajaran campuran karena harus menyesuaikan diri dengan mengajar dan mengembangkan kemampuan teknis, mengubah tanggung jawab pedagogis, atau menangani peluang yang berhubungan dengan pembelajaran campuran [10][11].  Penelitian ini bertujuan mengetahui pendapat pengguna Twitter tentang pembelajaran campuran. Hal ini dimaksudkan agar temuan pada penelitian ini menjadi penting untuk mendapatkan  opini publik  terhadap pembelajaran campuran melalui evaluasi pengguna Twitter.  Beberapa studi tentang penggalian opini  pada Twitter  telah pernah dilakukan [12][13][14][15][16] sehingga didapatkan sentimen berdasarkan kata kunci di  Twitter. Istilah 'pembelajaran campuranâ€™ atau â€˜blended learningâ€™  yang digunakan dalam penelitian ini  menjadi kata kunci. Pengumpulan data  mengguna kan Twitter streaming Drone Emprit Academic [17] pada September 2021 untuk mendapatkan data yang diperlukan. Data Twitter dianalisis menggunakan algoritma Naive Bayes untuk mengetahui persepsi publik di Twitter  selama periode tersebut . Temuan penelitian ini dimaksudkan untuk menghasilkan model kategorisasi yang tepat, memungkinkan model  pembelajaran campuran  dievaluasi untuk digunakan secara berkelanjutan 
sebagai model  pengajaran di masa depan.   

2. METOD OLOGI PENELITIAN  
2.1 Pembelajaran Campuran  
Pembelajaran campuran adalah kombinasi dari mode instruksional, desain instruksional, dan media pengajaran . 
Ini menggabungkan elemen konvensional dan modern , menghasilkan pengalaman belajar yang sinergis. Selama beberapa dekade, gagasan tersebut telah ada dengan banyak klasifikasi, mengacu pada lingkungan pendidikan yang sebanding tetapi sedikit perbedaan semantik. Ungkapan """"pembelajaran campuran"""" adalah klasifikasi yang relatif baru  namun  keragaman nama dan varian terkadang menjad i penyebab kesalahpahaman bahkan kesalahan informasi [6]. Model pembelajaran campuran  erat kaitannya dengan Pendidikan 4.0 karena kegiatan pembelajaran secara fisik  dan virtual terhubung dengan teknologi siber [18]. Pembelajaran campuran dianggap cara terbaik untuk menggabungkan keuntungan dari sistem pembelajaran online dan tatap muka sambil juga mengatasi kelemahan dari kedua sistem tersebut. Menggunakan multimedia pada komputer, ponsel, dan perangkat elektronik lainnya, siswa dapat belajar baik tatap muka maupun online dengan cara yang seimbang. Pengajar dan siswa dapat berkomunikasi meskipun ada jarak di antara mereka. Hal ini memungkinkan siswa untuk bertemu secara langsung, mengevaluasi kekurangan materi pembelajaran online, dan mengatasi berbagai hambatan penyerapan siswa yang mungkin timbul selama proses pembelajaran [19]. 
2.2 Twitter Sentiment Analysis  
Pesan teks pendek yang dikenal sebagai twit adalah metode  komunikasi utama di platform media sosial Twitter. Platform Twitter yang dipenuhi komentar dapat mempengaruhi kemampuan pembentukan opini. Pada twit bisa dilakukan  analisis sentimen dengan mengidentifikasi dan mengategorikan  polaritas sebuah teks untuk menentukan apakah dokumen tertentu memiliki nilai positif atau negatif sesuai dengan kategorisasi yang ditentukan [20]. Mayoritas pengguna Twitter bebas mengekspresikan pandangan mereka tentang banyak hal.  Studi ini menggali komentar dari media sosial Twitter untuk membuat model pengklasifikasi pengalaman pembelajaran campuran menggunakan teknik penambangan teks untuk mendapatkan pandangan asli tentang pengalaman dan kepuasan pembelajaran campuran. Gambar 1 menunjukkan banyak proses yang terlibat dalam pengumpulan dokumen, partisi data menjadi pelatihan dan pengujian, pra -pemrosesan data dalam bentuk bag words , penilaian se ntimen, klasifikasi data, evaluasi model pengklasifikasi, dan pemilihan sentimen terbaik. Semua proses dilakukan dengan bantuan software Rapid Miner menggunakan set data Drone Emprit Academic (DEA) [21] 
Gambar 1 . Tahap Penelitian [22]  
Aplikasi (API) streaming DEA. Pencarian dilakukan dengan menggunakan kata kunci â€˜pembelajaran campuranâ€™ dan â€˜ blended learningâ€™. Kata kunci pembelajaran campuran menghasilkan sekitar 4200 twit. Semua penilaian disaring untuk kesalahan ejaan dan emoticon  yang dapat mengubah hasil sebelum digunakan. Pembersihan  kalimat dilakukan untuk menghilangkan informasi yang tidak relevan atau ambigu yang dapat mempengaruhi analisis sentimen. Contohnya dalam hal ini seperti retweet , emoticon , dan hyperlink  dalam teks ulasan, tagar, skrip, dan iklan [23]. 
2.3 Algoritma Naive Bayes  
Algoritma Naive Bayes merupakan metode dalam melakukan klasifikasi teks dan penambangan data dalam analisis sentimen. Fitur utamanya adalah menghasilkan hipotesis yang kuat pada setiap kondisi atau peristiwa. Pendekatan algoritma Bayes menggunakan persamaan [23][24][25]: 
ð‘ƒ(ð‘Œ|ð‘‹)=ð‘ƒ(ð‘¥|ð‘¦)ð‘ƒ(ð‘Œ)
ð‘ƒ(ð‘‹)                                  (1) 
Dalam persamaan (1) Y merupakan kelas spesifik, X merupakan data pada kelas yang belum diketahui, P(Y|X) merupakan probabilitas hipotesis berdasarkan kondis i, sedangkan P(Y) dan P(X|Y) merupakan probabilitas sebelumnya. Dalam klasifikasi Naive Bayes, persamaan 1 kemudian dikembangkan lagi menjadi persamaan (2) berikut:  
ð‘ƒ(ð‘Œ|ð‘‹1,ð‘‹2,â€¦ð‘‹ð‘›)=ð‘ƒ(ð‘‹1,ð‘‹2,â€¦ð‘‹ð‘› |ð‘Œ)ð‘ƒ(ð‘Œ)
ð‘ƒ(ð‘‹1,ð‘‹2,â€¦ð‘‹ð‘›)= ð‘ƒ(ð‘‹1|ð‘Œ)ð‘ƒ(ð‘‹2|ð‘Œ)â€¦ð‘ƒ(ð‘‹ð‘› |ð‘Œ)ð‘ƒ(ð‘Œ)
ð‘ƒ(ð‘‹1,ð‘‹2â€¦ð‘‹ð‘›)                       (2) 
Dimana P(Yâ”‚X1,X2,â€¦Xn) adalah  hasil hitung dari semua probabilitas posterior pada nilai X untuk  semua nilai di Y . NaÃ¯ve Bayes membuat prediksi berdasarkan probabilitas maksimum yang ditunjukkan  pada persamaan (3).  
ð‘ƒ(ð‘‹ð‘–|ð‘Œ)=ð‘ð‘–ð‘+1
ð‘ð‘+ð‘                                  (3)      
3. HASIL DAN PEMBAHASAN  
API Streaming publik DEA digunakan untuk melakukan pencarian menggunakan istilah """"pembelajaran campuran"""" dan â€˜blended learningâ€™. Pada September 2021, prosedur tersebut menghasilkan 4.200 twit. Tabel 1 menggambarkan beberapa twit yang dikumpulkan  dalam Bahasa Inggris yang kemudian diterjemahkan ke Bahasa.  
Tabel. 1  Pengambilan Data Menggunakan Kata Kunci â€˜Pembelajaran Campuranâ€™  
Setelah pra-pemrosesan dataset , didapatkan 44,51 persen adalah sentimen yang positif, sedangkan 45,80 persen adalah sentimen negatif. Sentimen ini terlihat imbang dari sisi ulasan pada masing -masing sentimen. Sebagian besar umpan balik positif berasal dari siswa yang menyukai pembelajaran campuran karena memungkinkan mereka untuk mengontrol jadwal mereka, meningkatkan kenyamanan pelatihan, dan menghemat uang. Selain itu, sebagian besar evaluasi percaya bahwa pembelajaran campuran lebih bermanfaat bagi siswa. Sementara sebagian besar umpan balik nega tif lebih mengarah kepada pendidik. Metode pembelajaran  campuran yang berbeda dengan  metode pengajaran tatap muka konvensional mungkin sulit bagi pendidik  tertentu. Tidak ada yang tahu seberapa efektif siswa menggunakan waktu yang disisihkan  ketika  pembela jaran online.   
Gambar 2 . Proses Crawling Pada  Rapid Miner  
Nama Pengguna  Twit  
@VSG_Beacon  
@theedijester   
@liz_beth24  
@Sio_and_Tell  Saya suka bagaimana UNIS mencoba menggambarkan 'pembelajaran campuran' sebagai sesuatu yang sebenarnya diinginkan siswa daripada pembelajaran langsung  
Pembelajaran campuran adalah kode untuk pembelajaran digital yang tidak berfungsi  Bagi saya, pembelajaran campuran terlihat seperti siswa diberi banyak kesempatan dan platform untuk menunjukkan pen guasaan di suatu bidang Pembelajaran campuran  tidak boleh diabaikan. Ini bukan pilihan yang mudah atau 'ringan' bagi siapa pun, tetapi ini membuka pintu untuk pendidikan masa depan  bagi banyak orang dan itu harus dilihat sebagai hal yang berharga. search Twitter agar terhubung ke Twitter dengan memasukkan kode akses yang disediakan dari Twitter API. Hasil pengambilan data menggunakan Rapidminer ditunjukkan pada tabel 1 dimana memiliki atribut username dan teks.  
Table 1. Sentimen Tes Data Analisis  
Sentiment  Confident  
(Positive)  Confident  
(Neutral)  Confident  
(Negative)  Text 
Positive   
Negative  
Negative  
Positive  
0.9326  
0.0093  
0.0081  
0.0093  
0.0060  
0.0030  
0.0052  
0.0069   
0.0043  
0.8544  
0.9387  
0.9533  
Saya suka bagaimana UNIS mencoba menggambarkan 'pembelajaran campuran' sebagai sesuatu yang sebenarnya diinginkan siswa daripada pembelajaran langsung   Pembelajaran campuran adalah kode untuk pembelajaran digital yang tidak berfungsi  
Bagi saya, pembelajaran campuran terlihat seperti siswa diberi banyak kesempatan dan platform untuk menunjukkan penguasaan di suatu bidang   
Pembelajaran campuran tidak boleh diabaikan. Ini bukan pilihan yang mudah atau 'ringan' bagi siapa pun, tetapi ini membuka pintu untuk pendidikan masa depan bagi banyak orang dan itu harus dilihat sebagai hal yang berharga  
Seperti yang terlihat pada Tabel 2 di atas terlihat sentimen negatif dan positif tidak berbeda terlalu jauh pada periode September 2021 terkait pembahasan pembelajaran campuran di Twitter. Model analisis sentimen dibangun berdasarkan data training yang disiapkan dan pengujian data untuk menentukan sentimen terhadap pembelajaran campuran. Menurut penelitian di bulan September tahun 2021,  sebesar  45,80 persen pengguna memiliki pendapat yang tidak mendukung terhadap  pembelajaran campuran, sementara 44,51 persen memiliki  pendapat yang positif seperti yang ditunjukkan pada Gambar 3 di bawah.  
Gambar 3. Tren Sentimen dan Hasil Sentimen Pada September 2021  

4. KESIMPULAN  
Dalam penelitian ini, analisis sentimen dilakukan pada bulan September 2021 dengan memanfaatkan data Twitter dan 'pembelajaran campuran' atau â€˜blended learningâ€™ sebagai kata kunci. Selama periode tersebut, 44,51 persen pengguna menyatakan positif, 45,80 persen negatif, dan 9,69 persen netral. Hasil positif menunjukkan siswa, pendidik, dan institusi penyelenggara lebi h baik untuk menerapkan metode pembelajaran campuran di masa depan. Hasil juga menunjukkan bahwa pembelajaran campuran tetap menjadi bagian penting dari proses pendidikan  di masa pandemi . Ke depan, analisis sentimen terkait pembelajaran campuran dapat diti ngkatkan dengan meningkatkan kuantitas dan keragaman sumber data yang digunakan, seperti Facebook, forum, dan blog. Selanjutnya, persepsi pembelajaran campuran dapat diperluas dengan memasukkan komponen atau kualitas tambahan, seperti jenis kelamin, usia, dan area, untuk mempelajari lebih dalam faktor-faktor penting yang memengaruhi pengalaman dan kepuasan pembelajaran campuran.  

REFERENCES    
[1] R. Saboowala and P. Manghirmalani Mishra, â€œReadiness of In -service Teachers Toward a Blended Learning Approach 
10.1177/00472395211015232.  
[2] S. Lane, J. G. Hoang, J. P. Leighton, and A. Rissanen, â€œEngagement and Satisfaction: Mixed -Method Analysis of Blended Learning in the Sciences,â€ Can. J. Sci. Math. Technol. Educ. , vol. 21, no. 1, pp. 100 â€“122, Mar. 2021, doi: 10.1007/s42330 -021-00139 -5. 
[3] I. G. M. Karma, I. K. Darma, and I. M. A. Santiana, â€œBlended Learning is an Educational Innovation and Solution During the COVID -19 Pandemic,â€ 2021, doi: 10.2139/ssrn.3774907.  
[4] M. Giatman, S. Haq, and Y. F. Pratama, â€œEffectivity of Online Learning Teaching Materials Model on Innovation Course of Vocational and Technology Education,â€ J. Phys. Conf. Ser. , vol. 1387, no. 1, p. 12131, 2019.  
[5] R. Bordoloi, P. Das, and K. Das, â€œPerception towards online/blended learning at the time of Covid -19 pandemic:  an academic analytics in the Indian context,â€ Asian Assoc. Open Univ. J. , vol. 16, no. 1, pp. 41 â€“60, May 2021, doi: 
10.1108/AAOUJ -09-2020 -0079.  
[6] K. A. Jones and R. S. Sharma, Higher Education 4.0 . Singapore: Springer Singapore, 2021.  
[7] C. Bosch, â€œA Blended Learning Toolbox for Educators,â€ in Advances in Educational Technologies and Instructional 
Design (AETID) Book Series , IGI Global, 2021, pp. 1 â€“23. 
[8] R. H. Sakti, S. Sukardi, M. Giatman, E. Nazar, W. Wakhinuddin, and W. Waskito, â€œFlip ped Classroom -Computer Based Instruction untuk Pembelajaran Pada Revolusi Industri 4.0: Rancang Bangun dan Analisis Kebutuhan,â€ Edumatic J. 
Pendidik. Inform. , vol. 4, no. 1, pp. 63 â€“72, 2020.  
[9] Ambiyar, R. Efendi, Waskito, I. Rojiyyah, and R. A. Wulandari , â€œNeed Analysis for Development of Web -Based Flipped Classroom Learning Models in Vocational Education,â€ J. Phys. Conf. Ser. , vol. 1764, no. 1, p. 012103, Feb. 2021, doi: 10.1088/1742 -6596/1764/1/012103.  
[10] Ganefri, A. Yulastri, Ambiyar, Jeprimansyah, a nd Suryadimal, â€œNeed analysis development of learning model based on production in multimedia materials in higher education,â€ J. Phys. Conf. Ser. , vol. 1481, p. 012114, Mar. 2020, doi: 10.1088/1742 -6596/1481/1/012114.  
[11] E. P. Sari, S. Sukardi, E. Tasrif , and A. Ambiyar, â€œOptimalisasi Penggunaan E -learning dengan Model Delone dan McClean,â€ J. Educ. Technol. , vol. 4, no. 2, pp. 141 â€“149, 2020.  
[12] Samsir, Ambiyar, U. Verawardina, F. Edi, and R. Watrianthos, â€œAnalisis Sentimen Pembelajaran Daring Pada Twitter di Masa Pandemi COVID -19 Menggunakan Metode NaÃ¯ve Bayes,â€ J. Media Inform. Budidarma , vol. 5, no. 1, pp. 157 â€“163, 2021, doi: 10.30865/mib.v5i1.2604.  
[13] S. H. Sahir, R. S. Ayu Ramadhana, M. F. Romadhon Marpaung, S. R. Munthe, and R. Watrianthos, â€œOnlin e learning sentiment analysis during the covid -19 Indonesia pandemic using twitter data,â€ IOP Conf. Ser. Mater. Sci. Eng. , vol. 1156, no. 1, p. 012011, 2021, doi: 10.1088/1757 -899x/1156/1/012011.  
[14] R. Watrianthos, S. Suryadi, D. Irmayani, M. Nasution, a nd E. F. S. Simanjorang, â€œSentiment analysis of traveloka app using naive bayes classifier method,â€ Int. J. Sci. Technol. Res. , vol. 8, no. 7, pp. 786 â€“788, 2019, doi: 
10.31227/osf.io/2dbe4.  
[15] D. Irmayani, F. Edi, J. M. Harahap, and ..., â€œNaives Bayes Al gorithm for Twitter Sentiment Analysis,â€ J. Phys. â€¦ , 2021, [Online]. Available: https://iopscience.iop.org/article/10.1088/1742 -6596/1933/1/012019/meta.  
[16] Mesran et al. , Merdeka Kreatif di Era Pandemi Covid -19 Suatu Pengantar . Medan: Green Press, 2020.  
[17] I. Fahmi, â€œDrone Emprit Academic: Software for social media monitoring and analytics,â€ Drone Emprit Academic , 2018. https://academic.droneemprit.id/ (accessed Sep. 26, 2021).  
[18] S. Fitri and C. L. Zahari, â€œThe implementation of blended learning to i mprove understanding of mathematics,â€ J. Phys. Conf. Ser. , vol. 1188, p. 012109, Mar. 2019, doi: 10.1088/1742 -6596/1188/1/012109.  
[19] Z. Faraniza, â€œBlended learning best practice to answers 21 st century demands,â€ J. Phys. Conf. Ser. , vol. 1940, no. 1, p.  012122, Jun. 2021, doi: 10.1088/1742 -6596/1940/1/012122.  
[20] G. A. Ruz, P. A. HenrÃ­quez, and A. MascareÃ±o, â€œSentiment analysis of Twitter data during critical events through Bayesian networks classifiers,â€ Futur. Gener. Comput. Syst. , vol. 106, pp. 92 â€“104, May 2020, doi: 
10.1016/j.future.2020.01.005.  
[21] I. Fahmi, â€œDrone Emprit Academic: Software for social media monitoring and analytics,â€ Drone Emprit Academic , 2018. academic.droneemprit.id (accessed Sep. 21, 2021).  
[22] Samsir, Ambiyar, U. Verawardina,  F. Edi, and R. Watrianthos, â€œAnalisis Sentimen Pembelajaran Daring Pada Twitter di Masa Pandemi COVID -19,â€ J. MEDIA Inform. BUDIDARMAJURNAL MEDIA Inform. BUDIDARMA , vol. 5, no. 10, 
pp. 174 â€“179, 2021, doi: 10.30865/mib.v4i4.2293.  
[23] Samsir et al. , â€œNaive s Bayes Algorithm for Twitter Sentiment Analysis,â€ J. Phys. Conf. Ser. , vol. 1933, no. 1, p. 012019, 2021, doi: 10.1088/1742 -6596/1933/1/012019.  
[24] C. A. P. Dita, P. Chairunisyah, and M. Mesran, â€œPenerapan Naive Bayesian Classifier Dalam Penyeleksian Beasiswa PPA,â€ J. Comput. Syst. Informatics , vol. 2, no. 2, pp. 194 â€“198, 2021.  
[25] K. S. Nugroho, I. Istiadi, and F. Marisa, â€œNaive Bayes classifier opt imization for text classification on e-government using particle swarm optimization,â€ J. Teknol. dan Sist. Komput. , vol. 8, no. 1, pp. 21 â€“26, Jan. 2020, doi: 10.14710/jtsiskom.8.1.2020.21 -26. ",Analisis Sentimen,Naive Bayes,"komentar media sosial, data twitter",akurasi
Analisis Sentimen Pro dan Kontra Masyarakat Indonesia tentang Vaksin COVID-19 pada Media Sosial Twitter,"Analisis Sentimen Pro dan Kontra Masyarakat Indonesia tentang Vaksin COVID-19 pada Media Sosial Twitter

Fajar Fathur Rachman, Setia Pramana  

Abstract  
In order to accelerate the handling of the spread of COVID -19 in Indonesia, the Government of the Republic of Indonesia has issued a discourse on vaccination for the Indonesian people at the end of 2020.  Although the government has not officially released the schedule or procedure for the vaccinations, the discourse is considered controversial so that it has invited many groups  of people  to give their opinions in various media. T his opinion must be considered as material for evaluation so that the vaccinati on discourse that will be carried out can run well . By utilizing data from social media twitter, this study aims to analyze the public's response to the vaccination discourse by classifying these responses into positive and negative responses. Furthermore,  there will also be grouping of public opinion using the Latent Dirichlet Allocation (LDA) method to find out what topics of conversation are often discussed by the community regarding the vaccination discourse . The results of the analysis show tha t the pu blic gives more positive  responses  to the discourse (30%) than the negat ive responses  (26%) . The words with the most frequent appearances also indicate that there are more words with a positive  sentime nt than the words with a negative  sentiment. The LDA model that was built can also capture the topics discussed by the community regarding the vaccination discourse, such as public talks about vaccine controversies which are considered hasty, halal certification of vaccines and public doubts about the quality of the vaccine to be used.  
 
Keyword: COVID-19, Latent Dirichlet Allocation (LDA), sentiment analysis, twitter, vaccine   
 
 
Abstrak  
Dalam rangka melakukan percepatan penanganan penyebaran COVID-19 di Indonesia, Pemerintah Republik Indonesia telah mengeluarkan wacana vaksinasi untuk masyarakat Indonesia pada akhir tahun 2020 mendatang. Meskipun pemerintah belum secara resmi merilis jadwal maupun prosedur vaksinasi yang akan dilakukan, wacana tersebut dinilai kontroversial sehingga mengundang banyak kalangan untuk memberikan pendapatnya di berbagai media. Pendapat tersebut haruslah dipertimbangkan sebagai bahan evaluasi sehingga rencana vaksinasi yang akan dilakukan dapat berjalan dengan baik. Dengan memanfaatkan data dari media sosial twitter, peneli tian ini bertujuan untuk menganalisis respon masyarakat terhadap wacana vaksinasi dengan cara mengklasifikasikan respon tersebut ke dalam respon positif dan negatif. Selanjutnya juga akan dilakukan pengelompokkan opini masyarakat menggunakan metode Latent Dirichlet Allocation (LDA) untuk mengetahui topik pembicaraan yang sering dibahas 
oleh masyarakat terkait dengan wacana vaksinasi tersebut. Hasil analisis menunjukkan bahwa masyarakat lebih banyak memberikan respon positif terhadap wacana tersebut (30%) di bandingkan dengan respon negatifnya (26%). Kata-kata bersentimen yang paling sering muncul juga mengindikasikan lebih banyak kata yang bersentimen positif dibandingkan dengan kata yang bersentimen negatif. Model LDA yang dibangun juga dapat menangkap topik  yang dibicarakan masyarakat terkait wacana vaksinasi tersebut seperti pembicaraan masyarakat mengenai kontroversi vaksin yang dinilai terburu-buru, sertifikasi halal vaksin dan keraguan masyarakat terhadap kualitas vaksin yang akan 
digunakan.  
 
Kata Kunci : COVID-19, vaksin, analisis sentimen, Latent Dirichlet Allocation , twitter  
 
 
Pendahuluan  
Wabah penyakit baru yang disebabkan oleh virus korona (2019-nCoV) atau yang biasa disebut dengan COVID -19 ditetapkan secara resmi sebagai pandemi global oleh World Health Organization (WHO) pada tanggal 11 Maret 2020 lalu (1). Meskipun pusat penyebaran virus tersebut pada akhir tahun 
2019 lalu berada di Kota Wuhan, China, kini virus tersebut telah tersebar menjangkit ke seluruh masyarakat dunia dengan jumlah kasus sebanyak lebih dari 41,5 juta kasus dan jumlah kematian sebanyak lebih dari 1,1 juta jiwa per tanggal 23 Oktober 2020  (2). Di Indonesia sendiri, Presiden Joko Widodo mengumumkan kasus pertama COVID -19 masuk ke Indonesia yaitu pada tanggal 2 Maret 2020 lalu, 
yang menjangkit 2 orang Warga Negara Indonesia asal Depok, Jawa Barat (3). Berawal dari kasus tersebut, jumlah kasus masyarakat Indonesia yang terjangkit virus korona terus bertambah setiap harinya, hingga per tanggal 26 Oktober 2020 lalu, tercatat sebanyak lebih dari 392 ribu kasus deng an tingkat kematian sebanyak lebih dari 13 ribu jiwa (4). Kondisi demikian memberikan dampak langsung kepada jutaan bahkan seluruh masyarakat dunia, sebagai akibat dari diberlakukannya protokol kesehatan yang harus ditetapkan pada seluruh aspek kegiatan, mulai dari pembatasan sosial hingga lockdown  total sehinga menghambat seluruh kegiatan masyarakat. Efek lanjutan dari COVID-19 ini berpotensi membawa tantangan besar bagi sistem kesehatan dunia dan memiliki konsekuensi yang luas pada ekonomi global jika penyebaran virus tidak dikendalikan secara efektif (5). Melihat pesatnya penyebaran COVID-19 dan bahaya yang akan muncul jika tidak segera ditangani, salah satu cara yang sangat mungkin untuk mencegah penyebaran virus ini ada lah dengan mengembangkan vaksin (5). Vaksin tidak hanya melindungi mereka yang divaksinasi tetapi juga masyarakat luas dengan mengurangi pen yebaran penyakit dalam populasi (6). Meskipun tidak ada vaksin untuk SARS dan MERS yang ditem ukan, vaksin COVID-19 dapat ditemukan terlebih dahulu. 
Pengembangan vaksin yang aman dan efektif sangat penting dilakukan karena diharapkan dapat menghentikan penyebaran dan mencegah penyeb aran penyakit di masa mendatang (5). Selain itu, karena virus menyebar dengan sangat cepat maka diperlukan vaksin yang dapat diterapkan dalam waktu singkat sehingga dapat meminimalisir dampaknya.  Dalam menyikapi hal tersebut, Pemerintah Indonesia juga turut aktif dalam rencana ke giatan vaksinasi yang akan diberikan kepada masyarakatnya. Presiden Joko Widodo pada tanggal 5 Oktober 
2020 lalu meresmikan Peraturan Presiden (Perpres) Republik Indonesia Nomor 99 Tahun 2020 Tentang Pengadaan Vaksin dan Pelaksanaan Vaksinasi Dalam Rangka Penanggulangan Pandemi Corona Virus Disease 2019 (COVID -19) untuk mengatur kewenangan pemerintah, kementerian/lembaga dan para pejabatnya dalam rencana kegiatan vaksinasi (7). Perpres tersebut kem udian langsung ditindaklanjuti oleh seluruh elemen yang terlibat, misalnya seperti bertolaknya Menteri Luar Negeri Retno Lestari, Menteri Badan Usaha Milik Negara (BUMN) Erick Tohir dan tim Kementrian Kesehatan Indonesia ke 
Inggris & Swiss pada 12 Oktober lalu dalam rangka melakukan  kerjasama internasional untuk pengadaan vaksin di Indonesia (8). Hasilnya, muncul wacana vaksinasi yang bersumber dari pejabat pemerintahan yang mengatakan bahwa kegiatan vaksinasi akan mulai diberikan kepada masyarakat Indonesia pada bulan November mendatang (9â€“11). Rencana kegiatan vaksinasi tersebut haruslah mempertimbangkan segala aspek, mulai dari aspek kelayakan vaksin yang akan digunakan, resiko pasca pemakaian, sampai tahapan & prosedur dari pemberian va ksin hingga nantinya sampai ke masyarakat. Semua aspek tersebut haruslah dipertimbangkan secara terperinci agar rencana kegiatan vaksinasi dapat berjalan dengan baik dan terhindar dari hal-hal yang justru akan merugikan. Rencana kegiatan vaksinasi tersebut  juga haruslah mempertimbangkan berbagai masukan, diataranya adalah dengan melihat bagaimana respon dan opini masyarakat terhadap wacana vaksinasi tersebut.  Masyarakat memberikan respon dan opininya di berbagai media. Salah satu media yang banyak digunakan oleh masyarakat untuk memberikan pendapatnya terhadap sesuatu adalah media sosial. Media 
sosial kini seolah merupakan suatu hal yang wajib dimiliki oleh seluruh masyarakat. Berdasarkan data dari Global Digital Statistic â€œDigital, Social & Mobile in 2019â€  di We Are Social (2019), pada tahun 2019 jumlah pengguna media sosial di Indonesia yaitu berjumlah lebih dari 150 juta pengguna. Salah satu media sosial yang paling banyak digunakan oleh masyarakat Indonesia adalah media sosial twitter, yang mencakup lebih dari 52 persen dari total pengguna media sosial di Indonesia  (12). Hal tersebut 
menunjukkan adanya peluang sumber data yang sangat besar yang dapat dimanfaatkan untuk menghasilkan suatu knowledge yang bermanfaat.  Pemanfaatan data yang bersumber dari media sosial merupakan suatu terobosan baru yang dapat dijadikan sebagai alternatif sumber data sebaga i pengganti survey tradisional. Pengumpulan data respon dan opini masyarakat secara langsung/ real time menggunakan survei  tradisional dinilai sulit untuk dilakukan mengingat adanya proses tahapan yang diperlukan sehingga dalam prosesnya menjadi lama. Terlebih lagi, Indonesia sebagai salah satu negara berkembang dinilai ma sih sulit untuk mendapatkan respon dan opini publik secara langsung karena mempunyai jumlah penduduk yang sangat banyak dan wilayah negara yang sangat luas. Belum lagi ditambah adanya sistem tahapan pengaduan atau pemberian pendapat publik yang berjenjang,  sehingga prosesnya menjadi lama.  Pengumpulan data melalui media sosial dinilai dapat memberikan efisiensi dalam segala hal 
apabila dibandingkan dengan harus melakukan survey tradisional. Efisiensi tersebut mencakup biaya yang harus dikeluarkan untuk pemerolehan data yang minimal, dapat memperoleh data secara real time , dan menghasilkan data yang mempunyai informasi yang lebih detail untuk menggambarkan opini  masyarakat yang sebenarnya (13). Kegiatan menganalisis respon dan opini masyarakat menggunakan data yang bersumber dari media sosial twitter juga telah banyak dilakukan pada penelitian-penelitian 
sebelumnya, misalnya penelitian yang dilakukan untuk melihat opini masyarakat terhadap kebija kan ganjil genap di India (14) dan melihat bagaimana opini masyara kat terhadap pelayanan LRT di Los Angeles (15), Chicago (13) & KR L Commuter Line di Indonesia (16).   Berdasarkan latar belakang tersebut, maka penelitian ini ingin melihat bagaimana respon & opini masyarakat Indonesia terhadap vaksin COVID-19 dengan menggunakan data yang bersumber dari media sosial twitter. Untuk menjawab permasalahan tersebut, maka penelitian ini akan melakukan analisis sentimen dengan mengklasif ikasikan respon masyarakat tersebut ke dalam sentimen positif & negatif, dan mengelompokkan opini masyarakat terhadap vaksin COVID-19 dengan menggunakan metode Latent Dirichlet Allocation  (LDA).  
 
Metode Penelitian  
Landasan Teori  
1. Analisis Sentimen  
Analisis sentimen atau yang biasa dikenal dengan istilah opinion mining merupakan salah satu cabang penelitian dari text mining yang bertujuan untuk menentukan persepsi atau subjektivitas publik (khalayak) terhadap suatu topik pembahasan, kejadian, ataupun  permasalahan (17). Analisis sentimen adalah suatu tugas klasifikasi yang mengklasifikasikan suatu teks ke dalam orientasi positif atau negatif (18). Secara teknik, analisis sentimen dapat dibagi menjadi empat jenis pendekatan (19), yaitu Machine 
learning approach , Lexicon-based approach , Rule-based approach , dan Statistical model approach . Penentuan polaritas sentimen  pada penelitian ini, menggunakan matching kata berdasarkan kamus leksikon ( Lexicon -based approach ). Ada beberapa tahapan yang dilakukan pada penelitian ini, yakni:  (20) 
1. Menentukan kata bersentimen: setiap kata dalam kalimat akan diberi sebuah nilai yakni bernilai satu (1) untuk kata bersentimen positif dan bernilai negatif satu ( -1) untuk kata bersentimen negatif.  
2. Pemberian skor pada kalimat: skor digunakan untuk menentukan apakah sebuah kalimat bersentimen positif atau bersentimen negatif. Skor kalimat didapat dari  penjumlahan nilai dari kata bersentimen. Nilai dari skor sentimen menentukan sentimen dari sebuah kalimat dengan kondisi sebagai berikut: Jika nilai sentimen  > 0, maka tweets bersentimen positif sentimen < 0 maka tweets bersentimen negatif 
2. Latent Dirichlet Allocation  (LDA)  
Latent Dirichlet Allocation  (LDA) merupakan metode topic modeling  yang paling populer saat ini. LDA muncul sebagai salah satu metode yang dipilih dalam melakukan analisis pada dokumen yang berukuran sangat besar. LDA dapat digunakan untuk meringkas, melakukan klasterisasi, menghubungkan maupun memproses data yang sangat besar karena LDA menghasilkan daftar topik yang diberi bobot untuk masing -masing dokumen. Dalam LDA, dokumen -dokumen merupakan objek yang dapat diamati, sedangkan topik, distribusi topik per -dokumen, penggolongan setiap kata pada topik per -dokumen merupakan struktur tersembunyi. Maka dari itu, algoritma ini dinamakan Latent Dirichlet Allocation  (21). LDA merupakan 
model probabilistik generatif dari kumpulan tulisan yang disebut corpus. Ide dasar yang diusulkan metode LDA adalah setiap dokumen direpresentasikan sebagai campuran acak atas topik yang tersembunyi, yang mana set iap topik memiliki karakter yang ditentukan berdasarkan distribusi kata -kata 
yang terdapat di dalamnya (22).Sebagai metode unsupervised, LDA membutuhkan pendefinisian jumlah topik yang akan dihasilkan oleh model. Salah satu teknik utama yang digunakan untuk melihat jumlah topik terbaik yang akan digunakan untuk membangun model LDA adalah dengan melihat topic coherence  (23). Topic coherence  merupakan teknik yang berbasis pada kemudahan menginterpretasikan output pada topik yang dihasilkan.   
Metodologi  
1. Metode Pengumpulan Data  
Pengumpulan data respon & opini masyarakat Indonesia terhadap vaksin COVID -19 dilakukan dengan menggunakan teknik web scraping  pada media sosial twitter dalam bentuk tweets . Kegiatan web scraping tersebut dilakukan dengan menggunakan API twitter dengan menggunakan package  â€˜rtweetâ€™ (24).  â€˜rtweetâ€™ merupakan package yang dirancang untuk dapat mengumpulkan dan mengatur data twitter 
menggunakan API twitter dari aplikasi R (25,26). Kata kunci yang digunakan untuk menjaring respon & opini masyarakat terhadap vaksin COVID -19 dalam proses web scraping  tersebut adalah menggunakan dua kata kunci yaitu â€œVaksin Covidâ€ dan â€œVaksin Coronaâ€. Kata kunci yang digunakan dinilai dapat menjaring semua opini masyarakat Indonesia terhadap vaksin COVID -19 di media sosial twitter. Data tweets  yang diambil yaitu  tweets  yang diposting di media sosial twitter pada rentang tanggal 25 Oktober -3 November 2020  karena adanya keterbatasan pengumpulan data.   
2. Metode Persiapan Data  
Dari tweets  yang terambil, dilakukan penyaringan data/filter data  dengan cara   menghapus tweets  yang bersumber dari akun selain akun masyarakat. Kegiatan ini mengacu kepada penelitian yang dilakukan oleh Luong & Houston, 2018 (15) yang mengklasifikasikan akun tweets  ke dalam akun pemerintah, layanan, sekolah, perusahaan, ag en transportasi umum, dan masyarakat. Pada penelitian ini, 
peneliti menghapus tweets  yang bersumber dari akun selain akun masyarakat , dengan cut off  jumlah tweets  sebanyak 20 tweets . Selanjutnya, dilakukan kegiatan persiapan data/ preprocessing  untuk mempersiapkan data agar siap untuk dianalisis. Kegiatan preprocessing  tersebut meliputi tahapan pembersihan tweets  terhadap unsur-unsur yang tidak dibutuhkan dalam analisis, yaitu delete duplicate atau menghapus tweets respon & opini masyarakat yang sama percis, delete URL  atau menghapus link yang terdapat pada tweets , menghapus  mentions & hastags , menghapus emoji, menghapus punctuation , melakukan normalisasi kata, menghapus kata yang tidak penting ( stopwords removal ), dan mengubah format tulisan menjadi huruf kecil. Tahapan normalisasi kata berguna untuk mentransformasi kata singkatan, typo, dan kata berlebih menjadi sebuah kata yang formal. Kamus yang digunakan tersebut  menggunakan â€˜kamus alayâ€™ yang dibuat oleh Salsabila, 2018 (27). Penghapusan kata yang tidak penting ( stopwords ) berguna untuk mengurangi waktu sistem dalam merunning  data. Kamus stopwords  yang digunakan pada penelitian ini menggunakan kamus yang dibuat oleh Tala, 2013 (28). Tahapan preprocessing merupakan tahapan yang paling penting dalam penelitian yang menggunakan data hasil text mining , karena pada tahapan ini sangat menentukan hasil analisis yang akan didapatkan.                                                                                                                                         3. Metode Analisis Data  
1. Analisis sentimen  
Kegiatan mengklasifikasikan tweets atau analisis sentimen pada penelitian ini dilakukan dengan metode lexicon-based atau berbasis kamus postif-negatif. Kamus positif-negatif yang digunakan pada penelitian ini yaitu kamus positif -negatif yang dibuat oleh Liu, Hu & Cheng (29) yang telah 
diterjemahkan ke dalam Bahasa Indonesia & telah dilakukan penyesuaian Bahasa. Kamus ini sebelumnya telah diaplikasikan pada beberapa penelitian sebelumnya (30,31)  
2. Mengelompokkan opini masyarakat  
Mengacu pada penelitian yang dilakukan oleh (14,32) , kegiatan mengelompokkan opini masyarakat di media sosial twitter dilakukan dengan menggunakan metodel Latent Diric hlet Allocation  (LDA). Jumah topik pada penelitian ini ditentukan berdasarkan penghitungan topic coherence  pada dua puluh model awal yang dibentuk. Dua puluh model awal tersebut dibangun dengan mendefinisikan jumlah topik masing-masing dari 1 sampai 20, la lu dipilih satu model dengan jumlah topik terbaik (yang memiliki topic coherence tertinggi), untuk kemudian dilakukan analisis. Model yang akan dipilih yaitu model dengan jumlah topik pada rentang 5-15 topik, agar model yang dibangun tidak menghasilkan topik yang saling timpang tindih antar satu dengan yang lain, dan atau tidak terlalu mendetail sehingga banyak topik yang harus diinterpretasikan (32). 
 
Hasil dan Pembahasan  
Setelah dilakukan pengumpulan data menggunakan teknik web scrapping , diperoleh respon & opini masyarakat terhadap vaksin COVID-19 di media sosial twitter yaitu sebanyak 5583 tweets yang terdiri dari 1009 tweets untuk kata kunci â€œ vaksin coronaâ€ dan 4574 tweets  untuk kata kunci â€œvaksin covidâ€. Jenis tweets yang terambil merupakan tweets  yang sama yang akan muncul ketika dilakukan pencarian kata kunci pada kolom â€˜searchâ€™ yang terdapat pada aplikasi twitter dengan menggunakan kata kun ci yang sama. Twitter menyediakan Application Programming Interface  (API) sehingga memungkinkan siapapun dapat mengakses data informasi web dari web tersebut. Namun, API twitter membatasi penggunanya dalam mengakses data tweets  pada batasan jumlah tertentu . Hal tersebut menjadi suatu halangan bagi para peneliti yang akan menggunakan data tweets dalam melakukan penelitiannya.  Kegiatan menyaring/ filter data dilakukan dengan tujuan untuk hanya menangkap respon & opini yang murni berasal dari masyarakat saja, tidak tercampur dengan opini yang berasal dari akun -akun non-masyarakat seperti akun lembaga, perusahaan, portal berita, dan sebagainya. Sebuah lembaga , tentu saja hanya akan memposting sebuah kiriman tentang perusahaannya dari sisi yang baiknya saja, tidak mungkin sebuah lembaga  akan mengirimkan suatu postingan yang menjelek-jelekkan lembaga nya sendiri. Pada kondisi ini, masyarakat berada pada posisi â€˜tengahâ€™ yaitu tidak berpihak u ntuk menjelek -jelekan ataupun membagus-baguskan, melainkan hanya memberikan aspirasi sesuai  dengan apa yang mereka ketahui & rasakan. Setelah kegiatan filter data , jumlah  tweets  yang siap untuk dilakukan preprocessing dan dianalisis yaitu sebanyak 4941 tweets .  Preprocessing atau tahap persiapan data merupakan tahapan yang paling penting dan krusial dalam 
sebuah penelitian yang menggunakan metode text mining . Sebuah data mentah dari hasil kegiatan text mining  haruslah dipersiapkan terlebih dahulu sesuai dengan kebutuhan analisis sehingga dapat menghasilkan hasil an alisis yang baik. Sebagai contoh, pada penelitian ini salah satu tahapan pada kegiatan  preprocessing  adalah tahapan mengubah semua ukuran  huruf menjadi huruf kecil  (lowercase ). Hal ini sangat penting untuk dilakukan karena kata yang terdiri dari huruf-huruf yang sama akan dibaca oleh sistem sebagai kata yang berbeda  apabila dari huruf -hurufnya memiliki ukuran huruf yang berbeda. Misalnya seperti kata â€˜Senangâ€™ dan â€˜senangâ€™. Apabila hal tersebut dibiarkan, akan memberikan dampak kepada bertambahnya waktu komputer untuk mengolah data. Namun yang terpenting adalah, hasil yang akan didapat akan menjadi rancu atau tidak jelas.  
1. Analisis Sentimen   
Tabel 1.  
Jumlah dan persentase respon  publik terhadap vaksin COVID-19 berdasarkan jenis sentimennya  
Sentimen  Jumlah  Persentase  
Positif  1461  29,6 
Netral  2313  46,8 
Negatif  1167  23,6  
Pada penelitian ini, nilai sentimen untuk setiap tweets  diperoleh dari penghitungan jumlah kata positif & negatif yang terdapat pada suatu tweets . Secara rata-rata,diperoleh nilai sentimen untuk keseluruhan respon masyarakat terhadap vaksin COVID-19 yaitu sebesar 0,055. Hasil tersebut mengindikasikan masyarakat cenderung memberikan respon yang bersentimen positif dibandingkan dengan respon yang bersentimen negatif, meskipun nilai rata-rata yang dihasilkan sangat mendekati nilai 0 yang mengindikasikan banyaknya respon masyarakat yang tidak bersentimen (netral). Hasil tersebut sejalan dengan jumlah tweets berdasarkan jenis sentimen yang diperoleh. Pada Tabel 1 di atas terlihat bahwa masyarakat lebih banyak memberikan respon yang bersentimen positif dibandingkan dengan respon yang bersentimen negatif yaitu sebesar 29,6% banding 23,6%. Hal tersebut dapat diartikan sebagai masyarakat lebih banyak memberik an respon positif terhadap wacana vaksinasi yang dikeluarkan oleh pemerintah dibandingkan dengan respon negatifnya. Banyaknya jenis respon/ tweets  masyarakat yang bersentimen netral mempunyai arti bahwa tweets  masyarakat yang diperoleh tidak hanya terdiri d ari tweets masyarakat yang menyatakan apakah mereka pro atau kontra terhadap wacana vaksinasi tersebut, melainkan juga banyak respon masyarakat lainnya sepeti pengetahuan, harapan, atau pendapat umum mereka. Tabel 2 dibawah menunjukkan bahwa respon masyarakat terhadap wacana vaksinasi ini sangat 
beragam. Sejalan dengan hasil sebelumnya, masyarakat cenderung lebih banyak memberikan kata-kata yang mempunyai sentimen positif dibandingkan dengan kata-kata yang mempunyai sentimen negatif. Respon positif m asyarakat didominasi oleh pernyataan yang mendukung & percaya terhadap wacana vaksinasi yang dikeluarkan oleh pemerintah, seperti meyakini bahwa kegiatan vaksinasi merupakan suatu hal yang penting untuk memutus mata rantai penyebaran virus corona. Selain itu, masyarakat juga dominan mempercayai bahwa vaksin yang akan digunakan telah aman untuk digunakan, bangga dengan kinerja pemerintah dan juga optimis vaksin yang akan diberikan akan dapat terjangkau oleh seluruh masyarakat.  Pada kata bersentimen negatif  yang sering diutarakan oleh masyarakat, terlihat adanya kekhawatiran terhadap wacana vaksinasi yang akan dilakukan oleh pemerintah. Terlihat dari kata-kata yang sering muncul yaitu seperti â€˜tergesa -gesaâ€™, â€˜terburu -buruâ€™, â€˜takutâ€™, dan â€˜meragukanâ€™. Wacana vaksinasi yang direncanakan akan dilakukan pada akhir tahun 2020 nanti dinilai sangat terburu-buru sehingga 
banyak masyarakat yang mengkhawatirkan efektivitas dari vaksin tersebut. Masyarakat khawatir vaksin yang akan diberikan mempunyai efek samping yang justru akan merugikan masyarakat. Selain itu, tidak jarang juga masyarakat yang memberikan pendapat bahwa rencana kegiatan vaksinasi tersebut hanya hoaks dan tidak perlu dilakukan. Status kehalalan vaksin juga menjadi salah satu kata yang sering 
diucapkan oleh masyarakat perihal rencana kegiatan vaksinasi yang akan dilakukan oleh pemerintah.  
Tabel 2.  
Kata yang Sering Diutarakan Masyarakat Berdasarkan Jenis Sentimen  Positif  Negatif  Kata Jumlah  Kata Jumlah  Kata Jumlah  Kata Jumlah  
aman  323 tersedia  47 efek samping  150 meninggal  26 
efektif  109 penting  39 hoax  98 konspirasi  22 
siap 111 menjaga  37 tergesa -gesa 65 meragukan  22 
mandiri  82 mendukung  29 takut  64 kecemasan  21 
gratis  76 halal 26 mati 48 bingung  20 
terbaik  75 dukung  26 tidak perlu  40 kehalalalan  20 
percaya  68 ampuh  23 menolak  37 efektivitas  18 
terjangkau  68 maju  19 terburu -buru 30 korban  18 
2. Pengelompokkan Opini Masyarakat  
Setelah mengetahui bagaimana respon yang diberikan oleh masyarakat di media sosial twitter terhadap wacana kegiatan vaksinasi  yang dilakukan dengan melabelkan tweets ke dalam label positif & negatif, pada pembahasan ini akan dibahas mengenai hal-hal yang ser ing dibicarakan oleh masyarakat 
terhadap wacana vaksinasi tersebut secara keseluruhan.   
Tabel 3 me nunjukkan topik-topik yang dihasilkan dari model LDA yang terbuat. Dari total 20 model LDA awal yang dibangun, model dengan jumlah topik sebanyak 20 buah mempunyai rata-rata nilai topic coherence  yang paling tinggi dibanding model dengan jumlah topik lainn ya. Dapat terlihat pada tabel 3 di atas bahwa banyak sekali topik pembahasan yang sering dibicarakan di media sosial twitter 
perihal vaksin COVID-19. Mulai dari pembicaraan umum seperti kinerja pemerintah dalam kegiatan pengadaan vaksin, berita Negara Brasil yang menolak untuk menggunakan vaksin dari China, sampai pembicaraan mengenai uji klinis & efek samping dari vaksin yang akan digunakan. Semua topik tersebut 
merupakan rangkuman dari topik-topik pembahasan masyarakat perihal vaksin COVID -19 yang dibicar akan di media sosial.  
Pembicaraan masyarakat di media sosial twitter perihal berita Negara Brasil yang menolak untuk 
menggunakan vaksin COVID-19 yang dibuat oleh China dan Negara Jepang yang menggratiskan vaksin merupakan salah satu topik hangat yang dibic arakan masyarakat di twitter beberapa waktu lalu. Dengan munculnya berita tersebut, masyarakat turut aktif dalam memberikan pendapat mereka terkait fenomena yang terjadi. Masyarakat juga turut mengaitkan pendapatnya dengan harapan mereka terhadap kondisi di Indonesia. Status kehalalan vaksin juga merupakan salah satu topik hangat yang dibicarakan masyarakat di media sosial twitter.  Masyarakat bertanya-tanya mengenai hukum mengkonsumsi vaksin dalam agama mengingat bahan-bahan yang digunakan dalam vaksin ter sebut. Tidak hanya dari segi agama, uji kelayakan vaksin yang akan digunakan juga menjadi salah satu topik pembicaraan yang sering dibahas oleh masyarakat di twitter. Masyarakat sangat mengkhawatirkan perihal status layak pakai dan efek samping yang akan dihasilkan dari vaksin yang akan diberikan mengingat rencana kegiatan vaksinasi yang tampak seperti tergesa-gesa. Pembicaraan mengenai vaksin yang dikatakan hanyalah sebuah bisnis juga menjadi salah satu pembicaraan hangat di twitter. Bahkan, tidak jarang pembicaraan masyarakat yang menyuarakan sikap tidak percaya terhadap vaksin COVID-19 bahkan terhadap COVID-19 itu sendiri.  Vaksin merah putih juga tidak lepas dari pembicaraan masyarakat di twitter. Vaksin hasil produksi dalam negeri itu menjadi salah satu topik yang dibicarakan di media sosial twitter. Meskipun 
masih dalam tahap uji klinis, vaksin tersebut diharapkan oleh masyarakat untuk bisa menjadi pelopor dalam mencegah penyebaran virus corona. Kemudian harga vaksin juga menjadi topik yang dibicarakan oleh masyarakat di twitter.Masyarakat membicarakan perihal harga yang harus dibayarkan oleh masyarakat apabila ingin mendapatkan vaksin tersebut.  Masyarakat mengkhawatirkan apabila nantinya vaksin tersebut tidak bisa diperoleh secara gratis, bahkan apabi la harus mengeluarkan biaya yang sangat mahal. Lalu pembicaraan masyarakat perihal keterangan dari vaksin itu sendiri seperti fungsi & objeknya juga menjadi pembicaraan masyarakat di media sosial twitter. Pembicaraan tersebut merupakan diskusi atau penyeba ran informasi antar masyarakat yang dapat ditangkap oleh model.   
Tabel 3.  
Topik Pembahasan yang Dihasilkan oleh Model LDA  
Topik  Tema  Kata-kata yang mewakili  
1 Kinerja pemerintah  'covid' 'vaksin' 'buru' 'pengadaan' 'jokowi' erick' 'thohir' ' vaksinasi'  
2 Brasil menolak vaksin  'vaksin' 'covid' 'china' 'menolak' 'brasil' 'warga' 'beli'  
3 Status kehalalan vaksin  'vaksin' 'izin' 'darurat' 'penggunaan' 'kehalalan' 'mui' 'aman' 'edar'  
4 Fungsi vaksin  'vaksin' 'covid' 'manusia' 'rumah' 'keluarga' 'pencegahan'  
5 Jepang menggratiskan vaksin  'covid' 'vaksin' 'pemerintah' 'jepang' 'gratis' 'pemberian' 'warga'  
6 Harapan masyarakat  'vaksin' 'covid' 'semoga' 'pandemi' 'penyebaran' 'masker' 'jarak'  
7 Rencana vaksinasi  'vaksin' 'covid' ' juta' 'dosis' 'sinovac' 'november' 'masyarakat'  
8 Keamanan vaksin  'covid' 'vaksin' 'keamanan' 'tergesa' 'jokowi' 'pengadaan'  
9 Umum  'vaksin' 'corona' 'gue' 'orang' 'covid' 'berita' 'baca'  
10 Uji klinis vaksin sinovac  'uji' 'vaksin' 'covid' 'klinis' 'fase' 'tahap' 'keamanan' 'kandidat'  
11 Fungsi vaksin  'vaksin' 'covid' 'kekebalan' 'kebal' 'aman' 'flu' 'tubuh' 'orang'  
12 Protokol kesehatan  'vaksin' 'covid' 'masyarakat' 'pemerintah' 'prokes' 'liburan'  
13 Vaksin merah putih  'vaksin' 'pemerintah' ' merah' 'putih' 'mengembangkan' 'negeri'  
14 Harga vaksin  'vaksin' 'covid' 'harga' 'terjangkau' 'jokowi' 'masyarakat'  
15 Vaksin merah putih  'vaksin' 'covid' 'merah' 'putih' pengembangan' 'virus' 'negeri'  
16 Objek vaksinasi  'vaksin'  'negara' 'rakyat' ' presiden' 'pasien' 'pejabat' 'disuntik  
17 Bisnis vaksin  'vaksin' 'pemerintah' 'perusahaan' 'bisnis' 'dunia' 'amerika' 'bahan'  
18 Umum  'vaksin' 'covid' 'negara' 'dunia' 'pandemi' 'beliau' 'pemerintah'  
19 Uji klinis & efek samping  'vaksin' 'covid' 'uji' 'klinis' 'efek' 'samping' 'farma' 'aman' 'bio' 'fase'  
20 Kepercayaan vaksin  'covid' 'vaksin' 'anti' 'percaya' 'golongan' 'ramai' 'orang'  
Harapan masyarakat terhadap vaksin COVID-19 juga tertangkap dalam model. Masyarakat berharap semoga dengan disegerakannya kegiatan vaksinasi ini, dapat dengan segera mengakhiri pandemi. Masyarakat juga saling meningatkan untuk tetap memakai masker & menjaga jarak sambil menunggu kegiatan vaksinasi. Pembicaraan mengenai protokol kesehatan juga turut serta  tertangkap dalam model. Pernyataan untuk tetap mengikuti protokol kesehatan terus dibicarakan oleh masyarakat di twitter. Terlebih pada kondisi tertentu seperti saat liburan di tempat wisata yang menjadi tempat kumpul banyak orang.  
 
Kesimpulan  
Berdasarkan hasil dari analisis sentimen, dapat ditarik kesimpulan bahwa masyarakat lebih banyak memberikan respon yang bersentimen positif terhadap vaksin COVID-19 dibandingkan dengan respon yang bersentimen negatif. Kata -kata bersentimen yang diutarakan juga cenderung lebih banyak menghasilkan kata yang bersentimen positif dibanding kata yang bersentimen negatif. Model LDA yang dibangun dapat menangkap berbagai macam topik pembicaraan masyarakat di media sosial twitter terkait vaksin COVID -19 seperti pembicaraan masyarakat mengenai vaksin merah putih, sertifikasi halal vaksin, uji layak pakai vaksin, harga vaksin, sampai pembicaraan umum masyarakat seperti fungsi & objek vaksinasi. Hasil dari penelitian ini dapat menjadi pertimbangan bagi pihak terkait dalam perencanaan                                                                                                                                     kegiatan vaksinasi sehingga kegiatan tersebut dapat berjalan dengan baik. Penelitian selanjutnya diharapkan dapat melakukan analisis yang lebih dalam terhadap data respon dan opini masyarakat yang berasal dari media sosial twitter. Kegiatan tersebut dapat dilakukan dengan cara seperti menganalisa lokasi tempat seseor ang mem posting  tweets tersebut ataupun dengan melihat orang-orang yang paling 
berpengaruh terhadap suatu opini tersebut. Selain itu, penggunaan metode analisis yang lebih tervalidasi juga diharapkan untuk dapat dilakukan. Bagaimanapun, kegiatan analisis pada penelitian ini terbatas pada penggunaan kamus positif-negatif yang digunakan . 
 
Daftar Pustaka  
1.  WHO. Virtual press conference on COVID -19 â€“ 11 March 2020. 2020.  
2.  WHO. Weekly Operational Update on COVID -19. 2020.  
3.  Nuraini R. Kasus Covid -19 Pertama, Masyarakat Jangan Panik _ Indonesia. Indonesia. go.id [Internet]. 2020
angka/ekonomi/kasus -covid -19-pertama -masyarakat -jangan -panik  
4.  Maharani T. UPDATE 26 Oktober: Tambah 112, Pasien Covid -19 Meninggal Jadi 13. kompas.com [Internet]. 202 0
https://nasional.kompas.com/read/2020/10/26/15485201/update -26-oktober -tambah -112-pasien -covid -19-meninggal -jadi-13411  
5.  Liu C, Zhou Q, Li Y, Garner L V, Watkins SP, Carter LJ, et al. Research and Development on Therapeutic Agents and Vaccines for COVID -19 and Related Human Coronavirus Diseases. 2020
6.  Sari IP, Sriwidodo. Perkembangan Teknologi Terkini dalam Mempercepat Produksi Vaksin Covid -19. 2020
7.  PERATURAN PRESIDEN. REPUBLIK INDONESIA
8.  Hakim RN. Menlu Retno dan Menteri BUMN Akan ke Inggris dan Swiss Amankan Stok Vaksin Covid -19. kompas.com [Internet]. 2020 https://nasional.kompas.com/read/2020/10/12/09 074911/menlu -retno -dan-menteri -bumn -akan-ke-inggris -dan-swiss -amankan -stok-vaksin  
9.  Hastuti RK. Mohon Doanya! Bulan Depan Indonesia Mulai Vaksinasi Covid -19. cnbcindonesia.com [Internet]. 2020
https://www.cnbcindonesia.com/news/20201017154414 -4-195104/mohon -doanya -bulan - depan -indonesia -mulai -vaksinasi -covid -19 
10.  Anwar F. Program Vaksin COVID -19 Mulai November, Apa Itu Emergency Use Authorization? detik.com [Internet]. 2020
5210577/program -vaksin -covid -19-mulai -november -apa-itu-emergency -use-author ization  
11.  Artanti A ayu. Kabar Gembira, Pemerintah Mulai Program Vaksin November 2020 - Medcom. medcom.id [Internet]. 2020
https://www.medcom.id/ekonomi/bisnis/ObzZY7db -kabar gembira -pemerintah -mulai -program -vaksin -november -2020 
12.  SOCIAL WA. DIGITAL. 2019.  
13.  Collins C, Hasan S, Ukkusuri S V. A novel transit rider satisfaction metric: Rider sentiments measured from onlin e social media data. J Public Transp. 2013
14.  Basu R, Khatua A, Jana A, Ghosh S. Harnessing Twitter Data for Analyzing Public Reactions to Transportation Policies â€¯: Evidences from the Odd -Even Policy in Delhi , India. 2017 https://www.researchgate.net/publication/321997978_Harnessing_Twitter_Data_for_Analyzing_Public_Reactions_to_Transportation_Policies_Evidences_from_the_Odd -
Even_Policy_in_Delhi_India  
15.  Luong TTB, Houston D. Public opinions of light rail service in Los Angeles , an analysis using Twitter data. iConference 2015 Proc. 2015
16.  Pratama MO, Satyawan W, Jannati R, Pamungkas B, Raspiani, Syahputra ME, et al. The sentiment analysis of Indonesia commuter line using machine learning based on twit ter data. JPhys Conf Ser. 2019
17.  Pramana S, Yuniarto B, Mariyah S, Santoso I, Nooraeni R. Data mining dengan R konsep setara implementasi. Pertama. Bogor: Bogor â€¯: IN MEDIA, 2018 Â© 2018
18.  Haddi E, Liu X, Shi Y. The role of text pre -processing insentiment analysis. Procedia Comput Sci [Internet]. 2013
19.  Collomb A, Costea C, Joyeux D, Hasan O, Brunie L. A Study and Comparison of Sentiment Analysis Methods for Reputation Evaluation. Rapp Rech. 2014
20.  Ohana B, Tierney B. Sentiment classification of reviews using SentiWordNet. In: 9th International Conference on Information Technology and Telecommunication: Ubiquitous and 
Green Computing [Internet]. 2009. p. 3 â€“10. Available from: http://www.ittconference.ie/openconf/openconf.php  
21.  Wahyudin I, Tosida ET, Andria F. Teori dan Panduan Praktis Data Science dan Big Data [Internet]. Pertama. Lembaga penelitian dan pengabdian masyarakat universitas pakuan. Bogor 2019. 1 â€“6 p. Available from: https://www.researchgate.net/profile/Yulingga_Hanief/publication/330752923_Cara_Cepat_Kuasai_Massage_Kebugaran_Berbasis_Aplikasi_Android/links/5c529bca458515a4c74c5373/Cara-Cepat -Kuasai -Massage -Kebugaran -Berbasis -Aplikasi -Android.pdf  
22.  Blei DM, Ng AY, Jordan MI. Latent Dirichlet Allocation. J Mach Learn Res 3. 2003
23.  Kumar K. Evaluation of Topic Modeling:Topic Coherence [Internet]. datascienceplus.com. 2018. Available from: https://datascienceplus.com/evaluation -of-topic-modeling -topic -coherence/  
24.  Kearney MMW. Package â€˜ rtweet .â€™ 2020
25.  Pramana S, Yordani R, Kurniawan R, Yuniarto B. Dasar -dasar statistika dengan software R â€¯: konsep dan aplikasi. Kedua. Bogor: Bogor â€¯: In Media, 2017.
26.  Team RC. R: A language and environment for statistical computing [Internet]. R Foundation for Statistical Computing, Vienna, Austria. 2017. Available from: https://www.r -project.org/  
27.  Salsabila NA, Winatmoko YA, Septiandr i AA, Jamal A. Colloquial Indonesian Lexicon. In: International Conference on Asian Language Processing. 2018. p. 236 â€“9.  
28.  Tala FZ. A Study of Stemming Effects on Information Retrieval in Bahasa Indonesia. 2003
29.  Liu B, Hu M, Cheng J. Opinion obse rver. 2005
30.  Hartanto. TEXT MINING DAN SENTIMEN ANALISIS TWITTER PADA GERAKAN LGBT. Intuisi J Psikol Ilm. 2017
31.  Setyobudi W, Alwi A, Astuti IP. Sentimen Analisis Twitter Terhadap Penyelenggaraan Gojek Traveloka Liga 1 Indonesia. K omputek. 2018
32.  Purba NS, Nooraeni R. Using LDA for Innovation Topic of Technology â€¯: Quantum Dots Patent Analysis. 2020",Analisis Sentimen,Latent Dirichet Allocation,data dari media sosial twitter,
Sistem Tanya Jawab Konsultasi Shalat Berbasis RASA Natural Language Understanding (NLU),"Sistem Tanya Jawab Konsultasi Shalat Berbasis RASA Natural Language Understanding (NLU)

Muhammad Rizqi Sholahuddin1, Firas Atqiya2 

ABSTRAK  
Chatbot merupakan sistem cerdas  yang memberikan pengalaman kepada  user berupa interaksi langsung dengan mesin melalui media tulisan. Paper ini memaparkan penggunaan chatbot sebagai saranan tanya jawab seputar tata cara shalat.  Seorang muslim ada kalanya memiliki pertanyaan mengenai tata shalat  ketika menemukan adanya pe rbedaan antara tata cara yang dilakukannya dengan tata cara yang dilakukan muslim lainnya . Pemanfaatan chatbot dalam hal ini adalah untuk menyediakan jawaban mengenai hal tersebut . Chatbot ini dikembangkan dengan model deep learning , khususnya LSTM yang su dah terintegrasi dengan RASA framework . LSTM ( Long Short Term Memory ) secara efisien dapat menghemat beberapa 
memori yang diperlukan , namun juga akan menghapus beberapa memori yang tidak diperlukan. Platform telegram dipilih untuk implementasi chatbot ini.  Hasil penelitian menunjukkan  bahawa chabot telegram konsultasi shalat dengan DIET Classifier dan RASA mampu mengenali pertanyaan dan memberikan respon dalam bentuk teks dan gambar , untuk hasil akurasi didapatkan 96% . 
 
Kata kunci:  chatbot,  NLU,  RASA, shalat  
 
ABSTRACT  
A chatbot is an intelligent system that provides users with direct interaction with machines via written media. This paper describes how to use chatbots to ask questions about prayer procedures. A Muslim sometimes has questions about the procedure for praying when he finds a difference between the procedures performed by other Muslims. In this case, the use of chatbots is to provide an explanation. This chatbot was developed using a deep learning model, especially LSTM, that was integrated with the RASA fra mework. LSTM (Long Short Term Memory) can efficiently save some of the needed memory while also removing some of the unnecessary memory. The Telegram platform was chosen for the chatbot's implementation. The results showed that the chatbot telegram prayer consultation with DIET Classifier and RASA was able to recognize questions and provide answers in the form of text and images , with 9 6 percent accuracy.  
 
Keywords:  chatbot,  NLU, RASA,  Salat  
 
 
1. Pendahuluan  
Shalat merupakan ibadah wajib bagi umat muslim , namun terkadang terdapat perbedaan tata cara shalat yang mengakibatkan timbulnya pertanyaan di kalangan umat muslim sendiri. Seyogianya pertanyaan tersebut ditanyakan kepada seorang ahli, seperti kyai atau ustadz(ah), sehingga komunikasi terjalin secara interaktif. Akan tetapi tidak semua muslim memiliki akses langsung untuk bertanya langsung kepada para ahli sehingga mencari jawaban atas pertanyaan terkait shalat dilakukan dengan penelusuran di internet. Namun, hasil penelusuran melalui internet menampilkan banyak jawaban yang membuat pengguna harus memilah kembali  jawaban yang tersedia . Akibatnya, pencarian jawaban atas sebuah pertanyaan memakan waktu lama dan tidak praktis.  Sebagai solusi atas kondisi tersebut, peneliti  membangun chatbot interaktif yang be rfokus pada tata cara shalat.  Chatbot sendiri adalah salah satu sistem cerdas yang menerapkan Natural Language Processing (NLP) dalam prosesnya. Chatbot memberikan pengalaman kepada user berupa interaksi langsung dengan mesin melalui  media tulisan (text). Bahasa adalah timbal balik sosial dan budaya untuk protokol alami. Sudah saatnya mesin komputer menambahkan fitur untuk memahami manusia seiring dengan peningkatan kinerja perangkat keras mesin komputer baru-baru ini [1]. Sholahuddin  et al Penelitian yang menghasilkan luaran aplikasi yang interaktif telah banyak dipublikasikan , misalnya saja di bidang pendidikan telah dikembangkan media pembelajaran interaktif untuk mendukung pembelajaran jarak jauh [2], selain itu  di bidang pelestarian budaya dan sejarah telah dirancangan game tradisional â€œtambah satuâ€ berbasis android [3] dan game untuk mengenalkan tokoh pahlawan Indonesia kepada generasi Z [4]. Penelitian yang menghasilkan  chatbot sebagai luaran penelitian juga sudah dipublikasikan , baik itu di bidang 
pendidikan, pariwisata, medis dan bidang lainnya.  Sebagai contoh adalah  penelitian yang menghasilkan chatbot untuk memfaslitasi interaksi antara mahasiswa /i dengan pihak fakultas terkait proses akademik  [5]. Penelitian lainnya menghasilkan chatbot untuk menyediakan informasi terkait objek wisata di kota Bandung  [6], juga chatbot untuk membantu proses transaksi penjualan UMKM  [7]. Selain itu, ada pula penelitian untuk membangun model sistem tanya jawab medis berbasis case-based reasoning [8]. Case Based Reasoning (CBR) adalah menggunakan pengalaman yang telah ada untuk memahami dan menyelesaikan permasalahn baru. Pada CBR, solusi permasalahan ditentukan dengan mencari situasi lalu 
yang mirip dengan masalah yang sedang dihadapi kemudian menerapkan solusi tersebut. Secara sederhana, CBR dapat dipahami sebagai teknik untuk menentukan solusi sebuah permasalahan dengan mengadaptasi solusi-solusi permasalah yang mirip dan pernah ada sebelumnya [9]. Tujuan penelitian ini, menghasilkan chatbot yang dapat digunakan sebagai sarana konsultasi mengenai tata cara sholat. Hal ini diperlukan karena akan membantu pengguna untuk mendapatkan jawaban terkait tata cara sholat tanpa harus melakukan pencarian panjang melalui internet sehingga waktu yang diperlukan menjadi lebih singkat. 
 
2. Metode Penelitian  
Penelitian menggunakan metode kuantitatif, yang terdiri dari pengujian accuracy, precision, dan recall. Adapun tahapan penelitian dapat dilihat pada Gambar. 1.   
Gambar 1. Tahapan penelitian   
Penelitian  dimulai d engan  pengumpulan data. Pada tahap ini data dikumpulkan dari dari buku dan situs tanya jawab konsultasi sholat. Kemudian dilakukan proses prepocessing yang bertujuan  untuk melihat pola pertanyaan, luaran tahap ini adalah dataset pertanyaan dan jawaban terkait konsultasi sholat. Pada proses preprocessing sendiri yang dilakukan adalah klasifikasi maksud (intent classification) dan ekstraksi entitas (entity extraction)  dari setiap kalimat.   
Tahap berikutnya adalah pelatihan data . Pada tahap ini dataset hasil prepocessing pada tahap sebelumnya akan menjadi input .  Setelah proses training selesai, lalu dilanjutkan dengan tahap perancangan sistem.  Kemudian dilanjutkan dengan tahap pembangunan aplikasi . Lalu yang terkahir adalah tahap pengujian  sistem.  Pada tahap terakhir ini pengujian yang dilakukan adalah pengujian data yang dapat masuk ke server chat. 
 
3. Tinjauan Pustaka  
Natural Language Processing  
Natural Language Processing (NLP) adalah bidang keilmuan yang mempelajari bagaimana komputer atau mesin dapat digunakan untuk memahami dan memanipulasi bahasa natural baik yang berupa tulisan (text) atau suara (speech)  [10]. Tujuan dari bidang NLP adalah untuk membuat desain dan membangun aplikasi yang dapat memfasilitasi interaksi antara manusia dan mesin atau perangkat lainnya dengan menggunakan bahasa natural [11]. Bahasa natural adalah bahasa yang biasa digunakan oleh manusia untuk saling berkomunikasi. Beberapa area utama dalam bidang NLP diantaranya adalah Question Answering Systems (QAS), Summarization, Machine Translation, Speech Recognition, dan Document Classification [11].  
Chatbot  
Chatbot adalah salah satu sistem cerdas yang menerapkan Natural Language Processing (NLP) dalam prosesnya. Chatbot memungkinkan terjadinya komunikasi antara manusia dan mesin dengan menggunakan tulisan (text). Pada dasarnya bot memulai proses dengan melihat kata kunci dalam setiap data yang masuk dan kemudian memberikan balasan dengan kata kunci yang paling sesuai, atau pola rangkaian kata yang paling mirip dari basis data tekstual yang telah dibuat. Hal ini berarti apabila pengguna memasukkan sebuah permintaan, maka bot akan memberikan balasan dengan respon spesifik sesuai dengan kata kunci yang dimasukkan oleh pengguna ter sebut.  Perkembangan perangkat teknologi informasi saat ini menjadi salah satu pendukukung perkembangan aplikasi chatbot. Penerapan chatbot ada yang diarahkan untuk menjadi asisten dari penggunanya, misalnya saja chatbot yang digunakan untuk memberikan laya nan customer service 24 jam. Selain itu, chatbot juga dapat dijadikan pendukung layanan Frequently Ask Question (FAQ) [5]. Dalam penelitian ini, chatbot akan digunakan sebagai sarana konsultasi mengenai tata cara sholat. (https://www.chatbot.com/ ) 
Gambar 2. Contoh percakapan melalui chatbot  
Case Based Reasoning  
Case based reasoning berarti menggunakan rekaman pengalaman yang ada untuk memahami dan menyelesaikan permasalah baru. Di dalam CBR, solusi dari rekaman kejadian lampau yang memiliki kemiripan dengan masalah baru yang sedang dihadapi akan digunakan sebagai  solusi dari masalah yang sedang dihadapi saat ini. [8] Pada CBR terdapat empat  siklus utama yaitu retrieve, reuse,  revise dan retain. Retrieve adalah proses pengambilan kasus paling serupa. Pada penelitian ini direncakan berdasarkan kemiripan fitur  bag-of-word. Reuse adalah tahap mengambil jawaban yang paling mirip atau akurat pada dataset. Revise adalah proses revisi bisa pengurangan atau penambahan pengetahuan baru pada dataset. Tahap retain adalah proses memasukan hasil revise ke dalam dataset.  Artificial Intelligence Markup Language  
Artificial Intelligence Markup Language (AIML) [12] merupakan turunan dari Extensible Markup Languange (XML). AIML memiliki kelas objek data yang menggambarkan perilaku program computer yang memrosesnya. AIML terdiri dari tag atau unit yang disebut topik dan kategori. Pada AIML, kategori adalah unit dasar dari pengetahuan. Setiap Kategori terdiri dari pola yang mengandung input dan template yang berisi jawaban dari chatbot.  
Natural Language Understanding (NLU)  
Natural Language Understanding (NLU) adalah  subbidang dari pemrosesan bahasa alami yang berhubungan dengan machine reading comprehension. Tujuan dari sistem NLU adalah untuk menginterpretasikan sebuah fragmen teks input [13]. NLU akan mengesktrak informasi dari sebuah pesan. Informasi yang diekstrak adalah intent dan entity  
Gambar 3. Contoh informasi hasil ekstrak dari NLU  
Long Short -Term  Memory (LSTM)  
Long Short -Term  Memory (LSTM) merupakan  pengembangan dari RNN yang diperkenalkan oleh Hochreiter & Schmidhuber. LSTM dirancang secara eksplisit untuk menghindari masalah ketergantungan jangka panjang [14]. Pada LSTM, telah dilakukan modifikasi terhadap RNN deng an menambahkan memory cell yang dapat menyimpan informasi untuk jangka waktu yang lama [15]. 
Rasa 
Rasa adalah  sebuah framework  machine learning bersifat open-source yang digunakan untuk  mengotomatisasi teks dan percakapan berbasis suara  [16]. Rasa menyediakan infrastruktur  untuk membangun chatbot dan asisten virtual berbasis AI  . RASA memiliki dua modul utama, yaitu Rasa NLU dan Rasa Core.  Rasa NLU adalah alat pengolah bahasa alami yang digunakan untuk klasifikasi maksud (intent classification) dan ekstraksi entitas (entity extraction) dari sebuah percakapan. Pada dasarnya Rasa NLU berperan untuk menginterpretasikan pesan. [16] Rasa Core adalah sebuah chatbots framework untuk menangani percakapan kontekstual . Berperan untuk memprediksi dialog atau jawaban berdasarkan pada pesan sebelumnya yang dikirimkan oleh pengguna.  
DIET Classifier  
Dual Intent and Entity Transformer (DIET)  Classifier merupakan arsitektur  fleksibel  yang dapat menangani 
proses intent classification dan proses pengenalan entitas secara bersamaan. DIET Classifier memiliki performa yang tinggi meskipun dataset yang digunakan sederhana  [17].  Selain itu, DIET menyediakan kemampuan untuk plug and play berbagai embeddings pra-terlatih seperti BERT, GloVe, ConveRT, dan sebagainya.  [16]
 
4. Implementasi dan Hasil  
Tahap pengumpulan data  menghasilkan luaran berupa dataset pertanyaan dan jawaban. Gambar 4 adalah contoh dataset yang dihasilkan.   
Gambar 4. Format dalam  dataset  
Pada rasa secara default dataset pertanyaan di simpan pada data/nlu.yml, dengan format sebagai berikut.  
Intent: <Nama_Intent>  
Examples:  
-Pertanyaan 1 yang sesuai intent  
-Pertanyaan 2 yang sesuai intent  
#NAME?
Sedangkan untuk dataset balasan atau jawaban, di simpan pada domain.yml, dengan format sebagai berikut:  
utter_<nama_intent>:  
#NAME?
image: (link alamat citra)  
Selanjutnya adalah tahap pelatihan data. Data training yang digunakan sebanyak 58 pertanyaan. Dari 58 pertanyaan tersebut menghasilkan 15 intent, dengan komposisi training 38 dan validasi 20 pertanyaan.  Gambar 5 menunjukkan status data training.  
Gambar 5. Status data training  
Tahap berikutnya adalah perancangan sistem. Arsitektur dari sistem yang dibangun ditunjukkan pada Gambar 6.   
Gambar 6.  Arsitektur sistem  
Penjelasan untuk arsitektur yang digunakan adalah sebagai berikut:  
1. User dapat mengakses aplikasi melalui Telegram Desktop atau Telegram Mobile  
2. User meng-input data pada berupa pertanyaan terkait sholat.  
3. Sistem dengan menggunakan DIET Classifier dan NLU untuk mengklasifikasikan pertanyaan.  
4. Sistem akan memberikan output kepada user berupa jawaban  
Setelah perancangan sistem, selanjutnya adalah tahap pembangunan aplikasi, Pada Gambar 7 ditunjukkan tampilan awal aplikasi yang sudah dibangun.  
Gambar 7. Tampilan awal bot konsultasi sholat telegram    
Gambar 8. Pertanyaan dari user dan jawaban dari bot  
Gambar 9. Respon bot  
Gambar 8 dan Gambar 9 menunjukkan bagaimana proses interaksi yang terjadi antara pengguna dengan chatbot. Pada Gambar 8 pengguna bertanya mengenai masalah seputar shalat, yaitu â€œPosisi ruku yang benar bagaimana yaâ€. Respon yang diberikan oleh chatbot atas pertanyaan tersebut berupa teks â€œPosisi Ruku yang benar seperti ga mbar dibawah ya:â€ dan gambar posisi ruku. Selain itu, chatbot juga meminta feedback dari pengguna atas jawaban yang diberikan.  Selanjutnya Gambar 9 menunjukkan jawaban pengguna atas permintaan feedback dari chatbot yang kemudian chatbot memberikan respon atas jawaban tersebut.  Tahap pengujian sistem terdiri dari dua macam, yaitu pengujian chatbot dan pengujian accuracy.  Pengujian chatbot merupakan pengujian yang dilakukan langsung pada aplikasi telegram. Sedangkan pengujian accuracy dilakukan dengan menggun akan data test yang dibagi secara acak antara train dan validasi dengan 
menggunakan code evaluate_on_number_of_examples.  
Hasil dan pembahasan  
Berikut ini merupakan hasil dari pengujian chatbot pada aplikasi telegram  
Tabel 1. Hasil  pengujian chatbot  
No Skenario  Kriteria  Keterangan  Sukses  Gagal  
1 Handle command seperti /   âˆš Bot Gagal menghandle masukan yang dapat berpengaruh pada code seperti / atau 
karakter terkait code  
2 Pertanyaan tidak baku  âˆš  Bot dapat menjawab masukan kalimat tidak baku  yang masih berkaitan dengan dataset.  
3 Bot Mengirim Gambar  âˆš  Bot dapat mengirim jawaban berupa gambar  
4 Bot Mengirim tulisan arabic font âˆš  Bot dapat mengirimkan tulisan arabic  
5 Menekan tombol â€œPrediksiâ€  âˆš  Sistem melakukan prediksi dengan menggunakan Algoritma dan mengarahkan user ke halaman result  
Dari Tabel 1 diketahui bahwa interface aplikasi telegram dapat digunakan dengan baik oleh chatbot yang 
dikembangkan.  
Pengujian Respon API ChatBot  
Gambar 10. Hasil pengujian respon API  
Pengujian respon API chatbot dapat dilakukan dengan post ke localhost:5005/model/parse, dapat dilihat pada Gambar 10 bahwa chatbot akan memeriksa setiap intent dan memberikan skor condifence kesetiap kategori intent.  
Gambar 1 1. Training accuracy (acc), v alidation accuracy (val_acc)  dengan 99 step 
Gambar 1 2. training loss (loss ), validation loss (val_loss) dengan 99 step  
Pada Gambar 11 dan Gambar 12 , merupakan grafik hasil Training accuracy (acc), training loss (loss), validation accuracy ( val_acc), validation loss (val_loss) terhadap model yang dibuat . Perintah evaluate pada data dengan steps sebanyak 99 dari test generator  menampilkan tingkat validasi akurasi adalah 0.9 65 dengan loss sebesar 0.000006543.  Ini menunjukkan efektivitas Rasa dan model yang dibuat. Untuk meningkatkan akurasi perlu menambahkan lebih banyak data pertanyaan dan jawaban.   
Gambar 13. Intent Confusion Matrix  
Pada confusion matrix terlihat jika terdapat 2 kasus intent salam diprediksi salah.  Secara keseluruhan intent untuk evaluasi dataset seluruh pertanyaan, nilai Precission 0.9692, Recall 0.9692 dan F -1 Score 0.9615 . 

5. Simpulan  
Telah dibangun sebuah chatbot untuk Sistem Tanya Jawab Konsultasi Sholat Berbahasa Indonesia. Sistem 
dibangun dengan menerapka DIET Classifier dan Rasa  melalui beberapa tahapan. Sebanyak 38 pertanyaan 
telah diikutkan training dan 20 pertanyaan pada pengujian aplikasi ini. Berdasarkan hasil pengujian chatbot, 
sistem telah berhasil menjalankan fungsi dengan baik namun mas ih belum bisa handle char khusus seperti 
â€˜/â€™. Lebih jauh, dapat dilakukan penelitian lebih lanjut mengenai handle error, interactive chatbot dan 
menambah dataset. Adanya p enambahan data akan memperbaiki model chatbot.  

Ucapan Terima  kasih  
Penulis mengucapkan terima kasih kepada Politeknik Negeri Bandung atas fasilitas dan dukungan manajemen. Penelitian ini dilaksanakan di bawah Dana DIPA Politeknik Negeri Bandung , No . 105.80/PL.1R7/PG.00.03/2021  

Daftar Pustaka  
1. S. Yoo and O. Jeong, â€œAuto -Growing Knowledge Graph -Based Intelligent Chatbot Using BERT.â€ ICIC 
International å­¦ä¼š, 2020. Accessed: Sep. 07, 2021. [Online]. Available: https://doi.org /10.24507/icicel.14.01.67  
2. F. H. Firmansyah, I. P. Sari, and M. Musyarofah, â€œPengembangan Media Pembelajaran Interaktif Berbasis Android Untuk Pembelajaran Terbuka dan Jarak Jauh di Universitas Pendidikan Indonesia,â€ Edsence J. Pendidik. Multimed., vol. 1, no. 2, pp. 99 â€“108, Dec. 2019, doi: 
10.17509/edsence.v1i2.21667.  
3. A. G. I. Hutabarat and A. C. Padmasari, â€œRancang Bangun Game Tradisional â€˜Tambah Satuâ€™ berbasis Platform Android,â€ Edsence J. Pendidik. Multimed., vol. 2, no. 1, pp. 29 â€“44, Jun. 2020, doi: 10.17509/edsence.v2i1.25028.  
4. P. R. Shalih and I. Irfansyah, â€œPerancangan Game Berbasis Multimedia Development Life Cycle (MDLC) Tentang Tokoh Pahlawan Indonesia Masa Kini untuk Generasi Z,â€ Edsence J. Pendidik. Multimed., vol. 2, no. 2, pp. 83 â€“92, Dec. 2020, doi: 10.17509/edsence.v2i2.26690.  
5. H. Toba and B. Wijaya, â€œImplementasi Sistem Tanya Jawab Berbasis Skenario untuk Mendukung Proses Akademik dengan IBM Watson Assistant,â€ J. Edukasi Dan Penelit. Inform. JEPIN, vol. 6, no. 2, p. 154, Aug. 2020, doi: 10.26418 /jp.v6i2.40715.  
6. E. N. S. C. P and I. Afrianto, â€œRancang Bangun Aplikasi Chatbot Informasi Objek Wisata Kota Bandung dengan Pendekatan Natural Language Processing,â€ Komputa J. Ilm. Komput. Dan Inform., vol. 4, no. 1, pp. 49 â€“54, Mar. 2015, doi: 10.34010/komp uta.v4i1.2410.  
7. S. Triputra and F. Atqiya, â€œImplementation of Natural Language Processing in Seller -bot for SMEs,â€ J. Phys. Conf. Ser., vol. 1764, no. 1, p. 012069, Feb. 2021, doi: 10.1088/1742 -6596/1764/1/012069.  
8. W. Suwarningsih, â€œSistem Tanya Jawab Medis Berbasis Case Base Reasoning Menggunakan Semantic Role Labelling,â€ Disertasi Program Doktor, Institut Teknologi Bandung, 2017.  
9. J. L. Kolodner, â€œAn introduction to case -based reasoning,â€ vol. 6, pp. 3 â€“34, 1992, doi: https://doi.org/10.1007/BF00155578.  
10. G. G.  Chowdhury, â€œNatural language processing,â€ Ann Rev Info Sci Tech, vol. 37, pp. 51 â€“89, Jan. 2005, 
doi: https://doi.org/10.1002/aris.1440370103.  
11. J. Pustejovsky and A. Stubbs, Natural Language Annotation for Machine Learning, 3rd ed. Oâ€™Reilly 
Media, 2013.  12. B. R. Ranoliya, N. Raghuwanshi, and S. Singh, â€œChatbot for university related FAQs,â€ 2017, pp. 1525 â€“1530. doi: 10.1109/ICACCI.2017.8126057.  
13. E. Ovchinnikova, Integration of World Knowledge for Natural Language Understanding. Atlantis Press, 2012. [Online]. Ava ilable: https://books.google.co.id/books?id=jfJUHOncFzkC  
14. C. Olah, â€œUnderstanding LSTM Networks,â€ Aug. 27, 2015.  15. N. K. Manaswi, â€œRNN and LSTM,â€ in Deep Learning with Applications Using Python, Berkeley, CA: Apress, 2018, pp. 115 â€“126. doi: 10.1007/978 -1-4842-3516-4_9. 
16. M. Saini, â€œUsing the DIET classifier for intent classification in dialogue,â€ medium.com, Jul. 29, 2020. 
https://medium.com/the -research -nest/using -the-diet-classifier -for-intent -classification -in-dialogue -
489c76e62804 (accessed  Sep. 28, 2021).  
17. T. Bunk, D. Varshneya, V. Vlasov, and A. Nichol, â€œDIET: Lightweight Language Understanding for 
Dialogue Systems,â€ ArXiv200409936 Cs, May 2020, Accessed: Dec. 19, 2021. [Online]. Available: http://arxiv.org/abs/2004.09936",Sistem Tanya Jawab,RASA Natural Language Understanding,dataset pertanyaan dan jawaban,"akurasi, precission, recall, F-1 Score"
Optimasi Pertanyaan Menggunakan Refined Query Dalam Sistem Tanya Jawab Kitab Hadis,"Optimasi Pertanyaan Menggunakan Refined Query Dalam Sistem Tanya Jawab Kitab Hadis

Andy Huang Wijaya  1, Nazruddin Safaat Harahap 2, Muhammad Irsyad  3, Febi Yanto 4 

Abstrak
Penelitian ini bertujuan untuk meningkatkan Sistem Tanya  
Jawab untuk teks Hadis dengan menggabungkan teknik 
Refined Query  dan Large Language Models (LLMs), khususnya GPT-4 dari OpenAI. Memanfaatkan dataset  sebanyak  62.169 Hadis dari sembilan buku penting . Penelitian ini mengikuti metodologi komprehensif yang mencakup pengumpulan, analisis, dan pra-pemrosesan data, serta integrasi LangChain dan Large Language Models (LLMs ) OpenAI untuk kueri yang dioptimalkan. Evaluasi kinerja sistem dilakukan melalui analisis komparatif sebelum dan sesudah penerapan Refined Query , BERTScore untuk kualitas teks, dan penilaian kualitas berbasis pengguna . Hasilnya menunjukkan bahwa Refined Query  secara signifikan meningkatkan kapasitas sistem untuk menghasilkan respons yang akurat dan relevan secara kontekstual. Menerapkan Refined Query  tidak hanya 
meningk atkan ketepatan jawaban, tetapi juga memfasilitasi 
pembuatan tanggapan yang sebelumnya tidak tersedia. BERTScore rata -rata sebesar 0,80351 dan tingkat kulitas 
jawaban dari  pengguna dengan skor rata-rata 87,3%  untuk 
pengujian terhadap mahasiswa dan 90,3% pe ngujian kepada 
ahli hadis  semakin memvalidasi keampuhan sistem.  
Kata Kunci :   Refined Query, Hadis, Large Language Models 
Sistem, Tanya Jawab, Generative Pre-training, Transformer .  

Abstract    
This research aims to enhance a Question -Answering Syste m for Hadith texts by incorporating Refined Query  techniques and Large Language Models (LLMs), specifically OpenAI's GPT-4. Utilizing a dataset of 62,169 Hadith from nine significant books, the study follows a comprehensive methodology that covers data collection, analysis and preprocessing, and the integration of LangChain and OpenAI's Chat Model for optimized querying. The evaluation of the system's performance was conducted through comparative analysis before and after the application of Refined Query , BERTScore for text quality, and user-based quality assessments . Results demonstrate that Refined Query  significantly improves the system's capacity to produce  accurate and contextually relevant responses. Implementing Refined Query  not only enhanced answer precision but also facilitated the generation of responses where none were previously available. The average BERTScore of 0.80351 and the quality of user responses with an average score of 87.3% for the student test and 90.3% for the hadith expert test further validate the efficacy of the system.  

1. Pendahuluan  
Akses terhadap informasi merupakan hal yang sangat penting dan bisa dikatakan sebagai kebutuhan pokok, terutama pada 
kebutuhan pendidikan, penelitian, dan pengambilan keputusan. Hadis adalah salah satu sumber hukum Islam selain Al -Qurâ€™an, yang menjelaskan kalimat dalam Al -Qurâ€™an yang mengacu pada ucapan, perbuatan, atau penetapan dalam kehidupan sehari-hari yang diambil dari ajaran Nabi Muhammad SAW (Abdul Aziz et al., 2021 Niâ€™mah & Arifin, 2020) . Kitab Hadis yang paling populer adalah Kitab Hadis Sunni yang terdiri dari 9 Kitab oleh 9 Imam, yaitu Shahih Muslim, Shahih Bukhari, Sunan at-Turmudzi, Sunan Abu Dawud, Sunan Ibnu Majah, Muwatta Malik, Sunan an -Nasa'I, Sunan Darimi, dan Musnad Ahmad (Niâ€™mah & Arifin, 2020) . Dalam aspek literasi data hadis, hanya satu indikator dari beberapa indikator yang mampu direpresentasikan oleh lebih dari 80% peserta, menunjukkan bahwa analisis data dalam hadis memerlukan keterampilan yang cer mat dan kritis (Supriyadi et al., 2020) . Oleh karena itu, penting untuk memahami dan menganalisis data dalam hadis secara mendalam untuk 
memastikan informasinya.  Penggunaan sistem tanya jawab ini  
bertujuan untuk memenuhi kebutuhan informasi pengembang se cara on-demand  dengan memberikan respons mesin yang disesuaikan dengan konteks perangkat lunak dan pertanyaan individu (Bansal et al., 2021) . Terdapat 3 tahapan utama dalam menghasilkan jawaban atas pertanyaan pengguna. Tahap pertama adalah formulasi query, yang mencakup dua sub-tahap yaitu pra-pemrosesan pertanyaan yang masuk dan tahap formulasi  untuk mendapatkan kueri yang lebih baik . Tahap kedua adalah tahap pencarian informasi, saat di mana kueri  yang telah dibuat dicocokan dengan data vektor  yang relevan dalam database . Tahap ketiga adalah penggalian dan pengolahan jawaban yang ditemukan (Maraoui et al., 2021
Wang et al., 2021) .  Dalam perancangan sistem tanya jawab 
dibutuhkan pengolahan data hadis yang sudah ada agar representasi vektor padat dalam ruang berdimensi tinggi yang 
menangkap makna semantik dari kalimat atau teks, proses tersebut dinamakan dengan embedding  (Saxena et al., 2020
2023) . Data vektor yang diperoleh kemudian disimpan pada database  vektor , dalam penelitian ini akan menggunakan ChromaDB  (GonzÃ¡lez -Santamarta et al., 2023 2023) . Kemudian dalam penelitian ini juga akan memanfaatkan Large Language Models (LLMs)  seperti GPT  dalam Question 
Answering System  agar fokus penelitian menjadi lebih signifikan (Dao,  2023) . LLMs  memainkan peran penting dalam meningkatkan kualitas jawaban yang dihasilkan oleh sistem tersebut (Huo et al., 2023) . Bantuan Langchain sebagai sebuah framework  orkestrasi untuk mengelola dan 
menyediakan akses ke berbagai layanan bahasa alami, seperti penerjemahan, ringkasan teks, jawaban pertanyaan, pembangkitan teks, dan inferensi bahasa alami (Jeong, 2023
2023) .Penggunaan LLMs  seperti model chat GPT  berfungsi untuk memahami pertanyaan dengan konteks yang lebih luas dan 
menyediakan jawaban yang lebih kontekstual (Y. Wang et  al., 2023) . Dengan memanfaatkan teknologi  Refined Query  ini 
diharapkan dapat membantu  pengembangan sistem tanya jawab  dapat mencapai tingkat kinerja yang lebih tinggi dalam menyediakan jawaban yang  sesuai dengan pertanyaan pengguna, terutama dalam konteks data hadis yang memiliki kompleksitas linguistik dan kontekstualitas yang tinggi.  

2. Metode Penelitian  
Alur yang digunakan pada penelitian ini terdiri dari beberapa proses, berikut proses dari penelit ian dapat dilihat pada gambar 1.   
Gambar 1. Alur Penelitian  
2.1. Perencanaan  
Pada tahap awal ini terdapat 4 proses yang akan dilakukan untuk menunjukkan tujuan dari penelitian. Proses pertama adalah identifikasi masalah yang diran cang untuk mengenali pencarian dari isu penelitian. Proses kedua adalah penentuan tujuan, bertujuan agar dapat menentukan target yang ingin dicapai dalam penelitian. Proses selanjutnya adalah menentukan batasan masalah, guna agar ruang lingkup dalam 
pembah asan tidak keluar dari tujuan penelitian. Proses terakhir adalah studi pustaka, dimana proses ini bertujuan untuk mencari referensi untuk membantu dalam penelitian dan juga untuk mendukung penelitian . 
2.2. Pengumpulan  Data  
Tahapan ini melibatkan pengumpulan data hadis yang akan dijadikan sumber utama. Jumlah data yang dikumpulkan untuk 
penelitian ini sebanyak 5.362 hadis pada Kitab Shahih Muslim,  7.008 hadis pada Kitab Shahih Bukhari, 3.891 hadis pada Kitab Sunan at -Turmudzi, 4.590 hadis pada Kitab Sunan Abu Dawud, 4.332 hadis pada Kitab Sunan Ibnu Majah, 1.594 hadis pada Kitab Muwatta Malik, 5.662 hadis pada Kitab Sunan an-Nasa'I, 3.367 hadis pada Kitab Sunan Darimi, 26.363 hadis pada Kitab Musnad Ahmad, dengan total data 62.169 hadis yang akan digunakan pada penelitian ini (Rosdi et al., 2023) . Pengumpulan data hadis adalah kunci untuk menyediakan konten yang akan diproses dan dijawab oleh sistem  dalam bentuk TXT.  
2.3. Analisa dan Preprocessing  
Tahapan selanjutnya adalah menganalisa bagaimana format data yang dibutuhkan oleh sistem agar dapat diproses oleh model yang akan digunakan. Pada penelitian ini akan membutuhkan data dalam bentuk vektor agar dapat diproses. Kemudian untuk model bahasa yang akan digunakan pada penelitian adalah model GPT  dari OpenAI.  Selanjutnya proses preprocessing  yang akan dimulai dengan pengolahan data. Pada penelitian ini pengolahan data akan dilakukan proses embedding  pada data hadis agar mesin dapat memahami makna dari kata-kata dalam pertanyaan dan dokumen yang dijadikan ac uan (Huang et al., 2019) . 
2.4. Perancangan dan Implementasi  
Pada tahap perancangan berfokus pada bagaimana LangChain  dan OpenAI  Chat Model  akan diintegrasikan untuk meningkatkan kemampuan sistem dalam menjawab pertanyaan dengan baik. Proses selanjutnya adalah implementasi yang 
melibatkan coding , integrasi sistem, dan pengaturan database . Keseluruhan proses ini bertujuan untuk menciptakan sistem yang mampu menjawab pertanyaan tentang hadis secara interaktif  
2.5. Pengujian  
Setelah sistem sudah diimplementasikan tahapan selanjutnya adalah melakukan pengujian yang bertujuan untuk menemukan 
dan memperbaiki bug serta memastikan kualitas jawaban yang diberikan sistem. Pengujian akan dilakukan dengan 3 tahapan 
pengujian.  Tahapan pertama  adalah penilaian dengan membandingkan jawaban saat menggunakan Refined Query  dan tanpa Refined Query . Tahapan kedua  adalah BERTScore  yang bertujuan untuk mengevaluasi metrik secara otomatis untuk 
text generation  (Zhang et al., 2019) . Tahapan terakhir adalah Pengujian kualitas jawaban dilakukan kepada orang yang sering berinteraksi dengan Hadis seperti mahasiswa Fakultas Ushuluddin  Universitas Islam Negeri Sultan Syarif  Kasim  dan beberapa ahli hadis . 

3. Hasil dan Pembahasan  
Pada bab ini akan dilakukan 2 tahapan yaitu pengimplementasian  hasil sistem yang sudah dirancang dan membahas tentang pengujian yang akan dilakukan.  
3.1. Implementasi Sistem  
Penelitian ini menghasilkan sebuah sistem tanya jawab untuk membantu pengguna untuk me ncari informasi dalam hadis yang 
diharapkan dapat memberik an kemudahan bagi pengguna. Dimana sistem yang dibangun ini menggunakan program Python, library Langchain, framework Streamlit, OpenAI chat model, database ChromaDB, dan Tiktoken . Alur untuk sistem dapat dilihat pada gambar 2 di  bawah.  
Gambar 2. Alur Sistem 
Gambar 2 menjelaskan gambaran alur sistem yang terdiri dari 2 tahapan utama. Tahap pertama adalah penyimpanan data hadis ke dalam database. Pada tahapan ini peneliti membaginya menjadi 3 proses dimana proses awal adalah mengelompokan 
data ke dalam bentuk chunk . Setelah itu dilanjutkan ke proses selanjutnya yaitu proses embeddings  dimana proses ini merepresentasi vektor dari kata, frasa, atau kalimat dalam bentuk angka (Feng et al., 2022) . Data vektor yang sudah terkumpul kemudian dimasukan ke dalam database ChromaDB . Tahap kedua adalah tahapan sistem tanya jawab agar dapat menjawab pertanyaan dimana pada tahapan ini dibagi kedalam beberapa  proses. Proses pertama ialah 
pengajuan kueri  atau pertanyaan yang ingin disampaikan ke sistem. Selanjutnya kueri atau pertanyaan tersebut dilakukan proses Refined Query  dimana proses ini adalah mekanisme penyempurnaan pertanyaan yang diajukan oleh pengguna diubah atau diperbaiki untuk meningkatkan kemungkinan mendapatkan jawaban yang lebih akurat dari sistem (Kim et al., 2022) . Proses ketiga adalah embedding  agar kueri atau pertanyaan yang sudah disempurnakan agar dapat dicocokan menggunakan semantic search  ke dalam database . Semantic search  merupakan proses pencarian informasi yang memahami makna dokumen dan pertany aan di luar kata kunci (Muennighoff, 2022) . Setelah ditemukan kecocokan didalam database  proses selanjutnya adalah rank result  dimana data yang cocok diberikan peringkat berdasarkan tingkat kecocokannya. Setelah rank sudah ditentukan maka data yang cocok  tersebut diolah lagi oleh LLMs  dari OpenAI  agar bisa mendapatkan jawaban yang akan ditampilkan kepada pengguna.   
Gambar 3. Halaman Awal Sistem  
Gambar 3 menampilkan halaman awal pada sistem tanya jawab , pengguna dapat memilih kitab hadis  yang diinginkan pada dropdown .  
Gambar 4. Tampilan setelah memberikan pertanyaan  
Gambar 4 menampilkan halaman awal pada sistem tanya jawab dan sudah berisi percakapan tanya jawab antara pengguna dan chatbot  yang sudah ditampilkan Refined Query . 
3.2. Pengujian Sistem  
Pengujian sistem dilakukan 3 tahap pengujian yang dimulai dengan pengujian terhadap Refined Query  dan di lanjutkan dengan pengujian BERTScore  dan ditutup dengan pengujian kualitas jawaban  
3.2.1. Pengujian Terhadap Refined Query  
Tabel  1 dibawah merupakan tabel yang menunjukan hasil dari Refined Query  yang sudah diuji mengubah query  awal menjadi query yang lebih baik lagi format pertanyaannya .  
Tabel 1. Perbandingan Query  Awal dan Refined Query  
Tabel Perbandingan Query  Awal dan Refined Query Query  Awal  Refined Query  
Jika saya menemukan barang di jalan, apakah saya boleh 
mengambilnya?  Apakah diizinkan mengambil barang yang 
ditemukan di jalan?  
Ketika saya sedang berpuasa, saya tidak sengaja meminum air karena saya lupa, bagaimana dengan puasa saya? apakah puasa saya akan diterima?  Apakah puasa seseorang masih sah jika ia secara tidak sengaja minum air karena lupa saat berpuasa?  
Saya akan melakukan perjalana jauh keluar kota dari kota 
pekanbaru ke jakarta, apakah saya boleh tidak melaksan akan puasa?  Apakah diperbolehkan tidak berpuasa ketika melakukan perjalanan jauh, seperti dari Pekanbaru ke Jakarta?  
Saat sedang berpuasa saya muntah, bagaimana dengan puasa saya?  Apakah puasa saya batal jika saya muntah saat sedang berpuasa?  
Pada saat shalat saya ingin membuang angin, namun karena sedang shalat saya menahannya, bagaimana dengan shalat saya?  Apakah shalat saya masih sah jika saya menahan buang angin saat sedang melaksanakan shalat?  Saya sedang malaksanakan sholat dan kemudian ada orang yang lewat didepan saya apa yang perlu saya lakukan ?  Apa yang harus saya lakukan jika ada orang yang lewat di depan saya saat saya sedang 
melaksanakan sholat?  
Dapat dilihat dari beberapa hasil dari Refined Query terdapat beberapa kata yang terdapat kesalahan tulisan namun masih dapat dimengerti dan diperbaiki dengan baik  oleh sistem.   Dapat dilihat juga  pada tabel diatas ada beberapa pertanyaan yang sifatnya cerita dapat diubah dengan baik menjadi pertanyaan yang lebih baku tanpa mengubah maksud dari pertanyaan yang diberikan penggun
Tabel 2. Perbandingan Hasil Jawaban Tanpa Refined Query dan Menggunakan Refined Query  Tabel Perbandingan Query  Awal dan Refined Query  
Query  Awal  Refined Query  
Saya memberi makan orang yang berpuasa, seperti apa pahala yang saya dapatkan?  Apa pahala yang diperoleh ketika memberi makan kepada orang yang berpuasa?  
Ketika saya sedang shalat, kemudian ada orang yang megucapkan salam kepada saya, apa yang harus saya lakukan?  Apa yang harus dilakukan jika seseorang mengucapkan salam kepada kita saat kita sedang shalat?  
Bagaimana cara membersihkan kaki yang telah terkena air liur anjing?  Bagaimana prosedur yang benar untuk membersihkan kaki yang telah tercemar oleh air liur anjing?  
Keutamaan Bulan Ramadhan?  Apa saja keutamaan Bulan Ramadhan?    
Tabel  Hasil Jawaban Tanpa Refined Query dan Menggunakan Refined Query  
Jawaban tanpa Refined Query  Jawaban Sesudah Refined Query  
Jika Anda menemukan barang di jalan, Anda harus mempersaksikannya kepada orang yang ad il dan tidak boleh mengubah atau menyembunyikannya. Kemudian, umumkanlah barang temuan tersebut sampai setahun lamanya untuk mencari pemiliknya. Jika pemilik barang tersebut tidak ditemukan, maka barang tersebut adalah harta Allah yang Dia berikan kepada siapa saja yang dikehendaki-Nya.  Menurut Hadith yang disampaikan, barang temuan boleh diambil dengan syarat tertentu. Pertama, orang yang menemukan harus mengumumkannya sampai setahun, jika tidak ada yang mengenali maka kenalilah tali dan wadahnya dan boleh  dimakan atau digunakan. Namun, jika pemiliknya datang maka barang tersebut harus dikembalikan kepada pemiliknya.  
Ya, puasa Anda masih sah. Jika Anda lupa dan tidak sengaja makan atau minum saat berpuasa, Anda harus meneruskan puasa Anda karena Allah telah memberi Anda makan dan minum.  Ya, puasa masih dianggap sah jika seseorang tidak sengaja makan atau minum karena lupa saat sedang berpuasa. Rasulullah shallallahu 'alaihi wasallam bersabda bahwa jika seseorang 
lupa lalu makan atau minum ketika sedang berpuasa maka hendaklah dia meneruskan puasanya karena Allah telah memberinya makan dan minum. Hal ini menunjukkan bahwa 
puasa tidak batal karena lupa makan atau minum.  
Berdasarkan hadis yang disampaikan, Rasulullah shallallahu 'alaihi wasallam bersabda bahwa  berpuasa saat dalam perjalanan bukan termasuk kebaikan dan hendaknya umat Islam mengambil keringanan yang telah Allah berikan. Anda diizinkan untuk tidak berpuasa ketika melakukan perjalanan jauh dari Pekanbaru ke Jakarta.  Berdasarkan hadis yang disampaik an, Rasulullah SAW menegaskan bahwa bukanlah termasuk kebajikan berpuasa dalam perjalanan dan mengajarkan kita untuk menerima rukhshah (keringanan) yang diberikan Allah SWT. Oleh karena itu, seseorang yang melakukan perjalanan jauh, seperti dari Pekanbaru ke Jakarta, diperbolehkan untuk tidak menjalankan ibadah puasa. Rasulullah SAW mengajarkan untuk mengambil keringanan yang Allah SWT berikan dalam situasi perjalanan.  
Puasa Anda masih sah jika Anda muntah tanpa disengaja saat sedang berpuasa. Namun, jika  Anda sengaja muntah, maka Anda wajib mengqadha puasa tersebut.  Berdasarkan hadis yang disampaikan, puasa Anda tidak batal jika Anda muntah tanpa sengaja saat sedang berpuasa. Namun, jika Anda sengaja muntah, maka Anda wajib mengganti (mengqadha') puasa te rsebut. Hal ini ditegaskan dalam beberapa hadis yang disampaikan oleh Abu Hurairah dari Nabi shallallahu 'alaihi wasallam.  
Shalat Anda sah selama tidak ada suara buang angin atau Anda tidak mencium bau yang keluar dari tubuh Anda. Jika Anda ragu dan tidak  yakin apakah telah buang angin atau tidak tanpa adanya suara atau bau, maka shalat Anda tetap sah dan tidak perlu keluar dari masjid atau mengulangi shalat. Namun, jika terbukti buang angin dengan mendengar suara atau mencium bau, maka Anda harus berwudhu  dan mengulangi shalat tersebut.  Berdasarkan hadis yang disampaikan, shalat tetap sah selama tidak ada keluarnya angin (kentut) yang dibuktikan dengan mendengar suara atau mencium bau. Jika seseorang buang angin ketika sedang shalat, maka ia harus 
berwudhu  dan mengulangi shalatnya. Namun, jika hanya merasa ingin buang angin tetapi tidak ada bukti suara atau bau, maka tidak perlu membatalkan shalatnya.  
Jika seseorang mencoba lewat di depan Anda saat Anda sedang shalat, Anda harus menghalanginya semampunya. Jika orang tersebut menolak untuk berhenti, maka hendaklah Anda memeranginya karena dia dianggap sebagai setan. Anda tidak boleh membiarkan seseorang lewat di hadapan Anda saat Anda shalat.  Berdasarkan hadis yang disampaikan, apabila ada orang yang mencoba  lewat di depan seseorang yang sedang sholat, maka orang yang sholat tersebut hendaknya menghalanginya semampunya. Jika orang tersebut menolak untuk tidak lewat, maka orang yang sholat diperbolehkan untuk memeranginya karena dianggap orang tersebut membawa  qarin atau setan. Rasulullah SAW juga menyampaikan bahwa sebaiknya orang yang akan lewat di depan orang yang sholat mengetahui bahwa lebih baik ia menunggu atau berdiri selama empat puluh (tidak diketahui apakah hari, bulan, atau tahun) daripada lewat di depannya.  
Jika Anda memberi makan orang yang berpuasa untuk berbuka, maka Anda akan mendapatkan pahala seperti pahala orang yang berpuasa tersebut tanpa mengurangi pahala orang yang berpuasa sedikitpun.  Orang yang memberi makan kepada orang yang berpuasa akan mendapatkan pahala yang sama seperti pahala orang yang berpuasa tersebut, tanpa mengurangi pahala dari orang yang berpuasa sedikitpun. Ini berlaku untuk setiap kali ia memberi makan orang yang berpuasa untuk berbuka. Pahala yang diberikan ini mencerminkan nilai dan keutamaan dari membantu dan mendukung orang lain dalam ibadah mereka.  
Maaf, saya tidak menemukan informasi tentang ini dalam konteks Hadis yang saya miliki. Apakah ada pertanyaan lain yang bisa saya bantu?  
Saat kita sedang melaksanakan shalat dan ada seseorang yang mengucapkan salam, kita tidak perlu menjawab salam tersebut secara lisan. Hal ini didasarkan pada praktek Nabi Muhammad SAW yang tidak menjawab salam saat beliau sedang shalat setelah kembali dari negeri raja Najasyi, karena dalam  shalat terdapat suatu kesibukan yang membutuhkan konsentrasi penuh. Seorang sahabat, Ibrahim, menyebutkan bahwa ia menjawabnya dalam hati.  
Dari hasil pengujian dapat  disimpulkan bahwa  setelah menggunakan Refined Query  hasil jawaban menjadi lebih baik dan beberapa pertanyaan yang sebelumnya tidak ada jawaban menjadi ada jawabannya.  
3.2.2. Pengujian BERTScore  
Tabel  2 di bawah merupakan tabel yang menunjukan hasil dari perhitungan menggunakan BERTScore  yaitu  BERTScore  menghitung nilai dari Precision , Recall, dan F1. 
ð‘…ðµð¸ð‘…ð‘‡ = 1
|ð‘¥|âˆ‘ ð‘šð‘Žð‘¥
ð‘¥Ì‚ð‘—âˆˆð‘¥Ì‚ ð‘¥ð‘–âŠ¤ð‘¥Ì‚ð‘—
ð‘¥ð‘–âˆˆð‘¥            (1) 
Persamaan (1) di  atas menjelaskan bahwa RBERT merupakan rumus yang men ghitung  nilai korelasi Pearson  (Recall ) antara skor BERT  dan kalimat referensi .  
ð‘ƒðµð¸ð‘…ð‘‡ = 1
|ð‘¥Ì‚|âˆ‘ ð‘šð‘Žð‘¥
ð‘¥ð‘–âˆˆð‘¥ ð‘¥ð‘–âŠ¤ð‘¥Ì‚ð‘—
ð‘¥Ì‚ð‘—âˆˆð‘¥Ì‚            (2) 
Persamaan (2) di  atas menjelaskan bahwa PBERT merupakan rumus yang mengukur  nilai presisi sejauh mana kesamaan antara kalimat referensi dan kalimat kandidat.  
ð¹ðµð¸ð‘…ð‘‡ = 2ð‘ƒðµð¸ð‘…ð‘‡  .  ð‘…ðµð¸ð‘…ð‘‡
ð‘ƒðµð¸ð‘…ð‘‡ +ð‘…ðµð¸ð‘…ð‘‡                         (3) 
Persamaan (3) di  atas menjelaskan bahwa FBERT merupakan rumus  yang menghitung  nilai F1 score  yang merupakan perbandingan harmonis antara presisi (PBERT) dan recall  
(RBERT) 
Tabel  Hasil Jawaban Tanpa Refined Query dan Menggunakan Refined Que ry 
Jawaban tanpa Refined Query  Jawaban Sesudah Refined Query  
Berdasarkan konteks Hadis yang diberikan, tidak ada informasi spesifik tentang proses pembersihan kaki jika terkena air liur anjing. Maaf, saya tidak menemukan informasi tentang ini dalam konteks Hadis yang saya miliki. Apakah ada pertanyaan lain yang bisa saya bantu?  Prosedur yang benar untuk membersihkan kaki yang tercemar oleh air liur anjing adalah dengan mencucinya sebanyak tujuh kali, salah satunya menggunakan tanah. Ini berdasarkan hadis yang menyatakan jika bejana dijilat anjing, ha rus dicuci tujuh kali dan salah satunya dengan tanah. Meskipun konteks hadis mengacu pada bejana, prinsip yang sama dapat diterapkan pada kaki yang tercemar.  
Bulan Ramadhan memiliki keutamaan yang besar dalam Islam, di mana Rasulullah SAW menyebutkan bahwa bulan ini lebih baik dari bulan-bulan lainnya, dan di dalamnya terdapat malam yang lebih baik dari seribu bulan. Orang yang berpuasa dan shalat malam di bulan Ramadhan dengan keimanan dan mengharap pahala akan diampuni dosa-dosanya seperti hari ia dilahirkan. Selain itu, di bulan Ramadhan pintu -pintu surga dibuka, pintu-pintu neraka ditutup, dan setan-setan dibelenggu.  Bulan Ramadhan memiliki keistimewaan dimana pintu-pintu surga dibuka dan pintu-pintu neraka ditutup, serta setan-setan dibelenggu. Ada mal am di dalamnya yang lebih baik daripada seribu bulan, dikenal sebagai Lailatul Qadar. Barangsiapa yang berpuasa dan shalat malam dengan keimanan dan mengharapkan pahala, dosa-dosanya akan diampuni seperti hari ia dilahirkan.  
Gambar 5  Grafik Nilai Precision   
Dapat dilihat pada gambar grafik diatas soal nomor 7 merupakan soal dengan nilai precision  sedangkan soal d engan nilai precision  terendah adalah soal nomor 3 Dapat disumpulkan bahwa soal nomor 3 mendapatkan nilai paling rendah karena terdapat nama kota yang tidak ada didalam database hadis dan nomor 7 mendapatkan nilai tertinggi karena jawaban yang diberikan banyak teks dari sumber hadis yang diambil.
Gambar 6 Grafik Nilai Recal   
Dapat dilihat pada gambar grafik diatas soal nomor 10 merupakan soal dengan nilai recall  sedangkan soal dengan nilai recall  terendah adalah soal nomor 5  
Dapat disumpulkan bahwa soal nomor 10 mendapatkan nilai tertinggi karena banyak hanya membuat kesimpulan dari sedikit data hadis dari database dan nomor 5 mendapatkan nilai paling rendah karena jawaban yang diberikan menyimpulkan dari banyak sumber hadis dalam database   
Gambar 7 Grafik Nilai F1  
Dapat dilihat pada gambar grafik diatas soal nomor 7 merupakan soal dengan nilai F1 sedangkan soal dengan nilai F1 terendah adalah soal nomor 3.  
3.2.3. Pengujian Kualitas Jawaban  
Pengujian ini dilakukan dengan bantuan 20 responden mahasiswa  dan 6 ahli hadis  yang akan menilai kualitas jawaban dari 10 soal dan jawaban yang sudah dipertanyakan 
sebelumnya menggunakan sistem yang telah dibangun.   
Tabel 3. Pilihan Jawaban dan Bobot Penilaian  
Tabel Pilihan Jawaban dan Bobot Penilaian  
Pilihan Jawaban Keterangan  Nilai Bobot  
STS Sangat Tidak Sesuai  1 
TS Tidak Sesuai  2 
N Netral  3 
S Sesuai  4 
SS Sangat Sesuai  5 
Tabel 4. Jumlah Jawaban  Kuesioner  Mahasiswa  
Tabel Jumlah Hasil Kuesioner Mahasiswa  
No Soal Jumlah Jawaban  Total Nilai  % 
SS S N TS STS 
1 6 11 2 1 0 82 82% 
2 15 5 0 0 0 95 95% 
3 8 6 6 0 0 82 82% 
4 13 4 0 3 0 87 87% 
5 10 7 2 1 0 86 86% 
6 6 7 4 3 0 76 76% 
7 13 7 0 0 0 93 93% 
8 8 11 1 0 0 87 87% 
9 12 8 0 0 0 92 92% 
10 10 15 3 2 0 93 93% 
Hasil pengolahan data dari jawaban kuesioner bagi mahasiswa Fakultas Ushuluddin  Universitas Islam Negeri Sultan Syarif Kasim  sebagai responden menunjukan nilai tertinggi ada pada soal nomor  2 dengan nilai 95% dan soal dengan nilai terendah ada pada soal nomor  6 dengan nilai 76%  dengan rata-rata ni lai 87,3% . 
Tabel 5. Jumlah Hasi l Kuesioner Ahli Hadis  
Tabel Jumlah Hasil Kuesioner Ahli Hadis  
No Soal Jumlah Jawaban  Total Nilai  % 
SS S N TS STS 
1 4 2 0 0 0 28 93,3% 
2 4 2 0 0 0 28 93,3% 
3 4 2 0 0 0 28 93,3% 
4 4 2 0 0 0 28 93,3% 
5 2 4 0 0 0 26 86,7% 
6 4 2 0 0 0 28 93,3% 
7 2 3 1 0 0 25 83,3% 
8 4 1 0 1 0 26 86,7% 
9 3 2 1 0 0 26 86,7% 
10 4 2 0 0 0 28 93,3%  
Hasil pengolahan data dari jawaban kuesioner kepada ahli hadis sebagai responden menunjukan nilai tertinggi ada pada soal nomor  1, 2, 3, 4 , 6, dan 10  dengan nilai 9 3,3% dan soal dengan nilai terendah ada pada soal nomor  7 dengan nilai 83,3% dengan rata -rata nilai 90,3%. 

4. Simpulan  
Berdasarkan hasil penelitian yang telah dilakukan, dapat disimpulkan bahwa penerapan Refined Query  dengan pengembangan sistem tanya jawab hadis telah menunjukkan hasil yang baik. Sistem ini mampu  membantu memperbaiki kueri sehingga sistem dapat  memberikan jawaban yang akurat dan relevan terhadap pertanyaan-pertanyaan seputar hadis, dengan memanfaatkan model GPT-4-1106-preview  dari OpenAI . 
Pengujian awal dilakukan dengan membandingkan jawaban dari sistem  sebelum dan sesudah menggunakan Refined Query , pengujian ini menghasilkan kesimpulan bahwa  setelah menggunakan Refined Query  hasil jawaban menjadi lebih baik dan beberapa pertanyaan yang sebelumnya tidak ada jawaban menjadi ada jawabannya Pengujian selanjutnya dilakukan  dengan menggunakan matrik  BERTScore  yang merupakan salah satu metode evaluasi yang digunakan untuk  mengukur kualitas teks yang dihasilkan oleh model bahasa. Hasil pengujian menunjukkan bahwa nilai rata-rata BERTScore adalah  0.80351 . Selain itu, pengujian lebih lanjut dilakukan dengan  menge valuasi terhadap kualitas jawaban yang diberikan oleh sistem menunjukkan hasil yang memuaskan, dengan perolehan nilai rata-rata sebesar 8 7.3% untuk pengujian kepada mahasiswa dan nilai rata-rata 90,3% untuk pengujian kepada ahli hadis . Angka ini mengindikasikan bahwa jawaban yang dihasilkan oleh sistem memiliki kualitas  yang tinggi terhadap pertanyaan yang diajukan oleh pengguna.  
Pencapaian ini semakin memperkuat bukti bahwa sistem tanya jawab hadis yang dikembangkan bantuan Refined Query  menghasilkan  performa yang baik dalam menghasilkan jawaban yang sesuai dan berkualitas . 

5. Referensi  
Abdul Aziz, A., Salleh, D. M., Fadylaw aty, S., Abdullah, S., & Norazmi Bin Nordin, M. (2021). Analysis Of Literature Review On Spiritual Concepts According To The Perspectives Of The Al -Quran, Hadith And Islamic Scholars. Turkish Journal of Computer and Mathematics Education (TURCOMAT) , 12(9), 3152 â€“3159. https://turcomat.org/index.php/turkbilmat/article/view/4790  
Ariyanto, A. D. P., fatichah, C., & Arifin, A. Z. (2021). Analisis Metode Representasi Teks Untuk Deteksi Interelasi Kitab Hadis: Systematic Literature Review. Jurnal RESTI (Rekayasa S istem Dan Teknologi Informasi) , 5(5), 992 â€“1000. https://doi.org/10.29207/RESTI.V5I5.3499  
Bansal, A., Eberhart, Z., Wu, L., & Mcmillan, C. (2021). A Neural Question Answering System for Basic Questions about Subroutines. ArXiv Preprint . arXiv:2101.03999v1  
Dao, X. -Q. (2023). Performance Comparison of Large Language Models on VNHSGE English Dataset: OpenAI ChatGPT, Microsoft Bing Chat, and Google Bard. ArXiv Preprint .arXiv:2307.02288  
Feng, F., Yang, Y., Cer, D., Arivazhagan, N., & Wang, W. (2022). Language -agnostic BERT Sentence Embedding. Proceedings of the Annual Meeting of the Association for Computational Linguistics , 1, 878 â€“891. https://doi.org/10.18653/V1/2022.ACL -LONG.62  
GonzÃ¡lez -Santamarta, M. A., RodrÃ­guez -Lera, F. J., Angel, Â´, Guerrero -Higueras, M.,  & MatellÃ¡n -Olivera, V. (2023). Integration of Large Language Models within Cognitive Architectures for Autonomous Robots . https://arxiv.org/abs/2309.14945v1  
Huang, X., Zhang, J., Li, D., & Li, P. (2019). Knowledge graph embedding based question answering.  WSDM 2019 - Proceedings of the 12th ACM International Conference on Web Search and Data Mining , 105 â€“113. https://doi.org/10.1145/3289600.3290956  
Huo, S., Arabzadeh, N., & Clarke, C. L. A. (2023). Retrieving Supporting Evidence for LLMs Generated Answers. ArXiv Preprint . https://arxiv.org/abs/2306.13781v1  
Jeong, C. (2023). A Study on the Implementation of Generative AI Services Using an Enterprise Data -Based LLM Application Architecture. Advances in Artificial Intelligence and Machine Learning , 03(04), 1588 â€“1618. 
https://doi.org/10.54364/AAIML.2023.1191  
Kim, R., Research, A. G., Webster, K., Research, G., Collins, M., & Narayan, S. (2022). Query Refinement Prompts for Closed -Book Long -Form Question Answering. ArXiv Preprint . arXiv:2210.17525v1  
Maraoui, H., H addar, K., & Romary, L. (2021). Arabic Factoid Question -Answering System for Islamic Sciences Using Normalized Corpora. Procedia Computer Science , 192, 69â€“79. DOIâ€¯: 10.1016/J.PROCS.2021.08.008  
Muennighoff, N. (2022). SGPT: GPT Sentence Embeddings for Semantic Search. ArXiv Preprint . https://arxiv.org/abs/2202.08904v5  
Niâ€™mah, A. T., & Arifin, A. Z. (2020). Perbandingan Metode Term Weighting terhadap Hasi l Klasifikasi Teks pada Dataset 
Terjemahan Kitab Hadis. Rekayasa , 13(2), 172â€“180. 
https://doi.org/10.21107/REKAYASA.V13I2.6412
Rosdi, A. Z., Hassan, S. N. S., Muhamad, N. A. F., Zainuzi, N. I. H. M., & Mahfuz, M. S. (2023). Panduan Asas Kaedah Kenal Pasti Status Hadis: Kajian Diskriptif Penggunaan Ensiklopedia Hadis 9 Imam. Journal Of Hadith Studies , 46 â€“54. https://doi.org/10.33102/JOHS.V8I1.225  Saxena, A., Tripathi, A., & Talukdar, P. (2020). Improving Multi -hop Question Answering over Knowledge Graphs Usi ng Knowledge Base Embeddings. Proceedings of the Annual Meeting of the Association for Computational Linguistics , 4498 â€“4507. https://doi.org/10.18653/V1/2020.ACL -MAIN.412  
Supriyadi, T., Julia, J., Aeni, A., Learning, E. S. -I. J. of, & 2020, undefined. (202 0). Action Research in Hadith Literacy: A Reflection of Hadith Learning in The Digital Age. Ijlter.Net , 19(5), 99 â€“124. https://doi.org/10.26803/ijlter.19.5.6  
Topsakal, O., & Akinci, T. C. (2023). Creating Large Language Model Applications Utilizing LangCha in: A Primer on Developing LLM Apps Fast. All Sciences Proceedings . https://doi.org/10.59287/icaens.1127  
Wang, J., Yi, X., Guo, R., Jin, H., Xu, P., Li, S., Wang, X., Guo, X., Li, C., Xu, X., Yu, K., Yuan, Y., Zou, Y., Long, J., Cai, Y., Li, Z., Zhang, Z.,  Mo, Y., Gu, J., â€¦ Xie, C. (2021). Milvus: A Purpose -Built Vector Data Management System. Proceedings of the ACM SIGMOD International Conference on Management of Data , 2614 â€“2627. https://doi.org/10.1145/3448016.3457550  
Wang, Y., Ma, X., & Chen, W. (2023). Augmenting Black -box LLMs with Medical Textbooks for Clinical Question Answering. 
ArXiv Preprint . https://arxiv.org/abs/2309.02233v1  
Yu, C. -W., Chuang, Y. -S., Lotsos, A. N., & Haase, C. M. (2023). Decoding Affect in Dyadic Conversations: Leveraging Semanti c Similarity through Sentence Embedding. ArXiv Preprint . arXiv:2309.12646v1  
Zhang, T., Kishore, V., Wu, F., Weinberger, K. Q., & Artzi, Y. (2019). BERTScore: Evaluating Text Generation with BERT. 8th International Conference on Learning Representations, ICLR 2020 . https://arxiv.org/abs/1904.09675v3  ",Optimasi Pertanyaan,"Refined Query, BERTScore, LangChain, Large Language Models",data hadits,"precision, recall, F1"
APLIKASI CHATBOT  BERBASIS WEB  PADA SISTEM INFORMASI LAYANAN PUBLIK KESEHATAN DI MALANG DENGAN MENGGUNAKAN METODE TF-IDF ,"APLIKASI CHATBOT  BERBASIS WEB  PADA SISTEM INFORMASI LAYANAN PUBLIK KESEHATAN DI MALANG DENGAN MENGGUNAKAN METODE TF-IDF 

Dhebys Suryani Hormansyah1, Yoga Putera Utama2 

Abstrak  
Salah satu website yang dapat digunakan untuk mencari informasi mengenai layanan kesehatan di Kota malang yaitu melalui website www.malangkota.go.id  . Website tersebut merupakan website resmi dari pemerintah. Pengunjung website memperoleh informasi mengenai layanan kesehatan dengan cara mengakses website  tersebut . Informasi tersebu t dirasa kurang memudahkan dalam mencari data karena tidak terdapat fasilitas pencarian pada menu layanan kesehatan sehingga pengunjung harus melihat data satu per satu. Penyampaian 
informasi juga kurang interaktif karena informasi hanya berbentuk tabel dan tidak memiliki customer service. Oleh karena itu untuk mengatasi masalah tersebut dapat dibuatkan sebuah aplikasi yang dapat digunakan sebagai pengganti customer service berupa aplikasi chatbot. Chatbot adalah sebuah program komputer yang dirancang untuk  mensimulasikan sebuah percaka pan atau komunikasi yang interaktif kepada pengguna (manusia) melalui bentuk teks, suara, dan visual. Dengan adanya  aplikasi  tersebut  para pengunjung dapat melakukan tanya jawab  pada aplikasi  untuk memberikan informasi yang terkait layanan kesehatan di kot a Malang.  Hasil pada aplikasi  yang dibuat, pengunjung dapat melakukan tanya jawab pada aplikasi melalui website. Aplikasi yang dibuat telah diuji untuk mengetahui  ketepatan  dari jawaban sistem aplikasi  dengan melalui pengujian Recall  dan Precision . 
 
Kata kunci : layanan publik kesehatan kota malang, chatbot , tf-idf,cosine similarity,  web service, virtual customer service.  
  
1. Pendahuluan  
1.1 Latar Belakang  
Layanan publik merupakan suatu media yang disediakan oleh pemerintah untuk dapat memberikan informasi terkini kepada masyarakat. Dengan adanya layanan publik diharapkan masyarakat dapat memanfaatkan layanan tersebut semaksimal mungkin. Layanan tersebut terdiri dari pelayanan barang dan jasa, pelayanan barang yaitu pelayanan yang menghasilkan berbagai bentuk / jenis barang yang digunakan oleh publik, misalnya jaringan telepon, penyediaan tenaga listrik, air bersih, dan sebagainya. Sedangkan pelayanan jasa yaitu pelayanan yang menghasilkan berbagai bentuk jasa yang dibutuhkan oleh  publik, misalnya pendidikan,  pemeliharaan kesehatan, penyelenggaraan transportasi, pos, dan lain sebagainya. Kota Malang merupakan sebuah kota yang terletak di Provinsi Jawa Timur, yang merupakan kota terbesar kedua setelah Surabaya, Kota Malang tersebut memiliki layanan publik yang  banyak mulai dari bidang kependudukan, transportasi, pendidikan dan kesehatan. Pada layanan publik kesehatan di Kota Malang memiliki layanan publik kesehatan 
yang tersebar di daerah - daerah. Layanan kesehatan tersebut akan menjadi kurang optimal apabila masyarakat tidak mengetahui informasi mengenai layanan publik tersebut. Salah satu website yang dapat digunakan untuk mencari informasi mengenai layanan kesehatan di Kota malang yaitu melalui website www.malangkota.go.id . Website tersebut merupakan website resmi dari pemerintah. Pengunjung website memperoleh informasi mengenai layanan kesehatan dengan cara mengakses website, dan dapat melihat informasi pada halaman website. Informasi tersebut dirasa kurang memudahkan dalam mencari data karena tidak terdapat fasilitas pencarian pada menu layanan kesehatan sehingga pengunjung harus melihat data satu per satu. Penyampaian informasi juga kurang interaktif karena informasi hanya berbentuk tabel dan tidak memiliki customer service. Customer service  dapat melayani pengunjung yang ingin bertanya mengenai layanan kesehatan namun karena keterbatasan untuk melayani pengunjung 24 jam penuh. Oleh karena itu untuk mengatasi masalah tersebut dapat dibuatkan sebuah  sistem  aplikasi yang dapat digunakan sebagai pengganti customer service  berupa sistem aplikasi chatbot . Chatbot  adalah sebuah program komputer yang dirancang untuk mensimulasikan sebuah percakapan atau komunikasi yang interaktif kepada peng guna (manusia) melalui bentuk teks, suara, dan visual. Nantinya  sistem  aplikasi tersebut digunakan agar website terlihat lebih interaktif karena dapat melakukan tanya jawab untuk memberikan informasi yang terkait layanan kesehatan di kota Malang. Sistem Aplikasi chatbot juga membutuhkan suatu metode yaitu metode Tf-Idf, dengan menggunakan metode Tf-Idf, Sistem aplikasi chatbot dapat mencari kata kunci dari dokumen yang terkait layanan publik kesehatan di Kota Malang. Nantinya kata kunci dan isi dokumen ter sebut dijadikan sebagai pengetahuan dasar ( base knowledge ) pada sistem aplikasi. Dari permasalahan tersebut diusulkan sebuah sistem aplikasi chatbot menggunakan metode Tf-Idf sebagai pengganti customer service .  
1.2 Rumusan Masalah  
Berdasarkan latar belakang m asalah dan identifikasi masalah tersebut, rumusan dari penelitian ini adalah Bagaimana membuat sistem aplikasi chatbot yang menerapkan metode TF-IDF sebagai pengganti customer service sebagai layanan publik kesehatan di Kota Malang?   
1.3 Batasan Masalah  
1. Sistem a plikasi terdiri dari dua user yaitu admin dan user.  
2. Pengunjung dapat  menggunakan chatbot sebagai customer service  dengan sarana tanya jawab mengenai layanan publik kesehatan di Kota Malang  
3. Pengunjung dapat bertanya pada chatbot yang berkaitan dengan layanan publik kesehatan di Kota Malang, meliputi data praktek dokter obsetri dan ginekologi, data praktek dokter umum, data puskesmas dan data rumah sakit umum.  
4. Sistem aplikasi menggunakan bahasa pemrogaman PHP (Hypertex Preprocessor), JavaScript ,CSS, dan HTML.  

2. Landasan Teori   
2.1 Chatbot   
Chatbot adalah sebuah program komputer yang dirancang untuk mensimulasikan sebuah percakapan atau komunikasi yang interaktif kepada pengguna (manusia) melalui bentuk teks, suara, dan atau visual. Percakapan yang terjadi antara komputer dengan manusia merupakan bentuk respon dari program yang telah dideklarasikan pada database program pada komputer. Kemampuan komputer dalam menyimpan banyaknya data tanpa melupakan satu pun informasi yang disimpannya digabungkan dengan kepraktisan  bertanya pada sumber informasi langsung dibandingkan dengan mencari informasi sendiri serta kemampuan learning yang dimilikinya menyebabkan chatbot adalah customer service yang handal.  
Teknologi chatbot merupakan salah satu bentuk aplikasi Natural Language Processing, NLP itu sendiri merupakan salah satu bisang ilmu Kecerdasan Buatan ( Artificial Intelligence ) yang mempelajari komunikasi antara manusia dengan komputer melalui bahasa alami. (Kusumadewi, 2003)  
2.2 PHP  
Hypertex Preprocessor  (PHP) adalah skrip yang berjalan pada server side yang ditambahkan dalam HTML. PHP itu s endiri merupakan singkatan dari Personal Home Page Tools. Skrip ini akan membuat suatu aplikasi yang dapat diintegrasikan kedalam HTML sehingga suatu halaman HTML tidak lagi bersifat statis, namun menjad i bersifat dinamis. Sifat server side membuat pengerjaan skrip tersebut dikerjakan di server sdangkan yang dikirimkan kepada browser adalah hasil proses dari skrip tersebut yang sudah berbentuk HTML. PHP dibuat pada tahun 1994 oleh Rasmus Lerdfort. Tetapi dikembangkan oleh orang lain dan setelah melalui tiga kali karya penulisan, akhirnya PHP menjadi bahasa Universitas Sumatera Utara Pemograman Web. PHP adalah sebuah produk yang berbentuk open source, sehingga source code-code dari PHP dapat digunakan, diga nti, diedit tanpa harus membayar atau dikenakan biaya .(Sidik, 2001)   
2.3 Aplikasi Berbasis Web   
Aplikasi atau perangkat lunak (software) merupakan bagian yang tidak terpisahkan dan suatu sistem komputer, disamping keberadaan pengguna, perangkat keras dan jaringan . jika dilihat dari lingkungan pengembangannya, aplikasi dapat dibagi menjadi aplikasi berbasis desktop, aplikasi berbasis web dan aplikasi berbasis mobile. Aplikasi berbasis desktop merupakan aplikasi yang memerlukan proses instalasi di setiap komputer yang akan  menggunakannya. Contoh aplikasi berbasis  desktop antara lain Microsoft Office, Mozilla Firelox, Adobe Photoshop dan Macromedia Dreamweaver. Sementara itu, aplikasi berbasis web tidak memerlukan instalasi di setiap komputer karena aplikasi berada di suatu server. Untuk membuka aplikasi cukup meng gunakan browser yang terhubung melalui jaringan ke server.  Situs web merupakan salah satu contoh jenis aplikasi berbasis web. Jenis aplikasi yang ketiga yaitu aplikasi berbasis mobile merupakan aplikasi yang hanya dapat dijalankan pada perangkat bergerak  (mobile) seperti handphone, smartphone dan PDA. Contoh dan jenis aplikasi ini antara lain browser Opera Mini, Blackberry Messenger (BBM), WhatsApp Messenger dan Polaris Office  (Solichin, 2016). Berdasarkan IEEE (1990), definisi Black Box Testing adalah (1)  proses pengujian dimana mekanisme internal dari sebuah komponen atau sistem diabaikan dan berfokus kepada kondisi eksekusi serta nilai keluaran yang dihasilkan sebagai respon terhadap nilai input yang dipilih. (2) Proses pengujian yang  dilakukan untuk mengevaluasi pemenuhan sistem atau komponen dengan  kebutuhan fungsional tertentu  (IEEE, 1991)   
2.5 Recall  dan Precission   
Teknik yang digunakan pada saat pengujian sistem yaitu menggunkan Recall dan Precision.  Recall adalah prop orsi jumlah dokumen yang dapat ditemukan -kembali oleh sebuah proses pencarian di sistem IR. Rumusnya: Jumlah dokumen relevan yang ditemukan / Jumlah semua dokumen relevan di dalam koleksi.  Sedangkan, precision adalah proporsi jumlah dokumen yang ditemukan  dan dianggap relevan untuk kebutuhan si pencari informasi. Rumusnya: Jumlah dokumen relevan yang ditemukan / Jumlah semua dokumen yangditemukan .(Lestari,tanpa tahun)   
2.6 Metode TF IDF   
Metode Term Frequency -Inverse Document Frequency  (TF-IDF) adalah cara pemberian bobot hubun gan suatu kata (term) terhadap dokumen.  
a. Perhitungan Term Frequency  (tf) menggunakan persamaan : 
-1 
Dengan tf adalah term frequency , dan 
adalah banyaknya kemunculan term dalam dokumen, Term frequency  (tf) dihitung dengan menghitung banyaknya kemunculan term dalam dokumen 
b. Perhitungan Inverse Document Frequency (idf), menggunakan  persamaan : 
-2
Dengan 
adalah inverse documen t 
frequen cy, N adalah jumlah dokumen yang terambil oleh sistem, dan 
adalah 
banyaknya dokumen dalam koleksi dimana term muncul di dalamnya.  
c. Perhitungan term frequency Inverse Document Frequency (tfidf), menggunakan persamaan : 
-3
Dengan 
adalah bobot dokumen, N adalah Jumlah dokumen yang terambil oleh sistem, 
adalah banyaknya kemunculan term pada dokumen, dan 
adalah banyaknya dokumen dalam koleksi dimana term muncul di dalamnya. Bobot dokumen 
(
 ) dihitung untuk didapatkannya suatu bobot hasil perkalian atau kombinasi antara term frequency (
 ) dan Inverse Document Frequency (
 ).(Amin,2012)  
2.7 Cosine Similarity  
Perhitungan cosine similarity menggunakan persamaan : 
-4
Similaritas antara query dan dokumen atau Sim(q,dj) berbanding lurus terhadap jumlah bobot query (q) dikali bobot dokumen (dj) dan berbanding terbalik terhadap  akar jumlah kuadrat  q (|q|) dikali akar jumlah kuadrat dokumen (|dj|). Perhitungan similaritas menghasilkan bobot dokumen yang mendekati nilai 1 atau menghasilkan bobot dokumen yang lebih besar dibandingkan dengan nilai yang dihasilkan dari perhitungan inner product . (Amin,2012)   

3. Metodologi 
3.1 Metode Pengembangan Perangkat Lunak  
Dalam penelitian ini, pengembangan sistem aplikasi menggunakan metode pengembangan waterfall, dimana setiap tahapan di metode Waterfall menghasilkan satu atau lebih dokumen yang sudah disetujui. Tahap berikutny a tidak dapat dimulai sebelum tahapan sebelumnya selesai. Dalam tataran praktis, tahapan-tahapan tersebut saling tumpang tindih dan memberikan informasi satu sama lain. Pada waktu perancangan (design), masalah-masalah dengan persyaratan diidentifikasi. Pada waktu pengkodean (coding), dapat ditemukan masalah perancangan, walaupun juga masalah lainnya. Proses pengembangan perangkat lunak bukan merupakan model  linier yang sederhana karena juga melibatkan umpan balik (feedback) dari  satu tahapan ke tahapan lainnya. Dokumen yang dihasilkan pada setiap tahapan ada kemungkinan harus diubah supaya sesuai dengan perubahan yang sudah dibuat. (Sommerville,2011) . 
Gambar 1 . Metode Waterfall  
 
4. Perancangan  
4.1 Data Flow Diagram (DFD)  
Data Flow  Diagram (DFD)  adalah representasi grafik dari sebuah sistem yang merupakan alat perancangan sistem yang berorientasi pada alur data. Data Flow Diagram (DFD) . Dibawah ini merupakan Data Flow Diagram (DFD)  dari Sistem Aplikasi Chatbot  Pada Sistem Informasi Layanan Publik Kesehatan di Malang yang sedang berjalan adalah sebagai berikut:   
Gambar 2 . DFD Level 0   
Kemudian dijabarkan lagi pada DFD Level 1 .  
Gambar 3 . DFD Level 1  

5. Implementasi   
Aplikasi ini dibangun menggunakan bahasa pemrogramman PHP , Javascript , CSS, HTML  dan dengan menggu nakan database MySQL .  
5.1. Halaman User   
Pada halaman ini user dapat memberikan pertanyaan mengenai layanan publik kesehatan di Kota Malang  yaitu mengenai data dokter umun , data dokter kandungan, data puskesmas, dan data rumah sakit umum.   
Gambar 4 Halaman User 
Requirements analysis and definition  
System and software design  
Implementation and unit testing  
Integration and system testing  
Operation and maintenance  
Berikut adalah halaman utama sistem aplikasi chatbot, halaman ini di tampilkan pada awal sistem di jalankan terdapat input box untuk chat dengan sistem dan halaman menu admin dimana admin dapat melakukan log in.   
Gambar 5  Halaman Utama   
5.3. Halaman  Menu Admin   
Halaman menu admin berisikan mengenai aksi yang dilakukan untuk mengolah data dengan menggunakan metode Tf-Idf. 
Gambar 6 Halaman  Menu Admin  
 
6. Pengujian  dan Pembahasan  
Pengujian  yang dilakukan pada sistem aplikasi chatbot  yaitu  mengguna kan BlackBox testing yang dimaksudkan agar diketahui apakah hasil keluaran konten dari sistem berjalan sesuai dengan fungsinya.  Pengujian juga dilakukan dengan recall  dan precission .  
 
7. Kesimpulan dan Saran  
7.1 Kesimpulan  
Berdasarkan pembahasan yang telah dilakukan pad a bab I hingga bab VI, maka dapat disimpulkan bahwa:  
a. Sistem ini dapat menggunakan data excel sebagai data awal.  
b. Sistem ini dapat merubah data excel menjadi array dan juga dilakukan proses prepocessing (filter data array) dengan menghilangkan simbol-simbol.  
c. Sistem ini dapat  Melakukan  Tokenezing (Memisah kata penyusun dari suatu dokumen) dan menghitung score Tf-Idf tiap kata tersebut pada tiap array.  
d. Penggunaan Metode Tf -Idf dan cosine similarity untuk mencari jawaban pada sistem   
7.2 Saran  
Saran yang diberikan untuk pengembangan sistem ini ke depannya adalah sebagai berikut :  
a. Optimasi sistem lebih ditingkatkan ketika memproses pencarian jawaban.  
b. Hasil respon dari sistem dapat ditingkatkan dengan memisahkan jawaban sesu ai dengan konten pertanyaaan user seperti alamat, no tlp, fasilitas maka sistem menampilkan hanya pertanyaan yang bersangkutan .  
 
Daftar Pustaka:  
Sri Kusumadewi. 2003. â€œ Artifical Intelegence (Teknik dan Apliksinya)  â€œ. Yogyakarta : Graha Ilmu  
Betha Sidik. 2 001. â€œ Pemrograman Web PHPâ€ . Bandung : Penerbit Informatika.  
Achmad Solichin. 2016. â€œPemrograman Web dengan PHP dan MySQLâ€ . Penerbit Budi Luhur.  IEEE, IEEE Std 610.12 -1990 â€“ â€œIEEE Standard Glossary of Software Engineering Terminology, Corrected Edition, in IEEE Software Engineering Standard s Collection, The Institute of Electrical and Electronics Engineersâ€ , New York, 1991.  
Nisaa Putri Lestari , â€œUji Recall And Precision Sistem Temu Kembali Informasi Opac Perpustakaan Its Surabayaâ€ . Departemen Ilmu Informasi  Dan Perpustakaan. Universitas Airlangga  
Fatkhul Amin, 2012. â€œSistem Temu Kembali Informasi dengan Metode Vector Space Modelâ€ . Ejournal undip  Sommerville, I. 2011 .â€œSoftware Engineering 9th Editionâ€ . Addison -Wesley  http://ma langkota.go.id/layanan -publik/kesehatan/  , diakses pada 20 maret 2017  http://dinkes.malangkota.go.id   , diakses pada 27 
maret 2017  
Adhit Herwansyah. â€œAplikasi Pengkategorian Dokumen Dan Pengukuran Tingkat Sim ilaritas Dokumen Menggunakan Kata Kunci Pada Dokumen Penulisan Ilmiah Universitas Gunadarmaâ€.  Ejurnal gundarama  
Christopher D. Manning, Prabhakar Raghavan, Hinrich SchÃ¼tze. â€œAn Introduction to Information Retrievalâ€.  Cambridge University Press Cambridge, E ngland. Online edition (c) 2009 Cambridge UP  
Salton, G., â€œAutomatic information organization and retrievalâ€ , McGraw -Hill, New York. 1968  http://kominfo.pekalongankota.go.id/dow nload/Situs
_Web_Pemda.doc   , diakses pada 10 april 2017  http://kerinci.kemenag.go.id/2013/05/07/pentingnya -optimalisasi -website - institusi -pemeri ntah/   ,  diakses pada 10 april 2017",Aplikasi Chatbot Berbasis Web,"TF-IDF, cosine similarity",layanan publik kesehatan di Kota Malang,"recall, precision"
Sistem  Tanya Jawab dengan Web Semantik,"Sistem  Tanya Jawab dengan Web Semantik

Aâ€™la Syauqi  

Abstrak
Saat ini internet merupakan sarana favorit kebanyakan masyarakat dalam memperoleh informasi. Untuk mendapatkan informasi yang diinginkan mereka dengan mudah memasukkan kata kunci ke dalam layanan search engine yang telah tersedia. Namun informasi yang dimunculkan seringkali tidak sesuai dengan harapan. Pengguna harus memilih links (yang menyambung ke halaman lain) yang isinya terkadang tidak sesuai dengan kebutuhan. Penelitian ini bertujuan untuk menyelesaikan permasalahan tersebut dengan membuat sistem tanya jawab berbasis teknologi web semantik agar pengguna memperoleh informasi/jawaban yang sesuai dengan kebutuhan. Untuk penggunaan diperl ukan masukan berupa kalimat tanya yang kemudian diproses melalui empat tahapan untuk penemuan jawaban, ialah: teks processing, pencarian resource, eksekusi query sparql, dan penampilan jawaban. Dari pengujian ditunjukkan bahwa aplikasi mampu mengembalikan jawaban dengan baik. Akurasi ketepatan jawaban yang didapat mencapai 83,81%.  

Kata kunci aplikasi tanya jawab, web semantik, stemming, 
natural language processing  

I.  PENDAHULUAN  
Internet telah menjadi media yang mempermudah bagi setiap orang untuk mengakses sumber pengetahuan dan kebudayaan. Hal ini dimungkinkan karena adanya teknologi web yang semakin berkembang dari tahun ke tahun. Saat ini untuk mewujudkan website, baik organisasi atau perorangan bukan merupakan pekerjaan yang rumit lagi. Dengan begitu penyampaian informasi, ide, gagasan adalah hal yang mudah dilakukan. Demikian juga yang terjadi di Indonesia. Indonesia merupakan salah satu negara terbesar pengguna internet. Berdasarkan survei yang diselenggarakan oleh Asosiasi Penyelenggara Jasa Internet In donesia (APJII), jumlah pengguna internet di Indonesia mencapai 71,19 juta [1]. Dari jumlah tersebut, prosentase tertinggi pengguna internet di Indonesia dari sektor industri adalah pemanfaatan email 95,75%, disusul kemudian pencarian informasi atau berita  78,49%. Sedangkan di sektor konsumen, pemanfaatan internet untuk media sosial 88% dan sebagai sarana pencarian informasi atau berita 68%  [2]. Dari data tersebut menujukkan bahwa pemanfaatan internet untuk pencarian informasi atau berita menempati posisi yang penting.  Proses penemuan kembali informasi yang berguna melalui internet bisa saja menjadi sulit karena banyaknya dokumen web yang ada. Untuk memilah dokumen web yang sesuai dengan kebutuhan, pengguna dapat memanfaatkan layanan search engine yang telah  ada, misalnya: Google , Yahoo , Bing , dan sebagainya. Tetapi hasil yang disajikannya kurang spesifik, sebagai contoh untuk mendapatkan informasi yang diinginkan pengguna harus memilih links (yang menyambung ke halaman lain) yang terkadang tidak sesuai de ngan kebutuhan.  Dari masalah tersebut maka perlu dilakukan pembaharuan dalam teknik pencarian. Salah satunya yakni dengan membuat Sistem tanya jawab. Sistem tanya jawab merupakan suatu sistem yang mengijinkan pengguna menyatakan kebutuhan informasinya dalam pertanyaan, kemudian mengembalikan kutipan teks singkat sebagai jawaban. Sistem tanya jawab berbasis web yang dibangun bertujuan agar pengguna mendapat jawaban yang sesuai dengan kebutuhan.  

II. PENELITIAN TERKAIT  
Penelitian lain tentang teknologi semantic web diterapkan pada sistem rekam  medis  elektronik yang terintegrasi dengan sistem tanaman obat dengan metode sharing data [3]. Data  rekam  medis  yang  tersimpan  dalam  database, dapat diakses  dalam  konteks  semantik  dengan  melakukan  mapping  dalam  format  RDF (resource description framework).  Proses  query  data  dilakukan  dengan  menggunakan  query SPARQL.  Dari  hasil  ujicoba menunjukkan data dapat diakses melalui RDF map  tanpa  harus  mengakses  database  secara  langsung  sehingga  data  da pat  dikelola  user  sesuai  dengan kebutuhan.  Sistem tanya jawab pernah dibuat menggunakan metode yang menavigasi pengguna agar diperoleh jawaban yang benar. Metode ini berusaha untuk memfokuskan dalam proses pencarian jawaban jika pertanyaan yang diajukan oleh pengguna mengandung ketidakpastian. Hal ini dilakukan dengan mengkerucutkan topik yang diinginkan pengguna berdasarkan kata kunci dari dokumen-dokumen yang diperoleh. Kemudian pencarian dilakukan kembali berdasarkan kata kunci tersebut [4]. Teknik lain yang pernah digunakan dalam sistem jawab dengan mengotomasi kategorisasi yang interaktif. Metode ini terdiri dari empat tahap: konstruksi space feature, identifikasi dan pembobotan word berdasarkan topik, pemetaan semantik, dan perhitungan nilai simila ritas [5]. Penelitian tentang Sistem tanya jawab (Question Answering System) yang lain pernah dikerjakan dengan metode rule -based. Dari penelitian dihasilkan aplikasi desktop 
dengan menggunakan dokumen Terjemahan Al Qurâ€™an Surah 
Al Baqarah yang tersimpan d alam database relasional. Proses 
recall jawaban dimulai dengan memecah (parsing) suatu 
dokumen menjadi kalimat -kalimat. Kalimat -kalimat tersebut 
dipecah dan di -stem menjadi token. Begitu pula dengan 
kalimat pertanyaan pada query dipecah dan di-stem menjadi  
token. Token dari setiap kalimat dokumen maupun kalimat 
query diproses dalam rule sesuai dengan tipe pertanyaannya. 
Proses di dalam rule memberikan nilai untuk masing -masing 
kalimat dokumen. Kalimat yang memiliki nilai tertinggi akan 
dikembalikan sebagai jawaban. Akurasi rata-rata rule terhadap kueri dalam penelitian adalah 85.69%, sedangkan akurasi rata-rata rule terhadap kueri pengguna umum adalah 53 .14%  [6]. Question Answering System lainnya dikerjakan dengan menggunakan dokumen terjemah Juz Amma sebaga i sumber 
pengetahuan yang tersimpan dalam database. Dalam penelitian 
ini digunakan metodr wordmatch scoring dan rule based scoring. Penggunaan wordmatch scoring bertujuan untuk pemberian skor berdasarkan kesesuaian kata pada pertanyaan dan tipe jawaban. Sk or digunakan untuk menentukan kandidat 
jawaban berdasarkan pertanyaan yang diajukan oleh user. 
Skor juga digunakan untuk perangkingan jawaban/berdasarkan 
hasil pengukuran relevansi pada sistem presicion tertinggi 
adalah jawaban dari kata tanya siapa dan me ngapa. Recall 
tertinggi adalah jawaban dari kata tanya mengapa. Accuracy 
tertinggi adalah ja waban dari kata tanya mengapa [7]. 
Penelitian tentang penggalian informasi menggunakan 
Wikipedia sebagai basis pengetahuan juga telah dikerjakan. 
Penelitian ini ber fokus pada ekstraksi dan membuat 
penggunaan konsep, relasi, fakta dan deskripsi yang 
ditemukan di Wikipedia. Proses pengerjaannya dibagi menjadi 
empat kategori, yaitu : penggunaan Wikipedia ke dalam 
Natural Language Processing, pemanfaatan Wikipedia sebaga i 
fasilitas Information Retrieval dan Information Extraction, 
serta menggunakan Wikipedia sebagai sumber dari 
pembangunan ont ologi [8]. Pada penelitian ini dibuat sistem tanya jawab dengan penerapan semantik web dimana terdapat empat tahap dalam pemrosesan : teks processing, pen carian resource, eksekusi query SPARQL dan retrieve jawaban dari DBpedia.  

III. WEB SEMANTIK  
Semantic Web adalah perkembangan generasi berikutnya atau yang biasa disebut sebagai evolusi dari WWW (World Wide Web), yang dicetuskan pada tahun 2002. Semantic Web adalah Web yang mencakup dokumen, atau bagian dari dokumen, menggambarkan hubungan eksplisit antara hal dan berisi informasi semantik ditujukan untuk pemrosesan otomatis  oleh mesin (komputer) [9]. W3C (World Wide Web Consartium) mendefin isikan format metadata tersebut adalah Resource Description Framework (RDF). Tiap unit dari RDF adalah 3 komposisi, yaitu subject, predicate, dan object [10]. Subject dan object adalah entitas yang ditunjukkan oleh teks. Sedangkan predicate adalah komposis i yang menerangkan 
sudut pandang dari subject yang dijelaskan object. Hal yang 
paling menarik dari RDF yaitu object dapat menjadi subject yang nantinya diterangkan oleh object yang lainnya. Sehingga object atau masukan dapat diterangkan secara jelas dan detail, serta sesuai dengan keinginan pengguna yang memberikan masukan.  Dalam mencapai tujuannya dibutuhkan pemberian meaning kedalam masing-masing content (sebagai atribut) yang akan digunakan oleh teknologi web s emantic kedalam beberapa layer [11]. 
A. Ontology 
Ontology dapat didefinisikan sebagai suatu cara untuk mendeskripsikan arti dan relasi dari istilah-istilah. Ontology merupakan suatu teori. Deskripsi tersebut berisi classes terkadang juga disebut concept dan instances. Deskripsi ini dapat membantu sistem komputer dalam menggunakan istilah-istilah tersebut cara yang lebih mudah.  
B. SPARQL  
SPARQL Protocol dan RDF Query Language (SPARQL) adalah sebuah protocol  dan bahasa query untuk semantic web resources  [12]. SPARQL merupakan salah satu bahasa query yang di gunakan untuk melakukan query pada RDF ( Resource Description Framework ). Sama halnya dengan query SQL, SPARQL digunakan untuk me retrieve  data-data yang diinginkan. SQL digunakan untuk query pada data dari database yang terdiri dari satu atau beberapa tabel  sedangkan SPARQL ditujukan untuk query terhadap data pada RDF yang berupa triple. Query pada SQL dapat dilakukan cukup dengan mengetahui nama tabel dan atribut atau kolom tabel. Sedangkan untuk melakukan query SPARQL pada suatu file 
RDF setidaknya harus m engetahui resource, property dan 
value atau triple pada RDF tersebut  [13]. Untuk mengetahui 
triple pada RDF bisa dengan cara melakukan bentuk query 
DESCRIBE. Sebuah query yang menggunakan SPARQL dapat terdiri atas triple patterns , konjungsi (or) dan disjungsi (and). Kegunaan SPARQL dalam Sistem tanya jawab yang akan dibangun adalah untuk proses retrieve  jawaban dari sumber pengetahuan DBpedia.  
C. DBpedia  
DBpedia   merupakan sebuah komunitas yang bergerak untuk mengekstrak informasi terstruktur dari Wikipedia dan menyediakan infor masi tersebut dalam sebuah web [14]. Untuk mengakses pengetahuan (knowledge) DBpedia, digunakan URI (Uniform Resource Identifier) resource dari entitas dalam bentuk SPARQL [14]. Apabila URI resource diakses menggunakan Semantic Web agents, maka hasil yang ditampilkan adalah RDF descriptions. Sedangkan apabila diakses menggunakan Web Browser akan ditampilkan informasi dari entitas yang diakses dalam tampilan HTML sederhana.  
 D. Stemming  
Stemming merupakan suatu proses yang terdapat dalam sistem IR (Information Retrieval) yang mentransformasikan kata-kata yang terdapat dalam suatu kalimat ke kata-kata akarnya (root word) dengan menggunakan aturan-aturan tertentu. Stemming untuk bahasa yang satu berbeda algoritma stemming dengan bahasa lainnya. Sebagai contoh bahasa Inggris memiliki morfologi yang berbeda dengan bahasa Indonesia sehingga algoritma stemming untuk kedua bahasa tersebut juga berbeda. Pada umumnya kata dasar pada bahasa Indonesia terdiri dari kombinasi :  Prefix 1 + Prefix 2 + Kata das ar + Sufiks 3 + Sufiks 2 + Sufiks 1
Pada teks berbahasa Inggris, proses yang diperlukan hanya proses menghilangkan sufiks. Sedangkan proses stemming pada teks berbahasa Indonesia lebih kompleks karena terdapat imbuhan yang harus dibuang untuk mendapat kata  dasar (root word) dari sebuah kata.  Dari penelitian banyak algoritma yang telah ditemukan untuk keperluan stemming dengan keunggulan dan kelemahan masing-masing. Untuk bahasa Indonesia terdapat beberapa algoritma yang populer ialah algoritma Nazief and Ad riani, algoritma Arifin and Setiono, algoritma Vega,  serta algoritma Ahmad, Yusoff, and Sembok. Sistem tanya jawab yang akan dibangun menggunakan algoritma stemming Nazief and Adriani  karena dinilai paling efektif [15]. 

IV. METODE  
A. Diskripsi Sistem  
Pada penelitian ini tujuan pembangunan sistem adalah membuat aplikasi berbasis web untuk penggalian informasi dari internet dalam bentuk tanya jawab. Aplikasi ini dibangun dengan teknologi semantic web dengan sumber pengetahuan yang berasal dari DBpedia Indonesia. Sistem dari aplikasi yang dibangun terdiri dari beberapa tahap seperti ditunjukkan pada diagram blok gambar 1  
Gambar 1. Desain Sistem  
Berikut penjelasan secara rinci ta hap-tahap dari sistem yang dibangun : 
1) Tahap pertama, pengguna menginputkan pertanyaan. Selanjutnya kalimat tanya mengalami text preprocessing yang bertujuan untuk menghilangkan stop word dan penemuan kembali akar kata/kata dasar dari setiap kata dalam kalimat pertanyaan.  
2) Kemudian penentuan resource. Kata dasar yang diperoleh dari tahap sebelum nya digunakan dalam proses ini. Proses ini dilakukan dengan cara crawling website wikipedia, untuk memperoleh link url dokumen yang sesuai dengan resource Dbpedia.  
3) Tahap selanjutnya ialah proses ekstraksi teks dari resource Dbpedia dengan query SPARQL.  
4) Terakhir, informasi dari hasil ekstraksi query SPARQL ditampilkan kepada pengguna sebagai jawaban.  
B. Text Preprocessing  
Teks preprocessing adalah tahap pengolahan kalimat yang 
dimaksudkan untuk menghilangkan stop word dan memperoleh akar kata/kata dasar dari s etiap kata dalam kalimat tersebut. Tahap ini terdiri dari tiga bagian yaitu tokenizing, filtering, dan stemming sepe rti ditunjukkan dalam gambar 2   
Gambar 2. Flowchart Text Preprocessing  
Uraian dari masing -masing tahap tersebut adalah sebagai 
berikut:  
1) Tokenizing bertujuan untuk memecah kalimat menjadi 
satuan kata atau token. Algoritma dari tokenizing sebagaimana ditunjukkan gambar 3. Proses ini dimulai dengan 
penghilangan karakter atau simbol yang tidak diperlukan. Kemudian dilanjutkan dengan casefolding untuk merubah semua huruf teks menjadi huruf kecil. Proses ini diakhiri dengan pemecahan kalimat berdasarkan spasi sehingga diperoleh kata-kata penyusun kalimat.  
Gambar 3. Flowchart  Tokenizing  
 2) Filtering digunakan untuk menghilangkan kata -kata 
yang dianggap tidak penting. Algoritma filt ering ditunjukkan pada gambar 4. Proses filtering dilakukan dengan cara pencocokan kata dengan kamus stop word. Apabila kata cocok dengan kata yang ada dalam kamus stop word maka akan dihapus.   
Gambar 4. Flowchart Filtering  
3) Stemming digunakan untuk menghilangkan imbuhan pada kata sehingga diperoleh akar kata/kata dasarnya. Pada aplikasi yang dibangun diterapkan algoritma stemming Nazief & Adriani karena algoritma ini memiliki prosentase pre cission yang besar [16]. 
C. Pencarian Resource  
Pencarian resource bertujuan untuk penemuan URI resource  pada DBpedia yang diperlukan pada saat proses eksekusi SPARQL. Agar diperoleh URI resource yang sesuai, digunakan google custom search API untuk penelusuran artikel pada website Wikipedia. Gambar 5 menunjukkan tampilan dok umen wikipedia tentang internet .   
Gambar 5 . Dokumen Wikipedia  Tentang Internet  
Penelusuran dilakukan menggunakan keyword yang diperoleh dari teks preprocessing. Dari proses ini diperoleh beberapa link URL website wikipedia  yang sesuai dengan URI resource DBpedia. Tampilan dokumen DBpedia seperti pada gambar 6 .  Berikut contoh kesesuaian link URL dan URI resource: untuk artikel wikipedia dengan URL : http://id.wikipedia.org/wiki/Internet  maka memiliki URI resource :  DBpedia http://id.dbpedia.org/page/Internet .  Sedangkan algoritma pencarian resource ditunjukkan pada 
gambar 7 .  
Gambar 6 . Dokumen DBpedia  Tentang Internet  
Untuk mendapatkan resource dilakukan beberapa tahap yaitu 
input keyword pada sistem, keyword tersebut kemudian diproses menggunakan Google Custom Search Engine. Dari proses tersebut diperoleh indeks link yang selanjutnya diekstrak menggunakan format JSON. Dari hasil data berformat JSON tersebut kemudian dilaku kan proses pemotongan url dengan mengambil bagian path file atau resource-nya. Sehingga didapatkan suatu resource yang dibutuhkan untuk proses selanjutnya.   
Gambar 7 . Flowchart Pencarian  Resource  
D. Query SPARQL  
Resource yang telah diperoleh dari proses sebe lumnya, 
kemudian digunakan sebagai variabel URI dalam query SPARQL. Dalam istilah SPARQL, resource merupakan bagian dari URI resource yang digunakan sebagai penunjuk yang membawa informasi dalam suatu web. Gambar 8 menunjukkan contoh query SPARQL yang digu nakan dalam aplikasi:   
Gambar 8. Implementasi Resource pada Query SPARQL  
Dari eksekusi SPARQL tersebut diperoleh hasil berupa teks seperti yang ditunjukkan pada gambar 9  
Gambar 9. Hasil query SPARQL  
E. Desain Interface  
Tampilan Aplikasi Tanya Jawab yang di bangun didesain sesederhana mungkin dengan tujuan untuk memudahkan user dalam mengakses. Aplikasi tanya jawab berbasis web terdiri dari satu halaman yang memuat logo, texfield untuk mengajukan pertanyaan, button â€œtanyaâ€ untuk penemuan jawaban, tabel untuk menampilkan interpretasi pertanyaan, dan textarea untuk menampilkan hasil jawaban. Desain interface ditunjukkan pada gambar 10.   
Gambar 10. Desain Interface  
Pada tabel dimuat hasil interpretasi yang terdiri dari empat 
bagian yaitu :  
1) Pertanyaan yang telah diajukan  
2) Keyword yang ditemukan  
3) Link document pada Wikipedia  
4) Resource pada DBpedia  
Sedangkan pada text area dibagi menjadi dua bagian utama 
yaitu:  
1) Document extraction memuat hasil eksekusi query SPARQL yang merupakan jawaban untuk pertanyaan yang telah di ajukan . 
2) Source berisi links Wikipedia yang dirasa sesuai dengan jawaban yang dimunculkan.  

HASIL DAN PEMBAHASAN  
A. Pengujian  
Skenario pengujian dibuat untuk memperoleh hasil tingkat 
keakurasian aplikasi dalam menyajikan jawaban terhadap pertanyaan yang diajuka n oleh pemakai. Objek yang digunakan untuk pengujian adalah kalimat pertanyaan Bahasa Indonesia. Kalimat pertanyaan yang diproses harus berbahasa Indonesia baku. Kata tanya yang diajukan adalah dengan kata tanya 5W + 1H, ialah:  
1) Apa ( what ) 
Kata tanya â€œapaâ€ digunakan untuk awalan kalimat tanya dengan jawaban kata benda.  
2) Di mana (where)  
Kata tanya â€œdi manaâ€ digunakan untuk awalan kalimat tanya dengan jawaban tempat atau lokasi.  
3) Siapa (who)  
Kata tanya â€œsiapaâ€ digunakan sebagai awalan kalimat apabila kalimat tanya memerlukan jawaban berupa orang, group, kelompok, dan sebagainya.  
4) Kapan (when)  
Kata tanya â€œkapanâ€ digunakan sebagai awalan pada saat 
kalimat tanya memerlukan jawaban berupa waktu.  
5) Mengapa (why)  
Kata tanya â€œmengapaâ€ digunakan sebagai awalan pada kalimat tanya dimana jawaban yang diperlukan berupa sebab.  
6) Bagaimana (how)  
Kata tanya â€œbagaimanaâ€ digunakan sebagai awalan pada 
kalimat tanya dengan jawaban berupa deskripsi.  
7) Berapa  
Kata tanya â€œberapaâ€ digunakan pada awal kalimat tanya yang memerlukan jawaban berupa bilangan atau kuantitas suatu 
objek.  
Klasifikasi jenis pertanyaan yang digunakan dalam pengujian ditunjukkan pada tabel 1. Aplikasi ini dapat memproses pertanyaan yang memerlukan jawaban berupa bilangan, seperti pertanyaan tentang jarak, tinggi, usia, dan sebagainya. Akan tetapi, aplikasi tidak dapat memproses pertanyaan yang berbentuk perhitungan dan aritmatika.  
TABEL 1. KLASIFIKASI JENIS PER TANYAAN  
Kata Tanya  Tipe 
Jawaban  Contoh Pertanyaan  
Apa Benda  Apa yang dimaksud dengan smartphone ? 
Dimana  Lokasi  Dimana letak makam Bung Karno?  
Siapa  Orang  Siapa nama walikota Surabaya?  
Kapan  Waktu  Kapan Indonesia dinyatakan merdeka?  
Mengapa  Alasan  Mengapa Jepang menyerah kepada Belanda tahun 1945?  
Bagaimana  Deskripsi  Bagaimana proses metamorfosis berlangsung?  
Berapa  Integer (jarak, tinggi, usia dll) Berapa tinggi tugu Monas?  
Hasil pengujian yang telah dilakukan terhadap 
aplikasi s eperti ditunjukkan pada tabel 2, tabel 3, tabel 4, tabel 5, tabel 6, tabel 7, dan tabel 8. Masing -masing tabel menunjukkan jenis kalimat tanya beserta ketepatan jawaban yang dihasilkan.  
TABEL 2. TABEL UJI COBA PERTANYAAN TENTANG BENDA  
NO PERTANYAAN  JAWABAN  TEPAT  TIDAK  
1 Apa yang dimaksud dengan smartphone ? âˆš  
2 Apa warna bendera negara Jerman?  âˆš  
3 Apakah pengertian dari hardware ?  âˆš 
4 Apa nama maskot kota Surabaya?  âˆš  
5 Apa arti semboyan Bhineka Tunggal Ika?  âˆš  
6 Apa nama tarian khas Bali?   âˆš 
7 Apa makanan khas Yogyakarta?  âˆš  
8 Apakah judul lagu kebangsaan Indonesia?   âˆš 
9 Apa teori yang ditemukan oleh Albert Einstein?   âˆš 
10 Apa nama planet yang paling dekat dengan matahari?  âˆš  
11 Apa nama planet yang memiliki cincin?  âˆš  
12 Apa nama kota yang disebut kota hujan?  âˆš  
13 Apa makanan khas Lamongan?  âˆš  
14 Apa nama gunung di kota Batu?  âˆš  
15 Apa nama jembatan di kota Palembang ? âˆš  
TABEL 3. UJI COBA PERTANYAAN TENTANG LOKASI /TEMPAT  
NO PERTANYAAN  JAWABAN  TEPAT  TIDAK  
1 Dimana letak sungai Musi?  âˆš  
2 Dimana letak tugu Monas?  âˆš  
3 Dimana letak museum Radya Pustaka?  âˆš  
4 Dimana letak makam Bung Karno?  âˆš  
5 Dimanakah letak Je mbatan Ampera?  âˆš  
6 Dimanakah Pangeran Diponegoro dimakamkan?  âˆš  
7 Dimana letak kerajaan Majapahit?  âˆš  
8 Dimana letak Gunung Bromo?  âˆš  
9 Dimana tugu pahlawan berada?  âˆš  
10 Dimana tempat ibadah umat muslim?  âˆš  
11 Dimana letak jembatan suramadu?  âˆš  
12 Dimana letak pulau Raja Ampat?  âˆš  
13 Dimana lokasi Institut Teknologi Telkom?  âˆš  
14 Dimana lokasi Taman Safari Indonesia 2?  âˆš  
15 Dimana kota asal bahasa Osing?  âˆš   
TABEL 4. UJI COBA PERTANYAAN TENTANG ORANG  
NO PERTANYAAN  JAWABAN  TEPAT  TIDAK  
1 Siapa nama gubernur Jawa Timur?  âˆš  
2 Siapa nama istri Bung Karno?  âˆš  
3 Siapa pembuat sosial media Facebook?  âˆš  
4 Siapakah nama walikota Surabaya?  âˆš  
5 Siapakah CEO Apple Inc?  âˆš  
6 Siapakah nama kiper Arema?  âˆš  
7 Siapa pencipta lagu Indonesia Raya?  âˆš  
8 Siapa pencetus teori gravitasi?   âˆš 
9 Siapa pencetus teori relativitas?  âˆš  
10 Siapakah CEO Microsoft saat ini?  âˆš  
11 Siapakah proklamator kemerdekaan Indonesia?  âˆš  
12 Siapa vokalis Ungu band?  âˆš  
13 Siapa penemu listrik?   âˆš 
14 Siapa nama istri SBY?    âˆš  
15 Siapa nama gubernur Bank Indonesia?  âˆš  
TABEL 5. UJI COBA PERTANYAAN TENTANG WAKTU  
NO PERTANYAAN  JAWABAN  TEPAT  TIDAK  
1 Kapan Indonesia dinyatakan merdeka?  âˆš  
2 Kapan Gus Dur mulai menjabat sebagai presiden?  âˆš  
3 Kapan Dude Harlino lahir?  âˆš  
4 Kapan Nagita Slavina memulai karir?  âˆš  
5 Kapan tanggal lahir Bunga Citra Lestari?  âˆš  
6 Kapan sholat Idul Adha berlangsung?  âˆš  
7 Kapan perayaan natal berlangsung?  âˆš  
8 Kapan masa jabatan Jokowi sebagai Gubernur DKI Jakarta?  âˆš  
9 Kapan Hari Kebangit an Nasional diperingati?   âˆš 
10 Kapan Apollo 11 tiba di Bulan?  âˆš  
11 Kapan Soeharto berhenti menjadi presiden?  âˆš  
12 Kapan PKI dibubarkan?  âˆš  
13 Kapan TNI dibentuk?  âˆš  
14 Kapan terjadinya perjanjiann hudaibiah?  âˆš  
15 Kapan terjadinya perang badar?  âˆš   
TABEL 6. UJI COBA PERTANYAAN TENTANG  SEBAB  
NO PERTANYAAN  JAWABAN TEPAT  TIDAK  
1 Mengapa Jepang menyerah terhadap 
Belanda tahun 1945?  âˆš  
2 Mengapa terjadi perang sampit?  âˆš  
3 Mengapa Idul Adha disebut juga hari raya haji?  âˆš  
4 Mengapa Jogja diju luki sebagai daerah istimewa?   âˆš 
5 Mengapa terjadi gerhana bulan?  âˆš  
6 Mengapa terjadi gerakan Aceh merdeka?  âˆš  
7 Mengapa Bogor disebut kota hujan?  âˆš  
8 Mengapa Bali disebut pulau Dewata?   âˆš 
9 Mengapa Pontianak disebut kota Khatulistiwa?  âˆš  
10 Mengap a terjadi krisis moneter tahun 1998?  âˆš  
11 Mengapa Korea berpisah menjadi 2 wilayah?  âˆš  
12 Mengapa Malin Kundang dikutuk menjadi batu?  âˆš  
13 Mengapa Surabaya disebut kota Pahlawan?  âˆš  
14 Mengapa Edelweiss disebut bunga abadi?   âˆš 
15 Mengapa Timor Leste  berpisah dari Indonesia?  âˆš  
TABEL 7. UJI COBA PERTANYAAN TENTANG DESKRIPSI  
NO PERTANYAAN  JAWABAN  TEPAT  TIDAK  
1 Bagaimana proses metamorfosis berlangsung?  âˆš  
2 Bagaimana proses membuat tempe?  âˆš  
3 Bagaimanakah proses terbentuknya pelangi?   âˆš 
4 Baga imana cara menanam jagung?   âˆš 
5 Bagaimana cara menginstal ulang Windows?   âˆš 
6 Bagaimanakah cara merawat Kucing Anggora?   âˆš 
7 Bagaimana cara mengukur presisi?  âˆš  
8 Bagaimana aturan permainan gobak sodor?   âˆš 
9 Bagaimana cara mengukur akurasi?  âˆš  
10 Bagaimana aturan permainan catur?  âˆš  
11 Bagaimana proses terjadinya hujan?  âˆš  
12 Bagaimana proses terjadinya fotosintesis?  âˆš  
13 Bagaimana cara mencangkok tumbuhan?  âˆš  
14 Bagaimana cara menanam padi?   âˆš 
15 Bagaimana proses terjadinya gerhana matahari?  âˆš  
TABEL 8. UJI COBA PERTANYAAN TENTANG NILAI 
NO PERTANYAAN  JAWABAN  TEPAT  TIDAK  
1 Berapa panjang jalan tol Surabaya -Gempol?  âˆš  
2 Berapa tinggi tugu Monas?  âˆš  
3 Berapa banyak pulau di Indonesia?  âˆš  
4 Berapa luas Kebun Raya Purwodadi?  âˆš  
5 Berapa ba nyak suku yang ada di Indonesia?  âˆš  
6 Berapa tinggi gunung Bromo?  âˆš  
7 Berapa luas wilayah Taman Nasional Bromo Tengger Semeru?  âˆš  
8 Berapa diameter bunga Raflesia?  âˆš  
9 Berapa jarak Bumi dengan Matahari?  âˆš  
10 Berapa lama proses rotasi Bumi?  âˆš  
11 Berapa jarak dari surabaya ke jakarta?  âˆš  
12 Berapa personel JKT48?  âˆš  
13 Berapa tekanan darah normal manusia?  âˆš  
14 Berapa warna yang ada pada pelangi?   âˆš 
15 Berapa jumlah episode Running Man?  âˆš   
Setiap jawaban yang dihasilkan  dari masing-masing pertanyaan selanjutnya dilakukan pengukuran performansi. 
Pengukuran yang digunakan adalah recall , precission , dan 
accuracy . Pengukuran recall  digunakan untuk mengetahui 
kemampuan sistem untuk memanggil dokumen yang relevan. 
Sedangkan precission digunakan untuk  mengetahui kemampuan sistem untuk tidak memanggil dokumen yang tidak relevan.  Dari hasil pengujian diperoleh beberapa kemungkinan ialah:  
1) True Positive (TP) yaitu jawaban yang dihasilkan sistem benar  
2) False Positive (FP) yaitu jawaban yang dihasilkan salah 
atau sistem tidak menghasilkan jawaban  
3) True Negative (TN) yaitu pertanyaan yang diajukan tidak sesuai dengan ketentuan dan sistem tidak menghasilkan jawaban  
4) False Negative (FN) yaitu pertanyaan yang diajukan 
tidak sesuai dengan ketentuan tetapi sistem menghasilkan jawaban  
Berikut  rumus yang digunakan untuk menghitung precision  dan recall  beserta accuracy  pada sistem :    
Dari rumus precission, recall, dan accuracy maka dihasilkan masing -masing nilainya yang ditunjukka pada tabel 9  
TABEL 9. TABEL PERBAN DINGAN HASIL UJI COBA PERTANYAAN KESELURUHAN  
Precision  Recall  Accuracy  
83,81%  100%  83,81%   
B. Analisa  
Berdasarkan uji coba yang telah dilakukan, diketahui bahwa aplikasi tanya jawab yang telah dibangun mampu menemukembalikan jawaban dengan baik untuk setiap  
pertanyaan yang diajukan. Keakurasian aplikasi tanya jawab 
dengan adanya Algoritma stemming  Nazief & Adriani pada 
pemrosesan pertanyaan mencapai 83,81%.   
Gambar 11. Overstem yang Menyebabkan Kerancuan dalam  Menemukan Keyword   
Hasil analisa terhadap data uji coba diketahui bahwa akurasi jawaban dipengaruhi oleh hasil stemming yang menjadi keyword  dalam pencarian resource. Jenis kalimat tanya tidak mempengaruhi hasil jawaban, karena kata tanya yang digunakan tidak diproses pada sistem. Sistem memproses keyword  hasil text-preprocessing. Apabila terdapat overstem  pada hasil penemuan keyword , maka terjadi ketidaksesuaian resource  yang ditemukan sehingga jawaban yang ditampilkan menjadi rancu.   Gambar 11  menunjukkan  contoh hasil overstem  yang menyebabkan keyword tidak sesuai dengan pertanyaan yang diajukan. Pada proses stemming  tersebut, seharusnya keyword yang didapatkan adalah kata â€œarti hardwareâ€ atau â€œpengertian hardwareâ€. Namun, karena terjadi overstem  maka keyword  beserta jawaban yang diperoleh tidak sesuai dengan yang diharapkan.   
Gambar 12.  Contoh Pencarian T inggi Monas  
Selain terjadinya overstem , penyebab tidak ditemukannya jawaban adalah data tidak ditemukan pada dokumen yang ada 
pada DBpedia. Hal ini dikarenakan tidak semua artikel yang terdapat pada DBpedia mencakup segala pengetahuan yang dibutuhkan. Sebagai contohnya, ketika user bertanya mengenai  tinggi Monas seperti gambar 12  aplikasi memberikan jawaban yang sesuai. Namun ketika user bertanya mengenai tinggi menara Eiffel, aplikasi hanya memberikan jawaban berupa deskripsi singkat mengenai menara Eiffel dan tidak memberikan jawaban yang diharapkan seperti gambar 13 . Hal ini dikarenakan pada dokumen menara Eiffel yang terdapat pada DBpedia tidak terdapat data mengenai tinggi Menara tersebut .  
Gambar 13 .  Contoh Pencarian Tinggi Menara  Eiffel  
 
KESIMPULAN  
Kesimpulan yang diperoleh dari penelitian ini adalah sebagai berikut :  
1) Aplikasi Tanya Jawab dibangun deng an menerapkan semantic web pada sistem. Semantic web menjadi proses inti penggalian jawaban. Untuk mendapatkan jawaban, dilakukan pemrosesan pertanyaan yakni diawali dengan tokenizing, filtering dan stemming. Metode stemming yang digunakan adalah Algoritma  Nazief & Adriani. Dari hasil pemrosesan 
pertanyaan tersebut diperoleh keyword untuk melakukan pencarian resource. Resource digunakan sebagai URI resource atau petunjuk letak dokumen pada DBpedia. Setelah resource ditemukan, dokumen DBpedia tersebut kemudian diekstrak dengan menggunakan bahasa query SPARQL. Hasil ekstrak dokumen selanjutnya ditampilkan sebagai jawaban atas pertanyaan yang telah diajukan.  
2) Akurasi jawaban yang diperoleh dengan adanya pemrosesan pertanyaan menggunakan algoritma stemming Nazief  & Adriani mencapai 83,81%. Stemming merupakan bagian penting dalam suatu sistem temu balik karena hasil stemming mempengaruhi relevansi jawaban yang dihasilkan oleh sistem.  

REFERENSI  
[1]  Sinaga, R., 2014. APJII: penguna internet di Indonesia 
terus mening kat. [Online] Available at: http://www.antaranews.com/berita/414167/apjii -penguna -internet -di-indonesia -terus -meningkat [Accessed 24 March 2014]  
[2]  APJII, 2014. Profil Terkini Internet Industri Indonesia. [Online] Available at: http://www.apjii.or.id/v2/ read/content/info -terkini/213/press -release -profil -terkini -internet -industri -ind.html [Accessed 23 March 2014].  
[3]  Ana, N. & Syauqi, A., 2012. Implementasi Teknologi Semantic Web Pada Dokumentasi. In Seminar Nasional Ilmu Pengetahuan Teknik. Bandung, 201 2. LIPI.  
[4]  Fukumoto, J., Aburai, N., & Yamanishi, R., 2013. Interactive Document Expansion for Answer Extraction of Question Answering System. Procedia - Procedia Computer Science, 22, 991 â€“1000. doi:10.1016/j.procs.2013.09.184  
[5]  Song, W., Wenyin, L.,  Gu, N., Quan, X., & Hao, T., 2011. Automatic categorization of questions for user -interactive question answering. Information Processing, 
47(2), 147 â€“156. doi:10.1016/j.ipm.2010.03.002  
[6]  Anggraeny, Meinar Dwi. 2008. Skripsi : Implemetasi Question Answer ing dengan Metode Rule -Based pada Terjemahan Al Qurâ€™an Surat Al Baqarah. Bandung : IPB.  
[7] Lutfi, Citra Rosiana. 2012. Skripsi : Question Answering System pada terjemah juz Amma menggunakan metode Rule Based. Malang : UIN Maulana Malik Ibrahim.  
[8] Medely an, O., Milne, D., Legg, C., & Witten, I. H. (2009). Mining meaning from Wikipedia. International Journal 
of Human -Computer Studies, 67(9), 716 â€“754. Artificial 
IntelligenceRetrieval. doi:10.1016/j.ijhcs.2009.05.004  
[9]  W3C, W. W. W. C. (1999). Web Architecture: Describing and Exchanging Data. Retrieved 26 Februari, 2012, from http://www.w3.org/1999/04/WebData#References.  
[10] W3C, W. W. W. C. (2002). Resource Description Framework (RDF): Concepts and Abstract Syntax.  Retrieved 26 Februari, 2012, from http://www.w3.org/TR/2002/WD -rdf-concepts -
20021108/.  
[11]  Berners -Lee, T. (2000). Semantic Web - XML2000, slide 
10. Retrieved 26 Februari, 2012, from 
http://www.w3.org/2000/Talks/1206 -xml2k -tbl/slide10 -
0.html.  
[12]  Clark, K. G., Grant, K., & Torres, E., 2008. SPARQL 
Protocol for RDF. W3C Recommendation. Retrieved from http://www.w3.org/TR/rdf -sparql -protocol/  
[13]  Arenas, M., & PÃ©rez, J., 2011. Querying semantic web 
data with SPARQL. In Proceedings of the 30th symposiu m on Principles of database systems of data - PODS â€™11 (p. 305). New York, New York, USA: ACM Press. doi:10.1145/1989284.1989312  
[14]  Mendes, P. (2011). DBPedia. dbpedia.org. Retrieved from http://dbpedia.org/About  
[15]  Adriani, M., Asian, J., Nazief, B. , Tahaghoghi, S. M. M., & Williams, H. E., 2007. Stemming Indonesian. ACM Transactions on Asian Language Information Processing, 6(4), 1 â€“33. doi:10.1145/1316457.1316459  
[16]  Agusta, Ledy. 2009. Perbandingan Algoritma Stemming 
Porter dengan Algoritma Nazie f & Adriani untuk Stemming Dokumen Teks Bahasa Indonesia. Bali: Konferensi Nasional Sistem dan Informatika",Sistem Tanya Jawab,web semantik,data rekam medis,"akurasi, accuracy, precission, recall"
Aplikasi Tanya Jawab Tentang Fiqih Bersuci Berbasis Web ,"Aplikasi Tanya Jawab Tentang Fiqih Bersuci Berbasis Web 

Elvina Afriani1, Nazruddin Safaat H2, Muhammad Fikry3, Muhammad Affandes4 

Abstrak  
Dalam konteks perkembangan masyarakat yang semakin antusias terhadap teknologi dan keilmuan keagamaan, terdapat tantangan signifikan terkait akses terhadap informasi fiqih bersuci. Kesulitan mengakses dan mengorganisir data  terstruktur dari berbagai sumber  web seringkali menimbulkan kebingungan. Penelitian ini mengeksplorasi potensi penerapan Artificial Intelligence (AI), khususnya Question Answering System (QAS), sebagai solusi untuk meningkatkan akses dan 
pemahaman terhadap fiqih bersuci. QAS memungkinkan  komputer memahami pertanyaan dengan bahasa alami dan memberikan respons berdasarkan informasi yang tersedia. Implementasi multimedia dalam pembelajaran dan pemanfaatan metode Natural Language Processing (NLP) juga diintegrasikan untuk meningkatkan efisien si dan akurasi. QAS dibangun dengan frame work chatbot yang sudah ada yaitu streamlit dengan aplikasi Web sebagai antarmuka, Dengan memanfaatkan teknologi AI dan NLP, penelitian ini bertujuan mengembangkan platform pembelajaran yang menyajikan informasi fi qih bersuci secara mudah, cepat, dan terkini. Diharapkan, implementasi ini dapat memberikan kontribusi positif terhadap kemudahan akses dan pemahaman masyarakat terhadap aspek hukum Islam, khususnya mengenai kebersihan dan kesucian. Pengujian terhadap aplikasi menunjukkan kinerja yang relatif tinggi dalam memahami dan memproses bahasa manusia . Akurasi jawaban  dengan  BERTScore  didapati precision  sebesar  69%, recall sebesar 56% dan F1-score sebesar 83%.   

Kata kunci : Sistem Tanya Jawab, Fiqih Bersuci, Artificial Intelligence, NLP, Chatbot  
 
Abstract  
In the context of a growing society that is increasingly enthusiastic about technology and religious scholarship, there are significant challenges regarding access to information on fiqh of purification. The difficulty of accessing and organizing structured data from various web sources often leads to confusion. This research explores the potential application of Artificial Intelligence (AI), specifically Question Answe ring System (QAS), as a solution to improve access and understanding of fiqh of purification. QAS allows computers to understand questions in natural language and provide responses based on available information. The implementation of multimedia in learnin g and the utilization of Natural Language Processing (NLP) methods are also integrated to improve efficiency and accuracy . Through the utilization of AI and NLP technology, this study seeks to create a learning platform designed to provide information on t he fiqh of purification in a manner that is both accessible, rapid, and continuously updated . Hopefully, this implementation can make a positive contribution to the ease of access and public understanding of aspects of Islamic law, especially regarding cle anliness and purity. Testing of the application showed relatively high performance in understanding and processing human language. The accuracy of the answers with BERTScore was found to be 69% precision, 56% recall and 83% F1-score.  

Keywords:  Q&A system , Fiqh of Purification, Artificial Intelligence,  NLP,  Chatbot  

1. PENDAHULUAN  
Mengamati perkembangan saat ini, masyarakat semakin antusias berkontribusi dalam kemajuan teknologi dan keilmuan keagamaan. Oleh karena itu, dibutuhkan suatu sarana pembelajaran  yang mampu memikat minat masyarakat, mempermudah pemahaman terhadap aspek-aspek hukum Islam dalam bidang fi qih, serta menjadikan proses pembelajaran menjadi lebih menyenangkan.  Namun, akses mudah dan terkini terhadap informasi dan panduan mengenai fiqih bersuci  seringkali terbatas, sehingga seringkali menimbulkan keraguan dan kebingungan di kalangan umat Islam.   Kesulitan dalam mengakses dan mengorganisir data terstruktur tentang fiqih bersuci secara konsisten dari sumber yang beragam di web.  Pengguna harus telusuri halaman web secara manual atau melalui mesin pencari, tetapi meskipun dilengkapi filter, masih sulit menyaring informasi relevan secara efisien  [1]. Pengguna masih mengambil dokumen yang berisi konten yang terkait dengan kueri  mereka melalui mesin pencari yang dapat memakan waktu terutama karena jumlah data yang di posting di Web sangat besar dan meningkat dengan cepat  [2]. 
Penggunaan multimedia  dalam proses pembelajaran dianggap sesuai untuk memberikan pendidikan kepada masyarakat. edukasi kepada masyarakat terutama pada ilmu fiqih bersuci yang mengatur aturan dan tata cara mengenai kebersihan dan kesucian fisik dan jiwa. Saat ini p esatnya perke mbangan teknologi informasi berbasis komputer telah membuat banyak perubahan dalam kehidupan manusia, salah satunya adalah teknologi Artificial Intelligence (AI). Artificial Intelligence  (AI) atau kecerdasan buatan adalah teknologi yang memungkinkan komput er untuk melakukan tugas-tugas yang mirip dengan manusia  [3]. Kemajuan teknologi informasi, terutama Artificial Intelligence  (AI), menawarkan solusi melalui Question Answering System (QAS). QAS memungkinkan komputer untuk mengerti maksud pertanyaan yang diajukan oleh pengguna dengan bahasa alami dan memberikan respon berdasarkan informasi yang tersedia [4]. Langkah-langkah dalam sebuah aplikasi QA system  tidak akan terlepas dari tiga tahap utama yang membentuk arsitektur umum QA system , yaitu menganalis is pertanyaan, memilih kandidat dokumen atau segmen dokumen, dan mengekstrak   [5]. Dengan Diperlukan suatu metode pengolahan bahasa alami atau Natural Language Processing  (NLP), yang merupakan cabang ilmu komputer yang bertujuan untuk memahami konsep dan  maksud dari bahasa manusia. Hal ini tidak hanya meningkatkan akurasi, namun juga mempercepat kinerja kueri secara signifikan.  Pada penelitian aplikasi tanya jawab tentang fiqih bersuci ini menggunakan data berupa PDF dari 3 buku thaharah  yaitu buku  berjudul â€œ Thaharah berdasarkan Al -Quran dan As -sunnah â€ karya Abdullah Haidir (penerbit Kantor Dakwah dan laliat al -Sulay, Riyadh, Kerajaan Saudi Arabia, tahun 2005)  [6], â€œFiqih  Sunnah â€ karya Sayyid Sabiq (penerbit CP Cakrawala Publishing, ta hun 2008) [7] dan â€œFiqih Thaharah â€ karya Ahmad Sarwat, Lc (penerbit DU Center Press, tahun 2010)  [8]. Permasalahan pada penelitian Dhandapani dan Vadivel  [9] meskipun banyak sistem telah dikembangkan selama bertahun-tahun, masih ada tantangan dalam meningkatkan akurasi sistem dalam menafsirkan pertanyaan dengan benar dan memberikan jawaban. Banyak sistem ertanyaan dan jawaban mengonversi pertanyaan menjadi triple yang dipetakan ke basis pengetahuan, tetapi kurang dalam mengekspresikan representasi semantik pertanyaan, sehingga jawaban tidak dapat ditemukan dengan baik.  Penelitian yang dilakukan oleh Yunmar dan Wisesa [10] informasi tentang Penerimaan Mahasiswa Baru (PMB) tersebar luas di halaman web dan brosur, namun tidak semua informasi dapat langsung ditemukan. Mesin pencari pun tidak menjamin informasi yang sesuai dengan kebutuhan pengguna. Kendala seperti jarak, waktu, dan jam kerja sering membuat kunjungan  langsung ke kampus sulit. Penelitian ini mengembangkan Question Answering System  (QAS) untuk PMB, dengan arsitektur tiga tingkat dan antarmuka aplikasi mobile , menggunakan metode pengolahan bahasa alami dan ontologi sebagai dasar pengetahuannya.  Pada penelitian yang dilakukan Cahyana  [11], penelitian ini bertujuan untuk meningkatkan kepuasan pelanggan dalam industri wisata dengan mengembangkan aplikasi question and answering  yang berfungsi sebagai alat komunikasi antara masyarakat umum dan industri swasta melalui media sosial .yang berfungsi sebagai alat komunikasi antara masyarakat umum dan industri swasta melalui media sosial .  Pengembangannya tertentutan dilakukan secara kooperatif dengan menggunakan Unifield Modeling Language  dan Rational Unified Process . dengan pemrograman Java dan MySQL sebagai basis data. Aplikasi Question and Answer  (QNA) memungkinkan pengguna untuk mengajukan Elvina Afriani, et al., Aplikasi T anya Jawab Tentang Fiqih Bersuci Berbasis Web pertanyaan dan menerima jawaban, atau berkomunikasi secara langsung dengan admin mengenai informasi seputar industri wi sata.  Permasalahan pada penelitian Lenni  Bendi [12] adalah perkembangan teknologi informasi yang pesat telah menghasilkan peningkatan besar dalam jumlah data yang tersedia. Meskipun demikian, tidak semua informasi, terutama yang sangat spesifik seperti  pariwisata, mudah ditemukan. Natural Language Processing , khususnya Question Answering System , menawarkan solusi dengan memungkinkan komputer memahami pertanyaan dalam bahasa alami. Penelitian ini bertujuan untuk membangun aplikasi Question Answering Syst em sederhana untuk mengatasi permasalahan tersebut.  Penelitian oleh Ishlakhuddin   [13] penelitian ini bertujuan meningkatkan efisiensi layanan akademik melalui pengembangan chatbot untuk Biro Administrasi Akademik (BAAK). Chatbot 
memberikan akses mudah dan cepat terhadap dokumen seperti rencana studi dan hasil studi. Metode berbasis aturan digunakan, mencapai tingkat akurasi 98,95% dalam pengujian 96 kali dengan skema yang berbeda. Ini menunjukkan chatbot sebagai solusi efektif untuk meningkatkan layanan  akademik.  Alshammari & Alhumoud  [14] melakukan penelitian TAQS: An Arabic Question Similarity System Using Transfer Learning of BERT with BiLSTM . Penelitian ini  menggunakan dataset """"Tawasul"""" dengan 44.404 pasangan pertanyaan -jawaban. TAQS menggunakan transfer learning dari BERT dengan BiLSTM untuk ekstraksi representasi. Hasilnya, model HT -BERT -BiLSTM mencapai akurasi 94,45%, melampaui model lainnya, dan meningka tkan akurasi BiLSTM sebesar 43,19%.  Penelitian yang dilakukan oleh Haris  [15] Pemanfaatan machine learning  dalam domain kecerdasan buatan telah menyebar ke berbagai sektor, termasuk pendidikan. Dengan menggabungkan teknik machine learning , statistik, dan  basis data, educational data mining dapat digunakan untuk mengidentifikasi pola dalam dataset tertentu. Salah satu aplikasi khusus dari educational  data mining adalah dalam meramalkan performa siswa, yang memungkinkan penggunaan data untuk membuat prediksi tentang prestasi akademis atau kinerja belajar siswa di masa mendatang. Hasil prediksi ini dapat menjadi alat untuk memantau dan mengevaluasi proses pembelajaran, membantu menentukan tindakan perbaikan untuk meningkatkan efektivitas pembelajaran. Penelitian yang di lakukan oleh Rahayu & Maâ€™mun [16] dalam menghadapi perkembangan teknologi dan perbedaan pemahaman keagamaan, masyarakat semakin antusias untuk mengembangkan ilmu kepesantrenan. Namun, kurangnya minat dan keterbatasan ilmu dapat menyeba bkan perpecahan. Solusinya adalah melalui media pembelajaran yang menarik minat, terutama dalam memahami fikih ubudiyah  empat madzhab. Penggunaan multimedia dianggap tepat untuk memberikan edukasi, dan aplikasi multimedia berbasis Android  dirancang sebagai  media pembelajaran fiqih. Proses pengembangannya mengikuti Multimedia Development Life Cycle  (MDLC) dengan hasil pengujian mencapai 83% kenyamanan pengguna di sistem operasi Android . Penelitian Tinjauan Pustaka Sistemati s Implementasi Metode Deep Learning  pada Prediksi Kinerja Murid yang dilakukan oleh Haris et al  [15]. Machine learning  telah berperan penting dalam bidang pendidikan melalui educational data mining . Penelitian ini memberikan tinjauan literatur sistematis tentang penggunaan deep learning  dalam memprediksi  kinerja siswa. Dari 20 studi yang diulas, tingkat keberhasilan prediksi rata -rata mencapai 89,85%. Metode utama yang digunakan termasuk Deep Neural Network (DNN), Recurrent Neural Network (RNN), dan Long Short-Term Memory (LSTM). Studi-studi ini juga memanfaatkan fitur data seperti informasi demografis, perilaku, dan akademis. Penelitian yang dilakukan oleh Terpadu [17] Penerapan Computer Vision  Menggunakan 
Metode Deep Learning pada Persfektif Generasi Ulul Albab , membahas tentang implementasi machine learning  dalam kecerdasan buatan, khususnya dalam bidang computer vision  yang erat kaitannya dengan deep learning . Tujuan penelitian adalah melalui contoh sederhana dalam pengolahan gambar 
objek, mengerti teknologi deep learning  dan akomodasi kecerdasan buatan dari sudut pandang generasi Ulul Albab untuk memberi globalisasi.  Penelitian ini menggunakan metode studi pustaka untuk mengeksplorasi berbagai sumber, termasuk literatur dan jurnal, dengan fokus pada pengembangan teknologi  kecerdasan buatan menuju Kemajuan Islam di berbagai bidang ilmu pengetahuan dan teknologi telah mencapai taraf baru . Penelitian oleh Hidayat  [18] yaitu  Konsep Pendidikan Thahara  Menurut Syeikh Mahmud Al Mishri dalam kitab Alfiqhul Muyassar Liltiflilmuslim  ini Penelitian ini bertujuan untuk mengkaji konsep Islam tentang fikih taharah  yang terdapat dalam kitab """" Alfiqhul Muyassar Liltiflil Muslim """" karya Syeikh Mahmud Al -Mishri, serta untuk mengevaluasi manajemen pembinaan fikih taharah di Sekol ah Dasar Elvina Afriani, et al., Aplikasi T anya Jawab Tentang Fiqih Bersuci Berbasis Web Islam Arrohman. Latar belakang penelitian ini muncul karena adanya kurangnya pemahaman siswa baligh mengenai tata cara bersuci dalam Islam. Data untuk penelitian ini diperoleh melalui observasi, wawancara, dan dokumentasi yang dilakukan terhadap siswa di sekolah tersebut. Penelitian kualitatif 
ini berusaha menganalisis kehidupan sosial beragama di sekolah, dengan hasil menyimpulkan bahwa pemahaman fikih taharah siswa sesuai dengan konsep Islam dan manajemen pembinaan fikih taharah  di sekolah terseb ut dinilai baik. Kelemahan penelitian ini adalah data hanya berasal dari satu sumber, sehingga perlu hati -hati dalam menggeneralisasikan hasilnya.  Berdasarkan masalah yang dipaparkan maka peneliti akan melakukan pengembangkan algoritma yang dapat menganali sis konteks bahasa untuk memahami pertanyaan dengan lebih baik, mengingat kompleksitas terminologi fiqih. Hasil penelitian diharapkan dapat memberikan manfaat yang signifikan dengan memberikan akses mudah, cepat, dan akurat kepada pengguna berupa informasi  fiqih thaharah.  Sistem ini juga dapat berfungsi sebagai alat bantu pendidikan agama Islam, panduan praktik sehari-hari, dan sumber informasi yang relevan. Dengan demikian, penelitian ini akan memberikan manfaat besar dalam meningkatkan pemahaman dan kuali tas pelaksanaan ibadah di antara umat Islam.  
 
2. METODE PENELITIAN  
Metode penelitian ini menguraikan langkah-langkah yang akan diambil dalam menyelesaikan penelitian menggunakan LangChain,  seperti pada gambar berikut:   
Penelitian ini menggunkan LangChain  yang berupa kerangka kerja sumber terbuka untuk membangun aplikasi berdasarkan model bahasa besar (LLM). LLM  adalah model deep learning  besar yang telah dilatih sebelumnya pada sejumlah besar data yang dapat menghasilkan respons  terhadap kueri pengguna misalnya pada penelitian kali ini dapat  menjawab pertanyaan tengtang fiqih bersuci.  LangChain  memberikan alat dan abstraksi untuk meningk atkan penyesuaian, keakuratan, dan relevansi informasi yang dihasilkan model .  
2.1. Data buku thaharah  
Pada tahapan awal adalah pengumpulan data beru pa data PDF dari 3 buku thaharah  yaitu buku  berjudul â€œ Thaharah berdasarkan Al -Quran dan As -sunnah â€ karya Abdullah Haidir (penerbit Kantor Dakwah dan laliat al -Sulay, Riyadh, Kerajaan Saudi Arabia, tahun 2005)  , â€œFiqih  Sunnah â€ karya Sayyid Sabiq (penerbit CP Cakrawala Publishing, tahun 2008)  dan â€œ Fiqih Thaharah â€ karya Ahmad Sarwat, Lc (penerbit DU Center Press, tahun 2010) . 
Gambar  1. Tahapan Penelitian Menggunakan LangChain  Elvina Afriani, et al., Aplikasi T anya Jawab Tentang Fiqih Bersuci Berbasis Web  Dilakukan chunk of text  untuk memotong atau bagian dari teks yang dianggap sebagai satu kesatuan, baik itu beberapa kalimat, paragraf, atau bahkan lebih besar. Chunk of text adalah bagian dari teks yang diambil atau dipisahkan dari dokumen yang lebih besar. Chunk of text digunakan untuk merujuk pada sebagian teks yang relevan atau penting dalam konteks tertentu  [19] yang mana dapat merujuk pada bagian -bagian tertentu dari 3 dokumen yang membahas topik untuk tanya jawab tentang fiqih bersuci.   
2.3. Embedding  
Pada penelitian ini dokumen fiqih bersuci yang telah dilakukan chung of text akan di proses dalam embedding menggunakan OpenAI yang mengubah dokumen  bentuk teks menjadi vektor yang mana hasilnya akan dimasukkan  kedalam vektor store. Representasi ini memungkinkan komputer memahami dan memanipulasi makna kata -kata dalam konteks tertentu. Dengan embedding, kata-kata atau frasa diubah menjadi vektor yang diproses oleh algoritma pembelajaran mesin untuk analisis teks  dan pemrosesan bahasa yang lebih efektif  [20].  
2.4. Vectore store  
Proses dari  dokumen  fiqih bersuci  yang sudah dilakukan  embedding  akan  disimpan dalam vektor store berbentuk faiss. Tahapan  vector store adalah penyimpanan vektor kata-kata atau teks yang merepresentasikan makna dan hubungan antar kata-kata dalam sebuah model. Vector store memungkinkan komputer memahami dan memproses makna kata-kata atau teks. Dengan vector store, komputer dapat dengan cepat mengakses dan memanipulasi representasi vektor kata -kata yang diperlukan dalam tugas pemrosesan bahasa alami [21].  
2.5. Rangked result  
Rangked result  merupakan  tahapan yang akan melakukan perangkingan pada data fiqih bersuci di dalam vektor store , disusun dari yang paling sesuai hingga yang paling tidak sesuai . Dalam penelitian ini di ambil 4 referensi yang sesui untuk menghasilkan jawaban.  Hasil atau data yang diurutkan berdasarkan tingkat relevansi atau kriteria tertentu , akan  mempermudah pengguna  untuk dengan cepat mengenali informasi yang paling penting atau relevan dalam suatu set data yang merujuk pada hasil peringkat atau urutan  [22].  
2.6. LLM  
LLM ( Large Language Model ) adalah jenis model yang dilatih dengan sejumlah  set data yang besar untuk memahami dan menghasilkan teks  fiqih bersuci yang telah dilakukan rangking result . Model ini adalah  salah satu kecerdasan buatan generatif yang paling populer saat ini adalah LLM  yaitu model jaringan syaraf yang didasarkan pada data teks dengan jumlah yang besar, dan dirancang untuk menghasilkan output yang menyerupai manusia, namun tidak terbatas pada prosa, puisi, dan bahkan kode program  [23].  
2.7. Answer  
Proses answer  pada penelitian ini  adalah  respon atau jawaban terhadap suatu pertanyaan pada  hasil keluaran atau respon dari sistem terhadap permintaan atau pertanyaan pengguna. Merujuk pada jawaban yang diberikan [19] dalam konteks ini akan memberikan jawaban yang sesuai dengan data yaitu  seputar fiqih bersuci.  
2.8. Question  embedding  
Tahap selanjutnya yaitu question  embedding , melakukan proses embed dari pertanyaan yang diberikan user tentang fiqih bersuci, pertanyaan dapat digunakan dalam model pembelajaran mesin untuk meningkatkan kinerja dalam tugas seperti pencocokan pertanyaan -jawaban dan sistem tanya jawab otomatis. Teknik ini penting dalam pengembangan sistem NLP yang efektif. Question embedding dapat digunakan dalam tahap text preprocessing dan penentuan kemiripan untuk mengubah pertanyaan menjadi representasi vektor, memungkinkan sistem untuk mencocokkan pertanyaan dengan dataset dan menghasilkan jawaban yang sesuai   [24].  
2.9.  Similarity search  
Similarity search  yaitu proses mencari kesamaan antara pertanyaan yang diajukan oleh pengguna dengan  set data  pertanyaan, subjek, objek, dan kata kunci yang telah disiapkan  pada data fiqih bersuci didalam vektor store . Similarity search menjadi bagian penting dalam memastikan bahwa jawaban yang Elvina Afriani, et al., Aplikasi T anya Jawab Tentang Fiqih Bersuci Berbasis Web diberikan oleh aplikasi tanya jawab  sesuai dengan pertanyaan yang dia jukan oleh pengguna. Dalam pencarian kesamaan, algoritma membandingkan fitur-fitur item untuk menentukan tingkat 
kesamaannya, memungkinkan pengguna menemukan informasi atau item yang relevan berdasarkan preferensi atau kriteria yang ditentukan  dan sesuai dengan ekspektasi pengguna  [24]. 
 
3. HASIL DAN PEMBAHASAN  
3.1. Hasil implementasi tampilan  
Berikut merupakan hasil implementasi tampilan dari aplikasi tanya jawab tentang fiqih bersuci berbasis web. 
a. Tampilan Awal  
Tampilan ini adalah halaman awal dari aplikasi tanya jawab tentang fiqih bersuci, yang mana terdapat kolom pencarian untuk pengguna memasukkan kueri pencarian tentang fiqih bersuci , seperti pada gambar 2.  
Gambar  2.  Tampilan Awal   
b. Tampilan jawaban  
Pada halaman ini, akan menampilkan hasil jawaban sesuai dengan pertanyaan dari pengguna. Aplikasi akan menyajikan hasil jawaban singkat dan jawaban referensi 1 sampai 4 yang berasal dari dokumen PDF thaharah . Pada gambar 3 dibawah ini menunjukkan hasil jaw aban referensi dari aplikasi.  
Gambar  3. Tampilan Jawaban  
3.2. Pengujian  
Pengujian aplikasi tanya jawab tentang fiqih bersuci pada penelitian ini berupa akurasi  jawaban menggunakan BERTScore . BERT Score  menggunakan encoder dalam transformator sebagai sub-struktur untuk model pre -training untul tugas-tugas NLP  seperti Sentiment Analysis (SA), Question Answering (QA), Text Summarization (TS)  [25]. Metrik yang umum digunakan untuk mengevaluasi BERTScore termasuk pre cision , recall, F1-score,  dan metrik -metrik khusus tergantung pada tugas yang dinilai.  Evaluasi kinerja aplika si question answering dengan menggunakan BERTScore  melibatkan penilaian seberapa baik jawaban yang dihasilkan oleh sistem tersebut cocok dengan ja waban referensi. BERTScore mengukur tingkat kesamaan semantik antara jawaban sistem dan jawaban referensi dengan membandingkan representasi vektor kata yang diperoleh dari model BERT . Skor yang lebih tinggi menunjukkan bahwa jawaban sistem memiliki kesesua ian semantik yang lebih mirip dengan jawaban referensi, menunjukkan performa yang lebih akurat dalam memahami dan menjawab pertanyaan secara konseptual.  Berikut  adalah hasil pengujian BERTScore  dengan metrik precision (1), recall (2), F1-score (3).  
P=1
|ð¶| âˆ‘max  cosine (ð‘,ð‘Ÿ)
ð‘âˆˆð¶                                                                                                                                 (1) 
Keterangan:  
P: Precision  
|C|: jumlah token di kalimat kandidat  
c: token dikalimat kandidat  
R: himpunan t oken dikalimat referensi  
Cosine(c,r): cosine similarity  antara token (c) dan (r)  
R=1
|ð‘…|âˆ‘max ð‘ð‘œð‘ ð‘–ð‘›ð‘’ (ð‘Ÿ,ð‘)
ð‘Ÿâˆˆð‘…                                                                                                                                   (2)      
Keterangan:  
R: Recall  
|R|: jumlah token di kalimat referensi  
r: token dikalimat referensi  
(C): himpunan token dikalimat kandidat  
Cosine(r ,c): cosine similarity  antara token (r) dan (c)  
F1-Score = 2 x Precision  x Recall
Precision  x Recall                                                                                                                 (3)          
Keterangan:  
Precision: rata -rata cosine similarity dari token-token yang dipasangkan di kalimat kandidat dengan kalimat referensi . 
Recall: rata -rata cosine similarity dari token -token yang dipasangkan di kalimat referensi dengan kalimat kandidat .  
Tabel  1. Hasil Pengujian BERTScore   
No Question  Precision  Recall  F1-score  
1 Apa maksud bersuci didalam islam?  0,8820  0,8496  0,8655  
2 Bagaimana cara membersihkan najis yang menempel pada pakaian atau tubuh?  0,8592  0,8290  0,8438  
3 Bagaimana cara tayammum yang benar?  0,9327  0,8443  0,8863  
4 kapan waktu yang tepat untuk melakukan tayammum jika tidak ada air?  0,8711  0,8142  0,8417  
5 Siapa saja yang diwajibkan untuk bersuci sebelum melaksanakan ibadah?  0,8652  0,8334  0,8490  
6 Apa bunyi hadis rasulullah dalam bahasa arab tentang Jika air mencapai dua kulah, maka dia tidak mengandung najis?  0,7601  0,6650  0,7094  
7 Apa doa setelah berwudhu?  0,8368  0,7858  0,8105  
8 Apa bunyi dalil dalam bahasa arab tentang sucinya air sumur atau mata air?  0,8741  0,7854  0,8274  
9 Apa bunyi dalilnya firman Allah Ta'ala dalam bahasa arab tentang bangkai beserta artinya?  0,8152  0,7546  0,7837  
10 Mengapa bersuci menjadi syarat sahnya shalat dalam islam?  0,9146  0,8547  0,8836  
Jumlah  6, 9689  5,6724  8,3009  
Rata - rata 0,69689  0,56724  0,83009   
Pada table 1, hasil nilai dari precison sebesar  0,69689 atau 6 9%, recall sebesar 0,56724 atau 56% dan F1-score sebesar 0,83009 atau 83%.   
3.3. Pembahasan  
Penelitian ini berfokus pada aplikasi tanya jawab berbasis web yang berkaitan dengan fiqih bersuci. Pengembangan aplikasi ini termasuk pengumpulan data, pemrosesan teks, dan evaluasi kinerja sistem menggun akan metrik BERTScore. Aplikasi ini dibangun dengan menggunakan AI, terutama 
Large Language Model  (LLM). Aplikasi ini mampu memberikan jawaban yang akurat dan relevan terhadap pertanyaan pengguna tentang fiqih bersuci  dengan menggunakan model bahasa besar dan algoritma LangChain. Pada tahap awal, data dikumpulkan dari buku -buku yang relevan dalam format PDF. Selanjutnya, dilakukan proses chunk  of text , embedding, dan pembuatan vector store untuk memfasilitasi pencarian dan perangkingan informasi.  Hasil implementasi ditampilkan dalam antarmuka web , memungkinkan pengguna mencari dan mendapatkan jawaban tentang fiqih bersuci dengan mudah. Pengujian kinerja aplikasi dilakukan dengan metrik BERTScore, yang menunjukkan tingkat kesesuaian semantik antara jawaba n sistem dan jawaban referensi. Hasil pengujian menunjukkan bahwa aplikasi memahami dan menjawab pertanyaan tentang fiqih bersuci dengan tingkat akurasi yang baik . Penelitian ini berbeda dari yang sebelumnya karena bertujuan untuk  mengembangkan sistem Question Answering  (QA) menggunakan teknologi Artificial Intelligence  (AI) dan Natural Language Processing  (NLP) untuk menyediakan informasi tentang fiqih bersuci, dengan mengidentifikasi dan mengatasi masalah akses terbatas terhadap informasi fiqih bersuci.  Dengan pengembangan algoritma analisis bahasa yang didukung oleh AI dan NLP, penelitian ini bertujuan memberikan akses yang mudah, cepat, dan akurat kepada pengguna tentang informasi fiqih thaharah . 
 
4. KESIMPULAN  
Berdasarkan penelitian yang sudah  dilakukan, dapat disimpulkan:  
1. Penelitian ini telah berhasil mengimplementasikan sistem tanya jawab berbasis web  dalam konteks fiqih bersuci pada model ChatGPT dari OpenAI.  
2. Dengan adanya penelitian ini, pengguna dapat dengan mudah memperoleh informasi dan keakuratan jawaban terkait fiqih thaharah  melalui antarmuka web yang disediakan. Metode 
pengembangan yang digunakan mencakup penggunaan multimedia dalam pembelajaran serta pemanfaatan metode pemrosesan bahasa alami (NLP) untuk meningkatkan efisiensi dan ak urasi.  
3. Hasil penelitian menunjukkan bahwa  aplikasi tanya jawab  yang dikembangkan dapat diterapkan secara efektif berdasarkan kebutuhan,  dengan tingkat akurasi menggunakan BERTScore didapati precision sebesar 69%, recall sebesar 56% dan F1-score sebesar 83 %.  Oleh karena itu, untuk pengembangan penelitian selanjutnya peneliti memberikan saran atau rekomendasi untuk  melengkapinya dengan evaluasi yang lebih komprehensif  dan meningkatkan data dalam konteks fiqih bersuci.  
 
Daftar Pustaka  
[1] R. Cahyana, E. Satria, and N. H. Nisa, â€œPengembangan AplikasiI QNA Sebagai Jembatan Komunikasi Pengelola Wisata Industri Dengan Masyarakat,â€ 2020. [Online]. Available: 
http://jurnal.sttgarut.ac.id/  
[2] W. Alshammari and S. Alhumoud, â€œTAQS: An Arabic Questi on Similarity System Using Transfer Learning of BERT with BiLSTM,â€ IEEE Access , 2022, doi: 
10.1109/ACCESS.2022.3198955.  
[3] Guntoto, L. Costaner, and Lisnawita, â€œAplikasi Chatbot untuk Layanan Informasi dan Akademik Kampus Berbasis Artificial Intelligence Markup Language (AIML),â€ 2020, 
doi: 10.31849/digitalzone.v11i2.5049ICCS.  
[4] M. Lenni, R. Kristoforus, J. Bendi, M. Universitas, and K. M. Charitas, â€œQuestion Answering System Informasi Pariwisata Kota Palembang,â€ Jurnal Ilmiah MATRIK , vol. 
21, no. 2, 2019 , [Online]. Available: www.altavista.com  
[5] D. Apriliani, S. F. Handayani, T. N. Anugrahaeni, A. Miftahudin, L. Nurarifiah, and I. T. Saputra, â€œApliksi Question Answering Sebagai Medis Pembelajaran Interaktif Untuk Mata Pembelajaran Akuntansi,â€ JMM (Jurna l Masyarakat Mandiri) , vol. 7, no. 2, p. 2003, Apr. 2023, doi: 10.31764/jmm.v7i2.13867.  
[6] Abdullah Haidir, Fiqih Thaharah Berdasarkan Al -Qur`an dan As -Sunnah , 1st ed. Riyadh, 2005. Accessed: May 04, 2024. [Online]. Available: https://ebooksunnah.com/en/e books/fiqih -thaharah -berdasarkan -al-quran -dan-as-sunnah  Elvina Afriani, et al., 
[7] Sayid Sabiq, Fikih Sunnah . Jakarta, 2008. Accessed: May 04, 2024. [Online]. Available: https://maktabah.pesantrenalirsyad.org/index.php p=show_detail&id=5396  
[8] Ahmad Sarwat, Fiqih Thaharah , 1st ed. 2010. Accessed: May 04, 2024. [Online]. Available: https://ia801209.us.archive.org/15/items/KumpulanFIQIH
201510/fiqih -thaharah.pdf  
[9] A. Dhandapani and V. Vadivel, â€œQuestion Answering System over Semantic Web,â€ IEEE Access , vol. 9, pp. 46900 â€“46910, 2 021, doi: 10.1109/ACCESS.2021.3067942.  
[10] R. A. Yunmar and I. W. W. Wisesa, â€œPengembangan Mobile -Based Question Answering System Answering Dengan Basis Pengetahuan Ontologi,â€ Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK) , vol. 7, no. 4, pp. 693 â€“700, 2020, doi: 10.25126/jtiik.202072255.  
[11] R. Cahyana, E. Satria, and N. H. Nisa, â€œPengembangan Aplikasi QNA Sebagai Jembatan Komunikasi Pengelola Wisata Industri Dengan Masyarakat,â€ Jurnal Algoritma , vol. 16, 
no. 2, pp. 92 â€“99, 2020, doi: 10.33364/algori tma/v.16 -2.92.  
[12] M. Lenni and R. K. J. Bendi, â€œQuestion Answering System Informasi Pariwisata Kota Palembang,â€ Jurnal Ilmiah Matrik , vol. 21, no. 2, pp. 128 â€“138, 2019, doi: 10.33557/jurnalmatrik.v21i2.566.  
[13] F. Ishlakhuddin, A. Basir, and N. Nurlaela , â€œRancang Bangun Sistem Tanya -jawab Berbasis Aturan STMIK Muhammadiyah Paguyangan Brebes dengan Menggunakan Telegram Chatbot,â€ Jurnal Informatika: Jurnal Pengembangan IT , vol. 5, no. 3, pp. 100 â€“105, 2020, doi: 10.30591/jpit.v5i3.2900.  
[14] W. Alshammari a nd S. Alhumoud, â€œTAQS: An Arabic Question Similarity System Using Transfer Learning of BERT with BiLSTM,â€ IEEE Access , vol. 10, no. September, pp. 
91509 â€“91523, 2022, doi: 10.1109/ACCESS.2022.3198955.  
[15] M. Haris, T. Pustaka, M. H. Diponegoro, S. Kusumawa rdani, and I. Hidayah, â€œTinjauan Pustaka Sistematis: Implementasi Metode Deep Learning pada Prediksi Kinerja Murid (Implementation of Deep Learning Methods in Predicting Student Performance: A Systematic Literature Review),â€ 2021.  
[16] S. Rahayu and S. Maâ€™ mun, â€œRancang Bangun Aplikasi Fiqih Ibadah 4 Madzhab Berbasis Android,â€ Jurnal Algoritma , vol. 18, no. 1, pp. 41 â€“49, 2021, doi: 10.33364/algoritma/v.18 -1.833.  
[17] J. T. Terpadu, I. Arifin, R. Fakhran Haidi, and M. Dzalhaqi, â€œPenerapan Computer Vision Menggunakan Metode Deep Learning Pada Perspektif Generasi Ulul Albab,â€ Jurnal 
Teknologi Terpadu , vol. 7, no. 2, pp. 98 â€“107, 2021, [Online]. Available: https://journal.n urulfikri.ac.id/index.php/jtt  
[18] S. Hidayat, B. Handrianto, and A. Sastra, â€œKonsep Pendidikan Thahara Menurut Syeikh Mahmud Al Mishri dalam kitab Alfiqhul Muyassar Liltiflilmuslim,â€ vol. 31, no. 1, pp. 881â€“892, 2023.  
[19] J. Risch, T. MÃ¶ller, J. Gutsch, and M. Pietsch, â€œSemantic Answer Similarity for Evaluating Question Answering Models,â€ Aug. 2021, [Online]. Available: http://arxiv.org/abs/2108.06130  
[20] N. N. Moon et al. , â€œNatural Language Processing Based Advanced Method Of Unnecessary Video Detection ,â€ International Journal of Electrical and Computer Engineering , vol. 11, no. 6, pp. 5411 â€“5419, Dec. 2021, doi: 10.11591/ijece.v11i6.pp5411 -5419.  
[21] A. Samih, A. Ghadi, and A. Fennan, â€œEnhanced Sentiment Analysis Based On Improved Word Embeddings And XGb oost,â€ International Journal of Electrical and Computer 
Engineering , vol. 13, no. 2, pp. 1827 â€“1836, Apr. 2023, doi: 10.11591/ijece.v13i2.pp1827 -1836.  
[22] M. Zhang, L. Yang, Y. Dong, J. Wang, and Q. Zhang, â€œPicture Semantic Similarity Search Based on Bipar tite Network of Picture -Tag Type,â€ PLoS One , vol. 16, no. November, Nov. 2021, doi: 10.1371/journal.pone.0259028.  
[23] Q. Rizqie, N. Afifah, and A. Bardadi, â€œNetPLG Journal of Network and Computer 
Applications Eksplorasi Penggunaan Large Language Model (LL M) dalam Elvina Afriani, et al., Aplikasi T anya Jawab Tentang Fiqih Bersuci Berbasis Web  ZONAsi: Jurnal Sistem Informasi, Vol. 6 No. 2, Mei 2024  Page 390  Pembangunan Permainan Minesweeper dengan Python Programmingâ€, [Online]. Available: https://jurnal.netplg.com/jnca  
[24] R. F. Saldhi, Z. K. A. Baizal, and R. Dharayani, â€œQuestion Answering System at the Kingdom of Sumedang Larang with NaÃ¯ve Bayes M ethod,â€ Journal of Computer System and Informatics (JoSYC) , vol. 3, no. 4, pp. 322 â€“329, Sep. 2022, doi: 10.47065/josyc.v3i4.2079.  
[25] F. Fajri et al. , â€œMembandingkan Nilai Akurasi BERT dan DistilBERT pada Dataset Twitter,â€ JUSIFO (Jurnal Sistem Informasi) , vol. 8, no. 2, pp. 71 â€“80, 2022.",Aplikasi Tanya Jawab,"LangChain, LLM, deep learning",data buku thaharah,"akurasi, precision, recall F1-score"
Chatbot Layanan Akademik Menggunakan K-Nearest Neighbor,"Chatbot Layanan Akademik Menggunakan K-Nearest Neighbor

Kristian Adi Nugraha1), Danny Sebastian2) 

Abstrak  
Perusahaan atau institusi yang bergerak di bidang pelayanan publik pasti memiliki layanan customer service  untuk menjawab pertanyaan dari konsumen. Namun perusahaan atau institusi dengan skala menengah ke bawah seringkali tidak sanggup untuk menyediakan karyawan khusus untuk menangani pekerjaan tersebut, sehingga pekerjaan tersebut dirangkap oleh karyawan di posisi lain. Chatbot  dapat digunakan untuk menyelesaikan permasalahan yang berkaitan dengan layanan tanya jawab, khususnya bagi perusahaan atau institusi yang tidak memiliki sumber daya khusus untuk menangani pekerjaan  tersebut.  Dengan adanya chatbot , pertanyaan-pertanyaan 
konsumen yang bersifat redundan dapat ditangani secara otomatis.  Pada penelitian ini, penulis membangun sistem chatbot  untuk layanan tanya jawab seputar kegiatan akademik dengan menggunakan metode K-Nearest Neighbor . Berdasa rkan hasil pengujian yang telah dilakukan, sistem dapat memberikan nilai akurasi sebesar 53.48% untuk nilai K = 3.  
 
Kata kunci : chatbot, k-nearest neighbor, pengolahan bahasa natural   
 
Abstract  
To address customers' questions, company  involved in public services must provide customer service. Nevertheless, company  of a medium to lower scale are frequently unable to provide special personnel to perform the task, so that the job is held simultaneously by staff in other roles.  Chatbot  can be used to resolve issues related to question and answer services, especially for businesses or organizations that do not have specific resources to deal with this work. Therefore, redundant customer queries can be answered  automatically with the chatbot.  In this research, using the K-Nearest Neighbor process, the authors developed a chatbot framework for question and answer services about academic activities. The device can have an accuracy value of 53.48% 
for the value of K=3 based on the results of the tests that have been conducted.  
 
Keywords: chatbot, k-nearest neighbor, natural language processing   
 
1. PENDAHULUAN  
Perusahaan maupun institusi yang bergerak di bidang  layanan publik memiliki customer service  yang bertujuan untuk menjawab pertanyaan  pengguna apabila terdapat hal-hal yang kurang jelas.  Perusahaan biasanya menyediakan beberapa media komunikasi seperti telepon, pesan singkat ( chat) atau email . Pada  perusahaan  dengan skala kecil, posisi operator customer service  seringkali dirangkap oleh karyawan yang telah menduduki  posisi lain. Jika beban pekerjaan utama  yang dilakukan oleh  karyawan tersebut sedang  berada dalam jumlah yang  cukup banyak, hal ini akan  membuat karyawan tersebut  kesulitan  sehingga akan berpengaruh terhadap menurunnya performa dari pelayanan customer service  yang ditanganinya. Di samping  itu, operator customer service  dituntut untuk  selalu siap dalam  menjawab pertanyaan -pertanyaan dari pengguna  tanpa mengenal waktu . Hal tersebut sulit untuk dilakukan oleh perusahaan skala kecil karena harus mempekerjakan karyawan khusus dalam dua shift, yaitu pagi dan malam.  Salah satu solusi  untuk mengatasi permasalahan dalam menjawab pertanyaan-pertanyaan dari pengguna  adalah dengan membuat  daftar pertanyaan yang sering ditanyakan bese rta jawabannya, atau yang lebih dikenal dengan istilah  FAQ  (Frequently Asked Question ). FAQ  berisi  rangkuman  pertanyaan -pertanyaan yang cukup sering ditanyakan dan bersifat umum, serta dilengkapi dengan jawaban untuk masing -masing pertanyaan . FAQ  dibuat dengan tujuan untuk  mengurangi beban pekerjaan  dari customer service, sehingga customer service  hanya perlu menjawab pertanyaan yang tidak terdapat pada FAQ . Namun  FAQ  dengan pertanyaan   dalam jumlah besar  seringkali membuat  pengguna  kesulitan  saat mencari  daftar pertanyaan yang sesuai dengan pertanyaan yang akan ditanyakan . Pengguna  harus mencari pertanyaan yang sesuai dengan pertanyaan miliknya, hal ini akan sulit dilakukan jika daftar pertanyaan yang disediakan terlalu banyak. Pada beberapa implementasi,  disediakan fitur pencarian berdasarkan kata kunci yang dimasukkan oleh pengguna. Namun fitur ini juga tidak cukup membantu, karena meskipun kata kunci yang dimasukkan oleh pengguna terdapat pada sebuah pertanyaan, namun konteks dari pertanyaan tersebut belum tentu sama dengan yang hendak ditanyakan oleh pengguna. Dengan demikian, fitur pencarian hanya akan efektif apabila pengguna bisa memasukkan kata kunci yang bersifat unik dan hanya dimiliki oleh satu pertanyaan saja.  Penulis memiliki gagasan  untuk  mengatasi permasalahan di atas dengan  membangun sebuah  mesin penjawab pesan otomatis ( chatbot ) yang sanggup  menjawab pertanyaan dari pengguna secara otomatis  [1]. Pengguna dapat mengirimkan  pertanyaan  melalui aplikasi perpesanan biasa,  di mana pengguna seolah-olah sedang bertanya langsung  seperti biasa  kepada operator customer service  menggunakan bahasa bebas tanpa format  tertentu.  Langkah berikutnya,  pertanyaan akan diproses oleh mesin chatbot  untuk mendapatkan data pertanyaan ya ng paling sesuai dalam basis data, sehingga dapat memberikan jawaban yang tepat  [2]. Chatbot  banyak diimplementasikan untuk  berbagai bidang kebutuhan , di antaranya  adalah aplikasi chatbot  yang digunakan untuk customer service  [3]. Penulis mencoba mengimplementasikan chatbot  di lingkup  kampus  Universitas Kristen Duta Wacana, khususnya Fakultas Teknologi Informasi. Chatbot  akan berfokus pada pertanyaan yang sering ditanyakan oleh mahasiswa  atau wali  kepada pegawai administrasi fakultas , terkait dengan kegiatan akademik. Chatbot  akan dibangun dengan menggunakan metode K-Nearest Neighbor  (K-NN), di mana metode ini telah banyak diimplementasikan  untuk menyelesaikan permasalahan  terkait klasifikasi  teks da n dapat memberikan hasil yang cukup baik [4]. Pengguna  cukup mengetikkan  pertanyaan yang hendak ditanyakan  pada admin, kemudian sistem akan mengolah pertanyaan tersebut dan mencari pertanyaan yang paling serupa  dengan pertanyaan tersebut dengan menggunakan metode K-NN, kemudian  sistem akan mengirimkan jawaban berdasarkan pertanyaan serupa dari basis data.  Harapan penulis, dengan dibangunnya chatbot  ini akan dapat mengurangi beban  tugas operator customer service , sehingga kualitas pelayanan yang dapat diberikan oleh institusi menjadi semakin  optimal.  
 
2. TINJAUAN PUSTAKA  
Chatbot  telah banyak diimplementasi kan pada  berbagai sektor  seperti sektor kesehatan, e-commerce , maupun  segala bentuk customer call centers  [5]. Salah satu contoh dari implementasi  chatbot  adalah mesin bernama Agribot  yang bertujuan untuk menangani  keperluan agrikultur, di mana sistem ini akan digunakan oleh para petani  [6]. Agribot  digunakan para petani untuk mengetahui jenis tumbuhan yang paling optimal untuk ditanam , dengan memperhitungkan  kondisi tanah, kondisi lingkungan, dan keadaan cuaca  atau iklim . Penelitian lain yang sejenis adalah  penelitian dalam  membangun chatbot  yang berfungsi untuk menjawab pertanyaan-pertanyaan bersifat umum menggunakan  bahasa Thailand  [7]. Berdasarkan hasil pengujian  yang telah dilakukan , nilai akurasi chatbot  dalam memahami pertanyaan adalah 86.36%, sedangkan nilai akur asi dalam memberikan  jawaban adalah 93.2%.  Chatbot  merupakan kombinasi antara bidang ilmu pengolahan teks dan bidang ilmu kecerdasan buatan, sehingga chatbot  dapat dibangun dengan menggunakan kombinasi berbagai macam metode . Metode K-NN adalah  salah satu m etode  kecerdasan buatan untuk bidang  klasifikasi yang cukup sering  digunakan dalam menangani  pengolahan teks, contohnya  pada penelitian untuk memotong  kalimat pada sebuah paragraf  [8]. K-NN pada penelitian  tersebut bekerja dengan cara 
menganalisa relasi  antara kalimat yang satu dengan kalimat yang lain dalam sebuah paragraf memiliki keterkaitan  atau tidak . Dengan  menggunakan metode K-NN, nilai akurasi yang dihasilkan pada penelitian tersebut dapat  memberikan hasil yang cukup  baik. Penelitian lain dalam  bidang pengolahan teks menggunakan  metode  K-NN adalah penelitian yang bertujuan untuk mengetahui arti sebenarnya dari  sebuah kalimat yang ditulis dalam bahasa Bengali  [9]. Penelitian tersebut mencob a untuk menyelesaikan  permasalah an Word Sense Disambiguation  (WSD ) dengan menggunakan  metode  K-NN, sehingga arti yang sebenarnya  dari sebuah kalimat dapat diketahui dengan memperhatikan konteks  yang ada  pada  kalimat tersebut. Tingkat akurasi yang dihasilkan  oleh penelitian tersebut terbilang  cukup baik, yaitu dengan nilai persentase yang dihasilkan sebesar 71%.  Berdasarkan hasil  luaran  dari penelitian -penelitian sebelumnya  yang cukup baik dengan metode K-NN untuk pengolahan teks , maka penulis mela kukan penelitian dengan menggunakan metode K-NN untuk membangun sebuah mesin  chatbot  untuk menangani pertanyaan seputar  layanan akademik di Universitas Kristen Duta Wacana, khususnya  di Fakultas Teknologi Informasi.   
2.1 Pengolahan Bahasa Natural  
Pengolahan bahasa natural ( natural language processing )merupakan  salah satu turunan dari bidang ilmu komputer  (computer science ) yang merupakan kombinasi  antara bidang pengolahan teks (text processing ) dan bidang  kecerdasan buatan  (artificial intelligence ). Metode tersebut dapat  mengubah sebuah  komputer agar memiliki kemampuan dalam  memahami percakapan (lisan maupun teksi)  yang dilakukan oleh manusia . Jika dibandingkan dengan mesin pengolahan  berbasis kecerdasan buatan  di bidang lain, misalnya pengolahan citra , proses yang terjadi dalam pengolahan bahasa natural tidak jauh berbeda [10]. Dengan demikian,  tingkat performa yang dihasilkan  oleh mesin pengolahan bahasa natural sangat bergantung pada jenis algoritma kecerdasan buatan yang  diimplementasikan  di dalamnya.   
2.2 Chatbot  
Chatbot  adalah  perangkat lunak yang memiliki kemampuan untuk  mela kukan komunikasi  dengan manusia secara otomatis  dengan format  pesan  singkat  tertulis ( chat). Chatbot  adalah  salah satu produk  dari bidang ilmu pengolahan bahasa natural yang dikembangkan  dengan menggunakan metode kecerdasan buatan agar dapat  memproses  informasi dan memberikan jawaban  yang  paling  tepat sesuai dengan diharapkan pengguna [11]. Chatbot  diharapkan dapat menjadikan  komputer atau  sebuah  mesin agar sanggup  menggantikan peran manusia sebagai lawan bicara dari manusia yang lain.   
2.3 Pra-pemrosesan Teks  
Pra-pemrosesan teks ( text preprocessing ) merupakan sebuah tahapan yang dilakukan sebelum dokumen teks diolah lebih lanjut. Tahapan ini bertujuan untuk mengubah dokumen teks ke dalam bentuk teks lain yang lebih mudah diolah, sehingga akan memberikan hasil akhir yang lebih optimal [12, 13] . Pra-pemrosesan teks dapat memiliki satu atau lebih sub tahapan, di antaranya:  
1. Tokenisasi  
Proses untuk mengambil setiap kata dari sebuah kalimat. Masing-masing kata tersebut disebut sebagai token . Contohnya pada kalimat 'saya pergi ke sekolah' memiliki empat buah token  yaitu: saya, pergi, ke, sekolah.  
2. Stopwording  
Proses untuk menghilangkan kata -kata yang dianggap tidak memiliki arti pada sebuah kalimat. Kata ini biasanya tergolong kata sambung dan  kata hubung, contohnya: dari, ke, ini, pada.  
3. Stemming  
Proses mengambil kata dasar dari sebuah kata berimbuhan , contohnya kata ' belajar ' menjadi 'ajar', 'menyapu' menjadi 'sapu'.  
Dengan menggunakan ketiga pra-pemrosesan di atas, apabila terdapat kalimat berupa 'Agus dan Budi pergi ke sekolah menggunakan sepeda', maka hasil pra-pemrosesan  akhir nya menjadi: 'Agus ', 'Budi ', 'pergi ', 'sekolah ', 'guna ', 'sepeda '. Hasil tersebut nantinya akan digunakan pada proses berikutnya, yaitu  proses klasifikasi dengan menggunakan metode  K-NN.  
2.4 K-Nearest Neighbor  
K-Nearest Neighbor  atau K-NN adalah  salah satu metode  kecerdasan  buatan bertipe  supervised learning , yaitu kecerdasan buatan dengan pembelajaran terarah,  yang digunakan untuk melakukan klasifikasi atau identifi kasi terhadap sekumpulan data ke dalam kelas-kelas yang telah 
didefinisikan  [14, 15] . Metode K-NN melakukan klasifikasi  dengan cara mencari sejumlah k-data yang memiliki  jarak terdekat dari data yang  sedang  diujikan, berikutnya  menghitung  jumlah kelas yang paling banyak muncul  dari k -data tersebut  seperti yang ditunjukkan  pada gambar 1 .   
Gambar 1. Ilustrasi cara kerja K-NN [16]  
Data yang sedang diujikan dianggap satu kelompok dengan kelas yang paling banyak muncul dari sejumlah k-data tersebut. Maka dengan mengacu pada ilustrasi di gambar 1, data yang sedang diujikan (data dengan simbol '?') dengan nilai K = 1 akan dianggap satu j enis dengan data bintang 
berwarna mer ah, karena satu data yang paling dekat dengan data yang diujikan adalah data bintang berwarna merah. Apabila nilai K dinaikkan, maka jumlah data terdekat yang harus dihitung akan ditambah sesuai dengan nilai K tersebut.   
Perhitungan jarak pada metode K-NN umumnya digunakan dengan menggunakan persamaan berbasis spasial seperti euclidean distance . Namun pada kasus pemrosesan teks, perhitungan 
dilakukan dengan menggunakan persamaan cosine similarity  seperti ditunjukkan pada persamaan (1).  
ð‘ð‘œð‘ _ð‘ ð‘–ð‘šð‘–ð‘™ð‘Žð‘Ÿð‘–ð‘¡ð‘¦ (ð±,ð²)= âˆ‘ ð‘¥ð‘– Ã— ð‘¦ð‘–ð‘›
ð‘–=1
âˆšâˆ‘ ð‘¥ð‘–2 ð‘›
ð‘–=1Ã—âˆšâˆ‘ ð‘¦ð‘–2 ð‘›
ð‘–=1 (1)  
Keterangan:  
n = jumlah  atribut  
x = data uji  
y = data target   
Cosine similarity  merupakan sebuah metode untuk mencari kemiripan dua buah data berdasarkan kedekatan sudut ( cosine ) seperti yang ditunjukkan pada gambar 2 . Metode tersebut  cocok digunakan untuk mencari kemiripan dua buah dokumen yang memiliki format teks, karena panjang isi dari masing -masing dokumen tidak selalu sama, sehingga akan menjadi sulit jika dihitung menggunakan persamaan berbasis spasial seperti euclidean distance  [17].  
Gambar 2. Ilustrasi perhitungan jarak pada persamaan cosine similarity  [18]  
 
3. METODE PENELITIAN  
Penelitian dilakukan melalui beberapa tahapan yang disusun secara runtut, yaitu pengumpulan data, pembangunan sistem, pengujian, dan evaluasi.   
3.1 Pengumpulan Data  
Tahap pengumpulan data dilakukan dengan cara mengumpulkan data percakapan chat dari perangkat telepon seluler  milik fakultas yang  selama ini  digunakan sebagai sarana  layanan tanya jawab  dari pihak mahasiswa atau wali dengan admin . Selain itu, data juga dik umpulkan melalui kuisioner yang disebarkan kepada mahasiswa dan wali. Kuisioner tersebut meminta responden untuk memasukkan daftar pertanyaan yang biasa mereka tanyakan kepada pihak kampus. Dari tahap ini, terkumpul 534 data pertanyaan  yang akan digunakan untuk proses berikutnya.  Data yang berhasil dikumpulkan disimpan dalam sebuah file teks dengan format JSON (JavaScript Object Notation) sebagai basis data pengetahuan atau knowledge database . Struktur file tersebut terdiri dari attribute 'knowledge' yang di dalamnya berisi class-class hasil 
pengelompokan seluruh data yang telah terkumpul. Setiap class memiliki attribute 'class' untuk menyimpan nama class, 'patterns' untuk menyimpan daftar pertanyaan terkait class tersebut, dan 'responses' berisi daftar jawa ban terkait class tersebut. Salah satu contoh struktur sebuah class di file JSON adalah seperti berikut ini:   
{ 
class"""": """"beasiswa """", 
patterns"""" : [ 
 """"Bagaimana cara mendaftar beasiswa? """", 
 """"Apakah saya bisa minta informasi beasiswa? """" 
 ], 
responses"""" : [ 
 """"Informasi beasiswa bisa diakses melalui ukdw.ac.id/beasiswa """" 
 ], 
} 
Gambar 3. Struktur JSON dari sebuah data latih  
3.2 Pembangunan Sistem  
Sistem chatbot  dibangun dengan menggunakan bahasa pemrograman Python  versi 3.8 . Beberapa pustaka  pihak ketiga turut ditambahkan  pada sistem  chatbot  untuk mempermudah proses pengolahan data, di antaranya adalah  pustaka Natural Language Toolkit (NLTK) untuk keperluan tokenisasi, serta pustaka Sastrawi  untuk keperluan stemming  dan stopwording . Diagram alir mengenai cara kerja si stem dapat dilihat pada gambar 4 .    
Gambar 4. Diagram alir cara kerja sistem chatbot   
3.3 Pengujian Sistem  
Pengujian dilakukan dengan cara meminta bantuan dari 20 partisipan yang merupakan mahasiswa atau wali mahasiswa untuk mencoba mengajukan beberapa pertanyaan pada sistem  
chatbot  yang telah dibangun . Setiap partisipan diminta untuk mengajukan 5 buah pertanyaan terkait dengan kegiatan akademik  dengan tema yang telah ditentukan sebelumnya berdasarkan class  yang berhasil dibangun , sehingga total pertanyaan yang berhasil dikumpulkan adalah 100 pertanyaan. Dari 100 pertanyaan tersebut, penulis melakukan seleksi untuk membuang  pertanyaan-pertanyaan yang dianggap bias sehingga tidak dapat diproses oleh sistem. Setelah melalui proses tersebut, jumlah pertanyaan yang valid dan dapat diproses oleh sistem berjumlah 86 pertanyaan.   
 
4. PEMBAHASAN  
Sistem  chatbot  yang dibangun oleh penulis memiliki basis data yang terdiri dari 10 class , di mana masing -masing class  mem iliki paling sedikit  5 buah pertanyaan sebagai data latih.  Keterangan untuk masing -masing class  dapat dilihat pada tabel 1.   
Tabel 1. Class  pada basis data  
Nama  Keterangan  
beasiswa  Pertanyaan seputar pendaftaran beasiswa  
registrasi  Pertanyaan seputar registrasi perkuliahan  
pembayaran  Pertanyaan seputar tata cara pembayaran kuliah  
wisuda  Pertanyaan seputar prosedur pendaftaran wisuda poin Pertanyaan seputar poin keaktifan  
kuliah  Pertanyaan seputar agenda perkuliahan  
jadwal  Pertanyaan seputar jadwal kegiatan program studi selama satu semester  
administrasi  Pertanyaan seputar layanan administrasi fakultas  
dosen  Pertanyaan seputar jadwal konsultasi setiap dosen  
info Pertanyaan seputar informasi terbaru dari fakultas   
Pengujian akurasi metode K-NN dilakukan dengan nilai K = 1 sampai dengan K = 5 dengan pertimbangan jumlah data latih paling sedikit dari sebuah class  adalah 5, sehingga dengan 
menggunakan nilai K = 5 masih terdapta peluang agar seluruh class yang menjadi target dapat terpilih seluruhnya.  Melalui  pengujian yang dilakukan menggunakan  data sebanyak 86 pertanyaan, didapatkan nilai tingkat akurasi metode K-NN seperti ditunjukkan pada tabel 2.   
Tabel 2. Nilai akurasi pengujian  
K Nilai a kurasi (%)  
1 52.33%  
2 52.33%  
3 53.48%  
4 48.84%  
5 41.86%   
Berdasarkan hasil pengujian seperti yang ditunjukkan pada tabel 2, maka dapat disimpulkan bahwa nilai K tertinggi didapatkan pada K = 3 yaitu sebesar 53.48%.  Beberapa kendala yang mengakibatkan sistem  chatbot  memberikan hasil yang tidak tepat disebabkan  oleh adanya kata-kata penting  dalam kalimat yang masuk ke dalam dua atau lebih class , sehingga sistem chatbot  kesulitan untuk mengklasifikan pertanyaan tersebut secara tepat. Contohnya seperti ditunjukkan pada tabel 3, di mana ketiga pertanyaan tersebut memiliki susunan kata yang mirip, hanya berbeda pada bagian akhir saja.   
Tabel 3. Nilai akurasi pengujian  
No Pertanyaaan  Class Target  Token  
1 bagaimana tata cara pendaftaran wisuda?  wisuda  tata, cara, daftar, wisuda  
2 bagaimana tata cara pendaftaran beasiswa?  beasiswa  tata, cara, daftar, beasiswa  
3 bagaimana tata cara pendaftaran mata kuliah?  registrasi  tata, cara, daftar, mata, kuliah   
Pada contoh di tabel 3, token  yang dihasilkan oleh ketiga pertanyaan tersebut memiliki susunan kata yang hampir serupa, ketiganya sama -sama memiliki tiga buah kata: tata, cara, dan daftar. Sedangkan kata kunci yang dapat membedakan pertanyaan tersebut dibanding pertanyaan lainnya hanya satu atau dua kata, lebih sedikit jika dibandingkan dengan jumlah kata yang mirip (tiga). Hal ini menyebabkan sistem kesulitan dalam mengklasifikasikan pertanyaan tersebut secara tepat . 
Selain itu, terdapat beberapa kata yang menggunakan be ntuk tidak baku singkatan seperti 'sy' (saya) dan 'bgmn' (bagaimana) yang tidak dapat dikenali oleh sistem. Kemudian terdapat kata tidak baku slang /informal  seperti 'gimana' (bagaimana) dan 'kalo' (kalau) yang juga tidak dapat 
dikenali oleh sistem setelah melalui tahap tokenisasi. Kedua hal tersebut turut mengakibatkan sistem tidak dapat memberikan nilai akurasi yang maksimal dalam mengklasifikasikan pertanyaan.  
  
5. KESIMPULAN  
Sistem chatbot  yang dibangun dapat bekerja dengan baik dan memberikan nilai akurasi  maksimal sebesar 53.48% untuk nilai K = 3.  Beberapa kendala yang dialami oleh sistem adalah adanya pertanyaan -pertanyaan dari class  berbeda tetapi memiliki susunan kata yang serupa, sehingga sistem sulit untuk mengklasifikasikan pertanyaan tersebut dengan  tepat. Kemudian terdapat kata-kata yang tidak dapat dikenali oleh sistem karena kata tersebut tergolong sebagai jenis kata tidak baku, sementara basis data yang dimiliki oleh sistem hanya terdiri dari kata-kata dalam bentuk baku.  Beberapa hal yang dapat d ilakukan untuk dapat meningkatkan nilai akurasi dari sistem adalah dengan menghilangkan  kata-kata yang memiliki irisan pada beberapa class , sehingga masing -masing class  hanya berisi daftar kata yang unik. Selain itu pra-pemrosesan tambahan dapat diimplemen tasikan untuk mengolah kata -kata tidak baku menjadi baku agar dapat 
dikenali oleh sistem.  
  
DAFTAR PUSTAKA  
[1]  S. A. Abdul -Kader and J. Woods, """"Survey on Chatbot Design Techniques in Speech Conversation Systems,"""" International Journal of Advanced Computer  Science and 
Applications, vol. 6, no. 7, pp. 72 -80, 2015.  
[2]  J. R. Hill, W. R. Ford and I. Farreras, """"Real conversations with artificial intelligence: A comparison between human â€“human online conversations and human â€“chatbot conversations,"""" Computers in  Human Behavior , vol. 49, pp. 245 -250, 2015.  
[3]  A. Xu, Z. Liu, Y. Guo, V. Sinha and R. Akkiraju, """"A New Chatbot for Customer Service on Social Media,"""" in Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems , Denver, 2017.  
[4]  K. A. Nugraha, """"Deteksi Area Parkir Mobil Berbasis Marker Menggunakan Moment Invariants dan K -NN,"""" Jurnal Teknik Informatika dan Sistem Informasi, vol. 5, no. 1, pp. 112-121, 2019.  
[5]  N. Albayrak, A. Ã–zdemir and E. Zeydan, """"An overview of artificial intelligence based chatbots and an example chatbot application,"""" in 26th Signal Processing and Communications Applications Conference (SIU) , Izmir, Turkey, 2018.  
[6]  D. Sawant, A. Jaiswal , J. Singh and P. Shah, """"AgriBot - An intelligent interactive interface to assist farmers in agricultural activities,"""" in 2019 IEEE Bombay Section Signature Conference (IBSSC) , Mumbai, India, 2019.  
[7]  P. Muangkammuen, N. Intiruk and K. R. Saikaew, """"Aut omated Thai -FAQ Chatbot using RNN -LSTM,"""" in 2018 22nd International Computer Science and Engineering Conference 
(ICSEC) , Chiang Mai, Thailand, 2018.  
[8]  T. Jo, """"Using K Nearest Neighbors for text segmentation with feature similarity,"""" in 2017 Internatio nal Conference on Communication, Control, Computing and Electronics Engineering (ICCCCEE) , Khartoum, Sudan, 2017.  
[9]  R. Pandit and S. K. Naskar, """"A memory based approach to word sense disambiguation in Bengali using k-NN method,"""" in 2015 IEEE 2nd Inter national Conference on Recent Trends 
in Information Systems (ReTIS) , Kolkata, India, 2015.  
[10]  Z. Zong and C. Hong, """"On Application of Natural Language Processing in Machine Translation,"""" in 2018 3rd International Conference on Mechanical, Control and Computer Engineering (ICMCCE) , Huhhot, China, 2018.  
[11]  N. Albayrak, A. Ã–zdemir and E. Zeydan, """"An overview of artificial intelligence based chatbots and an example chatbot application,"""" in 2018 26th Signal Processing and 
Communications Applications Co nference (SIU) , Izmir, Turkey, 2018.  
[12]  K. A. Nugraha and D. Sebastian, """"Pembentukan Dataset Topik Kata Bahasa Indonesia pada Twitter Menggunakan TF -IDF & Cosine Similarity,"""" Jurnal Teknik Informatika dan Sistem 
Informasi, vol. 4, no. 3, pp. 376 -386, December 2018.  
[13]  D. Sebastian and K. A. Nugraha, """"Text normalization for indonesian abbreviated word using crowdsourcing method,"""" in 2019 International Conference on Information and Communications Technology (ICOIACT) , Yog yakarta, 2019.   [14]  Y. Udovychenko, A. Popov and I. Chaikovsky, """"Ischemic heart disease recognition by k-NN classification of current density distribution maps,"""" in 2015 IEEE 35th International 
Conference on Electronics and Nanotechnology (ELNANO) , Kiev , Ukraine, 2015.  
[15]  L. Li, Y. Yu, S. Bai, Y. Hou and X. Chen, """"An Effective Two -Step Intrusion Detection Approach Based on Binary Classification and k -NN,"""" IEEE Access, vol. 6, pp. 12060 - 12073, 2017.  
[16]  A. Navlani, """"KNN Classification using Scikit learn,"""" 2 Agustus 2018. [Online]. Available: https://www.datacamp.com/community/tutorials/k -nearest neighbor -classification -scikit -learn. [Accessed 17 Maret 2021].  
[17]  K. A. Nugraha and D. Sebastian, """"Analisis Trend Akun Media Sosial Twitter Meng gunakan TF-IDF dan Cosine Similarity,"""" in Prosiding Nasional Rekayasa Teknologi Industri dan Informasi XIII , 2018.  
[18]  P. Dangeti, """"Cosine similarity,"""" O'Reilly, [Online]. Available: https://www.oreilly.com/library/view/statistics -for-machine/978178829 5758/eb9cd609 -e44a -40a2 -9c3a -f16fc4f5289a.xhtml. [Accessed 17 Maret 2021].   
 
Biodata Penulis  
Kristian Adi Nugraha, S.Kom., M.T. , lahir di  Yogyakarta pada tanggal 04 Oktober 1989 . Meraih gelar Sarjana Komputer (S.Kom.) di Program Studi Informatika Universitas Kristen Duta Wacana pada tahun 2012 dan gelar Magister Teknik (M.T.) di Universitas Atma Jaya Yogyakarta pada tahun 2013.  Saat ini berprofesi sebagai dosen di Program Studi In formatika Universitas Kristen Duta Wacana.   
Danny Sebastian, S.Kom., M.M., M.T. , lahir di Pekalongan pada tanggal 26 November 1988. Meraih gelar Sarjana Komputer (S.Kom.) di Program Studi Informatika Universitas Kristen Duta Wacana pada tahun 2011, gelar M agister Manajemen (M.M.) di Universitas Pelita Harapan pada tahun 2014 dan gelar Magister Teknik (M.T.) di Universitas Atma Jaya Yogyakarta pada tahun 2016. Saat ini berprofesi sebagai dosen di Program Studi Informatika Universitas Kristen Duta Wacana.  ""
",Chatbot,K-Nearest Neighbor,data percakapan chat dari perangkat telepon seluler,akurasi
RANCANG BANGUN APLIKASI TANYA JAWAB MENGENAI IST AKPRIND YOGYAKARTA BERBASIS MOBILE MENGGUNAKAN ALGORITMA BOYER MOORE  ,"RANCANG BANGUN APLIKASI TANYA JAWAB MENGENAI IST AKPRIND YOGYAKARTA BERBASIS MOBILE MENGGUNAKAN ALGORITMA BOYER MOORE  

1) Agus Mars adualan , 2)Harmastuti , 3)Joko Triyono 

Abstrak                                                   
IST AKPRIND Yogyakarta adalah salah satu kampus yang menawarkan berbagai macam program studi. Banyaknya pertanyaan yang masuk dengan jenis pertanyaan yang hampir serupa  maka dibutuhkan sistem untuk meningkatkan  kinerja bagian admisi . Chatbot merupakan agen cerdas yang dapat meniru kemampuan manusia untuk dapat melakukan percakapan dengan pengguna yaitu manusia. Pembangunan chatbot dapat dilakukan dengan menggunakan  pendekatan dari bidang Question and Answering (tanya-jawab). Penelitian ini mengembangan chatbot berbasis mobile menggunakan metode Boyer Moore sebagai algoritma pen cocokan pola. Hasil pengujian fungsional dengan metode black box yang dilakukan pada aplik asi Tanya Jawab Mengenai IST AKPRIND Yogyakarta, menunjukkan aplikasi dapat berjalan sesuai dengan tujuan dan hasil yang diharapkan, pertanyaan dengan pola kata didepan, lebih cepat memberikan jawaban. Hasil pengujian kompatibilitas menunjukkan bahwa aplikasi da pat berjalan dengan baik pada berbagai platform mobile yang berbeda, versi android yang berbeda, ukuran, dan resolusi layar yang berbeda. Hasil pengujian User Acceptance Test (UAT)menghasilkan nilai 81.875%.                                                          
Kata Kunci: Algoritma Boyer Moore, Chatbot, IST AKPRIND Yogyakarta.                                          
                                                         
Abstract                                                   
IST AKPRIND Yogyakarta is one of the campuses th at offers a variety of study programs. With so many questions coming in with almost similar types of questions, a system is needed to improve the performance of the admi ssions department. Chatbots are intelligent agents that can mimic the ability of humans  to be able to carry out conversations with users, namely humans. Chatbot development can be done using an approach from the field of Question and Answer. This research develops a mobile -based chatbot using the Boyer Moore method as a pattern matching algo rithm. The results of functional testing with the black box method conducted on the Q&A application about IST AKPRIND Yogyakarta, show that the application can run accor ding to the objectives and expected results, questions with a word pattern in front, faster to provide answers. The compatibility testing results show that the app can run well on a variety of different mobile platforms, different android versions, differe nt screen sizes, and resolutions. The results of the User Acceptance Test (UAT) test resulted in a value of 81.875%.                                                           
Keywords:  Boyer Moore Algorithm, Chatbot, IST AKPRIND Yogyakarta.                                          
                                                          
PENDAHULUAN  
Perkembangan aplikasi mobile pada saat ini sangat cepat dan hampir         menyeluruh disemua kalangan dan semua bidang, hal ini ditandai dengan banyaknya pengguna komputer dan smartphone, baik untuk kepentingan perusahaan, Pendidikan dan kesehatan. Informasi berp eran sangat penting pada era globalisasi pada saat ini. Semua aktivitas dalam kehidupan membutuhkan informasi, sehingga semua aktivitas yang dijalankan dituntut untuk menghasilkan informasi yang berguna bagi setiap orang. Salah satu cara untuk mendapatkan informasi yaitu dengan menggunakan search engine seperti  google dan bing. Selain menggunakan search engine terdapat cara lain untuk mendapatkan informasi, yaitu dengan menggunakan sistem yang dikenal dengan Question & Answering (QA) system. QA System merup akan sistem yang memperbolehkan pengguna menginputkan pe rtanyaan dalam bahasa natural, yaitu bahasa yang kita gunakan sehari â€“ hari. Berbeda dengan search engine, ketika mencari informasi search engine  akan memberikan kita halaman web yang berisi dengan dokumen yang berkaitan dengan informasi yang kita inginkan, sehingga pengguna harus membuka halaman web tersebut untuk mendapatkan informasinya. Dengan menggunakan QA system, pengguna akan dapat bertanya dengan menggunakan bahasa sehari-hari, misalnya pengguna dapat bertanya â€œProgram studi yang ada di ist akprin d?â€ atau â€œfasilitas yang ada di ist akprind?â€ dan sistem akan langsung menjawab pertanyaan tersebut seperti dalam percakapan. Aplikasi yang 
bertipe QA system ini disebut dengan Chatbot. Menurut Khan &  Das [1]. Chatbot adalah program komputer yang memproses masukan bahasa alami dari pengguna dan menghasilkan tanggapan yang cerdas dan relevan yang kemudian dikirim kembali ke pengguna. Saat ini, chatbot ditenagai oleh mesin yang didorong oleh aturan atau mesin kecerdasan buatan (AI) yang berinteraksi dengan pengguna melalui antarmuka berbasis teks. Chandra et al.  [1] melakukan studi kasus Sistem Pemesanan pada Coffee Shop menggunakan chatbot, karena   seringnya seorang staff/karyawan dalam memberikan pelayanan informasi dan transaksi yang dilakukan secara manu al kepada pelanggan yang berkaitan dengan kegiatan usaha tersebut. Chatbot merupakan agen cerdas yang dapat meniru kemampuan manusia untuk dapat melakukan percakapan dengan pengguna yaitu manusia. Pembangunan chatbot dapat dilakukan dengan menggunakan pendekatan dari bidang Question and Answering (tanya-jawab). Chatbot dapat diimplementasikan untuk bidang komersial, pendidikan, hiburan, dan sektor pelayanan publik Azizan Hakim & Nurhayati  [1] Aplikasi chatbot akan menyimpan pertanyaan â€“ pertanyaan serta jawabannya pada sebuah database. Ketika pengguna mengajukan sebuah pertanyaan, chatbot akan menyamakan pertanyaan pengguna tersebut dengan yang ada dalam databasenya untuk memberikan jawaban yang tepat. Salah satu metode yang dapat digunakan dalam pengolahan  pertanyaan Chatbot ialah algoritma Boyer Moore. Algoritma Boyer-Moore adalah algoritma pencarian string yang paling efektif saat ini. Algoritma yang ditemukan oleh Bob Boyer dan J. Strother Moore ini telah menjadi standar untuk berbagai literatur pencarian string Lubis et al.,  [2], String Matching (pencocokan  string) adalah  proses  mencari  atau  mencocokkan  satu  atau lebih  pola  (pattern)  dalam  sebuah  teks  (string). Disini  """"teks"""" dapat berupa kumpulan karakter, kalimat atau paragraf, dan """"pola"""" adalah urutan karakter yang dicari dalam teks. M A Hakim, S. N.  [1], Pencocokan string  adalah teknik  penting dalam pemrosesan teks dan komputasi secara umum, dan algoritma-algoritma yang efisien digunakan untuk memastikan pencarian pola d apat dilakukan dalam  waktu yang wajar, terutama pada teks yang sangat besar. Menurut Raharjo  [1] dalam buku Pemrograman Android dengan Flutte dan Dart, Dart adalah bahasa pemrograman yang dapat digunakan untuk membuat aplikasi server (berbentuk command -line interface), web, maupun mobile (Android dan iOS). Aplikasi Dart dieksekusi secara langsung melalui Dart Virtual Machine (VM) tanpa melalui proses penerjemahan ke kode objek (bytecod e) terlebih dahulu sedangkan Flutter adalah software development kit (SDK) buatan google yang berfungsi untuk membuat aplikasi mobile menggunakan bahasa pemrograman Dart, baik untuk Android maupun iOS. Flutter ditujukan untuk mempermudah dan mempercepat proses pengembangan aplikasi mobile yang dapat berjalan di atas Android dan iOS, tanpa harus mempelajari dua Bahasa pemrograman secarah terpisah.  Pencocokan string (String Matching ) yaitu proses  mencari  atau  mencocokkan  satu  atau lebih pola  (pattern)  dalam sebuah teks  (string).  Dalam konteks  ini, """"teks""""  dapat berupa kumpulan karakter, seperti sebuah kalimat atau paragraf, dan """"pola"""" adalah urutan karakter yang  ingin  kita cari dalam teks. Pencocokan  string  sering  digunakan  dalam  berbagai  aplikasi  dan masalah  komputasi,  seperti  pemrosesan  bahasa alami,  analisis teks, pengenalan  pola,  kompilasi, dan berbagai  aplikasi  dalam  bioinformatika. Pencocokan  string adalah  teknik  penting  dalam  pemrosesan  teks  dan komputasi secara umum, dan algoritma -algoritma yang efisien diguna kan untuk memastikan pencarian pola dapat dilakukan dalam waktu yang wajar, terutama pada teks yang sangat besar Nurhayati,  [1]. Sedangkan Algoritma Boyer Moore adalah pencocokan pattern dari kanan ke kiri maka, informasi yang didapat akan lebih banyak, seperti pattern dengan panjang pattern diletakkan pada ujung kiri atas dari sebuah String, sehingga kedua karakter yang pertama sejajar dan char adalah karakter ke-pattern dari string , maka karakter tersebut akan sejajar dengan karakter terakhir dari pattern . Tidak seperti algoritma pencarian string lain, algoritma Boyer Moore mulai mencocokkan karakter dari sebelah kanan pattern, ide dibalik algoritma ini adalah bahwa dengan memulai pencocokkan karakter dari kanan, dan bukan dari kiri, maka akan lebih banyak  informasi yang didapat menjelaskan bahwa secara sistematis Satria, T.  [3]. Langkah-langkah penerapan algoritma Boyer Moore kedalam aplikasi menurut Wicaksono et al.,  [2] yaitu : 
a.Proses Pre Boyer Moore Bad Character dilakukan untuk mendapatkan nilai Occu rrence Heuristic (OH), 
b.Proses Pre Boyer Moore Good Suffix dilakukan untuk mendapatkan nilai Match heuristic (MH), 
c.Proses Boyer Moore Setelah mendapatkan nilai OH dan MH, m aka selanjutnya akan memasuki pencocokan string. Android merupakan sistem operasi  berbasis linux yang digunakan untuk telepon seluler (mobile), seperti telepon pintar (smartphone) dan Komputer Tablet (PDA), Prabowo et al.,  [4] Pada saat  ini, hampir set iap orang memiliki perangkat mobile seperti smartphone dengan kemampuan komputasi layaknya PC. Keragaman aplikasinya, mulai dari aplikasi sosial media sampai dengan aplikasi perkantoran, serta kemudahan menggunakan fungsi-fungsinya, membuat pengguna dapat bekerja dan berkomunikasi dalam keadaan mobile, Rohandi et al., n.d.  [1]. Dalam konteks kampus, aplikasi tanya jawab dapat membantu calon mahasiswa yang ingin memilih jurusan yang tepat dengan menyediakan informasi yang lengkap dan akurat mengenai profil , visi misi, fakultas, prodi, fasilitas dan fasilitas. Salah satu bentuk sistem infor masi yang dapat dikembangkan adalah aplikasi tanya jawab mengenai program studi dan fasilitas yang ada di kampus. IST AKPRIND Yogyakarta adalah salah satu kampus yang mena warkan berbagai macam program studi. Namun, terkadang calon mahasiswa masih kurang paham mengenai detail program studi, kurikulum, peluang kerja, dan sebagainya. Untuk mempercepat pencarian informasi maka penulis akan membuat QA system berupa chatbot mengg unakan algoritma Boyer Moore yang berkaitan dengan informasi seputar IST AKRPIND Yogyakarta.                                                                                                   
METODE                                                   
Langkah-langkah dalam melakukan penelitian ini dibagi menjadi beberapa tahap yang diuraikan  seperti pada gambar 1, seperti identifikasi masalah, studi literatur,A nalisa system, perancangan, implementasi  yang diuraikan sebagai berikut:                                                  
1. Identifikasi Masalah, mengidentifikasi masalah yang ada kemudian menjadikannya latar belakang penelitian ini. Setelah masalah teridentifikasi kemudian penulis membuat tujuan dari  penelitian yang dilakukan setelah tujuan ditentukan maka penulis memba tasi perma salahan. Tujuan dari pembatasan permasalahan adalah agar penelitian yang dilakukan tepat dan tidak melebar sehingga tujuan dari penelitian dapat dicapai.                                  
2. Studi Litelatur, Studi literatur yang dengan mencari dan mengumpulkan data atau informasi  berupa referensi yang terkait dengan permasalahan atau kasus yang diteliti. Referesi sumber berupa jurnal, artikel atau publikasi ilmiah mengenai pencarian data dengan memakai alogritma Boyer Moore atau membahas studikasus yang sama dengan penelitian ini.   Gambar 1 Diagram Alir Penelitian                           
3. Analisa ,pada tahap ini dilakukan analisis semua komponen dalam Chatbot yang akan dibangun dalam penelitian ini.  
a. Analisa Sistem                                          
Pada tahapan akan melakukan analisa sistem seperti mahasiswa dan calon mahasiswa mendapatkan inf ormasi dengan mendatangi langsung Bagian Admisi Institut Sains dan Teknologi AKPRIND Yogyakarta, menghubungi contact person, serta mengunjungi situs resmi. Pada analisa ini ditemukan permasalahan yang didapat, di mana mahasiswa dan calon mahasiswa kesulitan mendapatkan informasi secara lengkap. Sulitnya Admin dalam menjawab satu persatu pertanyaan yang masuk, sering kali pertanyaan yang masuk adalah jenis pertanyaan yang sama.Tahapan ini akan melakukan analisa lanjutan prosedur penelitian untuk sistem Chatb ot, analisa sistem ini ber tujuan dengan memanfaatkan teknologi informasi seperti sistem percakapan (Chatbot) sebagai alat bantu dan inovasi pengembangan untuk mempermudah kinerja Bagian Admisi dalam menjawab setiap pertanyaan yang masuk dari mahasiswa atau  calon mahasiswa dengan cepat. Analisa pembuatan sistem Chatbot menggunakan metode Boyer Moore untuk mencari suatu pola kosakata tertentu dalam string pertanyaan pengguna.  
b. Analisa Bot Program                          
Tahap ini berisikan analisa yang akan dilakukan oleh Bot Program. Dengan kata lain meru pakan proses analisa dari program utama Chatbot. Pada Bot Program akan dilakukan satu proses saja yakni Scanner. Scanner akan bertugas menerima input dari pengguna. Inputan yang diterima akan berupa teks yang kemudian teks akan di ubah menjadi huruf kecil. Tanda baca yang terdapat pada inputan pengguna juga akan dihapus pada tahap ini.                                          
c. Analisa Brain File                                  
Tahap ini akan membahas analisa bagaimana basis pengetahuan yang dibuat di simpan dalam Chatbot hingga bagaimana penggunaan algoritma Boyer Moore digunakan dalam mengolah respons yang akan diberikan Chatbot. Proses yang akan dijalankan adalah Reasoning dan Learning.Pada tahap reasoning, algoritma Boyer Moore akan bekerja, tahap ini akan menyelesaikan pertanyaan yang diberikan oleh  pengguna. Algoritma Boyer  Moore akan mencari kata kunci yang tepat dengan memeriksa setiap karakter kata kunci yang dimulai dari karakter terakhir kata kunci dan akan melakukan pergeseran karater ke sebelah kiri. Jika proses yang dilakukan oleh algoritma Boyer Moore berhasil menemukan kata kunci yang sesuai dengan pertanyaan pengguna maka akan mengrimkan jawaban sesuai dengan basis pengetahuan yang dimiliki oleh Chatbot.Tahap Learning akan bekerja apabila pertanyaan yang diberikan oleh pengguna tidak dapat  ditemukan dalam basis pen getahuan oleh algoritma Booyer Moore.         Chatbot akan memberikan respon ketidak mampuan untuk menjawab pertanyaan tersebut.                                  
d. Analisa Respon                                  
Tahap ini menganalisa bagaimana Chatbot akan berinteraksi dengan pengguna melalui respons yang berikan. Tahap ini membahas bagaimana cara Chatbot dapat memberikan respons terhadap pertanyaan tersebut, dan bagaimana respons yang akan diberikan oleh Chatbot jika pertanyaan yang diberikan tidak ditemukan dalam basis pengetahuan yang dimiliki. 
4.  Perancangan                                  
Tahap ini melip uti penentuan unsur-unsur yang perlu dimasukkan ke dalam sistem. Penentuan ini berdasarkan hasil analisis yang telah dilakukan sebelumnya. Langkah pada tahap perancangan meliputi pembuatan brain file, desain antarmuka dan mengumpulkan alat dan bahan yang akan digunakan . 5.Implementasi  
Implementasi merupakan  tahap eksekusi setelah semua tahap sebelumnya sudah dilakukan.          
6. Pengujian                                                  
Pada tahap ini pengujian pertama akan melakukan pengujian dengan menggunakan Black Box, yang bertujuan guna mengetahui penilaian terhadap perangkat lunak untuk mendapatkan hasil yang semuanya sudah sesuai dengan persyaratan fungsional dalam satu program. Pengujian kedua yang digunakan yaitu pengujian User Acceptance Test, dengan tujuan untuk mengetahui performa hasil kinerja dari  algoritma Booyer Moore sistem dengan pencocokan pola kata.          
7. Kesimpulan dan Saran                                  
Pada tahapan kesimpulan dan saran merupakan tahap terakhir dari sebuah penelitian yang telah dibuat. Penarikan kesimpulan bertujuan untuk mengetahui keberhasilan dan kesesu aian aplikasi yang telah dibangun terhadap target yang sudah dirancang sebelumnya. Selain itu pada tahap ini juga ditambahkan saran untuk penelitian agar dapat memiliki hasil yang lebih baik.                                  
8. Diagram alir aplikasi                          
Diagram alir  aplikasi dapat dilihat gambar 2 menjelaskan alur program sistem tanya jawab yang akan dibuat. Langkah (1) ketika program dijalankan maka akan muncul pesan pembuka aplikasi, (2) pengguna menginputkan pertanyaan. Pertanyaan akan dicari jawaban nya pada brainf ile,dan dilakukan proses pencocokan kata kunci. Jika ada maka jawaban akan di set sesuai pertanyaan, jika jawaban tidak ada maka jawaban akan di set bahwa pertanyaan tidak dimengerti program.  Gambar 2 Diagram Alir Aplikasi                                                          
HASIL DAN PEMBAHASAN                                          
1. Aplikasi Mobile                                  
Penelitian ini menghasilkan aplikasi tanya jawab mengenai IST AKPRIND Yogyakarta berbasis Android dengan menerapkan algoritma Boyer Moor. Aplikasi ini diberi nama BOT AKPRIND. Hasil pembuatan aplikasi Resiskom AR Brosur adalah sebagai berikut:                                         
1) Halaman Loading Screen                                  
Pada Gambar 3 menampilkan halaman loading screen pada aplikasi Mobile sebagai halaman awal pengguna yang akan masuk ke halaman selanjutnya selama 5 detik.  
Gambar 3. Halaman Loading Screen                          
2) Halaman Onboarding Screen                                  
Pada Gambar  4 menampilkan halaman onbording screen yang menunjukan pengenalan aplikasi, pengguna dapat langsung memilih tombol mulai untuk diarahkan ke halaman chat.   Gambar 4. Halaman Onboarding Screen                           
3) Halaman Aplikasi Tanya Jawab                  
Pada Gambar 5 adalah tampilan awal aplikasi. Untuk melakukan tanya jawab, pengguna harus memasukkan terlebih dahulu teks yang ingin ditanyakan setelah itu akan keluar jawaban yang dijawab oleh sistem.                                           
Gambar 5. Halaman Aplikasi Tanya Jawab                   
4) Contoh Hasil Pertanyaan                                  
Pada Gambar 6 merupakan contoh hasil dari pencarian yang didapatkan oleh Aplikasi Tanya Jawab Mengenai IST AKPRIND Yogyakarta dengan inputan atau pertanyaan â€Program studi yang ada di kampusâ€.                                  
Gambar 6. Contoh Hasil Pertanyaan                           
5. Implementasi Algoritma Boyer Moore                  
Penelitian ini menghasilkan aplikasi tanya jawab mengenai IST AKPRIND Yogyakarta berbasis Android dengan menerapkan algoritma Boyer Moore. Setelah pengguna memasukan pertanyaan proses terakhir adalah keluarnya output jawaban. Sebelum output tersebut keluar , kata kunci diolah terlebih dahulu setelah itu dicocokan menggunakan algoritma Boyer Moore sebelum hasilnya ditampilkan ke pengguna. Berikut implementasi Algoritma Boyer Moore pada aplikasi tanya jawab mengenai IST AKPRIND Yogyakarta. Pada pattern â€œprogra m stu diâ€ dengan teks pertanyaan â€œIST AKPRIND ada program studi apa aja?â€.                                           
6. Menentukan nilai Match heuristic (MH) dan Occurrence Heuristic (OH), untuk menentukan jumlah  pergeseran yang akan dilakukan jika mendapat karakter tidak cocok pada proses pencocokan dengan teks pertanyaan, seperti tabel 1 dan tabel 2.                                          
Tabel 1. Tabel Pencacahan Kata Kunci                  
Posisi  1 2 3 4 5 6 7 8 9 10 11 12 13                 
Kata Kunci  p r o g r a m  s t u d i                 
Pencacahan  12 11 10 9 8 7 6 5 4 3 2 1 0                  Tabel 2. Tabel Occurrence Heuristic(OH)          
Karakter  Shift/Pergeseran (OH)  Pencacahan                  
i 0 0                                                         
d 1 1                                                         
u 2 2                                                         
t 3 3                                                         
s 4 4                                                         
5 5                                                         
m 6 6                                                         
a 7 7                                                         
r 8 8                                                         
g 9 9                                                         
o 10 10                                         
r 8 11                                                         
p 12 12                                                 
Pencacahan dimulai dari posisi terakhir string sampai ke posisi awal, dimulai dengan 0. Karakter yang sudah ditemukan (missal k arakter â€œmâ€ dengan nilai 0) jika karakter tersebut ditemukan kembali maka nilainya sama dengan nilai pencacahannya. Jika karakter belum pernah ditemukan, maka nilai pergeserannya sama dengan nilai pencacah, penjelasan detail seperti Tabel 3. Tabel 3. Match  Heuristic (MH)  Posisi String  Karakter  Shift/Pergeseran (MH)          
0 i 1                                                         
1 di 13                                         
2 udi 13                                                 
3 tudi 13                                                 
4 studi  13                                                 
5 studi  13                                                 
6 m studi  13                                                 
7 am studi  13                                                 
8 ram studi  13                                         
9 gram studi  13                                         
10 ogram studi  13                                         
11 rogram studi  13                                         
12 Program studi  13                                         
Untuk menda patkan nilai OH,MH dapat dilihat table 4.  Pola yang akan digeser kekiri untuk memperoleh hasil yang cocok.   Tabel 4. Nilai OH dan MH                          
Posisi  1 2 3 4 5 6 7 8 9 10 11 12 13                         
Kata Kunci  p r o g r a m  s t u d i                 
Pencacahan  12 11 10 9 8 7 6 5 4 3 2 1 0                 
OH 12 8 10 9 8 7 6 5 4 3 2 1 0                                 
MH 13 13 13 13 13 13 13 13 13 13 13 13 1         
2. Setelah nilai OH dan MH didapat selanjutnya melakukan pencocokan kata kunci table 5 dengan melakukan pergeseran yang didapat dari hasil perbandingan antara nilai OH dan MH  Tabel 5. Langkah pertama pencocokan pola                  
1 2 3 4 5 6 7 8 9 10 11 12 13                                 
a k p r i n d  a d a   p                                 
p r o g r a m  s t u d i                                 
14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29         
r o g r a m  s t u d i   a p a                                 
Pencocokan pertama: â€˜pâ€™ dan â€˜iâ€™ = tidak cocok OH = karakter â€˜p â€™ ada dalam kata kunci, maka nilai pergeseran 12, MH = ketidakcocokan karakter â€˜iâ€™ pada posisi 12 memiliki nilai pergeseran 1. Dipilih nilai pergeseran OH dan MH yang paling besar yaitu 12 dapat dilihat pada table 6.                                  
Tabel 6. Langkah kedua pencocokan pola                  
1 2 3 4 5 6 7 8 9 10 11 12 13                                 
a k p r i n d  a d a   p                                 
            p                                                 
14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29         
r o g r a m  s t u d i   a p a                                 
r o g r a m  s t u d i                                     
Semua karakter yang dicocokkan, maka terdapat string yang di cari â€œtelah ditemukanâ€. Selanjutnya kata kunci yang cocok akan di sesuaiakan dengan jawaban yang telah tersimpan didalam brain file. Maka Chatbot akan memberikan jawaban seperti â€œBerikut                                         
A. Program Magister (S2)                                  
1. Magister Rekayasa Mesin                                  
B. Program Sarjana S1                                          
1. Teknik Kimia                                          
2. Teknik Industri                                          
3. Teknik Mesin                                          
4. Teknik Elektro                                          
5. Informatika                                          
6. Statistika                                                  
7. Rekayasa Sistem Komputer                                  
8. Teknik Lingkungan                                          
9.Teknik Geologi                                          
10. Bisnis Digital                                          
C. Program Vokasi D3                                          
1. Teknologi Industri                                          
2. Teknologi Mesinâ€.                                  
7. Pengujian                                          
Tahap pengujian dilakukan untuk mengetahui kesesuaian aplikasi dengan hasil perancangan yang dilakukan sebelumnya. Pengujian juga dilakukan untuk mengurangi resiko kesalahan dan menyempurnakan aplikasi sebelum diterapkan. P engujian pada penelitian ini dilakukan menggunakan 3 pengujian yaitu pengujian black box, pengujian kompatibilitas dan penguji an user acceptance test. Pengujian black box pada aplikasi tanya jawab mengenai IST AKPRIND Yogyakarta berbasis mobile, akan menguji respon mobile pada saat Loading Screen, Mulai, Input pesan, Output Pesan, Menu hasil uji dapat dilih at pada tabel 7.                                          
Tabel 7. Pengujian Black Box Aplikasi Chatbot                  
No Komponen Uji  Skenario dan Hasil Uji                  
Skenario Uji  Hasil yang                         
Diharapkan  Hasil                                 
Pengujian                                          
1.  Loading Screen  Menunggu loading  Loading Screen selama 5 detik. Masuk ke halaman on bording screen  Berhasil [âˆš] Gagal [ ]                                                  
2. Mulai  Klick tombol â€œMulaiâ€   Masuk ke halaman chat.  Berhasil [âˆš] Gagal [ ]                                  
3. Input pesan  Pengguna menuliskan pertanyaan di text box dan menekan tombol submit  Pertanyaan terkirim ke server dan diberikan jawaban  Berhasil [âˆš] Gagal [ ]                  
4. Output Pesan  Pengguna menanyakan                         
visi dan misi IST AKPRIND  Jawaban akan menampilkan visi dan misi IST AKPRIND  Berh asil [âˆš] Gagal [ ]                  
5. Menu                                                  
Kembali  Klik tombol                                  
â€œKembaliâ€  Keluar dari aplikasi dan kembali ke halaman onbording screen  Berhasil [âˆš]  Gagal [ ]          
Berdasarkan hasil pengujian fungsional dengan metode black box yang dilakukan pada aplikasi Tanya Jawab Mengenai  IST AKPRIND Yogyakarta, maka diperoleh kesimpulan bahwa aplikasi Tanya Jawab  Mengenai IST AKPRIND Yogyakarta berhasil berjalan sesuai dengan tujuan dan hasil yang diharapkan.  
8. Pengujian Kompatibilitas                          
Pengujian dari aplikasi yang dirancang dan pembahasan terhadap hasil dari aplikasi tersebut menggunakan metode kompatibilitas bertujuan untuk memastikan bahwa program telah berjalan sesuai dengan skenario (tabel 8). dan menghasilkan keluaran yang sesuai sebagai reaksi dari suatu aksi tertentu.                                  
Tabel 8. Tabel Pengujian Kompatibilitas                  
Nama Perangkat  Versi Android Ukuran Layar  Resolusi Layar  Hasil                                                          
Vivo Y12  9 6.35 Inchi 720 x 1544 px  Aplikasi  berjalan lancar                                                  
Realme C17 10 6.5 inchi  720 x 1600 px  Aplikasi  berjalan lancar                                          
Samsung A21S  10 6.5 inchi  720 x 1600 px  Aplikasi  berjalan lancar                                          
Oppo A16  11 6.51 inchi  720 x 1600 px  Aplikasi  berjalan lancar                                                  
Redmi Note 9 Pro  12 6.67 inchi  2400 x 1440 px  Aplikasi  berjalan lancar                                          
9. Pengujian User Acceptance Test                          
Pengujian  dilakukan terhadap 20 responden yang diam bil secara acak yaitu 15 mahasiswa dan 5 masyarakat umum yang terdiri dari 8 pertanyaan dan meliputi tiga variabel, yaitu Desain, Kemudahan dan Efisiensi. Setelah melakukan survei dengan         menyebarkan kuisioner beserta aplikasi yang dapat diunduh, maka diperolehlah data sebanyak 20 responden. Tabel 9 berikut adalah hasil dari jawaban para responden mengenai kuisioner yang menyatakan sangat setuju diberikan.  
Tabel 9. Nilai rata-rata jawaban                  
Pertanyaan  Jawaban Responden                          
Sangat Setuju                                         
(SS) Rata-rata (%)                                         
P1 12 60                                         
P2 11 55                                         
P3 19 95                                         
P4 20 100                                         
P5 20 100                                         
P6 13 65                                                 
P7 18 90                                                 
P8 18 90                                                 
jumlah  131 655                                         
Nilai Rata-rata 81.875                                  
Hasil jawaban dari responden sebanyak 20 orang tersebut di atas kemudian dapat dihitung seperti berikut:          
Jumlah pesponden = 20                                  
Jumlah pertanyaan = 8                                  
Total jawaban nilai sangat setuju = 131          
Total Skor = (131/160)*100% =  81.875                  
Berdasarkan perhitungan yang menyatakan Total Rata-rata adalah 655% dapat dicari nilai rata -rata persentase sebagai berikut:                                          
Nilai Rata-rata = (655%)/8 = 81.875%                          
Dari hasil perhitungan persentase diatas, dapat disimpulkan bahwa hasil pengujian aplikasi tanya jawab mengenai IST AKPRIND Yogyakarta berbasis mobile menggunakan algoritma boyer moore yang dilakukan pada 20 responden memiliki hasil 81.875 %. Nilai presentase  81.875 sudah termasuk dalam kategori sangat baik. Sehingga Aplikasi. Tanya Jawab ini dapat diterima dengan baik.                                                                                           
KESIMPULAN                                          
Berdasarkan Analisa, perancangan, implementasi, dan pengujian yang sudah dilakukan terhadap sistem yang dibangun dapat menghasilkan kesimpulan sebagai berikut:          
1. Aplikasi tanya jawab mengenai IST AKPRIND Yogyakarta sudah berhasil dibangun dengan menggunakan metode Boyer Moore.                                          
2. Aplikasi tanya jawab dapat menjawab pertanyaan yang sudah dibuat dan disusun dengan kata kunci yang sudah dimasukan kedalam brainfile.                                          
3. Pertanyaan dengan pola kata didepan, lebih cepat memberikan jawaban.                                          
4. Pengujian User Acceptance Test (UAT) dapat disimpulkan bahwa aplikasi dapat digunakan dengan sangat baik dengan nilai 81.875%.                                                          
UCAPAN TERIMAKASIH                                  
Ucapan terimakasih kepada Prodi Rekayasa Sistem Komputer Institut Sains & Teknologi AKPRIND Yogyakarta atas ijin dan perkenannya untuk men jadi tempat penelitian.                                                          
DAFTAR                                          
[1]  R. &. D. A. Khan, """" Build Better Chatbots. In Build Better Chatbots,"""" in In Build Better Chatbots , India, Springer, 2018, pp. 27-49.                                 
[2]  A. Y. K. D. & . M. R. Chandra, """" (2020). Perancangan Chatbot Menggunakan Dialogflow Natural Language Processing (Studi Kasus: Sistem Pemesanan pada Coffee Shop).,"""" Jurnal Media Informatika Budidarma, p. 208, 2020.                  
[3]  S. N. M A Hakim, """"Pembangunan Aplikasi Chatbot Mi dwify sebagai Media Pendukung Pembelajaran Ilmu Kebidanan Berbasis Android di Stikes Bhakti Kencana Bandung,"""" Komputikab: Jurnal Sistem Komputer, pp. 45 -52, 2019.          
[4]  T. Satria, """",Algor itma Boyer Moore Untuk Penyaringan Pesan Teks Menggunakan Perbanding an Kata Yang Sama,,"""" Seminar Nasional Sains & Teknologi Informasi (SENSASI), 2018.                                                          
[5]  Wicaksono, I. B., Santi, I. H., & Febrinita, F., """"Penerapan Algoritma Boyer-Moore Terhadap Aplikas i Kamus Teminologi Biomedis Berbasis ANDROID.,"""" Jurnal Mahasiswa teknik informatika, pp. 488 -495, 2022.                  
[6]  Aldis Gandi Mitra Sanjung, Norhikmah, """" Analisis Ketetapan Respon Chatbot Menggunakan Algoritma Boyer Moore,"""" Jurnal sistem Informasi 11(1), pp. 207-223, 2022.  [7]  M. S. G. R. D. Imron, """"Implementasi Push Notif ication Pada Sistem Peminjaman Sarana dan Prasarana Berbasis Website.,"""" JURNAL INFORMATIKA, Amikom, U., Fakultas, P., Komputer,, pp. 174-182, 2020.                          
[8]  B. Raharjo, Pemrograman Android d engan Flutter. Bandung â€¯: Informatika, bandung: Informatika, 2019.          
[9]  I. A. W. H. Y. B. W. &. N. S. Prabowo, E -BOOK Ajar Pemrograman Mobile Berbasis Android, -: In Angewandte Chemie International Edition., 2020.                                  
[10]  L. C. P. &. L. Z. Chen, """"Artifici al Intelligence in Edu cation: A Review,"""" IEE Access, pp. 75264 -75278, 2020.  [11]  M. H. N. &. B. I. W. (. Rohandi, """"Pengembangan Mobile -Assisted Language Learning Menggunakan User Centered Design,"""" JNTETI Jurusan Informatika, pp. 27 -34, 2018.  [12]  M. Z. S. H. S. N. Mhd. Andre Wahyuda Lubis, """"Aplikasi Kamus Bahasa Indonesia â€“ Jerman Online Dengan Menggunakan Algoritma Boyer -Moore,"""" in SEMNASTEK UISU , Sumatra Utara, 2023.                                                          
[13]  Y. Nurhayati, """"Implementasi Algoritma Boye r-Moore Untuk Deteksi Kesamaan Abstrak Pada Tugas Akhir,"""" Teknologipintar.org, pp. 1 -21, 2023.",Aplikasi Tanya Jawab,Boyer Moore,Informasi mengenai IST AKPRIND Yogyakarta,User Acceptance Test
PENERAPAN METODE TF-IDF DAN N-GRAM PADA  PENGEMBANGAN APLIKASI CHATBOT BERBASIS LINE UNTUK LAYANAN PUBLIK KESEHATAN DI KOTA MALANG ,"PENERAPAN METODE TF-IDF DAN N-GRAM PADA  PENGEMBANGAN APLIKASI CHATBOT BERBASIS LINE UNTUK LAYANAN PUBLIK KESEHATAN DI KOTA MALANG 

Dhebys Suryani Hormansyah 1,  Indinabilah Aulia2 

Abstrak  
Teknologi kecerdasan buatan saat ini dapat diolah dengan berbagai macam bentuk, seperti ChatBot  dengan berbagai metode, salah satunya menggunakan TF-IDF dan N-GRAM. TF-IDF merupakan sebuag metode dengan menghitung bobot masing-masing kata dalam suatu pertanyaan  yang nantinya akan dicocokan dengan dataset, sedangkan N-GRAM merupakan metode dimana sebagai ekstrasi kalimat masukan dari user yang nantinya akan dimasukkan ke dalam dataset. Hasil penelitian dapat diperoleh bahwa Question -Answering  dan pemberian 
inform asi baru dari user dalam bentuk ChatBot  menggunakan TF-IDF dan N-Gram proses pengurangan data yang relevan dengan dataset.  
 
Kata kunci : Chatbot, N-Gram, Tf-Idf, Chatbot, Bot Line   
 
1. Pendahuluan  
Informasi yang dibutuhkan masyarakat makin hari akan terus meningkat. Efisiensi waktu serta penyampaian sangat mendukung akan berkembangnya sebuah platform informasi. Penyampaian informasi yang didukung oleh perkembangan teknologi terbaru akan memudahkan masyarakat pengguna dalam mendapatkan informasi yang dibutuhkan. Semakin dimudahkannya sebuah media informasi maka akan semakin berkembangnya Kota tersebut. Layanan Publik merupakan suatu media yang disediakan oleh pemerintah untuk dapat memberikan informasi 
terkini kepada masyarakat. Dengan tersedianya layanan publik masyarakat akan dipermudah dalam mencari informasi yang diinginkan dan diharapkan masyarakat dapat memanfaatkan layanan tersebut semaksimal mungkin.  Terdapat website untuk menyediakan informasi layanan publik di Kota Malang yaitu 
www.malangkota.go.id. Pengunjung website akan memperoleh informasi mengenai layanan kesehatan pada website tersebut, serta dapat melihat informasi yang disediakan. Namun dalam penyampaian informasi dirasa kurang intera ktif, dimana 
pengunjng diharuskan dengan jeli memilah satu-persatu data informasi yang tersedia hingga mendapatkan yang dibutuhkan. Penyampaian informasi pada website tersebut hanya berbetuk 
table dan tidak terdapat customer service. Customer service akan sangat berguna pada sebuah website layanan publik dengan didukung mengikuti trend teknologi yang ada.  Terdapat sebuah sistem aplikasi yang dapat digunakan sebagai pengganti customer service  berupa sistem aplikasi chatbot, dimana pengaplikasiannya akan di taruh di website tersebut. Berdasarkan sistem yang sudah ada akan dikembangkan lagi dan juga meningkatkan hasil respon dari sistem yang sebelumnya tidak bisa menampilkan hasil sesuai detail yang diinginkan masyarakat pengguna. Pengembangan sistem informasi  mengikuti kebutuhan masyarakat pengguna yaitu ChatBot Line.  Oleh karena itu untuk mengatasi masalah tersebut dapat dibuatkan sebuah system yang dapat digunakan sebagai pengganti customer service  berupa system aplikasi chatbot . Sering kita ketahui bahwa customer service  diharuskan untuk standby  24 jam non-stop. Chatbot sendiri merupakan sebuah 
program computer yang dirancang untuk mensimulasikan sebuah percakapan atau komunikasi yang interaktif kepada pengguna (manusia) melalui bentuk teks, suara, dan visual. Dengan menggunakan metode TF-IDF sebagai respon tanya-jawab dan metode N-gram sebagai metode yang memproses masukkan informasi dari user/masyarakat pengguna, dimana akan di terapkan dalam pengerjaan aplikasi chatbot  Line pada layanan public kesehatan di Kota Malang.  

2. Landasan Teori   
a. ChatBot   
Chatbot  adalah  salah  satu  sistem cerdas  yang  dihasilkan  dari pemrosesan Bahasa Alami atau Natural Language Processing (NLP) yang merupakan salah satu cabang dari  Kecerdasan Buatan  atau Artificial Intelligence (AI). NLP mempelajari komunikasi antara m anusia dengan computer melalui Bahasa alami Fanani (2012 ). Chatbot memungkinkan manusia dapat berkomunikasi dengan mesin menggunakan perantaraan Bahasa alami. Bentuk komunikasi yang teljadi adalah melalui percakapan menggunakan media tulisan.  Percakapan dengan chatbot dapat berupa obrolan biasa atau obrolan pada tema-tema tertentu yang melibatkan disiplin ilmu yang lain. Percakapan yang terjadi antara komputer dengan manusia merupakan bentuk respon dari program yang telah dideklarasikan pada database pro gram pada computer Fanani (2012 ). Kemampuan komputer dalam menyimpan banyaknya data tanpa melupakan satu pun informasi yang disimpannya digabungkan dengan kepraktisan bertanya pada sumber informasi langsung dibandingkan dengan mencari informasi 
sendiri serta kemampuan learning yang dimilikinya menyebabkan chatbot adalah customer service yang handal.  Contoh percakapan dengan chatbot:  
User: siapa nama kamu?  
Bot : nama saya Bot  
Chatbot akan menjawab sesuai yang tersedia pada dataset, dimana dataset dibangun oleh penulis dengan bantuan perhitungan metode sehingga sistem  dapat menganalisa kemiripan antara pertanyaan harus di jawab dengan respon yang seperti apa.  
b. Line  
Line adalah suatu aplikasi yang digunakan untuk kegiatan berkirim pesan (messenger / chatting) secara gratis di perangkat smartphone. Namun, aplikasi Line sebenarnya juga bisa disebut sebagai aplikasi jejaring sosial karena terdapatnya fitur timeline sebagai wadah untuk berbagi status, pesan suara, video, foto, kontak dan informasi lokasi. Dengan aplikasi Line kita juga bisa melakukan voice call maupun video call secara  real time dan gratis. Line disediakan di semua perangkat smartphone dan di semua sistem operasi mobile: Android, iPhone / iOS, Nokia / Windows Phone, Blackberry dan juga PC (komputer yang bersistemkan Mac OS ataupun Windows) Amin (2012).  Line pada system chatbot kali ini akan berperan sebagai media perantara atau user interface  yang akan berh ubungan langsung dengan user/masyarakat pengguna. Dimana chatbot yang dibuat akan berupa bot chat dalam sebuah grup-room maupun room-chatting  sendiri.  
c. Messaging Api Line   
Messaging Api Line memungkinkan data yang dikirimkan melalui antar server aplikasi system bot dengan platform Line. Saat system bot mengirimkan pesan bot system, sebuah webhook akan dipicu dan platform Line akan mengirimkan permintaan ke URL webhook system  bot. Server system bot kemudian akan mengirimkan permintaan ke platform Line untuk menanggapi pengguna. Permintaan dikirim melalui HTTPS dalam format JSON. Berikut alur system Messaging Api Line pada sebuah system bot : Amin (2012).    
Gambar 2.1 Alur Sis tem Messaging Api Line     
d. Natural Language Processsing   
Natural Language Processing (NLP) merupakan salah satu cabang ilmu AI yang berfokus pada pengolahan bahasa natural. Bahasa natural adalah bahasa yang secara umum digunakan oleh manusia dalam berkomunikasi satu sama lain.  Bahasa yang diterima oleh komputer butuh untuk diproses dan dipahami terlebih dahulu supaya maksud dari user bisa dipahami dengan baik oleh computer.    
Gambar 2.2 Natural Languange Processing  
Ada berbagai terapan aplikasi dari NLP. Diantaranya adalah Chatbot (aplikasi yang membuat user bisa seolah-olah melakukan komunikasi dengan computer), Stemming atau Lemmatization (pemotongan kata dalam bahasa tertentu menjadi bentuk dasar pengenalan fungsi setiap kata dalam kalimat), Sum marization (ringkasan dari bacaan), Translation Tools (menterjemahkan bahasa) dan aplikasi-aplikasi lain yang memungkinkan komputer mampu memahami instruksi bahasa yang diinputkan oleh user Fanani (2012 ). 
e. TF-IDF 
Metode Term Frequency-Inverse Document Frequency (TF -IDF) adalah cara pemberian bobot hubungan suatu kata (term) terhadap dokumen. â€¨ 
1.  Perhitungan Term Frequency (tf) 
menggunakan persamaan (2.1)   
ð’•ð’‡ = ð’•ð’‡ð’Šð’‹ (2.1)â€¨ 
Dengan tf adalah term frequency, dan ð‘¡ð‘“ð‘–ð‘— 
adalah banyaknya kemunculan  term ð‘¡ð‘– dalam 
dokumen ð‘‘ð‘—, Term frequency (tf) dihitung dengan menghitung banyaknya kemunculan term ð‘¡ð‘– dalam dokumen ð‘‘ð‘—.â€¨ 
2. Perhitungan Inverse Document Frequency 
(idf), menggunakan     persamaan (2.2)   ð’Šð’…ð’‡ð’Š =ð’ð’ð’ˆ N/ð’…ð’‡ð’Š(2.2) Dengan ð‘–ð‘‘ð‘“ð‘– adalah inverse document frequency, N adalah jumlah dokumen yang terambil oleh sistem, dan ð‘–ð‘‘ð‘“ð‘– adalah banyaknya dokumen dalam koleksi dimana term ð‘¡ð‘– muncul di dalamnya. â€¨ 
3. Perhitungan term frequency Inverse Document Frequenc y (tfidf), menggunakan persamaan (2.3)â€¨  
ð‘¾ð’Šð’‹ = ð’•ð’‡ð’Š x ð’ð’ð’ˆ (D/ð’…ð’‡ð’Š ) (2.3) 
Dengan ð‘Šð‘–ð‘— adalah bobot dokumen, N adalah 
Jumlah dokumen yang terambil oleh sistem, ð‘¡ð‘“ð‘–ð‘— 
adalah banyaknya kemunculan term ð‘¡ð‘– pada 
dokumenð‘‘ð‘—,danð‘‘ð‘“ð‘– adalahbanyaknyadokumendalamkoleksidimanaterm 
ð‘¡ð‘– muncul di dalamnya. Bobot dokumen ( ð‘Šð‘–ð‘—) 
dihitung untuk didapatkannya suatu bobot hasil 
perkalian atau kombinasi antara term frequency 
(ð‘¡ð‘“ð‘–ð‘—) dan Inverse Document Frequency ( ð‘‘ð‘“ð‘–)[8]. 
f. N-GRAM  
Ekstraksi akan didasarkan pada algoritma pembagian N-gram. Disini N berartikan besaran nilai dari kata untuk dianggap sebagai satu kesatuan untuk berhubungan metadata-nya. Sebagai contoh, untuk kalimat """" the cow jumps over the moon """". Jika N = 2 (dikenal s ebagai bigrams), maka n -grams akan menjadi:  
ï‚· the cow  
ï‚· cow jumps  
ï‚· jumps over  
ï‚· over the  
ï‚· the moon  
Jika X = Jumlah kata dalam kalimat (K), 
jumlah ngrams untuk kalimat K akan menjadi:  N grams K = X â€“ (N-1)  
g. Proses Tanya-Jawab   
Kumpulan data informasi tersebut disebut dengan knowledge base . Knowledge Base( dataset ) merupakan sebuah tempat dimana data yang di masukkan sudah melalui proses tokenized dan dianalisis lebih jauh, disinilah NLP melakukan 
prosesnya.   
Gambar 2.3 Alur proses tanya jawab pengguna dengan sistem 
 
3. Hasil dan Pembahasan  
a. Tampilan pada Line  
Merupakan proses sistem mengalokasikan  kebutuhan-kebutuhan sistem baik perangkat keras maupun perangkat lunak dengan membentuk arsitektur sistem secara keseluruhan. Perancangan perangkat lunak melibatkan identifikasi dan penggambaran abstraksi sitem dasar perangkat lunak dan yang berhubungan.    
Gambar 3.1 Tampilan awal chatbot  
Pada tampilan awal tersebut akan muncul greeting message  sebagai default system (tampilan pada chat room)    
Gambar 3.2 Tampilan menu (1)  
Pada tampilan didalam menu cek terdapat 4 fitur menu salah satunya RS-Puskemas, dengan mengklik menu tersebut akan muncul contoh text.  
b. Konteks Pertanyaan   
Konteks pertanyaan merupakan kumpulan pertanyaan yang nantinya akan membantu system dalamm engolah jawaban dan memberikan jawaban yang sesuai. Konteks pertanyaan sebagai berikut :  
Tabel 3.1 Konteks Pertanyaan  
No Pertanyaan  Keterangan System Menjawab  
1 Dimana alamat praktek dokter ..(nama dokter)..  System akan menampilakan alamat praktek dokter sesuai nama dokter yang di tanyakan  
2 Alamat praktek dokter ..(nama dokter)..  System akan 
menampilakan alamat praktek dokter sesuai nama dokter yang di tanyakan  
3 Dimana praktek dokter ..(nama dokter)..  System akan menampilakan alamat praktek dokter sesuai nama dokter yang di tanyakan  
4 Jadwal praktek dokter ..(nama dokter)..  System akan 
menampilakan jadwal (jam, hari, buka dan tutup) dan alamat  praktek dokter sesuai nama dokter yang di tanyakan  
5 Jam berapa praktek dokter ..(nama dokter)..  System akan menampilakan jam berapa saja dokter tersebut melayani 
pasien beserta alamat praktek dokter   

4. Kesimpulan dan Saran  
Dari hasil penelitian dan perancangan yang telah dibuat, maka dapat diperoleh kesimpulan bahwa Question-Answering dalam bentuk ChatBot menggunakan N-Gram, TF-IDF dan Cosine 
Similarity dapat berkomunikasi dan menyampaikan informasi.  
 
Daftar Pustaka:  
Amin, Fatkhul, 2012. â€œSistem Temu Kembali Informasi dengan Metode Vector Space Modelâ€. Ejournal undip. â€¨ Anonim. https://developers.l ine.me/  , diakses pada 
23 Januari 2018.]  Betha Sidik. 2001. â€œPemrograman Web PHPâ€. Bandung : Penerbit Informatika.  
Fanani, A.Z. 2012. â€œ Sistem Costumer Service Cerdas Menggunakan Metode Fuzzy String Matching Pada E-Commerce â€. Jurusan Teknik Elektro. Instit ut Sepuluh Nopember  Shah, R., Lahoti, S., dan Prof Lavanya. K. 2017. â€œAn Intelligent Chat -bot using Natural Language Processingâ€. Department of Computer Engineering. VIT University.   Utama, Y.P. 2017. â€œ Aplikasi Chatbot Berbasis Web Pada Sistem Informasi L ayanan Publik Kesehatan Di Malang Dengan Menggunakan Metode Tf-Idf Dan Cosine Similarity â€. Jurusan 
Teknologi Informasi. Politeknik Negeri Malang.  ",Chatbot,"TF-IDF, N-Gram",Informasi layanan publik di kota Malang,
Implementasi Natural Language Processing Dalam Pembuatan Chatbot Pada Program Information Technology Universitas Surabaya ,"Implementasi Natural Language Processing Dalam Pembuatan Chatbot Pada Program Information Technology Universitas Surabaya 

Vincentius Riandaru Prasetyo1, Njoto Benarkah2, Vioni Jannet Chrisintha3 

Abstrak  
Program Information Technology  di Jurusan Teknik Informatika , Universitas Surabaya , merupakan salah satu program yang menggunakan bahasa Inggris sebagai pengantar pada saat perkuliahan berlangsung . Akan tetapi, kurangnya informasi mengenai Program Information Technology menyebabkan kurangnya minat calon mahasiswa terhadap program tersebut.  Oleh karena itu, penelitian ini bertujuan untuk membuat sebuah aplikasi chatbot  yang dapat membantu user untuk memperoleh informasi-informasi terkait dengan Program Information Technology  pada Jurusan Teknik Informatika , Universitas Surabaya.  Chatbot  yang dibangun hanya akan memproses pertanyaan dengan bahasa Inggris saja.  Chatbot  yang dibuat pada penelitian  ini menggunakan pendekatan Natural Language Processing  (NLP) untuk memproses pertanyaan yang disampaikan user dan untuk mendapatkan kata kunci dari informasi yang diinginkan user. Sistem akan melakukan pencarian informasi pada kamus informasi yang ada. Apabila informasi tidak ditemukan, maka sistem akan melakukan proses crawling  untuk memperoleh informasi yang dibutuhkan user. Pada penelitian ini, validasi sistem dilakukan dengan dua metode yaitu cross validation  dan user validation . Berdasarkan validasi dengan metode cross validation  didapatkan akurasi sebesar 83 ,33%. User validation  dilakukan dengan cara meminta 10 user untuk melakukan uji coba sistem dan didapatkan akurasi sebesar 76%.  
 
Kata Kunci: Chatbot, Natural Language Processing, Crawling . 
 
Implementation of Natural Language Processing in Creating  
Chatbots at Information Technology Program , University of 
Surabaya  
 
Abstract  
The Information Technology Program at the Department of Informatics Engineering, University of Surabaya, is one of the programs that uses English as a  medium  during lectures.  However, the lack of information about the Information Technology Program causes a lack of interest among pros pective students . Therefore, this study aims to create a chatbot application that can help users to obtain information related to the Information Technology Program at the Department of Informatics, University of Surabaya. The chatbot that is built will only process questio ns in English only. The chatbot made in this study uses a natural language processing (NLP) approach to process user -submitted questions and to get keywords from the information that the user wants  to know about . The system will search for information in t he existing information dictionary. If the information is not found, the system will perform a crawling process to obtain the information needed by the user. In this study, system validation was carried out by two methods, namely cross validation and user validation. Based on the validation with the cross validation method, the accuracy is 83.33%. User validation is done by asking 10 users to test the system and get an  accuracy of 76%.  
 
Keywords : Chatbot, Natural Language Processing, Crawling . 

I. PENDAHULUAN  
Sejalan dengan perkembangan zaman, teknologi telah mengalami berbagai perkembangan pesat. Salah satunya adalah informasi dapat diperoleh dengan lebih mudah. Kecerdasan buatan merupakan salah satu bentuk  teknologi yang mengalami perkembangan sangat pesat di era modern ini . Kecerdasan buatan memungkinkan mesin berpikir dan membuat keputusan sendiri, salah satunya ad alah teknologi chatbot . Chatbot  atau percakapan dengan robot adalah aplikasi kecerdasan buatan yang dapat mensimulasikan percakapan cerdas antar manusia berdasarkan pengetahuan yang diberikan. Chatbot  adalah agen cerdas yang dapat meniru kemampuan manusia untuk berkomunikasi melalui pesan teks  [1]. Keberadaan chatbot  telah banyak digunakan di perusahaan seperti  pada  bank untuk membantu menjawab pertanyaan tentang informasi terkait perbankan dan keluhan pelanggan.  Chatbot  pada penelitian ini dirancang untuk membantu  dalam  menjawab pertanyaan yang terkait dengan Program Information Technology , Jurusan Teknik Informatika , Universitas Surabaya. Informasi terkini tentang Program Information Technology  hanya dapat diakses di halaman http://teknik.ubaya.ac.id/id/program/information technology -international -dual-degree.html , akan tetapi informasi yang diberikan pada halaman ini masih sangat terbatas.  Keterbatasan informasi pada halaman  tersebut  mengakibatkan kurangnya minat dari calon mahasiswa untuk mendaftar pada Program Information Technology , Universitas Surabaya. Keterbatasan informasi tersebut sebenarnya dapat diatasi dengan bertanya langsung ke Direktorat  Marketing and Public Relations  (MPR) yang dimiliki Universitas Surabaya melalui telepon, email, ataupun livechatting . Akan tetapi, keterbatasan staf yang ada di MPR menyebabkan masalah baru ya itu human delay,  apabila banyak calon pendaftar ingin bertanya dalam waktu yang bersamaan. Selain itu, adanya office hour  mengakibatkan calon pendaftar tidak memiliki keleluasaan waktu dalam bertanya.  Oleh karena itu, chatbot  dipilih  karena dapat mengganti kan peran  manusia untuk memberikan jawaban  dengan cepat kepada pengguna  tanpa harus harus membaca skimming  atau scanning  pada sumber data informasi . Pada penelitian ini, chatbot  dibangun dengan menggunakan pendekatan Natural Language Processing . Natural Language Processing  atau sering disingkat NLP  adalah salah satu bidang ilmu komputer, kecerdasan buatan dan bahasa (linguistik) yang berkaitan dengan interaksi antara komputer dengan  bahasa alami manusia. Bahasa alami adalah bahasa yang dapat dipahami manusia. Pada prinsipnya, bahasa alami adalah suatu bentuk informasi yang akan disampaikan dari satu pengguna ke pengguna lainnya . Bahasa alami dapat  direpresentasikan  dalam bentuk suara  atau teks [2]. Penelitian yang berkaitan dengan perancangan aplikasi chatbot sudah pernah dilakukan sebelumnya. Suryani dan Amalia  [3] pada penelitiannya membangun aplikasi chatbot  yang bertujuan untuk memberikan informasi tentang objek wisata yang ada di Jawa Timur. Pada penelitian tersebut, chatbot  dibangun menggunakan konsep Artificial Intelligence Markup Language  (AIML). AIML adalah salah satu turunan dari XML ( Extensible Markup  Language ) di mana terdapat kumpulan pola dan respon yang dapat digunakan untuk pencarian jawaban yang diinginkan pengguna chatbot . Berbeda dengan penelitian sebelumnya, Benedictus, et.al.  [4] mengembangkan chatbot  yang berfungsi sebagai helpdesk  untuk melayani tanya -jawab seputar Sistem Informasi Terpadu yang dimiliki oleh Universitas Sam Ratulangi.  Chatbot  yang dikembangkan pada penelitian tersebut menggunakan algoritma bigram  untuk mencocokkan pola kalimat tanya yang diberikan oleh pengguna. Algoritma ini akan membagi suatu kalimat secara berpasang -pasangan. Metode forward chaining  juga digunakan pada penelitian tersebut untuk melakukan penalaran terhadap kondisi -kondisi tertentu pada sebuah pertanyaan, sehingga sistem dapat menentukan jawaban yang sesuai . Penggunaan metode forward channing  juga digunakan oleh Dwi R, et.al. [5] pada penelitiannya tentang pengembangan aplikasi chatbot  yang terintegrasi dengan web CMS pada UKM MINSU.  Chatbot  yang dibangun pada penelitian tersebut bertujuan untuk menyelesaikan permasalahan pada pelayanan customer service  UKM MINSU yaitu kurangnya respon cepat customer service  karena harus melayani banyak pelanggan, sehingga dapat menyebabkan hilangnya pelanggan tetap dan berpengaruh terhadap omset penjualan.  Penelitian lainnya yang masih berhubungan dengan chatbot  juga dilakukan oleh Amalia dan Wibowo  [6] untuk peningkatan performa bisnis. Pengembangan chatbot  dilakukan dengan memanfaatkan Chatfuel  sebagai bot builder  karena memiliki respon se time yang cepat dalam menjawab pertanyaan dari banyak pengguna sekaligus. Selain itu, penelitian tersebut juga menggunakan Facebook Messanger  sebagai platform chatting  di mana chatbot  akan diintegrasikan ke dalamnya. Berbeda dengan penelitian sebelumnya, Yuniar  dan Purnomo [7] membangun se buah chatbot  dengan nama ALITTA yang bertugas sebagai asisten virtual dan pusat informasi pada aplikasi BALITTAS. Dalam membangun chatbot  ALITTA, Yuniar dan Purnomo memanfaatkan platform  API.AI yang menyediakan layanan NLP dan NLU 
(Natural Language Underst anding ). NLU merupakan turunan 
ilmu dari NLP di mana fungsinya adalah untuk melakukan 
analisis semantik, sehingga makna dari suatu kalimat dapat 
dipahami oleh aplikai chatbot . 
  
II. METOD OLOGI  PENELITIAN  
A. Chatbot  
Chatbot  adalah sebuah aplikasi yang memungkinkan percakapan  antara mesin dengan manusia  menggunakan bahasa alami manusia. Chatbot  sering digambarkan sebagai salah satu cara untuk mensimulasikan interaksi antara mesin  dengan  manusia . Untuk memahami bahasa  alami  manusia, chatbot  menggunakan  pendekatan  NLP untuk  mempelajari  dan memproses setiap kata yang diucapkan oleh manusia  berupa pesan teks  [8]. Cara chatbot  bekerja dimulai dengan menerima input dari pengguna  berupa pesan teks . Sistem kemudian menggunakan NLP untuk memproses input untuk menganalisis, mengidentifikasi, dan menafsirkan makna  yang dimaksud oleh pengguna. Sistem akan memverifikasi input makna dan kondisi dari percakapan yang sedang berlangsung. Setelah sistem memahami artinya, sistem akan mencari data yang dianggap sesuai,  kemudian  respon berupa jawaban yang 
ditampilkan kepada pengguna berdasarkan struktur dan bahasa 
manusia.   
B. Natural Language Processing  
Natural Language Processing  (NLP) adalah kombinasi dari ilmu komputer dan bidang kecerdasan buatan yang terkait dengan linguistik. NLP berkaitan dengan bagaimana mesin memahami bahasa manusia untuk saling berinteraksi. Dengan adanya NLP, komputer dapat belajar dan memahami bahasa manusia, sehingga komputer dapat berkomunikasi dengan 
manusia.  Bahasa manusia adalah hal yang unik karena dibuat 
khusus untuk menyampaikan suatu makna. Untuk membuat 
komputer dapat mengerti bahasa manusia adalah tugas yang 
sulit, karena bahasa manusia memiliki struktur yang kompleks. Selain itu, setiap bahasa memiliki keunikannya sendiri dan mungkin memiliki makna ganda  [9]. Sebagai contoh dapat dilihat dari kalimat berikut, â€œ Look at the dog with one eye â€, di mana kalimat tersebut dapat memiliki arti â€œmelihat  anjing dengan satu mataâ€ atau â€œmelihat anjing yang mempunyai mata satuâ€.  Dua teknik utama untuk memahami NLP adalah syntactic analysis  (analisis sintaksis) dan semantic analysis  (analisis semantik ). Kedua teknik digunakan untuk memverifikasi struktur bahasa. Analisis sintaksis  mengacu pada tata bahasa, sedangkan  analisis  semantik merujuk pada penafsiran  suatu  kalimat.  Syntactic analysis  (analisis  sintaksis ) adalah teknik pengaturan pada suatu kalimat sehingga kalimat memiliki tata bahasa yang benar. Analisis sintaksis  melibatkan penentuan  stuktur kalimat seperti  subjek, predikat, kata benda, kata kerja, kata ganti, dan sebagainya. Sistem akan dapat membaca input kalimat, yang akan dipecah menjadi kata-kata, dan pada akhirnya menghasilkan deskri psi yang terstruktur. Teknik ini 
dapat digunakan untuk menyederhanakan kalimat untuk 
memudahkan pencarian informasi. Selain itu, penggunaan 
analisis sintaksis juga dapat membantu mendeteksi keberadaan 
kata atau kalimat baru atau tidak biasa  [10]. Sebuah kalimat dapat disebut sebagai kalimat, apabila paling tidak terdiri dari subjek dan predikat, sebagai contoh kalimat â€ Andi eatâ€ . Dengan menggunakan teknik analisis sintaksis, komputer dapat membedakan mana yang termasuk subjek (â€œ Andi â€) dan predikat (â€œ eatâ€). Kalimat yang terbentuk 
mungkin saja tidak memiliki makna apapun, karena analisis 
sintaksis hanya memastikan bahwa struktur dari sebuah kalimat sudah benar.  Analisis semantik adalah teknik yang digunakan untuk memahami makna dan interpretasi dari struktur bahasa. Seseorang bisa memahami perkataan orang lain berdasarkan intuisi dan pengetahuan dari bahasa itu sendiri. Komputer tidak memiliki intuisi dan pengetahuan semacam ini, sehingga mereka membutuhkan metode lain, yaitu semantik. Semantik adalah proses pe nting karena output semantik yang diharapkan adalah makna yang terkandung pada sebuah input  [10]. Analisis semantik memproses teks untuk mengidentifikasi dan memahami topik yang dimaksud. Semantik juga mempelajari hubungan antara berbagai konsep dalam teks . Sebagai contoh, apabila sebuah teks terdapat kataâ€œ money â€ dan â€œ accounting â€, maka topik yang sedang dibahasberkaitan dengan â€œ economy â€.  
C. Keyword Extraction  
Keyword extraction  adalah teknik dalam NLP yang menganalisis teks dengan menggunakan keyword  atau kata kunci yang terkandung dalam teks tersebut. Dengan menggunakan metode  ini dapat membantu meringkas teks dan mengidentifikasi subjek teks. Proses yang dilakukan dalam keyword extraction  adalah tokenisasi kata, penghapusan 
stopword , dan analisis. Tokenisasi adalah teknik pemotongan 
kalimat menjadi kata -kata. Penghapusan stopword  adalah 
teknik untuk menghilangkan kata umum yang terkandung 
dalam kalimat, seperti â€œ andâ€, â€œorâ€, â€theâ€, dan sebagainya. Tanda baca dan angka juga merupakan bagian dari stopword . Analisis dilakukan dalam bentuk Part-Of-Speech  (POS)  tagging , di mana setiap kata diberikan label atau tanda sesuai dengan jenis kata, seperti kata kerja, kata benda, kata ganti,  dan sebagainya. Pengambilan kata penting hanya menggunakan beberapa jenis kata, seperti kata kerja dan kata benda, karena kalimat lengkap paling tidak terdiri dari subjek dan predikat  [11]. Sebagai contoh,  terdapat sebuah kalimat tanya yaitu â€œwhere is Uba ya?â€. Proses keyword extraction  diawali dengan memenggal kalimat tersebut sehingga menjadi â€œ where â€, â€œisâ€, â€œUbaya â€, â€œ?â€. Setelah itu, sistem akan melakukan penghapusan stopword  yaitu kata â€œ isâ€ dan â€œ?â€. Sistem akan memberikan POS tag untuk setiap kata yang t ersisa, sehingga kata â€œ where â€ memiliki tag adverb  (ADV)  dan â€œ Ubaya â€ memiliki tag pronoun  (PROPN). Pengambilan kata penting 
hanya mengambil jenis kata verb, noun , dan pronoun , maka 
sistem akan mengambil kata â€œ Ubaya â€ sebagai keyword  dari kalimat tanya tersebut.  Selain menggunakan metode POS 
tagging , metode lain yang dapat digunakan untuk melakukan 
keyword extraction  adalah term weighting  atau pembobotan 
term. 
D. Term weighting  
Term weighting  atau pembobotan term dilakukan berdasarkan hubungan antara kata dan dokumen serta frekuensi kemunculannya. Metode pembobotan yang digunakan adalah TF -IDF ( Term Frequency - Inverse Document Frequency ). Term Frequency  menghitung jumlah kata yang muncul pada dokumen yang ada. Inverse Document Frequency  menganggap istilah yang jarang muncul dalam dokumen lebih penting daripada yang sering muncul.  Oleh karena itu, semakin sedikit kata yang muncul dalam dokumen, semakin penting kata tersebut dan semakin tinggi nilai IDF  [12]. Pembobotan term dengan TF -IDF dihitung berdasarkan Persamaan  1.  
ð‘¡ð‘“.ð‘–ð‘‘ð‘“ =ð‘¡ð‘“ ð‘¥ ð‘–ð‘‘ð‘“                                      (1) 
Di mana tf adalah term frequency , yaitu kemunculan suatu 
term/token  pada dokumen tertentu. Sedangkan idf adalah 
inverse document frequency , yaitu nilai log basis 10 dari jumlah N dokumen dibagi nilai df. Variabel df adalah frekuensi dokumen yang merupakan jumlah dokumen yang memiliki term tertentu  [13]. Oleh karena itu, IDF dapat dihitung berdasarkan  Persamaan 2 .  
ð‘–ð‘‘ð‘“ =logN
df                                                     (2)  
E. N-Grams  
N-Grams  adalah sebuah metode yang digunakan untuk memecah sebuah kalimat menjadi beberapa bagian, di mana masing-masing bagian terdiri dari N kata. Jumlah N dalam N-Gram  didasarkan pada jumlah kata yang terkandung dalam kalimat  [14]. Ketika jumlah kata dalam kali mat adalah X, jumlah maksimum N yang tersedia untuk N-Gram  adalah X, dan jumlah kombinasi yang diperoleh setelah mengeksekusi N-Gram  adalah X-(N-1). N-Grams  yang sering digunakan adalah unigrams  (N=1), bigrams  (N=2), dan trigrams  (N=3). Ilustrasi untuk metode N-Grams  dapat dilihat pada Gambar 1 di bawah ini.   
Gambar 1. Ilustrasi Metode N-Grams  
N-grams  sering dimanfaatkan  pada  language processing , 
seperti spelling correction  (perbaikan ejaan), word breaking  (pemecahan kata), predict upcoming words  (prediksi untuk kata selanjutnya), dan text summarization  (peringkasan teks). Pada  penelitian ini, N-Grams  digunakan untuk mendapatkan alternatif jawaban berdasarkan kata kunci.   
F. Crawling  
Crawling  adalah metode pengambilan data yang umumnya berasal dari suatu halaman web. Program yang mengimplementasikan metode  crawling  disebut web crawler  
[15]. Proses crawling  diawali dengan  mengakses suatu halaman web tertentu , kemudian  server  akan mengirim respon berdasarkan request  yang diberikan. Respon  yang diterima  akan berisi kode status, tipe konten, character encoding , dan konten  web itu sendiri.  Setelah itu,  crawler  akan membaca respon ini dan mengambil  konten yang dibutuhkan . Crawling  dapat di manfaatkan  untuk berbagai kebutuhan , seperti penggunaan  terkait mesin pencari ( search engine ) atau pencarian data untuk analisis statistik. Pada penelitian ini, crawling  digunakan untuk mencari data atau informasi yang berhubungan dengan program Information Technology . 
 
III. HASIL  DAN  PEMBAHASAN  
A. Gambaran Kerja Sistem  
Proses kerja chatbot  diawali dengan pengguna menginputkan pertanyaan pada user interface  yang disediakan. Sistem akan berusaha mengidentifikasi kata tanya  yang terdapat pada pertanyaan yang diinputkan user. Pertanyaan tersebut akan me ngalami tokenisasi terlebih dahulu sebelum dilakukan identifikasi kata tanya. Proses tokenisasi dilakukan dengan memanfaatkan library  NLTK. Setelah proses tokenisasi, sistem akan melakukan pengecekan pada daftar kata tanya yang sudah disiapkan sebelumnya. Apabila tidak ditemukan kata tanya pada pertanyaan yang diinputkan sebelumnya, maka sistem akan mengirim pesan  kepada user bahwa format pertanyaan tidak sesuai, sehingga user dapat memperbaiki pertanyaan yang diinputkan . Sedangkan apabila kata tanya  ditemu kan, maka sistem akan melanjutkan ke proses berikutnya  yaitu keyword extraction . Proses keyword extraction  diawali dengan penghapusan stopword  yang terdapat dalam kalimat tanya yang diinputkan oleh pengguna. Proses penghapusan stopword  ini juga akan memanfaatkan library  NLTK, karena library  tersebut sudah menyediakan daftar stopword  dalam bahasa Inggris yang siap untuk digunakan. Sistem kemudian akan mencari kata kunci 
dengan pada kalimat tersebut dengan memanfaatkan library  
spaCY . Setelah kata tanya dan ka ta kunci diperoleh, sistem akan mencari jawaban yang sesuai pada  database  yang ada. Terdapat 30 kombinasi kata tanya, kata kunci, beserta jawabannya pada database  yang telah disediakan , dimana hal 
tersebut didapatkan  dari hasil wawancara dengan Ketua 
Jurusan Teknik Informatika , Universitas Surabaya dan 
perwakilan dari Direktorat MPR , Universitas Surabaya. Apabila pencarian jawaban ditemukan pada database , maka 
sistem akan menampilkan jawaban tersebut kepada user. 
Sedangkan apabila pencarian jawaban tidak ditemukan, maka 
sistem akan mencari sinonim dari kata kunci dengan 
memanfaatkan kamus thesaurus . Setelah itu, sistem akan 
mengkombinasikan sinonim yang didapatkan dengan kata 
tanya. Hasil kombinasi -kombinasi tersebut akan digunakan 
untuk proses pencarian ulang jawaban pada database . Apabila 
jawaban masih tidak ditemukan, maka sistem akan melakukan 
crawling  ke halaman -halaman web terkait untuk mencari 
jawaban yang sesuai. Proses crawling  diawali dengan menggunakan kombinasi awal dari kata tanya dan kata kunci hasil keyword extraction . Apabila hasil crawling  awal ini tidak memberikan hasil jawaban, maka akan dilakukan lagi proses crawling  dengan menggunakan hasil kombi nasi-kombinasi sinonim kata kunci dengan kata tanya.  Jawaban yang ditemukan berdasarkan  hasil crawling  akan disimpan ke dalam database , beserta kombinasi kata tanya dan kata kunci yang digunakan. Hal ini dimaksudkan agar ke depannya proses pencarian jawaban menjadi lebih cepat, apabila ada user lain yang menanyakan pertanyaan serupa, karena sistem tidak perlu melakukan proses crawling  lagi. Sistem akan memberikan pesan kepada user untuk menanyakan hal lain, apabila setelah proses crawling  masih tidak ditemu kan jawaban yang cocok.  Alur proses kerja dari sistem chatbot  yang dibangun, dapat dilihat juga pada Gambar 2 berikut.   
Gambar 2. Flowchart  Alur Kerja Sistem Chatbot  
B. Uji Coba  Sistem  
Pada bagian ini, akan menjelaskan uji coba yang dilakukan 
pada aplikasi chatbot  yang telah dibangun.  Chatbot  diuji 
dengan menginputkan tiga jenis pertanyaan yang berbeda yaitu 
pertanyaan di mana jawaban sudah tersedia di database , 
pertanyaan di mana jawaban tidak terdapat di database  sehingga sistem harus melakukan crawling , dan pertanyaan di 
mana jawaban tidak ditemukan di database  maupun dari hasil 
crawling . Selain itu, dilakukan juga uji coba pada chatbot  
apabila diinputkan kalimat pertanyaan dengan format yang 
salah.  Pertama chatbot  diuji dengan menginputkan pertanyaan 
â€œwhat is the accreditation of ITDD? â€, seperti yang ditunjukkan pada Gambar 3. Pertanyaan tersebut sudah tersedia di database  dengan jawaban adalah â€œAâ€.  Chatbot  memerlukan waktu selama 6,96  detik untuk mencari dan menampilkan jawaban dari pertanyaan tersebut.    
Gambar 3. Uji Coba Sistem 1   
Uji coba kedua dilakukan dengan menginputkan pertanyaan yaitu â€œ What is QUT â€, di mana pertanyaan dan jawaban tidak terdapat di database , sehingga sistem akan melakukan crawling  untuk mencari jawaban yang sesuai. Sistem melakukan crawling  pada halaman web dari Queensland University of Technology  (QUT) seperti yang diperlihatkan pada Gambar 4. Proses crawling  ini menyebabkan pencarian jawaban memerlukan waktu yang lebih lama dari sebelumnya, yaitu 10,68 detik. Hasil pencarian jawaban ditampilkan ke user seperti yang ditunjukkan pada Gambar 5.   
Gambar 4. Halaman Web QUT  
Gambar 5.  Uji Coba Sistem 2  
Pada percobaan ketiga, chatbot  diberikan pertanyaan yaitu 
â€œHow many students enrolled in ITDD â€, di mana pertanyaan dan jawaban yang terkait tidak tersedia di database  maupun dari hasil crawling . Untuk percobaan ketiga ini, chatbot  akan menampilkan pesan bahwa  chatbot  masih dalam proses pengembangan, seperti yang dapat dilihat pada Gambar 6. Proses pencarian jawaban membutuhkan waktu yang cukup lama yaitu 83,12 detik. Hal ini dikarenakan sistem mencoba untuk mencari jawaban yang sesuai da ri berbagai macam sumber yang ada. Jawaban dari pertanyaan tersebut sebenarnya dapat diperoleh pada Sistem Akademik 
Universitas Surabaya. Akan tetapi, dikarenakan sistem 
akademik tersebut berisi data -data yang penting dan rahasia, maka chatbot  tidak diperk enankan untuk melakukan crawling  data di dalamnya.    
Gambar 6. Uji Coba Sistem 3   
Uji coba terakhir dilakukan dengan menginputkan pertanyaan dengan format yang salah, yaitu â€œ this is bot for ITDD? â€. Sistem tidak mengganggap kalimat tersebut sebagai pertanyaan yang valid karena tidak mengandung kata tanya 
seperti what , who, where , when , why, dan how. Oleh karena 
itu, chatbot  akan memberikan pesan ke pengguna untuk menginputkan pertanyaan dengan format yang sesuai, seperti yang ditunjukkan pada Gambar 7. Proses ini berlangsung 
relatif cepat yaitu 5,45 detik karena sistem tidak melakukan 
proses pencarian jawaban, baik pencarian  di database  maupun dengan proses crawling .   
Gambar 7. Uji Coba Sistem 4   
C. User Validation  
User validation  adalah salah satu metode validasi, di mana 
user akan mencoba langsung sistem yang telah dibangun dan 
kemudian menilai apakah output  yang diberikan oleh sistem 
sudah sesuai dengan kebutuhan user. Pada penelitian ini, 
validasi dilakukan oleh 10 user, di mana setiap  user akan 
menginputkan 5 pertanyaan unt uk menguji chatbot  yang telah 
dibuat.  Gambar 8 menunjukkan bahwa akurasi dari sistem 
chatbot  yang dibangun yaitu 76%, berdasarkan user validation  yang dilakukan. A kurasi sistem  dihitung  dengan cara, jumlah validasi benar dibagi total pertanyaan dan dikali 100%, sehingga  akurasi = (38/50) x 100% = 76% .  
Gambar 8. Hasil User Validation  
Berdasarkan hasil user validation  yang dilakukan, masih 
ditemukan 12  pertanyaan yang menghasilkan jawaban yang 
tidak sesuai dengan kebutuhan user. Hal ini disebabkan oleh 
keterbatasan sumber data yang dimiliki, baik yang ada di 
database , maupun sumber-sumber lain saat sistem melakukan 
crawling . Pada hasil user validation , masih ditemukan juga 
pertanyaan-pertanyaan yang memiliki makna sama, tetapi 
jawaban yang dihasilkan berbeda, sehingga hasil validasi 
menjadi tidak sesuai. Sebagai contoh, pertanyaan â€œ Who is the head of ITDD program ?â€ dan â€œ Who is the head department of ITDD ?â€. Pada pertanyaan pertama, sistem memberikan output  jawaban â€œ Religion Ethics English â€, sedangkan untuk pertanyaan kedua mengha silkan jawaban â€œBudi Hartantoâ€.  Pada dua pertanyaan tersebut, hanya pertanyaan kedua yang menghasilkan jawaban yang sesuai. Hal ini dikarenakan ada kata kunci yang dihasilkan berbeda. Pertanyaan pertama menghasilkan kata kunci â€œ head â€, â€œITDDâ€, dan â€œprogramâ€, sedangkan pertanyaan kedua menghasilkan kata kunci â€œhead â€, â€œdepartment â€, dan â€œITDDâ€. Perbedaan tersebut terletak pada kata kun ci â€œprogramâ€ dan â€œ department â€, di mana berdasarkan kamus thesaurus  yang digunakan pada sistem, kedua kata tersebut tidak saling bersinonim satu sama lain. Selain alasan yang disampaikan di atas, beberapa pertanyaan masih menghasilkan jawaban yang tidak sesuai, karena kombinasi kata kunci yang dihasilkan dari suatu pertanyaan sangat banyak dan beragam. Seperti yang sudah dijelaskan pada sub bab III.A, apabila pencarian jawaban tidak ditemukan dengan kata kunci awal, maka sistem akan mencari sinonim kata kunci tersebut dan melakukan pencarian ulang. Sebagai contoh terdapat pertanyaan berikut, â€œ Where will we live when weâ€™re abroad â€. Pertanyaan tersebut menghasilkan kata kunci â€œ liveâ€ dan â€œ abroad â€. Kata â€œ liveâ€ mempunyai 20 sinonim, sedangkan â€œ abroad â€ memiliki 3 sinonim, dan apabila sinonim -sinonim tersebut dikombinasikan, maka akan ada 60 kombinasi kata kunci yang bisa digunakan untuk pencarian ulang jawaban. Hal ini menyebabkan kombinasi jawaban yang didapatkan menjadi beragam dan tidak sesuai dengan yang diingin kan oleh user. Penyebab lainnya sehingga hasil user validation  tidak optimal yaitu ada pertanyaan yang sebenarnya sudah memberikan jawaban yang benar, tetapi tidak sesuai dengan kebutuhan user. Hal ini dapat dilihat pada pertanyaan berikut â€œHow to apply ITDD â€, di mana jawaban dari pertanyaan tersebut adalah â€œhttp://d aftar.ubaya.ac.id. Click on this link for more information â€. Pada kasus tersebut, user menginginkan agar semua informasi-informasi yang terdapat pada link http://daftar.ubaya.ac.id  juga ditampilkan di chatbot , sehingga user tidak perlu lagi untuk melakukan  scanning  dan skimming  pada link tersebut untuk memperoleh informasi yang lengkap.   
D. Cross  Validation  
Cross Validation  adalah metode validasi yang mengambil 
sebagian dataset  untuk dijadikan sebagai data testing . Validasi dilakukan dengan cara membandingkan,  apakah hasil klasifikasi atau prediksi yang dilakukan sistem sudah sesuai 
dengan data asli klasifikasi atau tidak  [16]. Akurasi sistem dapat dihitung dengan cara, jumlah validasi benar dibagi dengan total data testing , kemudian dikalikan dengan 100%.  Pada  penelitian ini, data testing  didapatkan dengan 
mengambil 20% data dari total 30 data pertanyaan dan jawaban 
yang ada di database  sistem. Pengambilan data testing  
dilakukan secara acak, dan kemudian data tersebut dihapus 
dari database  sistem. Setelah itu, pertanyaan -pertanyaan pada data testing  akan ditanyakan kembali pada sistem chatbot . Hasil cross validation  dari sistem chatbot  yang dibangun, dapat dilihat pada Gambar 9 . Akurasi sistem chatbot  yang didapatkan berdasarkan hasil cross validation  adalah 83,33%.   
Gambar 9. Hasil Cross Validation  

IV. KESIMPULAN  
Berdasarkan hasil user validation  dan cross validation  
yang telah dilakukan, maka dapat disimpulkan bahwa metode 
NLPdapat diimplementasikan untuk membangun  chatbot  Program Information Technology , Universitas Surabaya. Akurasi yang didapatkan berdasarkan hasil dua validasi tersebut adalah lebih dari 75%, yang artinya metode NLP cukup baik untuk diterapkan pada penelitian ini. Akan tetapi, chatbot  masih perlu dikembangkan lagi agar akurasi menjadi yang lebih baik. Hal ini dapat dilihat dengan masih ditemukannya beberapa kasus yang membuat hasil validasi kurang tepat, seperti yang sudah dijelaskan pada sub bab sebelumnya.  Untuk pengembangan chatbot  berikutnya, diharapkan pemrosesan sinonim dari kata kunci dapat berjalan lebih baik lagi, sehingga pencarian jawaban juga dapat berlangsung lebih cepat. Selain itu berdasarkan saran dari user, perlu 
ditambahkan menu atau halaman admin khusus agar bisa menambahkan daftar pertanyaan, kata kunci, dan jawaban dengan lebih mudah, terutama untuk pertanyaan yang tidak ditemukan jawabannya, sehingga dataset  yang ada menjadi lebih kaya dan beragam.  Chatbot  juga diharapkan untuk dikembangkan agar dapat menerima pert anyaan dalam bahasa Indonesia.  

REFERENSI  
[1] Hakim, M.A  & Nurhayati , S. (2019 ). Pembangunan 
Aplikasi Chatbot Midwify sebagai Media Pendukung Pembelajaran Ilmu Kebidanan Berbasis Android di  Stikes Bhakti Kencana Bandung . Komputika: Jurnal Sistem Komputer, Vol. 8 (1), pp. 45 -52. 
[2] Wangsanegara, N.K . & Subaeki, B. (2015) . Implementasi Natural Language Processing Dalam Pengukuran Ketepatan Ejaan Yang Disempurnakan (EYD) Pada Abstrak Skripsi Men ggunakan Algoritma Fuzzy Logic . Jurnal Teknik Informatika, Vol. 8 (2), pp. 1-6. 
[3] Suryani, D . & Amalia, E.L. (2017). Aplikasi Chatbot 
Objek W isata Jawa Timur Berbasis AIML . SMARTICS Journal, Vol. 3 (2), pp. 47 -54. 
[4] Benedictus, R.R., Wowor, H.  & Sambul, A. (2017). Rancang Bangun Chatbot Helpdesk untuk Sistem Informasi Terpadu Universitas Sam Ratulangi . E-Journal Teknik Informatika, Vol. 11 (1). 
[5] Dwi, A.R., Imamah, F., Andre, Y. M.S. & Ardiansyah. 
(2018). Aplikasi Chatbot (MILKI BOT) Yang Terintegrasi Dengan Web CMS Unt uk C ustomer Service Pada UKM MINSU . Jurnal Cendikia, Vol. XVI, pp. 100 -106. 
[6] Amalia, E.L . & Wibowo, D.W . (2019). Rancang Bangun 
Chatbot Untuk Meningkatkan Performa Bisnis,  Jurnal Ilmiah Teknologi Informasi Asia, Vol. 13 (2), pp. 137-142. 
[7] Yuniar, E . & Purnomo, H. (2019). Implementasi Chat bot 
â€œALITTAâ€  Asisten Virtual Dari BALITTAS Sebagai Pusat Informasi Di BALITTAS . Jurnal Ilmiah Teknik Informatika, Vol. 12 (1), pp. 24 -35. 
[8] Khanna, A., Pandey, B., Vashishta, K., Kalia, K., 
Pradeepkumar, B., & Das, T. (2015). A Study of Todayâ€™s 
A.I. through Chatbots and Redis covery of Machine Intelligence . International Journal of u - and e - Service, 
Science and Technology, Vol. 8 (7), pp. 277 -284. 
[9] Lisangan, E.A. (2013). Natural Language Processing 
Dalam Memproses Informasi Akademik Mahasiswa Universitas Atma Jaya Makassar . Jurnal TEMATIKA, Vol. 1 (1), pp. 1 -9. 
[10] Redd , M.V . & Hanumanthappa.  (2014) . Semantical and 
Syntactical Analysis of NLP . International Journal of 
Computer Science and Information Technologies, Vol. 5(3), pp. 3236 -3238.  
[11] Siddiqi , S. & Sharan,  A. (2015).  Keyword and 
Keyphrase Extraction T echniques: A Literature Review,  
International Journal of Computer Applications, Vol. 
109(2), pp. 18 -23. 
[12] Qaiser, S. & Ali, R. (2018). Text Mining: Use of TF -IDF to Examine the Relevance of Words to Documents.  International Journal of Computer Applications , Vol. 181(1), pp. 25 -29. 
[13] Christia n, H., Agus, M.P.  & Suhartono, D. (2016). 
Single Document Automatic Text Summarization Using 
Term Frequency -inverse Document Frequency (TF-IDF).  ComTech: Computer, Mathematics and Engineering Applications , Vol. 7(4), pp. 285-294. 
[14] Khan,  N.H.,  Saha,  G.C.,  Sarker , B. & Rahman,  M.H. 
(2014).  Checking the Correctnes s of Bangla Words using N-Gram . International Journal of Computer Applications, Vol. 89 (11). 
[15] Prasetyo,  V.R. (2018).  Searching Cheapest Product On 
Three Different E-Commerce Using K-Means Algorithm . Proceeding of  International Seminar on Intelligent Technology and Its Application (ISITIA) . Bali, Indonesia.  
[16] Prasetyo,  V.R.,  Hartanto , B. & Mulyono , A.A . (2019). Penentuan Pembimbing Tugas Akhir Mahasiswa Jurusan Teknik Informatika Universitas Surabaya Dengan Metode Dice Coefficient . Teknika , Vol. 8 (1), pp. 44 -51. ",Chatbot,Natural Language Processing,hasil wawancara dengan Ketua Jurusan,akurasi
Penerapan Question Answering System Pada Pembahasan Agama Islam Dengan Pendekatan Metode Pattern Based,"Penerapan Question Answering System Pada Pembahasan Agama Islam Dengan Pendekatan Metode Pattern Based

Ramadhana Rosyadi, Said Al -Faraby , Adiwijaya  

Abstrak  
Agama Islam terdapat 25 nabi sebagai pedoman hidup manusia, dokumen yang berisikan informasi mengenai kisah-kisah kehidupan para nabi semasa hidupnya. Penelitian ini bertujuan untuk membangun sistem Tanya jawab yang lebih spesifik dengan menghasilkan jawaban yang relavan tidak dalam bentuk kumpulan dokumen. Question Answering System mampu mengatasi permasalahan dalam sistem Tanya jawa b, sistem pencarian informasi dimana jawaban yang dikeluarkan menjadi tepat dengan tanggapan atas permintaan yang disampaikan, tidak dalam bentuk kumpulan dokumen yang mungkin berisi jawaban. Penelitian ini menggunakan metode Pattern Based sebagai mengekst rak potongan kalimat yang menjadi jawaban untuk menemukan jawaban yang sesuai dengan pola yang telah dibuat. Pemilihan dataset menyebabkan sejumlah pertanyaan yang dapat diajukan menjadi terbatas pada informasi yang tersimpan dalam data itu sendiri. Selain  itu pertanyaan juga dibatasi berupa kata Tanya yang bersifat Factoid, yaitu Siapa, kapan, dimana, apa dan berapa. Hasil Accuracy yang didapatkan dengan menggunakan metode Pattern Based pada Question  Answering System sebesar  39,36%. 

Kata kunci:  Question Answering System, Pattern Based, Accuracy , 25 Nabi.  

Abstract  
Islam has 25 prophets as guidelines for human life, documents containing information about the stories of the lives of the prophets during their lifetime. This study aims to build a more specific question and answer system by generating relevant answers not in the form of documents. Question Answering System is able to overcome problems in the Question and answer system, information retrieval systems where the answers issued are corre ct with responses to requests submitted, not in the form of documents that may contain answers. This study uses the Pattern Based method as extracting sentence pieces which are the answers to find answers that match the patterns that have been made. The se lection of datasets causes a number of questions that can be submitted to be limited to information stored in the data itself. Besides that, questions are also limited in the form of Question words that are Factoid, namely Who, when, where, what and how. A ccuracy results obtained using the Pattern Based method on Question Answering System are 39.36%.  

Keywords:  Question Answering System, Pattern Based, Accuracy, And 25 Prophets  

1. PENDAHULUAN  
Peningkatan pesat dalam penyimpanan pada teknologi informasi dengan menggunakan media web dan sebagainya, yang memungkinkan pada peneliti atau pengguna dapat menyimpan sebuah informasi agar dapat tersedia untuk pengguna umum. Namun, akibat besarnya jumlah data dan informasi yang berdampak dalam pencarian sebuah informasi  yang tepat. Karena kesulitan ini banyak pengembang membuat suatu sistem yang dapat menjawab suatu pertanyaan dalam Bahasa alami dan mengembalikan jawaban yang tepat sesuai dengan pertanyaan yang di sampaikan, bukan lagi berupa kumpulan jawaban yang di ang gap relevan.  Question Answering System  merupakan solusi yang baik dalam menyelesaikan masalah tersebut dengan 
mengajukan sebuah pertanyaan dan mengembalikan respon jawaban yang relevan dengan mengembalikan dalam bentuk daftar dokumen teks singkat atau frase sebagai jawaban tanpa harus disaring  lagi oleh pengguna untuk menentukan dokumen yang mengandung jawaban yang tepat. Question Answering System  merupakan pertanyaan dalam bahasa natural, yaitu bahasa yang digunakan dalam percakapan sehari-hari. 
Pattern Based Approach  merupakan salah satu meto de yang dapat di implementasikan pada Question Answering System  ini. Metode ini memanfaatkan pola kalimat yang telah ditentukan maupun pola jawaban dalam proses menemukan jawaban yang relevan. Metode ini dipilih karena mampu menghasilkan tingkat Accuracy  jawaban yang baik pada Question Answering System  berbahasa Indonesia [6]. Maka dari itu dalam tugas akhir ini akan mengimplementasikan Question Answering System  ini dengan menggunakan Pattern Based sebagai metode yang digunakan dengan pembahasan seputar tentang agama islam yaitu 25 nabi-nabi dengan menggunakan berbahasa Indonesia.  Rumusan masalah dalam penelitian ini adalah  Bagaimana mengimplementasikan Question Answering System  dengan topik pembahasan seputar agama islam yaitu 25 nabi-nabi dengan berbahasa Indonesia, dan bagaimana pengaruh yang didapat dengan struktur dan pengembangan pola kalimat terhadap performansi Question Answering System . Terdapat batasan masalah dalam penelitian ini, yaitu  pertanyaan telah disediakan dan sistem menanyakan pertanyaan seputar agama islam yaitu 25 nabi-nabi dengan berbahasa Indonesia.  Pertanyaan yang dapat diproses hanya pertanyaan yang bersifat Factoid , seperti siapa, dimana, apa, berapa, dan kapan. Dilakukan penghilangan stopwords  pada preprocessing dataset, dan menggunakan bantuan tools  dalam penelitian ini. Tujuan dari pembuatan Question Answering System  pada penelitian ini yaitu mampu mengimplementasikan Question Answering System  dengan pembahasan seputar agama islam yaitu 25 nabi-nabi dengan berbahasa Indones ia, dan melakukan analisis terkait pengaruh yang didapat dengan struktur dan pengembangan pola kalimat terhadap performansi Question Answering System . Pada jurnal ini, terdapat studi terkait yang menjelaskan mengenai metode penelitian sebelumnya yang berkaitan dengan metode penelitian yang diterapkan pada penelitian ini. Pada bagian ketiga, terdapat penjelasan mengenai sistem Question Answering System  yang dibangun dan di implementasikan pada penelitian ini yaitu pada dokumen 25 Nabi pada Agama Islam dalam bahasa Indonesia dengan melewati proses preprocessing dataset , dan penggunaan Metode Pattern Based.  Pada bagian ke empat, terdapat evaluasi hasil skenario pengujian dan analisis hasil pengujian yang telah didapatkan. Pada bagian terkahir, terdapat kesimpul an dan saran dari penelitian yang telah dilakukan . 

2. TEORITIS  
Gunawan dan Gita Lovina (2006) membuat Question Answering System  dan menerapkannya pada alkitab. Kesimpulan yang berhasil diperoleh dari penilitian ini mengenai QA yaitu QA system merupakan bagian dari information retrieval . Sistem ini dapat dipandang sebagai bentuk pengembangan terhadap kemampuan yang dimiliki oleh search engine  dengan mengembalikan respon jawaban terhadap kueri yang berupa pertanyaan natural language . QA system dapat dikembangkan pada domain yang beranekaragam, tergantung dari tujuan pengembangan sistem. Domain yang dimasuk disini erat kaitannya denga n sumber informasi yang akan digunakan untuk menjawab pertanyaan, yang secara langsung akan membatasi jenis pertanyaan sesuai dengan dataset yang dapat dipertanyakan. Teknik yang digunakan dalam mengembangkan sebuah QA system dapat bervariasi mulai dari teknik yang paling sederhana seperti halnya pencocokan pola, sampai dengan teknik â€“ teknik lain yang lebih kompleks, tergantung dari keterbatasan dan kebutuhan sistem. Tahapan proses yang dijalankan oleh sebuah aplikasi QA system tidak akan terlepas dari tiga tahapan proses utama yang menyusun arsitektur umum QA system, yaitu analisis pertanyaan, memilih kandidat dokumen atau segmen dokumen, dan ekstraksi jawaban [1].  Kartina (2010) membuat analisis pertanyaan berBahasa Indonesia pada Question Answering Syste m. Hasil dari penelitian yang telah beliau lakukan adalah pembentukan frase pada tahap analisis pertanyaan dapat meningkatkan relevansi dokumen yang di temu kembalikan, dan semakin tepat Top passage  yang diperoleh, maka semakin tepat jawaban yang dikembali kan oleh sistem QA. Oleh karena itu jika dokumen yang relevan tetapi dalam metode pembobotan passage  belum tepat, maka berakibat pada jawaban yang diperoleh belum tepat [10].  Hapnes Toba dan Mirna Adriani (2009) membuat Question Answering System bahasa Indonesia dengan menggunakan metode Pattern Based . Memperoleh hasil dari uji coba dengan menggunakan pendekatan pola pertanyaan yang hasilnya menunjukan bahwa pada QA sistem sang at menjanjikan jika diimplementasi pada pertanyaan seputar dokumen berbahasa Indonesia, akan tetapi ada kelemahan utama pada pendekatan pola pembelajaran yaitu pola pertanyaan yang diperlukan harus dikembangkan secara spesifik dan fase ekstraksi jawaban yang besar [6].  

3. ANALISA DAN PEMBAHASAN  
Berikut ini merupakan gambaran umum dari proses sistem Question Answering System :   
Gambar 1 . Diagram Alur Sistem  
3.1 Dokumen 25 nabi  
Pada penelitian ini, peneliti menggunakan Dataset  yang berisikan tentang 25 Nabi pada Agama Islam yang menceritakan kisah-kisah nabi. Sumber dataset yang digunakan yaitu dari Wikipedia. Terdapat 25 dokumen dari setiap nabi didalamnya, yang merupakan penjelasan dari kisah teladan nabi, dengan total kalimat sebanyak 34,702. Dataset yang ada akan di proses lebih lanjut untuk kebutuhan penelitian.     
Dokumen Nabi  
Dokumen Nabi  Jumlah Kalimat  
Nabi Adam  2018  
Nabi Idris  509 
Nabi Nuh  1295  
...... ...... 
Total Kalimat  34702  
3.2 Analisi Pertanyaan  
Pertanyaan yang dibuat berdasarkan sumber Wikipedia dengan pembahasan 25 nabi dalam ajaran agama Islam dengan Bahasa Indonesia. Pertanyaan menghasilkan target, konteks dan properti. Pola pertanyaan dan pola jawaban yang saling berkaitan. Target jawaban berdasarkan kata tanya seperti, siapa ( Person ), kapan ( Time ), dimana ( Location ), apa ( Object ) dan berapa ( Count ).  
Tabel 2. Analisis Pertanyaan dan Dokumen Pertanyaan  
Kata Tanya  Pertanyaan  Jawaban  Pola Pertanyaan  Pola Jawaban  dan Target Named Entity Recognition  
Siapa  Siapa nabi pertama ?  nabi pertama adalah nabi 
adam  (Siapa)<C><T>  (PERSON)<C><T>Adalah<P>  
Kapan  kapan Hawa di lahirkan ?  hawa di lahirkan pada 
tahun 3890 SM  (Kapan)<C> <T>Hawa lahir  (TIME)<C><T>Tahun<P>  
Dimana  Dimana Hawa di turunkan ?  Hawa diturunkan di Arabia  (Dimana)<C><T>Diturunkan di bumi  (LOCATION)<C><T>di<P>  
Apa Apa tujuan Nabi Adam di turunkan ?  tujuan nabi adam di 
turunkan adalah sebagai khalifah (pemimpin) di 
muka bumi  (Apa)<C><T>Di Turunkan  (OBJECT)<C><T>Adalah<P>  
Berapa  Berapa tinggi badan Nabi Adam ?  tinggi badan Nabi Adam Adalah 27,432 meter  (Berapa)Tinggi 
Badan<C><T>  (COUNT)<C><T>Adalah<P>  
........  ...........  ...........  ...........  ...........  
3.3 Dokumen Pertanyaan  
Dokumen pertanyaan berisikan kumpulan pertanyaan yang telah di analisis pada tahap sebelumnya, diperoleh 282 pertanyaan bersifat factoid  yaitu pertanyaan yang mempunyai jawaban yang singkat atau terdiri dari beberapa kata. Penjelasan dalam tabel berada pada lampiran.  
3.4 Preprocessing dataset  
Proses preprocessing  yaitu proses pembersihan teks dengan cara membuang kata-kata yang tidak terpakai, dilakukan juga restrukturisasi dengan cara memisahkan tiap kata, menghilangkan imbuhan pada tiap kata yang ada, dan mel akukan proses penghilangan kata yang tidak relevan pada dataset dokumen nabi maupun pertanyaan yang akan menghasilkan data yang bersih dan siap diolah dengan tahapan sebagai berikut.  
Gambar 2 . Preprocessing dataset   
1. Case Folding adalah proses mengubah semua huruf dalam dokumen menjadi huruf kecil, agar sama untuk setiap kata yang ada. Pada penilitian ini menggunakan bantuan fungsi dari str.lower () untuk Case Folding pada bahasa pemrograman Python . 
2. Tokenizing adalah proses pemotongan string  berdasarkan setiap kata yang menyusunnya. pada penelitian ini digunakan bantuan library  yang ada pada bahasa pemrograman Python  yaitu Natural Language Toolkit (NLTK).  
3. Stopword adalah tahap menghilangkan kata -kata yang tidak memberika n informasi penting. Pada penilitian ini menggunakan bantuan kamus list Bahasa Indonesia yaitu Stopword list  dari Tala pada bahasa pemrograman Pyhton . 
4. Stemming  adalah proses untuk memperkecil jumlah indeks yang berbeda dari suatu dokumen, juga untuk 
melakukan pengelompokan kata-kata lain yang memiliki kata dasar dan arti yang serupa namun memiliki bentuk yang berbeda karena mendapatkan imbuhan yang berbeda. Pada penilitian ini menggunakan bantuan library  yang ada pada bahasa pemrograman Python  yaitu Sastrawi stemmer untuk Bahasa Indonesia.  
3.5 Pembobotan Kata  
Setelah didapatkan data bersih melalui proses Preprocessing . Tahap pertama yang dilakukan adalah melakukan pembobotan kata ( Term Weighting ) yaitu jumlah kemunculan kata dalam suatu dokumen. Selanjutnya melakukan 
perhitungan Inverse Document Frequency  (IDF) yaitu bagaimana term didistribusikan secara luas pada koleksi 
dokumen, semakin sedikit jumlah dokumen yang mengandung term, maka nilai IDF semakin besar. Berikut merupakan persamaan untuk menghitung bobot term :  
ð‘‡ð¹ð¼ð·ð¹ (ð‘‘,ð‘¡)=ð‘‡ð¹(ð‘‘,ð‘¡)  .  ð¼ð·ð¹ (ð‘¡)=ð‘‡ð¹(ð‘‘.ð‘¡) .  ð‘™ð‘œð‘” (ð·
ð‘‘ð‘“ð‘—)    (1) 
Keterangan :  
TFIDF(d,t)  : bobot kata(t)  terhadap dokumen(d).  
TF(d,t)  : jumlah kemunculan kata(t)  dalam dokumen(d).  
D   : jumlah semua dokumen dalam koleksi.  
Dfj   : jumlah dokumen yang mengandung kata.  
3.6 Seleksi Kandidat Dokumen  
Tahap selanjutnya adalah proses seleksi kandidat dokumen untuk setiap pertanyaan atau Query  dengan menggunakan metode Vektor Space Model. Vektor Space Model  merupakan suatu model yang digunakan untuk mengukur kemiripan antara suatu dokumen dengan suatu Query . Query  dan dokumen dianggap sebagai Vektor-Vektor  pada n-dimensi, dimana t adalah jumlah dari seluruh term (kata) yang ada dalam leksikon. Menghitung kesamaan antara dokumen dan Query  di ukur  berdasarkan sudut cosinus  dari Vektor  dokumen dan Vektor  Query  (Cosine Measure ) dari nilai pembobotan yang telah diperoleh, berikut ini merupakan persamaan dari Cosine 
Similarity  :  
ð¶ð‘œð‘ ð‘–ð‘›ð‘’ (ð‘‘ð‘—,ð‘ž)=(ð‘‘ð‘—Â·ð‘ž)
||ð‘‘ð‘—||Ã—||ð‘ž||     (2) 
Keterangan :  
q  : jumlah term keyword  
d  : jumlah term dokumen  
|q|  : panjang vektor  dari keyword  
|d|  : panjang vektor  dari dokumen  
Maka diperoleh hasil perhitungan Cosine Similarity  dan dilakukan perankingan berdasarkan nilai Cosine Similarity  tertinggi lalu di ambil 3 nilai tertinggi untuk setiap pertanyaan.  
Tabel 3. Cosine Similarity  
Pertanyaan  Rank  Dokumen  Cosine  
1 1 10 1 
2 1 0,894427191  
3 4 0,894427191  
2 1 25 0,962576835  
2 1 0,872425573  
3 3 0,872425573  
..... ... ... ... 
3.7 Answer Extraction  
Proses selanjutnya yaitu Answer Extraction , proses menemukan kandidat kalimat yang mengandung jawaban. 
Berikut ini adalah tahap -tahapan dalam proses Answer Extraction  :  
Gambar 3 . Answer Extraction  
3.7.1 Sentence Segmentation  
Kandidat jawaban yang masih berupa dokumen dipisahkan menjadi dalam bentuk kumpulan kalimat-kalimat. Pada proses pemisahan kalimat ini digunakan penanda sebagai batas antara satu kalimat dengan kalimat lainnya, yaitu menggunakan titik.  
3.7.2 Number of Keyword  
Proses selanjutnya yaitu menghitung jumlah Number of Keyword  yang ada pada setiap kalimat-kalimat yang telah di pecah dari proses sebelumnya. Keyword merupakan kata kunci atau pertanyaan yang digunakan untuk pencarian dokumen pada proses sebelumnya, contoh  pada pertanyaan 1 dengan menghilangkan kata tanya, â€œsiapa nabi pertama ?â€ menjadi â€œnabi pertamaâ€ yang mempunyai jumlah 2 kata pada keyword , kemudian jumlah keyword  yang ditemukan didalam setiap kalimat dimasukkan ke dalam persamaan sebagai berikut :   
ð‘€ â‰¥[ âˆšð¾âˆ’1 ]+1      (3) 
Keterangan :  
K  : Jumlah Keyword pada pertanyaan.  
M  : Jumlah Keyword yang terdapat pada kalimat kandidat jawaban.  
Kalimat -kalimat kandidat jawaban yang terpenuhi persamaan tersebut, akan menjadi kalimat jawaban dengan skor 
berdasarkan nilai M tersebut. sebaliknya, jika tidak terpenuhi maka akan di eliminasi kalimat yang tidak memenuhi 
persamaan tersebut. Agar skor tidak terlampaui jauh maka perlu di normalisasikan terlebih dahulu pada skor tersebut dengan perhitungan persamaan sebagai berikut :   
ð‘†ð‘˜ð‘œð‘Ÿ =ð‘€
ð¾Ã—10      (4)  
3.7.3 Hit Position 
Pada proses Number of Keyword  didapatkan skor pada masing â€“ masing kandidat kalimat. Pada proses Hit Position kandidat kalimat jawaban tersebut diurutkan berdasarkan skor tertinggi yang telah di  peroleh dari perhitungan 
diatas, diambil 3 nilai tertinggi untuk setiap pertanyaan. Untuk penjelasan dalam bentuk tabel berada pada lampiran.   
Tabel  4. Hit Position  
Pertanyaan ke  Kandidat kalimat  Skor  Siapa nabi 
pertama  Unta Nabi Shaleh dibunuh ............  15 
nabi pertama adalah nabi adam  15 
Nabi Shaleh memberi waktu .........  15 
Siapa anak nabi adam  Dari Ibnu Abi Hatim Abu .............  16,56854  
Perbedaan Nabi dan rasul .............  16,56854  
anak nabi adam adalah Qabil â€¦.... 12,42641  
........  ...........  ..........  
3.7.4 Named Entity Recognition  
Proses selanjutnya Named Entity Recognition menggunakan bantuan tools anago[11] yaitu melakukan pengenalan 
sejumlah entity  dari setiap kandidat kalimat seperti Person, Location, Time, Object dan Count  berdasarkan kata tanya yang ada seperti siapa mencari entity Person  dimana mencari entity Location, kapan mencari entity Time, apa mencari entity Object dan berapa mencari entity Count . Setelah proses Named Entity Recognition  maka didapatkan hasil kandidat kalimat baru, jika terdapat entity yang tidak memenuhi syarat berdasarkan kata tanya, maka tidak akan masuk ke proses selanjutnya.   
Tabel 5 Named Entity Recognition  
Pertanyaan  Ke Kandidat kalimat  Named Entity Recognition  
Siapa nabi pertama  Unta Nabi Shaleh dibunuh 
............  [Unta = Object ], [Nabi Shaleh = Person ] 
nabi pertama adalah nabi adam  [Nabi adam = Person ] [Nabi 
pertama = Person ] 
Nabi Shaleh memberi waktu .........  [Nabi shaleh = Person ] 3.7.5 Pola Jawaban dan Respon Jawaban  
Selanjutnya proses mencocokan pola jawaban berdasarkan kata yang mewakili target dan konteks pada kandidat kalimat. Contoh pertanyaan 1, dengan merubah â€œnabiâ€ menjadi tag target<T> dan â€œpert amaâ€ menjadi context <C>. Sesuai dengan pola jawaban dari pertanyaan yang telah di tentukan :  Contoh implementasi pada pertanyaan 1 :  
1. Kandidat Kalimat 1 = Unta <T> Shaleh dibunuh  
2. Kandidat Kalimat 2 = <T> <C> adalah nabi adam  
3. Kandidat Kalimat 3 = <T> Shaleh memberi waktu  
Setiap kandidat kalimat jawaban dibandingkan dengan pola jawaban yang memiliki tipe properti yang sesuai dengan hasil interpretasi pertanyaan. Dari semua pola jawaban yang didapatkan, kemudian di cari pola yang paling mirip dengan kali mat kandidat jawaban. Untuk dapat menentukan kemiripan dilakukan perbandingan dengan posisi <T>, dan posisi <C>, serta kalimat yang menyertai tag tersebut. Berikut pola jawaban yang mewakili tipe properti PERSON :  
Pattern = PERSON <T><C> adalah <P>  
Pada ka ndidat kalimat 1, 2, dan 3, hanya kalimat 2 yang mewakili target dan konteks dari pertanyaan. Maka kalimat kandidat 2 akan dijadikan kandidat jawaban untuk diproses ditahap selanjutnya. Sehingga di dapatkan kandidat kalimat baru yaitu :  
Kandidat Kalimat 2 = <T> <C> adalah nabi adam  
Dari pencocokan pola jawaban dengan kandidat kalimat didapat hanya kandiat kalimat 2 yang ditemukan 
pola jawaban yang cocok dengan properti PERSON yaitu :  
Pattern  = PERSON <T> <C> adalah <P>  
Pada pola pertanyaan tersebut tag <P> mewakili potongan kalimat yang akan di ekstrak dan akan menghasilkan respon jawaban dari pertanyaan. Sehingga dari kandidat kalimat 2 untuk pertanyaan pertama di dapatkan jawaban dari hasil ekstrak <P> dengan kata setelah â€œadalahâ€ yaitu â€œnabi adamâ€, maka respon jawaban yang diberikan sebagai berikut :  
Respon Jawaban : nabi pertama adalah nabi adam.  
Tabel 6. Pola jawaban  
Properti  Pola pertanyaan  Pola Jawaban  
Person  (Siapa)<T><C>  
(Siapa)anak<T><C>  
(Siapa)makhluk 
sebelum<T><C>  
â€¦â€¦â€¦â€¦...  (PERSON)< T><C> Adalah<P>  
Time  (Kapan)<T><C>di lahirkan  
(Kapan)<T><C>menjadi nabi  
(Kapan)<T><C>menjadi rasul  
â€¦â€¦â€¦â€¦.  (TIME)<T><C>tahun<P>  
Location  (Dimana)<T><C>  
(Dimana)<T><C>di turunkan  
(Dimana)<T><C>bertemu  
â€¦â€¦â€¦â€¦  (LOCATION)<T><C>di<P>  
Object  (Apa)<T><C>  
(Apa) julukan<T><C>  
(Apa)mukjizat<T><C>  
â€¦â€¦â€¦â€¦.  (OJECT)<T><C>Adalah<P>  
Count  (Berapa)usia<T><C>  
(Berapa)jumlah<T><C>  
(Berapa)anak<T><C>  
â€¦â€¦â€¦â€¦.  (COUNT)<T><C>Adalah<P>  
3.8 Metode Evaluasi  
Tahap terakhir yaitu mengevaluasi hasil Question Answering System yang telah di bangun pada penelitian ini dengan perhitungan Accuracy . Accuracy  dipilih sebagai perhitungan evaluasi untuk mengukur performasi dari Question Answering System  dengan pertanyaan sebanyak 282, semakin tinggi Accuracy , maka performansi dalam penggunaan metode Pattern Based  semakin baik dalam kasus Question Answering System . Berikut merupakan perhitungan Accuracy  :  
ð‘¨ð’„ð’„ð’–ð’“ð’‚ð’„ð’š = ð’‹ð’–ð’Žð’ð’‚ð’‰  ð’‘ð’†ð’“ð’•ð’‚ð’ð’šð’‚ð’‚ð’  ð’šð’‚ð’ð’ˆ  ð’ƒð’†ð’ð’‚ð’“
ð’‹ð’–ð’Žð’ð’‚ð’‰  ð’‘ð’†ð’“ð’•ð’‚ð’ð’šð’‚ð’‚ð’Ã—ðŸðŸŽðŸŽ  %    (6) 

4.   IMPLEMENTASI  
Performansi dari sebuah Question Answering System dengan menggunakan metode evaluasi dengan menggunakan perhitungan Accuracy  dari keberhasilan sistem yang mampu mengembalikan jawaban yang sesuai dengan jawaban yang telah disediakan sebelumnya. Pada penelitian ini telah disediakan pertanyaan berikut jawaban, pertanyaan terdiri dari kata tanya siapa berjumlah 84, kapan berjumlah 59, dimana berjumlah 51, apa berjumlah 50, dan berapa berjumlah 38 pertanyaan, dengan total 282 pertanyaan.  Hasil pengujian penelitian ini berupa evaluasi dari jawaban yang sesuai, dengan menggunakan metode Accuracy  sebagai evaluasi dari keberhasilan si stem mengembalikan jawaban yang benar.   
Berikut ini ada beberapa skenario yang dibuat dalam penelitian ini :  
1. Skenario pengujian pengaruh penggunaan proses  Stemming , Number of Keyword dan Named Entity Recognition  pada Question Answering System. Pada skenario pengujian pengaruh dengan penggunaan proses Stemming , Named Entity Recognition dan Number of Keyword pada Question Answering System . Stemming merupakan proses mengubah kata berimbuhan menjadi kata dasar. Named Entity Recognition  merupakan komponen utama  dari information extraction yang bertujuan untuk mendeteksi dan mengklasifikasikan Named Entity  pada suatu teks[11], dengan mendeteksi PERSON, LOCATION, TIME, OBJECT, dan COUNT dari kata pada setiap kalimat. Number of Keyword  untuk menghitung jumlah kata  yang sama dari pertanyaan terhadap dokumen jawaban. Pada penelitian ini bertujuan untuk mengetahui peran penting dalam penggunaan Stemming , Named Entity Recognition dan Number of Keyword pada Question Answering System . Diperoleh hasil dari skenario pengujian ini dengan nilai Accuracy  sebesar 17,73 %.  
Tabel 7. skenario 1  
kata tanya  jawaban  Benar  Salah  
Siapa  7 77 
Kapan  12 47 
Dimana  7 44 
Apa 10 40 
Berapa  14 24 
Total  50 232 
total pertanyaan  282 
Accuracy  17,73049645   
Berdasarkan tabel 7 hasil penelitian dengan menggunakan Stemming  berpengaruh pada hasil Accuracy  dengan menghilangkan kata imbuhan menjadi kata dasar. Pengaruh Penggunaan Number of keyword pada penelitian ini menghitung jumlah kata yang sama dari pertanyaan terhadap dokumen jawaban. Pengaruh penggunaan Named Entity Recognition  dapat mendeteksi lebih baik pada pola pertanyaan dengan membandingkan kata tanya terhadap target pola jawaban.  
2. Skenario pengujian pengaruh penggunaan proses  Number of Keyword  dan Named  Entity Recognition  pada Question Answering System dengan menghilangkan proses Stemming . Pada skenario pengujian pengaruh penggunaan proses Number of Keyword  dan Named  Entity Recognition  pada Question Answering System  dengan menghilangkan proses Stemming . Berikut ini merupakan hasil dari penelitian dari skenario ke 2 :  
Tabel 8. skenario 2  
kata tanya  Jawaban  
Benar  Salah  
siapa  4 80 
kapan  7 52 
dimana  7 44 
Apa 11 39 
berapa  12 26 
total 41 241 
total pertanyaan  282 
Accuracy  14,53900709  
Berdasarkan penggujian ini diperoleh hasil Accuracy  dengan menghilangkan proses Stemming  sebesar 14,53%. Dapat disimpulkan, bahwa dengan menghilangkan proses Stemming  dapat mengurangi hasil Accuracy , dikarenakan pada proses Stemming  berfungsi untuk mengurangi dimensi kata dengan menghilangkan kata imbuhan menjadi kata yang bermakna sama atau kata dasar.  
3. Skenario pengujian pengaruh penggunaan proses  Stemming  dan Number of Keyword pada Question Answering System  dengan menghilangkan proses Named Entity Recognition.  Pada skenario pengujian pengaruh penggunaan proses  Stemming  dan Number of Keyword pada Question Answering System dengan menghilangkan proses Named Entity Recognition . Berikut ini merupakan hasil dari penelitian dari skenario ke 3 : 
Tabel 8. skenario 3  
kata tanya  Jawaban  
Benar  Salah  
siapa  7 77 
kapan  12 47 
dimana  6 45 
apa 8 42 
berapa  8 30 
total 41 241 
total 
pertanyaan  282 
Accuracy  14,53900709  
Berdasarkan pengujian ini diperoleh hasil dengan menghilangkan proses Named Entity Recognition  sebesar 14,53%. Dapat disimpulkan, bahwa dengan menghilangkan proses Named Entity Recognition dapat mengurangi hasil Accuracy , dikarenakan saat proses pencocokan  berdasarkan kata tanya dengan target jawaban yang mengakibatkan terjadi kesalahan dalam mengambil jawaban.  
4. Skenario pengujian pengaruh penggunaan proses  Stemming  dan Named Entity Recognition pada Question 
Answering System  dengan menghilangkan proses Numbe r of Keyword.  Pada skenario pengujian dengan pengaruh penggunaan proses Stemming  dan Named Entity Recognition pada Question Answering System  dengan menghilangkan proses Number of Keyword . Berikut ini merupakan hasil dari penelitian dari skenario ke 4 :  
Tabel 9. skenario 4  
kata tanya  jawaban  
Benar  salah  
siapa  30 54 
kapan  22 37 
dimana  20 31 
apa 23 27 
berapa  16 22 
total 111 171 
total pertanyaan  282 
Accuracy  39,36170213  
Berdasarkan pengujian ini diperoleh hasil dengan menghilangkan proses Number of Keyword  sebesar 39,36%. 
Dapat disimpulkan, bahwa dengan menghilangkan proses Number of Keyword  dapat meningkatkan hasil Accuracy , dikarenakan saat proses Number of Keyword  kata nabi lebih dominan pada setiap kalimatnya yang berakibat terjadi kesalahan dalam mengambil pada kandidat kalimat jawaban.  
4.1 Analisis Hasil Pengujian  
Dari hasil analisis pengujian yang telah dilakukan dengan 282 pertanyaan dengan berbagai kata tanya, didapat jawaban benar sebanyak 111 dan jawaban yang tidak sesuai sebanyak 171 pertanyaan. Diperoleh hasil Accuracy  terbaik dengan nilai 39,36% dengan mengh ilangkan proses Number of Keyword . Berikut ini yang menyebabkan tidak ditemukannya dokumen relevan atau kalimat yang relevan dengan pertanyaan sehingga pertanyaan dianggap tidak berhubungan dengan dokumen dan sistem juga tidak menghasilkan jawaban karena b eberapa faktor yang menyebabkan tidak ada dokumen yang dapat diproses untuk mendapatkan jawaban.  Sistem mengeluarkan jawaban yang salah dikarena kan dalam proses Number of Keyword  yaitu menentukan kandidat kalimat yang sesuai dengan pertanyaan dari setiap  dokumen yang telah menjadi kandidat dokumen yang didapatkan, dikarenakan Query yang dikeluarkan pada saat pencarian kandidat kalimat lebih 
banyak sehingga kalimat yang diambil meskipun kalimat tersebut tidak mengandung jawaban, seperti pada kata nabi yang  menjadi konteks, selalu ada di setiap dokumen dan berkali kali muncul, sedangkan targetnya seharusnya tertutupi oleh kata nabi, yang dapat menimbulkan salah dalam mengambil kandidat kalimat, hal ini bisa di atasi dengan menghilangkan proses Number of Keyword dengan menghitung jumlah kata yang sama hanya terhitung satu.  Pada saat proses Named Entity Recognition  ada beberapa kata yang salah dalam tag kata yang tidak sesuai, seperti kata Object  menjadi Person,  hal itu dapat mempengaruhi dalam proses pola eks traksi jawaban. Hal ini bisa diatasi jika dikembangkan lagi dalam proses Learning  dalam model Named Entity Recognition . Permasalahan dengan pola jawaban, karena tidak ditemukannya pola jawaban yang mirip dengan susunan kalimat kandidat jawaban, untuk mengu rangi permasalahan ini dapat dilakukan dengan pegembangan dalam menemukan pola jawaban yang baik . 

5.   KESIMPULAN  
Setelah dilakukan analisis Question Answering System dengan metode Pattern Based pada dokumen 25 Nabi dalam Agama Islam maka dapat disimpulkan bahwa peran pola jawaban sangat penting dalam ekstraksi jawaban. Sistem akan lebih mudah mengenali pola jika pola lebih spesifik dan lebih unik. Peran memberi tag pada kata mempengaruhi dalam me nemukan target jawaban yang sesuai dengan kalimat tanya. Sistem akan lebih mudah jika tag yang di berikan lebih akurat. Proses Number of Keyword terdapat masalah jika Query  atau kata selalu muncul dalam semua dokumen, yang dapat mengakibatkan kesalahan dalam melakukan pengambilan kandidat kalimat yang relevan.  Saran untuk penelitian selanjutnya, dalam pencarian dokumen yang membahas nabi lebih diperluas. Untuk di kembangkan lagi dalam proses analisa tentang Natural Language Processing (NLP) terkait Named Entity Recognition  dan memperbanyak dalam pembuatan pola jawaban yang lebih spesifik dan lebih unik . 

REFERENCES 
[1] Gunawan dan Gita Lovina â€œ QUESTION ANSWERING SYSTEM  DAN PENERAPANNYA PADA ALKITABâ€.  
[2] Hirschman, L, dan Gaizauskas, R, Natural language question asnwring: the view from here . 2001. Cambrige University Press, United Kingdom.  
[3] Bintang Kristina Situmorang â€œAnalisis Question Answering System  pada dokumen Bahasa Indonesia Menggunakan Pattern Based  Approachâ€.  
[4]  H. T. a. M. Adriani, """"Pattern Based Approach in Indonesian Question Answering System """" 2010.   
[5] Abdelghani BOUZIANE, Djelloul BOUCHIHA, Noureddine DOUMI and Mimoun MALKI â€œ Question Answering Systems: Survey and 
Trends â€. 
[6] Hapnes Toba and Mirna Adriani â€œ Pattern Based Indonesian Question Answering System â€. 
[7] Junichi Fukumoto, Noriaki Aburai,  dan Ryosuke Yamanishi â€œ Interactive Document Expansion for Answer Extraction of Question Answering System â€. 
[8] Amit Mishra,  dan Sanjay Kumar Jain â€ A survey on Question Answering Systems with classification â€. 
[9] Sanjay K Dwivedi,  dan Vaishali Singh â€œ Research and reviews in Question Answering System â€. 
[10] Kartina â€œAnalisis Pertanyaan Berbahasa Indonesia Pada Question Answering System â€. 
[11] Wibisono, Yudi. NE R (Named Entity Recognition) dengan anaGo (Python Keras)https://yudiwbs.wordpress.com/2018/03/29/ner -named -entity -recognition -dengan -anago -python -keras/ . Diakses pada 16 juli 2018  """,Question Answering System,Pattern Based,"wikipedia, kisah-kisah nabi",accuracy
Penerapan Metode Cosine Similarity Dalam Aplikasi Chatbot Layanan Wisata Di Wilayah Malang,"Penerapan Metode Cosine Similarity Dalam Aplikasi Chatbot Layanan Wisata Di Wilayah Malang

Ridwan Rismanto 1, Yoppy Yunhasnawa 2, Ragata Anggada Bhakti 3 

Abstrak
Chatbot adalah salah satu aplikasi yang dirancang untuk berkomunikasi dengan mesin. Komunikasi ini membantu user dalam mencari sebuah informasi. Informasi yang diberikan  
bermacam-macam, seperti media informasi mengenai Layanan 
Publik Wisata di Wilayah Malang. Natural Language Processing 
(NLP) merupakan salah satu cabang ilmu Artificial Intelligence (AI) yang berfokus pada pengolahan bahasa natural . Bahasa natural adalah Bahasa yang secara umum digunakan oleh manusia dalam berkomunikasi satu sama lain. Dengan teknologi kecerdasan buatan saat ini , bahasa natural dapat diolah menjadi dengan berbagai macam bentuk, seperti chatbot dengan metode, salah satunya menggunakan Tf-Idf dan Cosine Similarity. Cosine Similarity meru pakan sebuah metode untuk system Question-Answering dengan menghitung bobot masing-masing kata dalam suatu pertanyaan yang nantinya akan dicocokkan dengan dataset. Penggunaan metode tersebut akan dite rapkan kedalam sistem chatbot yang dip eruntukkan sebagai media informasi mengenai Layanan Publik Wisata di Wilayah Malang, sebagai pengganti customer service, selain itu merubah penyampaian informasi agar mudah dipahami. Berdasarkan pengujian yang telah dilakukan dari beberapa data uji dengan memperoleh hasil waktu eksekusi lebih cepat serta mempunyai hasil recall maksimal yaitu 100% dan nilai precision paling kecil diantara hasil pengujian yaitu 0,0 1% 
Kata kunci chatbot, cosine similarity, layanan publik wisata 
wilatah malang 

I.  PENDAHULUAN 
Perkembangan dunia sistem informasi pada saat ini sudah sedemikian pesat dan merambah ke berbagai sisi kehidupan manusia. Manusia mampu membuat mesin-mesin yang memiliki kecerdasan sehingga dapat bekerja dengan sendirinya. Hal 
tersebut mulai dapat terwujud setelah diciptakannya sebuah mesin canggih yang bernama komputer. Efisiensi waktu serta penyampaian sangat mendukung akan berkembangnya sebuah platform informasi. Penyampaian informasi yang didukung oleh perkembangan teknologi terbaru akan memudahkan masyarakat pengguna dalam mendapatkan informasi yang dibutuhkan. Semakin dimudahkannya sebuah media informasi maka akan semakin berkembangnya daerah tersebut. Layanan publik merupakan suatu media yang disediakan oleh pemerintah untuk dapat memberikan informasi terkini kepada masyarakat. Dengan adanya layanan publik diharapkan masyarakat dapat memanfaatkan layanan tersebut. Layanan tersebut terdiri dari pelayanan barang dan jasa, pelayanan barang yaitu pelayanan yang menghasilkan berbagai bentuk atau jenis barang yang digunakan oleh publik, misalnya jaringan telepon, penyediaan tenaga listrik, air bersih, dan sebagainya. Salah satu website yang dapat digunakan untuk mencari informasi mengenai layanan wisata di wilayah malang yaitu melalui website www.malangkota.go.id, www.malangkab.go.id. Website tersebut merupakan website resmi dari pemerintah. Pengunjung website memperoleh informasi mengenai layanan wisata dengan cara mengakses website, dan dapat melihat informasi pada halaman website. Informasi tersebut dirasa belum cukup dalam mencari data karena tidak terdapat pencarian pada menu layanan wisata sehingga pengunjung harus melihat data satu per satu.  Penerapan aplikasi tersebut adalah untuk membantu dan mempermudah  user dalam tanya jawab menggantikan  Customer service dan dapat melayani pengunjung yang ingin bertanya mengenai layanan wisata. Oleh karena itu untuk mengatasi masalah tersebut dibuatkan sebuah sistem aplikasi yang digunakan sebagai pengganti customer service berupa  sistem aplikasi chatbot . Chabot  sendiri adalah sebuah program komputer yang dirancang untuk mensimulasikan sebuah percakapan atau komunikasi yang interaktif kepada user atau pengguna melalui bentuk teks, suara, dan visual. Nantinya  sistem aplikasi tersebut digunakan untuk membantu wisatawan, karena dapat melakukan tanya jawab untuk memberikan informasi terkait layanan wisata di wilayah malang .  Layanan wisata merupakan suatu industri yang memiliki pengaturan yang cukup kompleks, karena mencakup pengaturan perjalanan wisatawan dari tempat asalnya menuju tempat wisata yang diinginkannya, hingga kembali lagi ke tempat asalnya. Dalam proses tersebut, terdapat berbagai bidang jasa pariwisata yang terlibat, seperti misalnya penginapan, restoran, transportasi, bahkan pemandu wisata, apabila diperlukan. Biro perjalanan wisata sebagai salah satu bentuk usaha perjalanan wisata di Indonesia, merupakan penghubung antara wisatawan dengan penyedia jasa pariwisata lainnya. Dalam peraturan pemerintah nomor 67 tahun 1996, dijelaskan secara khusus tentang pengertian usaha pariwisata yaitu kegiatan yang bertujuan menyelenggarakan jasa pariwisata, menyediakan atau mengusahakan objek dan daya tarik pariwisata, usaha sarana pariwisata dan usaha lain yang terkait dengan bidang-bidang tersebut, yang terdiri dari Biro Perjalanan Wisata. Namun dalam peraturan ini tidak dijelaskan mengenai definisi dari masing-masing usaha 
perjalanan jasa tersebut. Menurut Spillane. JJ, dalam bukunya yang berjudul â€œFirst Class an Introduction to Travel & Tourism â€œ menyatakan bahwa, Biro Perjalanan Wisata adalah sebuah perusahaan perjalanan yang menjual sebuah rancangan perjalanan dan menjual pro duk-produk wisata lain yang berhubungan dengan perjalanan tersebut secara langsung kepada masyarakat. Produk wisata yang terdapat dalam paket tersebut umumnya berupa jasa akomodasi dan transportasi [2] .  Program chatbot pertama kali ditulis oleh Joseph Weizenbaum, professor MIT pada tahun 1996. Pada waktu itu tentu saja chatbot dibuat masih sangat sederhana. Meskipun perkembangan kecerdasan buatan saat ini sangat pesat dan canggih, namun chatbot tetap mempertahankan kedudukannya dalam dunia Artifial Intelligence. Chatbot adalah salah satu sistem cerdas yang dihasilkan dari pemrosesan Bahasa Alami atau Natural Language Processing  (NLP) yang merupakan salah satu cabang dari Kecerdasan Buatan atau Artificial Intelligence  (AI). NLP mempelajari komunikasi antara manusia dengan komputer melalui bahasa alami [3]. Chatbot memungkinkan manusia dapat berkomunikasi dengan mesin menggunakan perantaraan bahasa alami. Bentuk komunikasi yang terjadi adalah melalui percakapan menggunakan media tulisan.  Percakapan dengan chatbot dapat berupa obrolan biasa atau obrolan pada tema-tema tertentu yang melibatkan disiplin ilmu yang lain. Percakapan yang terjadi antara komputer dengan manusia merupakan bentuk respon dari program yang telah di deklarasikan pada database program pada komputer. Kemapuan komputer dalam menyimpan banyaknya data tanpa melupakan satu pun informasi yang disimpannya digabungkan dengan kepraktisan bertanya pada sumber informasi langsung dibandingkan dengan mencari informasi sendiri serta kemampuan learning yang dimilikinya menyebabkan chatbot adalah customer service yang handal [2]. 

II. TINJAUAN  PUSTAKA 
A. Kecerdasan Buatan 
Kecerdasan buatan ( artificial intelligence ) merupakan salah satu bagian ilmu komputer yang membuat mesin komputer dapat melakukan pekerjaan seperti dan sebaik yang dilakukan manusia. Pada awal diciptakannya, komputer hanya difungsikan sebagai alat hitung saja. Namun seiring denga  perkembangan waktu, peran komputer semakin mendominasi kehidupan umat manusia. Komputer tidak lagi hanya digunakan sebagai alat hitung, lebih dari itu komputer diharapkan untuk dapat memberdayakan untuk mengerjakan segala sesuatu yang bisa dikerjakan oleh manusia. 
B. Natural Language Processing 
Natural Language Processing  adalah pembuatan program yang memiliki kemampuan untuk memahami bahasa manusia. Pada prinsipnya bahasa alami adalah suatu bentuk representasi dari suatu pesan yang ingin dikomunikasikan antar manusia. NLP adalah upaya untuk mengekstrak lebih jauh representasi dari suatu teks bebas. Hal ini dapat dimasukkan secara kasar seperti mencari siapa melakukan apa kepada siapa, kapan, di mana, bagaimana dan mengapa. NLP biasanya membuat penggunaan konsep-konsep linguistic  seperti kata benda, kata kerja, kata sifat, dan lainnya dan struktur gramatikal (baik direpresentasikan sebagai ungkapan-ungkapan seperti frase nomina atau frase preposisional, atau hubungan ketergantungan seperti subjek dari- atau objek-dari. 
C. Chatbot Line 
Chatbot  Line adalah aplikasi Chatbot  yang di implementasikan ke dalam aplikasi line messenger. Chatbot  
sendiri merupakan merupakan sistem cerdas  yang dihasilkan 
dari pemrosesan Bahasa Alami atau Natural Language Processing. Terdapat dua pilihan untuk menerapkannya yaitu 
dengan Chatbot  yang berdiri sendiri mengunkan aplikasi atau 
Chatbot  yang harus ditambahkan terlebih dahulu ke dalam  grup chat di aplikasi line[6]. 
D. Messaging API 
Messaging API memungkinkan untuk mengembangkan komunikasi dua arah antara layanan dan pengguna Aplikasi line messenger. Messaging API digunakan untuk membuat bot yang memberikan kemudahan pengguna dalam mengakses beberapa informasi maupun program yang lebih interaktif dengan banyak ragam cara menampilkannya seperti dalam bentuk video, gamabr, teks, gift, emoticon, dan lain sebagainya . Messaging API memungkingkan data dilewatkan antara server aplikasi bot dan Platfom Line. Ketika seseorang pengguna mengirimkan bot pesan, webhook dan Line Platform mengirimkan permintaan ke URL webhook. Server kemudian mengirimkan permintaan ke Platform Line untuk menanggapi pengguna. Permintaan dikirim melalui HTTPS dalam format JSON, Berikut alur sistem Messaging Api Line pada sebuah sistem bot [6] 
E. Term Frequency-Inverse Document Frequency (Tf-Idf) 
Metode Term Frequency-Inverse Document Frequency  (TF-IDF) adalah cara pemberian bobot hubungan suatu kata (term) terhadap dokumen. Dalam skema arsitektur temu balik informasi, terdapat sebuah proses yang berkaitan dengan pembobotan kata atau term baik secara lokal maupun global. Pembobotan lokal hanya berpedoman pada frekuensi munculnya term dalam suatu dokumen dan tidak melihat frekuensi kemunculan term tersebut di dalam dokume n lainnya. Pendekatan dalam pembobotan lokal yang paling banyak diterapkan adalah term frequency (tf) meskipun terdapat skema lain seperti pembobotan biner, augmented normalized tf, logaritmik tf dan logaritmik alternative [11].  
Nilai Tf-Idf dapat dihitung dengan persamaan berikut : 
1. Perhitungan Term Frequency (tf) menggunakan persamaan. (2.1) 
(2.1) 
Tf adalah term frequency, dan adalah banyaknya kemunculan term dalam dokumen, Term Frequency (tf) dihitung dengan menghitung banyaknya kemunculan term dalam dokumen 
2. Perhitungan Inverse Document Frequency (idf), menggunakan persamaan.  (2.2) 
Dengan 
adalah inverse document frequency, N adalah jumlah dokumen yang terambil oleh sistem, dan adalah banyaknya dokumen dalam koleksi dimana term muncul di dalamnya.   
3. Perhitungan term frequency inverse document frequency (Tf-Idf), menggunakan persamaan. (2.3). 
(2.3) 
Dengan 
adalah bobot dokumen, N adalah jumlah dokumen yang terambil oleh sistem, adalah banyaknya kemunculan term pada dokumen dan 
adalah 
banyaknya dokumen dalam koleksi dimana term muncul di dalamnya. Bobot dokumen dihitung untuk didapatkannya suatu bobot hasil perkalian atau kombinasi antara term frequency dan inverse document frequency 
Perhitungan bobot TF.IDF dilakukan dengan melakukan perkalian antara persamaan 1 dengan 2 sehingga menghasilkan persamaan 3 
Keterangan :  
: pembobotan kata atau term i pada dokumen j 
: banyak kata atau term i pada dokumen j 
D: total dokumen dalam dataset   
ti: total dokumen yang memunculkan term i 
F. Cosine Similarity 
Cosine Similarity  adalah suatu tipe teknik Vector Space 
Model  yang digunakan untuk mengukur kemiripan antara suatu dokumen dengan suatu query. Pada model ini query  dan dokumen dianggap sebagai vektor-vektor  pada ruang n-dimensi, yang dimana n adalah jumlah dari seluruh term yang ada dalam leksikon. Leksikon adalah daftar semua term yang ada dalam indeks. Salah satu cara untuk mengatasi hal tersebut dalam model vector space  adalah dengan cara melakukan perluasan vektor. Proses perluasan dapat dilakukan pada vektor query , vektor dokumen, atau pada kedua vektor  tersebut [11]. Dokumen dapat digambarkan sebagai bentuk vektor sebagai:    
Keterangan :   
   : vektor q   
   : vektor d 
wqk  : bobot term q dalam blok Wqk 
wdk  : bobot term d dalam blok Wdk 
k  : jumlah term dalam kalimat 
t   : jumlah vektor  
  
III. IMPLEMENTASI  DAN  PENGUJIAN 
A. Desain Arsitektur Sistem 
Gambar 1. Desain Arsitektur Sistem  
Gambar diatas merupakan perancangan desain arsitektur 
Penerapan Metode Cosine Similarity  Dalam Aplikasi Chatbot 
Layanan Wisata Di Wilayah Malang sebagai gambaran alur data-data dapat disimpan, diproses dan ditampilkan kembali ke pengguna. (2.7) 
(2.4) B. Usecase Diagram 
Gambar 2 . merupakan usecase  tersebut dijelaskan definisi 
aktor dan definisi usecase  yang terdapat pada usecase 
Penerapan Metode Cosine Similarity Dalam Aplikasi Chatbot 
Layanan Wisata Di Wilayah Malang sebagai berikut:  
Tabel 1. Definisi Aktor 
No Aktor Kebutuhan Fungsional 
1. Admin Admin adalah pihak yang melakukan manajemen user dan pengelolaan data pada aplikasi chatbot 
2. User  User  adalah pegawai yang berperan sebagai pihak yang melakukan input pertanyaan pada aplikasi chatbot.  
No Usecase Kebutuhan Fungsional 
1. Beranda Merupakan proses penggunaan sistem untuk menuju halaman beranda admin atau user 
2. Data Sistem Merupakan proses penggunaan sistem untuk mengakses data wisata 
3. Data Wisata Merupakan proses penggunaan sistem untuk mengakses dan mengelola data wisata 
4. Simulasi Chat Merupakan proses penggunaan sistem untuk simulasi data riwayat chat masuk  yang telah dimasukkan user 
5. Data Chat Merupakan proses penggunaan sistem untuk data chat masuk yang diinputkan user masuk ke dalam sistem 
6. Login Merupakan proses penggunaan sistem untuk masuk ke dalam sistem.  
Nama Usecase  Beranda 
Aktor 1. Admin 
Tujuan Menampilkan halaman utama dari sistem 
Pre-Condition Aktor berhasil melakukan login 
Skenario Aktor melihat halaman utama  
TABEL 2. DESKRIPSI USECASE DATA WISATA  
Nama Usecase Data Wisata 
Aktor Admin 
Tujuan Mengelola data wisata 
Pre-Condition Admin melakukan login  
Skenario 1. Admin melihat data wisata 
2. Admin menambah data wisata 
Invariant 1 Admin mengedit data wisata 
Invariant 2 Admin menghapus data wisata 
TABEL 3. DESKRIPSI USECASE LOGS  
Nama Usecase  Logs 
Aktor Admin 
Tujuan Mengelola data logs 
Pre-Condition Admin melakukan login  
Skenario 1. Admin melihat data logs 
2. Admin menghapus data logs 
Invariant 1 Admin menghapus data suplier 
TABEL 4.DESKRIPSI USECASE CHAT 
Nama Usecase  Chat 
Aktor User 
Tujuan Memasukkan Pertanyaan 
Pre-Condition User melakukan inputchat 
Skenario 1. Admin melihat data masuk chat   
Invariant 2 Admin meghapus data pengguna  
C. Desain Sistem dan Aplikasi  
Pada tahap ini perancangan sistem dilakukan dengan membentuk arsitektur sistem secara keseluruhan. Perancangan sistem digambarkan dengan membuat desain alur sistem. Konsep alur sistem dapat dilihat pada alur proses gambar 3.2 Konsep alur sistem terdiri dari beberapa bagian yaitu pengolahan data masuk dari user dengan proses menggunakan TF-IDF, kemudian pemrosesan berlanjut dengan pembobotan menggunakan TF-IDF dan Cosine Similarity. Berikut penjelasan alur proses gambar 2.  
GAMBAR 3. ALUR PROSES SISTEM CHATBOT  
1.  User memasukkan pertanyaan kepada sistem chatbot 
2. Proses pengolahan data dengan menggunakan metode Tf-Idf, Cosine Similarity. Data masukan dari user yang dimana sistem akan membaca semua masukan dari user adalah sebuah pertanyaan. Pertanyaan yang masuk akan di proses dimana pengambilan query yang sama di database sistem dengan query pertanyaan, kemudian dikumpulkan untuk ke proses selanjutnya yaitu Pre-Processing. Pengolahan data selanjutnya sesuai urutan yaitu menggunakan Tf-Idf, Cosine Similarity sebagai pembobotan. 
3. Hasil keluaran respon dari Chatbot  tersebut di dapat dari proses  pengolahan data dengan menggunakan metode Tf-Idf dan Cosine Similarity. 
4. Dari hasil tersebut proses selanjutnya masuk kedalam 
sistem chatbot. 
5. Dari sistem Chatbot maka hasil dari pengolahan kata akan 
di simpan pada database sistem aplikasi Chatbot. 
6. Pada bagian ini sistem Chatbot memberi respon pada user 
berupa jawaban atas pertanyakan yang diisikan user. 
7. Dibagian ini admin dapat login pada sistem chatbot 
D. Data Flow Diagram (DFD) 
Data Flow Diagram merupakan representasi grafik dari sebuah sistem yang merupakan alat perancangan sistem yang berorientasi pada alur data. Data Flow Diagram dapat digunakan sebagai alat pembuatan model yang memungkinkan profesioanal sistem untuk menggambarkan sistem sebagai suatu jaringan proses fungsional yang dihubungkan satu sama lain dengan alur data baik secara manual maupun komputerisasi. Berikut penjelasan alur DFD sistem aplikasi chatbot:  
GAMBAR 4. ALUR DFD  PROSES SISTEM CHATBOT  
Diagram diatas menggambarkan dari admin dapat melakukan menambahkan data (mencakup semua data dalam konteks manual yang dibutuhkan oleh sistem), pengolahan data menggunakan metode (dalam sistem aplikasi ini menggunakan  metode pendukung yaitu Tf-Idf, Cosine Similarity), verifikasi data masuk terdapat pada menu tambahan pada UI Chatbot yang di gunakan sebagai informasi masukkan dari user), mengolah hasil pre-processing (pengolahan berurutan dimulai dari query user -> pengambilan query dataset yang mirip dengan query user -> tokenizing seluruh query -> stopword), menambah data admin, dan login. Sedangkan user dapat Input pertanyaan maupun input informasi yang terbaru. 
E. Implementasi Sistem 
GAMBAR 5. TAMPILAN AKUN PROVIDER ( WISATA BOT ) 
Halaman ini berisi nama bot yang telah di buat di line 
developer â€œ Wisata Botâ€ dan pengatu ran default yang di 
sediakan oleh line developer. 
GAMBAR 6. TAMPILAN MENU DI PROVIDER LINE DEVELOPER  
token tf 
kk d1 d2 d3 d4 d5 
dimana 1 1 0 0 0 0 
lokasi 1 1 1 0 0 0 
pantai 1 1 1 1 1 1 
gatra 0 1 0 1 0 0 
pantai 1 1 1 1 1 1 
tamban 1 0 1 0 0 1 
fasilitas 0 0 0 1 0 0 
pantai 1 1 1 1 1 1 
gatra 0 1 0 1 0 0 
jam 0 0 0 0 1 0 
buka 0 0 0 0 1 0 
tutup 0 0 0 0 1 0 
pantai 1 1 1 1 1 1  
GAMBAR 7. HALAMAN LOGIN  
Gambar 8. Halaman Awal Web  
Gambar 9. Halaman Data Sistem  
Gambar 10. Tampilan Chatbot di Aplikasi LINE.  
F. Pengujian menggunakan metode Tf-Idf dan Cosine Similarity 
No Dokumen 
D1 Dimana lokasi pantai gatra   
D2 Objek Kebun The Wonosari  
D3 Jam Buka Tutup Candi Telih sampai pukul  
D4 Fasilitas Coban Rondo meliputi 
D5 Lokasi pantai Tamban 
token tf 
kk d1 d2 d3 d4 d5 
dimana 1 1 0 0 0 0 
lokasi 1 1 1 0 0 0 
pantai 1 1 1 1 1 1 
gatra 0 1 0 1 0 0 
pantai 1 1 1 1 1 1 
tamban 1 0 1 0 0 1 
fasilitas 0 0 0 1 0 0 
pantai 1 1 1 1 1 1 
gatra 0 1 0 1 0 0 
jam 0 0 0 0 1 0 
buka 0 0 0 0 1 0 
tutup 0 0 0 0 1 0 
pantai 1 1 1 1 1 1 
WQ x Wd i 
kk d1 d2 d3 d4 d5 
0.158356 0.158356 0 0 0 0 
0.049217 0.049217 0.049217 0 0 0 
0.00627 0.00627 0.00627 0.00627 0.00627 0.00627 
0 0.158356 0 0.158356 0 0 
0.00627 0.00627 0.00627 0.00 627 0.00627 0.00627 
0.049217 0 0.049217 0 0 0.049217 
0 0 0 0.488559 0 0 
0.00627 0.00627 0.00627 0.00627 0.00627 0.00627 
0 0.158356 0 0.158356 0 0 
0 0 0 0 0.488559 0 
0 0 0 0 0.488559 0 
0 0 0 0 0.488559 0 
0.00627 0.00627 0.00627 0.00627 0.00627 0.006 27 
0 0 0 0 0.488559 0 
0 0 0 0 0 0.488559 
0 0 0 0 0 0.488559 
0.00627 0.00627 0.00627 0.00627 0.00627 0.00627 
0.049217 0 0.049217 0 0 0.049217 
0.337355 0.555634 0.178999 0.83662 1.985585 1.1069       
0.580823 0.745409 0.423083 0.914669 1.409108 1.052093 
G. Analisis Hasil Recall dan Precision 
akurasi menggambarkan seberapa akurat sistem dapat mengklasifikasikan data secara benar. Dengan kata lain, nilai akurasi merupakan perband ingan antara data yang terklasifikasi benar dengan keseluruhan data. Nilai akurasi 
dapat diperoleh dengan Persamaan 1. Nilai presisi menggambarkan jumlah data kategori positif yang diklasifikasikan secara benar dibagi dengan total data yang diklasifikasi p ositif. Presisi dapat diperoleh dengan Persamaan 
2. Sementara itu, recall menunjukkan berapa persen data 
kategori positif yang terklasifikasikan dengan benar oleh sistem. Nilai recall diperoleh dengan Persamaan 3. 
(6.1) 
(6.2) 
(6.3) 
H. Saran 
Berdasarkan hasil studi literatur, analisis, perancangan, 
implementasi, dan pengujian sistem, maka kesimpulan yang 
didapatkan adalah sebagai berikut: 
: 
â€¢ Untuk peneliti selanjutnya, sistem dapat dibuat menjadi 
aplikasi mobile agar dapat di akses dimanapun dan mempermudah user untuk mengaksesnya. 
â€¢ Sistem ini dapat membandingkan semua dokumen yang 
ada di dalam database, dan nilai perbandingan di tandai 
dengan no urut query dan no urut dokumen pembanding. 

DAFTAR PUSTAKA  
[1] Spillane, JJ., 1994. Pariwisata Indoensia: Siasat Ekono mi dan Rekayasa Kebudayaan. Yogyakarta, Kanisius. 
[2] Ahmad Zainul Fanani. 2012 . â€œSistem Costumer Service Cerdas Menggunakan Metode Fuzzy String Matching Pada E-Comm erceâ€. Jurusan Teknik Elektro. Institut Sepuluh November. 
[3] Rishabh Shah, SiddhantLahoti, dan Prof. Lavanya. K. 2017. â€œAn Intelligent Chat-bot using Natural Language Process ingâ€. Department of Computer Engineering VIT University. 
[4] Betha Sidik. 2001. â€œPemrograman Web PHP â€œ. Bandung: Penerbit Informatika.  
[5] M. Astiningrum et al ., â€œImplementasi nlp dengan konversi kata pada sistem chatbot konsultasi laktasi, â€œVol. 5, no. November, pp. 46-52, 2018. 
[6] Anonim. https://developers.line.me/, di akses pada 4 mei 2019. 
[7] Yoga Putera Utama. 2017. â€œAplikasi Chatbot Berbasis Web Pada Sistem Informasi Layanan Publik Kesehatan Di Malang Dengan Menggunakan Metode Tf-Idf dan Cosine Similarity â€. Jurusan Teknologi Informasi. Politeknik Negeri Malang. 
No Recall Cosine Precission Cosine Hasil Recall Cosine Hasil Precission Cosine 
1 29/29 20/29 1 0,689 
2 2/2 1/2 1 0,5 
3 29/29 20/29 1 0,689 
4 12/12 16/12 1 0,455 
5 34/34 30/34 1 0,2 
[8] Fatkul Amin, 2012. â€œSistem Temu Kembali Informasi dengan Metode Vector Space Model â€. Ejournal undip. 
[9] Christopher D Manning, Prabhakar Raghavan, Hinrich S chutze. â€œAn Introduction to Information Retreiveal â€œ. Cambridge University Press Cambridge, England. Online Edition Â© 2009 Cambridge U p. 
[10] Nisa Putri Lestari, â€œUji Recall And Precision Sistem Temu Kembali Informasi Opac Perpustakaan Its Surabaya â€. Departemen Ilmu Informasi Dan Perpustakaan. 
[11] Herwijayanti, B., Ratnawati, D.E., & Muflikhah, L. (2018). Klasifikasi Berita Online dengan menggunakan pembobotan Tf-Idf dan Cosine Similarity. Jurnal Pengembangan Teknologi Informasi dan Ilmu Komputer, 2(1), 306- 312 
[12] Sri Kusumadewi. 2003. â€œArtificial Intelligence (Teknik dan Aplikasinya) â€. Yogyakarta: Graha Ilmu, 5(1), 5-26.  """,Chatbot,"Cosine Similarity, TF-IDF",Data Wisata,"Recall, Cosine, Precission"
Layanan Pelanggan Berbasis NLP Melalui Chatbot Layanan Pelanggan Berbasis Natural Language Processing  Melalui Chatbot Pada UKM NQ Water Menggunakan Naive Bayes Algorithm ,"Layanan Pelanggan Berbasis NLP Melalui Chatbot Layanan Pelanggan Berbasis Natural Language Processing  Melalui Chatbot Pada UKM NQ Water Menggunakan Naive Bayes Algorithm 

Muhammad Arju Said1, Hidayatus Sibyan2, Nur Hasanah3 

Abstract  
Proper, quick and easy customer service  is what every business player should care about. Includes how to virtually communicate with customers  through messaging apps. Thanks to the sophistication of information technology, they can be used to create new  opportunities for economic actors. One of them is natural language processing or NLP technology that allows machines to interact with natural human  language. This study aims to provide courier services to customers in an efficient and effective manner. The implementation is done  using chatbots  on  messaging applications. Chatbot is designed to be able to respond to customer messages automatically and in real time by implementing  NLP methods. Based on the observations made, it is known that the 3 types of questions most  frequently asked by cus tomers are location, price list and shuttle service. Research results  show that chatbots created in natural language can be easily understood and used by customers. It is also made easier for business stakeholders as they no longer need to respond to each  customer message, making  customer service   more responsive and optimized . 
 
Keywords : Costumer sevice, Chatbot, Natural Language  
 
Abstrak  
Layanan pelanggan yang tepat, cepat dan mudah adalah hal yang harus diperhatikan oleh setiap pemain bisnis. Termasuk bagaimana berkomunikasi secara virtual dengan pelanggan melalui aplikasi perpesanan. Berkat kecanggihan teknologi informasi, hal tersebut dapat dimanfaatkan untuk menciptakan peluang baru bagi para pelaku ekonomi. Salah satunya adalah teknologi natural language processing atau NLP yang memungkinkan mesin berinteraksi dengan bahasa alami manusia. Penelitian ini bertujuan untuk memberikan layanan kurir kepada pelanggan dengan cara yang efisien dan efektif. Implementasinya dilakukan dengan menggunakan chatbot pada aplikasi perpesanan. Chatbot dirancang untuk dapat merespon pesan pelanggan secara otomatis dan real time dengan mengimplementasikan metode NLP. Berdasarkan observasi yang dilakukan, diketahui bahwa 3 jenis pertanyaan yang paling sering ditanyakan oleh pelanggan adalah lokasi, daftar harga, dan layanan antar jemput. Hasil penelitian menunjukkan bahwa chatbot yang dibuat dengan bahasa alami dapat dengan mudah dipahami dan digunakan oleh pelanggan. Hal ini juga memudahkan para pemangku kepentingan bisnis  karena mereka tidak perlu lagi menanggapi setiap pesan pelanggan, membuat layanan pelanggan menjadi lebih responsif dan optimal.  
 
Kata kunci : Layanan pelanggan, Chatbot, Natural L anguage  
 
1. PENDAHULUAN  
Bentuk komunikasi bisnis ini merupakan salah satu pr ioritas utama layanan pelanggan. Setiap pelaku bisnis harus memperhatikan  cara mereka berkomunikasi dengan pelanggan. Pesatnya perkembangan teknologi informasi memungkinkan 
dilakukannya komunikasi  secara online atau virtual, dimana pelanggan dapat menghubungi badan usaha tanpa harus datang langsung ke lokasi. Hal ini merupakan peluang yang dapat dimanfaatkan untuk meningkatkan pelayanan  pelanggan secara akurat, cepat dan sederhana. Dengan memberikan umpan balik secara real-time, kepuasan pelanggan terha dap layanan dapat meningkat [1]. Untuk berkomunikasi dengan pelanggan, bisnis dapat menggunakan aplikasi perpesanan seluler seperti WhatsApp , Telegram  atau Line . Aplikasi perpesanan 
menawarkan berbagai fitur yang membuat komunikasi online lebih mudah. Namun, masalah bisa muncul ketika responsnya lambat, sementara pelanggan membutuhkan respons yang cepat. Hal ini dapat menurunkan kualitas pelayanan kepada pelanggan karena komunikasi menjadi kurang efektif [2]. NQ Water merupakan perusahaan di Kota Wonosobo y ang bergerak di bidang pembuatan air minum. Media komunikasi yang digunakan oleh perusahaan ini adalah aplikasi WhatsApp  karena lebih banyak digunakan oleh pelanggan dibandingkan aplikasi pesan seluler lainnya  [3]. Berdasarkan hasil observasi menunjukkan adanya kendala dalam proses komunikasi dan penyebaran informasi  khususnya melalui aplikasi perpesanan. Akumulasi pesan atau chat  pelanggan terjadi karena tidak menerima respon tepat waktu sehingga memaksa pelanggan  menunggu lama untuk membalas pesan  [4 ]. Dengan demikian, kerugian dapat terjadi karena  pelanggan membatalkan pesanan atau beralih ke perusahaan minuman lain [5]. Selain itu, pelanggan  kesulitan  memperoleh informasi mengenai lokasi dan jam buka, harga dan layanan yang ditawarkan, serta layanan pengambilan dan pengembalian produk [6]. Untuk mengatasi permasalahan tersebut,  perlu diterapkan mekanisme otomasi untuk merespon pesan pelanggan. Dalam hal ini, fungsionalitas chatbot  dapat ditambahkan ke aplikasi perpesanan untuk merespons pesan  masuk secara otomatis [7]. Untuk menentukan jawaban yang diberikan berdasarkan pertanyaan  pelanggan, dapat digunakan pemrosesan bahasa alami atau NLP. Dinyatakan dalam [8] bahwa teknologi NLP memungkinkan  mesin berinteraksi dengan bahasa alami manusia. Sejumlah penelitian telah dilakukan mengenai pendekatan teknologi pada NLP, terutama untuk memudahkan proses komunikasi. Penerapan metode NLP dilakukan pada 
[3], [6] untuk mengembangkan asisten virtual  berbasis aplikasi pesan pada pusat layanan informasi mah asiswa. Hal serupa juga dilakukan pada penelitian [9], dimana fungsi chatbot digunakan sebagai pusat informasi fasilitas kursus dan pelatihan. Sedangkan pada [10], NLP diterapkan untuk melayani pelanggan dalam sistem pemes anan minuman . Penelitian ini bertu juan untuk mengembangkan fungsionalitas chatbot  di  WhatsApp  untuk meningkatkan kecepatan respon komunikasi khususnya dengan pelanggan  [11]. Sistem dibangun dengan menggunakan pendekatan metode NLP. Melalui penelitian ini diharapkan efisiensi dan kinerja para agen bisnis NQ Water dapat meningkat karena tidak perlu lagi merespon setiap pesan pelanggan. Selain itu, dengan memberikan pelayanan yang optimal, kami berharap dapat meningkatkan kepercayaan pelanggan bahkan mendapatkan pelanggan baru.  
 
2. METODOLOGI PENELITIAN  
Metodologi penelitian yang dimaksud adalah segala hal yang berhubungan dengan metode-metode yang digunakan untuk merancang  aplikasi ini dengan cara melakukan pendekatan terhadap metode -metode yang telah ada. Metode penelitian yang dipakai adal ah metode penelitian deskriptif  yaitu suatu metode yang bertujuan untuk mendapatkan Gambar an yang jelas tentang hal-hal yang diperlukan. Metodologi penelitian ini memiliki dua tahapan, yaitu pengumpulan data dan pengembangan perangkat lunak  
2.1. Metode Pengumpulan Data  
a) Study pustaka  
Studi pustaka adalah segala usaha yang dilakukan oleh peneliti untuk menghimpun informasi yang relevan dengan topik atau masalah yang akan atau sedang diteliti. Studi pustaka dapat dilakukan dengan cara mempelajari, meneliti dan menelaah berbagai literatur-literatur yang bersumber dari bukubuku, teks, jurnal ilmiah, situr-situs di internet, dan bacaan-bacaan yang ada kaitannya dengan topik penelitian ini.  
b) Study Lapangan  
Studi lapangan adalah salah satu proses kegiatan pengungka pan fakta-fakta dalam proses memperoleh keterangan atau data. Studi ini dilakukan dengan cara mengunjungi tempat yang akan diteliti dan dikumpulkan datanya secara langsung. 
Hal ini meliputi:  
1. Wawancara  
Wawancara yaitu metode pengumpulan data dengan cara ber temu secara langsung dengan narasumber yang terkait dengan permasalahan dan melakukan tanya jawab untuk memperoleh data dan informasi.  
2. Observasi  
Observasi yaitu metode pengumpulan data dengan cara melakukan pengamatan secara langsung terhadap objek permasa lahan yang diambil.  
2.2. Metode Pengembangan Aplikasi  
Tujuan dari penelitian ini adalah untuk membuat  chatbot yang dapat merespon  pesan pelanggan secara otomatis . Pesan atau chat WhatsApp  akan direspon oleh bot melalui penerapan meode NLP.  Metode pengembangan perangkat  yang digunakan yaitu Extreme Programming  (XP) yang terdiri dari sejumlah tahapan yaitu  planning, design, coding, dan testing . Teknik pengumpulan data dilakukan dengan  metode observasi dan wawancara dengan pihak terkait untuk mengetahui bagai mana gaya komunikasi antara pelaku usaha dan pelanggan  terbentuk . Proses komunikasi berjalan dengan melibatkan dua pihak yaitu pelanggan dan chatbot. Pelanggan dapat  mengirimkan pesan berupa pertanyaan atau pernyataan, dan akan  menerima respon berupa infor masi [12]. Sedangkan chatbot bertugas untuk memberikan respon berupa jawaban kepada pelanggan [9], dimana  akan  dilakukan proses penyesuaian antar pertanyaan dari pelanggan dengan database. Sistem diawali dengan pelanggan yang mengirimkan pesan  melalui nomor layanan chatbot , kemudian pesan tersebut akan disinkronkan dengan database melalui Application Programming Interface  (API). Database akan mencari respon yang paling sesuai dengan pesan yang di kirimkan oleh pelanggan . Kemudian, respon akan dikirimkan me lalui API kembali ke chatbot berupa jawaban yang diharapkan oleh pelanggan. Rancangan arsitektur sistem bot diperlihatkan pada Gambar  1. Proses pengiriman pesan dilakukan oleh pengguna melalui ponsel yang sudah dilengkapi dengan aplikasi WhatsApp . Pesan tersebut kemudian diteruskan menuju API yang bertugas sebagai perantara komunikasi antara aplikasi dengan server aplikasi. Selanjutnya, pesan diteruskan ke server aplikasi untuk dilakukan pemrosesan [13]. Jika pe san tersebut valid, akan dilakukan proses request data ke database  yang  kemudian akan dikembalikan atau return  sesuai data yang diminta. Setelah itu, data yang diperoleh dari database 
akan dirangkai dengan string berupa beberapa kata yang akan menjadi susunan kalimat. Susunan kalimat tersebut yang kem udian akan  dikirim kembali melalui API lalu diteruskan ke WhatsApp menuju ponsel milik pengguna [14] . 
Gambar  1. Rancangan arsitektur system bot 
Alur sistem dari fitur chatbot  tersebut dapat dijelaskan sebagai berikut. Pertama akan diperiksa apakah ada pes an yang masuk dari pelanggan. Jika ada, maka pelanggan akan diberikan pesan pembuka serta me nampilkan  opsi yang tersedia di dalam fitur chatbot . Selanjutnya pelanggan dapat memilih salah satu nomor dari menu layanan dan menulis pertanyaan yang akan  dijawab  oleh bot. Kemudian bot akan memproses apakah jawaban pertanyaan tersebut tersedia atau tidak melalui sinkronisasi antara isi pesan dengan database sistem. Ketika isi pesan tidak memilki  kecocokan dengan database , maka sistem akan memberikan balasan yang menjelaskan bahwa pesan  tersebut  tidak dikenali dan meminta pelanggan untuk kembali memilih nomor dari menu layanan. Sebaliknya jika terdapat kecocokan antara isi pesan dengan database, maka jawaban akan langsung diberikan kepada pelanggan dan muncul dengan  responsif . Setelah proses  tersebut, bot akan menanyakan kembali apakah pelanggan ingin mengirimkan pesan  lain lagi. Jika iya, maka pelanggan dapat memilih kembali salah satu nomor yang tersedia. Jika pelanggan telah selesai mengirimkan pesan, maka bot akan menampilkan pesan ucapan terima kasih atas kunjungan dari pelanggan.  
 
3. HASIL DAN PEMBAHASAN  
3.1. Hasil Perancangan Chatbot  
Untuk dapat mengetahui pola komunikasi yang terjalin antara pelaku usaha dengan pelanggan, maka observasi dilakukan terhadap proses tanya jawab melalui chat  pada aplikasi WhatsApp . Melalui hasil observasi, diperoleh daftar kata yang paling banyak keluar saat berkomunikasi seperti yang ditunjukkan pada Tabel 1.   
Tabel 1.  Daftar kata yang paling sering muncul di  dalam pesan  Lokasi Dan Jam  Daftar Menu  Layanan Antar Jemput  
Alamat  Isi Ambil  
Posisi Layanan  Kirim  
Letak  Galon  Rumah  
Lokasi  Air Jemput  
Tempat  Gelas  Antar  
Dimana  Harga   
Kapan  Ongkos   
Buka  Biaya   
Tutup  Ganti   
Jam Berapa   
Waktu  Baru   
Bisa  Besar   
 Ulang   
 Kotak   
 Botol   
 Kecil   
Tabel 1 memperlihatkan bahwa pertanyaan yang sering diajukan oleh pelanggan dapat dikelompokkan ke dalam tiga kategori yaitu lokasi dan jam, daftar menu , serta layanan antar jemput. Berdasarkan hal tersebut, maka dapat diGambar kan rancangan  alur sistem bot dalam bentuk flowchart  seperti yang ditunjukkan pada Gambar  2.   
Gambar  2. Alur sistem bot  
Pada tahapan ini, dilakukan analisa untuk menentukan proses penerapan metode Naive Bayes Classifier . Algoritma Naive Bayes Classifier  dikembangkan berdasarkan dari teori  Bayes dan termasuk kedalam kategori algoritma supervised learning . Algoritma ini menggunakan training dataset  (kumpulan data untuk dilatih) yang akan memandu komputer dalam menghasilkan keluaran yang sesuai dengan harapan. Teorema Bayes adalah sebuah teori  yang terdiri dari dua 
penafsiran yang berbeda. Teorema Bayes menyatakan bagaimana seharusnya tingkat kepercayaan subjektif dapat berubah secara wajar ketika diberikan petunjuk baru. Teorema ini berasal dari penerapan teori probabilitas, yaitu cara  mengetahui probabilitas dar i dua penafsiran yang berbeda [15 ]. Algoritma Naive Bayes Classifier  banyak digunakan karena memiliki komputasi yang lebih sederhana dalam implementasinya dibanding metode klasifikasi lainnya, meskipun mungkin dalam  hal akurasi masih lebih baik jika digunakan metode C4.5, K-Nearest Neighbors , dan Backpropagation Neural Network  [16]. Teorema Bayes dirumuskan dengan  : 
-1
Dimana:  
P(A|B) = Kemungkinan dari kejadian A apabila terjadi kejadian B ( event  A given event B) atau disebut posterior probability .  
P(B|A) = Kemungkinan dari kejadian B apabila terjadi kejadian A ( event  B given event  A) atau disebut likelihood . 
P(B) = Probabilitas atau kemungkinan (B) atau disebut prior probability.  Berlaku ketentuan dimana P(B ) â‰  0.  
Langkah-langkah dalam proses Naive Bayes Classifier  adalah sebagai berikut:  
a. Hitung jumlah dari kelas ( class ) atau label.  
b. Menghitung jumlah dari kasus per kelas ( class ).  
c. Kalikan semua variabel dari kelas ( class ).  
d. Lakukan komparasi dari hasil per kelas ( class )  
Contohnya,  pada kalimat â€œHalo selamat siang â€ maka kalimat tersebut akan dipecah menjadi â€˜Haloâ€™,â€™selamatâ€™,â€™siang â€™. Kemudian diberikan data pelatihan yang nantinya akan disimpan dalam bentuk daftar atau kamus yang memiliki kelas ( class) dan kalimat sebagai atribut. Misalnya terdapat data latihan sebagai berikut :   
Class  : Salam  
â€˜Salam sehatâ€™  
â€˜Salam sejahteraâ€™  
â€˜Halo selamat pagiâ€™  
Masukan pengguna: â€˜Halo selamat pagiâ€™ Istilah: Halo (cocok dengan class salam) 
Istilah: selamat (cocok deng an class salam) Istilah: pagi ( cocok dengan class salam) 
Maka dihasil kan klasifikasi Salam dan skor 3. 
Naive Bayes Classifier  dapat digunakan untuk menyelesaikan permasalahan klasifikasi melalui pendekatan probabilitas dengan asumsi prediktor variabel saling independen satu sama lain. Sehingga hasil dari model hanya bergantung pada sekumpulan  variabel independen dan tidak saling mempengaruhi [15].Kelebihan dari algoritma ini adalah apabila ada kelas yang telah didefinisikan sebelumnya maka akan menjadi mudah untuk diprediksi. Namun apabila data yang diberikan  sebagai masukan ( input ) bukan merupakan milik kelas yang telah ditentukan  sebelumnya maka menjadi tidak mungkin untuk dapat memprediksi kalimat keluaran ( output ). Oleh karena itu, karena kelemahan  ini lah algoritma Naive Bayes Classifier  memiliki kegunaan yang ter batas.  
Gambar  3. Diagram komponen sistem bot 
Pada Gambar  3 menunjukkan diagram komponen  sistem bot. Diagram tersebut mencakup komponen  seperti Messenger  dan chatbot , bersama dengan provided  interfaces  yang disediakan seperti Message  API, Teks  Response , Action , dan lainnya. Lalu lintas  pesan diarahkan ke komponen chatbot , dimana konten berupa knowledge  diambil. Setelah makna pesan dipahami, Knowledge  dikirim ke  respons  
generator  dengan outpu t sebagai text respons . Kemudian beralih ke Balasan User response  untuk mengirim tanggapan ke pesan melalui  API Pesan [18 ]. Melalui fitur chatbot yang dibangun pada aplikasi WhatsApp , sejumlah tugas dapat dilakukan diantaranya memberitahuan lokasi detail  dan jam operasional perusahaan, informasi mengenai daftar dan hargajenis minuman yang disediakan, hingga layanan antar jemput sesuai lokasi yang dituliskan pelanggan. Karena chatbot  dapat merespon pesan secara otomatis, maka pelanggan tidak perlu menunggu  balasan pesan dari pelaku usaha. Dengan adanya chatbot  ini, pelanggan hanya perlu menghubungi nomor layanan chatbot WhatsApp  dan mengirimkan pesan . Kemudian setelah memilih menu  dan menuliskan pertanyaan yang diajukan, maka bot akan memberikan jawaban dengan responsif. Pemodelan arsitektur dari fitur chatbot menggunakan aplikasi WhatsApp  ditunjukkan pada Gambar  4. Gambar  4. Pemodelan dari fitur chatbot  
3.2. Hasil Implementasi Chatbot  
Berdasarkan dari proses perancangan, pengembangan, dan pengujian, maka  didapatkan hasil implementasi sistem berupa fitur chatbot  pada aplikasi WhatsApp  dengan menggunakan bahasa  yang mudah dipahami oleh pelanggan. Uji coba ini 
dilakukan terhadap pelanggan untuk menunjukkan tahapan proses komunikasi melalui fitur chatbot . Alur komunikasi chatbot dengan pelanggan akan dimulai  ketika pelanggan memulai pengiriman pesan melalui nomor layanan chatbot 
WhatsApp . Maka bot akan merespon secara otomatis dengan mengirimkan pesan pembuka atau welcome chat  seperti yang ditunjukkan pada Gambar  5.   
Gambar  5. Chat  pembuka   
Ketika pelanggan ingin mengajukan pertanyaan yang berkaitan dengan menu layanan pertama, maka pelanggan dapat menuliskan nomor ataupun pertanyaan dengan bahasa sehari -hari yang biasa digunakan dalam berkomunikasi. Beberapa contoh kalimat yang biasa di tanyakan yaitu: â€œpermisi pak, ini lokasinya dimana ya?â€tempatnya di sebelah mana pak?â€. Setelah mengirimkan pesan tersebut, maka bot akan merespon dengan jawaba n berupa informasi lokasi detail dan jam operasional seperti yang ditunjukkan pada Gambar  6.    
Gambar  6. Respon bot untuk lokasi dan jam operasional   
Berikutnya jika pelanggan ingin mengetahui menu  apa saja yang disediakan beserta hargan ya, maka pelanggan dapat mengajukan pertanyaan seperti: â€œ berapa harga gallon baru pak?â€kemasan gelas harganya berapa pak?â€dari bot yang dikirimkan kepada pelanggan ber upa informasi daftar menu dan harga seperti yang diperlihatkan pada Gambar  7.   
Gambar  7. Respon bot untuk daftar menu dan harga Pelanggan yang ingin memesan minuman  akan tetapi tidak dapat mendatangi lokasi usaha dapat memilih opsi ketiga yaitu layanan antar jemput. Pelanggan akan diminta untuk menuliskan alamat tujuan pengan antar an atau  penjemput an seperti yang diperlihatkan pada Gambar  8. Di setiap opsi layanan yang disediakan pada chatbot , respon jawaban selalu diikuti dengan k alimat keterangan akhir yang menjelaskan tentang informasi untuk menunggu sebentar atau langsung menghubungi pelaku usaha jika sedang tidak berada di tempat.  
Gambar  8. Respon bot untuk layanan antar jemput   
Survei tersebut dilakukan terhadap pelaku usaha dan pelanggan untuk mendapatkan feedback  terkait implementasi fitur chatbot  yang telah dilakukan. Hasil yang diperoleh menunjukkan bahwa dengan hadirnya fitur chatbot  dapat bermanfaat bagi kedua belah pihak. Pelanggan yang melakukan komunikasi dengan chatbot  bisa mendapatkan respon yang cepat karena tidak perlu lagi menunggu antrian balasan, serta juga puas terhadap peningkatan pelayanan yang dilakukan, karena fitur chatbot  dapat memberikan balasan informasi terhadap pertanyaan yang diajukan dengan jelas dan lengkap. Selain itu, fitur chatbot  dapat membantu pelaku usaha agar dapat bekerja dengan lebih maksimal dan fokus pada pekerjaan yang lebih utama  ataupun mendesak . 
 
4.  SIMPULAN  
Pengembangan fitur chatbot  men ggunakan aplikasi WhatsApp  dilakukan untuk memberikan solusi atas permasalahan terhadap komunikasi yang kurang optimal pada usaha NQ Water. Pesan yang masuk dari pelanggan pertama-tama akan direspon oleh chatbot  dalam bentuk welcome  chat . Kemudian disediak an tiga opsi layanan untuk menjawab pertanyaan yang mencakup lokasi detail dan jam operasional, daftar dan harga, serta layanan antar jemput. Dengan menggunakan bahasa alami dari NLP, maka respon yang diberikan oleh chatbot  dapat dengan 
mudah dipahami oleh  pelanggan. Berdasarkan hasil dari penelitian, pelayanan pelanggan dapat berjalan dengan lebih efektif dan efisien karena pertanyaan pelanggan melalui aplikasi pesan dapat dijawab secara real-time  dan responsif. Pelanggan dapat di berikan pelayanan dengan lebih baik, sementara kinerja pelaku usaha juga dapat lebih maksimal. Untuk penelitian yang selanjutnya, fitur pada chatbot  dapat dikembangkan dengan memperluas kosakata yang ada di dalam database . Layanan komunikasi melalui chatbot  lebih cepat dan fleksibel sehingga dapat juga diterapkan pada berbagai bidang, seperti p elayanan publik atau usaha 
kecil . 
 
DAFTAR PUSTAKA  
[1] M. R. Alfares, L. Fimawahib, and E. Riskigmailcom, â€œ( Studi Kasus Dinas Perumahan Dan Kawasan Permukiman Rokan Hulu ),â€ vol. 9, no. 1, pp. 28 â€“34, 2023.  
[2] S. Pusat, I. Calon, M. Baru, and D. I. U. Nasional, â€œRANCANG BANGUN CHATBOT BERBASIS RULEBASED,â€ 2023.  
[3] S. H. Bariyah and K. A. N. Imania, â€œPengembangan Virtual Assistant Chatbot Berbasis Whatsapp Pada Pusat Layanan Informasi M ahasiswa Institut Pendidikan Indonesia - 
Garut,â€ J. Petik , vol. 8, no. 1, pp. 66 â€“79, 2022, doi: 10.31980/jpetik.v8i1.1575.  
[4] M. Sidik, B. Gunawan, and D. Anggraini, â€œPembuatan Aplikasi Chatbot Kolektor dengan Metode Extreme Programming dan Strategi For ward Chaining,â€ J. Teknol. Inf. dan Ilmu Komput ., vol. 8, no. 2, p. 293, 2021, doi: 10.25126/jtiik.2021824298.  
[5] A. Nugroho, D. P. Adi, and A. B. Gumelar, â€œChatbot Untuk Customer Service Berbasis Teks dan Suara pada Sistem Manajemen Pemesanan (OMS) Menggunakan Platform 
Android,â€ J. Repos ., vol. 2, no. 6, p. 683, 2020, doi: 10.22219/repositor.v2i6.939.  
[6] A. A. Chandra, V. Nathaniel, F. R. Satura, F. Dharma Adhinata, and P. Studi, â€œPengembangan Chatbot Informasi Mahasiswa Berbasis Telegram dengan Metode Natural Language Processing,â€ J. ICTEE , vol. 3, no. 1, pp. 20 â€“27, 2022.  
[7] N. Y. N. Pratama and F. Y. Al Irsyadi, â€œPerancangan Chatbot Islami untuk Aplikasi ChatAja,â€ Emit. J. Tek. Elektro , vol. 21, no. 1, pp. 64 â€“71, 2021, doi: 10.23917/emitor.v21i1. 12123.  
[8] D. Fajar Ramadhan, S. Noertjahjono, and J. Dedy Irawan, â€œPenerapan Chatbot Auto Reply Pada Whatsapp Sebagai Pusat Informasi Praktikum Menggunakan Artificial 
Intelligence Markup Language,â€ JATI (Jurnal Mhs. Tek. Inform ., vol. 4, no. 1, pp. 198 â€“205, 2020, doi: 10.36040/jati.v4i1.2375.  
[9] A. L. Maitri and J. Sutopo, â€œRancangan Bangun Chatbot Sebagai Pusat Informasi Lembaga Kursus Dan Pelatihan Menggunakan Pendekatan Natural Language Processing,â€ Eprints.Uty.Ac.Id , pp. 1 â€“9, 2019, [Online]. Avail able: 
http://eprints.uty.ac.id/ . 
[10] A. Y. Chandra, D. Kurniawan, and R. Musa, â€œPerancangan Chatbot Menggunakan Dialogflow Natural Language Processing (Studi Kasus: Sistem Pemesanan pada 
Coffee Shop),â€ J. Media Inform. Budidarma , vol. 4, no. 1, p. 208, 2020, do i: 10.3086 5/mib.v4i1.1505.  
[11] Dinar Nur Safitri and Muhammad Imron Rosadi, â€œRancang Bangun Penyedia Layanan Informasi Pelayanan Masyarakat Kantor Kecamatan Pandaan Menggunakan Chatbot,â€ J. Comput. Sci. Vis. Commun. Des ., vol. 6, no. 2, pp. 74 â€“83, 
2021, doi: 1 0.55732/jikdiskomvis.v6i2.427.  
[12] D. I. Rumah, S. Mata, and Y. A. P. Yogyakarta, â€œAplikasi Autoresponder Wa Untuk Laya nan Pendaftaran,â€ p. 115, 2021.  
[13] D. S. Hormansyah and Y. P. Utama, â€œAplikasi Chatbot Berbasis Web Pada Sistem Informasi Layanan Publik Kesehat an Di Malang Dengan Menggunakan Metode Tf-Idf,â€ J. Inform. Polinema , vol. 4, no. 3, p. 224, 20 18, doi: 10.33795/jip.v4i3.211.  
[14] E. Larasati Amalia and D. Wahyu Wibowo, â€œRancang Bangun Chatbot Untuk Meningkatkan Performa Bisnis,â€ J. Ilm. Teknol. Inf. Asia , vol. 13, no. 2, pp. 137 â€“142, 
2019.  
[15] R. Primartha, Algoritma Machine Learning . Informatika Bandung, 2021 . 
[16] Z. Sari, M. Sarosa, and S. Suhari, â€œâ€˜Si Toleâ€™ Chatterbot untuk Melatih Rasa Percaya Diri Menggunakan Naive Bayes Classification,â€ J. Nas. Tek. Elektro dan  Teknol. Inf ., vol. 7, no. 1, pp. 64 â€“71, 2018, doi: 10.22146/jnteti.v7i1.402  
[17] S. Pardeshi, S. Ovhal, P. Shinde, M. Bansode, and A. Birajdar, â€œA Survey on Consensus Algorithms used in Blockchain Platforms,â€ Int. J. Adv. Trends Comput. Sci. Eng., vol. 9, no. 5, pp. 9155 â€“9162, 2020, doi: 10.30534/ijatcse/2020/323952020.  
[18] H. W. T. A. E. D. Mayatopani, â€œPeran Ketua Rt Dalam Edukasi Warga Melalui Transformasi Digital Pandemi Covid -19 Menggunakan Chatbot,â€ KOCENIN Ser. Konf ., vol. 1, no. 1, pp. 1 â€“7, 2020 . """,Chatbot,Naive Bayes,"wawancara, observasi",
QAS  Untuk Peningkatan Kualitas Pelayanan Bidang  Administrasi Pada Kantor Desa Dengan Algoritma Cosine Similarity,"QAS  Untuk Peningkatan Kualitas Pelayanan Bidang  Administrasi Pada Kantor Desa Dengan Algoritma Cosine Similarity

Jumantri Tua Beruntung  Silaen*, Guidio Leonarde  Ginting , Ryan Syahputra  

Abstrak 
Perkembangan dan penggunaan teknologi komputer sekarang sudah semakin canggih. Setiap tahun tek nologi komputer 
semakin berkembang seiring dengan berjalannya waktu. Penggunaan komputer sangat penting untuk memperoleh informasi dalam proses pendaftaran maupun pengolahan data, seperti halnya pada Kantor Desa Silaen.  Question Answering System dan metode  Cosine Similarity adalah sistem berbasis komputer untuk meningkatkan kualitas pelayanan dengan sistem tanya jawab yang bertujuan memberikan alternatife-alternatif yang lebih baik, Disini penulis berusaha untuk membuat alternatif pelayanan yang memamfaatkan teknologi komputer dengan tujuan memberikan kemudahan bagi masyarakat maupun peserta didik untuk mempelajari materi pelayanan serta mempermudah untuk mengatur waktu dalam hal pengurusan administrasi sehingga mudah dipahami.  

Kata Kunci : Administrasi1, Cosine Similarity2, Natural Language Processing3, Pelayanan4, Question Answering System  (QAS)
 
Abstract 
The development and use of computer technology is now increasingly sophisticated. Every year computer technology is growing with the pass age of time. The use of computers is very important to obtain information in the registration process and data processing, as is the case at the Silaen Village Office. The Question Answering System  and the Cosine Similarity  method are computer-based systems to improve service quality with a question and answer system that aims to provide better alternatives. learn service material and make it easier to manage time in terms of administrative management so that it is easy to understand.  

Keywords : Administration1, Cosine Similarity2, Natural Language Processing3, Service4, Question Answering System  (QAS)
 
1. PENDAHULUAN  
Question Answering System (QAS) merupakan teknologi kecerdasan buatan yang dapat diolah dengan berbagai macam 
bentuk, seperti ChatBot dan berbagai macam metode, salah satunya dengan menggunakan Natural Languege Processing 
(NLP) atau bisa juga di kenal dengan Artificial Matching Markup Language (AIML) dimana keduanya menggunakan metode yang membandingkan pola -pola tertentu pada database [1]. Namun pada saat sekarang ini kenyata annya penyelenggara pelayanan administrasi kependudukan yang dilakukan oleh pemerintah daerah masih belum efisien serta kualitas pelayanan yang belum baik, sehingga masyarakat mengeluh atas pelayanan yang diberikan oleh penyelenggara pelayanan karena tidak  sesuai dengan harapan mereka.  Terutama pelayanan yang dirasakan oleh masyarakat Desa Silaen, terkhusus dalam hal pengurusan surat -surat atau pelayanan di bidang administrasi di Desa Silaen belum prima, sebagai contoh ketika akan melakukan pengurusan KTP a taupun surat -surat lainnya, masyarakat kerap bingung dengan berkas-berkas yang akan dilengkapi serta antrian yang cukup lama juga terkadang pelayan bidang administrasi di Desa Silaen tersebut cenderung tidak hadir, sehingga membuat masyarakat desa harus ke mbali lagi di lain hari untuk pengurusan administrasi yang sama.  meskipun tuntutan tersebut sering tidak sesuai dengan harapan karena pelayanan yang terjadi selama ini masih berbelit-belit dan melelahkan. Kualitas pelayanan prima yang dimaksud yaitu pelaya nan yang mendekatkan pemerintah kepada masyarakat. Hal ini diwujudkan dengan cara mengetahui dan menganalisis berbagai persoalan yang dihadapi oleh masyarakat, untuk kemudian menciptakan strategi pelayanan yang efisien [2].  Berdasarkan penelitian terdahulu yang dilakukan oleh Erdipa Panjaitan dalam jurnal nya yang berjudul â€œ Peranan Pemerintah Desa dalam Meningkatkan Kualitas Pelayanan Administrasi kepada Masyarakatâ€. Hasil penelitian menunjukkan bahwa Kualitas pelayanan di kantor Kepala Desa Aek Korsik Kecamatan Aek Kuo Kabupaten Labuhanbatu Utara dapat dinilai dari lima dime nsi yaitu Tangible, Reliability, Responsiviness, Assurance, dan Emphaty [3]. K Purba dalam jurnal nya yang berjudul â€œ Kualitas Pelayanan Administrasi Kependudukan Pada UPT DISDUKCAPIL Kecamatan Tampan Kota Pekanbaru â€. Kualitas pelayanan administrasi kependudukan pada UPT Disdukcapil kecamatan Sail masih belum optimal. Berdasarkan hasil penelitian masih ditemukan dimana unsur-unsur kualitas pelayanan publik belum berjalan sebagaimana mestinya. Unsur reliability  & responsibility  dan tangible aspect  merupakan unsur yang harus diperhatikan dalam meningkatkan kualitas pelayanan administrasi kependudukan [4]. Rama Nur Jazuli Setiawan  dalam jurnal nya yang berjudul â€œ sistem penjawab pertanyaan publik di kecamatan kaliwates jember menggunakan metode cosine similartiy â€. Kesimpulan dari Sistem Penjawab Pertanyaan Publik dengan menggunakan metode Metode Cosine Similarity  dalam Sistem Penjaw ab Pertanyaan Publik ini memiliki tingkat akurasi sebesar 85%.  Metode Cosine Similarity  sesuai diterapkan dalam Sistem Penjawab Pertanyaan Publik karena tingkat kesalahannya relatif rendah [4], [5]  Untuk menyelesaikan masalah tersebut dalam penelitian ini, maka penulis melakukan perancangan suatu aplikasi berbasis komputer yaitu Question Answering System  Peningkatan Pelayanan Administrasi dengan menggunakan bahasa 
pemrograman Pemograman Web  dengan menerapkan metode Cosine Similarity . Question Answering System  Peningkatan Pelayanan Administrasi yang dirancang penulis pada penelitian ini dapat memberikan hasil yang lebih baik terhadap hasil dari proses yang dilakukan dalam peningkatan pelayanan bidang administrasi di Kantor desa dan berdasarkan perangkingan  nilai dari tiap-tiap keadaan yang ditemui oleh masyarakat Desa Silaen.

2. METODOLOGI  PENELITIAN  
2.1 Question Answering System  
Sistem yang dikenal sebagai Question Answering  System  ini mengijinkan user untuk menginputkan pertanyaan dalam bahasa natural, yaitu bahasa yang digunakan dalam percakapan sehari -hari, dan memperoleh jawaban dengan cepat serta ringkas, atau bahkan disertai dengan kalimat yang cukup untuk mendukung kebenaran dari jawaban tersebut. Search engine  yang ada saat ini dapat mengembalikan daftar dokumen yang telah diurutkan berdasarkan tingkat relevansi dari dokumen tersebut terhadap query user , tetapi tidak memberikan jawaban kepada user[6]. 
2.2 Natural Language Processing  
Natural language processing  (NLP) adalah cabang dari kecerdasan buatan  yang berhubungan dengan interaksi antara 
komputer dan manusia menggunakan bahasa alami. Menurut  Textmetrics , NLP digunakan untuk mengukur sentimen 
dan menentukan bagian mana dari bahasa manusia yang penting [7]. 
2.3 Text Mining  
Text mining  digunakan untuk mengubah kumpulan teks menjadi numerik sehingga dapat dikomputasikan. Text mining adalah salah satu bidang khusus. Sesuai dengan buku The Next Mining Handbook. Text Mining dapat didefenisikan sebagai suatu proses menggali informasi dimana seorang user berinteraksi dengan sekumpulan dokumen dengan menggunakan tools analisis yang merupakan komponen-komponen, yang salah satunya adalah peningkatan dokumen [8]â€“[10]. 
Tabel 1. Data pertanyaan  dan jawaban   
Kode  Pertanyaan  Jawaban  
D1 1. Min dikantor desa sudah bisa mengurus KTP?  
2. Min sudah bisa buat KTP belum?  
3. Hai min, sudah bisa apa belum ngurus KTP?  Ya, sudah  D2 1. Apa aja sih berkas untuk ngurus KTP min?  
2. Min untuk ngurus KTP, perlu gak sih surat pengantar?  
3. Emang surat apa aja sih buat ngurus KTP min?  Photocopy KK, surat pengantar dari Kepala Dusun  
D3 1. Untuk pengurusan KTP untuk anak Sekolah sudah boleh dilakukan dan waktunya kapan ya? 
2. Anak SMA Udah bisa gak sih buat KTP?  
3. Min, kelas satu SMA udah bisa ya buat KTP?  Sudah, Anak berusia 17 tahun ke atas dan Waktu pengurusan KTP dimulai setiap senin-jumat sesuai jam kerja kantor  
D4 1. Untuk lokasi rekaman pembuatan KTP dimana ya?  
2. Lokasi ngurus KTP dimana ya min?  
3. Tempat ngurus KTP emang bisa ya di Kantor camat?  Untuk rekaman KTP bisa dilakukan di kantor camat kecamatan atau langsung ke Disdukcapil  Berikut ini merupakan tabel data pertanyaan, dapat dilihat pada tabel 2 dibawah ini:  
Tabel 2. Data Pertanyaan   
Kode  Pertanyaan  
D1 1. min dikantor desa sudah bisa mengurus ktp?  
2. min sudah bisa buat ktp belum ?  
3. hai min, sudah bisa apa belum ngurus ktp ?  
D2 1. apa aja sih berkas untuk ngurus ktp min ?  
2. min untuk ngurus ktp, perlu gak sih surat pengantar ?  
3. emang surat apa aja sih buat ngurus ktp min ?  
D3 1. untuk pengurusan ktp untuk anak sekolah sudah boleh dilakukan dan waktunya kapan ya ?  
2. anak sma udah bisa gak sih buat ktp ?  
3. min, kelas satu sma udah bisa ya buat ktp ?  
D4 1. untuk lokasi rekaman pembuatan ktp dimana ya ?  
2. lokasi ngurus ktp dimana ya min ?  
3. tempat ngurus ktp emang bisa ya di kantor camat ?  
Berikut ini merupakan tabel hasil tokenzing , dapat dilihat pada tabel 2 dibawah ini:  
Tabel 3. Hasil tokenzing   
Teks  Hasil Tokenizing  
1. min  dikantor desa sudah bisa mengurus ktp  
2. min sudah bisa buat ktp belum  
3. hai min, sudah bisa apa belum ngurus ktp  [min]  [ di] [kantor] [desa] [ sudah ] [bisa] [mengurus] [ktp]  
[min] [ sudah ] [bisa] [buat] [ktp] [belum]  
[hai] [min] [ sudah ] [bisa] [apa] [belum] [ngurus] [ktp]  
1. apa aja sih berkas untuk ngurus ktp min  
2. min untuk ngurus ktp, perlu gak sih surat pengantar  
3. emang surat apa aja sih buat ngurus ktp min  [apa] [aja] [sih] [berkas] [ untuk ] [ngurus] [ktp] [min]  
[min] [ untuk ] [ngurus] [ktp] [perlu] [gak] [ sih] [surat ] 
[pengantar]  
[emang] [ surat ] [apa] [aja] [sih] [buat] [ngurus] [ktp] [min]  
1. untuk pengurusan ktp untuk anak sekolah sudah boleh dilakukan dan waktunya kapan ya  
2. anak sma udah bisa gak sih buat ktp  
3. min, kelas satu sma udah  bisa ya buat ktp  [untuk ] [pengurusan] [ktp] [ untuk ] [anak] [sekolah] [sudah] 
[boleh] [dilakukan] [ dan] [waktunya] [kapan] [ ya] 
[anak ] [sma] [udah] [ bisa] [gak] [sih] [buat] [ktp]  
[min] [kelas] [satu] [sma] [udah] [ bisa] [ya] [buat] [ktp]  
1. untuk lokasi rekaman pembuatan ktp dimana ya  
2. lokasi ngurus ktp dimana ya min  
3. tempat ngurus ktp emang bisa ya di kantor camat  [untuk ] [lokasi] [rekaman] [pembuatan] [ktp] [dimana] [ ya] 
[lokasi] [ngurus] [ktp] [dimana] [ ya] [min]  
[tempat] [ngurus] [ktp] [emang] [ bisa] [ya] [di] [kantor] 
[camat]  
Berikut ini merupakan tabel hasil filtering , dapat dilihat pada tabel 2 dibawah ini:  
Tabel 3. Hasil filtering  
No Hasil Tokenizing  Hasil Filtering  
1 [min]  [ di] [kantor] [desa] [ sudah ] [bisa] [mengurus] [ktp]  [min] [ sudah ] [bisa] [buat] [ktp] [belum]  
[hai] [min] [ sudah ] [bisa] [apa] [belum] [ngurus] [ktp]  [min] [kantor] [desa] [mengurus] [ktp]  [min] [buat] [ktp] [belum]  [hai] [min] [apa] [belum] [ngurus] [ktp]  
2 [apa] [aja] [sih] [berkas] [ untuk ] [ngurus] [ktp] [min]  
[min] [ untuk ] [ngurus] [ktp] [perlu] [gak] [ sih] [surat ] 
[pengantar]  [emang] [ surat ] [apa] [aja] [sih] [buat] [ngurus] [ktp] [min]   [berkas] [ngurus] [ktp] [min]  
[min] [ngurus] [ktp] [perlu] [gak] [pengantar]  [emang] [ buat] [ngurus] [ktp] [min]  
3 [untuk ] [pengurusan] [ktp] [ untuk ] [anak] [sekolah] 
[sudah] [boleh] [dilakukan] [ dan] [waktunya] [kapan] 
[ya] [anak ] [sma] [udah] [ bisa] [gak] [sih] [buat] [ktp]  
[min] [kelas] [satu] [sma] [udah] [ bisa] [ya] [buat] [ktp]   [pengurusan] [ktp] [ [anak] [sekolah] [sudah] [boleh] [dilakukan] [waktunya] [kapan] [sma] [udah] [buat] [ktp]  
[min] [kelas] [satu] [sma] [udah] [buat] [ktp]  
4 [untuk ] [lokasi] [rekaman] [pembuatan] [ktp] [dimana] 
[ya] [lokasi] [ngurus] [ktp] [dimana] [ ya] [min]  [tempat] [ngurus] [ktp] [emang] [ bisa] [ya] [di] [kantor] [camat]   [lokasi] [rekaman] [pembuatan] [ktp] [dimana]  [lokasi] [ngurus] [ktp] [dimana] [min]  [tempat] [ngurus] [ktp] [emang] [kantor] [camat]  
Berikut ini merupakan tabel hasil case streaming , dapat dilihat pada tabel 2 dibawah ini:  
Tabel 4 . Hasil  Streaming  
No Hasil Filtering  Hasil Steaming  
1 [min] [kantor] [desa] [mengurus] [ktp]  
[min] [buat] [ktp] [belum]  [hai] [min] [apa] [belum] [ngurus] [ktp]  [min] [kantor] [desa] [urus] [ktp]  [min] [buat] [ktp] [belum]  [hai] [min] [apa] [belum] [urus] [ktp]  
2  [berkas] [ngurus] [ktp] [min]  [min] [ngurus] [ktp] [perlu] [gak] [pengantar]  [emang] [buat] [ngurus] [ktp] [min]   [berkas] [urus] [ktp] [min]  [min] [urus] [ktp] [perlu] [gak] [antar]  [emang] [buat] [urus] [ktp] [min]  
3  [pengurusan] [ktp] [ [anak] [sekolah] [sudah] [boleh] 
[dilakukan] [waktunya] [kapan]   [urus] [ktp] [ [anak] [sekolah] [udah] [boleh] [lakukan] [waktu] [kapan]  http://ejurnal.stmik -budidarma.ac.id/index. php/komik  No Hasil Filtering  Hasil Steaming  
[sma] [udah] [buat] [ktp]  [min] [kelas] [satu] [sma] [udah] [buat] [ktp]   [sma] [udah] [buat] [ktp]  [min] [kelas] [satu] [sma] [udah] [buat] [ktp]  
4  [lokasi] [rekaman] [pembuatan] [ktp] [dimana]  
[lokasi] [ngurus] [ktp] [dimana] [min]  [tempat] [ngurus] [ktp] [emang] [kantor] [camat]   [lokasi] [rekam] [buat] [ktp] [mana]  [lokasi] [urus] [ktp] [mana] [min]  [tempat] [urus] [ktp] [memang] [kantor] [camat]  
2.4 TF-IDF 
TF-IDF ( Term Frequency Invers Document Frequency ) merupakan me tode yang digunakan untuk menentukan seberapa 
jauh keterhubungan kata ( term) terhadap dokumen dengan memberikan bobot setiap kata. Metode TF-IDF ini 
menggabungkan dua konsep yaitu frekuensi kemunculan sebuah kata di dalam sebuah dokumen dan inverse frekuen si 
dokumen yang menggunakan kata tersebut.Dalam perhitungan bobot menggunakan TF -IDF, dihitung terlebih dahulu 
nilai TF perkata dengan bobot masing -masing kata adalah 1 [11], [12]  
Tabel 6. Penerapan TF -IDF 
Pertanyaan sebelum di text mining  Pertanyaan setelah di text mining  
Dimanakah Lokasi Untuk Pembuatan KTP dilaksanakan?  [mana] [lokasi] [buat] [ktp] [laksana]  
Berikut ini merupakan gambar dari hasil TF -IDF yang dapat lihat pada gambar 1 dibawah ini:  
Gambar 1. Hasil TF -IDF 

3. HASIL DAN PEMBAHASAN  
3.1 Analisa Masalah  
Dalam penelitian ini, akan dilakukan analisa dan perancangan perangkat lunak sistem tanya jawab dengan menggunakan 
algoritma cosine similarity . Question Answering System  Peningkatan Pelayanan Administrasi yang dirancang penulis 
pada penelitian ini dapat me mberikan hasil yang lebih baik terhadap hasil dari proses yang dilakukan dalam peningkatan 
pelayanan bidang administrasi di Kantor desa dan berdasarkan perangkingan nilai dari tiap -tiap keadaan yang ditemui oleh masyarakat Desa Silaen.  
3.2 Penerapan TF-IDF 
Kesesuaian jawaban yang akan disampaikan oleh sistem sangat bergantung kepada data yang digunakan, pada penelitian 
tersebut sebagai contoh penulis menggunakan beberapa pertanyaan yang akan dijadikan sebagai acuan dalam menjawab 
pertanyaan yang akan disampaikan oleh masyarakat.  
Gambar 2. Perhitungn TF-IDF 
Berikut ini merupakan gambar dari lanjutan perhitungan TF -IDF, dapat dilihat pada gamabar 3 dibawah ini:  
mana 1 1 1
lokasi 1 1 1
buat 1 1 1
ktp 1 1 1
laksana 1 1 1Term Q IDF TF*DFTF
min 1 1 1 1 1 1 0 0 1 0 1 0 8 1.176091
kantor 1 0 0 0 0 0 0 0 0 0 0 1 2 1.778151
desa 1 0 0 0 0 0 0 0 0 0 0 0 1 2.079181
urus 1 0 1 1 1 1 1 0 0 0 1 1 8 1.176091
ktp 1 1 1 1 1 1 1 1 1 1 1 1 12 1
buat 0 1 0 0 0 1 0 1 1 1 0 0 5 1.380211
belum 0 1 1 0 0 0 0 0 0 0 0 0 2 1.778151
hai 0 0 1 0 0 0 0 0 0 0 0 0 1 2.079181
apa 0 0 1 0 0 0 0 0 0 0 0 0 1 2.079181
berkas 0 0 0 1 0 0 0 0 0 0 0 0 1 2.079181
gak 0 0 0 0 1 0 0 0 0 0 0 0 1 2.079181
antar 0 0 0 0 1 0 0 0 0 0 0 0 1 2.079181
emang 0 0 0 0 0 1 0 0 0 0 0 0 1 2.079181
anak 0 0 0 0 0 0 1 0 0 0 0 0 1 2.079181
sekolah 0 0 0 0 0 0 1 0 0 0 0 0 1 2.079181
boleh 0 0 0 0 0 0 1 0 0 0 0 0 1 2.079181
lakukan 0 0 0 0 0 0 1 0 0 0 0 0 1 2.079181
waktu 0 0 0 0 0 0 0 0 0 0 0 0 0 0TF IDF2 3 1 2 3Term P1 2 3 1 2 3D1 D2 D3 D4
1
kapan 0 0 0 0 0 0 1 0 0 0 0 0 1 2.079181
sma 0 0 0 0 0 0 0 1 1 0 0 0 2 1.778151
udah 0 0 0 0 0 0 1 1 1 0 0 0 3 1.60206
kelas 0 0 0 0 0 0 0 0 1 0 0 0 1 2.079181
satu 0 0 0 0 0 0 0 0 1 0 0 0 1 2.079181
lokasi 0 0 0 0 0 0 0 0 0 1 1 0 2 1.778151
rekam 0 0 0 0 0 0 0 0 0 1 0 0 1 2.079181
mana 0 0 0 0 0 0 0 0 0 1 1 0 2 1.778151
tempat 0 0 0 0 0 0 0 0 0 0 0 1 1 2.079181
memang 0 0 0 0 0 0 0 0 0 0 0 1 1 2.079181
camat 0 0 0 0 0 0 0 0 0 0 0 1 1 2.079181
perlu 0 0 0 0 1 0 0 0 0 0 0 0 1 2.079181D4
TF IDF3 1 2 3 1 2 3 1 2Term PD1 D2 D3
1 2 3
Gambar 3. Lanjutan Perhitungan TF-IDF 
3.3 Penerapan Cosine Similarity  
Setelah term ditentukan dan telah dilakukan tahapan text mining , maka tahapan selanjutnya adalah menentukan bobot 
dari data pertanyaan dengan menggunakan cosine similarity  dengan tujuan untuk mendapatkan kesamaan terbesar terhadap data pertanyaan, adapun cara yang dila kukan untuk menghitung bobot dari setiap pertanyaan tersebut menggunakan rumus persamaan sebagai berikut.  
Gambar 4. Pernerapan Cosine Similarity  
Berikut ini merupakan gambar dari lanjutan penerapan cosine similarity, dapat dilihat pada gambar 5 dibawah ini: 
Gambar 5. Lanjutan Penerapan Cosine Similarity  
1 2 3 1 2 3 1 2 3 1 2 3
1.176091 1.176091 1.176091 1.176091 1.176091 1.176091 0 0 1.176091 0 1.176091 0
1.778151 0 0 0 0 0 0 0 0 0 0 1.778151
2.079181 0 0 0 0 0 0 0 0 0 0 0
1.176091 0 1.176091 1.176091 1.176091 1.176091 1.176091 0 0 0 1.176091 1.176091
1 1 1 1 1 1 1 1 1 1 1 1
0 1.380211 0 0 0 1.380211 0 1.380211 1.380211 1.380211 0 0
0 1.778151 1.778151 0 0 0 0 0 0 0 0 0
0 0 2.079181 0 0 0 0 0 0 0 0 0
0 0 2.079181 0 0 0 0 0 0 0 0 0
0 0 0 2.079181 0 0 0 0 0 0 0 0
0 0 0 0 2.079181 0 0 0 0 0 0 0
0 0 0 0 2.079181 0 0 0 0 0 0 0
0 0 0 0 0 2.079181 0 0 0 0 0 0
0 0 0 0 0 0 2.079181 0 0 0 0 0
0 0 0 0 0 0 2.079181 0 0 0 0 0
0 0 0 0 0 0 2.079181 0 0 0 0 0
0 0 0 0 0 0 2.079181 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0D2 D3 D4TF*IDF
D1
1 2 3 1 2 3 1 2 3 1 2 3
0 0 0 0 0 0 2.079181 0 0 0 0 0
0 0 0 0 0 0 0 1.778151 1.778151 0 0 0
0 0 0 0 0 0 1.60206 1.60206 1.60206 0 0 0
0 0 0 0 0 0 0 0 2.079181 0 0 0
0 0 0 0 0 0 0 0 2.079181 0 0 0
0 0 0 0 0 0 0 0 0 1.778151 1.778151 0
0 0 0 0 0 0 0 0 0 2.079181 0 0
0 0 0 0 0 0 0 0 0 1.778151 1.778151 0
0 0 0 0 0 0 0 0 0 0 0 2.079181
0 0 0 0 0 0 0 0 0 0 0 2.079181
0 0 0 0 0 0 0 0 0 0 0 2.079181
0 0 0 0 2.079181 0 0 0 0 0 0 0TF*IDF
D1 D2 D3 D4
1 2 3 1 2 3 1 2 3 1 2 3
min 0 0 0 0 0 0 0 0 0 0 0 0
kantor 0 0 0 0 0 0 0 0 0 0 0 0
desa 0 0 0 0 0 0 0 0 0 0 0 0
urus 0 0 0 0 0 0 0 0 0 0 0 0
ktp 1 1 1 1 1 1 1 1 1 1 1 1
buat 0 1.380211 0 0 0 1.380211 0 1.380211 1.380211 1.380211 0 0
belum 0 0 0 0 0 0 0 0 0 0 0 0
hai 0 0 0 0 0 0 0 0 0 0 0 0
apa 0 0 0 0 0 0 0 0 0 0 0 0
berkas 0 0 0 0 0 0 0 0 0 0 0 0
gak 0 0 0 0 0 0 0 0 0 0 0 0
antar 0 0 0 0 0 0 0 0 0 0 0 0
emang 0 0 0 0 0 0 0 0 0 0 0 0
anak 0 0 0 0 0 0 0 0 0 0 0 0
sekolah 0 0 0 0 0 0 0 0 0 0 0 0
boleh 0 0 0 0 0 0 0 0 0 0 0 0D1 D2 D3 D4Q*P
Term P
1 2 3 1 2 3 1 2 3 1 2 3
lakukan 0 0 0 0 0 0 0 0 0 0 0 0
waktu 0 0 0 0 0 0 0 0 0 0 0 0
kapan 0 0 0 0 0 0 0 0 0 0 0 0
sma 0 0 0 0 0 0 0 0 0 0 0 0
udah 0 0 0 0 0 0 0 0 0 0 0 0
kelas 0 0 0 0 0 0 0 0 0 0 0 0
satu 0 0 0 0 0 0 0 0 0 0 0 0
lokasi 0 0 0 0 0 0 0 0 0 1.778151 1.778151 0
rekam 0 0 0 0 0 0 0 0 0 0 0 0
mana 0 0 0 0 0 0 0 0 0 1.778151 1.778151 0
tempat 0 0 0 0 0 0 0 0 0 0 0 0
memang 0 0 0 0 0 0 0 0 0 0 0 0
camat 0 0 0 0 0 0 0 0 0 0 0 0
perlu 0 0 0 0 0 0 0 0 0 0 0 0
laksana 0 0 0 0 0 0 0 0 0 0 0 0
SUM 2 4.380211 4 2 3 5.380211 2 4.380211 5.380211 6.936514 6.556303 4Q*P
D1 D2 D3 D4 Term P
Hasil perkalian di jumlahkan
1 2 3 1 2 3 1 2 3 1 2 3
mana 1 min 0 0 0 0 0 0 0 0 0 0 0 0
lokasi 1 kantor 0 0 0 0 0 0 0 0 0 0 0 0
buat 1 desa 0 0 0 0 0 0 0 0 0 0 0 0
ktp 1 urus 0 0 0 0 0 0 0 0 0 0 0 0
laksana 1 ktp 1 1 1 1 1 1 1 1 1 1 1 1
buat 0 1.904983 0 0 0 1.904983 0 1.904983 1.904983 1.904983 0 0
belum 0 0 0 0 0 0 0 0 0 0 0 0
hai 0 0 0 0 0 0 0 0 0 0 0 0
apa 0 0 0 0 0 0 0 0 0 0 0 0
berkas 0 0 0 0 0 0 0 0 0 0 0 0
gak 0 0 0 0 0 0 0 0 0 0 0 0
antar 0 0 0 0 0 0 0 0 0 0 0 0
emang 0 0 0 0 0 0 0 0 0 0 0 0
anak 0 0 0 0 0 0 0 0 0 0 0 0
sekolah 0 0 0 0 0 0 0 0 0 0 0 0
boleh 0 0 0 0 0 0 0 0 0 0 0 0Term P IDF Term QQ*P
D1 D2 D3 D4
1 2 3 1 2 3 1 2 3 1 2 3
lakukan 0 0 0 0 0 0 0 0 0 0 0 0
waktu 0 0 0 0 0 0 0 0 0 0 0 0
kapan 0 0 0 0 0 0 0 0 0 0 0 0
sma 0 0 0 0 0 0 0 0 0 0 0 0
udah 0 0 0 0 0 0 0 0 0 0 0 0
kelas 0 0 0 0 0 0 0 0 0 0 0 0
satu 0 0 0 0 0 0 0 0 0 0 0 0
lokasi 0 0 0 0 0 0 0 0 0 3.161822 3.161822 0
rekam 0 0 0 0 0 0 0 0 0 0 0 0
mana 0 0 0 0 0 0 0 0 0 3.161822 3.161822 0
tempat 0 0 0 0 0 0 0 0 0 0 0 0
memang 0 0 0 0 0 0 0 0 0 0 0 0
camat 0 0 0 0 0 0 0 0 0 0 0 0
perlu 0 0 0 0 0 0 0 0 0 0 0 0
2.236.068
SUM 2 4.904983 4 2 3 5.904983 2 4.904983 5.904983 10.22863 9.323644 4
âˆš 1.414214 2.21472 2 1.414214 1.732051 2.430017 1.414214 2.21472 2.430017 3.198222 3.053464 2Q*P
D1 D2 D3 D4 Term Q IDF Term P
Akarkan hasil dari pejumlahan diatas5
Hasil dari kuadrat diatas dijumlahkan
ð¶ð‘œð‘ ð‘†ð‘–ð‘š (ð‘„,ð·11)=âˆ‘ (ð‘¡ð‘‘ð‘–ð‘—Ã—ð‘¡ð‘žð‘–ð‘˜)ð‘›
ð‘–=1
âˆšâˆ‘ ð‘¡ð‘‘ð‘–ð‘—2 ð‘›
ð‘–=1 Ã—âˆ‘ ð‘¡ð‘‘ð‘–ð‘˜2 ð‘›
ð‘–=1 
       =1
223607 âˆ—1=0,44721  
Perhitungan similaritis antara Q (pertanyaan yang di analisa) dengan D1 1 didapatkan hasil  0,44721 . Begitu selanjutnya sampai didapatkan hasil pada perhitungan ke 12 . 
Tabel 7. Hasil dari penerapan Cosine Similarity  
Q 1 2 3 
D1 0,44721  0,62454  0,44721  
D2 0,44721  0,44721  0,62454  
D3 0,44721  0,62454  0,62454  
D4 0,87393  0,75295  0,44721  
3.4 Implementasi  
Tahap implementasi merupakan tahap penciptaan perangkat lunak, tahap kelanjutan dari kelanjutan dari kegiatan 
perancangan sistem. Tahap ini merupakan tahap dimana sistem siap untuk dioperasikan, yang terdiri dari penjelasan 
mengenai kebutuhan sistem, dan implementasi antar muka.  
A Web Page http ://layanan .administrasi .desa .id
//desasilaen .co.id @2022Layanan Administrasi Desa
PEMERINTAH KABUPATEN TOBA
KECAMATAN SILAEN
DESA SILAENcari
Silahkan masukkan pertanyaan anda disini  .
Kirim
Gambar 6 . Tampilan Interface QAS  
Dibawah ini dapat dilihat tampilan QAS pada gambar 7 dibawah ini:  
L a y a n a n  A d m i n i s t r a s i  
D e s a  S i l a e n
Selamat pagi min   .
Iya, Selamat pagi
Ada yang bisa kami bantu ?
Apa pengurusan KTP sudah bisa dilakukan min ?
Untuk pengurusan KTP sudah bisa dilakukan ya
Ketik pesan ...10.12
10.18
10.20
10.22
10.25
KIRIM PESAN
Gambar 7 . Tampilan  QAS  

4. KESIMPULAN  
Berdasarkan dari penelitian yang telah dilakukan, maka hasil akhir dari penelitian tersebut dapat diambil kesimpulan 
dari pembahasan sebelumnya. Algoritma TF-IDF mampu mencocokkan pertanyaan dengan data yang sudah tersimpan 
pada database  yang mana dapat me nghasilkan jawaban yang sesuai. Dengan menrapkan pendekatan Natural Language 
Processing pada aplikasi Question Answering System percakapan yang terjadi layaknya antara manusia dengan manusia. Dengan membuat aplikasi Question Answering System ini dapat meng gantikan manusia sehingga dapat meningkatkan 
kualitas Pelayanan di Kantor Desa Silaen terutama di bidang administrasi.  

REFERENCES  
[1] R. R. R. Ferbiansyah, â€œQuestion Answering System Berbahasa Indonesia Menggunakan Metode Pattern Based Approach (Studi Kasus Bahan Ajar Mata Kuliah Sistem Operasi Prodi S1 Sistem Informasi Universitas Airlangga),â€ pp. 1 â€“4, 2015.  
[2] K. Purba, â€œKualitas Pelayanan Administrasi Kependudukan Pada Upt Disdukcapil Kecamatan Tampan  Kota Pekanbaru,â€ J. Adm. Publik , vol. 11, no. 1, pp. 31 â€“55, 2020, doi: 10.31506/jap.v11i1.7127.  
[3] E. Panjaitan, R. Dewi, and N. Angelia, â€œPeranan Pemerintah Desa dalam Meningkatkan Kualitas Pelayanan Administrasi kepada Masyarakat,â€ Perspektif , vol. 8, no. 1, p. 32, 2019, doi: 10.31289/perspektif.v8i1.2543.  
[4] M. Metode et al. , â€œuntuk memenuhi kebutuhannya dalam berbagai bidang.â€  
[5] D. Liu, X. Chen, and D. Peng, â€œSome cosine similarity measures and distance measures between qâ€rung orthopair fuzzy sets,â€ Int. J. Intell. Syst. , vol. 34, no. 7, pp. 1572 â€“1587, 2019.  
[6] F. Azwary, F. Indriani, and D. T. Nugrahadi, â€œQuestion Answering System Berbasis Artificial Intelligence Markup 
Language,â€ Kumpul. J. Ilmu Komput. , vol. 04, no. 01, pp. 48 â€“60, 2016.  
[7] A. N . Rohman, E. Utami, and S. Raharjo, â€œDeteksi Kondisi Emosi pada Media Sosial Menggunakan Pendekatan Leksikon dan Natural Language Processing,â€ Eksplora Inform. , vol. 9, no. 1, pp. 70 â€“76, 2019, doi: 10.30864/eksplora.v9i1.277.  
[8] H. Sari, G. L. Ginting, an d T. Zebua, â€œPenerapan Algoritma Text Mining dan TF -IDF Untuk Pengelompokan Topik Skripsi Pada Aplikasi Repository STMIK Budi Darma,â€ vol. 2, no. 7, pp. 414 â€“432, 2021.  
[9] D. Antons, E. GrÃ¼nwald, P. Cichy, and T. O. Salge, â€œThe application of text mining m ethods in innovation research: current state, evolution patterns, and development priorities,â€ R&D Manag. , vol. 50, no. 3, pp. 329 â€“351, 2020.  
[10] T. Jo, â€œText mining,â€ Stud. Big Data , 2019.  
[11] B. Herwijayanti, D. E. Ratnawati, and L. Muflikhah, â€œKlasifikasi Berita Online dengan menggunakan Pembobotan TF-IDF dan Cosine Similarity,â€ Pengemb. Teknol. Inf. dan Ilmu Komput. , vol. 2, no. 1, pp. 306 â€“312, 2018.  
[12] S.-W. Kim and J. -M. Gil, â€œResearch pa per classification systems based on TF -IDF and LDA schemes,â€ Human -centric Comput. Inf. Sci. , vol. 9, pp. 1 â€“21, 2019.  ",QAS,Cosine Similarity,data pertanyaan dan jawaban,
Pencarian Question-Answer  Menggunakan Convolutional Neural Network Pada Topik Agama Berbahasa Indonesia,"Pencarian Question-Answer  Menggunakan Convolutional Neural Network Pada Topik Agama Berbahasa Indonesia

Rizqa Raaiqa Bintana1, Chastine Fatichah2, Diana Purwitasari3 

Abstract
Community-based question answering (CQA) is formed to  help people who search information that they need through a community. One condition that may occurs in CQA is when people cannot obtain the information that they need, thus they will post a new question. This condition can cause CQA archive increased  because of duplicated questions. Therefore, it becomes important problems to find semantically similar questions from CQA archive towards a new question. In this study, we use convolutional neural network  methods  for semantic modeling of sentence to obtain words that they represent the content of documents and new question. The result for the process of finding the same question semantically to a new question (query) from the question-answer documents archive using the convolutional neural network method, obtained the mean average precision value is 0,422. Whereas by using vector space model, as a comparison, obtained mean  average precision value is 0,282.                                                          
Index Terms community-based question answering, convolutional neural network, question retrieval                                                          
I. PENDAHULUAN                                  
Komunitas tanya-jawab dibentuk untuk mempermudah seseorang dalam memperoleh informasi yang dibutuhkannya melalui suatu komunitas, contohnya Yahoo! Answers. Salah satu kondisi yang bisa terjadi dalam komunitas tanya-jawab adalah ketika pencari informasi tidak mampu menemukan informasi yang di butuhkan, sehingga mereka akan menginputkan pertanyaan baru ke dalam sistem. Hal ini dapat mengakibatkan jumlah arsip dokumen pertanyaan dan jawaban  menjadi ganda. Sehingga menjadi permasalahan yang penting untuk bisa menemukan pertanyaan  yang sama secara semantik antara pertanyaan baru terhadap pertanyaan yang ada di arsip. Classical retrieval models, seperti TF-IDF dan Okapi BM25, menggunakan representasi bag-of-words dan tidak mampu secara efektif menangkap informasi kontekstual dari sebuah kata. Model ini bekerja dengan mempertimbangkan informasi kemunculan kata dalam sebuah dokumen. Sebagian besar tugas temu kembali ( retrieval ) menggunakan metode-metode  yang berdasarkan semantik dengan pencocokan leksikal untuk pengambilan informasi. Hal ini sebagian disebabkan bahwa konteks  yang sama sering dinyatakan dengan menggunakan kosa kata dan gaya bahasa yang berbeda dalam dokumen dan query. Beberapa penelitian menggunakan pengetahuan dari WordNet  untuk menemukan kata yang sama secara semantik dan membantu pengukuran nilai kemiripan semantik diantara dua kata[1]. WordNet merupakan database  leksikal yang menyimpan sinonim suatu kata, dan digunakan secara luas dalam analisa teks, namun terbatas hanya untuk kata dalam bahasa inggris. Berbagai metode diusulkan untuk pembelajaran representasi kata terdistribusi ( word embeddings ) dalam ruang vektor berdimensi rendah. Representasi kata terdistribusi membantu algoritma pembelajaran (learning algorithm ) untuk mencapai kinerja yang lebih baik dengan cara mengelompokkan kata-kata yang mirip, dan telah diterapkan secara luas pada bidang bahasan pemrosesan  bahasa alami ( natural language processing) [2] [3]. Selain menggunakanrepresentasi kata terdistribusi, beberapa metode lain untuk memodelkan kalimat (neural sentence models, model yang dikombinasikan terhadap struktur neural network ), seperti Neural Bag-of-Words  (NBOW), recurrent neural network  (RNN), recursive neural network (RecNN), dan convolutional neural network (CNN) [4]. NBOW merupakan metode yang sederhana dan intuitif, namun mempunyai kekurangan dimana susunan kata menjadi hilang. Pemodelan kalimat berdasarkan RNN sensitif terhadap susunan kata, tetapi memiliki bias  terhadap kata-kata terbaru yang dibutuhkan sebagai inputan. Hal ini memberikan  RNN kinerja yang sangat baik  dalam memodelkan bahasa, tetapi kurang optimal  untuk memodelkan keseluruhan kalimat . RecNN mengadopsi struktur yang lebih umum untuk mengkodekan kalimat. Di setiap node dalam tree, konteks pada anak node  kiri dan kanan digabungkan oleh classical layer. Bobot dari lapisan dibagi di semua node  dalam tree. Lapisan yang dihitung pada node  atas memberikan  sebuah representasi untuk kalimat. Namun, Rec NN bergantung pada external constituency parse tree yang disediakan oleh external parse tree . CNN mempunyai kelebihan yaitu, dapat mempertahankan informasi susunan kata yang sangat penting untuk kalimat pendek, serta aktivasi nonlinier dalam CNN dapat mempelajari karakteristik yang lebih abstrak [4]. Pemodelan kalimat adalah cara untuk menganalisa dan merepresentasikan isi semantik yang ada dalam sebuah kalimat, yang melibatkan pemahaman bahasa alami. Neural sentence models  digunakan untuk menghasilkan kata demi kata dari suatu kalimat [5][6]. Neural network  digunakan untuk mengekstrak struktur semantik yang tersimpan  dalam sebuah kalimat ataupun dokumen. Neural sentence models bekerja dengan cara memetakan kata melalui inputan query  dan representasi kata terdistribusi dari koleksi dokumen. Dari pemetaan kata tersebut akan diperoleh ekstrak kata yang dianggap sama secara semantik terhadap query melalui lapisan ( layer ) proyeksi. Dalam penelitian ini, diterapkan model  CNN  untuk pemodelan semantik kalimat pertanyaan. Penelitian ini bertujuan untuk mengetahui performansi metode CNN dalam menemukan pertanyaan dari arsip komunitas tanya-jawab yang sesuai dan sama secara semantik dengan pertanyaan baru (query ) yang diinputkan oleh penanya. Pada bagian berikutnya dalam tulisan ini berisi tinjauan literatur yang terkait. Dilanjutkan dengan bagian penjelasan metod ologi penelitian, penjelasan hasil dan  pembahasan. Dan bagian terakhir diberikan  kesimpulan.                                                         
II. LITERATUR TERKAIT                                          
A. Questions Retrieval                                 
Dalam komunitas tanya-jawab, berbagai cara telah dipelajari untuk menyelesaikan permasalahan lexical gap dalam temu kembali pertanyaan ( questions retrieval ). Meskipun sebagian besar model retrieval yang sederhana menga sumsikan bahwa kemunculan kata benar-benar independen, namun informasi kontekstual  sangat penting untuk mendeteksi maksud pencarian tertentu  dari sebuah query. Pendekatan berbasis model terjemahan  (translation model-based ) diusulkan [7] yang mencoba untuk mengekstrak hubungan frase-ke-frase berdasarkan click through data. Hubungan tersebut  diharapkan menjadi lebih efektif dalam menjembatani kesenjangan antara query dan dokumen. Pendekatan lainnya yang diterapkan dalam temu kembali pertan yaan adalah dengan pencocokan leksikal untuk pengambilan informasi. Pendekatan ini berdasarkan sifat semantik antar kata dalam query  dan koleksi dokumen, sehingga konteks yang sama namun dinyatakan dengan kosa kata yang berbeda juga akan dapat di-retrieve. B. Word Embeddings                                         
Word embeddings  (representasi kata terdistribusi) merupakan cara yang merepresentasikan kata-kata bahasa alami dengan cara mempertahankan kemiripan semantik dan sintaksis  di antara  kata-kata tersebut. Hal ini didapat  melalui representasi kata-kata sebagai vektor berdimensi tinggi, yaitu hubungan spasial di antara embeddings merepresentasikan hubungan di antara kata-kata. Sebagai contoh , representasi dari kata â€œfisika â€ dan â€œkimiaâ€ akan dekat secara bersama, dan kata â€œm obilâ€ akan dekat dengan kata â€œbalapâ€ dan â€œsupirâ€. Ada dua teknik  yang dikembangkan  untuk memperoleh word embeddings  yaitu, word2vec dan GloVe. Teknik tersebut dilakukan dengan mengolah bentuk bebas teks sehingga menghasilkan vektor berkualitas tinggi yang merepresentasikan kata-kata. Teknik yang digunakan dalam penelitian ini adalah teknik word2vec.  Word2vec, diperkenalkan oleh Mikolov dkk (2013), menggunakan teknik yang disebut â€œ skip-gram with negative sampling â€. Teknik ini tidak memprediksi kata berdasarkan pada konteks, tapi mencoba untuk memaksimalkan klasifikasi sebuah kata berdasarkan kata lain dalam kalimat yang sama. Lebih tepatnya, kita menggunakan setiap kata ( current word ) sebagai inputan untuk log-linear classifier dengan lapisan proyeksi yang kontinyu, dan memprediksi kata-kata dalam jarak tertentu sebelum dan setelah kata inputan tersebut ( current word ). Dari penelitian Mikolov dkk (2013) ditemukan bahwa peningkatan jarak memperbaiki kualitas vektor kata yang dihasilkan, tetapi juga meningkatkan kompleksitas komputasi. Karena kata-kata yang lebih jauh jaraknya biasanya kurang terkait dengan kata inputan daripada yang berjarak dekat dengan kata inputan. Berikut gambaran umum tentang cara kerja teknik word2vec:          
a. Mengambil kata di dalam koleksi dokumen (corpus ) latih, dan sejumlah kata-kata yang terletak dekat dengan konteks . b. Merepresentasikan setiap kata-kata tersebut melalui sebuah vektor (sejumlah daftar kata). Karena teknik word2vec dan GloVe menangkap hubungan semantik dan sintaksis, kedua teknik ini bisa digunakan untuk pencarian (sinonim, query expansion) serta rekomendasi. Word embeddings terlihat  tidak memberikan  diskriminatif  antara konsep terkait namun  konsep yang berbeda.                                 
C. Convolutional Neural Network                         
Ada beberapa metode untuk memodelkan kalimat yang disebut neural sentence model . Peranan penting dari neural sentence model adalah untuk merepresentasikan variable-length sentence  sebagai fixed-length vector . Convolutional neural network (CNN) merupakan salah satu neural sentence model  yang digunakan untuk memodelkan kalimat [8]. Hal pertama yang dilakukan dalam tahap model CNN adalah mentransformasi semua kata tunggal ( token ) dalam kalimat pertanyaan menjadi  vektor melalui lookup layer dan menggunakan word embedding dalam kalimat secara berurutan. CNN merangkum makna sebuah kalimat melalui convolutional layer dan pooling layer, hingga mencapai sebuah representasi fixed-length vector  pada lapisan ( layer ) akhir . CNN mempunyai kelebihan, yaitu dapat mempertahankan informasi susunan kata dimana hal tersebut menjadi sangat penting untuk kalimat pendek. Convolutional layer  menerapkan matriks filter satu dimensi yang melewati tiap baris fitur dalam matriks kalimat. Pembelitan ( convolving ) filter yang sama dengan n-gram di setiap posisi dalam kalimat memungkinkan fitur-fitur untuk diekstrak secara bebas dari posisi mereka dalam kalimat. Convolutional layer diikuti oleh dynamic pooling layer dan non-linearitas dari pemetaan fitur [8]. Arsitektur  convolutional  untuk kalimat pemodelan, seperti digambarkan  pada Gambar 1, dibutuhkan sebagai inputannya berupa word embedding (yang dilatih terlebih dahulu dengan  metode unsupervised ) dalam kalimat yang selaras  secara berurutan, dan meringkas makna  kalimat melalui lapisan convolutional  dan pooling , sampai mencapai representasi kata dalam fixed length vector pada lapisan  terakhir. Embeddings  untuk seluruh kata dalam kalimat s membangun matriks inputan s Ïµ ð‘…ð‘›ð‘¤ð‘‹ð‘™ð‘ , dimana ls menyatakan panjang s. Sebuah convolutional layer diperoleh melalui convolving  sebuah matriks dari bobot (filter) m Ïµ Rnxm dengan matriks aktivasi pada layer berikutnya, dimana m adalah lebar filter. Lapisan (layer) pertama diperoleh dengan menggunakan convolutional filter untuk matriks kalimat s dalam layer inputan. Dimensi nw dan lebar filter m adalah hyper-parameters  pada networ k. Jaringan menangani rentetan inputan  dari berbagai         variasi panjang  kata.  Lapisan dalam jaringan interleave convolutional layers  dan dynamic k-maxpooling layers satu dimensi . Dynamic k-max pooling adalah generalisasi dari  operator max pooling. Operator max pooling  merupakan fungsi subsampling non-linear yang mengembalikan nilai-nilai maksimum [8].                                                         
III. METODE PENELITIAN                          
Untuk mencapai tujuan penelitian, maka detail rancangan keseluruhan proses yang dilakukan dalam penelitian ini seperti yang terlihat pada Gambar 2 . Berdasarkan rancangan tersebut akan dibangun sistem yang mencakup keseluruhan proses untuk membantu proses training  dan testing  dalam penelitian ini.                                         
A. Dataset                                          
Tahapan penelitian dimulai dari pengumpulan data penelitian. Dalam penelitian ini, dataset  yang digunakan adalah dokumen pertanyaan-jawaban  yang diambil dari komunitas tanya-jawab online www.piss-ktb.com. Pertanyaan baru yang diinputkan penanya, yang selanjutnya akan disebut query, akandibandingkan dengan pertanyaan yang ada di arsip (koleksi dokumen) komunitas tanya-jawab dengan tujuan untuk menemukan pertanyaan dari arsip komunitas tanya-jawab yang sama secara semantik dengan query .                         
B. Pemrosesan Teks                                  
Seperti yang dapat dilihat pada Gambar 2, beberapa proses yang akan dilakukan dalam penelitian ini setelah pengumpulan data yaitu, melakukan preproses terhadap arsip dokumen tanya-jawab dan query, melakukan proses word embeddings  terhadap keseluruhan kata dalam dokumen tanya-jawab yang telah dipreproses, proses pemodelan kalimat untuk dokumen pertanyaan dan jawaban di sisi training dan query  di sisi testing  yang dimodelkan  menggunakan convolutional neural network, dan mengukur kecocokan antara pertanyaan dan jawaban yang ada di arsip dokumen untuk proses training  serta antara query  dan dokumen jawaban pada proses testing  menggunakan  model neural tensor network.         
Gambar 1.  Arsitektur convolutional secara keseluruhan dalam memodelkan kalimat [9]                                 
Arsip dokumen tanya-jawab
Pemrosesan teks (preprocessing)                        
Pencocokan semantik antara pertanyaan (query) dan jawaban dengan neural tensor network                        
Sejumlah dokumen pertanyaan hasil temu Kembali beserta jawabannya
Pertanyaan baru ( query ) penanya
Mulai                                                        
Pemodelan kalimat menggunakan convolutional neural network
Word embeddings dan koefisiennya                
Kata-kata yang merepresentasikan isi dokumen/kalimat dalam bentuk fixed-length vectorProses word embeddings
Dokumen teks yang telah dipreproses                
Gambar 2 . Rancangan keseluruhan proses dalam penelitian Pemrosesan teks dalam penelitian ini dilakukan sebagai tahapan preproses terhadap arsip dokumen tanya-jawab dan query. Tujuan dilakukannya pemrosesan teks adalah untuk membersihkan data sebagai langkah awal untuk analisis data. Proses yang dilakukan dalam tahapan ini, yaitu :         
1. Tahap penghapusan tag markup  dan format khusus dari dalam dokumen pertanyaan-jawaban. Sebelum dilakukan tokenisasi, semua tag markup  dan format khusus akan dihapus dari dalam dokumen. Karena koleksi dokumen pertanyaan -jawaban yang digunakan dalam penelitian ini adalah file dengan ekstensi .html, maka seluruh tag maupun javascript  serta style akan dihapus .                                 
2. Tahap tokenisasi, merupakan proses pemisahanrangkaian kata. Dalam tahap ini, seluruh kata di dalam dokumen  atau kalimat  dipisahkan menjadi potongan kata tunggal (term ). Dalam proses ini juga dilakukan penghapusan karakter-karakter tertentu, yaitu tanda baca serta mengubah semua kata ke bentuk huruf kecil ( lowercase ). 
3. Tahap  penghapusan stop-words  (linguistic preprocessing). Setelah tahap tokenisasi dilakukan, maka dilanjutkan dengan tahap penghapusan stop-words  dari dalam dokumen. Dalam tahap ini, ada dua operasi utama yang dilakukan yaitu penghapusan stop-words  (stop-words removal) dan stemming  (pemotongan imbuhan).  Stop-words adalah kata yang sering muncul dalam dokumen, namun kata tersebut tidak dapat mendeskripsikan topik atau sub-topik dari dokumen tersebut, sehingga tidak dapat membedakan dokumen satu dengan dokumen lainnya di dalam koleksi (corpus). Karena itu, kata tersebut dihapus dari dalam dokumen. Contoh data inputan penelitian dan output dalam tahapan preprocessing  dapat dilihat pada Tabel 1.                          
Tabel 1. Dokumen sebelum dan setelah tahapan preprocessing  Dokumen Sebelum Preprocessing                          
3729. puasa : cara mengqadha puasa yang tidak diketahui jumlahnya                                          
pertanyaan                                          
>> agus suryo komputro                          
assalamu alaikum wa rahmatullahi wa barakatuh  saya mau tanya nih ... jika saya (laki-laki) dulunya lalai dalam beribadah khususnya berpuasa bulan ramadhan sering bolong bolong, saya berniat membayar puasa ramadhan saya yang bolong tapi sudah lupa berapa banyak yang bolong .... apa yang harus  saya lakukan berdasar al-quran & hadits yang ada ? syukron                                  
jawaban                                          
>> ghufron bkl                          
wa'alaikumussalaam warohmatullah wabarokaatuh wajib mengqadha puasa sampai yakin sudah dikerjakan semua.  referensi: hawasyi asy -syarwani iii / 396                   ÙˆÙŽÙ„ÙŽÙˆÙ’ Ø¹ÙŽÙ„ÙÙ…ÙŽ Ø£ÙŽÙ†ÙŽÙ‘Ù‡Ù ØµÙŽØ§Ù…ÙŽ  Ø¨ÙŽØ¹Ù’Ø¶ÙŽ Ø§Ù„Ù„ÙŽÙ‘ÙŠÙŽØ§Ù„ÙÙŠ ÙˆÙŽØ¨ÙŽØ¹Ù’Ø¶ÙŽ Ø§Ù’Ø£Ù„ÙŽÙŠÙŽÙ‘Ø§Ù…Ù ÙˆÙŽÙ„ÙŽÙ…Ù’ ÙŠÙŽØ¹Ù’Ù„ÙŽÙ…Ù’ Ù…ÙÙ‚Ù’Ø¯ÙŽØ§Ø±ÙŽ Ø§Ù’Ø£Ù„ÙŽÙŠÙŽÙ‘Ø§Ù…Ù Ø§Ù„ÙŽÙ‘ØªÙÙŠ ØµÙŽ Ø§Ù…ÙŽÙŽÙŽØ§ ÙÙŽØ¸ÙŽØ§Ù‡ÙØ±ÙŒ Ø£ÙŽÙ†ÙŽÙ‘Ù‡Ù ÙŠÙŽØ£Ù’Ø®ÙØ°Ù Ø¨ÙØ§Ù„Ù’ÙŠÙŽÙ‚ÙÙŠÙ†Ù ÙÙŽÙ…ÙŽØ§ ØªÙŽÙŠÙŽÙ‚ÙŽÙ‘Ù†ÙŽÙ‡Ù Ù…ÙÙ†Ù’ ØµÙŽÙˆÙ’Ù…Ù Ø§Ù’Ø£Ù„ÙŽÙŠÙŽÙ‘Ø§Ù…Ù Ø£ÙŽØ¬Ù’Ø²ÙŽØ£ÙŽÙ‡Ù ÙˆÙŽÙ‚ÙŽØ¶ÙŽÙ‰ Ù…ÙŽØ§ Ø²ÙŽØ§Ø¯ÙŽ Ø¹ÙŽÙ„ÙŽÙŠÙ’Ù‡Ù Ø³Ù… Ø§Ù‡Ù€ Ø­ÙˆØ§Ø´ÙŠ Ø§Ù„Ø´Ø±ÙˆØ§Ù†ÙŠ Ø¬ Ù£ Øµ Ù£Ù©Ù£ Ù…ÙƒØªØ¨Ø© Ø¯Ø§Ø± Ø¥Ø­ÙŠØ§Ø¡ Ø§Ø§ØªØ±Ø§Ø« Ø§Ù„Ø¹Ø±Ø¨ÙŠ                  
apabila ada seseorang mengetahui bahwa dirinya berpuasa sebagian jatuh pada malam hari (karena tinggal di daerah yang tidak diketahui batas siang dan malamnya), dan sebagian jatuh pada siang hari, sedangkan dia tidak mengetahui jumlah puasa yang dikerjakan pada siang harinya, maka menurut qoul yang jelas orang tersebut wajib mengambil hitungan yang diyakininya, maka hitungan puasa siang hari yang diyakininya itu cukup baginya (untuk dijadikan jumlah puasa siang harinya) dan wajib mengqadha sisanya puasa yang dilakukan pada malam harinya"""" .  wallahu a'lam                  
Dokumen Setelah Preprocessing                          
puasa mengqadha puasa jumlah laki lalai ibadah puasa bulan ramadhan bolong bolong niat bayar puasa ramadhan bolong lupa bolong laku dasar al-quran hadits wajib mengqadha puasa yakin hawasyi asy-syarwani puasa jatuh malam tinggal daerah batas siang malam jatuh siang jumlah puasa siang orang wajib ambil hitung hitung puasa siang jumlah puasa siang wajib mengqadha sisa puasa malam                                  
C. Proses Pemodelan Kalimat Menggunakan Convolutional Neural Network Selanjutnya akan dilakukan pemodelan semantic terhadap masing-masing kalimat pertanyaan dan jawaban di dalam dokumen. Dalam proses pemodelan semantik, digunakan model CNN. Metode CNN digunakan hanya untuk proses  pemodelan kalimat, bukan untuk proses klasifikasi seperti pada umumnya. Hyperparameters  yang dibutuhkan dalam menerapkan model CNN, yaitu inputan kata representasi (word embeddings), jumlah convolution filters, pooling strategies  (max-pooling), dan fungsi aktivasi. Dalam proses pemodelan semantik dengan CNN, terkait natural language processing , maka inputan yang digunakan berupa koefisien (nilai) dari masing-masing word embeddings  terhadap kosa kata yang ada dalam kalimat pertanyaan serta jawaban dimana direpresentasikan sebagai matriks dua dimensi. Word embeddings  diperoleh melalui cara seperti yang telah dijelaskan pada bab II. Data inputan untuk proses dalam memperoleh word embeddings  adalah berupa dokumen teks yang telah dipreproses dan output dari proses ini berupa beberapa word embeddings yang merepresentasikan suatu kata beserta koefisien word embeddings-nya (yang menunjukkan nilai kemiripan atau kedekatan makna antara kata dan word embeddings-nya yang diperoleh dari proses word embeddings), sehingga satu kata memungkinkan akan memiliki beberapa kata lain yang mungkin memiliki kedekatan makna. Dalam penelitian ini, dari hasil akhir proses word embeddings  untuk setiap kosa kata, diambil sebanyak 15 kata yang merepresentasikan sebuah kosa kata. Contoh output dari proses word embeddings  seperti terlihat pada Tabel 2. Hal selanjutnya yang dilakukan dalam tahap  model CNN adalah  mentransformasi semua kata tunggal (token) dalam kalimat (dalam hal ini direpresentasikan dalam bentuk koefisien dari masing-masing word embeddings  yang dimiliki setiap kata tunggal dalam kalimat) menjadi  vektor oleh lookup layer, kemudian mengubah nya (encode) menjadi fixed-length vector melalui convolutional layer  dan pooling layer dengan kedalaman layer 3. Dalam penelitian ini, filters slide melewati full rows sebuah matriks sehingga lebar filters slide  akan sama dengan lebar matriks inputan (jumlah word embeddings  yang akan digunakan untuk per kata). Sedangkan un tuk tinggi ( region size ) filters slide  atau sliding windows  melewati 3 kata. Convolutional layer  menerapkan matriks filter satu dimensi yang melewati tiap baris fitur dalam matriks kalimat. Pembelitan ( convolving ) filter yang sama dengan n-gram di setiap posisi dalam kalimat memungkinkan fitur-fitur untuk diekstrak secara bebas dari posisi mereka dalam kalimat.  Gambar 3 menunjukkan gambaran dari proses pemodelan kalimat menggunakan CNN dengan inputan berupa koefisien dari masing -masing word embeddings (d) terhadap kata tunggal (t) dalam kalimat yang akan dimodelkan hingga diperoleh output dari proses ini dalam bentuk fixed-length vector .                                         
D. Pencocokan Semantik Antara Kalimat Pertanyaan-Jawaban Menggunakan Neural Tensor Network                 
Fixed-length vector dari masing-masing kalimat dokumen pertanyaan dan jawaban yang diperoleh dari proses pemodelan kalimat dengan menggunakan CNN         akan diukur kecocokannya. Dalam penelitian ini, pencocokan  tersebut  dimodelkan dengan non-linear tensor layer , dimana sebelumnya sudah pernah diguna kan untuk pemodelan interaksi relasional data secara eksplisit [10]. Sebuah pertanyaan q dan jawabannya a, akan di gunakan dua CNN untuk memodelkan keduanya menjadi fixed vectors q  dan fixed vectors a . Berikutnya Neural Tensor Network, sebuah tensor layer yang diterapkan pada akhir dari CNN untuk memodelkan relasi a ntara pertanyaan dan jawabannya. Proses tersebut digambarkan seperti pada Gambar  4. Tensor layer  menghitung kecocokan pasangan pertanyaan -jawaban melalui score function seperti pada (1).  Tabel 2. Beberapa kosa kata dan word embeddings-nya 
Kosa Kata  Word Embeddings                          
puasa mati capai tinggal bawa bani ijtihad kalang warga bulan alami salah saleh        pimpin anggap uang 
mengqadha harun        saleh ahli dosa        majlis hasan ijma bani
puasa sedekah nyata cari takwil        anak makkah ibadah uang         nadzar jasa capai witir        santri negara          
qadha mudah izin pesantren nikah akibat                  
ajak kencing                                                  
ramadhan qobliyah amal hadir qunut jumat subuh                  
tahiyat        maghrib        tidal majlis harap shalatnya                 
neraka pahala fardhu                                          
niat arah mutlak jatuh taukid Tarik qobul batin          
talak hajar panitia jil        ijtihad        zain syar yakin  
bayar lunas negara pajak berat kena angsur riba          
ganti pecah izin qadha palsu Makkah akibat         
wajib                                                          
wajib  rugi qadha santri nadzar        jasa zakat negara          
fidyah nishab akibat masyhur daerah pindah                  
pajak berat                                                 
Gambar 3. Deskripsi pemodelan kalimat menggunakan CNN 
Gambar 4.  Pencocokan kalimat antara pertanyaan dan jawaban [4]                                                         
-1                                                        
dimana f = tanh adalah standard nonlinearity,         
ð‘€[1:ð‘Ÿ]âˆˆð‘…ð‘›ð‘  ð‘¥ ð‘›ð‘  ð‘¥ ð‘Ÿadalah sebuah tensor , r adalah jumlah tensor slice , dan parameter yang lainnya adalah bentuk standar dari neural network , ð‘‰ âˆˆ ð‘…ð‘Ÿ ð‘¥ 2ð‘› ð‘ , ð‘ âˆˆ ð‘…ð‘Ÿ dan ð‘¢ âˆˆ ð‘…ð‘Ÿ.                                 
Parameter dalam penelitian ini adalah L, ð‘Šð¶ð‘ð‘ð‘ž,                 
ð‘Šð¶ð‘ð‘ð‘Ž, u, ð‘€[1:ð‘Ÿ], V, dan b. Dimana L adalah word embeddings , ð‘Šð¶ð‘ð‘ð‘ž dan ð‘Šð¶ð‘ð‘ð‘Ž adalah parameter dari CNN untuk pertanyaan dan jawaban, dan parameter lainnya dari tensor layer . Objective function-nya adalah (2).                 
-2                                                        
dimana Î³ > 0 (dalam penelitian ini nilainya 1) adalah maximum margin , dan ( q, aâ€™) adalah pasangan pertanyaan-jawaban yang salah (random). C adalah kumpulan data latih dari pasangan pertanyaan-jawaban dalam  dokumen dan Câ€™ menunjukkan kumpulan dari seluruh pasangan pertanyaan- jawaban yang salah. Dan untuk optimasinya, digunakan L- BFGS.  Selanjutnya, fixed-length vector dari kalimat query  dan dokumen jawaban akan diukur kecocokannya pada sisi testing. Output dari tahapan ini, yaitu berupa nilai kecocokan antara query dan jawaban dari arsip dokumen penelitian.                                                         
IV. HASIL DAN PEMBAHASAN                         
Untuk uji coba, jumlah pasangan dokumen yang digunakan terdiri dari 200 dokumen tanya-jawab dan akan diujikan untuk 5 pertanyaan baru ( query ) yang diinputkan penanya . Masing-masing dari query tersebut akan dibandingkan terhadap 200 dokumen tanya-jawab dengan tujuan untuk mendapatkan pertanyaan yang relevan terhadap query dengan menggunakan metode CNN.  Output dari penelitian berupa nilai kecocokan antara query  dan dokumen jawaban  yang diperoleh menggunakan neural tensor network  dengan menerapkan (1) dan (2)  sebagaimana yang telah dijelaskan pada bab III . Output tersebut akan dikembalikan kepada penanya dalam bentuk tampilan dokumen pertanyaan-jawaban dari arsip berdasarkan urutan nilai kecocokan tersebut. Pertanyaan-jawaban yang dikembalikan  dinilai secara objektif  apakah relevan atau tidak terhadap query . Selanjutnya dilakukan evaluasi dan validasi terhadap dokumen tanya-jawab hasil temu kembali dengan cara mengukur kualitas  hasil temu Kembali pertanyaan. Parameter yang digunakan untuk mengukur kualitas hasil temu kembali tersebut  adalah mean average precision  (MAP) dimana secara luas digunakan dalam question retrieval. Mean average precision  untuk satu set query  adalah rata-rata dari nilai presisi  rata-rata (average precision ) untuk setiap query  yang dihitung menggunakan (3).                                                    (3) dimana Q adalah jumlah query  dan AveP  diperoleh dari (4)  untuk masing-masing query . Average precision (AveP) adalah rata-rata nilai  presisi yang diperoleh untuk kumpulan k dokumen teratas yang ada setelah  setiap dokumen yang relevan di-retrieve, dan nilai ini kemudian dirata -ratakan berdasarkan kebutuhan informasi . 
ð´ð‘£ð‘’ð‘ƒ =âˆ‘ (ð‘ƒ(ð‘˜)Ã—ð‘Ÿð‘’ð‘™ (ð‘˜))ð‘›ð‘˜=1                                                        
ð‘›ð‘¢ð‘šð‘ð‘’ð‘Ÿ ð‘œð‘“ ð‘Ÿð‘’ð‘™ð‘’ð‘£ð‘Žð‘›ð‘¡ ð‘‘ð‘œð‘ð‘¢ð‘šð‘’ð‘›ð‘¡ð‘            (4)                         
n adalah jumlah dokumen yang di-retrive , P(k) adalah nilai presisi dokumen di peringkat k yang dihitung menggunakan (5), dan rel(k) merupakan fungsi indikator yang bernilai 1 jika dokumen di peringkat k adalah dokumen yang relevan, jika tidak maka bernilai 0. Jika  dokum en yang relevan tidak di-retrieve  sama sekali, maka nila i pada (4) dianggap  0 [11].                                         
-5                                                        
Dalam penelitian ini, nilai precision yang dihitung merupakan nilai precision  pada masing-masing 10 dokumen teratas dari hasil temu kembali ( top-10 retrieved documents ), atau disebut juga sebagai precision @10. Kelima query, selain di uji coba kan terhadap metode CNN juga di uji cobakan terhadap metode VSM ( vector space model ) dalam tahapan proses mencari dan menemukan dokumen pertanyaan yang sama secara semantik dari dalam koleksi dokumen tanya -jawab terhadap query. Gambar 5 memperlihatkan grafik perbandingan nilai precision  masing -masing dokumen pertanyaan-jawaban  hasil temu  kembali ( retrieve ) terhadap query-1 yang berada di urutan 10 dokumen teratas hasil pencarian dengan menggunakan metode CNN dan VSM . Nilai precision tersebut diperoleh menggunakan (5). 10 dokumen pertanyaan-jawaban yang ditemukan dengan menggunakan metode CNN berbeda dengan yang ditemukan dengan menggunakan metode VSM. Untuk nilai precision  dari hasil temu kembali dokumen pertanyaan terhadap masing-masing query-2, query-3, query-4, dan query-5 yang berada di urutan 10 dokumen teratas hasil pencarian menggunakan metode CNN dan VSM, dapat dilihat grafik perbandingannya pada Gambar 6, Gambar 7, Gambar 8, dan Gambar 9. Sepuluh dokumen pertanyaan-jawaban  yang ditemukan oleh kedua metode tersebut berbeda-beda. Kelima query inputan tersebut masing-masing mengembalikan beberapa dokumen pertanyaan-jawaban  dari dalam koleksi  dokumen tanya-jawab sebagai hasil temu kembali dari proses pencarian.                                         
Gambar 5. Grafik perbandingan nilai precision antara dokumen pertanyaan hasil temu kembali query-1 menggunakan metode CNN dan VSM                                          
Gambar 6 . Grafik perbandingan nilai precision antara dokumen pertanyaan hasil temu kembali query-2 menggunakan metode CNN dan VSM                                  
Gambar 7 . Grafik perbandingan nilai precision antara dokumen pertanyaan hasil temu kembali query-3 menggunakan metode CNN dan VSM                                  
Gambar 8 . Grafik perbandingan nilai precision antara dokumen pertanyaan  hasil temu kembali query-4 menggunakan metode CNN dan VSM                                  
Dokumen pertanyaan-jawaban yang dikembalikan tersebut, oleh sistem dianggap memiliki kerelevanan dengan query. Namun hanya diambil 10 dokumen pertanyaan dalam peringkat teratas yang dikembalikan oleh sistem untuk dij adikan acuan penilaian evaluasi  terhadap hasil temu Kembali pertanyaan oleh sistem . Dari hasil tersebut, dapat dihitung nilai average precision-nya untuk masing-masing query  inputan menggunakan (4). Sehingga diperoleh nilai average precision  terhadap hasil temu kembali dokumen pertanyaan menggunakan metode CNN untuk query  inputan pertama hingga kelima berturut-turut yaitu, 0,25, 0,33, 0,33, 1, dan 0,2. Sedangkan nilai average precision  terhadap hasil temu kembali dokumen pertanyaan menggunakan metode VSM untuk query  inputan pertama hingga kelima berturut-turut yaitu, 1, 0 ,21, 0, 0,2, dan 0.                          
Gambar 9 . Grafik perbandingan nilai precision antara dokumen pertanyaan  hasil temu kembali query-5         menggunakan metode CNN dan VSM                                  
Tabel 3. Average precision  (AveP) untuk hasil temu kembali pertanyaan menggunakan CNN dan VSM                 
Query  Inputan         Ke-Kalimat Query  AveP(CNN)  AveP(VSM)  
1 assalamualaikum... apakah wajib mencabut sesuatu yang palsu dari tubuh 0,25 1                           
Query Inputan Ke- Kalimat Query  AveP(CNN)  AveP(VSM)  jenazah sebelum dikubur?                                  
2 perintah membaca taâ€™awudz dalam al-quran.  assalamualaikum... saya pernah dengar seorang khatib ketika akan mengucapkan ayat al-quran begini â€œqoolallaahhu taâ€™ala fil qur anil adzim.. a uâ€™dzubillahhi minasysyaithonirrojimâ€ setelah itu baru membaca ayat al-quran. pertanyaan saya :                                  
1. apa khatib itu termasuk berbohong? karena di dalam al-quran tidak ada  bacaan taâ€™awudz.                          
2. solusinya yang tepat gimana?  0,33 0,21                 
3 assalamuâ€™alaikum. kepada para kyai dan member. mohon ditakwilkan mengenai mimpi meninggal dunia. sekian dan terimakasih sebelumnya  0,33 0                                 
4 assalamualaikum...  bagaimana hukum muamalahnya bensin oplosan / campuran ? apakah termasuk tindak kriminal ?  1 0,2                                                         
5 assalaamu'alaikum. afwan, mohon pencerahannya... hal -hal apa sajakah yang di senangi oleh allah swt ? sehingga allah swt memberi ridho dan rahmat-nya kepada orang tersebut ? syukron kat sir 0,2 0                                 
Nilai MAP  untuk sekumpulan uji coba  adalah rata-rata dari nilai average precision untuk setiap query . MAP  dipengaruhi oleh bobot dari setiap query yang  dilaporkan dalam bentuk penilaian average precision  tiap query , baik itu diperoleh banyak dokumen pertanyaan yang relevan dengan query  maupun yang sangat sedikit yang relevan dengan query . Nilai MAP untuk keseluruhan uji coba terhadap lima query  yang berbeda tersebut dengan metode CNN  dihitung menggunakan (3), sehingga diperoleh  nilai MAP -nya yaitu 0,422 . Sedangkan nilai MAP untuk keseluruhan uji cob a dengan metode VSM  yaitu 0,282.                  
Gambar 10. Grafik perbandingan nilai average  precision  antara hasil temu kembali menggunakan  metode CNN dan VS M                                                         
V. SIMPULAN                                          
Kemampuan metode convolutional neural network dalam menemukan pertanyaan yang sama secara semantik dengan query  dari dalam arsip dokumen tanya-jawab bernilai 0,422 berdasarkan hasil hitungan mean average precision-nya (MAP). Sedangkan pencarian dengan menggunakan vector space model, MAP-nya bernilai 0,282. Untuk memperoleh nilai MAP yang lebih besar lagi (mendekati 1), dapat dilakukan penelitian lebih lanjut dengan kemungkinan menggabungkan penggunaan metode pengelompokkan dokumen untuk proses pencarian yang lebih efisien atau penggunaan metode pencarian yang lainnya.                                                         
DAFTAR PUSTAKA                                          
[1] K. Wang, Z. Ming, and Tat -Seng Chua, """"A Syntactic Tree Matching Approach to Finding Similar Question in Community -based QA Services,"""" in Proceedings of SIGIR ,         2009, pp. 187 -194.                                         
[2] J. Turian, L. Ratinov, and Y. Bengio, """"Word Representations: A Simple and General Method for Semi -supervised Learning,"""" in Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics , Sweden, 20 10, pp. 384 -394.                                 
[3] R. Collobert et al., """"Natural Language Processing (Almost) from Scratch,"""" The Journal of Machine Learning Research , vol. 12, pp. 2493 -2537, 2011.                  
[4] Xipeng Qiu and Xuanjing Huang, """"Convolutional Neural Tensor Network Architecture for Community-based Question Answering,"""" in Proceedings of the Twenty-Fourth International Joint Conference on Artificial Intelligence (IJCAI) , 2015, pp. 1305 -1311.                          
[5] T. Mi kolov and G. Zweig, """"Context Dependent Recurrent Neural Network Language Model,"""" in Spoken Language Technology (SLT) , 2012, pp. 234 -239.                         
[6] N. Kalchbrenner and P. Blunsom, """"Recurrent Continuous Translation Models,"""" in Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, Seattle, 2013, pp. 1700 -1709.                          
[7] J. Gao, X. He, and Jian -Yun Nie, """"Clickthrough -Based Translation Models for Web Search: from Word Models to Phrase Models,"""" in Proceedings of the 19th ACM International Conference on Information and Knowledge Management , Canada, 2010, pp. 1139 -1148.                  
[8] N. Kalchbrenner, E. Grefenstette, and P. Blunsom, """"A Convolutional Neural Network for Modelling Sentences,"""" in Proceedings of ACL , 2014.                          
[9] Baotian Hu, Zhengdong Lu, Hang Li, and Qingcai Chen, Convolutional Neural Network Architectures for Matching Natural Language Sentences,"""" in Proceedings of the 27th International Conference on Neural Information Processing Systems , Canada, 2014, pp. 2042 -2050.                  
[10] Richard Socher, Danqi Chen, Christopher D. Manning, and Andrew Y. Ng, """"Reasoning With Neural Tensor Networks for Knowledge Base Completion,"""" in Proceedings of the 26th International Conference on Neural Information Processing Systems , Nevada, 2013, pp. 926 -934.                         
[11] C. D. Manning, P. Raghavan, and H. Schutze, An Introduction to Information Retrieval . England: Cambridge University Press, 2009.",Question-Answer,"Convolutional Neural Network, CNN, Vector Space Model, VSM",dokumen pertanyaan-jawaban yang diambil dari komunitas tanya-jawab online,precision
Menerapkan Algoritma NN Pada Chatbot Mengenai Pariwisata Menerapkan Algoritma Neural Network  Pada Chatbot Mengenai Pari wisata Di Provinsi Bangka Belitung,"Menerapkan Algoritma NN Pada Chatbot Mengenai Pariwisata Menerapkan Algoritma Neural Network  Pada Chatbot Mengenai Pari wisata Di Provinsi Bangka Belitung

Ristian Mahendra1, Mia Kamayani2

Abstract  
Bangka Belitung Province, precisely in South Bangka regency, is one of the areas that have the potential to be visited by tourists. However, not all attractions are known by tourists due to lack of information. From these problems, researchers tried to d evelop a chatbot system. Chatbot is a program that conducts conversations between humans and machines using human language. This chatbot system aims to help tourists do questions and answers automatically to find 
information about tourist attractions in South Bangka. The chatbot system applies a model with a natural language processing approach and neural network algorithms. This study aims to create a chatbot model that can provide information with good accuracy about paratourism 
in Bangka Belitung Provin ce, especially South Bangka district. The data used in this study were the results of interviews and filling out questionnaires to the community. Then the data obtained is stored and converted into JSON format consisting of 173 tags, 618 patterns, and 187 responses. Then preprocessing the data was carried out by taking 25 random test questions. The results of the chatbot system accuracy test got an accuracy score of 92% from 25 questions asked randomly by getting an error value of 8%. From the results of ac curacy testing, the chatbot system gets a response by looking at the appropriate questions asked by users based on tags, so that they can get the right answer.  
 
Keywords : South Bangka
 
 
Abstrak  
Chatbot merupakan program yang melakukan percakapan antara manusia dengan mesin dengan menggunakan bahasa manusia . Sistem chatbot  ini bertujuan untuk membantu wisatawan melakukan tanya jawab secara otomatis untuk mencari sebuah informasi mengenai objek wisata yang ada di Bangka Selatan.  Sistem chatbot menerapkan sebuah model dengan pendekatan Natural language processing dan algoritma neural networks.  Penelitian ini bertujuan untuk menciptakan sebuah model chatbot yang bisa memberikan informasi dengan akurasi  yang baik mengenai pari wisata yang ada di Provinsi Bangka Belitung khususnya kabupaten Bangka Selatan. Data yang digunakan dalam penelitian ini adalah hasil dari wawancara dan pengisian kuesioner ke masyarakat. Kemudian data yang didapatkan disimpan dan diubah kedalam bentuk format JSON yang terdiri dari 173 tag, 618 patterns, dan  187 responses . Lalu dilakukan preprocessing data dengan mengambil data test sebanyak 25 pertanyaan secara random . Hasil pengujian akurasi sistem chatbot mendapatkan sebuah nilai akurasi sebesar 92% dari 25 pertanyaan yang ditanyakan secara random  dengan mendapatkan nilai kesalahan sebesar 8%. Dari hasil uji coba akurasi sistem chatbot mendapatkan sebuah respon dengan melihat pertanyaan sesuai yang diajukan user  berdasarkan tag, sehingga dapat mendapatkan jawaban yang tepat.  
 
Kata Kunci : Bangka Selatan

1. PENDAHULUAN  
Bangka  Belitung  adalah  sebuah  provi nsi di Indonesia  dengan  dua pulau  utama,  Bangka  dan Belitung.  Ada  tujuh  kabupaten  di Bangka  Belitung: Kabupaten  Bangka  Tengah,  Kabupaten  Bangka  Selatan,  Kabupaten  Bangka, Kabupaten  Bangka  Barat, Kabupaten  Belitung,  Kabupaten  Belitung  Timur, dan Kota  Pangka lpinang  yang  merupakan  ibu kota  provinsi.  Ada  banyak  tempat  wisata  menarik  yang  wajib  dikunjungi  di Bangka  Belitung  [1]. Akan tetapi, tidak semua objek wisata yang diketahui oleh wisatawan karena 
keterbatasan informasi.  Wisatawan biasanya mencari informasi mengenai seputaran objek wisata di website. Pencarian sebuah informasi di  website ternyata kurang efektif dan jelas. Atas masalah itu perlu dibuat program 
aplikasi yang memudah kan wisatawan agar lebih interaktif. Wisatawan bisa melakukan sebuah proses Tanya jawab dengan menggunakan chatbot  untuk mendapatkan sebuah informasi.  
Chatbot merupakan program yang melakukan sebuah percakapan 
antara manusia dengan mesin memakai bahasa manusia [2]. Secara  umum  chat  terdiri  dari  dua kata  yaitu  chat  dan bot. Dalam  dunia  komputer,  chat  dapat  diartikan  sebagai  kegiatan  komunikasi  yang  menggunakan  tulisan.  
Pada saat  yang  sama,  bot adalah  program  yang  memiliki  informasi  yang,  ketika  dimasukkan,  menghasilkan  keluaran  sebagai  respons   [3]. Dalam membuat chatbot  membutuhkan sebuah model untuk melakukan proses  training  data dan testing  dengan menggunakan sebuah algoritma machine learning  yaitu Neural Network  [4]. Salah satu algoritma pembelajaran mesin yang paling populer sekarang adalah algoritma jaringan saraf tiruan atau neural network [5]. Jaringan saraf tiruan merupakan gagasan bag aimana 
aturan kerja otak bekerja dan diimplementasikan ke dalam Komputer [6]. Penelitian yang berkaitan dengan implementasi chatbot meng gunakan algoritma neural network . Pertama penelitian dari Deby Fambayun, Frigit , Asrofi Buntoro, Ghulam, Masykur, Fauzan â€œPenerapan Algoritma Neural 
Network  Pada Chatbot Bahasa Jawa Tingkat Tutur Krama Alus â€, 2022  menjelaskan bahwa dengan menggunakan metode Neural Network  untuk  desain  chatbot  mencapai  akurasi  0,9 dan pengujian usability,  aplikasi mendapatkan nilai Akurasi 72,8% dan mendapatkan predikat baik [6]. Kedua penelitian dari I. Ruben and T. Lesmana, â€œImplementasi Neural Network  
untuk Pembuatan Chatbot  Menggunakan Dataset Pertanyaan Mahasiswa, 2022. Penelitian dibuat bertujuan untuk melakukan sebuah model agar bisa digunakan untuk melatih aplikasi â€œchatbotâ€  yang  tahu  bagaimana  menjawab  pertanyaan  dari  mahasiswa  tentang  permasalahan  yang  ada di dalam buku panduan mahasiswa Kalbis Institute . Tahap pengujian dari penelitian ini adalah  untuk  mendapatkan  hasil  model  yang  ketika  dilatih  1000  kali memberikan  hasil  akurasi  98% dan nilai  loss  sebesar  0,05275  [7]. Ketiga penelitian Fadli, Muhammad Furqon, Buntoro,  Ghulam Asrofi, Masykur, Fauzan, â€œPenerapan Algoritma Neural Network Pada Chatbot Pmb Universitas Muhammadiyah Ponorogo Berbasis Web â€  penelitian ini dibuat agar memudah kan menemukan sebuah informasi dengan benar dan cepatseperti apa yang ingin ditanyakan mengenai masalah dalam PMB Universitas Muhammadiyah Ponogoro dan menjelas kan hasil akurasi sebuah model dengan menggunakan neural network dengan tingkat akurasi 0.8% [8].  Penelitian Keempat Hikmah, Alifya, Azmi, Fairuz, Nugrahaeni, Ratna Astuti â€œImplementasi Natural Language Proce ssing  Pada Chatbot  Untuk Layanan Akademikâ€ penelitian ini mendapatkan hasil pengujian akurasi sebesar 100% dengan menggunakan algoritma neural network  [9].  Keenam penelitian dari T. A. Zuraiyah, D. K. Utami, and D. Herlambang, â€œImplementasi Chatbot Pada Pendaftaran Mahasiswa Baru Menggunakan Recurrent Neural Networkâ€ , 
2019. Penelitian  ini dibuat untuk mencip takan sistem chatbot  langsung yang bisa berinteraksi terhadap manusia tentang informasi pendaftaran siswa baru memakai algoritma RNN untuk pendataan teks.  Hasil uji coba dalam Penelitian ini menggunakan confusion matrix  mend apatkan  nilai akurasi  sebesar 88%, untuk presisi  95% dan recall 92% [10] . Berdasarkan uraian diatas, penelitian ini bertujuan untuk menciptakan sebuah model chatbot  dengan memberikan informasi akurasi yang baik mengenai pari wisata yang 
ada di Bangka Belitung tepatnya di Bangka Selatan dan memakai sebuah algoritma neural network.  
 
2. METOD OLOGI  PENELITIAN  
Pada penelitian penulis melakukan beberapa tahapan, yaitu tahap pertama melakukan sebuah identifikasi mas alah yang akan diteliti, kemudian melakukan liter atur review  terhadap topik dengan melihat pene litian terdahulu termasuk metode atau algoritma yang digunakan. Setelah itu 
peneliti melakukan pengumpulan data yang diperlukan yang dimana data yang didapatkan akan dirubah file menjadi JSON. Data  dihasilkan  dalam  file JSON   akan dilakukan sebuah tahap  preprocessing  data dimana data tersebut dibagi  menjadi  dua bagian,  yaitu  90%  data  latih  dan 10%  data  uji  tersebut akan digunakan untuk membuat model dengan menggu nakan metode algoritma neural network . Setelah model dibuat akan dilakukan tahap training model yang dimana untuk melihat sebuah akurasi yang didapatkan terbaik, setelah itu dilakukan sebuah pengujian untuk melihat apakah algoritma yang digunakan merespon dengan baik atau tidak. Berikut alur 
metodologi penelitian menggunakan algoritma neural network  diGambar kan di Gambar  1.  
Gambar  1. Alur Penelitian  
2.1. Pengumpulan Data  
Saat mengumpulkan data dilakukan dengan cara wawancara serta kuisioner kepada masyar akat untuk mencari sebuah informasi apa saja yang ingin ditanyakan seputar wisata yang terdapat di Bangka Belitung utamanya kabupaten Bangka Selatan. Setelah melakukan wawancara dan penyebaran kuesioner maka data yang nanti didapatkan akan dibuat ke dalam bentuk 
berformat JSON  [10] . Dataset dalam json memiliki format, sebagai berikut [11] : 
a) Tag adalah sebuah kategori yang digunakan untuk sebuah program dalam menentukan respon.  
b) Patterns  adalah sebuah kalimat berupa pertanyaan yang ingin ditanyakan/diharapkan oleh user  
c) Respons  adalah sebuah jawaban diberikan sesuai dengan  pertanyaan  yang diajukan sesuai dengan tag dan patterns.   
2.2. Pre-Processing Data  
Dalam tahap pre-processing, data diolah menggunakan  metode natural language processing. NLP ( Natural language processing ) yaitu kemampuan untuk melatih  mesin agar   dapat  memahami  dan mengerti  arti dari  bahasa  manusia  dan meresponnya  [12] . Tahap dari  preprocessing  data yang 
terdapat di  dalam natural language proce ssing  yaitu case folding, tokenizing, stemming dan bag of word [8]. 
a) Case Folding  yaitu  suatu proses mengubah  semua kalimat  menjadi huruf kecil dan meng hapuskan  karakter selain huruf   [13] . Proses dari case folding  terdapat di  Gambar  2.  
Gambar  2. Casel Folding   
b) Tokenizing  yaitu  sebuah proses mengubah kalimat menjadi  sebuah kata berdasarkan spasi  [12] . Prose dari tokenizing pada Gambar  3.  
Gambar  3.  Tokenizing   
c) Stemming  yaitu Proses mengubah kata yang memiliki kata berimbuhan  dari hasil tokenizing  menjadi kata dasar [14] . Proses stemming pada Gambar  4. 
Gambar  4. Stemming  
d) Bag Of Word  yaitu Proses pengumpulan kal imat menjadi kata ke dalam bentuk array atau matriks  lalu memodelkan setiap kata dengan menghitung kemunculan dari setiap kata  [15]  seperti tabel  1 dibawah ini.    
Tabel 1.  Bag Of Word  
Kata  Bag Of Vector  
Wisata  1 0 0 0 0 0 
yang  0 1 0 0 0 0 
terdapat  0 0 1 0 0 0 
Di 0 0 0 1 0 0 
bangka  0 0 0 0 1 0 
selatan  0 0 0 0 0 1  
2.3. Algoritma Neural Network  
Jaringan saraf tiruan atau Neural Network  (NN) adalah suatu algoritma komputer yang memiliki kemampuan untuk memecahkan masalah yang kompleks. Algoritma ini bekerja dengan meniru proses kerja otak, di mana terdapat sejumlah neuron sebagai unit pemroses informasi yang terhubung dalam lapisan-lapisan dan saling berinteraksi  melalui koneksi sinaptik dengan bobot tertentu, sehingga menghasilkan keluaran (output) yang 
diinginkan [16] . Neural network  memiliki 3 jenis layer  yaitu [17]  yaitu Input layer  berfungsi menerima input, Hidden l ayer  berfungsi untuk memproses  input dan Output layer  berfungsi untuk menghasilkan output. Model dari 
arsitektur neural network  bisa di lihat pada Gambar  5:  
Gambar  5. Arsitektur Neural Network   
Setiap  lapisan  NN memiliki  fungsi  aktivasi.  Fungsi  aktivasi  adalah  fungsi  yang  menentukan  apakah  output  dari  sebuah  neuron  adalah  linear  atau  non-linear.  Fungsi  aktivasi  yang  digunakan  dalam  penelitian  ini adalah:   
a) Fungsi  Aktivitas ReLU  
Fungsi ReLU ( Rectified Linear Unit ) adalah fungsi aktivasi sederhana yang mengubah nilai negatif menjadi nol tanpa operasi eksponensial, perkalian, atau pembagian. Persamaan (1) dan (2) digunakan untuk menjelaskan fungsi aktivasi ReLU.     
( ) (   )                                                    (1) 
( )  *                                             (2)  
b) Fungsi aktivitas sofmax  
Fungsi softmax adalah fungsi aktivasi yang digunakan untuk melakukan klasifikasi multi-kelas berdasarkan probabilitas tertinggi. Fungsi ini menghasilkan nilai probabilitas keluaran antara 0 dan 1. Persamaan (3) mengGambarkan fungsi softmax.  
( )     (  )
âˆ‘   (  ) 
                       ( ) 
Saat  membuat  model  neural  network,  beberapa  parameter  digunakan  untuk  pelatihan  model,  yaitu [18]  : 
a. Epoch  adalah proses pengu langan dalam pelatihan model untuk mencari sebuah akurasi dari model yang terbaik dan error yang kecil.  
b. Batch size  yaitu proses penyebaran total sampel data selama pelatihan mode.  
c. Iteration  yaitu total batch  dalam proses epoch  untuk melewati feedword dan backward. 
d. Loss  yaitu melihat nilai error yang agar model yang buat sangat baik.   
2.4. Training Model  
Proses pelatihan menggunakan algoritma jaringan syaraf tiruan atau neural network, yaitu rangkaian feedforward dimana neuron dihubungkan dengan suatu bobot. Melatih data membuat model untuk memprediksi pertanyaan yang dimasukkan oleh pengguna. Didalam proses training model  terdiri dari tiga jenis lapisan yakni input layer, hidden layer dan output layer . Pada proses training  data dari hidden layer  digunakan fungsi aktivasi ReLU, sedangkan pada output layer  digunakan fungsi aktivasi Softmax.    
2.5. Pengujian  
Uji coba  ini dilakukan untuk  melihat  bahwa  chatbot  yang  dibuat  mampu beroperasi  dengan  tepat  setelah  dibuat  dan didesain.  Kemudian proses  tahap  uji coba  ini, model yang  sudah  dibuat  akan di  test untuk melakukan  proses  tanya  jawab  tentang  pari wisata yang terdapat di Bangka Belitung khususnya di kabupaten Bangka Selatan. Pengujian dilakukan dengan mengambil 25 pertanyaan untuk meninjau apakah chatbot  dapat me mberikan respon dari pertanyaan yang diajukan. Untuk melihat sebuah akurasi model dan kesalahan jawaban agar tid ak terjadi overfitting  dapat menggunakan perhitungan (4) dan (5):                        
                          ( ) 
                              ( ) 
 
3. HASIL DAN PEMBAHASAN  
Data yang dipakai dalam penelitian adal ah data hasil dari pengisian kuesioner  dan wawancara kepada masyarakat. Kemudian data yang didapatkan di simpan dan diub ah kedalam bentuk format JSON yang terdiri dari 173 tag, 618 patterns,  dan 187 responses . Contoh  dataset untuk berbagai  jenis  pertanyaan  dari  pengguna  dengan  maksud  khusus  untuk  obrolan  dan jawaban  terkait  pertanyaan  seperti  yang  ditunjukkan  pada  Gambar  6 Jika pola  yang  cocok  ditemukan,  sistem  mengirimkan  respon ses kembali  ke pengguna.  Namun,  jika pola  tidak  ditemukan,  bot akan  memberikan  responses default  [19] .    
Gambar  6. Data set JSON   
Setelah dataset dibuat, akan dilakukan preprocessing  data. Kemudian dilakukan proses yaitu case folding, tokenizing, stemming dan bag of word. Hasil dari pre-processing  mendapatkan 127 token atau kata unik dan 173 tag.  Hasil dari stemming kata diubah seperti angka array yaitu 0 dan 1. Data dibagi menjadi 2 yaitu data train  x dan train  y. Data train  x array token sedangkan train  y berisi aray tag. Hasil dari proses case folding  dapat dilihat di Gambar  7, hasil proses stemming  dilihat di Gambar  8, dan bag of word  dilihat di Gambar  9.   
Gambar  7. Hasil Case Folding  
Gambar  8. Hasil Stemming    
Gambar  9. Hasil Bag Of Word   
Setelah melakukan tahap pre-processing  data, selanjutnya akan dilakukan training  menggunakan  algoritma neural network  sebuah model dengan inputan  4 layer yaitu layer  pertama menggunaka n 128 perceptron  untuk melatih data dengan menerapkan fungsi aktivitas ReLU. Layer  kedua menggunakan hidden layer  dan perceptron  sebanyak 200 dengan menerapkan fungsi aktivitas ReLU. Layer  ketiga menggunakan hidden layer  dan perceptron  layer 100 dengan fungsi aktivitas ReLU. Dan terakhir menggunakan Dense Output Layer  sebanyak 16 neuron dengan menggunakan fungsi Softmax.   
Dari model yang telah dibuat akan dilakukan proses dalam pelatihan data yang dijalankan dengan berkali -kali dan tersusun sehingga mendapatkan sebuah skor akurasi yang terbaik dan memiliki nilai loss yang sangat kecil. Hasil nilai dari sebuah akurasi dan loss diGambar kan dengan 
grafik. Dalam hasil training untuk membuat mode l terbaik dengan dilakukan iterasi dengan epoch  250,500,700  dan 1000 terdapat pada table 2 :  
Tabel 2. Pelatihan Data  
Pengujian  Epoch  Akurasi  Loss  
1 250  0.6866  0.9714  
2 500  0.8546  0.5128  
3 700  0.9338  0.2924  
4 1000  0.9709  0.1252  
Dari hasil tabel 2 yang dim ana menerapkan nilai epoch  yang berbeda, hasil pengujian ke-4 dengan nilai epoch 1000 yang memiliki performa model yang paling baik. Oleh sebab itu model yang diambil yaitu model hasil pengujian ke-4. Hasil dari nilai akurasi dan loss pada pengujian model bisa dilihat di Gambar  14 berikut :   
Gambar  10.  Hasil Training  model   
3.1. Implementasi aplikasi  
3.1.1.  Tampilan Chatbot  
Tampilan chatbot  yaitu suatu proses yang digunakan user untuk melakukan sebuah percakapan antara pengguna dengan  bot mengenai pertanyaan informa si seputaran objek wisata Bangka selatan [20] . Tampilan chatbot  terdapat pada Gambar  11.  
Gambar  11. Tampilan Halaman Chatbot  
3.1.2.  Pengujian Sistem Chabot  
Pada pengujian sistem chatbot  melakukan Uji akurasi  yang bertujuan untuk mengetahui  dan mengevaluasi  apakah  sistem  chatbot  ini memiliki akurasi  yang  tepat  atau  tidak.  Kemudian, pada pengujian sistemnya dilakukan pengujian dengan memberikan 25 pertanyaan mengenai objek wisata yang ada di Bangka Selatan. Dari hasil pengujian 25 pertanyaan 
mendapatkan 23 pertanyaan yang benar dan 2 pertanyaan yang salah. Cara menghitung akurasi dan kesalahan bisa dilihat di persamaan (3) dan (4):                                                             
Berdasarkan perhitungan akurasi dan kesalahan pada persamaan (1) dan (2) mendapatkan sebuah akurasi sebesar 92% serta kesalahan 8%. Berikut ini contoh hasil pengujian 3 pertanyaan dalam tampilan Chabot  dilihat pada Gambar  18: 
Gambar  12. Tampilan Halaman Chatbot  Hasil Interaksi  
 
4.  SIMPULAN  
Berdasarkan hasil penelitian diatas, peneliti dapat mengambil beberapa kesimpulan bahwa h asil dari pembuatan Chabot agar membantu wisatawan dalam mencari informasi mengenai objek wisata yang ada di Bangka Selatan.  Dalam menggunakan algoritma neural networks  berhasil diterapkan pada chatbot  sehingga dapat menjawab pertanyaan yang diajukan oleh user dengan baik.  Hasil pengujian akurasi sistem chatbot  mendapatkan sebuah nilai akurasi sebesar 92% dari 25 pertanyaan yang ditanyakan secara random  dengan mendapatkan nilai kesalahan sebesar 8%.  
 
DAFTAR PUSTAKA  
[1] Y. Megawandi, â€œPembangunan Pariwisata di Provinsi Kepulauan Bangka  Belitung dalam Pendekatan Whole of Government,â€ J. Widyaiswara Indones., vol. 1, no. 2, pp. 108 â€“119, 2020, [Online]. Available: http://ejournal.iwi.or.id/ojs/index.php/iwi/article/view/27/26  
[2] V. R. Prasetyo, N. Benarkah, and V. J. Chrisintha, â€œImplemen tasi Natural Language Processing Dalam Pembuatan Chatbot Pada Program Information Technology Universitas Surabaya,â€ Teknika , vol. 10, no. 2, pp. 114 â€“121, 2021, 
doi: 10.34148/teknika.v10i2.370.  
[3] D. Irga, B. N. Fakhri, C. Prianto, and S. Fachri Pane, â€œSem inar Nasional Informatika dan Aplikasinya (SNIA) 2021 ISSN: 2686 -6595 Cimahi,â€ pp. 1 â€“8, 2021.  
[4] N. A. Purwitasari and M. Soleh, â€œImplementasi Algoritma Artificial Neural Network Dalam Pembuatan Chatbot Menggunakan Pendekatan Natural Language Parocessing, â€ J. IPTEK , vol. 6, no. 1, pp. 14 â€“21, 2022, doi: 
10.31543/jii.v6i1.192.  
[5] N. Nurmila, A. Sugiharto, and E. A. Sarwoko, â€œAlgoritma Back Propagation Neural Network Untuk Pengenalan Pola Karakter Huruf Jawa,â€ J. Masy. Inform. , vol. 1, no. 1, pp. 1 â€“10, 2010,  doi: 10.14710/jmasif.1.1.74.  
[6] F. Deby Fambayun, G. Asrofi Buntoro, and F. Masykur, â€œPenerapan Algoritma Neural Network Pada Chatbot Bahasa Jawa Tingkat Tutur Krama Alus,â€ J. Tek. Inform. , vol. 14, no. 1, pp. 40 â€“46, 2022.  
[7] I. Ruben and T. Lesmana, â€œI mplementasi Neural Network untuk Pembuatan Chatbot Menggunakan Dataset Pertanyaan Mahasiswa,â€ vol. 8, no. 1, pp. 573 â€“581, 2022.  
[8] M. F. Fadli, G. A. Buntoro, and F. Masykur, â€œPenerapan Algoritma Neural Network Pada Chatbot Pmb Universitas Muhammadiyah Ponorogo Berbasis Web,â€ JuSiTik  J. Sist. dan Teknol. Inf. Komun. , vol. 6, no. 1, pp. 13 â€“22, 2023, doi: 10.32524/jusitik.v6i1.786.  
[9] A. Hikmah et al. , â€œImplementasi Natural Language Processing Pada Chatbot Untuk Layanan Akademik,â€ vol. 10, no. 1, pp. 371 â€“382, 2023.  
[10]  T. A. Zuraiyah, D. K. Utami, and D. Herlambang, â€œImplementasi Chatbot Pada Pendaftaran Mahasiswa Baru Menggunakan Recurrent Neural Network,â€ J. Ilm. Teknol. dan Rekayasa , vol. 24, no. 2, pp. 91 â€“101, 2019, doi: 
10.35760/tr.2019.v24i2.2388.  
[11] A. S. Toamain, â€œRancang Bangun Aplikasi Chatbot Sebagai Virtual Assistant Dalam Pelayanan Pengguna Data Di Badan Pusat Statistik Provinsi Maluku,â€ J. Teknol. Inf. , vol. 7, no. 1, pp. 24 â€“31, 2021, doi: 10.52643/jti.v7i1.1292.  
[12]  Y. Yunefri, Y. E. Fadri al, and S. Sutejo, â€œChatbot Pada Smart Cooperative Oriented Problem Menggunakan Natural Language Processing dan Naive Bayes Classifier,â€ INTECOMS J. Inf. Technol. Comput. Sci. , vol. 4, no. 2, pp. 131 â€“140, 2021, doi: 10.31539/intecoms.v4i2.2704.  
[13]  P. Y. S. . M. S. R. Astiningrum Mungki., â€œImplementasi NLP dengan Konversi Kata pada Sistem Chatbot Konsultasi Laktasi,â€ J. Inform. Polinema , vol. 5, no. 
November, pp. 46 â€“52, 2018.  
[14]  K. D. Ningtyas, R. Kurniawan, and A. Armansyah, â€œPenerapan Natural Language Processing Pada Aplikasi Chatbot Info Layanan Kantor Menggunakan Naive Bayes Algorithm,â€ J-SISKO TECH (Jurnal Teknol. Sist. Inf. 
dan Sist. Komput. TGD) , vol. 6, no. 1, p. 266, 2023, doi: 
10.53513/jsk.v6i1.7413.  
[15]  A. Almustaqim and A. N. Toscany, â€œPeranc angan Sistem Chatbot Sebagai Virtual Assistant Pada Pt. Everbright Jambi,â€ Skanika , vol. 5, no. 2, pp. 228 â€“239, 2022, doi: 10.36080/skanika.v5i2.2953.  
[16]  D. Yuliana, Purwanto, and C. Supriyanto, â€œKlasifikasi Teks Pengaduan Masyarakat Dengan Menggunakan Algoritma Neural Network,â€ J. KomtekInfo , vol. 5, no. 3, pp. 92 â€“116, 2019, doi: 10.35134/komtekinfo.v5i3.35.  
[17]  B. Warsito, â€œKapita Selekta Statistika Neural Network,â€ 2009.  
[18]  T. Iskandar Zulkarnain Maulana Putra, A. Farhan Bukhori,  dan Ilmu Pengetahu an Alam, and U. Gadjah Mada, â€œModel Klasifikasi Berbasis Multiclass Classification dengan Kombinasi Indobert Embedding dan Long Short-Term Memory untuk Tweet Berbahasa Indonesia (Classification Model 
Based on Multiclass Classification with a Combination of  Indobert Embedding and Long ,â€ J. Ilmu Siber dan Teknol. Digit. , vol. 1, no. 1, pp. 1 â€“28, 2022, [Online]. Available: https://doi.org/10.35912/jisted.v1i1.1509  
[19]  Mahardhika Chandra, Rizki Pratama, Fathan Azka Pradana, and Alvita Bonita, â€œChatbot Interak si Rumah Sakit menggunakan FFNN,â€ Indones. J. Data Sci. , vol. 3, no. 1, pp. 62 â€“68, 2022, doi: 10.56705/ijodas.v3i1.36.  
[20]  A. Muhidin, M. Danny, and E. Rilvani, â€œAlgoritme Multinomial NaÃ¯ve Bayes Pada Aplikasi Chatbot Layanan Informasi Berbasis Teks,â€ Progresif J. Ilm. â€¦ , pp. 71 â€“80, 2023, [Online]. Available: http://ojs.stmik -
banjarbaru.ac.id/index.php/progresif/article/view/1113%0Ahttp://ojs.stmik-banjarbaru.ac.id/index.php/progresif/article/download/1113/640",Chatbot,"Neural Network, NN","wawancara, kuisioner",akurasi
Aplikasi Tanya Jawab Otomatis Seputar Rekayasa Perangkat Lunak Dengan Menggunakan Metode Cosine Similarity Berbasis Android,"Aplikasi Tanya Jawab Otomatis Seputar Rekayasa Perangkat Lunak Dengan Menggunakan Metode Cosine Similarity Berbasis Android

Rizky Heriawan P.T 1, Maskur  2, Nur Hayatin , S. 3 

Abstrak  
Jawaban pertanyaan aplikasi penjawab pertanyaan yang tersedia saat ini masih menggunakan metode pencocokan kata kunci untuk melakukan pencarian atas jawaban. Sistem penjawab pertanyaan otomatis adalah sistem yang secara otomatis mencoba menemukan kembali informasi yang benar untuk pertanyaan diajukan oleh user. Pertanyaan dapat dikembangkan untuk membantu dan memb uat lebih mudah untuk menjawab pertanyaan tentang 
rekayasa perangkat lunak . Aplikasi ini menggunakan metode  Cosine Similarity  yang merupakan salah satu solusi untuk membantu mencari jawaban pertanyaan yang diinginkan dengan tepat, yang bermanfaat untuk sistem pengolah kata. Karena dengan metode ini, tanya jawab otomatis 
dapat mencari data yang diinginkan oleh penanya, dengan men ampilkan jawaban dengan bobot tertinggi sebagai jawaban yang paling tepat. Jawaban pertama atau bobot  tertinggi yang dihasilkan oleh sistem adalah jawaban yang  benar menurut penilaian sistem dan  pakar.  Jawaban 
pertama atau bobot tertinggi yang dihasilkan o leh sistem adalah jawaban yang benar menurut penilaian sistem, pakar dan pengujian Kappa. Hasil pengujian menggunakan kappa statistik memberikan nilai terbaik Kappa pada jawaban pertama (jawaban dengan bobot terbesar). Nilai 
tersebut membuktikan bahwa sist em yang telah dibangun dapat digunakan untuk mengetahui kemiripan antar kasus penggunaan pertanyaan dan jawaban.  
 
Kata Kunci : Cosine Similarity, Rekayasa Perangkat Lunak, Tanya Jawab  
 
Abstract  
The Answers of question answering applications that are available today are still using keyword matching method to perform a search for answering. Automatic question answering system is a automatically system used to find information that might correspond to the questions 
asked by the user. Questions can be dev eloped to help and make it easier to answer questions about  software engineering. This application uses the method of Cosine Similarity which is one 
solution to help searching for the desired answer of questions correctly, that is useful for word processing system. By this method, Automatic Question Answering can looking for desired data of user by showing the the highest weights answer as  the best answer.  The first or the highest answer resulted by system is the right answer based on system, expert and Kappa Testing. The result of Kappa testing giving the best Kappa value on the first answer (the highest weights answer). It proves that the  system can be used to know the similarity between question and answer for between cases of using quetions and answers.  
 
Keywords: Cosine Similarity, Software engineering, Question Answering  
 
1. Pendahuluan  
Rekayasa perangkat lunak merupakan satu disiplin ilmu y ang bertujuan mengembangkan sistem perangkat lunak yang efektif dari segi biaya. Perangkat lunak bersifat abstrak dan tidak nyata. Perangkat lunak tidak terbuat dari unsur, mengikuti hukum fisika atau proses manufaktur. 
Dalam beberapa hal, kenyataan ini menyederhanakan rekayasa perangkat lunak karena tidak ada pembatasan fisis terhadap potensi perangkat lunak. Akan tetapi, dalam hal lain, tidak adanya batasan natural ini berarti bahwa perangkat lunak de ngan mudah dapat menjadi sangat kompleks dan dengan demikian sangat sulit dipahami. Rekayasa perangkat lunak masih merupakan disiplin yang relatif muda. Istilah rekayasa 
perangkat lunak pertama kali diajukan pada tahun 1968 pada kon ferensi yang diselenggarakan untuk membahas apa yang pada waktu itu disebut ini merupakan akibat langsung dari lahirmya perangkat keras komputer generasi ketiga yang canggih (pada waktu itu). Kecanggihannya membuat aplikasi komputer yang belum terealisasi pada saat itu menjadi proposisi yang layak. Perangkat lunak yang dihasilkan menjadi beberapa kali lipat lebih besar dan lebih kompleks dari sistem perangkat lunak sebelumnya . 
Rekayasa  perangkat lunak di Indonesia dijadikan disiplin ilmu y ang dipelajari mulai tingkat sekolah menengah kejuruan sampai tingkat perguruan tinggi. Di tingkat perguruan tinggi, jurusan ini sudah memiliki kurikulum materi pelajaran sendiri yang sudah ditentukan oleh jurusan. Rekayasa Perangkat Lunak di tingkat pergu ruan tinggi biasanya mempelajari materi seperti bahasa pemprograman, desain web, dan sebagainya, tergantung dari kurikulum tiap tahunnya.  Smartphone android merupakan perangkat mobile yang sering di bawa oleh masyarakat umum sehingga mempermudah pengguna dalam mencari informasi hanya dengan 
menggunakan smartphone user dapat menggali informasi melalui media internet, atau melalui aplikasi lain yang tertanam dalam perangkat tersebut  [1].  Melihat dari  permasalahan yang telah dipaparkan di atas, pada tugas akhir ini akan di buat sebuah sistem dengan memanfaatkan metode cosine similarity dalam menentukan jawaban atas 
pertanyaan-pertanyaan seputar software engineering berbasis android . 
 
2. Landasan Teori  
2.1 Question And Answering System  
Question answering system  merupakan sebuah sistem yang mengizinkan user 
menyatakan kebutuhan informasinya dalam bentuk yang spesifik dan alami, yaitu dalam bentuk natural language question  dan tidak mengembalikan daftar dokumen yang harus disaring oleh user untuk menentukan apakah document-dokumen tersebut mengandung jawaban atas pertanyaan, tetapi mengembalikan kutipan teks singkat atau frasa sebagai jawaban  [2]. 
Question answering  adalah bentuk khusus dari pencarian informasi. Mengingat koleksi dokumen,  Question answering  sistem adalah sistem yang mencoba menemukan kembali informasi yang benar untuk pertanyaan diajukan dalam bahasa alami. Question answering  adalah sebuah bentuk dari information retrieval  yang berkaitan dengan jawaban yang  tepat yang diberikan oleh pertanyaan dengan bahasa alami. Sebuah question -answering system  (QAS)  mencoba untuk menemukan kembali jawaban eksplisit dalam sebuah bentuk jawaban tunggal, potongan teks dari sebuah dokumen atau kumpulan dari dokumen.  Tantangan terbesar di dalam QAS  adalah bagaimana cara mengelompokkan sebuah pertanyaan ke dalam kategori tertentu yang selanjutnya akan akan digunakan untuk menemukan jawaban yang tepat dari sebuah dokumen yang besar . 
2.2 Text Mining  
Text Mining merupakan proses otomatis atau sebagian proses otomatis untuk teks. Ini melibatkan pembentukan text yang lebih terstruktur dan penggalian informasi yang relevan dari teks [3].  Text Mining selalu berurusan dengan kata â€“ kata, jutaan kata â€“ kata yang disimpan dalam 
bentuk file elektronik. File elektronik ini biasa berbentuk beberapa dokumen yang akan diproses, namun tentu saja dokumen â€“ dokumen ini belum dalam bentuk yang terstruktur. Butuh mekanisme untuk menambang teks - teks yang ada dalam koleksi dokumen sehingga didapatkan 
informasi â€“ informasi yang lebih bernilai dan terstruktur. Mekanisme tersebut dibagi dalam beberapa tahapan (fase pre-processing ). Tahapan -tahapan seperti pada Gambar 1 yang dilakukan secara umum dalam text mining, yai tu: Tokenizing, Filtering, Stemming, Tagging, dan Analyzing  [4].   
Gambar 1. Tahapan Text Mining [4] 
2.3 Text Preprocesing  
Proses ekstraksi ini bertujuan untuk menghasilkan term-term yang akan digunakan sebagai prototype  bagi setiap dokumen.  Tiap term tersebut dicari bentuk kata dasar-nya berdasarkan  kamus kata dasar Bahasa Indonesia. Hal ini untuk menghindari tersimpannya kata-kata yang memiliki kata dasar yang sama namun berimbuhan berbeda. Disamping itu dilakukan penyaringan (filtering) terhadap kata -kata yang tidak layak untuk dijadikan sebagai pembeda. Kelompok kata ini biasanya disebut sebagai stoplist. Oleh karena belum tersedia maka penelitian ini juga berusaha mencari stoplist tersebut secara manual.   
2.4 Text Transformation  
Pada tahap ini dilakukan penyaringan ( filtration ). Penyaringan dilakukan dengan menentukan term mana yang akan digunakan untuk merepresentasikan dokumen sehingga dapat mendiskripsikan  isi dokumen dan membedakan dokumen tersebut dengan dokumen lain dalam koleksi.  Term yang sering dipakai tidak dapat digunakan untuk tujuan ini, setidaknya karena dua hal. Pertama, jumlah dokumen yang relevan terhadap suatu query  kemungkinan besar merupakan bagian kecil dari koleksi. Term  yang efektif dalam pemisahan dokumen yang relevan dari dokumen tidak relevan kemungkinan besar adalah term yang muncul pada sedikit dokumen. Ini berarti bahwa term dengan frekuensi kemunculan tinggi bersifat poor descriminator. Kedua, term yang muncul dalam banyak dokumen tidak mencerminkan definisi dan top ik atau sub-topik dokumen. Karena itu, term yang sering digunakan dianggap sebagai stop-word  dan dihapus.   
Stop-word  didefinisikan sebagai term yang tidak berhubungan (irrelevant ) dengan subjek utama dari database meskipun kata tersebut sering kali  hadir di dalam dokumen [5]. Stopword  merupakan kata-kata yang bukan merupakan ciri (kata unik) sehingga dengan menghilangkannya dari suatu teks maka sistem hanya akan memperhitungkan kata-kata yang 
dianggap penting. Penghapusan stop-word  dari dalam suat u koleksi dokumen pada satu waktu membutuhkan banyak waktu. Solusinya adalah dengan menyusun suatu pustaka stop-word  atau stop-list dari term yang akan dihapus.  Konversi term ke bentuk akar ( stemming ) juga merupakan tindakan yang dapat dilakukan pada tahap  ini. Stemming  merupakan proses untuk mereduksi kata ke bentuk dasarnya . Kata-kata yang muncul di dalam dokumen sering mempunyai banyak varian morfologik . Karena itu, setiap kata yang bukan stop-words  direduksi ke bentuk stemmed word  yang cocok. Dengan cara ini, diperoleh kelompok kata yang mempunyai makna serupa tetapi berbeda wujud sintaksis daru dengan lainnya. Kelompok tersebut dapat direpresentasikan oleh satu kata tertentu. 
Pembahasan lanjut tentang stemming dipaparkan di pembahasan  sebelumnya [6].  
2.5 Stemming Bahasa Indonesia  
Stemming dapat dikatakan sebagai proses membentuk suatu kata menjadi kata dasarnya. Misalnya:  
berkata  â†’   kata  
mengakatakan â†’ kata  
perkataan  â†’ kata  
Beberapa algoritma dasar dalam stemming antara lain:  
1) Brute force stemming . Algoritma ini adalah algoritma yang paling sederhana. Bermodalkan database  kata dengan kata dasarnya, komputer dengan mudah mencari kata dasar. Namun metode ini mempunyai kelemahan yaitu jumlah database  kata dan kata dasarnya harus besar. Kesalahan terjadi bila kata tidak ditemukan di database  dan kemudian dianggap kata dasar, padahal bukan.  
2) Menghilangkan imbuhan (awalan, akhiran, sisipan). Untuk menggunakan metode ini harus tahu terlebih dahulu aturan bahasanya. Kata akan dipotong imbuhannya berdasar aturan bahasanya. Kesalahan terjadi bila kata tersebut adalah kata dasar yang dipotong, misalnya: perawan â†’ awan.  
3) Porter Stemmer . Algoritma ini terkenal digunakan sebagai stemmer  untuk bahasa Inggris. Porter Stemmer  dalam bahasa Indonesia akan  menghasilkan keambiguan karena aturan morfologi bahasa Indonesia  [6][7].  
4) Nazief & Adriani Stemmer . Algoritma ini paling sering dibicarakan dalam stemming  bahasa Indonesia. Algoritma ini merupakan h asil penelitian internal UI (Universitas Indonesia) dan tidak dipublish secara umum  [8]. Algoritma ini merupakan gabungan antara algoritma menghilangkan imbuhan dan brute force stemming . Namun algoritma ini mempunyai dua masalah, yang pertama kem ampuannya tergantung dari besarnya database  kata dasar, dan yang kedua, hasil stemming tidak selalu optimal untuk aplikasi information retrieval  (Tala, 2003).  
5) Dan masih banyak algoritma -algoritma dasar lainnya, seperti gabungan algoritma di atas, stokasti k, lematasi , dll.  
Bila dibandingkan, untuk teks berbahasa Indonesia, Porter stemmer  lebih cepat prosesnya daripada Nazief & Adriani stemmer  namun algoritma Nazief & Adriani  memilki tingkat keakuratan lebih tinggi daripada Porter stemmer  [9].    
2.7 Pembobotan  Tf-Idf 
Metode pembobotan yang paling sederhana terhadap suatu term (term wighting ) adalah dengan  menggunakan frekuensi kemunculan term (kata) / term frequency  (TF) yang bersangkutan pada suatu dokumen. Eksperimen -eksperimen pre-proces sing dokumen berbasiskan frekuensi term, telah ban yak dilakukan dalam bidang information retrieval . Namun, dalam kaitannya dengan performa recall dan precision,  penggunaan frekuensi term saja ternyata hanya dapat memenuhi fungsi recall . Fungsi precision  yang baik sayangnya tidak dapat dicapai dengan repre sentasi frekuensi term saja pada suatu dokumen. Precision  yang tinggi mengisaratkan kemampuan untuk membedakan suatu dokumen dengan dokumen yang lain untuk mencegah retrieval  yang tidak diingink an. Frekuensi term yang tinggi dapat digunakan dalam pre-processing, hanya jika frekuensi kemunculan term bersangkutan tidaklah tinggi pada dokumen â€“ dokumen yang lainnya. Nilai precision  yang baik pada kenyataannya dihasilkan oleh term-term yang kemuncula nnya tergolong jarang pada suatu dokumen, karena term-term bersangkutan seringkali menjadi pembeda signifikan antara dokumen -dokumen yang memiliki term-term tersebut dengan dokumen yang tidak memiliki term-term bersangkutan. [10]. Persamaan 1  menyatakan bobot ( w) masing -masing dokumen terhadap kata kunci .  
ð‘¾ð’…,ð’• = ð’•ð’‡ ð’…,ð’• Ã— ðˆðƒð…ð’• (1)  
Dimana:  
d =  dokumen ke-d 
t =  kata ke-t dari kata kunci  
Wd,t  =  bobot dokumen ke-d terhadap kata ke-t  
2.8 Penghitungan Tingkat Kemiripan  (Cosine Similarity)  
Perbandingan kemiripan ( similarity ) yang digunakan disini adal ah standard cosine similarity  dengan  Persamaan 2  [10].  
-2 
SDiDj: Similarity Dokumen ke I dan ke j  
 
3. Analisa dan Perancangan Sistem  
3.1 Desain Sistem  
Perancangan sistem merupakan tahap awal dari perancangan aplikasi yang meluputi desain proses yang digambarkan dalam diagram alur atau flowchart, desain database yang di gambarkan dalam ERD dan desain interface . perancangan ini dilakukan untuk mengetahui kondisi system  secara umum. Dalam prancangan sistem ini akan membahas mengenai Kerangka Sistem, tahapan  preprocessing yang meliputi  proses tokenizing, filtering / stopword removal dan stemming , Cosine Similary yang di mulai dari perhitungan bobot term dengan menggunakan  tf-idf, dan Perangkingan Nilai Kemiripan . Gambar 2 berikut merupakan kerangk a sistem yang akan dibuat . 
Database 
Jawaban Input 
Pertanyaan
Preprocessing
Cosine Similarity
Perankingan Nilai 
Kemiripan
Jawaban Tokenizing Stopword Removal Stemming Deteksi Kata Tanya
Terdapat Kata 
Tanya? No
Yes
Ektraksi Fitur Kata 
Tanya Daftar Fitur 
Kata Tanya Start
End 
Gambar 2. Flowchart Sistem   
Dari Gambar 2 dapat dijelaskan awal mula system berjalan yaitu dengan cara  user menginput pertanyaan kedalam system lalu pertanyaan tersebut akan di proses melalui tahapan  preprocessing  yang terdiri dari tiga bagian yaitu Tokenizing  yang berfungsi untuk memparsing dan menghilangkan tanda baca, Stopword Removal  yang berfungsi unt uk menghilangkan kata tidak penting, dan Stemming  yang berfungsi untuk menghila ngkan awalan atau akhiran dari sebuah kata. Kemudian hasil preprocessing  akan di proses kedalam proses selanjutnya yaitu proses pencarian kemiripan antara pertanyaan dengan data  jawaban yang ada pada database dengan menggunakan metode cosine similarity lalu hasil kemiripan akan di urutkan dari nilai terbesar hingga terkecil, nilai terbesar akan di jadikan jawaban yang paling tepat yang akan di sajikan kepada user. Berikut merupak an contoh perhitungan pencarian jawaban menggunakan metode cosine similarity:  
Sebelum melakukan proses perhitungan perlu di ketahui bahwa setiap kata tanya memiliki fitur masing-masing berikut merupakan fitur setiap kata tanya:  
1. Apa 
a. Adalah  
b. Yaitu  
c. Merupakan  
2. Kapan  
a. Waktu  
b. Saat 
c. Tanggal  
d. Jam 
3. Dimana  
a. Di 
b. Tempat  
c. Lokasi  
4. Berapa  
a. Jumlah  
b. 0-9 
c. Angka  
Contoh pertanyaan:  
â€œKapan waktu perbaikan atau restart ?â€ 
Contoh dokumen:  
D1. Banyaknya kegagalan system untuk sejumlah permintaan layanan system tertentu  
D2. Waktu antara kegagalan system  
D3. Waktu perbaikan atau waktu restart yang dibutuhkan ketika terjadi kegagalan  
Penyelesaian: 
1. Lakukan proses preprocessing, Tabel 1 berikut merupakan hasil preprocessing   
Tabel 1. Hasil Preprocessing  
Term  
kapan  
waktu  
perbaikan  
restart  
saat 
tanggal  
Jam 
banyaknya  
gagal  
system  
jumlah  
minta  
layan  
tentu  
butuh  
Jadi  
2. Hitung tf-idf, Tabel 2 dan Tabel 3 berikut merupakan hasil perhitungan tf-idf  
Tabel 2.  Hasil idf  
Term  Tf Idf Q D1 D2 D3 Df 
kapan  1 0 0 0 1 0.84509804  
waktu  1 0 1 2 4 0.243038049  
perbaikan  1 0 0 1 2 0.544068044  
Restart  1 0 0 1 2 0.544068044  
Saat 1 0   1 0.8450980 4 
tanggal  1 0   1 0.84509804  
Jam 1 0   1 0.84509804  
banyaknya  0 1 0 0 1 0.84509804  
Gagal   1 1 1 3 0.367976785  
System   1 1  2 0.544068044  
Jumlah   1   1 0.84509804  
Minta   1   1 0.84509804   
Layan   1   1 0.84509804  
Tentu   1   1 0.84509804  
Butuh     1 1 0.84509804  
Jadi    1 1 0.84509804   
Tabel 3. Hasil tf -idf 
Kapan  0.84509804  0 0 0 
Waktu  0.243038049  0 0.243038  0.486076  
perbaikan  0.544068044  0 0 0.544068  
Restart  0.544068044  0 0 0.544068  
Saat 0.84509804  0 0 0 
tanggal  0.84509804  0 0 0 
Jam 0.84509804  0 0 0 
banyaknya  0 0.845098  0 0 
Gagal  0 0.367977  0.367977  0.367977  
System  0 0.544068  0.544068  0 
Jumlah  0 0.845098  0 0 
Minta  0 0.845098  0 0 
Layan  0 0.845098  0 0 
Tentu  0 0.845098  0 0 
Butuh  0 0 0 0.845098  
Jadi 0 0 0 0.845098   
3. Hitung bobot kemiripan cosine similarity , dengan hasil seperti pada Tabel 4.   
Tabel 4. Hasil Cosine Similarity  
TERM  D1 D2 D3 
Kapan  0 0 0 
Waktu  0 0.059067  0.118135  
Perbaikan  0 0 0.29601  
Restart  0 0 0.29601  
Saat 0 0 0 
Tanggal  0 0 0 
Jam 0 0 0 
banyaknya  0 0 0 
Gagal  0 0 0 
System  0 0 0 
Jumlah  0 0 0 
Minta  0 0 0 
Layan  0 0 0 
Tentu  0 0 0 
Butuh  0 0 0 
Jadi 0 0 0 
0 0.059067  0.710155   
Dari hasil hitung pembobota kemiripan maka didapat nilai yang paling tingg yaitu pada dokimen tiga (D3) dengan nilai 0.710 sehingga dapat disi mpulkan bahwa jawaban  yang paling tepat untuk pertanyaan diatas adalah dokumen ke 3.  
3.4.1  Data Flow Diagram  
1. Data Flow Diagram Level 0 (Diagram Konteks)  
Pada Gambar 3, DFD level 0 ini terdapat 2 entitas luar yaitu user sebagai pengguna sistem dan dapat melakukan  proses tanya jawab otomatis. dan admin sebagai pengelola sistem, pada user terdapat beberapa alir data yaitu data Data hasil cari, dan data keyword. Pada admin juga terdapat alir data yaitu data login, data admin, dan Data Data Permasalahan.  
DATA PERMASALAHAN DATA LOGIN DATA LOGIN DATA PERMASALAHAN
DATA ADMIN
PERTANYAANJAW ABAN
DATA PERMASALAHANDATA ADMIN0
SISTEM TANYA JAWAB 
OTOMATIS SEPUTAR 
SOFTWARE ENGINERING
#NAME?
USER 
Gambar 3 . Context Diagram  
 
4. Implementasi dan Pengujian  
4.1 Implementasi  Antar muka  
Implementasi antar muka terdiri dari beberapa tampilan pada menu -menu yang ada pada aplikasi. Ada dua antar muka  yang dirancang, yaitu user antar muka dan admin antar muka . Desain  dari user antar muka yang baik pada suatu sistem dapat mempermudah user untuk menggunakan sistem tersebut. Berikut user antar muka pada sistem yang sudah dibangun, diantaranya adalah :  
4.1.1  Implementasi User Antar muka  
Desain  dari user antar muka yang baik pada suatu sistem dapat mempermudah user untuk menggunakan sistem tersebut. Berikut user antar muka pada sistem yang sudah dibangun, diantaranya adalah : 
a. Main Menu  
Main Menu pada Gmabar 4 merupakan tampilan awal untuk user yang didalamnya terdapat tiga menu utama yaitu menu pertanyaan yang berfungsi untuk menampilkan form pertanyaan, menu data permasahalan yang berfungsi untuk menampilkan data data permasahalan yang telah tersimpan pada dat abase, dan menu help yang berfungsi untuk menampilkan cara menggunakan sistem tanya jawab.  
Gambar 4.  User Antar muka  Main Menu  
b. Menu Pertanyaan  
Gambar 5. User Antar muka  menu pertanyaan   
Pada Gambar 5, menu ini menampilkan antar muka untuk menginputkan pertanyaan, dan akan menampilkan beber apa kandidat jawaban, dan jawaban yang paling benar adalah jawaban yang berada pada posisi pertama.   
4.1.2  Implementasi admin Antar muka  
Implementasi admin antar muka terdiri dari beberapa tampilan  pada menu-menu yang ada pada aplikasi. Desain  dari admin antar muka yang baik pada suatu sistem dapat mempermudah admin  untuk menggunakan sistem tersebut. Berikut admin antar muka pada sistem yang sudah dibangun, diantaranya adalah : 
a. Login Form  
Gambar 6. User Antar muka  menu Data permasahalan   
Login form pada Gambar 6, merupakan tampilan yang pertamakali muncul ketika admin akan melakukan proses pengolahan data yang berfungsi untuk memverifikasi hak akses admin untuk melakukan manajemen data.   
b. Main Menu  
Ketika login berhasil maka akan tampil main menu atau halaman index yang akan menjelaskan tentang menu apa saja yang terdapat pada admin dalam hal ini yaitu menu home, data permasahalan dan stemming.   
Gambar 7. User Antar Muka Main Menu Pengelolaan Data Permasalahan   
c. Menu Data permasahalan  
Menu Gambar 8 merupakan data permasahalan berfungsi untuk mengelola data data permasahalan yang akan disimpan dalam database, peda menu ini terdapat sub menu yaitu tambah  data, edit, dan delete.  
Gambar 8. User Antar Muka  Menu Data Permasahalan   
4.3 Pengujian  
4.3.1.  Pengujian Akurasi  
Data-data permasalahan yang digunakan adalah Data -data permasahalan yang di ambil dari buku berjudul rekayasa perangkat lunak karangan  Ian Somerville . Pengujian dilakukan dengan menginputkan 20 pertanyaan. Dengan rincian kata tanya apa, bagaimana, kapan dan berapa. Dalam penelitian ini pengujian akurasi dilakukan dengan membandingkan jawaban yang di uji oleh pakar. Pengujian pakar merupa kan pengujian dimana sistem diuji oleh pakar yang merupakan dosen di bidang rekayasa perangkat lunak. Pada pengujian ini pak ar yang melakukan pengujin terhadap sistem adalah bapak Yuda Munarko, S.kom. M.Sc. yang merupakan dosen teknik informatika bidang minat rekayasa perangkat lunak di Universitas Muhammadiyah Malang.  Untuk menghitung nilai akurasi pencarian jawaban yang tepat  akan di hitung dengan menggunakan rumus berikut:  
Akurasi = jawaban  yang  benar
jumlah  pertanyaan  ð‘¥ 100%  
Akurasi =16
20 ð‘¥ 100%  
Akurasi =80.00% 
Dari hasil sebanyak 20 pertanyaan diatas, nilai akurasi pencarian jawaban yang benar dapat di simpulkan sebanyak 80.00% akurat.  Untuk menghitung nilai precission pencarian jawaban yang tepat akan di hitung de ngan menggunakan rumus berikut:  
Precission = jawaban  yang  relevan
jumlah  pertanyaan  ð‘¥ 100%  
Precission = 13
20 ð‘¥ 100%  
Precission = 65.00% 
Dari hasil sebanyak 20 pertanyaan diatas, nilai precission pencarian jawaban yang relevan dapat di simpulkan sebanyak 65.00%.  
4.3.2.  Pengujian Konsistensi Cohen's Kappa  
Uji Konsistensi Cohen's Kappa Merupakan ukuran yang menyatakan konsistensi pengukuran yang dilakukan dua penilai (Rater) atau konsistensi antar dua metode pengukuran atau dapat juga mengukur konsistensi antar dua  alat pengukuran. Koefiseien Cohen's kappa hanya diterapkan pada hasil pengukuran data kualitatif (Kategorik). Contoh pada penentuan jawaban relevan dan tidak relevan, dimana dua peneliti diminta untuk menentukan jawaban relevan pada 20 data soal dan jawab an.  Apakah penent uan jawaban relevan antara dua peneliti tersebut menunjukan hasil yang sama (kosisten)?.   
System  
Benar  Salah  
Pakar  Benar  16 0 
Salah  3 1  
Dimana  
Hasil pengukuran benar oleh  
Pr(Sistem) = 16+3
20 = 0.95 = 95%  
Pr(Pakar) = 16+0
20 = 0.80 = 80%  
Hasil pengukuran salah oleh  
Pr(Sistem) = 0+1
20 = 0.05 = 5%  
Pr(Pakar) = 3+1
20 = 0.2 = 20%  
Perubahan kemungkinan hasil pengukuran  
Benar = 95% x 80% = 76%  
Perubahan kemungkinan hasil pengukuran  
Salah =5% x 20% = 1 %  
Total perubahan pengu kuran  antar Rater = 76% + 1% = 77%  
Berdasarkan hasil hitung diatas maka di dapat nilai koefisien kappa berikut:  
K = 0.77âˆ’0.76
1âˆ’0.76 = 0.0416   
Hasil Nilai koefiesien kappa dijadikan sebagai nilai ambang batas dari pengujian yang dilakukan oleh sistem. Apabila nilai bobot yang diuji oleh sistem lebih dari atau sama dengan nilai ambang batas maka dianggap relevan, kemudian apabila nilai dibawah dari nilai ambang batas maka dianggap kurang relevan.  
 
5. Penutup  
5.1 Kesimpulan  
Berdasarkan pengujian pada bab sebel umnya, didapat kesimpulan dalam penelitian auto answer seputar Permasalahan software engineering  menggunakan metode cosine similarity ini, diantaranya adalah:  
1. Bobot jawaban tertinggi merupakan jawaban terbaik untuk setiap pertanyaan yang di inputkan kedalam sistem tanya jawab.  
2. Dari hasil sebanyak 20 pertanyaan diatas, nilai precission pencarian jawaban yang relevan dapat di simpulkan sebanyak 65.00%.  
3. Dari 10 pertannyaan yang menghasilkan jawaban relevan sebanya 8 pertanyaan dan 2 dari pertanyaan tidak relevan sehingga dapat di simpulkan bahwa sistem dapat menjawab pertanyaan dengan nilai 80% relevan.   
5.2 Saran  
Untuk lebih menyempurnakan dibutuhkan pengembangan untuk menjadikan sistem ini menjadi lebih baik. Adapaun beberapa saran untuk pengemb angan sistem ini, diantaranya adalah:  
1. Dapat di implementasikan pada beberapa platform smartphone yang lain seperti blackberry dan windows phone, sehingga dapat digunakan oleh lebih banyak orang.  
2. Penambahan metode yang di gunakan untuk meningkatkan dan men yempurnakan sistem tanya jawab otomatis sehingga menghasilkan jawaban yang paling akurat.  ISSN: 2714 -7975 

Referensi  
[1] Stephanus Hermawan Susanto, Mu dah Membuat Aplikasi Android. Yogyakarta: C.V ANDI OFFSET,  2011.  
[2] Gunawan dan Lovina, G., 2006, Question Answering System dan Penerapannya ada Alkitab.  Jurnal Informatika.  No. 1, Vol 7, hal 1 -9. 
[3] Miller, K. (2005), Communi cation Theorie s: Perspectives, processes, and ontexts, 2nd EdNew York: McGraw -Hill. 
[4] Riza, BAB 11 Text Mining,  http://student.eepisits.edu/~risa/files/DataMining /chapter11.pdf, 2008 . 
[5] Cios, Krzysztof J. Etc.2007.Data Mining A Knowledge Discovery Approach, Springer.  (online). (http://www.4shared.com/document/FyVdn5pm/Data_Mining_Knowledge_Discov.html, diakses 8 oktober 2014).  
[6] Tala, F.Z., 2003, A Study of Stemming Effects on Information Retrieval in bahasa Indonesia. Master Thesis, Institut for logic , Language and  Computation Universiteit van Amsterdam The Netherlands.  
[7] Abdul Chaer. (2008). Morfo logi Bahasa Indonesia (Pendakatan dan Proses). Jakarta:  Rineka Cipta . 
[8] Adriani, M., Asian, J., Nazief, B., Tahaghoghi, S. M., and Williams, H. E. (2007). Stemming indonesian: A confix -stripping approach. ACM Transactions on Asian Language Information Proce ssing (TALIP), 6(4):1 â€“33. 
[9] Augusta, L edy.  2009. â€œPerbandingan    Algoritma Stemming Porter Dengan Algoritma Nazief & Adriani Untuk Stemming Dokumen Teks BahasaIndonesiaâ€. Konferensi Nasional Sistem dan Informatika  2009, Bali, November 14, 2009.  
[10] Mahendra, Krisnatuti D, Tobing A, Boy. Care Your Self DiabetesMellitus. Jakarta: Penebar Plus. 2008 . 
",Aplikasi Tanya Jawab,"Cosine Similarity, TF-IDF",data permasalahan,"akurasi, precission"
DESAIN SISTEM TANYA-JAWAB PADA RESERVASI HOTEL DENGAN METODE MODEL KERUANGAN VEKTOR,"DESAIN SISTEM TANYA-JAWAB PADA RESERVASI HOTEL DENGAN METODE MODEL KERUANGAN VEKTOR

Nurgiyatna1, Hernawan Sulistyanto2 

ABSTRAK 
Layanan reservasi merupakan sebuah proses penyajian kembali informasi dari konten suatu basis data. Permasalahan dalam kajian proses reservasi hotel adalah bagaimana cara menyajikan dan menyediakan informasi reservasi yang sesuai dan memadai bagi calon tamu hotel. Pada penelitian ini dirancang dan dikembangkan sebuah purwarupa sistem reservasi 
hotel dengan antarmuka bahasa sehari-hari menggunakan model keruangan vektor (Vector Space  Model , VSM). Masukan aplikasi berupa teks kalimat dalam bahasa sehari-hari serta 
berbahasa Indonesia akan digunakan untuk melakukan query  informasi yang telah tersimpan dalam basis data hotel. Kemampuan dan performa sistem temukembali (retrieval) ini 
bergantung pada algoritma, kekayaan pengetahuan kalimat, dan data yang dimiliki oleh basis datanya. Hasil keluaran sistem adalah informasi kepada calon tamu dengan Recall  83,79% 
dan Precision  85,89%. Adanya aplikasi pencarian kamar dengan antarmuka bahasa sehari-hari ini diharapkan menjadi sebuah alternatif pada proses reservasi hotel dalam rangka 
menyediakan sebuah sistem yang lebih luwes dan fleksibel dalam berinteraksi dengan penggunanya. 
 
Kata kunci: hotel
 
PENDAHULUAN  
Layanan penyajian informasi dari sebuah hotel untuk membantu calon tamu hotel mendapatkan jenis kamar hotel dan informasi hotel sesuai dengan yang dikehendakinya merupakan bentuk reservasi hotel (Ding, dkk., 2003). Proses pencarian dan penemuan kembali informasi ( information retrieval ) yang tersimpan dalam suatu basis data sistem reservasi hotel menjadi kunci utama dalam sebuah aplikasi reservasi karena tujuan dari reservasi menurut McTavis dan Sankaranarayanan (2010) adalah memilih sebuah kamar terbaik di sebuah hotel yang berada di lokasi prima dengan fasilitas sesuai pilihan calon tamu hotel.. Model pencarian informasi kamar hotel yang umum digunakan adalah dengan menggunakan aplikasi sistem reservasi berbasis web. Penggunaan web reservasi tersebut sayangnya hanya menampilkan informasi secara umum disertai dengan sejumlah form isian yang harus dilengkapi oleh calon tamu hotel sehingga terkesan kaku dalam melakukan layanan reservasi. Menurut McTavis dan Sankaranarayanan (2010) bahwa dalam reservasi hotel umumnya dilaksanakan 
sebelum calon tamu hotel datang di hotel. Ketika berlangsung reservasi sebuah kamar hotel umumnya akan ditawarkan beberapa kriteria fasilitas kamar yang akan dipesan, semisal tipe kamar, jumlah tempat tidur (bed), AC/fan, kamar mandi dalam/luar ( shared bathroom ) dan sebagianya. Selanjutnya apabila telah disepakati kondisi di atas baru akan dilanjutkan dengan proses pemesanan kamar ( booking). Ding, dkk. (2003) mengategorikan jenis reservasi ke dalam (1) Confirmed, kamar yang dipesan ada dan dapat diberikan Tentative, reservasi yang dilakukan oleh calon tamu dimana calon tamu sudah memberikan alamat dan identitasnya tetapi belum memberikan garansi apapun. Tanggal kedatangan (chek- in) dan kepulangan (chek-out) calon tamu masih belum ditentukan hotel sudah dipesan namun masih ada yang melakukan reservasi. Adanya teknologi pengolahan bahasa alami saat ini membuka sebuah peluang besar untuk mengembangkan model sistem reservasi yang fleksibel baik dan luwes bagi penggunanya dengan terapan penggunaan bahasa sehari-hari. Berdasarkan perkembangannya, penggunaan bahasa alami memungkinkan peningkatan kualitas interaksi antara komputer (mesin reservasi) dengan manusia (calon tamu hotel) secara lebih baik. Pengembangan sistem berbasis bahasa alami diarahkan pada perbaikan dan peningkatan teknik komputasi melalui penyempurnaan teknik dan algoritmanya sehingga proses pengolahan berbahasa alami mencapai performa akurasi yang semakin baik. Beberapa kajian variasi implementasi sistem berbasis bahasa alami juga terus bermunculan selaras dengan permasalahan dalam kehidupan sehari-hari. Raharjo dan Hartati (2014) mengimplementasikan bahasa alami untuk melakukan query melalui penerjemahan ke dalam bahasa SQL terhadap terjemahan Alquran pada basis data relasional. Sistem dikembangkan hanya terbatas pada 5 pertanyaan dengan mengikuti 7 aturan produksi. Sebelumnya, query dengan penerjemahan ke dalam X Query pada basis data XML telah dikerjakan oleh Hartati dan Zuliarso (2008) serta Wibisono (2013). Pada Wibisono (2013) mengimplementasikan bahasa alami untuk query basis data akademik dengan mengikuti 7 aturan produksi. Sementara itu Hartati dan Zuliarso (2008) telah mengimplementasikannya pada basis data XML berupa bibliografi koleksi perpustakaan. Bentuk implementasi bahasa alami yang agak berbeda dikerjakan oleh Ratnasari, dkk (2014) dalam bentuk perancangan sistem anamnesis yang membantu perumusan permasalahan pasien berdasarkan keluhan-keluhan yang disampaikan oleh pasien sehingga diperoleh narasi permasalahan pasien yang baku. Vector Space Model (VSM) menjadi salah satu metode yang dapat dipergunakan pada pengembangan bahasa alami untuk proses penyajian reservasi. VSM sebagai metode yang mengukur kemiripan antara suatu dokumen dengan suatu query user  dengan menggunakan cosinus dari sudut antar vektor yang dibentuk oleh dokumen dengan vektor dari kata kunci yang di-input-kan oleh user. Pada penelitian ini diimplementasikan VSM pada pengolahan bahasa alami untuk memperoleh informasi seputar reservasi hotel. Model keruangan vektor ( Vector Space Model, VSM ) adalah suatu model yang digunakan untuk mengukur kemiripan antara 
suatu dokumen dan suatu query dengan mewakili setiap dokumen dalam sebuah koleksi sebagai sebuah titik dalam ruang (vektor dalam ruang vektor). Poin yang berdekatan di ruang ini memiliki kesamaan semantik yang dekat dan titik yang terpisah jauh memiliki kesamaan semantik yang semakin jauh. Kesamaan antara vektor dokumen dengan vektor query tersebut dinyatakan dengan cosinus dari sudut antar keduanya.  Pada metode Vector Space Model  bobot dari setiap term yang didapat dalam semua dokumen dan query dari user harus dihitung lebih dulu. Term adalah suatu kata atau suatu kumpulan kata yang merupakan ekspresi verbal dari suatu pengertian. Perhitungan bobot tersebut dinyatakan sebagai Term Frequency  (TF) dan Inverse Document Frequency  (IDF) melalui persamaan (1) dan persamaan (2) berikut ini.  
 
ï€¨ ï€©ij i tf TF2logï€½
-1
di mana tf merupakan frekuensi term i dalam dokumen j.  
1 log2ï€«ïƒ·ïƒ·
ïƒ¸ïƒ¶
ïƒ§ïƒ§
ïƒ¨ïƒ¦
ï€½
jnNIDF
-2
Di mana N adalah jumlah total dokumen dalam koleksi dan 
jn  adalah jumlah dokumen yang mengandung minimal sebuah term i.  Similaritas antara query dengan dokumen ditetapkan oleh cosine dari sudut antara vektor pertanyaan dan vektor dokumen jawaban sebagaimana dinyatakan dalam persamaan (3) berikut. 
j qj q
j qd dd d
d dï€½) , cos(
-3
dengan qd dan jd adalah vektor query dan kumpulan dokumen. 

Metode  
Proses desain ditandai dengan menggambarkan aliran control melalui ERD, DFD dan flowchart  sebagaimana disajikan pada Gambar 1 berikut.   
Gambar 1. ERD untuk merepresentasikan hubungan basis data yang ada dalam reservasi hotel 
 
HASIL DAN PEMBAHASAN 
Pada penelitian ini telah dibangun sebuah sistem reservasi hotel. Sistem terdiri atas dua bagian utama, yaitu pencarian kamar dan aplikasi booking kamar. Menu home pada aplikasi ditampilkan pada Gambar 3 di bawah ini.   
TB_HISTORY  
idhistory 
tanggal 
jenis 
TB_RATING  
ruangan 
Harga  
Lokasi  
Makanan  
servis 
Fasilitas  
Memilih  
TB_KAMAR  
nokamar 
status 
sisa 
batal 
dp 
idreservasi  
lamamenginap  
diskon 
hargadiskon  
tanggalkeluar  
status 
subtotal 
tanggalmasuk  
harga 
TB_RESERVASI  
TB_TIPE  
minikulkas  
idtipe 
bathtub 
jeniskamar 
TV 
jenistempattidur  
harga 
makstamu  
AC 
TB_PEMBAYARAN 
idpembayaran  
totbooking  
tanggal 
totalbayar  
totaldp 
Melakukan
m  
TB_K_KREDIT  
nokk 
tipekk  
TB_GET_EMAIL 
email 
tanggal  
idgetemail  
TB_MAKANAN 
idmakanan  
kategori 
harga 
nama 
nokamar 
status 
subtotal 
jumlah 
TB_MAKANAN_DETAIL  
TB_TAMU  
menginap  
idtamu 
tempatlahir  
identitas 
telepon 
nama 
tanggallahir 
alamat 
provinsi 
negara 
kota 
email 
TB_FAKTUR  
nofaktur  
tanggal 
totaltagihan  
Memiliki  
TB_COMMENT 
idcomment  
Harga  
kategori  
nama 
tanggal 
Melakukan
m  
TB_REPLY  
idreply 
batas 
nama 
tanggal 
TB_FASILITAS 
idfasilitas  
nama 
harga 
TB_FASILITAS_DETAIL  
status 
subtotal 
jumlah 
nokamar 
Memiliki  
tujuan 
judul 
pesan 
TB_USER  
password  
roles  
username 
Gambar 3. Menu utama (home) aplikasi  
Berdasarkan pada tampilan menu tersebut terlihat bahwa calon tamu hotel dapat mencari informasi sebuah kamar yang dikehendaki dengan mengetikkan sebuah kalimat dalam bahasa yang dikenal sehari-hari. Sebuah kalimat sebagai contoh â€ada kamar kosongâ€ seperti ditampilkan pada Gambar 4 berikut.    
Gambar 4. Sebuah kalimat masukan â€œada kamar kosongâ€  
Sebuah kalimat masukan selanjutnya akan diolah dengan melaksanakan suatu query pada basis data sistem di table pertanyaan yang sering ditanyakan ( Frequently Asked Question, FAQ ) yang dimiliki oleh aplikasi. Hasil pengolahan dari masukan pada Gambar 5 disajikan pada Gambar 4 di bawah ini.  
Gambar 5. Hasil query pada FAQ  
Faktor terpenting dalam aplikasi ini adalah bagaimana basis data didesain dan dikonfigurasi agar mengandung setiap kata -kata penting yang dituliskan pada antarmuka sisi masukan aplikasi. Pada suatu kondisi di mana sebuah kalimat gagal untuk dimengerti oleh aplikasi maka hasil jawaban yang diberikan adalah â€œmaaf kami tidak bisa menjawab pertanyaan anda akan kami tanyakan kepada supervisor kamiâ€, sebagaimana disajikan pada Gambar 6(a) dan 6(b) berikut ini. 
       (a)    (b) 
Gambar 6. Kalimat pertanyaan dan jawabannya 
Beberapa bentuk pertanyaan yang lain akan dapat dijawab dengan baik selama kata kata hasil penguraian kalimat yang dilakukan oleh algoritma Vector Space Model (VSM)  dikenali dengan baik oleh aplikasi. Metode yang diterapkan selanjutnya dalam aplikasi ini adalah dengan melakukan pencocokan (matching) kata kunci yang ditemukan oleh algoritma VSM. Beberapa pertanyaan aktual yang tersimpan dalam basis data ditunjukkan pada Gambar 7 berikut ini. 
Gambar 7. Kumpulan kalimat yang tersimpan dalam basis data  
Sementara itu untuk beberapa jenis tabel yang diciptakan dalam basis data ada aplikasi ini berturut turut ditampilkan pada Gambar 8 di bawah ini.  
Gambar 8. Ragam tabel dalam basis data hotelsolo  
Evaluasi dari sistem temu-kembali informasi dipengaruhi oleh dua parameter utama yaitu recall dan precision(Grossman, 2002). Recall adalah rasio antara dokumen relevan yang berhasil ditemukembalikan dari seluruh dokumen relevan yang ada di dalam sistem dinyatakan dengan bentuk persamaan (4) berikut.  
RRacallï€½Re
-4 
dengan Ra adalah dokumen relevan yang ditemukan kembal dan R adalah dokumen yang relevan. Sementara precision adalah rasio dokumen relevan yang berhasil ditemukembalikan dari seluruh dokumen yang berhasil ditemu-kembalikan sebagaimana dinyatakan pada persamaan (5) berikut.  
ARaecisionï€½ Pr
-5 
Di mana A adalah hasil temu kembali. 
Berdasarkan eksperimen yang dilaksanakan maka dapat disajikan hasil pada Tabel 1 berikut ini.   
Tabel 1. Hasil unjuk kerja sistem pada dataset reservasi  
Data set Recall  Precision  
FAQ reservasi  83.79% 85.89% 
Simpulan  
Aplikasi sistem pencarian kamar dengan mengimplementasikan metode SVM telah dibangun pada penelitian ini. Aplikasi mampu melaksanakan temu kembali data dengan Recall dan Precision  yang cukup baik, yaitu 83,79% dan 85,89%. terhadap data yang tersimpan dalam basis data dengan menggunakan bahasa Indonesia. Pertanyaan yang diproses masih terbatas pada beberapa kalimat yang sesuai dengan aturan 
produksi yang dibangun sejumlah 30 pertanyaan. Guna saran bagi penelitian mendatang adalah perluasan pertanyaan yang lebih banyak dan variatif sebagaimana bahasa alami asli yang dipergunakan oleh manusia dalam kesehariannya. 
 
DAFTAR PUSTAKA 
Ding, Y., Litz, Y., Malaka, R., and Pfisterer, D. 2003. On programming information agent systems : an integrated hotel reservation service as case study. LNAI 2831. E-book of Springer-Verlag Berlin Heidelberg:. 50â€“ 61. 
Kao, A., and Poteet, S.R. 2007. Natural language processing and text mining , London: ebook of Springer-Verlag. 
Liu, L., Li, X. and Wang, Y-Y. 2011. Lexicon modelling for query understanding, e-paper on IEEEXplore in Proceeding of ICASSP, pp. 5604 -5607, 22-27 May 2011, Prague, Crezch Republic. DOI: 10.1109/ICASSP.2011.5947630 
McTavish, C. and Sankaranarayanan, S. 2010. Intelligent agent based hotel serach & booking system, e-paper 
on IEEEXplore in Proceeding of EIT, pp. 1-6, 20â€” 22 May 2010, Normal, IL. DOI: 10.1109/EIT. 2010.5612121 
Raharjo, S., dan Hartati. 2014. Antarmuka bahasa alami untuk melakukan query terhadap terjemahan 
Alquran, e-paper dari Jurnal Teknologi, Vol. 7 No. 1, Juni: 12-19. 
Ratnasari, C.I., Kusumadewi, S., dan Rosita, L. 2014. Model natural language processing untuk perumusan keluhan pasien, e-paper dalam Proceeding Seminar Nasional Medis V, 6 Desember, MTI, FTI, UII. Wibisono, S. 2013. Aplikasi pengolahan bahasa alami untuk query basisdata akademik dengan format data xml, e-paper dari Jurnal Teknologi Informasi, Vol. 18, No. 1, Januari: 65-79.",Sistem Tanya Jawab,"Model Keruangan Vektor, Vector Space Model, VSM",data hotel,"recall, precision"
KLASIFIKASI MASYARAKAT MISKIN MENGGUNAKAN METODE NAIVE BAYES,"KLASIFIKASI MASYARAKAT MISKIN MENGGUNAKAN METODE NAIVE BAYES

Haditsah Annur  

Abstrak   
Permasalahan utama dalam upaya pengurangan kemiskinan saat ini terkait dengan adanya fakta bahwa pertumbuhan ekonomi tidak  tersebar secara merata. Penelitian akan melakukan klasifikasi berdasarkan data penduduk miskin yang d iperoleh dari Kecamatan Tibawa dengan menggunakan teknik data mining. Atribut yang akan digunakan dalam melakukan klasifikasi penduduk adalah Umur, Pendid ikan, Pekrjaan, Penghasilan, Tanggungan, Status (Kawin/Belum Kawin). Metode yang akan digunakan adalah metode Naive Bayes Classifier, yang merupakan salah satu teknik pengklasifikasian dalam data mining. Berdasarkan penelitian yang dilakukan dihasilkan kes impulan bahwa, Sistem klasifikasi masyarakat miskin di wilayah pemerintahan Kecamatan Tibawa Kab. Gorontalo dapat direkayasa dan Berdasarkan hasil pengujian confussion matrix  dengan teknik split validasi,  penggunaan metode klasifikasi naive bayes  terhadap dataset yang telah diambil pada objek 
penelitian diperoleh tingkat akurasi sebesar 73% atau termasuk dalam kategori Good . Sementara nilai Precision  sebesar 92% dan Recall  sebesar 86%.  

Kata kunci : Tingkat kemiskinan, Data Mining, Klasifikasi, Naive Bayes  

Abstract   
The main problem in the current poverty reduction effort is related to the fact that economic growth is not evenly distributed. The research will classify based on the data of poor people obtained from Tibawa District by using data mining technique . Attributes to be used in classifying the population are Age, Education, Work, Income, Dependent,  Status (Married / Unmarried). The  method to be used is the Naive Bayes Classifier method, which is one of the classification techniques in data mining. Based  on the research, it is concluded that, the classification system of the poor in the administrative area of Tibawa sub -district, Gorontalo regency can be engineered and Based on the result of confusion  matrix testing with split validation technique, the us e of naive Bayes  classification method to 
the dataset which has been taken on the research object obtained the level of accuracy 73% or included in the Good category. While the Precision value of 92% and Recall of 86%.  

Keywords: Poverty Level, Data Mining, Classification, Naive Bayes  

1. Pendahuluan   
Semua  Masyarakat miskin merupakan suatu kondisi dimana fisik masyarakat yang tidak memiliki akses ke prasarana dan sarana daser lingkungan yang memadai, dengan kualitas 
perumahan dan pemukiman yang jauh dibawah standar kelayakan serta mata pencaharian yant tidak menentu yang mencakup serluruh mulitidimensi. Penggolongan kemikskinan didasarkan pada suatu standart tertentu yaitu dengan membandingkan tingkat pendapatan orang atau keluarga dengan tingkat pendapatan yang  diperlukan untuk memenuhi kebutuhan pokok minimum  [1]. Wilayah Kecamatan Tibawa yang terbagi ke dalam 16 Desa, dan Kecamatan Tibawa termasuk Kecamatan yang memiliki penduduk yang masih di bawah taraf hidupnya, yang biasa dikatakan masyarakat miskin. Berda sarkan data masyarakat miskin yang peroleh dari Kecamatan Tibawa Kabupaten Gorontalo yaitu sebagai berikut :  
Tabel 1. Data Penduduk Miskin  
Tahun  Jumlah Penduduk Miskin  
2015  2790  
2014  2819  
2013  2950  
Sumber : Kecamatan Tibawa  
Permasalahan utama dalam upa ya pengurangan kemiskinan saat ini terkait dengan adanya fakta bahwa pertumbuhan ekonomi tidak tersebar secara merata di seluruh wilayah Indonesia, khususnya di Kecamatan Tibawa, ini dibuktikan dengan tingginya perbedaan pendapatan antar daerah. Selain itu  kemiskinan juga merupakan sebuah hubungan sebab akibat (kausalitas melingkar) artinya tingkat kemiskinan yang tinggi terjadi karena rendahnya pendapatan perkapita, pendapatan perkapita yang rendah terjadi karena investasi perkapita yang juga rendah  [2]. Salah satu metode Data Mining  yang bisa digunakan adalah Association rule discovery  merupakan tugas yang sama dalam data mining, dengan pengecualian bahwa tujuan utama dari klasifikasi adalah prediksi label kelas, sedangkan asosiasi aturan penemuan menggambarkan korelasi antara item dalam database  
transaksional  [3]. Metode yang akan digunakan adalah metode Naive Bayes Classifier, yang merupakan salah satu teknik pengklasifikasian dalam data mining  [4]. Dimana akan dilakukan analisis untuk memperoleh informasi terhadap data lama tingkat kemiskinan. Diharapkan dari penelitian yang 
dilakukan terhadap sampel data penduduk miskin tersebut dapat diperoleh suatu informasi yang bisa membantu pihak kecamatan untuk merancang strategi dalam meningkatkan kesejahteraan masyarakat.  Penelitian akan membuat aplikasi klasifikasi berdasarkan data penduduk miskin yang diperoleh dari Kecematan Tibawa tahun 2015 dengan menggunakan teknik data mining. Variabel inputan yang akan digunakan dalam melakukan klasifikasi penduduk miskin tahun 2016  adalah Umur, Pendidikan, Pekerjaan, Penghasilan, Tanggungan, Status (Kawin/Belum Kawin), sesuai data yang telah diambil dan sesuai dengan variabel yang akan diinputkan, maka hasil klasifikasinya nanti akan menentukan tingkat kemiskinan seperti :  Miskin dan Tidak Miskin.  Rumusan Masalah penelitian ini adalah  menentukan cara merekayasa sistem untuk klasifikasi masyarakat miskin Menggunakan Algoritma Naive Bayes dan Hasil penerapan Algoritma Naive Bayes untuk klasifikasi masyarakat miskin di kecamat an tibawa.  Adapun tujuan dari penelitian ini  adalah :  Klasifikasi masyarakat miskin di Kecamatan Tibawa Menggunakan Algoritma Naive Bayes  dan Menerapkan Algoritma  Naive  Bayes  klasifikasi masyarakat miskin di Kecamatan Tibawa . 

2. Metode   
1.1 Klasifikasi  
Proses pe nemuan model (atau fungsi) yang menggambarkan dan membedakan  kelas  data  atau  konsep  yang bertujuan  agar  bisa  digunakan  untuk memprediksi  kelas  dari  objek  yang  
label kelasnya  tidak  diketahui [5]. Algoritma  klasifikasi  yang  banyak  digunak an secara luas, yaitu Decision/classification  trees, Bayesian  classifiers/  Naive  Bayes  classifiers, Neural  networks, Analisa  Statistik,  Algoritma Genetika,  Rough  sets,  k -nearest  neighbor, Metode Rule Based,  Memory based reasoning, dan Support vector machines (SVM)  [6]. 
1.2 Algoritma NaÃ¯ve Bayes  
Bayesian classification adalah pengklasifikasian statistik yang dapat digunakan untuk memprediski probabilitas keanggotaan suatu class. Bayesian classification didasarkan pada teorema Bayes yang memiliki kemampuan klasifikasi serupa dengan decesion tree dan neural network. Bayesian classification terbukti memiliki akurasai dan kecepatan yang tinggi saat diaplikasikan ke dalam database dengan data yang besar  [7]. Metode Bayes merupakan pendekatan statistic untuk melakukan inferensi induksi pada persoalan klasifikasi. Pertama kali dibahas terlebih dahulu tentang konsep dasar dan definisi pada Teorema Bayes, kemudian menggunkan teorema ini untuk melakukan klasifikasi dalam Data Mining. Teorema Bayes memiliki  bentuk umum sebagai berikut :   
 P(H | X)  =   (1)  
Keterangan :  
X   = Data dengan class yang belum diketahui  
H   = Hipotesis data X merupakan suatu class spesifik  
P(H|X)  = Probabilitas hipotesis H berdasarkan kondisi x (posteriori prob.)  
P(H) = Probabilit as hipotesis H (prior prob.)  
P(X|H) = Probabilitas X berdasarkan kondisi tersebut  
P(X)   = Probabilitas dari X  
P(X|H)P(H)  
P(X) 
Gambar 1. Teorema Bayes  

3. Hasil dan Pembahasan    
3.1 Manual Penggunaan  Metode Klasifikasi   
Klasifikasi dengan Naive Bayes  Menggunakan Data Latih  Berdasarkan dataset/data latih, maka akan dilakukan proses klasifikasi terhadap data baru berikut :  
Umur = Tua  
Status = Kawin  
Pendidikan = SLTP  
Tanggungan = 1 Orang  
Pekerjaan = Pedagang  
Penghasilan = Tinggi  
Proses naive bayes  
Probabilitas Kelas Miskin :  
P(Miskin) = 145/171 = 0.847  
Probabilitas Kelas Tidak Miskin :  
P(Tidak Miskin) = 26/171 = 0.152  
Menghitung kemungkinan termasuk kategori miskin :  
P(Class.Miskin | Umur.Tua) = 86 / 145 = 0.59  
P(Class. Miskin | Status.Kawin) = 122 / 145 = 0.84  
P(Class.Miskin | P endidikan.SLTP) = 121 / 145 = 0.83  
P(Class.Miskin | Tanggungan.1 Org) = 19 / 145 = 0.13  
P(Class.Miskin | Pekerjaan.Pedagang) = 1 / 145 = 0.006  
P(Class.Miskin | Penghasilan.Tinggi) = 0 / 145 = 0  
Maka kemungkinan termasuk kategori miskin adalah  
Class.Miskin = 0.847 x 0.59 x 0.84 x 0.83 x 0.13 x 0.006 x 0  
Class.Miskin = 0   
Menghitung kemungkinan termasuk kategori tidak miskin :  
P(Class.Tidak Miskin | Umur,Tua) = 13 / 26 = 0.5  
P(Class.Tidak Miskin | Status.Kawin) = 20 / 26 = 0.77  
P(Class.Tidak Miskin | Pendidik an.SLTP) = 3 / 26 = 0.11  
P(Class.Tidak Miskin | Tanggungan.1 Org) = 2 / 26 = 0.08  
P(Class.Tidak Miskin | Pekerjaan.Pedagang) = 4 / 26 = 0.15  
P(Class.Tidak Miskin | Penghasilan.Tinggi) = 8 / 26 = 0.31  
Maka kemungkinan termasuk kategori tidak miskin :  
Class. Tidak Miskin = 0.152 x 0.5 x 0.77 x 0.11 x 0.08 x 0.15 x 0.31  
Class.Tidak Miskin = 0.0002 3 
Karena nilai probabilitas Class.Miskin lebih kecil dari nilai probabilitas Class.Tidak Miskin, maka dapat disimpulkan bahwa data baru diatas termasuk dalam kategori TIDAK MISKIN   
3.2 Pengujian Metode Klasifikasi Menggunakan Data Testing  
1. Adapun pengujian terhadap metode klasifikasi naÃ¯ve bayes yang digunakan, dilakukan dengan menggunakan teknik split validation  dengan confussion matrix,  dimana dataset yang disajikan diatas  akan dibagi kedalam dua bagian yakni 90% (171 record) dari dataset akan dijadikan sebagai data training  atau latih dan 10% (19 record) sisanya akan dijadikan sebagai data testing  atau uji.  
2. Hasil proses klasifikasi menggunakan metode naive bayes pada data testing yang berjumlah 19 record  dihasilkan proses klasifikasinya sebagai berikut  :  
Tabel 2. Hasil Klasifikasi Data Testing   
Dari hasil proses klasif ikasi yang disajikan pada tabel diatas maka dapat dikonversi kedalam bentuk tabel confussion matrix  seperti dibawah :  
Tabel 3.  Pengujian Confussion Matri x 
19 Record  Tidak Miskin  Miskin   
Actual : Tidak Miskin  4 1 5 
Actual : Miskin  2 12 14 6 13  
Berdasarkan tabel conffussion matrix  diatas maka kinerja dari penggunaan metode klasifikasi naive bayes dapat diukur dengan menghitung nilai accurasi, precision  dan recall.  
Accuracy  : (TP+TN)/Total   
: (12 + 4) / 19 = 73 %  
Precision  : TP / Predicted Miskin  
: 13 / 13 = 92 %  
Recall  : TP / Actual Miskin  
: 12 / 14 = 86 %  
id Umur  Status  Pendidikan Tanggungan  Pekerjaan  Penghasilan  Actual Class  Predicted Class  
1 Tua Kawin  SLTP  1 Pedagang  Tinggi  TIDAK MISKIN  TIDAK MISKIN  
2 Muda  Belum Kawin  SD 0 Buruh Lepas  Rendah  MISKIN  MISKIN  
3 Tua Kawin  Sarjana  3 Aparatur Negara  Tinggi  TIDAK MISKIN  TIDAK MISKIN  
4 Tua Kawin  SLTP  4 Petani  Rendah  MISKIN  MISKIN  
5 Muda  Kawin  Sarjana  4 Aparatur Negara  Tinggi  TIDAK MISKIN  TIDAK MISKIN  
6 Muda  Kawin  SD 3 Petani  Rendah  MISKIN  MISKIN  
7 Muda  Kawin  Tidak Sekolah  2 Petani  Sedang  MISKIN  TIDAK MISKIN  
8 Tua Kawin  SLTP  3 Buruh Lepas  Rendah  MISKIN  MISKIN  
9 Tua Cerai  SLTA  2 Tiada  Tiada  MISKIN  MISKIN  
10 Muda  Kawin  SD 3 Petani  Renda h MISKIN  MISKIN  
11 Muda  Kawin  SLTP  3 Petani  Sedang  TIDAK MISKIN  TIDAK MISKIN  
12 Muda  Belum Kawin  SD 0 Buruh Lepas  Rendah  TIDAK MISKIN  MISKIN  
13 Tua Kawin  SD 1 Tiada  Tiada  MISKIN  MISKIN  
14 Muda  Kawin  SD 3 Buruh Lepas  Rendah  MISKIN  MISKIN  
15 Muda  Kawin  SD 5 Petani  Sedang  MISKIN  TIDAK MISKIN  
16 Tua Kawin  SD 3 Petani  Rendah  MISKIN  MISKIN  
17 Tua Cerai  SLTA  1 Tiada  Tiada  MISKIN  MISKIN  
18 Tua Cerai  SD 2 Tiada  Tiada  MISKIN  MISKIN  
19 Tua Kawin  SD 3 Buruh Lepas  Rendah  MISKIN  MISKIN  
3.3 Hasil Klasifikasi pada Sistem  
Form di bawah ini menunjukkan Hasil akhir dari sistem , yang merupakan hasil klasifikasi pada setiap objek dengan menggunakan metode yang diusulkan, pada halaman ini juga nantinya dapat dilakukan proses pencetakan dari hasil klasifikasi tersebut sebagai bahan laporan kepada pimpinan/yang membutuhkan hasil klasifikasi tersebut .  
Gambar 2. Halaman Hasil Klasifikasi   
3.4  Pengujian Black -Box 
Tabel 4 . Hasil Pengujian Black-Box 
Input event  Fungsi  Hasil sistem  Hasil uji  Klik menu kelas  Untuk menampilkan form 
input kelas  Ditampilkan form input kelas  Sesuai  
Klik menu parameter  Untuk menampilkan form input parameter / atribut  Ditampilkan form input parameter / atribut  Sesuai  
Klik menu sub parameter  Untuk menampilkan form input sub parameter  
Ditampilkan form input sub parameter  Sesuai  
Klik menu training  Untuk menampilkan form input data latih / training  Ditampilkan form input data latih / training  Sesuai  
Klik menu objek  Untuk me nampilkan form input objek  Ditampilkan form input objek  Sesuai  
Klik menu hasil 
Klasifikasi  Untuk menampilkan hasil 
Klasifikasi keseluruhan objek  Ditampilkan hasil 
Klasifikasi keseluruhan objek  Sesuai  
Beri masukan pada form kelas dan klik tombol simpan/save Untuk menyimpan data kelas yang diketikkan pada database  Data kelas disimpan kedalam database  Sesuai  
Klik tombol tambah pada data objek  Untuk menampilkan form 
input data fakta / uji pada objek yang dimaksudkan  Ditampilkan form input data latih  Sesuai  
Diberi masukan pada form input data latih dan klik tombol 
simpan/save  
Untuk menyimpan data fakta/uji untuk objek tersebut  Data fakta/uji disimpan kedalam database  Sesuai  
 
4. Kesimpulan dan Saran   
4.1 Kesimpulan  
1. Sistem klasifikasi masyarakat miskin di wilayah pe merintahan Kab. Gorontalo dapat direkayasa, hal tersebut dapat dibuktikan melalui interface yang disajikan dan sistem yang telah direkayasa sudah dilakukan pengujian sistem dengan menggunakan whitebox  untuk memeriksan alur logika yang digunakan pada sistem  dan juga telah dilakukan pengujian blackbox  untuk memeriksa kesesuaian fungsi pada setiap interface yang ada.  
2. Berdasarkan hasil pengujian confussion matrix  dengan teknik split validasi, penggunaan metode klasifikasi naive bayes  terhadap dataset yang telah  diambil pada objek penelitian diperoleh tingkat akurasi sebesar 73% atau termasuk dalam kategori Good . Sementara nilai Precision  
sebesar 92% dan Recall  sebesar 86%. Berdasarkan hal tersebut dapat dinyatakan bahwa sistem klasifikasi yang dibangun dapat gun akan sebagai bahan masukan bagi pengambil keputusan   
4.2 Saran  
1. Mengingat nilai akurasi masih berada pada angka 73%, maka masih sangat dimungkin untuk dapat dilakukan penelitian selanjutnya untuk meningkatkan nilai akurasi  dengan menambahkan fitur seleksi atau penggunaan Algoritma komputer yang lain.  
2. Pada penelitian lain diharapkan dapat digunakan dataset dalam jumlah yang lebih besar atau dengan sejumlah variabel lainnya guna meningkatkan performa dari metode yang digunakan.  
5. Terima Kasih  
Terwujudnya publikasi  karya ilmiah ini tidak lepas dari bantuan berbagai pihak,yang telah memberikan dana penelitian melalui Hibah Penelitian Kompetitif di lingkungan Universitas Ichsan Gorontalo, oleh karena itu penulis mengucapkan terima kasih yang sebesar -besarnya kepada :  Ketua Yayasan PIPT Ichsan Gorontalo, Rektor Universitas Ichsan Gorontalo, Ketua Lembaga Penelitian Unisan Gorontalo dan Sekretaris Lemlit Unisan Gorontalo. Semoga hasil publikasi karya ilmiah ini, dapat bermanfaat bagi peneliti dan masyarakat.  

Daftar Pustaka  
[1] Sumanta, Jaka. 2005. Fenomena lingkaran kemiskinan di Indonesia  : Analisis ekonometri regional data panel propinsi tahun 1999 -2002. MPKP UI.  
[2] Suryawati. 2004. Teori Ekonomi Mikro. UPP. AMP YKPN. Yogyakarta  
[3] Ayub, Mewati. (2007). â€œ Proses Data Mining dalam Sistem Pembelajaran Berbantuan Komputer â€, Jurnal Sistem Informasi Vol. 2 No. 1 Maret 2007 : 21 -30 
[4] Mustafa , Muhammad Syukri . Simpen, I Wayan. (2014). Perancangan Aplikasi Prediksi Kelulusan Tepat Waktu Bagi Mahasiswa Baru Dengan Teknik Data Mining (Studi Kasus: Data Akademik Mahasiswa STMIK Dipanegara Makassar), ISSN: 2354-5771  
[5] Kursini, Luthfi, E. T., 2009, Algoritma Data Mining, Andi Offset, Yogyakarta.  
[6] Jananto, Arief. 2013. Algoritma Naive Bayes untuk Mencari Perkiraan Waktu Studi Mahasiswa.  
[7] Supriyanto, Catur. Purnama Parida. 2013. deteksi penyakit diabetes type ii dengan naive bayes berbasis particle swarm optimization. Jurnal Teknologi Informasi, Volume 9 Nomor 2, Oktober 2013  
[8] Kusumadewi, Sri dkk. 2006. Fuzzy Multi Attri bute Decison Making (FMADM). Yogyakarta.Graha Ilmu.  
[9] Bambang Hariyanto, (2004), Sistem Manajemen Basis Data, Informatika, Bandung  
[10] Jeffry, L. Whitten,et al. 2004. Metode Desain dan Analisis Sistem. Edisi I. Diterjemahkan oleh tim 
penerjemah ANDI. Y ogyakarta: Penerbit Andi Madcoms.  
[11] Jogiyanto, HM.,2005, Analisis dan Desain Sistem Informasi : PendekatanTerstruktur Teori dan Praktek Aplikasi  Bisnis , Yogyakarta : Andi",klasifikasi,naive bayes classifier,data penduduk miskin,"akurasi, precision, recall"
Penerapan Metode Naive Bayes Untuk Klasifikasi Pelanggan,"Penerapan Metode Naive Bayes Untuk Klasifikasi Pelanggan

Hakam Febtadianrano Putro1) Retno Tri Vulandari2) Wawan Laksito Yuly Saptomo3) 

ABSTRACT  
Business location plays an important role in sales. The business location in cities makes the seller easier to distribute activities for people. Distribution activities are closely related to sales activities. If there is a sales transaction, a classification of potential and non -potential customers will be required. One method that can be used for classification is mining data. One of the most frequently used data mining for classification is the Naive Bayes method. The attributes used in the customer classification process are purchase amount, time interval, and location. The result of classification system are 23 true reactions and 2 false reactions. Based on the results are using the confusion matrix method, it shows that the accuracy value reaches 92%, the precision value reaches 100%, the recall value reaches 91%.  

Keywords : Trading Business, Customer Classification, Naive Bayes, Confusion Matrix  
 
I. PENDAHULUAN  
Usaha dagang di Sukoharjo semakin berkembang pesat. Semakin banyak pula usaha dagang dalam bidang penjualan ayam. 
Dengan adanya usaha dagang ini juga meliputi aspek yang bermanfaat bagi masyarakat sekitarnya. Perkembangan teknologi yang terus berkembang membuat usaha dagang berlomba-lomba mencari terobosan baru. Permasalahan utama dalam usaha dagang ini masih kesulitan dalam mengolah data. Kurangnya pemanfaatan secara optimal dari banyaknya data transaksi untuk melihat pelanggan mana yang berpotensi atau tidak berpotensi. Data mining merupakan salah satu teknik dalam pengolahan data yang menemukan hubungan dari data yang tidak diketahui oleh pengguna serta menyajikan nya kedalam 
bentuk yang mudah dipahami sehingga dari hubungan data tersebut dapat dijadikan sebagai dasar dalam pengambilan keputusan  [1]. Data mining dibagi menjadi beberapa 
kelompok berdasarkan tugas yang dapat dilakukan yaitu : Deskripsi, Estimasi, Prediksi, Klasifikasi, Clustering, dan  Asosiasi  [2]. Secara singkat, klasifikasi merupakan 
pengelompokan objek kedalam kelas tertentu berdasarkan kelompoknya yang biasanya disebut dengan kelas ( class ). Salah satu metode klasifikasi yang sering digunakan adalah metode naive bayes. Berdasarkan penelitian yang telah dilakukan sebelumnya menggunakan  metode naive bayes.  Metode naive bayes memiliki kelebihan,  yaitu cepat dalam perhitungan, algoritma yang sederhana dan berakurasi tinggi  [3]. Metode Naive Bayes yang hanya membutuhkan jumlah data pelatihan ( Training  Data) yang kecil untuk menentukan estimasi parameter yang diperlukan dalam proses pengklasifikasian  [4]. Metode Algoritma Naive Bayes Casifier lebih mudah digunakan karena memiliki alur perhitungan yang tidak panjang  [5] Dari permasalahan tersebut maka menerapkan metode naive bayes untuk 
mengklasifikasikan pelanggan. Adapun Tujuan dari penelitian ini adalah membuat aplikasi yang dapat membantu mengklasifikasikan pelanggan yang berpotensi dan tidak berpo tensi, serta digunakan sebagai dasar pertimbangan keputusan salah satunya sebagai strategi pemasaran.  
 
II. TINJAUAN PUSTAKA  
2.1 Data Mining  
Data mining adalah serangkaian proses untuk menggali nilai tambah berupa informasi yang selama ini tidak diketahui secara manual dari suatu basis data. Informasi yang dihasilkan diperoleh dengan cara mengekstraksi dan mengenali pola yang penting atau mencari dari data yang terdapat 
pada basis data. Data mining terutama digunakan untuk mencari pengetahuan yang terdapat dalam basis data yang besar sehingga sering disebut Knowledge Discovery Databases  (KDD)  [6]. Klasifikasi merupakan suatu pekerjaan menilai objek data untuk memasukkannya ke dalam kelas tertentu dari sejumlah kelas yang tersedia. Dalam klasifikasi ada dua pekerjaan utama yang dilakukan, yaitu (1)Pembangunan 
model sebagai prototype  untuk disimpan sebagai memori dan (2) Penggunaan model tersebut untuk melakukan pengenalan/klasifikasi/prediksi pada suatu objek data lain agar diketahui dikelas mana objek data tersebut dalam model yang sudah disimpannya  [7].  
2.2 Personal Home Page Hipyertext 
Preprocessor  (PHP)  PHP merupakan bahasa berbentuk script 
yang ditempatkan dalam server dan diproses di server. PHP singkatan dari Hipyertext Preprocessor  yaitu bahasa pemrograman web server-side yang bersifat open source  
[8]. Artinya semua sintaks yang diberikan akan sepenuhnya dijalankan pada server, sedangkan yang dikirimkan ke browser  hanya hasilnya saja. PHP tergolong sebagai perangkat lunak open source  yang diatur dalam aturan General Public Lice nse (GPL). PHP dirancang khusus untuk membentuk web dinamis, artinya PHP mampu menghasilkan website yang secara terus menerus hasilnya bisa berubah -ubah sesuai dengan pola yang diberikan. Hal ini berkaitan erat dengan basis data sebagai sumber data yang akan ditampilkan  [9].  
2.3 Penelitian Terkait  
Penelitian tentang prediksi besarnya Penggunaan listrik rumah tangga. Tujuan dari penelitian ini mampu untuk memprediksi besarnya penggunaan listrik tiap rumah tangga agar lebih mudah mengatur penggunaan listrik. Variabel yang dipakai meliputi jumlah tanggungan keluarga, luas rumah, pendapatan/bulan, daya listrik, perlengkapan yang dimiliki. Metode yang dipakai menggunakan metode Naive Bayes. Hasil dari penelitian ini persentase 78,3333% untuk keakuratan prediksi, di mana dari 60 data penggunaan listrik rumah tangga yang diuji terdapat 47 data penggunaan listrik rumah tangga yang berhasil diklasifikasikan dengan benar  [10]. Penelitian tentang penerapan data mining pada penjualan barang menggunakan metode Naive Bayes Classifier  untuk optimasi strategi pemasaran. Tujuan dari penelitian ini 
untuk mengetahui minat dan ketertarikan calon pembeli terhadap produk yang tersedia. Variabel yang dipakai meliputi bulan, model barang, harga barang, terjual. Metode yang dipakai menggunakan metode NaÃ¯ve Bayes. Hasil dari penelitian ini didapatkan nilai p value ( sig ), nilai p value ( sig ) 0,807 > 0,05 maka Ho diterima dan Ha ditolak, nilai t- hitung dan t-tabel, Nilai t- hitung â€“ 0,246 > - t-tabel -2,045 maka Ho diterima dan Ha ditolak [11]. Penelitian tentang penentuan penerima beasiswa bidikmisi Universitas Mulawarman. Tujuan dari penelitian ini untuk membantu bagian proses seleksi dengan membuat aplikasi  perangkat lunak sistem pendukung keputusan untuk penentuan penerima beasiswa bidikmisi Universitas Mulawarman. Variabel yang dipakai meliputi pekerjaan orang tua, penghasilan orang tua, jumlah tanggungan, daya listrik( watt), dan nilai ujian 
nasional. Metode yang dipakai menggunakan metode Naive Bayes. Hasil dari penelitian ini menghasilkan sebuah aplikasi sistem pendukung keputusan dengan tingkat akurasi 
sebesar 85.56%  [12]. Penelitian tentang penentuan kelayakan 
pemilihan tempat  tinggal. Tujuan dari penelitian ini untuk konsumen dalam mempertimbangkan penentuan pencarian 
tempat tinggal. Variabel dipakai meliputi keamanan, fasilitas umum, bebas banjir, harga, air bersih, model, sejuk dan nyaman. Metode yang dipakai menggunakan metode 
Naive Bayes. Hasil dari penelitian ini menghasilkan probabilitas antara layak (sesuai) atau tidak sesuai, yang nantinya dapat digunakan oleh masyarakat umum untuk mempermudah dalam penentuan pencarian tempat tinggal  [13]. 
Penelitian tentang klasifikasi kelayakan keluarga penerima beras rastra. Tujuan dari penelitian ini untuk mengatasi masalah yang belum optimal di desa Bandar Siantar Kecamatan Gunung Malela. Variabel yang dipakai meliputi Nama Kepala Rumah Tangga, PKH, Jml Ta ngungan, Kepala Rumah Tangga, Kondisi Rumah, Jml Penghasilan, Status Pemilik Rumah. Metode 
yang dipakai menggunakan metode Naive Bayes. Hasil dari penelitian ini diharapkan dapat membantu pemerintah khususnya di daerah dalam menentukan kelayakan keluarga penerima beras Rastra  [14]. Bayesian classification  adalah 
pengklasifikasian statistik yang dapat digunakan untuk memprediksi probabilitas keanggotaan suatu class. Bayes classification  didasarkan pada teorema Bayes yang memiliki kemampuan klasifikasi serupa dengan  decision tree dan neural network. Bayesian classification  terbukti memiliki 
akurasi dan kecepatan yang tinggi saat diaplikasikan ke dalam database dengan data yang besar  [15]. NBC merupakan salah satu algoritma klasifikasi yang sederhana namun memiliki kemampuan dan akurasi tinggi.   
P(Ci|X)= P(X|Ci).P(Ci)
P(X) 
dengan  
X : data dengan class yang belum diketahui  
Ci : hipotesis data X merupakan suatu class spesifik  
P(Ci|X) :probabilitas hipotesis C i berdasarkan kondisi X ( posteriori probability ) 
P(Ci) : probabilitas hipotesis Ci ( prior 
probability ) 
P(X|Ci) : probabilitas X berdasrkan kondisi pada hipotesis C i 
P(X) : probabilitas dari X  
Naive Bayesian Classifier mengasumsikan bahwa keberadaan sebah atribut (variabel) tidak ada kaitannya dengan beradaan atribut (variabel) yang lain karena asumsi atribut tidak saling terkait (conditionally independent ), ditulis dengan 
rumus:  
P(X|Ci)=âˆ‘ P(Xk|Cin k=1) 
Setelah diperoleh hasil dari seluruh data pada setiap class, maka hasil akhirnya dapat menggunakan rumus:  
P(X|Ci)=argmaxP (Xi|Ci)âˆ—P(Ci) 
 
III. METODE PENELITIAN  
Dalam penyusunan penelitian ini diperlukan metode -metode penelitian dalam proses pengumpulan data antara lain:   
3.1 Sumber Data  
a. Data Primer  
Data primer diperoleh dari hasil kegiatan pengumpulan data terhadap data transaksi penjualan ayam.  
b. Data Sekunder  
Data sekunder dalam penelitian ini melakukan pengolahan data dari data laporan penjualan ayam untuk menentukan kriteria status usaha, jumlah pembelian, dan lokasi.  Selain itu untuk menunjang data pendukung yang diperoleh dari media pustaka tentang teori-teori yang digunakan dalam penelitian ini. Adapun data sekunder yang diantaranya Data Mining, Klafikasi, Naive Bayes, MySQL, PHP, UML, Kajian Pustaka.   
3.2 Metode Pengump ulan Data  
a. Metode Observasi, dalam penelitian ini dilakukan pengamatan terhadap prosedur penjualan ayam.  
b. Metode Wawancara, menanyakan langsung kepada pemilik UD.Samodro untuk mendapatkan data yang akan diteliti untuk menyesuaikan proses data yang akan diolah menggunakan metode 
Naive Bayes.  
c. Studi Pustaka, terdiri dari literatur mengenai penelitian yang sedang dilakukan. Literatur yang dimaksud diantaranya beberapa jurnal ilmiah dan buku yang terkait dengan kasus 
penelitian ini. Adapun jurnal ilmiah dan buku yang dijadikan sebagai acuan.   
3.3 Metode Pengembangan Sistem  
a. Perancangan Sistem  
Perancangan sistem dalam penelitian ini menggunakan UML diharapkan pengerjaan bahasa visual yang lebih jelas dan terstruktur baik user yang digunakan.  
b. Kontruksi Sistem  
Kontruksi sistem dalam penelitian ini penunjang pembuatan sebuah aplikasi yang saling berkaitan, yaitu perangkat keras(hardware), perangkat lunak (software).  
c. Pengujian Sistem  
Proses selanjutnya pengujian aplikasi yang telah dibuat akan diuji untuk mengetah ui apakah  aplikasi yang dibuat sudah berjalan dengan dan sesuai perancangan yang dilakukan.  
 
IV. HASIL DAN PEMBAHASAN  
4.1 Klasifikasi Pelanggan  
Data latih dan data uji yang digunakan 
untuk klasifikasi berjumlah 75 data latih dan (1) 
-2
(3) 
25 data uji, dimana data latih selanjutnya akan proses menggunakan metode naive bayes. Adapun data latih yang digunakan dapat dilihat pada Tabel 1.   
Tabel 1. Data Latih  
Kode Pelanggan  Jumlah Pembelian  Interval Waktu  Lokasi  Target  
P1 Sangat Banyak  Harian  Dekat  Berpotensi  
P2 Sangat Banyak  Harian  Jauh  Berpotensi  
P3 Sangat Sedikit  Mingguan  Jauh  Tidak Berpotensi  
P4 Sangat Sedikit  Mingguan  Dekat  Tidak Berpotensi  
P5 Banyak  Harian  Jauh  Berpotensi  
P6 Banyak  Harian  Dekat  Berpotensi  
P7 Sangat Sedikit  Mingguan  Dekat  Tidak Berpotensi  
P8 Sangat Sedikit  Mingguan  Dekat  Tidak Berpotensi  
P9 Banyak  Harian  Jauh  Berpotensi  
P10 Banyak  Harian  Jauh  Berpotensi  
P11 Sedikit  Harian  Dekat  Berpotensi  
P21 Sedikit  Harian  Dekat  Berpotensi  
P31 Sangat Sedikit  Harian  Jauh  Tidak Berpotensi  
P41 Sangat Banyak  Harian  Dekat  Berpotensi  
P51 Sangat Sedikit  Mingguan  Jauh  Tidak Berpotensi  
P61 Sedikit  Harian  Dekat  Berpotensi  
P71 Sedikit  Mingguan  Dekat  Berpotensi  
P75 Sangat Banyak  Harian  Dekat  Berpotensi   
Data yang dipakai sebagai data latih dan uji menggunakan data pada tahun 2019 yang dapat dilihat pada Tabel 2.   
Tabel 2. Komposisi Data Latih & Data Uji  
Jenis Data  Jumlah  Keterangan  
Data Latih  75 Penjualan pada Bulan Juni - Agustus  
Data Uji  25 Penjualan pada Bulan Juni - Agustus   
Adapun nilai probabilitas setiap kriteria yang didapatkan dari data latih pada Tabel 1. Ditentukan nilai probabilitas dari setiap kriteria kedalam kategori, yaitu :  
a. Probabilitas jumlah pembelian pada setiap class, seperti pada Tabel 3.   
Tabel 3. Probabilitas Jumlah Pembelian  Jumlah Pembelian Jumlah kejadian  
â€Jumlah Pembelianâ€  Probabilitas  
Berpotensi  Tidak 
Berpotensi  Berpotensi  
Tidak Berpotensi  Sangat 
Banyak  19/55  0/20 0,34 0 
Banyak  18/55  0/20 0,33 0 
Sedikit  17/55  2/20 0,31 0,1 
Sangat Sedikit  1/55 18/20  0,02 0,9 
b. Probabilitas interval waktu pada setiap class, seperti pada Tabel 4.  
Tabel 4. Probabilitas Interval Waktu  
Interval Waktu  Jumlah kejadian  
â€Interval Waktuâ€  Probabilitas  
Berpotensi  Tidak 
Berpotensi  Berpotensi  Tidak Berpotensi  
Harian  53/55  3/20 0,95 0,15 
Mingguan  3/55 17/20  0,05 0,85 
c. Probabilitas lokasi pada setiap class, seperti pada Tabel 5.  
Tabel 5. Probabilitas Lokasi  
Lokasi  Jumlah kejadian 
â€Lokasiâ€  Probabilitas  
Berpotensi  Tidak 
Berpotensi  Berpotensi  
Tidak Berpotensi  
Dekat  39/55  7/20 0,71 0,35 
Jauh  16/55  13/20  0,29 0,65 
d. Probabilitas target pada setiap class , 
seperti pada Tabel 6.  
Tabel 6. Probabilitas Target  
Jumlah Kejadian â€Targetâ€  Probabilitas  
Berpotensi  Tidak Berpotensi  
Berpotensi  Tidak Berpotensi  
55/75  20/75  0,73 0,27  
4.2 Pengujian Metode Naive Bayes 
Menggunakan Data Testing  Setelah proses klasifikasi menggunakan metode naive bayes selesai, selanjutnya pengujian data uji yang berjumlah 25 data pelanggan dapat dilihat pada Tabel 7.  
Tabel 7. Data Uji  
Kode Pelanggan  Jumlah Pembelian  Interval Waktu  Lokasi  Prediksi Target  
P76 Banyak  Harian  Dekat  Berpotensi  
P77 Sedikit  Mingguan  Dekat  Berpotensi  
P78 Banyak  Harian  Jauh  Berpotensi  
P79 Banyak  Harian  Jauh  Berpotensi  
P80 Banyak  Harian  Dekat  Berpotensi  
P81 Sedikit  Harian  Dekat  Berpotensi  
P82 Sangat Banyak  Harian  Dekat  Berpotensi  
P83 Sedikit  Harian  Jauh  Berpotensi  
P84 Sangat Banyak  Harian  Dekat  Berpotensi  
P85 Banyak  Harian  Dekat  Berpotensi  
P86 Sangat Banyak  Harian  Dekat  Berpotensi  
P87 Banyak  Harian  Dekat  Berpotensi  
P88 Sangat Sedikit  Mingguan  Jauh  Tidak Berpotensi  
P89 Banyak  Harian  Jauh  Berpotensi  
P90 Sedikit  Mingguan  Dekat  Berpotensi  
P91 Sedikit  Mingguan  Dekat  Berpotensi  
P92 Sangat Sedikit  Harian  Dekat  Tidak Berpotensi  
P93 Sangat Sedikit  Harian  Dekat  Tidak Berpotensi  
P94 Sangat Sedikit  Mingguan  Dekat  Tidak Berpotensi  
P95 Sangat Banyak  Harian  Dekat  Berpotensi  
P96 Banyak  Harian  Dekat  Berpotensi  
P97 Sedikit  Mingguan  Dekat  Berpotensi  
P98 Banyak  Harian  Jauh  Berpotensi  
P99 Banyak  Harian  Jauh  Berpotensi  
P100  Banyak  Harian  Dekat  Berpotensi 
Hasil klasifikasi yang disajikan pada Tabel 8, maka selanjutnya dapat dikonversikan menggunakan metode  confusion matrix seperti bawah ini :  
Tabel 8. Pengujian Conffusion Matrix  
Confusion Matrix  Data Sebenarnya  
TRUE  FALSE  
Data Prediksi  TRUE  21 0 FALSE  2 2  
Dari tabel confusion matrix  diatas maka kinerja dari penggunaan metode naive bayes dapat diukur dengan menghitung nilai precision, recall, acuracy . Dalam perhitungan ini  sekaligus dikonversikan kedalam bentuk presentase.  
a). Maka untuk menghitung nilai precision  menggunakan rumus (1), hasil perhitungan sebagai berikut :  
Nilai Precision = 21/ (21+0)   = 100%  
b). Maka untuk menghitung nilai recall menggunakan rumus (2.1), hasil perhitungan sebagai berikut :  
Nilai Recall = 21/  (21+2)   = 91%  
c). Maka untuk menghitung nilai accuracy menggunakan rumus (2.1), hasil perhitungan sebagai berikut :  
Nilai Accuracy  = 21+2/ (21+2+0+2)  = 92%  
 
V. PENUTUP  
5.1 Kesimpulan  
Berdasarkan penelitian tentang klasifikasi pelanggan menggunakan metode naive bayes dapat ditarik kesimpulan dari 
beberapa kesimpulan sebagai berikut:  
1. Penerapan metode naive bayes untuk mengklasifikasikan pelanggan dapat membantu pemilik memberikan bonus terhadap pelanggan berpotensi dan meningkat kualitas yang lebih baik lagi terhadap pelanggan.  
2. Aplikasi metode naive bayes untuk mengklasifikasikan pelanggan dirancang dengan menggunakan aplikasin PHP dan 
MySQL.  
3. Berdasarkan master pelanggan yang dijadikan data latih, telah berhasil mengklasifikasikan 23 data dari 25 data   yang diuji. Sehingga berhasil memprediksi pelanggannya dengan nilai precision  mencapai 100%, nilai recall  mencapai 91%, nilai accuracy  mencapai 92%.   
5.2 Saran  
Saran yang dapat dituliskan untuk penelitian ini adalah sebagai berikut: Sistem yang dibuat masih cukup sederhana  karena mengutamakan proses perhitungan dan hasil 
perhitungan sehingga diharapkan sistem dikembangkan lebih detail.  

DAFTAR PUSTAKA  
[1]  M. Ridwan, H. Suyono and M. Sarosa, Penerapan Data Mining untuk Evaluasi Kinerja Akademik Mahasiswa menggunakan Algoritma Naive Bayes Classifier,"""" EECCIS, vol. VII, 2013.  
[2]  W. Muslehatin, M. Ibnu and Mustakim. , Penerapan NaÃ¯ve Bayes Classification untuk Klasifikasi Tingkat Kemungkinan 
Obesitas Mahasiswa Sistem Informasi UIN Suska Riau,"""" 2017.  
[3]  H. Muhamad, C. Prasojo, N. Sugianto, L. Surtiningsih and I. Cholissodin, """"Optimasi Naive Bayes Classifier dengan 
Menggunakan Particle Swarm Optimization pada Data Iris,"""" Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK), vol. IV, pp. 180 -184, 2017.  
[4]  E. Manulu, F. Sianturi and M. Manulu, Penerapan Algoritma Naive Bayes untuk Memprediksi Jumlah Produksi Barang Berdasarkan Data Persediaan dan Jumlah Pemesanan PASTRIES,"""" Jurnal Mantik Penusa, vol. I, 2017.  
[5]  T. Rosandy, """"Perbandingan Metode Naive  Bayes Classifier dengan Metode Decision Tree (C4.5) untuk Menganalisa Kelancaran Pembiayaan (Studi Kasus : KSPPS/BMT Al -Fadhila),"""" Jurnal TIM Darmajaya, vol. II, p. 52, 2016.  
[6]  Vulandari, Data Mining Teori dan Aplikasi Rapidminer, Yogyakarta: Gava Me dia, 2017.  
[7]  E. Prasetyo, Data Mining Konsep dan Aplikasi Menggunakan MATLAB, Yogyakarta: ANDI , 2012.  
[8]  Anhar. Panduan Menguasai PHP & MySQL Secara Otodidak, jakarta: Mediakita, 2010.  
[9]  S. Faisal, Aplikasi Berbasis Web dengan PHP & MySQL, Y ogyakarta: Ram Media, 2011.  
[10]  A. Saleh, """"Implementasi Metode Naive Bayes Dalam Memprediksi Besarnya Penggunaan Listrik Rumah Tangga,"""" Jurnal TIKomSiN, Vol. 8, No. 2, Oktober  2020 ISSN Cetak  : 2338 -4018 ISSN Online  : 2620 -7532  24 Citec Journal, 2015.  
[11]  O. Nurdiawan and N. Salim, """" Penerapan Data Mining Pada Penjualan Barang Menggunakan Metode Naive Bayes Classifier Untuk Optimasi Strategi Pemasaran,"""" Jurnal Teknologi Informasi dan Komunikasi, 2018.  
[12]  D. Dahri, F. Agus and D. Khairina, Metode Naive Bayes Untuk Penentuan Penerima Beasiswa Bidikmisi Universitas 
Mulawarman,"""" Jurnal Informatika Mulawarman, 2016.  
[13]  D. Fithri, """"Model Data Mining Dalam Penentuan Kelayakan Pemilihan Tempat Tinggal Menggunakan Metode Naive 
Bayes,"""" Jurnal SIMETRIS, 2016.  
[14]  C. Fadlan, S. Ningsih and A. Windarto, Penerapan Metode Naive Bayes Dalam Klasifikasi Kelayakan Keluarga Penerima Beras Rastra,"""" JUTIM, 2018.  
[15]  Kusrini. and E. Luthfi, Algoritma Data Mining, Yogyakarta: ANDI, 2019.  ",klasifikasi,Naive Bayes Classifier,"data transaksi, data laporan penjualan ayam","precision, recall, accuracy"
ANALISIS DATA HASIL DIAGNOSA UNTUK KLASIFIKASI GANGGUAN KEPRIBADIAN MENGGUNAKAN ALGORITMA C4.5,"ANALISIS DATA HASIL DIAGNOSA UNTUK KLASIFIKASI GANGGUAN KEPRIBADIAN MENGGUNAKAN ALGORITMA C4.5

Siska Febriani1, Heni Sulistiani2 

Abstract  
Psychological disorders also vary, according to the American Psychiantric Association DMS-IV-TR (2000), namely: anxiety disorders consisting of phobic disorders, panic disorders, and generalized anxiety disorders (GAD). Mood disorders include major depression and bipolar disorder. Somatoform disorders consist of pain disorders, body dysmorphic disorders, hypochodiasis disorders, conversion disorders and somatization disorders. Of the three disorders, the authors only focused on examining anxiety disorders (GAD), mood disorders (major depressive disorder) and somatoform disorders (conversion disorder). Because these disorders are most often experienced by society in general. But that's not all, there are still various other psychological disorders that need to be watched out for because they seem common to a person but can unknowingly have a bad effect if the condition is severe. The method used in this study is the classification of data is C4.5 by using primary data obtained from the community questionnaire for the classification process. The determination is classified as a classification process using Rapid Miner for classification and using cross validation as validation of data accuracy. The results of this study are predictions of personality disorders to produce information needed by the community.  
 
Kata kunci: Data Mining, Algoritma C4.5, dan Cross Validation .  
 
Abstrak  
Gangguan psikologis  juga bermacam -macam, menurut American Psychiantric Association DMS-IV-TR (2000), yaitu: gangguan kecemasan yang terdiri dari gangguan fobia, gangguan panik, dan gangguan kecemasan umum (GAD). Gangguan mood termasuk depresi berat dan gangguan bipolar. Gangguan somatoform terdiri dari gangguan nyeri, gangguan dismorfik tubuh, gangguan hipokodiasis, gangguan konversi dan gangguan somatisasi. Dari ketiga gangguan tersebut, penulis hanya memfokuskan pada pemeriksaan gangguan kecemasan (GAD), gangguan mood (gangguan depresi mayor) dan gangguan somatoform (gangguan konversi). Karena gangguan tersebut paling sering dialami oleh masyarakat pada umumnya. Namun bukan itu saja, masih ada berbagai gangguan psikologis lainnya yang perlu diwaspadai karena terlihat biasa pada seseorang namun tanpa disadari bisa berdampak buruk jika kondisinya sudah parah. Metode yang digunakan dalam penelitian ini adalah klasifikasi data C4.5 dengan menggunakan data primer yang diperoleh dari angket 
masyarakat untuk proses klasifikasi. Penetapan tersebut diklasifikasikan sebagai proses klasifikasi menggunakan Rapid Miner untuk klasifikasi dan menggunakan validasi silang sebagai validasi keakuratan data. Hasil dari penelitian ini adalah prediksi gangguan kepribadian untuk menghasilkan informasi yang dibutuhkan oleh masyarakat.  
 
Kata kunci: Data Mining, Algoritma C4.5, dan Cross Validation.  

1. Pendahuluan  
Gangguan psikologis adalah kondisi kelainan pada seseorang yang mengakibatkan perbedaan pola perilaku, pikiran hingga emosi yang memengaruhi kehidupan sehari-hari. Di Indonesia, penderita gangguan mental diidentikkan dengan sebutan â€˜orang gilaâ€™ atau â€˜sakit jiwaâ€™, dan sering mengalami perlakuan yang tidak menyenangkan, bahkan hingga dipasung. Padahal, penderita gangguan mental bisa dibawa ke rumah sakit untuk diberikan pengobatan. Ada banyak faktor yang bisa memicu terjadinya gangguan mental, mulai dari menderita 
penyakit tertentu sampai mengalami stres akibat peristiwa 
traumatis, seperti ditinggal mati orang yang disayang, 
kehilangan pekerjaan, atau terisolasi untuk waktu yang 
lama. Mengingat peristiwa-peristiwa traumatis tersebut kerap dialami banyak orang akhir-akhir ini, maka tak heran adanya pandemi COVID-19 juga sering dikaitkan dengan munculnya gangguan mental pada seseorang [1] [2]. Menurut data WHO (2016), terdapat sekitar 35 juta orang terkena depresi, 6 0 juta orang terkena bipolar, 21 juta terkena skizofrenia, serta 47,5 juta terkena dimensia. Di Indonesia, dengan berbagai faktor biologis, psikologis dan sosial dengan keanekaragaman penduduk jumlah kasus gangguan jiwa terus bertambah yang berdampak  pada penambahan beban negara dan 
penurunan produktivitas manusia untuk jangka panjang.  Data Riskesdas 2013 menunjukkan prevalensi ganggunan mental emosional yang ditunjukkan dengan gejala-gejala depresi dan kecemasan untuk usia 15 tahun ke atas mencapai sekitar 14 juta orang atau 6% dari jumlah penduduk Indonesia. Sedangkan prevalensi gangguan jiwa berat, seperti skizofrenia mencapai sekitar 400.000 orang atau sebanyak 1,7 per 1.000 penduduk . 
Gangguan psikologis pun bermacam-macam, menurut American Psychi antric association  DMS-IV-TR (2000) yaitu: gangguan kecemasan terdiri dari gangguan fobia, gangguan panik, dan gangguan GAD ( Generalized anxiety disorder ). Gangguan mood terdiri dari depresi mayor dan gangguan bipolar. Gangguan somatoform terdiri dari gang guan nyeri, gangguan dismorfik tubuh, gangguan hipokodiasis, gangguan konversi dan gangguan 
somatisasi. Dari ketiga gangguan tersebut penulis hanya 
memfokuskan untuk meneliti gangguan kecemasan (gangguan GAD), gangguan mood (gangguan depresi mayor) dan gan gguan somatoform (gangguan konversi). Karena gangguan tersebut yang paling sering di alami masyarakat pada umumnya. Namun tidak sebatas itu saja, masih ada berbagai gangguan psikologis lainnya yang perlu diwaspadai karena tampak umum dialami seseorang tapi secara tidak sadar bisa memberi efek buruk jika kondisinya sudah parah.  Untuk mencegah terjadinya peningkatan gangguan mental, maka perlu upaya sedini mungkin untuk mengenal kondisi psikologis, maka dari itu harap diketahui faktor-faktor yang menimbulkan gangguan mental dan gejala-gejalanya sebagai bentuk deteksi diagnosis. Deteksi yang biasa dilakukan ialah dengan mengenali gejala-gejala ketidakwajaran pada jiwa. Pendekatan diagnosis ini dilakukan untuk mencegah terjadinya kekalutan mental yang lebih parah yang dapat merusak kepribadian. 
Pentingnya melakukan deteksi dini juga dapat membantu dalam mengetahui dan memahami terhadap kondisi psikologis individu dalam menanggulangi akan terjadinya gangguan jiwa serta dapat memberikan penangan yang lebih baik  [3] [4]. Banyak cara yang dapat dilakukan untuk mendeteksi gangguan kepribadian salah satunya dengan menggunakan teknik data mining. Data mining adalah proses yang menggunakan teknik  statistic, matematika, kecerdasan buatan dan machine learning  untuk mengekstrasi dan mengidentifikasi informasi yang bermanfaat dan pengetahuan yang terkait dari berbagai 
database  yang besar. Didalam data mining  terdapat beberapa metode salah satunya algo ritma C4.5. Algoritma C4.5 merupakan algoritma yang digunakan untuk memprediksi sebuah keputusan dengan menerapkan serangkaian aturan keputusan  [5]. Algoritma C4.5 juga diterapkan di dalam berbagai kasus. Anna Hendri Soleliza Jones melakukan penelitian tentang penerapan algoritma C4.5 untuk indexing data pasien dalam mendiagnosa penyakit gangguan kepribadian dengan hasil akurasi sebesar 80%. Penelitian tentang penerapan algoritma C4.5 untuk deteksi  dini gangguan autisme pada anak dengan hasil akurasi sebesar 72. Penelitian tentang penerapan data mining untuk klsifikasi gangguan jiwa menggunakan metode fuzzy logic  di telah dilakukan oleh [6] [7]. Dalam penelitian ini diharapkan algoritma C4.5 dapat melakukan klasifikasi gangguan psikologis berdasarkan gejala -gejala yang telah ditentukan, sehingga dapat membantu dalam proses 
kegiatan diagnosis secara cepat dan tepat.  Berdasarkan penelitian -penelitian terdahulu, algoritma C4.5 memiliki nilai akurasi lebih dari 60% sehingga dalam penelitian ini diusulkan untuk menerapkan algoritma tersebut untuk mendeteksi gangguan psikologis. Diharapkan nilai akurasi dalam diagnosa gangguan psikologis mampu mencapai 70%.  
 
2. Tinjauan Pustaka   
2.1. Ganggu an Psikologis  
Gangguan psikologis adalah kondisi kelainan pada seseorang yang mengakibatkan perbedaan pola perilaku, pikiran hingga emosi yang mem pengaruhi kehidupan sehari-hari. Gangguan psikologis adalah kondisi dimana seseorang mengalami cara berpikir, perilaku, serta emosi yang abnormal. Biasanya hal ini terjadi karena berbagai faktor, seperti trauma di masa lalu, depresi, maupun faktor genetik.    
2.1.1.  Macam -Macam Gangguan Psikologis  
1. Gangguan Kecemasan  
Gangguan kecemasan  adalah salah satu bentuk gangguan psikologis yang melibatkan reaksi tubuh ter hadap situasi yang mengancam. Berbeda dari rasa cemas pada umumnya, gangguan kecemasan membuat penderitanya mengalami rasa takut dan reaksi cemas yang berlebihan. Kondisi ini juga dapat semakin buruk dari waktu ke waktu. Menurut  Anxiety  and Depression  Association  of America, gangguan kecemasan adalah gangguan mental yang paling umum di Amer ika Serikat, memengaruhi 40 juta orang dewasa yang berusia 18 tahun ke atas.  Gangguan kecemasan terdiri dari beberapa jenis yaitu : Gangguan fobia, gangguan panik, dan gangguan GAD (Generalized  anxiety disorder).  Gangguan fobia adalah ketakutan yang kuat atau keengganan terhadap akan suatu objek atau situasi tertentu. Gangguan panik adalah munculnya rasa ketakutan yang intens yang datang dengan cepat dan hanya berlangsung dalam beberapa menit secara tiba-tiba. Sedangkan gangguan GAD adalah gangguan yang menunjukkan kecemasan  atau kekhawatiran yang berlebihan hampir setiap hari setidaknya selama 6 bulan.  
2. Gangguan  Mood  
Gangguan mood adalah kondisi perubahan suasana hati atau emosi yang tidak biasa. Di mana kondisi tersebut sampai menggangu kegiatan sehari-hari seseorang. Gangguan mood 
terdiri dari 2 jenis yang paling umum terjadi yaitu, bipolar dan depresi. Bipolar adalah seseoranng yang mengalami kondisi ini akan menunjukkan gejala perubahan mood atau suasana hati yang ekstrem. Depresi merupakan salah satu masalah kesehatan mental serius yang berbahaya dan banyak terjadi. Gangguan depresi terbagi menjadi depresi mayor dan depresi persisten atau disebut juga distimia. Depresi mayor adalah jenis depresi yang membuat penderitanya merasa sedih dan putus asa sepanjang waktu. Sedangkan depresi persisten 
atau distimia merupakan istilah yang digunakan untuk menggambarkan kondisi depresi yang besifat kronis.  
3. Gangguan Somatoform  
Gangguan somatoform merupakan kelainan psikologis pada seseorang yang ditandai dengan sekumplan keluhan fisik yang tidak menentu, namun tidak tampak saat pemeriksaan fisik. Munculnya gangguan ini biasanya disebabkan oleh stres dan banyak pikiran. Gangguan somatoform terdiri dari gangguan nyeri, gangguan dismorfik tubuh, gangguan hipokondriasis, gangguan konversi dan gangguan somatisasi. Gangguan nyeri adalah suatu kondisi ketika seseorang merasakan rasa sakit terus-menerus yang setelah diperiksa tidak bisa  ditemukan penyebab fisiknya. Gangguan dismorfik tubuh merupakan kondisi ketika penderitanya lebih banyak menghabiskan waktu untuk khawatir terkait penampilan tubuhnya. Gangguan hipokondriasis adalah kondisi ketika seseoranng takut bahwa gejala ringan yang  dialaminya disebabkan oleh penyakit serius. Gangguan konversi adalah kondisi ketika penderitanya memiliki gejala yang menunjukkan adanya penyakit serius pada sistem syaraf, namun tidak dapat ditelusuri penyebab medisnya. Gangguan somatisasi adalah keluhan  fisik  di berbagai bagian tubuh yang disebabkan oleh stres atau beban mental yang berat.   
2.2. Data Mining  
Menurut [9] [10] perkembangan data mining yang pesat tidak dapat  lepas dari perkembangan teknologi informasi yang memungkinkan data dalam jumlah  yang besar terakumulasi. Tetapi pertumbuhan yang pesat dari akumulasi data telah menciptakan suatu kondisi yang disebut dengan â€œ rich of data but poor of informationâ€ karena data yang terkumpul itu tidak dapat digunakan dalam suatu aplikasi yang berguna. Bahkan tidak jarang kumpulan data tersebut dibiarkan begitu saja sehingga tercipta â€œ data tombsâ€ (kuburan data).  Dalam jurnal ilmiah, data mining juga dikenal dengan nama KDD ( Knowledge Discovery in Database ). Namun pada tahun 1995, telah diadakan Internatio nal KDD Conference di Montreal yang berhasil mendefinisikan bahwa KDD merupakan suatu proses dalam mengenali informasi atau suatu kebenaran baru dan benar-benar berguna serta mengenali pola yang dapat 
dimengerti dari data. Tujuan utama dari proses KDD adalah memprediksikan nilai -nilai yang berguna dari variabel- variabel yang ada atau menemukan pola-pola dari sebuah gugusan data yang dapat diinterpretasikan oleh manusia. Sesuai dengan tujuan tersebut, maka proses dalam mengenali informasi baru dan penemuan pola tersebut perlu diaplikasikan dengan data mining . Sehingga sebenarnya data mining merupakan suatu bagian yang tidak dapat dilepaskan dari proses  KDD.  Perlu diketahui bahwa data mining merupakan salah satu bidang yang cukup banyak didukung oleh 
cabang ilmu lain di dalam teknologi informasi yaitu statistik, teknologi basis data, machine learning, sistem 
pakar, algoritma paralel, algoritma genetika, pengenalan 
pola, visualisasi data, dan lain-lain [11].  
Gambar 1 . Data  mining merupakan bidang multidisipliner   
Ada beberapa faktor yang menjadi alasan utama mengapa menggunakan data mining : 
1. Banyaknya data yang terkumpul sehingga memerlukan waktu yang sangat lama dan tenaga ahli yang cukup banyak untuk menganalisisnya.  
2. Komputer menjadi salah satu pilihan utama karena kemampuannya dalam kecepatan, ketepatan, tidak pernah lelah dan mudah dioperasikan.  
3. Tekanan dari kompetisi bisnis yang terus menguat sehingga menjadikan informasi menjadi sangat penting dan harus segera dimiliki.  
4. Mampu menemukan suatu pola yang tidak terpikirkan 
sama sekali.   
Menurut [13] [14] data mining merupakan salah satu aktifitas dibidang perangkat  lunak yang dapat memberikan ROI (Return of Investment) yang tinggi. Hal yang perlu diperhatikan adalah bahwa data mining berbeda dengan query tools. Query dan data mining merupakan dua hal yang saling melengkapi. Keberadaan data mining bukan untuk menggan tikan query tetapi menambahkan beberapa tambahan yang berarti. Jika menggunakan query sederhana maka informasi yang dapat diakses sekitar 80% dari data yang ada dalam basis data sedangkan 20% lagi akan menjadi informasi tersembunyi yang memerlukan teknik-teknik khusus dalam mengaksesnya.  Karena data mining adalah suatu rangkaian proses maka dibagi menjadi beberapa tahap antara lain:  
a. Pembersihan data: untuk membuang data yang tidak konsisten dan noise.  
b. Integrasi data: untuk menggabungkan data dari beberapa  sumber.  
c. Transformasi data: untuk mengubah data menjadi bentuk yang sesuai untuk  di mining.  
d. Aplikasi teknik data mining.  
e. Evaluasi pola yang ditemukan: untuk menemukan informasi yang menarik atau  pun bernilai . 
f. Presentasi pengetahuan dengan teknik  visualisasi.  
Tahap-tahap diatas dapat digambarkan sebagai berikut :  
Gambar 2 . Tahap-tahap dalam data mining [8]  
2.3. Klasifikasi  
Klasifikasi adalah proses untuk menemukan model atau fungsi yang menjelaskan atau membedakan konsep atau kelas data, dengan tujuan untuk dapat memperkirakan kelas dari suatu objek yang labelnya tidak diketahui. Model itu sendiri bisa berupa aturan â€œjika makaâ€, decision tree ataupun formula matematis . Desicion tree merupakan salah satu metode klasifikasi yang paling populer karena mudah untuk diinterpretasikan oleh manusia. Contoh dari decision tree dapat dilihat melalui 3:  
Gambar 3. Contoh dari Decision Tree Pembeli Komputer   
Setiap percabangan menyatakan kondisi yang  harus dipenuhi dan tiap ujung pohon menyatakan kelas data atau atribut data. Dari decision tree tersebut, diketahui bahwa salah satu kelompok yang potensial membeli komputer adalah orang yang berusia dibawah atau sama dengan 30 dan juga merupakan seorang pelajar. Algoritma Decision tree yang sering dipakai adalah ID3 dan C4.5, namun akhir -akhir ini sedang dikembangkan suatu algoritma yang dikenal dengan Rain Forest . Metode-metode clas sification yang lain adalah Bayesian, Neural Network, Genetic Algorithm, Fuzzy, Case -based Reasoning dan K-Nearest Neigboor [8] [15] [11].  
Genetic 
Algoritm  
Applied 
Statistic  
Visualisation  
Parallel 
Algoritm  
Data Mining  
Database  
Machine  
Artificial 
Intelegent  
2.4. Algoritma C4.5  
Salah satu algoritma yang dapat digunakan untuk membuat pohon keputusan ( decission tree ) adalah algoritma C4.5. Algoritma C4.5 merupakan algoritma yang sangat populer yang digunakan oleh banyak peneliti di dunia, Algoritma C4.5 merupakan pengembangan dari algoritma ID3 yang di ciptakan oleh J. Rose Quinlan. Secara umum algoritma C4.5 untuk membangun pohon keputusan adalah sebagai berikut:  
a. pilih atribut sebagai akar  
b. buat cabang untuk tiap-tiap nilai  
c. bagi kasus dalam cabang  
d. ulangi proses untuk setiap cabang sampai  
Algoritma C4.5 merupakan algoritma yang digunakan untuk membangun sebuah pohon keputusan (decision tree) dari data. Algoritma C4.5 merupakan pengembangan dari algoritma ID3 yang juga merupakan algoritma untuk membangun sebuah pohon keputusan. Algoritma C4.5 secara rekursif mengunjungi tiap simpul keputusan, memilih percabangan optimal, sampai tidak ada cabang lagi yang mungkin dihasilkan. Adapun tahapan-tahapan untuk melakukan perhitung algoritma C4.5 diantaranya, menyiapkan data training, menentukan akar dari pohon dengan menghitung entropy, kemudian menghitung nilai gain, setelah itu menentukan tupel yang ingin dipartisi [10] .  
ðºð‘Žð‘–ð‘›  (ð‘†.ð´)=ð¸ð‘›ð‘¡ð‘Ÿð‘œð‘ð‘¦  (ð‘†)âˆ’âˆ‘|ð‘†1
|ð‘†|ð‘›
ð‘–=1
âˆ— ð¸ð‘›ð‘¡ð‘Ÿð‘œð‘ð‘¦  (ð‘†ð‘–)  
Keterangan :  
S : Himpunan Kasus  
A : Atribut  
Si  : Jumlah Kasus pada Partisi ke -i  
N  : Jumlah Partisi  
Atribut A S| : Jumlah Kasus dalam S  
Adapun untuk mencari nilai Entropy, digunakan rumus 
sebagai berikut :   
ð¸ð‘›ð‘¡ð‘Ÿð‘œð‘ð‘¦  (ð‘†)=âˆ‘âˆ’ ð‘ð‘–âˆ—ð‘™ð‘œð‘”2 ð‘ð‘–
ð‘–=1 
Keterangan :  
S : Himpunan Kasus  
A : Fitur  
N : Jumlah Partisi S  
pi : Proporsi dari Si thdp S  
  
3. Metodologi  Penelitian   
Metode penelitian merupakan tata cara dalam tahapan penelitian pada dasarnya adalah tahapan-tahapan antara konsep -konsep yang ingin diamati atau diukur melalui penelitian yang akan dilakukan. Tahap Penelitian dapat dilihat pada Gambar 4.  
Gambar 4. Tahapan Penelitian   
3.1. Pemilihan Atribut  
Berdasarkan data -data yang telah diperoleh, maka selanjutnya menentukan variabel yang menjadi variabel keputusan dalam mengklasifikasikan  gangguan psikologis . Diketahui beberapa faktor yang menjadi penentu dalam klasifikasi gangguan psikologis . Berikut pengklasifikasian data berdasarkan variabel dalam penelitian adalah sebagai berikut:  
1. Usia dikategorikan berdasarkan range dinas kesehatan menurut Depkes RI (2009) dapat diklasifikasikan sebagai berikut:   
Tabel 1.  Kategori Usia Usia  Klasifikasi  
0-5 Tahun  Balita  
6-11 Tahun  Kanak -kanak  
12-16 Tahun  Remaja Awal  
17-25 Tahun  Remaja Akhir  
26-35 Tahun  Dewasa Awal  
36-45 Tahun  Dewasa Akhir  
46-55 Tahun  Lansia Awal  
56-65 Tahun  Lansia Akhir  
>65 Tahun  Manula  
Sumber : Depkes RI (2009)   
2. Hobi  
3. Perokok diklasifikasikan menjadi Ya dan Tidak   
4. Golongan darah diklasifikasikan menjadi: O, A, B dan AB.  
5. Pengelompokkan gejala gangguan psikologis  sebagai berikut:   
Tabel 2. Data Gejala Gangguan GAD  (Generalized anxiety disorder ) Sumber: Diagnostic And Statistical Manual Of Mental Disorders  
Tabel 3. Data Gejala Gangguan Konversi  Kode Gejala Serangan gejala yang terjadi  
GJ10 Menangis berlebihan atau mudah sedih  
GJ11 Nafsu makan kurang saat kondisi sedih atau sedang dalam masalah  
GJ12 Nafsu makan meningkat saat kondisi sedih atau sedang dalam masalah  
GJ13 Berfikir bunuh diri  
GJ14 Kehilangan keseimbangan  
GJ15 Gerakan bagian tubuh tidak terkontrol  
GJ16  Kehilangan sensasi peradaban  
GJ17  Susah berkomunikasi dalam menyusun kalimat saat berbicara  
GJ18  Kesulitan dalam mendengar  
Sumber: Diagnostic And Statistical Manual Of Mental 
Disorders   
6. Pengelompokkan Gangguan Psikologis       
Tabel 4. Hasil Diagnosa Gangguan Psikologis Kode Gangguan  Gangguan yang menyerang Pasien  
GG01  Konversi  
GG02  Depresi Mayor  
GG03  GAD  (Generalized anxiety disorder)  

4. Hasil dan Pembahasan  
Pengujian ini akan dihitung dan di klasifikasikan dengan menggunakan 201 data yang terdiri dari 40 data training dan 161 data Testing . Dengan bantuan rapid miner, data set yang digunakan akan dihitung dengan memasukan data yang telah disesuaikan. Langkah pertama adalah masukan data set yang  telah di siapkan, setelah itu cari splid data  yang berfungsi untuk membagi 2 data yaitu untuk data training  dan data testing, lalu cari set role, random tree, apply model, dan performance untuk menghasilkan tingkat akurasi dari metode  yang digunakan.  Kemudian sambungkan seperti Gambar 5  berikut ini:  
Gambar 5 . Proses Model Klasifikasi   
menghasilkan sebuah grafik hasil Prediksi sebagai berikut:   
Gambar 6. Grafik  Hasil Prediksi   
 
5. Kesimpulan  
Berdasarkan pembahasan dari penulisan laporan skripsi dapat diambil kesimpulan yaitu:   
1. Penerapan algoritma C4.5 untuk mengklasifikasi gangguan psikologis memiliki nilai akurasi sebesar  57.50%,  mean precission  sebesar 57.50%, classification error  sebesar 0%, dan recall sebesar 57.50% untuk data training  sedangkan data testing  memiliki tingkat akurasi sebesar 72.67 %, precission  25% 73% 2% 
Hasil Grafik Prediksi despresi mayor GAD Konversi Kode 
Gejala  Serangan gejala yang terjadi  
GJ01  Memiliki kecemasan dan kekhawatiran yang berlebihan  
GJ02  Merasa kekhawatiran yang sulit di kendalikan  
GJ03  Tidak sabaran dalam melakukan apapun  
GJ04  Merasa mudah lelah  
GJ05  Merasa sulit untuk berkonsentrasi  
GJ06  Mudah tersinggung  
GJ07  Mudah merasakan keteganggan otot  
GJ08  Tidur terlalu banyak dari biasanaya  
GJ09  Tidur terlalu sedikit dari biasanaya   
sebesar 72.67%, dan recall  sebesar 100%. Dan adapun hasil prediksinya despresi mayor adalah 73% masyarakat mengalami GAD 25% masyarakat dan masyarakat yang mengalami gangguan konve rsi 2%, hal ini berdasarkan nilai confidance . 
2. Nilai kalsifikasi akurasi yang didapat pada penerapan algoritma C4.5 menghasilkan nilai lebih dari 60% yaitu akurasi data 72.67%.  
 
Daftar Pustaka  
[1] E. B. Fahrizq i, I. Mahfud, R. Yuliandra, and A. 
Gumantan, â€œTINGKAT KEBUGARAN JASMANI MAHASISWA OLAHARAGA 
SELAMA NEW NORMAL PANDEMI COVID-19,â€ Tadulako J. Sport Sci. Phys. Educ. , vol. 8, no. 2, pp. 53 â€“62. 
[2] C. Fatimah and N. D. Puspaningtyas, â€œDampak Pandemi Covid-19 terhadap Pembelajaran Online Mata Pelajaran Matematika di MAN 1 Lampung Selatan,â€ J. Pendidik. Mat. Univ. LAMPUNG , vol. 8, no. 4, pp. 250 â€“260, 2020.  
[3] H. Rizki and R. M. Aguss, â€œAnalisis Tingkat Pencapaian Perkembangan Motorik Kasar Anak Usia 4-5 Tahun Pada Masa Pandemi Covid -19,â€ J. Phys. Educ. , vol. 1, no. 2, pp. 20 â€“24, 2020.  
[4] D. Pamungkas and I. Mahfud, â€œTingkat Motivasi Latihan Ukm Taekwondo Satria Teknokrat Selama Pandemi Covid 2019,â€ J. Phys. Educ. , vol. 1, no. 2, pp. 6 â€“9, 2020.  
[5] L. N. Rani, â€œKlasifikasi Nasabah Menggunakan Algoritma C4.5 Sebagai Dasar Pemberian Kredit,â€ INOVTEK Polbeng - Seri Inform. , vol. 1, no. 2, p. 126, 2016, doi: 10.35314/isi.v1i2.131.  
[6] A. A. Aldino and H. Su listiani, â€œDecision Tree 
C4. 5 Algorithm For Tuition Aid Grant Program Classification (Case Study: Department Of Information System, Universitas Teknokrat Indonesia),â€ Edutic -Scientific J. Informatics Educ. , vol. 7, no. 1, 2020.  
[7] A. F. O. Pasaribu, â€œANA LISIS POLA MENGGUNAKAN METODE C4. 5 UNTUK PEMINATAN JURUSAN SISWA BERDASARKAN KURIKULUM (studi kasus: SMAN 1 NATAR),â€ J. Teknol. dan Sist. Inf. , vol. 2, no. 1, pp. 80 â€“85, 2021.  
[8] Pramudiono, Penghantar Data Miningâ€¯: Penambang Pratama Pengetahuan di Gunung Data . Surabaya: Penambang Pratama, 2013.  
[9] Z. Nabila, A. R. Isnain, P. Permata, and Z. Abidin, 
â€œANALISIS DATA MINING UNTUK CLUSTERING KASUS COVID-19 DI PROVINSI LAMPUNG DENGAN ALGORITMA K-MEANS,â€ J. Teknol. dan Sist. Inf., vol. 2, no. 2, pp. 100 â€“108, 2 021. [10] H. Widayu, S. Darma, N. Silalahi, and Mesran, â€œData Mining Untuk Memprediksi Jenis Transaksi Nasabah Pada Koperasi Simpan Budidarma., Pinjam Dengan Algoritma C4.5.,â€ Media Inform. , vol. 1, no. 1, pp. 1 â€“10, 2017.  
[11] I. Ahmad, H. Sulistiani, and H. Saputra, â€œThe 
Application Of Fuzzy K -Nearest Neighbour Methods For A Student Graduation Rate,â€ Indones. J. Artif. Intell. Data Min. , vol. 1, no. 1, pp. 47 â€“52, 2018.  
[12] Sucahyo, Implementasi Data Warehose Untuk 
Menunjang Kegiatan Akademik.  Surajit: Chaudhurin, 2013.  
[13] A. R. Isnain, J. Supriyanto, and M. P. Kharisma, 
â€œImplementation of K -Nearest Neighbor (K-NN) Algorithm For Public Sentiment Analysis of Online Learning,â€ IJCCS (Indonesian J. Comput. Cybern. Syst. , vol. 15, no. 2, pp. 121 â€“130. 
[14] A. P. Giovani, A. Ardiansyah, T. Haryanti, L. 
Kurniawati, and W. Gata, â€œAnalisis Sentimen Aplikasi Ruang Guru Di Twitter Menggunakan Algoritma Klasifikasi,â€ J. Teknoinfo , vol. 14, no. 2, p. 115, 2020, doi: 10.33365/jti.v14i2.679.  
[15] H. Sulistiani, I. Darwan to, and I. Ahmad, 
â€œPenerapan Metode Case Based Reasoning dan K-Nearest Neighbor untuk Diagnosa Penyakit dan Hama pada Tanaman Karet,â€ JEPIN (Jurnal Edukasi dan Penelit. Inform. , vol. 6, no. 1, pp. 23 â€“28, 2020.",klasifikasi,C4.5,data gejala ,"akurasi, precission, recall"
Implementasi Data Mining dengan Algoritma Naive Bayes Untuk Klasifikasi Kelayakan Penerima Bantuan Sembako,"Implementasi Data Mining dengan Algoritma Naive Bayes Untuk Klasifikasi Kelayakan Penerima Bantuan Sembako

Amat Damuri1, Umbar Riyanto2, Hengki Rusdianto2,*, Mohammad Aminudin3 

Abstrak   
Kemiskinan adalah salah satu persoalan mendasar yang menjadi pusat perhatian pemerintah di suatu negara. Salah satu aspek penting untuk mendukung Strategi Penanggulangan Kemiskinan adalah tersedianya data kemiskinan yang akurat dan tepat sasaran. Naive Bayes merupakan salah satu metode yang dapat digunakan untuk  mengklasifikasikan data. Hasil klasifikasi yang dilakukan nantinya akan membantu pengelola bantuan untuk mengambil keputusan terkait klasifikasi penentuan penerima bantuan sembako.  Prediksi penerima bantuan sembako yang digunakan terdapat dua kelas, yaitu layak dan tidak layak. Data yang  digunakan untuk prediksi yaitu data sampel dari desa XYZ. Pada penelitian ini algoritma Naive Bayes  diimplementasikan dan dianalisa menggunakan aplikasi yang dikembangkan berbasis web. Dari hasil evaluasi menggunakan confusion matrix didapatkan akurasi ya ng dihasilkan untuk 135 data training dengan 40 data testing dan tujuh atribut yang digunakan menghasilkan akurasi sebesar 86%, recall 85%, dan presisi 88%.  

Kata Kunci : Naive Bayes, Confusion matrix, Data mining, Algoritma, Bantuan Sembako. 

Abstract  
Poverty is one of the fundamental problems that is the center of attention of the government in a country. One of the important aspects to support the Poverty Reduction Strategy is the availability of accurate and targeted poverty data. NaÃ¯ve Baye s is one method that can be used to classify data. The results of the classification carried out will later help aid managers to make decisions regarding  the classification of determining the recipients of basic food assistance. There are two classes of pre dictions for the recipients of the basic food assistance, namely eligible and not eligible. The data used for prediction is sample data from XYZ village. In this research, the nave Ba yes algorithm is implemented and analyzed using a web-based application. From the results of the evaluation using the confusion matrix, the resulting accuracy for 135 training data with 40 testing data and seven attributes used resulted in an accuracy of 86%, recall of 85%, and precision of 88%.  

Keywords : Naive Bayes 

1. PENDAHULUAN  
Kemiskinan adalah salah satu persoalan mendasar yang menjadi pusat perhatian pemerintah di suatu negara. Salah satu aspek 
penting untuk mendukung Strategi Penanggulangan Kemiskinan adalah ter sedianya data kemiskinan yang akurat dan tepat 
sasaran. Sembako (sembilah bahan pokok) merupakan sembilan kebutuhan pokok masyarakat Indonesia yang terdiri dari makanan atau minuman yang digunakan untuk memenuhi kehidupan sehari-hari. Atas dasar tersebut, biasanya pemerintah mengadakan program -program bantuan sembako yang ditujukan kepada masyarakat yang membutuhkan.  Bantuan Pangan Non Tunai (BPNT)/Program  Sembako  adalah  bantuan  sosial pangan dalam bentuk non tunai dari pemerintah yang diberikan 
kepada Keluarga Penerima Manfaat (KPM) setiap bulannya melalui mekanisme perbankan.  Namun, dalam prakteknya pemberian bantuan sembako tidak tepat sasaran, sehingga butuh pendataan yang lebih valid terkait keluarga yang layak atau tidak layak menerima bantu an sembako.  Untuk menetukan kelayakan penerima sembako dapat memanfaatkan teknik data 
mining. Data mining atau penambangan data merupakan metode yang bermanfaat untuk memperoleh informasi berharga dari sejumlah data yang dilakukan dengan menggunakan penget ahuan seperti statistik, matematika dan pengenalan pola. Penambangan data melibatkan data besar untuk aktrak dan identifikasi untuk ditemukan informasi yang berguna bagi 
perusahaan . Penambangan data dapat digunakan untuk mengklasifikasikan, memprediksi, memperkirakan untuk mendapatkan informasi yang bermanfaat. Data mining membantu  tahapan perencanaan dan memberikan informasi tepat untuk membuat prediksi berdasarkan tren masa lalu dan kondisi saat ini.  Data mining  memungkinkan perusahaan menggunakan alokasi dana lebih efisien karena otomatisasi pengambilan keputusan  dapat  mengurangi biaya. Prediksi merupakan sebuah fungsi yang dapat menemukan pola tertentu dari suatu data [1]. Pola-pola tersebut dapat diketahui dari berbagai variabel yan g ada pada data.  Ketika sudah menemukan pola, maka pola yang didapat tersebut bisa digunakan untuk memprediksi variabel lain yang belum diketahui nilai ataupun jenisnya [2]. Salah satu metode prediksi yang dapat digunakan untuk penambangan data adalah dengan algoritma Naive Bayes . Naive Bayes  merupakan salah satu metode 
yang dapat digunakan untuk  mengklasifikasikan data. Bayesian classification  merupakan algoritma pengklasifikasian statistik yang digunakan untuk memprediski probabilitas keanggotaan suatu  class  [3]. Beberapa penelitian terdahulu yang telah berhasil menerapkan algoritma Naive Bayes  dalam klasifikasi yaitu, penentuan pemberian kredit [3], penentuan lokasi pembangunan sumber air [4], evaluasi kinerja akademik mahasiswa [5], prediksi jumlah produksi barang [6], klasifikasi masyarakat miskin [7], dan penentuan kelayakan penerima bantuan program keluarga harapan [8]. Naive Bayes  adalah suatu kelas keputusan, dengan menggunakan perhitungan probabilitas matematika dengan sya rat bahwa nilai keputusan adalah benar, berdasarkan informasi obyek [5]. Hasil klasifikasi yang dilakukan nantinya akan membantu pengelola bantuan untuk mengambil keputusan terkait klasifikasi penentuan  penerima bantuan sembako.  Penelitian ini bertujuan untuk melakukan prediksi klasifikasi penerima bantuan sembako  dengan menggunakan algoritma Naive Bayes. Algoritma Naive Bayes  memiliki fungsi untuk menemukan pengetahuan atau pola-pola kesamaan karakteristik dalam suatu kelompok atau kelas tertentu. Prediksi penerima bantuan sembako  yang digunakan terdapat dua kelas, yaitu layak  dan tidak layak. Data yang digunakan untuk prediks i yaitu data sampel dari desa XYZ . Pada penelitian ini algoritma Naive Bayes  diimplementasikan dan dianalisa menggunakan aplikasi yang dikembangkan berbasis web .  

2. METO DOLOGI PENELITIAN  
2.1 Tahapan Penelitian  
Pada penelitian dibutuhkan perencanaan dan langkah-langkah yang terstuktur agar penelitian dapat berjalan dengan baik. 
Tahapan penelitian yang dilakukan dapat dilihat pada Gambar 1.   
Gambar 1.  Tahapan Penelitian   
a. Identifikasi Masalah  
Penelitian ini dimulai dengan mengumpulkan  data melalui wawancara atau mendengarkan kebutuhan pengguna, hal ini 
bermanfaat  untuk mengetahui  informasi dan permasalahan yang akan diselesaikan [9]. Permasalahan utama pada penelitian ini adalah bagaimana membangun sistem yang dapat mengklasifikasikan kepala keluarga yang layak menerima bantuan sembako.   
b. Analisa Kebutuhan  
Analisa kebutuahn berisi kebutuhan-kebutuhan fungsional yang dibutuhan oleh pengguna. Kebutuhan fungsional diperlukan 
untuk mengetahui proses apa saja yang dapat dilakukan oleh sistem  atau fitur apa saja yang terdapat pada sistem, serta siapa saja yang dapat mengg unakan sistem yang dibangun [10][11]. Berikut  adalah kebutuhan fungsional dari sistem yang akan dikembangkan:  Sistem akan digunakan oleh single user yaitu, admin atau user. Proses yang dapat dilakukan oleh admin atau user adalah:  
1. Admin dapat mengelola data training  
2. Admin dapat memasukkan data uji  
3. Admin dapat melihat hasil uji  
c. Perancangan Sistem  
Perancangan sistem berupa identifikasi dan deskripsi abstraksi sistem berdasarkan  hubungan-hubungannya  [12]. Pada tahap perancangan, peneliti menggunakan salah satu diagram Unified Modelling Language (UML) yaitu use case diagram. Use case diagram  menggambarkan  sebuah interaksi antara satu atau lebih aktor dengan sistem informasi yang akan dibuat [13]. 
d. Klasifikasi dengan Naive Bayes  
Naive Bayes  merupakan salah satu metode yang dapat digunakan untuk  mengklasifikasikan data. Bayesian classification merupakan pengklasifikasian statistik yang dapat digunakan untuk memprediski probabilitas keanggotaan suatu class  [4]. Naive Bayes  merupakan suatu kelas keputusan, dengan menggunakan perhitingan probabilitas matematika dengan syarat bahwa nilai keputusan adalah benar, berdasarkan informasi obyek [5]. Adapun alur dari metode Naive Bayes  adalah sebagai berikut:  
Identifikasi Masalah
Analisa Kebutuhan
Perancangan Sistem
Klasifikasi dengan 
Naive Bayes
Implementasi Sistem
Pengujian
1. Baca data training  
2. Hitung Jumlah dan probabilitas, apabila data numerik maka:  
a) Cari nilai mean dan standar deviasi dari masing masing parameter yang merupakan data numerik.  
b) Cari nilai probabilistik dengan cara menghitung jumlah data yang sesuai dari kategori yang sama dibagi dengan 
jumlah data pada kategori tersebut.  
3. Mendapatkan nilai dalam tabel mean, standart deviasi dan probabilitas.  
Skema NaÃ¯ve Bayes  dapat dilihat pada Gambar 2.   
Gambar 2. Skema NaÃ¯ve Bayes  
e. Implementasi Sistem  
Tahap  implementasi  yaitu  melakukan  pengkodean  berdasarkan  dari perancangan  dan analisa  yang  telah  dilakukan sebelumnya.  Pengkodean  merupakan  tahapan  merubah  rancangan  yang  telah  dibuat  kemudian  diimplementasikan  ke dalam  bentuk  bahasa  pemrograman  yang  dapat  dikenali  oleh komputer  [14]. Pada penelitian ini , pengkodean dilakukan dengan menggunakan bahasa pemrograman PHP dengan compailer Visual Studio Code  dan DBMS  MySQL.  
f. Pengujian  
Proses pengujian pada penelitian ini menggunakan confusion matrix , yang akan menghitung nilai  precision , recall , dan accuracy. Confusion matrix  terdiri dari true positive , false positive , true negative  dan false negative  untuk menghitung presisi, recall dan akurasi [15]. Precision  merupakan tingkat ketepatan antara informasi yang diminta oleh pengguna dengan jawaban yang diberikan oleh sistem. Recall  merupakan tingkat keberhasilan sistem dalam menemukan kembali sebuah informasi. Sedangkan Accuracy  merupakan tingkat kedekatan antara nilai prediksi dengan nilai aktual. Untuk menghitung precision, recall dan accuracy dapat me nggunakan  persamaan berikut:  FP TPTPPrecision+=-1
FN TPTPRecall+=-2
FN FP TN TPTN TPAccuracy++++=-3
TP adalah true positive yang didapatkan dari jumlah data positif yang diprediksi benar.  TN adalah true negative 
didapatkan dari jumlah data negatif yang diprediksi benar . FP adalah false positive didapatkan dari jumlah d ata negatif namun diprediksi sebagai data positif . Sedangkan FN adalah false negative yang diadapatkan dari jumlah data positif namun diprediksi sebagai data negatif . 

3. HASIL DAN PEMBAHASAN  
3.1 Analisis Data  
Pada tahapan ini dilakukan analisis data dengan :  
1. Menghilangkan noise (data yang tidak konsisten atau data tidak relevan).  
Menghilangkan data noise (data yang tidak relevan / berhubungan langsung dengan tujuan akhir proses data mining). Antara lain membuang redudansi data , memeriksa data yang inkonsisten, dan memperbaiki kesalahan pada data, seperti kesalahan cetak.  
2. Pengelompokkan data.  
Dalam Pemetaan atau pengelompokkan Klas ifikasi Kelayakan Penerima Bantuan Sembako  terdapat beberapa fitur yang menjadi variabel dalam perhitungan metode Klasifikasi Naive Bayes , yaitu :  
a) Nama  
Merupakan variabel identitas nama kepala keluarga . 
b) Status Program Keluarga Harapan (PKH)  
Merupakan variabel status keluarga PKH atau non PKH.  
c) Jumlah Tanggungan  
Merupakan variabel yang berisi jumlah tanggungan yang ditanggung kepala keluarga . 
d) Kepala Rumah Tangga  
Merupakan variabel status jenis kelamin kepala rumah tangga, Laki-laki atau perempuan.  
e) Kondisi Rumah  
Merupakan variabel kondisi rumah yang ditempati, batu permanen, batu anyam atau papan.  
f) Jumlah Penghasilan  
Merupakan variabel jumlah penghasilan kepala keluarga.  
g) Status Pemilik Rumah  
Merupakan variabel status kepemilikan rumah  yang di kelompokkan dalam dua kategori yaitu milik sendiri, atau sewa. 
Sampel data training dapat dilihat pada tabel 1.  
Tabel 1.  Sampel Data Training 
Id Training Nama  PKH  Jml tangg  Kepala Rumah Tangga Kondisi Rumah  Jumlah Penghasilan  Status kepemilikan Rumah  Status Kelayakan  
1 Beni Afri Angga  Non 1 Laki-laki Batu permanen  100000 Milik sendiri  Layak  
2 Febriza Ardiansyah  Non 4 Laki-laki Batu permanen  1600000  Milik sendiri  Layak  
3 Andhyca Ilham Akhbar  Non 3 Laki-laki Batu permanen  3000000  Milik sendiri  Layak  
..         
120 Saffrudin  Non 4 Laki-laki Batu permanen  3000000  Milik sendiri  Tidak layak  
..         
135 Nining Yulianingsih  1 1 Perempuan Batu permanen  100000  Milik sendiri  layak  
3.2 Desain  
Tahapan awal dalam  mengembangkan sistem klasifikasi kelayakan penerimaan bantuan sembako  adalah identifikasi masalah, agar dapat mendapatkan kebutuhan. Kebutuhan tersebut diubah  menjadi fungsional sistem. Dari analisa kebutuhan kemudian sistem dirancang. Pada penelitian ini  sistem dirancang menggunakan use case diagram. Gambar 3 merupakan  use case diagram dari sistem yang dikembangkan.   
Gambar 3. Use Case Diagram Sistem Klasifikasi Penerimaan Bantuan Sembako Pada Gambar 3 terlihat bahwa sistem akan digunakan oleh satu  orang pengguna atau user. User dapat mengelola data training, input data uji dan melihat hasil uji.  
3.3 Implementasi  
Pada tahapan implementasi, sistem dikembangkan berbasis web menggunakan Bahasa pemrograman PHP dengan DBMS MySQL. Sistem dibuat berdasarkan use case diagram. Gambar 4 merupakan tampilan halaman data training yang sudah diinputkan oleh user.    
Gambar 4. Halaman Data Training  
Berdasarkan data training, sistem dapat melakukan uji data melalui halaman  input data uji yang akan diinputkan oleh user. Tampilan input data uji dapat dilihat pada Gambar 5.   
Gambar 5. Halaman Input Data Uji  
Berdasarkan inputan data uji, selanjutnya sistem akan mengklasifikasin inputan data menggunakan perhitungan Naive 
Bayes, hasil dari pengklasifikasian penerimaan bantuan sembako dapat dilihat pada Gambar 6.  
Gambar 6. Halaman Hasil Uji  
Pada Gambar 6 terlihat bahwa data uji menerima kesimpulan layak untuk menerima bantuan berupa beras rastra. Hasil uji ini didapat dari inputan data uji.  
3.4 Pengujian  
Selanjutnya system perlu dievaluasi guna mengetahui tingkat akurasi dari model yang dibangun. Untuk menghitung akurasi 
data maka digunakan confusion matrix. Confusion matrix pada dasarnya informasi akurasi yang dih asilkan didapatkan dari 
perbandingan hasil klasifikasi yang dihasilkan oleh sistem dengan hasil yang seharusnya. Hasil evaluasi system dapat dilihat pada Tabel 2.  
Tabel 2.  Hasil Evaluasi  
Evaluasi  Persentase  
Accuracy  86% 
Recall  85% 
Precision  88% 
Berdasarkan informasi yang ditampilkan confusion matrix, untuk mendiskripsikan hasil evaluasi/proses klasifikasi yang menggunakan data training  sejumlah 135  record, dan data testing  sebanyak 40 record . Hasil akurasi yang diperoleh 
dari pengujian yaitu 86% yang artinya nilai akurasi dari klasifikasi cukup tinggi [12]. Akurasi merupakan hasil perhitungan semua nilai prediksi yang benar dibagi dengan keseluruhan data. Sedangkan hasil recall  (Sensitivity) dari pengujian juga menunjukkan nilai yaitu 85%. Recall atau Sensitivity  dihitung dari jumlah prediksi positif yang b enar dibagi dengan jumlah keseluruhan kelas yang positif. Hasil precision  (presisi) dari pengujian terklasifikasi dengan benar sangat tinggi [12]. Presisi dihitung dari jumlah keseluruhan nilai prediksi  positif yang benar dibagi dengan jumlah keseluruhan prediksi kelas yang benar. Nilai presisi sebesar  88% pada penelitian ini dipengaruhi atau tergantung dari data training  dan data testing  beserta 
class  atau label klasifikasinya, semakin banyak  data training  dan data testing  serta class yang bernilai benar maka akan mempengaruhi tingkat presisinya .  

4. KESIMPULAN  
Pada penelitian ini melakukan prediksi klasifikasi penentuan penerima bantuan sembako  menggunakan algoritma Naive Bayes. Algoritma Naive Bayes  merupakan salah satu metode yang dapat digunakan untuk  mengklasifikasikan data. Bayesian classification merupakan pengklasifikasian statistik yang dapat digunakan untuk memprediski probabilitas keanggotaan 
suatu class. Algoritma NaÃ¯ve Bayes  memiliki fungsi untuk menemukan pengetahuan atau pola -pola kesamaan karakteristik 
dalam suatu kelompok atau kelas tertentu. Prediksi tingkat penerimaan bantuan sembako  yang digunakan terdapat dua kelas, yaitu layak  dan tidak layak . Data yang di gunakan untuk prediksi yaitu data yang diambil dari sampel data warga di desa XYZ. Dari hasil evaluasi menggunakan confusion matrix didapatkan akurasi yang dihasilkan untuk 135 data training dengan 40 data testing dan tujuh  atribut yang digunakan menghasil kan akurasi sebesar 86%, recall 85%, dan presisi 88%. Akurasi dapat dipengaruhi oleh beberapa faktor, diantaranya: jumlah data training, data testing dan atribut yang digunakan. Untuk penelitian selanjutnya dapat menggunakan variasi data training, data tes ting dan atribut sehingga didapatkan model dengan akurasi yang terbaik.  

REFERENCES  
[1] M. Akbar and Y. Rahmanto, â€œDesain Data Warehouse Penjualan Menggunakan Nine Step Methodology Untuk Business 
Intelegency Pada PT Bangun Mitra Makmur,â€ Jurnal Informatika dan Rekayasa Perangkat Lunak , vol. 1, no. 2, pp. 137 â€“146, 2021, doi: 10.33365/jatika.v1i2.331.  
[2] A. Fauzi, N. M. Saraswati, and R. C. S. Hariyono, â€œPenerapan Algoritma K -Modes dan C4.5 Untuk Prediksi Pemilihan Jurusan di Universitas Peradaban  Pada Siswa SMA (Studi Kasus: SMA Islam Taâ€™allumul Huda Bumiayu),â€ IJIR, vol. 1, no. 2, pp. 57 â€“64, 2020.  
[3] M. H. Rifqo and A. Wijaya, â€œIMPLEMENTASI ALGORITMA NAIVE BAYES DALAM PENENTUAN PEMBERIAN KREDIT,â€ Jurnal Pseudocode , vol. 4, no. 2, 2017, [Online].  Available: www.ejournal.unib.ac.id/index.php/pseudocode  
[4] T. Imandasari, E. Irawan, A. Perdana Windarto, A. Wanto, and S. A. Tunas Bangsa Pematangsiantar Jln Jendral Sudirman Blok No, â€œAlgoritma Naive Bayes Dalam Klasifikasi Lokasi   Pembangunan Sumber A ir,â€ in Prosiding Seminar Nasional Riset Information Science (SENARIS) , 2019, pp. 750 â€“761. 
[5] M. Syukri Mustafa, M. Rizky Ramadhan, A. P. Thenata, K. Kunci -Algoritma Naive Bayes Classifier, and K. Akademik Mahasiswa, â€œImplementasi Data Mining untuk Evalu asi Kinerja Akademik Mahasiswa Menggunakan Algoritma Naive Bayes Classifier,â€ Citec Journal , vol. 4, no. 2, 2017.  
[6] E. Manalu, F. A. Sianturi, and M. R. Manalu, â€œPENERAPAN ALGORITMA NAIVE BAYES UNTUK MEMPREDIKSI   JUMLAH PRODUKSI BARANG BERDASARKAN DATA   PERSEDIAAN DAN JUMLAH PEMESANAN PADA CV. PAPADAN MAMA PASTRIES,â€ Jurnal Mantik Penusa , vol. 1, no. 2, 2017.  
[7] H. Annur, â€œKLASIFIKASI MASYARAKAT MISKIN MENGGUNAKAN METODE NAÃVE BAYES ,â€ ILKOM Jurnal Ilmiah , vol. 10, no. 2, p. 160, 2018.  JURIKOM (Jurnal Riset Komputer) , Vol. 8 No. 6, Desember  2021 e-ISSN 2715 -7393 (Media Online ), p-E. Fitriani, â€œPERBANDINGAN ALGORITMA C4.5 DAN NAÃVE BAYES  UNTUK MENENTUKAN   KELAYAKAN PENERIMA BANTUAN PROGRAM KELUARGA HARAPAN,â€ Jurnal Sistem Informasi , vol. 9, no. 1, 2020.  
[9] R. I. Borman, I. Yasin, M. A. P. Darma, I. Ahmad, Y. Fernando, and A. Ambarw ari, â€œPengembangan Dan Pendampingan Sistem Informasi Pengolahan Pendapatan Jasa Pada PT. DMS Konsultan Bandar Lampung,â€ Journal of Social Science and Technology for Community Service (JSSTCS) , vol. 1, no. 2, pp. 24 â€“31, 2020.  
[10] R. I. Borman, A. T. Priand ika, and A. R. Edison, â€œImplementasi Metode Pengembangan Sistem Extreme Programming (XP) pada Aplikasi Investasi Peternakan,â€ JUSTIN (Jurnal Sistem dan Teknologi Informasi) , vol. 8, no. 3, pp. 272 â€“277, 2020, doi: 10.26418/justin.v8i3.40273.  
[11] M. Melinda , R. I. Borman, and E. R. Susanto, â€œRancang Bangun Sistem Informasi Publik Berbasis Web (Studi Kasusâ€¯: Desa Durian Kecamatan Padang Cermin Kabupaten Pesawaran),â€ Jurnal Tekno Kompak , vol. 11, no. 1, p. 1, 2018, doi: 10.33365/jtk.v11i1.63.  
[12] A. D. Saputr a and R. I. Borman, â€œSistem Informasi Pelayanan Jasa Foto Berbasis Android (Studi Kasus: Ace Photography Way Kanan),â€ Jurnal Teknologi dan Sistem Informasi (JTSI) , vol. 1, no. 2, pp. 87 â€“94, 2020.  
[13] R. D. Gunawan, T. Oktavia, and R. I. Borman, â€œPerancang an Sistem Informasi Beasiswa Program Indonesia Pintar (PIP) Berbasis Online (Tudi Kasusâ€¯: SMA N 1 Kota Bumi),â€ Jurnal Mikrotik , vol. 8, no. 1, pp. 43 â€“54, 2018.  
[14] I. Ahmad, R. I. Borman, J. Fakhrurozi, and G. G. Caksana, â€œSoftware Development Dengan Extr eme Programming (XP) Pada Aplikasi Deteksi Kemiripan Judul Skripsi Berbasis Android,â€ Jurnal Invotek Polbeng - Seri Informatika , vol. 5, no. 2, pp. 297 â€“307, 2020.  
[15] M. F. Arifin and D. Fitrianah, â€œPenerapan Algoritma Klasifikasi C4.5 Dalam Rekomendasi P enerimaan Mitra Penjualan Studi Kasus: PT Atria Artha Persada,â€ InComTech , vol. 8, no. 2, pp. 87 â€“102, 2018, doi: 10.22441/incomtech.v8i1.2198.",klasifikasi,Naive Bayes,data kemiskinan,"akurasi, recall, presisi"
Klasifikasi Citra Buah Menggunakan Convolutional Neural Network,"Klasifikasi Citra Buah Menggunakan Convolutional Neural Network 

Febian Fitra Maulana1, Naim Rochmawati2

Abstrak
Deep Learning merupakan sebuah pengembangan dari teknologi Machine Learning yang menggunakan algoritma yang dibuat berdasarkan pada hukum matematik yang bekerja layaknya otak manusia. Salah satu pemanfaatan dari deep learning adalah dalam bidang image processing atau pengolahan citra digital. Image Processing dimanfaatkan untuk membantu manusia dalam mengenali dan/atau mengklasifikasi objek dengan cepat, tepat, dan dapat melakukan proses dengan banyak data secara bersamaan. Salah Satu algoritma dari Deep learning yang digunakan dalam image processing adalah Convolutional Neural Network (CNN). Algoritma CNN terdiri dari 3 layer utama yaitu Convolutional Layer, Pooling Layer, dan Fully Connected Layer. Pada penelitian ini menggunakan arsitektur CNN dengan perpaduan 3 Convolutional Neural Network dan 2 Fully Connected Layer. Pada tahap pembuatan system klasifikasi yang menggunakan deep learning terdapat beberapa tahapan proses utama yaitu pengumpulan data, perancangan system, training, dan testing. Dataset yang diolah adalah dataset citra buah-buahan yang berasal dari dataset Fruit-360. Kelas data yang digunakan yaitu sejumlah 15 kelas dari 111 kelas pada dataset fruit-360.  Hasil dari proses learning didapatkan model CNN dengan akurasi 100% dan loss sebesar 0,012. Pada proses pengujian model CNN yang mengguakan 45 sampel citra buah didapatkan akurasi sebesar 91,42%. Sehingga dapat disimpulkan bahwa metode CNN yang dirancang pada penelitian ini dapat mengklasifikasi citra dengan baik.  

Kata Kunci Deep Learning, Image Processing, Convolutional Neural Network, Fruit-360. 

I. PENDAHULUAN 
Artificial Intelligence (AI) merupakan suatu bidang keilmuan yang membuat komputer menirukan kebiasaan manusia. Dapat diartikan pula sebagai bagian dari ilmu komputer yang yang berfokus pada mesin dengan kemampuan kecerdasan yang dapat berinteraksi dan/atau bekerja seperti manusia. Manusia semakin berkembang berdasarkan pelajaran yang didapat dari apa yang dilaluinya. Begitu juga AI, AI juga dapat belajar seperti manusia dan semakin banyak yang dipelajari maka semakin baik pula kemampuan dari AI tersebut. Berbeda dengan manusia, AI dapat belajar dan menemukan pola dan mencatatnya dengan jauh lebih efisien dan cepat.  Proses dari pembelajaran pada AI disebut juga dengan learning. Pada cabang AI, terdapat sebuah proses pembelajaran yang spesifik atau rinci yang dikenal dengan istilah Deep Learning. Deep Learning merupakan proses pembelajaran yang menggunakan algoritma yang mengacu pada hukum matematik yang bekerja seperti otak pada manusia. Deep Learning dimanfaatkan untuk berbagai macam pekerjaan seperti memprediksi peluang atau kejadian, mengenali objek,  hingga mendiagnosa penyakit. Salah satu pemanfaatan dari Deep Learning adalah bidang image processing atau pengolahan citra digital. Dengan adanya sistem image processing dimaksudkan untuk membantu manusia dalam mengenali atau mengklasifikasi objek dengan efisien yaitu cepat, tepat, dan dapat melakukan proses dengan banyak data sekaligus.  Pada bidang image processing terdapat beberapa algoritma yang dapat digunakan. Di antaranya adalah NaÃ¯ve Bayes, Support Vector Macine, dan Neural Network. Salah satu algoritma yang sering digunakan adalah Neural Network. Neural Network dikembangkan berdasarkan cara kerja jaringan saraf pada otak manusia. Sejalan dengan perkembangan teknologi, maka, dikembangkan pula algoritma pengolahan citra digital. Salah satu pengembangan dari deep learning adalah Convolutional Neural Network. Pada tahun 1989, Yan LeCun, dkk mengembangkan model Neural Network dengan melakukan klasifikasi citra kode zip menggunakan kasus khusus dari Feed Forward Neural Network yang kemudian diberi nama Convolutional Neural Network (CNN). Metode Convolutional Neural Network memiliki hasil yang paling signifikan dalam pengenalan citra digital. Hal tersebut dikarenakan CNN diimplementasikan berdasarkan sistem pengenalan citra pada visual cortex manusia.  Karena termasuk kedalam Deep Learning, CNN memerlukan pelatihan model yang cukup lama dan bergantung pada perangkat yang digunakan. CNN memiliki beberapa arsitektur umum yang sering digunakan seperti LeNet 5, AlexNet, VGGNet, GooLeNet, ResNet. Masing masing arsitektur mempunyai kelebihan dan kekurangan masing masing. Penggunaan arsitektur yang digunakan pada CNN sangat mempengaruhi hasil dari klasifikasi.  Oleh Karena itu, penelitian ini bermaksud mengembangkan arsitektur CNN yang menggunakan objek citra buah buahan sebagai data uji. Arsitektur CNN yang dikembangkan dalam penelitian ini diharapkan mampu mengklasifikasi citra buah dan menghasilkan akurasi yang terbaik. Dengan proses pengolahan citra digital dengan CNN, diharapkan dapat membantu para peneliti di bidang perkebunan dan pertanian, botanist, dokter, maupun sebagai media pembelajaran.   

II. METODOLOGI PENELITIAN 
A. Dataset 
Dataset yang digunakan pada penelitian ini merupakan dataset Fruit-360. Dataset Fruit-360 berisi citra buah-buahan dan sayur mayur. Dataset Fruit-360 diperoleh dari situs Kaggle. Dataset Fruit-360 yang digunakan dalam penelitian ini adalah Fruit-360 dengan versi 2019.06.29.0. Seluruh citra pada dataset Fruit-360 memiliki ukuran 100x100 piksel dengan total jumlah citra yaitu 75.937. Dataset Fruit-360 terdiri dari 111 kelas buah dan sayur dengan total data training sebesar 56.781 citra dan total data testing sebesar 56.781 citra.  
B. Convolutional Neural Network 
Algoritma Convolutional Neural Network (CNN) pada penelitian ini dimaksudkan untuk mengklasifikasi citra buah-buahan. Berbeda dengan algoritma klasifikasi biasa, jika pada algoritma klasifikasi biasanya melakukan proses ekstraksi fitur dan klasifikasi secara terpisah maka model algoritma dari cabang bidang deep learning ini akan mengekstraksi fitur lalu mengklasifikasi citra dalam satu proses. Dengan kata lain, ekstraksi fitur pada algoritma CNN juga ikut me-learning. Penelitian ini bermaksud untuk merancang model CNN yang dapat mengklasifikasi citra buah dengan akurasi yang baik. Terdapat beberapa tahapan dalam proses pembuatan sistem klasifikasi CNN seperti yang ditunjukkan pada gambar 1.   
Gbr. 1 Alur Pembuatan Sistem Klasifikasi CNN 
Proses pembuatan sistem klasifikasi CNN dimulai dari perancangan arsitektur CNN. Perancangan model CNN dilakukan meggunakan platform google colaboratory. Desain dari arsitektur CNN yang dibuat pada penelitian ini ditunjukkan pada gambar 2.     
Gbr. 2 Arsitektur CNN 
Arsitektur CNN dalam penelitian ini memiliki 3 lapisan konvolusi (convolutional layer) yang menggunakan fungsi aktivasi ReLu dan dipadukan dengan Max Pooling layer. Pada tahap klasifikasi (Fully Connected Layer) digunakan algoritma ANN (Artificial Neural Network) yang memiliki 2 hidden layer. Hidden layer 1 memiliki 700 kernel dan hidden ayer 2 memiliki 500 hidden layer. Fungsi aktivasi yang digunakan pada fully connected layer adalah Sigmoid.  Setelah CNN selesai dirancang, maka tahap selanjutnya adalah proses learning. Proses learning dilakukan agar CNN dapat mengenali objek citra buah berdasarkan indeks dari tiap kelas yang diinputkan. Proses learning dilakukan hingga ditemukan model CNN yang memenuhi target. Model yang memenuhi target tersebut akan disimpan dan akan digunakan pada proses testing. Proses testing dilakukan untuk menguji performa dari model CNN yang telah dirancang untuk mengklasifikasi citra buah. Setelah dilakukan testing model CNN, Tahap selanjutnya adalah melakukan penghitungan akurasi untuk mengukur ketepatan CNN dalam mengklasifikasi citra buah-buahan. 
C. Preprocessing 
Proses preprocessing dimaksudkan untuk menyiapkan data mentah agar siap untuk diolah oleh sistem. Proses preprocessing pada penelitian ini yaitu memilih 15 dari 111 kelas citra buah. Setelah dipilih, dataset citra buah kemudian diunggah ke dalam google drive yang berfungsi sebagai media penyimpanan yang digunakan oleh google colaboratory.  
D. Learning 
Proses learning (pembelajaran) atau sering disebut juga dengan training (latih) dimaksudkan untuk melatih model CNN yang telah dirancang agar dapat memahami dan membedakan citra buah-buahan yang telah diberikan indeks sesuai dengan kelasnya. Jumlah data citra yang digunakan untuk proses learning adalah 3.375 citra yang terdiri dari 225 citra dari 15 kelas buah. Untuk data validasi menggunakan citra dari kelas testing yang berjumlah 225 citra dari 15 kelas citra buah-buahan.  Proses learning dilakukan menggunakan 500 epoch. Dengan epoch sebanyak 500, akan diambil model CNN yang menghasilkan nilai indeks ketepatan (akurasi) pengklasifikasian citra buah yang tertinggi. Variabel yang digunakan sebagai target pada proses learning ini adalah akurasi > 0.999 dan loss < 0.05. Dari proses learning ditunjukkan pada gambar 3.  
Gbr. 3 Alur Proses Learning 
E. Testing 
Proses testing (pengujian) adalah proses terakhir dari keseluruhan sistem penelitian. Proses testing dilakukan untuk menguji ketepatan klasifikasi dengan menilai indeks yang dihasilkan oleh model CNN yang telah dilatih. Alur proses testing ditunjukkan pada gambar 4. 
Gbr. 4 Alur Proses Testing 
Alur proses testing dimulai dengan melakukan resize (mengubah ukuran) citra input menjadi 100x100 piksel. Setelah melalui proses resize, citra input kemudian diklasifikasi oleh CNN. Output dari proses klasifikasi CNN merupakan klasifikasi kelas buah dan probabilitas citra uji. Proses testing pada penelitian ini menggunakan data citra uji sebanyak 345 citra uji dengan rincian 23 citra dari setiap 15 kelas citra buah. 
F. Proses Penghitungan Akurasi Proses penghitungan akurasi merupakan proses akhir pada penelitian ini. Akurasi dalam penelitian ini merupakan variabel yang merepresentasikan kinerja yang digunakan untuk menilai tolok ukur keberhasilan model CNN untuk mengklasifikasi citra buah-buahan. Persamaan yang digunakan untuk menghitung akurasi ditunjukkan pada persamaan (1).                        (1)  

III. HASIL DAN PEMBAHASAN 
Paragraf harus teratur. Semua paragraf harus rata, yaitu sama-sama rata kiri dan dan rata kanan. 
A. Hasil Proses Learning 
Proses learning model CNN dilakukan untuk mencari model CNN yang terbaik dan/atau sesuai dengan target yang diberikan. 
1) Akurasi: Akurasi pada tahap ini adalah probabilitas dari kelas buah yang dihasilkan dari softmax dimana softmax memiliki probabilitas output dari 0 hingga 1 dan jumlah keseluruhan probabilitas output adalah 1. Cuplikan dari Akurasi yang didapatkan oleh model CNN dalam proses learning yang telah dilakukan ditunjukkan pada gambar 5.  
Gbr. 5 Grafik Akurasi Proses Learning 
2) Loss: Loss adalah fungsi yang menggambarkan kerugian yang berkaitan dengan probabilitas yang dihasilkan oleh model CNN. Loss function yang digunakan dalam penelitian ini adalah categorical cross-entropy. Salah satu syarat categorical cross-entropy dapat digunakan adalah pada proses klasifikasi menggunakan fungsi aktivasi softmax. Categorical cross-entropy digunakan saat hanya terdapat satu hasil yang benar. Categorical cross-entropy akan membandingkan distribusi dari probabilitas prediksi dengan distribusi dari kelas yang benar (target), dimana probabilitas dari kelas yang benar diset dengan 1 dan untuk kelas yang lain 0.  
Gbr. 6 Grafik Loss Proses Learning 
3) Model CNN: Model CNN yang memenuhi target selama proses learning ditunjukkan pada gambar 7.   
Gbr. 7 Model CNN Hasil Learning 
Proses learning menemukan 4 model yang memenuhi target yang diberikan. Model yang akan digunakan untuk proses learning adalah model yang memiliki akurasi tertinggi yaitu model CNN 100.jlb yang mempunyai akurasi 100% dan loss sebesar 0.012.  
B. Hasil Proses Testing 
Proses testing pada penelitian ini menggunakan 345 citra testing yang terdiri dari 23 citra dari 15 kelas citra buah-buahan. Proses testing dilakukan untuk menguji performa dari model CNN yang telah diperoleh dari proses learning. Variabel yang akan dinilai pada proses testing adalah â€˜salahâ€™ dan â€˜benarâ€™ dari klasifikasi citra yang dihasilkan dari CNN. Nilai â€˜benarâ€™ dan â€˜salahâ€™ akan digunakan untuk menghitung akurasi dari model CNN. Hasil testing ditunjukkan pada tabel I.   
TABEL I HASIL TESTING No. Kelas Buah Jumlah Data Uji Salah Benar 
1. Apple Red 1 23 5 18 
2. Avocado 23 0 23 
3. Banana 23 2 21 
4. Dates 23 0 23 
5. Grape Blue 23 0 23 
6. Grape White 23 0 23 
7. Kiwi 23 0 23 
8. Lemon 23 0 23 
9. Lychee 23 0 23 
10. Mango 23 0 23 
11. Orange 23 0 23 
12. Papaya 23 0 23 
13. Pear 23 0 23 
14. Strawberry 23 0 23 
15. Tomato 1 23 0 23  
Total 345 7 338  
Pengujian model CNN juga dilakukan menggunakan citra buah yang tidak termasuk dalam 15 kelas buah yang di-learning. Pengujian dilakukan menggunakan citra dari kelas buah Apple Golden 1. Hasil dari klasifikasi citra Apple Golden 1 menunjukkan bahwa citra tersebut terklasifikasi ke dalam kelas Pear. Klasifikasi tersebut dikarenakan bentuk, warna, dan tekstur dari Apple Golden 1 mirip dengan bentuk, warna, dan tekstur dari buah Pear. Selain itu, pengujian lainnya dilakukan menggunakan citra buah yang tidak termasuk dalam dataset Fruit-360. Citra yang akan diuji adalah citra buah mangga yang diambil menggunakan kamera smartphone. Hasil klasifikasi dari citra mangga yang diambil menggunakan kamera smartphone menunjukkan bahwa citra tersebut terklasifikasi ke dalam kelas Mango dengan probabilitas sebesar 0.7319665. 
C. Penghitungan Akurasi Setelah melakukan testing, maka tahap selanjutnya adalah menghitung akurasi. Penghitungan akurasi dilakukan untuk menilai presentase keberhasilan model CNN dalam mengklasifikasi citra. Akurasi juga dapat menjadi tolok ukur dalam perbandingan maupun pengembangan model CNN yang dibuat pada masa yang akan datang. Proses penghitungan akurasi menggunakan persamaan (1).   

IV. KESIMPULAN 
Kesimpulan yang dapat diambil dari penelitian yang telah  dilakukan yaitu model CNN yang menggunakan perpaduan 3 covolutional layer dan 2 hidden layer mampu mengklasifikasi citra buah-buahan dengan akurasi yang baik. Akurasi yang didapatkan dari proses testing yang menggunakan 345 citra uji menunjukkan angka 97,97%. Model CNN yang dibuat pada penelitian ini juga dapat mengklasifikasi citra buah yang 
diambil menggunakan kamera smartphone. Model CNN akan mengklasifikasikan citra buah yang tidak dikenalinya ke dalam kelas buah yang dianggap paling mirip diantara kelas buah yang telah di-learning. UCAPAN TERIMA KASIH Ucapan terimakasih diucapkan kepada Allah SWT tuhan semesta alam yang senantiasa memberikan pertolongan untuk mengerjakan penelitian ini. Ucapan terimakasih juga dipersembahkan kepada seluruh pihak yang mendukung dan membantu pengerjaan penelitian ini sehingga dapat berjalan dan rampung dengan lancar. 

REFERENSI     
[1] Bai, C. et al., 2018. Optimization of Deep Convolutional Neural Network for Large Scale Image Retrieval. Neurocomputing, Volume 303, pp. 60-67. 
[2] Guo, T., Dong, J., Li, H. & Gao, Y., 2017. Simple Convolutional Neural Network on Image Classification. Beijing, IEEE. 
[3] Khan, S., Rahmani, H., Shah, S. A. A. & Bennamoun, M., 2018. A Guide to Convolutional Neural Networks for Computer Vision. s.l.:Morgan & Claypool Publishers . 
[4] Mohamed, O., Khalid, E. A., Mohamed, O. & Brahim, A., 2019. Content-Based Image Retrieval Using Convolutional Neural Networks. pp. 463-476. 
[5] Naik, S., 2017. Machine Vision based Fruit Classification and Grading. International Journal of Computer Application, Volume 170. 
[6] Naik, S. & Patel, B., 2017. Machine Vision based Fruit Classification. International Jurnal of Computer Application, 170(9). 
[7] Tyagi, V., 2018. Content-Based Image Retrieval: Ideas, Influences, and Current Trends. London: Springer.",klasifikasi,"Convolutional Neural Network, CNN",Fruit-360,"akurasi, loss"
IMPLEMENTASI FUZZY RULE BASED SYSTEM UNTUK KLASIFIKASI BUAH MANGGA,"IMPLEMENTASI FUZZY RULE BASED SYSTEM UNTUK KLASIFIKASI BUAH MANGGA  

Subhan Hartanto  

Abstrak  
Mangga merupakan tamanan tahunan yang sudah tersebar di 
dunia, penelitian ini bertujuan untuk melakukan klasifikasi buah Mangga yang dapat memudahkan masyarakat dalam melakukan 
penamaan buah Mangga. Penelitian dilakukan dengan menggunakan metode Fuzzy Rule Based System,  penentuan penamaan buah Mangga mengggunakan software  yang telah ada yaitu Matlab, klasifikasi buah Mangga dilakukan berdasarkan bentuk dan warna serta ukuran dan menghasilkan penamaan buah Mangga. Hasil dari peneli tian ini adalah menjadikan masyarakat mandiri dalam melakukan pengecekan penamaan buah, penggunaan Fuzzy Rule Based System pada klasifikasi buah Mangga sangat membantu dalam melakukan penamaan buah. Klasifikasi buah Mangga dapat dilakukan dengan menggunakan ciri-ciri yang ada pada buah.   
 
Kata Kunci: Mangga, Fuzzy Rule Based System, Matlab.   
 
1. PENDAHULUAN  
Mangga merupakan tanaman buah tahunan berupa pohon yang berasal dari negara India. Kini, tanaman ini tersebar di berbagai penjuru dunia termasuk Indonesia. Tanaman Mangga dapat tumbuh dengan baik di dataran rendah dan berhawa panas. Banyak hasil observasi yang menyebutkan bahwa terdapat berbagai jenis Mangga yang tersebar di Indonesia yang memiliki ciri khas dan harga ekonomisnya masing-masing.  
Masyarakat yang memanfaatkan buah Mangga umumnya lebih 
berpatokan pada ciri-ciri agronomi buah yang membutuhkan klasifikasi lebih jelas sehingga penamaan dapat menjadi lebih pasti. Dengan adanya perkembangan ilmu pengetahuan dan teknologi yang telah maju saat ini, dapat digunakan untuk membantu masyarakat dalam mengetahui penamaan buah Mangga. Salah satu pemanfaatan teknologi tersebut adalah Artificial Intelligent  (kecerdasan buatan).     
 
2. KAJIAN LITERATUR DAN PEGEMBANGAN HIPOTESIS   
Pengertian Fuzzy Logic  
Logika  Fuzzy  adalah suatu cara untuk memetakan ruang-ruang input  ke dalam suatu ruangan output  yang sesuai. Ada banyak cara untuk memetakan ruang input  ke output  ini, seperti dengan sistem linear, jaringan syaraf, dan persamaan diferensial. Meskipun banyak cara selain Fuzzy, namun Fuzzy dianggap memberikan solusi terbaik karena dengan menggunakan Fuzzy akan lebih cepat dan lebih murah (Kusumadewi S., 2010).   
Himpunan Fuzzy  
Pada himpunan tegas ( Crisp ), nilai keanggotaan suatu item  x dalam suatu himpunan A, yang sering di tulis dengan ÂµA(x), memiliki dua kemungkinan, yaitu (Kusumadewi S. et al. , 2004):  
1. Satu (1), yang berarti bahwa suatu item menjadi anggota dalam suatu himpunan, atau  
2. Nol (0), yang berarti bahwa suatu item tidak menjadi anggota dalam suatu himpunan.  
Ada beberapa hal yang perlu diketahui dalam memahami sistem 
Fuzzy , yaitu (Muzayyanah, I, Mahmudy, WF, dan Cholissodin I, 2014):  
1. Variabel Fuzzy  
Variabel Fuzzy  merupakan variabel yang hendak dibahas dalam 
suatu sistem Fuzzy.  
2. Himpunan Fuzzy  
Himpunan Fuzzy  merupakan s uatu grup yang mewakili suatu 
kondisi atau keadaan tertentu dalam suatu variabel Fuzzy. 
3. Semesta Pembicaraan   
Semesta pembicaraan adalah keseluruhan nilai yang diperbolehkan untuk dioperasikan dalam suatu variabel Fuzzy . 
Semesta pembicaraan merupakan himpu nan bilangan real yang 
senantiasa naik (bertambah) secara monoton dari kiri ke kanan. Nilai semesta pembicaraan dapat berupa bilangan positif maupun negatif. Adakalanya nilai semesta pembicaraan ini tidak dibatasi batas atasnya.Implementasi Fuzzy Untuk Klarifikasi Buah Mangga                                                               
4. Domain   
Domain himpunan Fuzzy adalah keseluruhan nilai yang diijinkan dalam semesta pembicaraan dan boleh dioperasikan dalam suatu himpunan Fuzzy . Seperti halnya semesta pembicaraan, domain merupakan himpunan bilangan real yang senantiasa naik (bertambah) secara monoton dari kiri ke kanan. Nilai domain dapat berupa bilangan positif maupun negatif.   
Metode Tsukamoto  
Pada Metode Tsukamoto setiap konsekuen pada aturan yang berbentuk IF-THEN harus direpresentasikan dengan himpunan Fuzzy  dengan fungsi keanggotaan yang monoton. yaitu (Sho lihin, M, Fuad, N, dan Khamiliyah, N. 2013):  
[R1]If (x is A1) and (y is B2) Then (z is C1)  
[R2]If (x is A2) and (y is B1) Then (z is C2)   
Metode Mamdani  
Metode Mamdani sering dikenal sebagai Metode Max-Min. Metode ini diperkenalkan oleh Ebrahim Mamdani pada tahun 1975. Untuk mendapatkan output , diperlukan 4 tahapan (Nasution, IA. 2014):  
1.  Pembentukan himpunan Fuzzy   
2. Aplikasi fungsi implikasi  
3.  Komposisi aturan  
4.  Defuzzyfikasi   
Metode Sugeno  
Penalaran dengan Metode Sugeno hampir sama dengan penalar an 
Mamdani, hanya saja output  (konsekuen) sistem tidak berupa himpunan Fuzzy, melainkan berupa konstanta atau persamaan linear. Ada 2 model fuzzy metode Sugeno yaitu sebagai berikut: (Arsyad M. 2004).  
1. Model Fuzzy  Sugeno Orde -Nol 
Secara umum bentuk model Fuzzy Sugeno Orde -Nol adalah:  
IF(x1 is A 1)o(x 2 is A 2)o(x 3 is A 3)â€¦â€¦.o(x N is A N) THEN z=k                     
dengan A1 adalah himpunan Fuzzy  ke-i sebagai anteseden, dan k adalah suatu konstanta (tegas) sebagai konsekuen.  
2. Model Fuzzy  Sugeno Orde -Satu  
Secara umum bentuk model Fuzzy  Sugeno Orde-Satu adalah:  
IF(x1 is A 1)oâ€¦â€¦.o(x N is A N) THEN z= p1*x1+â€¦+p N*xN+q        
(2.20.)   
dengan Ai adalah himpunan Fuzzy  ke-i sebagai anteseden, dan pi adalah suatu konstanta (tegas) ke -i dan q juga merupakan 
konstanta dalam konsekuen.   
Rule-Based System  
Rule Based System  merupakan sistem yang digunakan sebagai cara untuk menyimpan dan memanipulasi pengetahuan untuk diwujudkan dalam suatu informasi yang dapat membantu dalam menyelesaikan berbagai permasalahan atau dapat juga didefin isikan sebagai suatu Sistem Pakar yang menggunakan aturan -aturan untuk menyajikan pengetahuannya. Dengan kata lain bahwa sistem berbasis aturan adalah suatu perangkat lunak yang menyajikan keahlian pakar dalam bentuk aturan-aturan pada domain tertentu untuk menyelesaikan suatu permasalahan.  
Rule based system  sering digunakan dalam pembuatan aplikasi 
kecerdasan buatan dan penelitian, salah satu contoh aplikasi dapat dihasilkan dari konsep ini misalnya aplikasi dalam bidang agronomi. Pada bidang agronomi salah satunya adalah aplikasi yang dapat membantu seorang pakar dalam mengklasifiksi suatu permasalahan agronomi berdasarkan ciri-ciri yang telah diketahui.  Pada kombinasi antara  Fuzzy Logic  dengan  Rule-Based System  atau disebut dengan Fuzzy Rule-Based System  memungkinkan penggunaan aturan linguistik untuk menggambarkan hubungan antara parameter masukan dengan keluaran yang diharapkan dari sistem yang dibangun. Salah satu cara untuk merepresentasikan pengetahuan dalam bahasa semi natural pada Fuzzy Rule -Based S ystem  adalah dengan memakai bentuk:  
IF premis THEN  konklusi  
Bentuk IF-THEN tersebut sering kali disebut sebagai bentuk berbasis aturan. Apa bila aturan yang dipakai merupakan aturan Fuzzy, maka dapat dituliskan sebagai  IF X is A THEN  Y is B Dengan A dan B adalah himpunan Fuzzy . Dalam contoh diatas bagian premis adalah X is A dan bagian konklusi adalah Y is B. Komponen utama dalam sistem berbasis aturan Fuzzy  terdiri dari 3 yaitu:  
1. Fuzzification  mengubah masukan -masukan yang nilai 
kebenarannya bersifat pasti (crisp input ) ke dalam bentuk Fuzzy                            
2. input , yang berupa nilai linguistik yang semantiknya ditentukan berdasarkan fungsi keanggotaan tertentu.  
3. Inference  melakukan penalaran menggunakan Fuzzy input  dan Fuzzy Rules  yang telah ditentukan sehingga menghasilkan  Fuzzy output . 
4. Defuzzification  mengubah Fuzzy output  menjadi crisp value  berdasarkan fungsi keanggotaan yang telah ditentukan (Suyanto, 2007).  
 
3. METODE PENELITIAN  
Dalam metodologi penelitian ada urutan kerangka kerja yang 
harus diikuti, urutan kerangka kerja ini merupakan gambaran dari langkah-langkah yang akan dilakukan dalam menyelesaikan 
permasalahan yang akan dibahas agar penelitian berjalan dengan baik. Kerangka kerja yang digunakan  bisa dilihat pada gambar 3.1. berikut :   

4. HASIL DAN PERANCANGAN SISTEM  
Analisa Data   
Adapun data yang didapatkan untuk diproses adalah bentuk 
buah, bentuk pucuk, bentuk lekukan, bentuk paruh dan warna serta ukuran. Selanjutnya data -data tersebut akan diproses menggunakan logika Fuzzy  agar dapat ditentukan variabel yang akan digunakan untuk mendapatkan output  yang diharapkan. Tabel 4.1. menunjukkan data yang diperoleh dari klasifikasi buah Mangga.   
Analisa Sistem  
Sistem dianalisa berdasarkan data-data bentuk, warna dan ukuran, kemudian diproses untuk mengetahui penamaan buah Mangga . Maka dari itu perlu juga dipertimbangkan ciri -ciri fisik yang tampak untuk lebih menguatkan klasifikasi yang dilakukan.   
Perancanganga Sistem  
Dalam perancangan sistem akan dibangun variabel Fuzzy  yang 
membantu dalam pengambilan keputusan. Vari abel Fuzzy  yang akan dibangun terdiri dari enam variabel input  yaitu variabel bentuk buah, variabel bentuk pucuk, variabel bentuk lekukan, variabel bentuk paruh, variabel warna dan variabel ukuran serta satu variabel output  yaitu penamaan buah.   
Representa si Keanggotaan Fuzzy  
1. Variabel Bentuk Buah  
Variabel bentuk buah merupakan variabel masukan yang pertama 
untuk melakukan klasifikasi buah Mangga. Variabel ini terdiri dari tiga himpunan Fuzzy  yaitu bulat, jorong dan panjang.   
ÂµBulat[x] =   
ÂµJorong[x] =   
ÂµPanjang[x] =  
2. Variabel Bentuk Pucuk  
Variabel bentuk pucuk merupakan variabel masukan yang kedua 
untuk melakukan klasifikasi buah Mangga. Variabel ini terdiri dari tiga himpunan Fuzzy  yaitu runcing, bulat dan datar.  
ÂµDatar[x] = 
ÂµBulat[x] =   
ÂµRuncing[x] = 
3. Variabel Bentuk Lekukan  
Variabel bentuk lekukan merupakan variabel masukan yang 
ketiga untuk melakukan klasifikasi buah Mangga. Variabel ini 
terdiri dari tiga himpunan Fuzzy yaitu tidak ada, sedikit dan jelas.Implementasi Fuzzy Untuk 
ÂµTidak Ada[x] =   
ÂµSedikit[x] =   
ÂµJelas[x] =    
4. Variabel Bentuk Paruh  
Variabel bentuk paruh merupakan variabel masukan yang 
keempat untuk melakukan klasifikasi buah Mangga.  Variabel ini terdiri dari tiga himpunan Fuzzy yaitu tidak ada, sedikit dan jelas.  
ÂµTidak Ada[x]  =   
ÂµSedikit[x] =   
ÂµJelas[x] =    
5. Variabel Warna  
Variabel warna merupakan variabel masukan yang kelima untuk 
melak ukan klasifikasi buah Mangga. Variabel ini terbagi tiga himpunan Fuzzy  yaitu hijau, kuning dan merah.  
ÂµHijau[x] =   
ÂµKuning[x] =   
ÂµMerah[x] = 
6. Variabel Ukuran  
Variabel ukuran merupakan variabel masukan yang keenam 
untuk melakukan klasifikasi buah Mangga. Variabel ini terbagi dua himpunan Fuzzy  yaitu pendek dan panjang.  
ÂµPendek[x] = 
ÂµPanjang[x] = 
7. Variabel Penamaan Buah  
Variabel penamaan buah adalah variabel output  yang merup akan hasil yang diinginkan dari klasifikasi buah Mangga.  
Âµ A1[x]   =  
ÂµA2[x]   =
ÂµA3[x]   =
ÂµA4[x]   =
0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80A1 A2 A3 A4 A6 A7 A8 A9 A10 A11 A12 A13 A14 A5 A15
ÂµA5[x]   =  
ÂµA6[x]   =  
ÂµA7[x]   =  
ÂµA8[x]   =  
ÂµA9[x]  =  
ÂµA10[x]  =  
ÂµA11[x]  =  
ÂµA12[x]  =  
ÂµA13[x]  =  
ÂµA14[x]  =
ÂµA15[x]  =   
Pembentukan Aturan Logika Fuzzy  
Fuzzy logic bekerja berdasarkan aturan-aturan dalam melakukan pemetaan dari input  dan output , yang dilakukan dalam bentuk condition  dan action. Hal ini memungkinkan sistem Fuzzy  berjalan tanpa harus melalui komposisi dan dekomposisi. Bentuk condition  dan action  bisa juga disebut dengan IF-THEN rule, dengan format If an tecedent then consequent. Antecedent  yang dimaksud adalah input  dari sistem Fuzzy,  sedangkan untuk consequent  diasosiasikan terhadap Ouput . 

KESIMPULAN  
Berdasarkan hasil analisis yang telah dilakukan pada  implementasi fuzzy  rule based system  klasifikasi  buah mangga, dapat diambil kesimpulan sebagai berikut :   
1. Menjadikan masyarakat mandiri dalam melakukan pengecekan 
penamaan buah. 
2. Variabel input  yang mendukung pengambilan keputusan 
dikelompokkan menjadi 6 bagian yaitu variabel bentuk buah, 
bentuk pucuk, bentuk lekukan, bentuk paruh, warna dan ukuran 
dengan output  penamaan buah.  
3. Sistem yang dirancang menggunakan fuzzy rule -based system  dapat digunakan untuk pengambilan keputusan dalam 
mengklasifikasi buah Mangga.  
 
DAFTAR PUSTAKA  
Arsyad, M. 2014. Implementasi Metode Sugeno pada Sistem Pakar Penentuan Stadium pada Penyakit Tuberculosis (TBC).  
Broto, Wisnu. 2003. 
Mangga: Budi Daya, Pascapanen dan Tata Niaganya. Jakarta: AgroMedia Pustaka.  Gwon, et al.,  2016. 
Estimation of Gaze Detection Accuracy Using the Calib ration Information-Based Fuzzy System . M Jaya Pal , et al., 2015. Software Quality Prediction using Fuzzy Rule Based System.  
Jiang., et al., 2014. 
A New Fuzzy System Based on Rectangular Pyramid.  Kusumadewi, S. dan Purnomo. H. 2005. 
Aplikasi Logika Fuzzy . Yogyakarta: Graha Ilmu.  
Mohammadpour., et al ., 2015. 
Fuzzy Rule -Based Classification System for Assessing Coronary Artery Disease.  Muzayyanah, I. Mahmudy, W. F. dan Cholissodin, I. 2014. 
Penentuan Persediaan Bahan Baku dan Membantu Target Marketing Industri dengan Metode Fuzzy  Inference System  Tsukamoto.  Naba. E. A. 2009. 
Belajar Cepat Fuzzy Logic  Menggunakan Matlab. Yogyakarta: ANDI.  Nasution, I. A. 2014. 
Sistem Pendukung Keputusan Penentuan Pemilihan Laptop dengan Menerapkan Fuzzy  Tahani.  Shaout. et al.,  2013. Fuzzy Rule Base System for Software Classification.  Singhala. P. et al.,  2014. 
Temperature Control using Fuzzy Logic.  Sholihin, M. et al., 2013. 
Sistem Pendukung Keputusan Penentuan Warga Penerima Jamkesmas Dengan Metode Fuzzy  Tsukamoto.  Suyanto. 200 7. 
Artificial Intelligence . Bandung: Informatika.  Wibowo, S. 2015. 
Penerapan Logika Fuzzy Dalam Penjadwalan Waktu Kuliah.  
Winarto, S. S. et al., 2012. 
Menentukan Harga Mobil Bekas dengan Menggunakan Metode Fuzzy  Mamdani dan Metode Jaringan  Syaraf Tiruan.
",klasifikasi,Fuzzy Rule Based,buah mangga,
Penerapan Metode Klasifikasi K-Nearest Neigbor pada Dataset Penderita Penyakit Diabetes,"Penerapan Metode Klasifikasi K-Nearest Neigbor pada Dataset Penderita Penyakit Diabetes

Andi Maulida Arginaa

I. Pendahuluan  
Diabetes adalah suatu penyakit metabolik yang diakibatkan oleh meningkatnya kadar glukosa atau gula darah. Gula darah sangat vital bagi kesehatan karena merupakan sumber energi yang penting bagi sel-sel dan jaringan. Jika tidak dikelola dengan baik, diabetes dapat menyebabkan terjadinya berbagai komplikasi, seperti penyakit jantung koroner, stroke, obesitas, serta gangguan pada mata, ginjal, dan saraf.  Terdapat banyak metode klasifikasi dalam supervised learning  pada machine learning , diantaranya adalah K-Nearest Neighbor  (knn),  Naive Bayes Classifier (nbc), Support Vector Machine  (svm),  Neural Netowork (nn), Random Forest Classifier  (rfc), Ada Boost Classifier  (abc), serta Quadratic Discriminant Analysis  (qda). Metode tersebut memiliki kelebihan serta kekurangannya masing -masing, salah satu faktor me njadi keunggulan metode klasifikasi tersebut dilihat dari bagaimana metode tersebut mengolah objek dataset, K-Nearest Neighbor atau KNN adalah algoritma yang berfungsi untuk melakukan klasifikasi suatu data berdasarkan data pembelajaran ( train data sets ), yang diambil dari K tetangga terdekatnya ( nearest neighbors ).  Pada penelitian ini penulis menggunakan metode KNN untuk menghitung akurasi, presisi, recall , dan F-Measure  berdasarkan nilai K.  Tahap yang dilakukan pada penelitian ini adalah splitting  data training  dan data testing , menerapkan metode klasifikasi knn, serta menghitung performa metode yang akan diuji.  

Kata Kunci : klasifikasi, k-nearest neighbor, analisis, performa, diabetes, dataset  

II. Metode  
A. Data Mining  
Data mining adalah proses yang  menggunakan  statistik, matematika, kecerdasan  buatan,  dan  machine  learning untuk mengekstraksi dan mengidentifikasi informasi yang bermanfaat. Data Mining didefinisikan sebagai proses penemuan pola dalam data. Berdasarkan tugasnya, data mining 
dikelompokkan menjadi deskripsi, est imasi, prediksi, klasifikasi, clustering dan asosiasi. Proses dalam tahap 
data mining terdiri dari tiga langkah Utama, yaitu data Preparation Pada langkah ini, data dipilih, dibersihkan, 
dan dilakukan preprocessed mengikuti pedoman dan knowledge dari ahli domain yang menangkap dan mengintegrasikan data internal dan eksternal ke dalam tinjauan organisasi secara menyeluruh. Penggunaan algoritma data mining dilakukan pada langkah ini untuk menggali data yang terintegrasi untuk memudahkan identifikasi informasi  bernilai. Namun semakin besar data yang diolah maka semakin besar pula waktu 
prosesnya [3][4]. Diabetes adalah penyakit yang berlangsung lama atau kronis serta ditandai dengan kadar gula (glukosa) darah yang tinggi atau di atas nilai normal. Jika diabetes tidak dikontrol dengan baik,  Pengujian performa berbagai metode pada sebuah dataset merupakan salah satu cara dalam penetapan metode klasifikasi yang tepat, masalah yang diangkat pada penelitian ini adalah bagaimana mengukur performa metode klasifikasi dalam mengelola dataset penderita diabetes . Metode yang digunakan yaitu algoritma K-Nearest Neigh bor (KNN), dimana merupakan sebuah metode 
untuk melakukan klasifikasi terhadap objek berdasarkan data pembelajaran yang jaraknya pal ing dekat dengan objek tersebut. Pada hasil akhir penelitian ini, telah dihitung akurasi tertinggi 39% pada K=3, presisi ter tinggi 65% pada K=3 dan K=5, recall  tertinggi 36% pada K=3, dan F-Measure tertinggi 46% pada K=3.  
B. K-Nearest Neighbor  
K-Nearest Neighbor (K-NN) termasuk kelompok instance -based learning. Algoritma ini juga merupakan salah satu teknik lazy learning. kNN dilakukan dengan mencari kelompok k objek dalam data training yang paling dekat (mirip) dengan objek pada data b aru atau data testing. diperlukan suatu sistem klasifikasi sebagai sebuah sistem yang mampu mencari informasi. Contoh kasus, misal diinginkan untuk mencari solusi terhadap masalah seorang pasien baru dengan menggunakan solusi dari pasien lama. Perhitungan jarak ketetanggan menggunakan algoritma euclidien seperti yang ditunjukkan pada persamaan 1.  
euc = âˆš((a_1âˆ’b_1 )^2+â‹¯+(a_nâˆ’b_n )^2 ) 
Dimana a = a1,a2, â€¦, an, dan b = b1, b2, â€¦, bn mewakili n nilai atribut dari dua record. Untuk atribut 
dengan nilai kategori..  
Algoritma K-Nearest Neighbor (K-NN) adalah sebuah metode klasifikasi terhadap sekumpulan data berdasarkan pembelajaran data yang sudah terklasifikasikan sebelumya. Termasuk dalam supervised learning, dimana hasil query instance  yang baru diklasi fikasikan berdasarkan mayoritas kedekatan jarak dari kategori yang ada dalam K-NN.  Algoritma ini bekerja dengan berdasarkan pada jarak terpendek dari sample uji ke sample latih untuk menentukan KNNnya. Setelah mengumpulkan KNN, kemudian diambil mayoritas dari KNN untuk dijadikan prediksi dari sample uji. Dekat atau jauhnya tetangga biasanya dihitung berdasarkan jarak Eucledian. Langkah-langkah untuk menghitung metode K-Nearest Neighbor antara lain:  
1. Menentukan parameter K  
2. Menghitung jarak antara data traini ng dan data testing  
Perhitungan jarak yang paling umum dipakai pada perhitungan pada algoritma KNN adalah menggunakan perhitungan jarak Euclidean. Rumusannya adalah sebagai berikut:  
ð‘’ð‘¢ð‘ = âˆš(âˆ‘(ð‘ð‘–âˆ’ð‘žð‘–)2)ð‘›
ð‘–=1 
dimana :  
pi  = sample data / data training  
qi  = data uji / data testing  
i  = variabel data  
n = dimensi data  
3. Mengurutkan jarak yang terbentuk  
4. Menentukan jarak terdekat sampai urutan K  
5. Memasangkan kelas yang bersesuaian  
6. Mencari jumlah kelas dari tetangga yang terdekat dan tetapkan kelas tersebut sebagai kelas data yang 
akan dievaluasi  
Akurasi   
Akurasi didefinisikan sebagai tingkat kedekatan antara nilai prediksi dengan nilai actual [5]. rumus akurasi dipaparkan pada persamaan 2.  
Presisi   
Presisi didefinisikan sebagai rasio item relevan yang dipilih terhadap semua item yang terpilih [6]. Presisi 
dapat diartikan sebagai kecocokan antara permintaan informasi dengan jawaban terhadap permintaan tersebut. 
rumus presisi ditunjukkan pada persamaan 3.  
Recall   
Recall didefinisikan sebagai rasio dari item relevan yang dipilih terhadap total jumlah item relevan yang 
tersedia. Rumus Recall diuraikan pada persamaan 4.  
F-Measure  
Measure adalah harmonic mean antara nilai presisi dan recall, F-measure juga kadang disebut dengan nama F1-Score. Rumus F -Measure  dijabarkan pada persamaan 5.   AKURASI=((TP+TN))/((TP+TN+FP+FN))  
PRESISI=TP/(TP+FP)  
RECALL=TP/(TP+FN)  
F-Measure=2 (Presisi x Recall)/(Presisi+Recall)  
Keterangan Variabel:  
TP : True Positive  
TN : True Negative  
FP : False Positive  
FN : False Negative.  

III. Hasil dan Pembahasan  
Seperti  yang telah dipaparkan sebelumnya bahwa tahapan yang dilakukan pada penelitian ini adalah dengan melakukan pembagian data training dan data testing, data yang digunakan sebanyak 77 data, dengan pembagian 
sebesar 90% sebagai  data training dan 10% sebagai data tesing. Tahapan selanjutnya adalah menerapkan metode 
KNN, pemilihan nilai K pada penelitian ini yaitu nilai K=3,4 dan 5. Tabel 1. Menunjukkan hasil percobaan 
metode knn pada k=3,4 dan 5  
Hasil  Pemasangan Kelas sesuai K  
K=3 K = 4  K = 5  
1 TP 1 TP 1 TP 
0 FN 0 FN 0 FN 
1 TP 1 TP 1 TP 
0 FN 0 FN 0 FN 
0 FP 1 TP 0 FP 
â€¦ â€¦ â€¦ â€¦ â€¦ â€¦ 
0 FN 0 FN 0 FN 
0 FN 0 FN 0 FN 
0 FN 0 FN 0 FN 
Berdasarkan Tabel 1. Tahap selanjutnya adalah meneruskan hasil tersebut ke dalam bentuk  confusion matrix, Tabel 2 menunjukkan confussion matrix pada k=3.  
Tabel 2. Confusion Matrix K = 3  
n = 77  Predicted : 1  Predicted : 0  
Actual : 1  TP = 20  FN = 36  
Actual : 0  FP = 11  TN = 10  
Setelah diterapkan kedalam confusion matrix, performa metode dapat di ukur, Tabel 3. Menunjukkan performa metode K -nn pada nilai K=3, dimana performa yang diukur adalah akurasi, presisi serta recall  
Tabel 3. Hasil KNN dimana K=3 
Akurasi  39% 
Presisi  65% 
Recall  36% 
F-Measure  46% 
Berdasarkan Tabel 1. Tahap selanjutnya adalah meneruskan hasil tersebut ke dalam bentuk confusion 
matrix, Tabel 4 menunjukkan confussion matrix pada k=4.  
Tabel 4. Confusion Matrix K = 4  
n = 77  Predicted : 1  Predicted : 0  
Actual : 1  TP = 18  FN = 37  
Actual : 0  FP = 13  TN = 9   
Penerapan Metode Klasifikasi K -Nearest Neigbor pada Dataset Penderita Penyakit Diabetes  Setelah diterapkan kedalam confusion matrix, performa metode dapat di ukur, Tabel 3. Menunjukkan performa metode K-NN pada nilai K=4, dimana performa yang diukur adalah akurasi, presisi serta recall  
Tabel 5. Hasil KNN dimana K=4  
Akurasi  35% 
Presisi  58% 
Recall  33% 
F-Measure  42% 
Berdasarkan Tabel 1. Tahap selanjutnya adalah meneruskan hasil tersebut ke dalam bentuk confusion matrix, 
Tabel 4 menunjukkan confussion matrix pada k=5.  
Tabel 6. Confusion Matrix K = 5  
n = 77  Predicted : 1  Predicted : 0  
Actual : 1  TP = 20  FN = 39  
Actual : 0  FP = 11  TN = 7  
Setelah diterapkan kedalam confusion matrix, performa metode dapat di ukur, Tabel 3. Menunjukkan performa metode K-nn pada nilai K=5, dimana performa yang diukur adalah akurasi, presisi serta recall  
Tabel 7. Hasil KNN dimana K=5  
Akurasi  35% 
Presisi  65% 
Recall  34% 
F-Measure  44% 

IV. Kesimpulan  
Dari hasil perhitungan algoritma K -Nearest Neighbor (KNN) di atas, maka telah mendapatkan hasil akurasi tertinggi yaitu 39% pada K=3, presisi tertinggi yaitu 65% pada K=3 dan K=5, recall  tertinggi yaitu 36% pada K=3, dan F-Measure  tertinggi yaitu 46% pada K=3.  Nilai yang diperoleh tidak cukup baik dikarenakan jumlah data yang digunakan cukup kecil. Saran untuk penelitian selanjutnya adalah melakukan percobaan yang sama dengan menambahkan jumlah data serta menerapkan crossvalidation.  

Daftar Pustaka  
[1] N. Fadhillah, H. Azis, and D. Lantara, â€œValidasi Pencarian Kata Kunci Menggunakan Algoritma Levenshtein Distance Berdasarkan Metode Approximate String Matching,â€ Pros. Semin. Nas. Ilmu Komput. dan Teknol. Inf. , vol. 3, no. 2, pp. 3 â€“7, 2018.  
[2] Hasran, â€œKl asifikasi Penyakit Jantung Menggunakan Metode K -Nearest Neighbor,â€ Indones. J. Data Sci., vol. 1, no. 1, pp. 1 â€“4, 2020.  
[3] M. M. Baharuddin, T. Hasanuddin, and H. Azis, â€œAnalisis Performa Metode K -Nearest Neighbor untuk 
Identifikasi Jenis Kaca,â€ Ilk. J. Ilm. , vol. 11, no. 28, pp. 269 â€“274, 2019.  
[4] A. Ilham, â€œKomparasi Algoritma Klasifikasi Dengan Pendekatan Level Data Untuk M enangani Data Kelas Tidak Seimbang,â€ J. Ilm. Ilmu Komput. , vol. 3, no. 1, pp. 9 â€“14, 2017.  
[5] M. Yusa, E. Utami, and E. T. Luthfi, â€œAnalisis Komparatif Evaluasi Performa Algoritma Klasifikasi pada Readmisi Pasien Diabetes,â€ J. Buana Inform. , vol. 7, no. 4,  pp. 293 â€“302, 2016, doi: 10.24002/jbi.v7i4.770.  
[6] Rizky Ade Putranto, Triastiti Wuryandari, and Sudarno, â€œPerbandingan Analisis Klasifikasi Antara Decision Tree Dan Support Vector Machine Multiclass Untuk Penentuan Jurusan Pada Siswa Sma,â€ J. Gaussian , vol. 4, no. 4, pp. 1007 â€“1016, 2015.  
[7] Y. Lukito and A. R. Chrismanto, â€œPerbandingan Metode -Metode Klasifikasi untuk Indoor Positioning System,â€ J. Tek. Inform. dan Sist. Inf. , vol. 1, no. 2, pp. 123 â€“131, 2015, doi: 10.28932/jutisi.v1i2.373.  
[8] S. Niu, J.  Yang, S. Wang, and G. Chen, â€œImprovement and parallel implementation of canny edge detection algorithm based on GPU,â€ Proc. Int. Conf. ASIC , no. 6, pp. 641 â€“644, 2011, doi:  ISSN: 2715 -9930  IJODAS  Vol. 1, No. 2, Juli 2020, pp. 29-33 33 Andi Maulida Argina  10.1109/ASICON.2011.6157287.  
[9] W. Ye, Y. Xia, and Q. Wang, â€œAn Improved Canny Alg orithm for Edge Detection,â€ J. Comput. Inf. Syst., vol. 75, pp. 1516 â€“1523, 2011, doi: 10.1109/WCSE.2009.718.  
[10] T. F. Wu, C. J. Lin, and R. C. Weng, â€œProbability estimates for multi -class classification by pairwise 
coupling,â€ J. Mach. Learn. Res. , vol. 5 , pp. 975 â€“1005, 2004.  
[11] K. Crammer, â€œOn the algorithmic implementation of multiclass kernel -based vector machines,â€ J. Mach. Learn. Res. - JMLR , vol. 2, no. 2, pp. 265 â€“292, 2002.  
[12] M. J. Hartmann and G. Carleo, â€œNeural-Network Approach to Dissipative  Quantum Many-Body Dynamics,â€ Phys. Rev. Lett. , vol. 122, no. 25, p. 250502, Jun. 2019, doi: 10.1103/PhysRevLett.122.250502.  
[13] B. Gao and L. Pavel, â€œOn the Properties of the Softmax Function with Application in Game Theory and Reinforcement Learning,â€ 2 017. 
[14] H. Zhang, â€œThe optimality of Naive Bayes,â€ Proc. Seventeenth Int. Florida Artif. Intell. Res. Soc. Conf. 
FLAIRS 2004 , vol. 2, pp. 562 â€“567, 2004.  
[15] V. Metsis, I. Androutsopoulos, and G. Paliouras, â€œSpam filtering with Naive Bayes - Which Naive Bayes?,â€ 3rd Conf. Email Anti -Spam - Proceedings, CEAS 2006 , 2006.  
[16] M. Christopher, P. Raghavan, and H. Schutze, An Introduction to Information Retrieval . Cambridge University Press, 2009.  
[17] Y. L. Pavlov, â€œRandom forests,â€ Random For. , pp. 1 â€“122, 20 19, doi: 10.1201/9780367816377 -11. 
[18] T. Hastie, S. Rosset, J. Zhu, and H. Zou, â€œMulti -class AdaBoost,â€ Stat. Interface , vol. 2, no. 3, pp. 349 â€“360, 2009, doi: 10.4310/sii.2009.v2.n3.a8.  
[19] R. Puri and K. Khamrui, â€œApplication of Quantitative Descripti ve Analysis (QDA), Principal Component Analysis (PCA) and Response Surface Methodology (RSM) in standardization of cham-cham making.,â€ 2015.  
[20] A. Tharwat, â€œLinear vs. quadratic discriminant analysis classifier: a tutorial,â€ Int. J. Appl. Pattern 
Recogni t., vol. 3, no. 2, p. 145, 2016, doi: 10.1504/ijapr.2016.079050.  
[21] A. Tharwat, â€œClassification assessment methods,â€ Appl. Comput. Informatics , 2018, doi: 10.1016/j.aci.2018.08.003.  
[22] P. A. Flach and M. Kull, â€œPrecision -Recall -Gain curves: PR analysis  done right,â€ Adv. Neural Inf. 
Process. Syst. , vol. 2015 -Janua, pp. 838 â€“846, 2015.  
[23] L. Nurhayati and H. Azis, â€œPerancangan Sistem Pendukung Keputusan Untuk Proses Kenaikan Jabatan 
Struktural Pada Biro Kepegawaian,â€ Semin. Nas. Teknol. Inf. dan Multimed ., pp. 6 â€“7, 2016.  
[24] J. D. Kelleher, B. Mac Namee, and A. D. Arcy, Fundamentals of Machine Learning For Predictive 
Data Analytics Algorithms, Worked Examples, and Case Studies . London: The MIT Press, 2015.  
[25] K. H. Brodersen, C. S. Ong, K. E. Stephan, and J. M. Buhmann, â€œThe balanced accuracy and its 
posterior distribution,â€ Proc. - Int. Conf. Pattern Recognit. , pp. 3121 â€“3124, 2010, doi: 10.1109/ICPR.2010.764.  
[26] A. A. Karim, H. Azis, and Y. Salim, â€œKinerja Metode C4.5 dalam Penyaluran Bantuan Dana Bencana 
1,â€ Pros. Semin. Nas. Ilmu Komput. dan Teknol. Inf. , vol. 3, no. 2, pp. 84 â€“87, 2018.  
[27] A. Fitria and H. Azis, â€œAnalisis Kinerja Sistem Klasifikasi Skripsi men ggunakan Metode NaÃ¯ve Bayes 
Classifier,â€ Pros. Semin. Nas. Ilmu Komput. dan Teknol. Inf. , vol. 3, no. 2, pp. 102 â€“106, 2018.",klasifikasi,K-Nearest Neighbor,Dataset Penderita Penyakit  Diabetes,"akurasi, presisis, recall, f-measure"
KLASIFIKASI PEMINJAMAN NASABAH BANK MENGGUNAKAN METODE NEURAL NETWORK,"KLASIFIKASI PEMINJAMAN NASABAH BANK MENGGUNAKAN METODE NEURAL NETWORK

Nur Hadianto1, Hafifah Bella Novitasari2, Ami Rahmawati3

Abstract
Payment of loans that experience difficulties in repayment or often called bad credit is a very detrimental thing for the bank, with the occurrence of bad credit the bank does not have the maximum ability to make money for investment. 
Choosing the right customer must  go through the right analysis because the decision to approve or disagree with the loan is the main point that determines the possibility of bad credit. This study aims to classify eligible customers to obtain loans by taking into account existing parameters such as age, total income, number of families, monthly expenditure average, education level and others. 
This study uses a data mining classification method with a neural network model, to assess the accuracy of data processing using rapid miners then proceed with measurements using confusion matrix, ROC curve. The results of the neural network algorithm after going through confusion matrix testing, the ROC curve shows a very high accuracy value, and the dominant value of AUC and algorithm. The accuracy value is 98.24% with AUC of 0.979 . 
 
Keywords : Loan, Classification, Neural Network, Data Mining , Rapid Miner, Backpropagation  
 
Abstrak 
Pembayaran pinjaman yang mengalami kesulitan dalam pengembalian atau sering disebut  kredit macet merupakan sebuah hal yang sangat merugikan bagi pihak bank, dengan terjadinya kredit macet bank tidak memiliki kemampuan yang 
maksimal dalam melakukan perputaran uang untuk investasi. Pemilihan nasabah yang tepat harus melalui analisa yang matang karena keputusan untuk menyetujui atau tidak menyetujui pinjaman adalah poin utama yang menentukan kemungkinan terjadinya kredit macet. Penelitian ini bertujuan untuk mengklasifikasi nasabah yang layak untuk mendapatkan pinjaman dengan memperhitungkan  parameter yang ada seperti usia, jumlah pendapatan, jumlah keluarga, rata-rata pengeluaran perbulan tingkat pendidikan dan lainnya. Penelitian ini menggunakan metode klasifikasi data mining  dengan model neural network, untuk menilai akurasi pengolahan data menggunakan  rapid miner  kemudian dilanjutkan dengan pengukuran menggunakan confusion matrix, kurva ROC. Hasil algoritma neural network  setelah melalui pengujian confusion matrix, kurva ROC  menunjukkan nilai akurasi yang sangat tinggi, dan nilai dominan AUC dan algor itma. Nilai akurasi adalah 9 8,24 % dengan AUC sebesar 0,9 79 
 
Kata Kunci : Pinjaman, Klasifikasi, Neural Network, 
Data Mining, Rapid Miner, Backpropagation . 
 
PENDAHULUAN  
Menurut Undang-Undang Perbankan Nomor 10 Tahun 1998, kredit adalah penyediaan uang atau tagihan yang dapat dipersamakan 
dengan itu berdasarkan persetujuan atau kesepakatan pinjam-meminjam antar bank dengan pihak lain yang mewajibkan pihak peminjam melunasi hutan gnya setelah jangka waktu tertentu dengan pemberian bunga (Marhumi, 2017) , dalam menjalankan bisnisnya penting bagi bank dan lembaga pembiayaan untuk mengevaluasi resiko kredit dilakukan dimuka bagi konsumen. Sebuah model yang baik bagi penilaian kredit akan membantu bank dan lembaga pembiayaan membuat keputusan yang tepat dalam rangka menghindari potensi besarnya resiko  (Defu, Stephen, & Zhimei, 2008) ,  Penilaian kredit sebagai teknik penilaian mer upakan  instrumen penting dalam industri  keuangan dan perbankan  (Wang, Lai, & Niu, 2011) . Besarnya jumlah kredit yang disalurkan  akan menentukan keuntungan yang diperoleh. Akan tetapi tidak berarti bahwa jumah kredit yang disalurkan besar akan memberikan keuntungan yang besar pula  (Marhumi, 2017) . Dewasa ini, masih banyak perusahaan keuangan atau bank mengalami kesulitan untuk meminjamkan asset berupa pinjaman (loan) kepada nasabah yang terpercaya dan sesuai ketentuan (Arun, Ishan, & Sanmeet, 2016) . Dalam proses pemberian pinjaman selama ini  yang dilakukan oleh bank, meskipun melalui analisa kredit yang berjenjang 
masih saja terdapat permasalah yang timbul salah satunya adalah para calon peminjam melakukan berbagai macam cara agar pinjamannya dapat disetujui oleh pihak Bank. Hal ini lah yang menyebabkan ting kat kredit macet menjadi meningkat  (Iriadi & Nuraeni, 2016) . Penyebab lainnya antara lain kurang akuratnya pegawai Bank dalam menganalisa calon debitur  (Iriadi & Nuraeni, 2016) . Salah satu metode yang dapat digunakan adalah pendekatan Machine Learning  (Putri, 2018) . Data mining  adalah proses menemukan korelasi, pola, dan tren baru yang bermakna dengan menyaring sejumlah besar data yang disimpan dalam repositori, menggunakan teknologi pengenalan pola serta  teknik statistik dan matematik  (Larose, 2005) , jika data mining  berfokus pada penggunaan program untuk membantu pembelajaran manusia terhadap data maka metode pembuatan program yang dapat belajar disebut machine learning, berbeda dengan program komputer yang biasa, machine learning  adalah program yang dirancang untuk  mampu belajar sendiri (Putri, 2018) . Metode klasifikasi 
adalah salah satu metode yang paling sering digunakan, di dalam metode klasifikasi salah satu teknik yang digunakan adalah Neural Network  yang sering digunakan untuk menyelesaikan masalah-masalah yang rumit dan berkaitan dengan identifikasi input, prediksi , pengenalan pola dan sebagainya  (Windarto, 2017) . Dikarenakan hal tersebut maka dalam penelitian ini penulis akan menggunakan metode klasifikasi menggunakan teknik Neural Network dalam menentukan klasifikasi peminjaman bagi nasabah yang memiliki peluang tinggi untuk menjadi nasabah peminjam . 
 
BAHAN DAN METODE   
a. Sumber data  
Data yang digunakan dalam penelitian ini adalah data sekunder yang diperoleh dari machine learning repository  dengan alamat web http://www.kaggle.com  dengan jumlah data 5000 observasi mengenai perilaku nasabah pada bank dalam periode tertentu.   
b. Variabel Penelitian  
Dalam penelitian ini kita akan menggunakan dataset sebanyak 5000 data yang terdiri dari 14 variabel yang dapat diihat pada Tabel 1  
Tabel 1 : Variabel Penelitian  
1  ID Identitas nasabah berupa nomor urut  Kuantitatif  
2  Age Usia nasabah (tahun)  Kuantitatif  
3  Experience  Pengalaman profesional Kuantitatif  nasabah (tahun)  
4  Income  Pendapatan per tahun nasabah ($000)  Kuantitatif  
5  ZIP Code  Kode ZIP (Zone Improvement Plan) atau kode pos alamat nasabah  Kuantitatif  
6  Family  Jumlah anggota keluarga nasabah (tanpa nasabah)  Kuantitatif  
7  CCAvg  Rata-rata pengeluaran nasabah menggunakan kartu kredit per bulan ($000)  Kuantitatif  
8  Education  Tingkat pendidikan nasabah  1. Belum lulus kuliah  2. Sudah lulus kuliah  3. Profesional  Kuantitatif 
9  Mortgage  Harga penggadaian rumah nasabah ($000)  Kuantitatif  
10  Securities Account  Kepemilikan nasabah akan  akun keamanan bersama bank  0. Tidak  1. Ya  Kuantitatif  
11  CD Account  Kepemilikan nasabah akan  sertifikat deposit 
bersama bank  0. Tidak  1. Ya  Kuantitatif  
12  Online  Penggunaan nasabah akan fasilitas online banking  0. Tidak  1. Ya  Kuantitatif  
13  CreditCard  Penggunaan nasabah akan  kartu kredit yang 
dikeluarkan oleh UniversalBank  0. Tidak  1. Ya  Kuantitatif  
14  Personal Loan  (Target)  Pembelian peminjaman aset  Kuantitatif (personal loan) oleh nasabah  0. Tidak  1. Ya  
Sumber : (Hadianto et al., 2019)   
c. Neural Network : Multi Layer Perceptron  Neural network  adalah pemrosesan informasi sistem. Secara umum neural network  dapat dianggap sebagai sistem kotak hitam yang 
menerima input  dari lingkungan dan menghasilkan output.  neural  network  mengandung  elemen pemrosesan dan pembobotan yang saling terhubung. Setiap lapisan dalam jaringan  berisi oleh kelompok elemen pemrosesan seperti yang ditunjukkan pada gambar.1  (Fadly, Uddin, & Sutarto, 2002)   Sumber: (Fadly et al., 2002)  
Gambar 1. Multi Layer Perceptron Neural Networks   
Setiap elemen pemrosesan mengumpulkan nilai dari semua input  yang terhubung ke elemen pemrosesan dan menghasilkan output  melalui operasi matematika  (perkalian  operasi). Ada tiga 
lapisan yang membangun neural network , yaitu lapisan input , lapisan tersembunyi, dan lapisan keluaran. (Fadly et al., 2002)   
d. Artificial Neural Network   
Artificial Neural Network  (Jaringan Syaraf Tiruan) adalah model non-linear  yang kompleks, dibangun dari komponen yang secara individu berperilaku mirip dengan model regresi. Jaringan syaraf tiruan dapat divisualisasikan dengan grafik, 
dan beberapa sub-grafik beberapa memiliki perilaku yang sama dengan grafik sebelumnya. Meskipun struktur dari jaringan saraf secara eksplisit dirancang terlebih dahulu, pengolahan jaringan saraf ini tidak untuk menghasilkan hipotesis (berbagai neuron  dan pengolahan lainnya terstruktur dalam jaringan) berkembang selama proses pembelajaran. Hal ini memungkinkan neuron  yang membentuk jaringan akan digunakan sebagai pemecahan masalah dari """"program itu sendiri"""" . (Yalidhan, 2018)   
e. Arsitektur Backpropagation  
Algoritma back-propagation  adalah  algoritma yang paling populer  dalam pembelajaran jaringan saraf tiruan. Algoritma ini didasarkan pada aturan pembelajaran dengan koreksi kesalahan  (Fadly et al., 2002) . Pembelajaran kesalahan-koreksi pada back -propagati on dibagi dalam dua cara utama
mundur. Di depan, vektor input diterapkan pada layer input  di setiap jaringan kemudian mempengaruhi semua jaringan, lapis demi lapis. Output  dari jaringan adalah respon dari jaringan saraf. Bobot di setia p lapisan di depan adalah tetap. Gambar dan persamaan pembelajaran maju ditunjukkan dalam gambar  2 dan persamaan 1 dan 2 (Fadly et al., 2002)   
Sumber: (Fadly et al., 2002)  
Gambar 2. Forward Learning Neural Network  
ð‘š=ð‘‰ð‘ž+ð‘Ž  â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦.â€¦â€¦â€¦..(1)  
ð‘Ÿ=ð‘“(ð‘š)â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦..(2)   
Pada bagian belakang semua pembobotan di setiap lapisan berubah  berdasarkan aturan koreksi kesalahan. Kesalahan adalah pengurangan respons jaringan dan target keinginan. Kesalahan ini diterapkan secara  mundur ke semua jaringan  yang telah dilewati  atau  dengan  cara yang berlawanan dari struktur jaringan  karenanya disebut  sebagai back- propagation """". Semua bobot dalam jaringan diperbaiki  dan respon jaringan bergerak menuju sasaran. Teknik pembelajaran back-propagation pada koreksi error menggunakan metode gradient descent. Prinsip metode ini adalah efisiensi turunan parsi al dari fungsi aktivasi di setiap elemen untuk menyesuaikan perubahan bobot pada setiap input.  
ð‘‰(ð‘˜+1)=ð‘‰(ð‘˜)âˆ’ðœ‚ðœ•ð¸
ðœ•ð‘šðœ•ð‘š
ðœ•ð‘‰â€¦â€¦â€¦â€¦â€¦â€¦â€¦(3) 
Dimana  
ð¸=1
2ð‘’ð‘‡(ð‘˜)ð‘’(ð‘˜)â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦.(4) 
ð‘’(ð‘˜)=ð‘‘(ð‘˜)âˆ’ð‘Ÿ(ð‘˜) 
Dimana  
ð‘’(ð‘˜)=  Kesalahan antara target dan respon  
ð‘‘(ð‘˜)=  Target yang diinginkan  
       ðœ‚=   Learning rate  
f. Percobaan  dan Pengujian Model  
Dataset  yang dimiliki akan dibagi 2, sebagian akan digunakan sebagai training set  dan sebagian akan digunakan sebagai data testing set, kemudian data training  tersebut akan dimasukkan dalam sebuah metode neural network  dengan 
backpropagation  program menggunakan tools Rapid Miner . 
g. Evaluasi dan Validasi Hasil  
Evaluasi dan validasi dilakukan untuk membahas hasil pengamatan dan analisa yang dilakukan terrhadap pene litian ini menggunakan Neural Network  di Rapid Miner . Pengujian yang didapat dari  metode confusion matrix  adalah akurasi sedangkan pengujian yang didapat dari metode ROC CURVE  (AUC) adalah gambaran kurva yang memisahkan antara kelas berbeda .  
I. Cross Validation  
Cross validation  adalah prosedur untuk memperkirakan generalisasi kinerja dalam sebuah metode permodelan. Cross-validation adalah metode yang paling sering digunakan untuk 
evaluasi kinerja prediktif dari sebuah model, yakni model yang diberikan sebelumnya atau model yang telah dikembangkan oleh prosedur permodelan  (Yadav & Shukla, 2016). Data biasanya akan dibagi menjadi dua bagian pada bagian pertama 
dilakukan pelatihan sementara pada bagian lainnya dilakukan uji kinerja, skema pelatihan dan pengujian bekerja dengan baik pada model klasifikasi di dalam machine learning , beberapa record  dalam dataset  dijadikan data training  untuk dilatih sementara record  lainya di dalam dataset  
digunakan sebagai data testing, hal tersebut adalah 
prinsip dasar dari cross validation, karena hal tersebutlah cross-validation  sangat diterima dalam komunitas data mining dan machine learning dan berfungsi sebagai prosedur standard untuk pemilihan model atau  pemilihan prosedur 
permodelan, (Yadav & Shukla, 2016)  
 
II. Pengukuran menggunakan ROC Curve  
Pengukuran hasil validasi dengan menggunakan ROC Curve  dan Confusion matrix  sampai mendapatkan tingkat akurasi yang 
tertinggi. ROC Curve  adalah Kurva ROC banyak digunakan para peneliti untuk menilai hasil prediksi Kurva  ROC menggambarkan kinerja klasifikasi tanpa memperhatikan distribusi kelas atau kesalahan, pada sumbu vertical  menggambarkan nilai positif (TP) dan sumbu horizontal  menandakan nilai negative (FP) . (Ir. Adi Sucipto, n.d.) .. ditunjukkan dalam gambar  3  Sumber : (Sucipto, 2012)  
Gambar 3. Contoh Grafik ROC  
Garis diagonal yang membelah ruang ROC menggambarkan ruang diatas garis diagonal menandakan klasifikasi baik dan ruang dibawah garis diagonal menandakan klasifikasi buruk, sementara tebakan yang benar-benar acak terdapat pada sepanjang garis diagonal mulai dari kiri bawah sampai dengan kanan atas  Sebuah metode umum untuk menghitung  daerah dibawah kurva ROC adalah Area Under Curve  (AUC) dimana bidang yang berada dibawah kurva mempunyai nilai yang selalu berada pada nilai 0,0 dan 1,0. Namun yang menarik untuk 
dihitung adalah yang mempunyai luas diatas 0,5, semakin tinggi luasnya maka akan semakin baik seperti petunjuk yang disajikan berikut ini (Ir. Adi Sucipto, n.d.) .: 
ïƒ˜ 0.9- 1.00 = klasifikasi yang sangat baik  
ïƒ˜ 0.8 â€“ 0.9 = klasifikasi baik  
ïƒ˜ 0.7 â€“ 0.8 = klasifikasi rata -rata  
ïƒ˜ 0.6 â€“ 0.7 = klasifikasi rendah  
ïƒ˜ 0.5 â€“ 0.6 = kegagalan  
 
III Pengukuran menggunakan confusion matrix  
Pengukuran terhadap kinerja suatu sistem klasifikasi merupakan hal yang penting. Kinerja sistem klasifikasi menggambarkan seberapa baik sistem dalam mengklasifikasikan data. Confusion  matrix  merupakan salah satu metode yang dapat digunakan untuk mengukur kinerja suatu metode klasifikasi. Pada dasarnya  confusion  matrix  mengandung informasi yang membandingkan hasil klasifikasi yang dilakukan oleh sistem dengan hasil klasifikasi yang seharusnya. (E. Prasetyo, 2012)  Pada pengukuran kinerja menggunakan  confusion  matrix , terdapat 4 (empat) istilah sebagai representasi hasil proses klasifikasi. Keempat istilah tersebut adalah  True  Positive  (TP),  True  Negative  (TN),  False  Positive  (FP) dan  False  Negative  (FN). Nilai  True  Negative  (TN) merupakan jumlah data negatif yang terdeteksi dengan benar, sedangkan  False  Positive  (FP) merupakan data negatif namun terdeteksi sebagai data positif. Sementara itu,  True  Positive  (TP) merupakan data positif yang terdeteksi benar.  False  Negative(FN) merupakan kebalikan dari  True  Positive , sehingga data positif, namun  terdeteksi sebagai data negatif.  Pada jenis klasifikasi  binary  yang hanya memiliki 2 keluaran kelas,  confusion  matrix  dapat disajikan seperti pada Tabel 2 (Sokolova & Lapalme, 2009)   
Tabel 2. Confusion Matrix   
Sumber : (Hadianto et al., 2019)   
Dari tabel diatas kita dapat melihat nilai akurasi, presisi dan recall  didapat dari nilai True Positive  (TP), True Negative  (TN), False Positive  (FP) dan False Negative  (FN), nilai akurasi menggambarkan seberapa akurat dan efektifitas sistem secara keseluruhan dalam mengklasifikasikan data secara benar, perhitungan akurasi dinyatakan dalam persamaan 5 (Sokolova & Lapalme, 2009)   
Akurasi = ð‘‡ð‘ƒ+ð‘‡ð‘
ð‘‡ð‘ƒ+ð‘‡ð‘+ð¹ð‘ƒ+ð¹ð‘ð‘¥100%  â€¦â€¦â€¦â€¦â€¦.. (5)  
 
HASIL DAN PEMBAHASAN   
Hasil Penelitian  
Pada bagian ini akan membahas hasil implementasi penggunaan Neural Network pada penentuan klasifikasi peminjaman nasabah pada sebuah bank dengan menggunakan metode backpropagation, Analisa difokuskan pada pengaruh struktur neural network, tingkat pembelajaran (learning rate) neural network, dan 
momentum  neural  network , dalam penelitian ini menggunakan dataset  sebanyak 5000 data.  Dalam penelitian untuk mendapatkan struktur neural network  yang optimal kami melakukan beberapa ujicoba perubahan struktur dengan tingkat pembelajaran (learning rate), training cycles  dan momen tum  yang sama yakni learning rate  = 0.0.1, training cycles  = 500 dan momentum  = 0.1, pertama kali kami mencoba struktur 12 â€“ 7 â€“ 3 â€“ 1 artinya struktur tersebut memiliki 12 input , 7 neuron  pertama yang tersembunyi, 3 neuron  kedua yang tersembunyi dan 1 output, kemudian kami mencoba beberapa struktur yang lain seperti 12 â€“ 20 â€“ 8 â€“ 1 , 12 â€“ 15 â€“ 8 â€“ 1 , 12 â€“ 10 â€“ 5 â€“ 1 , 12 â€“ 7 â€“ 3 â€“ 1, dari semua struktur yang dicoba tidak terdapat perbedaan yang signifikan hanya selisih 0 (nol) koma sekian, 
akan tetapi dari seluruh struktur yang sudah kami coba kami menemukan bahwa struktur 12 â€“ 15 â€“ 8 â€“ 1 merupakan struktur yang paling adaptif dengan akurasi 98.24 %, struktur 12 â€“ 15 â€“ 8 â€“ 1 adalah seperti pada gambar 4. dibawah ini.  
Sumber : (Hadianto et al., 2019)  
Gambar 4. Neural Network  Struktur 12 â€“ 15 â€“ 8 â€“ 1  
Tingkat akurasi yang didapatkan dari hasil ujicoba ini adalah sebesar 98.24% +/ - 0.62% dan AUC sebesar 0.979 +/ - 0.0.14 seperti pada gambar yang disajikan dari Performance Vector  seperti pada gambar 5. dibawah ini.  
Sumber : (Hadianto et al., 2019)  
Gambar 5. Performance Vector  Neural Network  
Pembahasan penelitian  
Setelah pada tahap proses pengumpulan data dan pemilahan atribut yang akan digunakan di dalam dataset  maka langkah selanjutnya adalah kita harus memasukkan datanya terlebih dahulu dengan fungsi read excel  kedalam tools rapid miner  
lalu pembuatan permodelan  neural network menggunakan data sebanyak 5000, tahapan proses dimulai dengan tahap permodelan  kemudian memasuki tahap learning  guna memproses 
datatraining  dengan ujicoba struktur, training cycles, learning rate, momentum  kemudian diakhiri dengan testing  untuk melihat hasil . 
1. Proses Permodelan  
Proses ini menggunakan cross validation  untuk melakukan pengujian model setelah sebelumnya model telah dibaca dengan operator read excel, seperti pada gambar 6 .  
Sumber : (Hadianto et al., 2019)  
Gambar 6. Permodelan  Neural Network   
Pada gambar diatas dilakukan proses pengujian model yang telah dibaca menggunakan operator read excel , data yang telah dibaca tersebut kemudian dimasukkan kedalam operator cross validation , dalam penelitian ini cross validation  yang digunakan sebesar 10 fold validation . 
2. Proses Training  
Proses selanjutnya yang dilakukan adalah proses training , proses ini dilakukan di dalam operator cross validation  dengan menggunakan algoritma neural network , dengan algoritma ini maka data akan dibagi menjadi 2, bagian pertama digunakan sebagai datatraining  dan bagian kedua digunakan sebagai datatesting , seperti pada gambar 7 dibawah ini.  
Sumber : (Hadianto et al., 2019)  
Gambar 7. Proses  Training  Neural Network   
Pada gambar diatas proses training  dilakukan menggunakan operator neural network, training  diatas menggunakan struktur 12 â€“ 15 â€“ 8 â€“ 1 dengan training cycles  sejumlah 500, learning rate  0.01 dan momentum  0.1.  
3. Proses Testing  
Tahapan terakhir dari proses ini setelah dilakukan training  adalah testing  terhadap dataset  menggunakan fungsi backpropagation  yang telah dilakukan pada datatraining  sebelumnya, proses testing  ini dilakukan dengan cara insert apply model  dan performance  dengan main criterion accuracy  dan AUC, seperti pada gambar 8  dibawah ini.  
Sumber : (Hadianto et al., 2019)  
Gambar 8. Proses  Testing  Neural Network  
4. Hasil Testing  
Hasil dari training  dan juga testing data terhadap 5000 data nasabah Bank yang mengajukan pinjaman dapat kita lihat pada Performance Vector  seperti pada gambar  9 dibawah ini .   
Hasil testing  menggunakan algoritma neural 
network  menunjukkan performance accuracy  yang didapat sebesar 98.24%.   
5. Hasil Uji ROC Curve  
Hasil dari training dan juga testing data menggunakan neural network menampilkan grafik ROC dengan nilai AUC (Area Under Curve) sebesar, hasil tersebut dapat dilihat seperti pada gambar 10 dibawah ini.   
Sumber : (Hadianto et al., 2019)  
Gambar 10. Nilai AUC pada grafik ROC Neural Network .  
Dari gambar diatas kita dapat melihat bahwa nilai sebesar 0.979. termasuk dalam kategori â€œklasifikasi yang sangat baikâ€ karena data tersebut berada diantara range  0.9 â€“ 1.0 .   
6. Hasil Uji Confusion Matrix  
Tabel dari confusion matrix  hasil pengolahan dataset  menggunakan algoritma backpropagation  pada neural network  adalah seperti pada gambar  11 dibawah ini. Dari parameter TP, FP, FN dan TN pada gambar diatas kita dapat menghitung secara manual nilai akurasi dengan menggunakan rumus pada persamaan 6 , 7 dan 8 . sebagai berikut.   
Akurasi  = ð‘‡ð‘ƒ+ð‘‡ð‘
ð‘‡ð‘ƒ+ð‘‡ð‘+ð¹ð‘ƒ+ð¹ð‘ð‘¥100% .    â€¦............... (6) 
(Sokolova & Lapalme, 2009)  
               ð‘‡ð‘Ÿð‘¢ð‘’  ð‘ƒð‘œð‘ ð‘–ð‘¡ð‘–ð‘£ð‘’  (ð‘¡ð‘)=4491  record   
ð¹ð‘Žð‘™ð‘ ð‘’  ð‘ð‘’ð‘”ð‘Žð‘¡ð‘–ð‘£ð‘’  (ð‘“ð‘›)=59 record     
ð‘‡ð‘Ÿð‘¢ð‘’  ð‘ð‘’ð‘”ð‘Žð‘¡ð‘–ð‘£ð‘’  (ð‘¡ð‘›)=421  record  
ð¹ð‘Žð‘™ð‘ ð‘’  ð‘ƒð‘œð‘ ð‘–ð‘¡ð‘–ð‘£ð‘’  (ð‘“ð‘)=29 record    
TP = 4491          FN = 59  
FP = 29               TN = 421  
Akurasi  = (4491 +421 )
(4491 +421 +29+59) ð‘¥ 100%   â€¦â€¦........... (7)  
Akurasi  = 4912
5000ð‘¥100% =98.24%   â€¦â€¦â€¦â€¦â€¦â€¦ (8) 
Dari hasil klasifikasi menunjukkan bahwa, tingkat akurasi dengan menggunakan algoritma neural network adalah sebesar 98,24%  
 
KESIMPULAN  
Berdasarkan penelitian yang telah dilakukan menggunakan tools rapid miner  9.0 terhadap data nasabah Bank sejumlah 5000 dataset  yang didapat dari machine learning repository  dengan alamat web http://www.kaggle.com  yang diuji dengan algoritma backpropagation  dalam Neural Network  menggunakan struktur 12 â€“ 15 â€“ 8 â€“ 1 , training cycles  seju mlah 500, learning rate  0.01 dan momentum  0.1 menghasilkan nilai akurasi = 98.24 %, dengan AUC sebesar =0, 979  yang menunjukkan bahwa klasifikasi yang dihasilkan sangat baik, sehingga nasabah dengan parameter yang ada dapat diprediksi menggunakan pola ini untuk menentukan nasabah yang layak diberikan pinjaman dari pihak Bank.  
 
REFERENSI  
Arun, K., Ishan, G., & Sanmeet, K. (2016). Loan Approval Prediction based on Machine Learning Approach . 18(3), 2016. 
https://doi.org/10.9790/0661 -1803017981   
Defu, Z., Stephen, C. H. L., & Zhimei, Y. (2008). A decision tree scoring model based on genetic algorithm and K-means algorithm. Proceedings - 3rd International Conference on 
Convergence and Hybrid Information Tech nology, ICCIT 2008 , 1, 1043 â€“1047. https://doi.org/10.1109/ICCIT.2008.110   
Fadly, M., Uddin, N., & Sutarto, H. Y. (2002). Flutter 
Suppression Using Neural Networksâ€¯: Design and Implementation . (January 2017).   
Hadianto, N., Novitasari, H. B., Rahmawati, A.,  Prasetyo, R., Miharja, J., & Komputer, I. (2019). Klasifikasi peminjaman nasabah bank menggunakan metode neural network . 14(2), 1â€“7.  
Ir. Adi Sucipto, M. K. (n.d.). CREDIT PREDICTION 
WITH NEURAL NETWORK ALGORITHM Ir . Adi Sucipto , M . Kom . Sains and Tec hnology Faculty Universitas Islam Nahdlatul Ulama Jepara . (15), 978 â€“979.   
Iriadi, N., & Nuraeni, N. (2016). kajian penerapan metode klasifikasi data mining algoritma C4.5 untuk prediksi kelayakan kredit pada bank mayapada jakarta. Jurnal Teknik Komputer AMIK BSI (JTK) , 2, 132 â€“137.   
Larose, D. T. (2005). Discovering Knowledge in Data . New Jersey: Johny Wiley & Sons, Inc.   
Marhumi, S. (2017). Analisis Manajemen Perkreditan Untuk Meningkatkan Profitabilitas Pada Bank Bni Wilayah Vii Makassar. Perspektif , 02(01), 2355 â€“2538. Retrieved from 
www.journal.unismuh.ac.id/perspektif   
Putri, C. B. (2018). Klasifikasi Nasabah Thera Bank Membeli Personal Loan Menggunakan Metode Klasifikasi Dalam Machine Learning .  
Sokolova, M., &  Lapalme, G. (2009). A systematic analysis of performance measures for classification tasks. Information Processing and Management , 45(4), 427 â€“437. https://doi.org/10.1016/j.ipm.2009.03.002   
Sucipto, A. (2012). CREDIT PREDICTION WITH NEURAL NETWORK ALGORIT HM Ir . Adi Sucipto , M . Kom . Sains and Technology Faculty Universitas Islam Nahdlatul Ulama Jepara . (15), 978 â€“979.   
Wang, Q., Lai, K. K., & Niu, D. (2011). Green credit scoring system and its risk assessemt model with support vector machine. Proceedings - 4th International Joint Conference on Computational Sciences and Optimization, CSO 2011 , 284 â€“287. https://doi.org/10.1109/CSO.2011.143        
Windarto, A. P. (2017). Implementasi Jst Dalam Menentukan. Sains Komputer & Informatika , 1(1), 12 â€“23.  
Yadav, S., & S hukla, S. (2016). Analysis of k-Fold Cross -Validation over Hold-Out Validation on Colossal Datasets for Quality Classification. Proceedings - 6th International Advanced Computing Conference, IACC 2016 , (Cv), 78 â€“83. https://doi.org/10.1109/IACC.2016.25   
Yalidhan, M. D. (2018). Implementasi Algoritma Backpropagation Untuk Memprediksi Kelulusan Mahasiswa. Klik - Kumpulan Jurnal Ilmu Komputer , 5(2), 169. 
https://doi.org/10.20527/klik.v5i2.152   ",klasifikasi,"Neural Network, NN",nasabah bank,"akurasi, AUC"
Klasifikasi Penyakit Gigi Dan Mulut Menggunakan Metode Support Vector Machine,"Klasifikasi Penyakit Gigi Dan Mulut Menggunakan Metode Support Vector Machine

Ana Mariyam Puspitasari1, Dian Eka Ratnawati2, Agus Wahyu Widodo3 

Abstrak  
Penyakit gigi dan mulut merupakan salah satu penyakit yang berdampak serius bagi kesehatan manusia secara umum, karena gigi dan mulut merupakan tempat masuknya suatu kuman dan bakteri. Penanganan penyakit gigi dan mulut diharuskan untuk segera ditangani lebih cepat dan benar, namun tidak semua  tim ahli gigi dapat dengan cepat melakukan penanganan dikarenakan kurangnya tim ahli gigi yang berada ditempat kerja atau rumah sakit selama 24 jam.  Mengetahui jenis penyakit gigi dan mulut sejak awal sangatlah penting. Oleh karena itu diperlukan adanya sistem yang mempunyai kemampuan untuk mengklasifikasikan jenis penyakit gigi dan mulut guna membantu masyarakat dalam melakukan diagnosa awal terha dap penyakit gigi dan mulut. Dalam penelitian ini sistem klasifikasi yang digunakan yakni menggunakan metode SVM, karena metode SVM dapat mengatasi masalah klasifikasi dan regresi dengan linear maupun non-linear  sehingga dapat menjadi suatu kemampuan algor itma pembelajaran pada klasifikasi ataupun regresi. Pada penelitian ini strategi yang digunakan yakni One-Againts-All dan karena proses yang n antinya akan dilakukan bersifat non-linear sehingga kernel yang digunakan yakni kernel RBF. Hasil klasifikasi yang  diperoleh dengan menggunakan metode SVM mempunyai rata-rata 
nilai akurasi sebesar 94.442% dengan menggunakan dataset sebanyak 122 data dan dengan parameter sequential training SVM nilai ðœ† (lamda) = 0.1, y (gamma) = 0.1, C (Complexity) = 1, ðœ€ (epsilon)  = 1.10-10 dengan itermax = 50 dan rasio data 80%:20%. Dengan pencapaian hasil akurasi yang baik, maka penelitian ini dapat diterapkan untuk membantu melakukan klasifikasi penyakit gigi dan mulut dengan metode support vector machine.  

Kata kunci : Klasifikasi, Support Vector Machine, Radial Basis Function, Penyakit Gigi dan Mulut.  

Abstract  
Oral diseases is one of the most serious diseases thatimpact to human health in general, as the mouth is a place where the germ and bacteria oral diseases should  be handled  immediately  but not all dental expert can quickly  do the handling  due to  the lack of a dental expert that is available in the  hospital  for 24 hours. Knowing the types  oral diseases  since the beginning  is very important.  Therefore , a system that has the ability to classify types of oral diseases will be very helpful  in order to help the community in conducting early diagnosis of oral diseases. This research  used classification system using of SVM method  because SVM method can resol ve the problem of classification and regression with linear or non-linear  kernel with its capability as a learning algorithm on the classification or regression. This research used One-Againts-All strategies for  non-linear  process and used RBF kernel. The results obtained usi ng SVM method has a mean median values of accuracy â€“ 94,442% using the dataset as much as 122 data and with the parameter Î» value SVM training sequential (lamda) = 0.1, y (gamma) = 0.1, C (Complexity) = 1, Îµ (epsilon) = 1.10 -10 with ite rmax = 50 and r atio data 80%: 20%. The results shows good accuracy, and the research can be applied to help perform classification of oral disease using support vector machine method.  

Keywords : Classification, Support Vector Machine, Radial Base Function,  Oral diseases  
 
1. PENDAHULUAN  
Kesehatan gigi dan mulut terkadang memang merupakan prioritas kesekian bagi beberapa orang, padahal sebenarnya penyakit  gigi dan mulut berdampak serius bagi kesehatan secara umum, sebab gigi dan mulut merupakan tempat masuknya kuman dan bakteri sehingga kemungkinan besar dapat mengganggu  kesehatan organ tubuh yang lainnya (Ratih, 2012) . Menurut Riskesdas tahun  2007 dan 2013 persentase penduduk Indonesia yang mengalami masalah pada gigi dan mulut meningkat dari 23.2% menjadi 25.9% dan yang menerima perawatan medis hanya sebesar 31.1%  (Riskesdas, 2013) ..  Beberapa faktor yang menyebabkan timbulnya penyakit gigi dan mulut antara lain yakni mengkonsumsi rokok yang berlebihan dan kurang sehat sehingga membahayakan kesehatan, baik kesehatan gigi dan mulut maupun organ yang lain, pemakaian tembakau dan alkohol yang berlebihan sangat berbahaya, kurangnya menjaga kebersihan  mulut, adanya jamur, adanya bakteri dan virus HIV (Ratih, 2012). Penanganan terhadap penyakit gigi dan mulut diharuskan untuk dilakukan dengan cepat dan benar. Sebab dengan kita mengetahui jenis penyakit gigi dan mulut sejak awal sangatlah Penting, guna melakukan proses penyembuhan dengan lebih cepat dan tepat. Oleh karena itu perlu adanya sistem cerdas yang mampu mengklasifikasikan penyakit gigi dan mulut berdasarkan gejalanya. Dengan adanya sistem cerdas diharapkan dapat membantu pengguna maupun tim medis untuk mengetahui jenis penyakit gigi dan mulut dan dapat menentukan langkah awal untuk menangani penyakit tersebut. Meskipun seorang dokter gigi dan mulut adalah seorang yang ahli dibidangnya, namun terkadang manusia biasan juga mempunyai keterbatasan daya ingat dan stamina kerja. Sehingga yang ditakuti yakni ketika seorang dokter gigi dan mulut mungkin saja melakukan kesalahan pada saat mengambil hasil diagnosa yang dapat berakibat fatal. Beberapa penelitian telah dilakukan dengan memilih metode klasifikasi terbaik, yakni dilakukan oleh Akbar Afizal Laksita  pada tahun 2015 terhadap penyakit stroke dengan menggunakan metode   Support Vector Machine. Penelitian tersebut bertujuan untuk membuat hyperplane yang optimal, sehingga diperoleh hasil  rata-rata akurasi sebesar 0.8939 pada saat panjang fold 5 dengan nilai parameter epsilon 0.001 dan cost 10. Kemudian penelitian yang kedua yakni dilakukan oleh A.Muis, dkk., pada tahun 2015 mengenai klasifikasi tweet  dengan menggunakan kernel Radial Basis Function (RBF). Hasil yang diperoleh pada penelitian tersebut adalah nilai akurasi tertinggi 97.54% untuk data yang belum dilakukan pemilihan fitur, sedangkan yang sudah dilakukan pemilihan fitur mencapai nilai akurasi tertinggi 99.12%. Dari beberapa pen jelasan masalah dan penellitian yang telah dilakukan diatas, penulis ingin melakukan penelitian terhadap penyakit gigi dan mulut dengan menggunakan metode support vector machine. Diharapkan penelitian ini dapat menghasilkan suatu sistem cerdas yang dapat menghasilkan kesimpulan apakan seseorang mempunyai potensi terkena penyakit gigi dan mulut jenis yang mana dengan menggunakan metode support vector machine.  
 
2. GIGI DAN MULUT  
2.1 Rongga Mulut  
Didalam rongga mulut terdapat beberapa bagian seperti gigi, lidah, gusi, bibir dan jaringan lunak lainnya yang mempunyai fungsi masing-masing.  
a. Bibir mempunyai fungsi dapat menjaga makanan dan minuman agar tidak berceceran keluar mulut, membantu kita dalam berbicara, dll.  
b. Gusi mempunyai fungsinya yaitu untuk melindungi serat-serat halus yang mengikat akar gigi kepada tulang rahang (Kesehatan, 2012)   
c. Lidah mempunyai fungsinya yakni sebagai alat indera perasa sehingga dapat merasakan makanan dan minuman.  
d. Gigi memiliki fungsi dari gigi yakni dapat mengunyah makanan, menghancurkan makanan, dll.  
e. Jaringan lunak merupakan jaringan yang meliputi bagian pipi, bibir, langit-langit dan jaringan lunak yang lainnya dibawah lidah  
2.1.2 Gigi 
Bagian dari gigi yakni mahkota gigi dan akar gigi yang mempunyai banyak fungsi. Macam-macam bentuk gigi beserta fungsinya antara lain:  
a. Gigi seri yang berfungsi untuk memotong makanan yang akan masuk ke dalam mulut.  
b. Gigi taring mempunyai fungsi mencabik-cabik makanan sesudah dipotong 
c. Gigi geraham mempunyai fungsi menggiling atau menghaluskan makanan.  
2.2 Penyakit Gigi dan Mulut  
Gigi dan mulut merupakan bagian dari tubuh kita yang sangat vital,  sebab disanalah tempat masuknya makanan yang kita makan dan gigi yang menghancurkan makanan tersebut. Oleh sebab itu kesehatan dan kebersihan gigi dan mulut sangatlah penting. Banyak faktor yang dapat menyebabkan timbulnya penyakit gigi dan mulut, antara lain seperti diet yang tidak sehat, mengkonsumsi minuman alkohol dan merokok yang berbahaya dan berlebihan, dan kebersihan mulut yang tidak terawat, jamur dan bakteri. Beberapa macam penyakit gigi dan mulut yang biasa dijumpai antara lain :  
a. Gingivitis mer upakan penyakit radang gusi yang mengalami pembengkakan pada mulut sebab kurang terjaganya kebersihan 
mulut sehingga menyebabkan adanya karang-karang gigi atau plak yang menumpuk dan berbatasan dengan tepi gusi (Lita, 2016).  
b. Acute Necrotizing Ulcerative Gingingivitis (ANUG) adalah penyakit yang disebabkan oleh adanya infeksi pada nekrosis gingiva. Penyakit ini dapat terjadi pada siapa saja, terutama orang yang mengkonsumsi rokok secara berlebihan, stress berat, dan malnutrisi berat, dll  
c. Karies gigi merupa kan penyakit gigi yang terjadi pada kerusakan jaringan gigi hingga membentuk lubang  
d. Pulpitis merupakan proses radang pada jaringan pulpa gigi yang menetap, gejalanya yakni gigi nyeri ketika mendapat 
rangsangan panas atau dingin  
e. Nekrosis Pulpa adalah penyakit gigi yang disebabkan oleh adanya bakteri, trauma dan iritasi yang menyebabkan kerusakan dan kematian pada pulpa yang disebabkan oleh pulpitis yang tidak dirawat (Yamin, 2012)  
f. Periodontitis merupakan inflamasi jaringan dan infeksi yang terjadi pada gingiva (gingivitis) yang tidak dirawat dan menyebar ke ligamen dan tulang alveolar penyangga gigi.  
g. Herpes Simpleks adalah infeksi virus HIV yang terjadi pada sudut bibir atau mulut. Gejala yang ditimbulkan antara lain sensitive, terbakar pada daerah bibir atau perbatasan kulit bibir  
h. Glositis merupakan penyakit radang pada lidah dimana keadaannya di dalam mulut biasanya ditunjukkan dengan adanya pembengkakan di lidah, jika kasusnya lebih parah mampu memicu penyumbatan pernafasan pada saat lidah membengkak yang sangat parah (Lita, 2016).  
i. Impaksi gigi adalah kerusakan erupsi pada gigi yang disebabkan adanya malposisi, kekuranan tempat atau terhalangi gigi yang lain. Hal itu disebabkan oleh adnaya gusi bengkak, demam, dan gigi yang tumbuh tidak sempurna  
2.3 Klasifikasi  
Klasifikasi merupakan suatu proses yang bertujuan untuk menentukan suatu obyek kedalam suatu kelas atau kategori yang sudah ditentukan sebelumnya. Menurut (Elly Susilowati, 2015)  klasifikasi adalah proses dari pembangunan terhadap suatu model yang mengklasifikan suatu objek sesuai dengan 
atribut-atributnya. Klasifikasi data ataupun dokumen juga dapat dimulai dari membangun aturan klasifikasi tertentu yang menggunakan data training yang sering disebut sebagai tahapan pembelajaran dan pengujian digunakan sebagai data testing. (Winarko2, Oktober 2014) . Beberapa tugas dari klasifikasi yang melibatkan proses pembangunan terhadap model yang dibentuk untuk melakukan prediksi target atau variabel dari data set yang sudah jelas, ataupun variabel independen. Klasifikasi juga dapat dilakukan dengan menggunakan beberapa metode atau berbagai jenis pengklasifikasian. Beberapa metode yang sering digunakan pada klasifikasi yakni decision-tree, rule based, ANN, 
nearest-neighbor, dan naive Bayesian (Weiss, 2010) . 
2.4 Support Vector Machine  
Pengertian Support Vector Machine (SVM) yaitu sistem pembelajaran yang menggunakan ruang hipotesis berupa fungsi-fungsi linier dalam sebuah fitur yang berdimensi tinggi dan 
dilatih dengan menggunakan algoritma pembelajaran yang didasarkan pada teori optimasi. SVM pertama kali diperkanalkan pada tahun 1992 oleh Vapnik sebagai rangkaian dari beberapa konsep-konsep unggulan dalam bidang pattern recognition (Elly Susilowati, 2015)  Tingkat akurasi pada model yang akan dihasilkan oleh proses peralihan dengan SVM 
sangat bergantung terhadap fungsi kernel dan parameter yang digunakan (Siagian, 2011)  Berdasarkan dari karakteristiknya, metode SVM dibagi menjadi  dua, yaitu SVM Linier dan SVM Non-Linier. SVM linier merupakan data yang dipisahkan secara linier, yaitu memisahkan kedua class pada hyperplane dengan soft margin. Sedangakan SVM Non-Linier yaitu menerapkan fungsi dari kernel trick terhadap ruang yang berdimensi tinggi (F, 2012)   
2.5 Kernel Trick  
Pada umumnya untuk masalah yang ada dalam domain dunia nyata, kebanyakan bersifat non liniar. Algoritma Support Vector Machine (SVM) dimodifikasi dengan cara memasukkan 
fungsi kernel kedalam non liniar SVM, dengan cara yang pertama yaitu data x i  dipetakan ke dalam fungsi Î¦ (ð‘¥) ke ruang vector yang memiliki ukuran dimensi tinggi. Notasi matematika dari mapping akan ditunjukkan seperti pada rumus berikut  (Nugroho, 2003)  
Î¦âˆ¶ â„œd ïƒ  â„œq   d < q    (1) 
Dikarenakan transformasi Î¦ pada umumnya tidak diketahui, oleh karena itu fungsi dari Kernel Trick dapat digantikan sesuai rumus berikut  (Nugroho, 2003) :  
ðœ…(ð‘¥Òƒi , xÒƒj ) = Î¦ (ð‘¥Òƒi). Î¦ (xÒƒj)  (2) 
Fungsi dari nilai Î¦ (ð‘¥Òƒi) pada dot product  dengan 
menggunakan dua vector yang menunjukkan feature dari atribut sehingga dapat di hitung dengan baik pada feature space. Selanjutnya  feature  space akan dibuat  sebuah fungsi linear yang mewakili fungsi dari non-linear pada input 
space. Di  dalam input space  tidak bisa dipisahkan secara linear, namun input space  bisa dipisahkan di feature space dan dapat membantu proses klasifikasi menjadi lebih mudah. Untuk mendapatkan solusi pada fungsi klasifikasi dari data (x), didapatkan rumus  berikut  (Nugroho, 2003) :   
f ( x ) = âˆ‘ ð‘Žð‘›
ð‘–=1,ð‘¥Òƒ,ð‘’ð‘†ð‘‰ i yi  ðœ… (xÒƒ, xÒƒi) + b (3) 
dimana  
wÒƒ = âˆ‘ ð‘Žð‘›
ð‘–=1,ð‘¥Òƒ,ð‘’ð‘†ð‘‰ i yi  Î¦( xÒƒ ) . Î¦( xÒƒi ) 
= âˆ‘ ð‘Žð‘›
ð‘–=1,ð‘¥Òƒ,ð‘’ð‘†ð‘‰ i yi  ðœ… (xÒƒ, xÒƒi)  (4) 
Maksud dari persamaan diatas yakni dengan subset dari data training dot yang terpilih sebagai support vector, dengan kata lain data () yang berkorespondensi terhadap Î±  â‰¥ 0. Jenis kernel yang umum digunakan seperti yang terlihat pada 
Tabel 1  :   
Tabel 1 Kernel yang sering digunakan  Jenis Kernel  Definisi  
Polynomial  ðœ… (xÒƒi, xÒƒj) = (xÒƒi, xÒƒj  + 1)p 
RBF  ðœ… (xÒƒi, xÒƒj) = exp ( - âˆ¥ð‘¥Òƒð‘– âˆ’ ð‘¥Òƒð‘—âˆ¥
2ðœŽ) 
Sigmoid  ðœ… (xÒƒi, xÒƒj) = tanh ( Î± xÒƒi, xÒƒj + 
ð›½) 
Penggunaan kernel dapat dilakukan dalam percobaan untuk menentukan parameter kernel dan menghasilkan keakuratan yang terbaik dalam proses klasifikasi. Kernel linear digunakan pada saat data yang diklasifikasikan dapat dengan mudah dipisahkan dengan sebuah garis atau hyperplane, sementara untuk kernel non-linear digunakan pada saat data yang digunakan dipisah dengan menggunakan garis lengkung atau sebuah bidang pada ruang yang mempunyai dimensi tinggi. Dalam penelitian ini kernel yang digunakan yakni kernel RBF, 
dimana kernel RBF merupakan kernel yang mempunyai performansi yang baik pada parameter tertentu dengan kesalahan pelatihan yang minimum . 
2.6 Sequential Training  
Salah satu Hyperplane yang optimal terletak didalam SVM yang dapat ditemukan dengan merumu skan ke dalam Quadratic Programming (QP) problem yang nantinya akan diselesaikan dengan analisa numerik. Alternatif lain yang cukup simple dan sederhana yakni Sequential Training  seperti halnya yang telah dikembangkan oleh (Vijayakumar S, 1999)  sebagai berikut : 
a. Inisialisasi Î± 1 = 0  setelah itu hitung matrik Hessian. Matrik Hessian adalah perkalian antara kernel gaussian dengan nilai Y. Nilai Y disini yaitu nilai berupa vector yang berisi nilai 1 dan -1. Î± 1 digunakan untuk mencari nilai support vector. Untuk setiap data dari i sampai j, hitung menggunakan rumus Matrik Hessian yang ditunjukkan 
seperti berikut :  
D ij  = y i yj ( K (x i , xj ) + â„·2)  (5) 
b. Kemud ian melakukan rumus dibawah ini : 
Ei  = âˆ‘ ð’‚ð’Š
ð’‹=ðŸ j Dij    (6) 
ð›¿Î±i = min {max[ y (1 â€“ Ei ) -  Î±i ]  
 C - Î±i }    (7) 
Î±i = Î±i + ð›¿Î±i     (8) 
Keterangan : 
Î±i = alfa ke -i 
Dij = matriks Hessian  
Ei = error rate  
C = konstanta C  
ð›¿Î±i = delta alfa ke -i 
Setelah itu kembali ke langkah 2 sampai nilai Î± i mencapai konvergen. Konvergensi didapatkan dari tingkat perubahan pada nilai Î± i. 
2.7. One Againts All  
Strategi dari menggunakan metode One-Againts-All ini yaitu membangun sejumlah nilai k kedalam model SVM biner( k merupakan jumlah kelas). Dari setiap klasifikasi ke -i dilatih dengan menggunakan data secara keseluruhan. Misal, terdapat sebuah permasalahan klasifikasi dnegan 4 buah kelas yang digunakan pada pelatihan hanya 4 buah SVM biner : (Sembiring, September 2007)  seperti yang ditunjukkan pada 
tabel berikut :  
Tabel 2 Contoh 4 SVM dengan metode One-Againts-All  
Yi = 1 Yi = -1 Hipotesis  
Kelas 1  Bukan kelas 
1 f 1 (x) = (w1) x + 
b1 
Kelas 2  Bukan kelas 
2 f 2 (x) = (w2) x + 
b2 
Kelas 3  Bukan kelas 
3 f 3 (x) = (w3) x + 
b3 
Kelas 4  Bukan kelas 
4 f 4 (x) = (w4) x + 
b4 
2.8 Kelebihan dan Kekurangan SVM  
Beberapa kelebihan yang ada pada SVM antara lain : 
a. Generalisasi yang artinya mempunyai kemampuan suatu metode (SVM,  neural network, dsb) untuk melakukan klasifikasi suatu pattern, dimana tidak termasuk data  yang dipakai dalam fase  pembelajaran metode tersebut.  
b. Curse of dimensionality yakni suatu masalah yang biasa dihadapi suatu metode pattern recognition dalam melakukan estimasi parameter . Dikarenakan jumlah sampel data yang relatif sedikit jika dibandingkan dengan dimensional ruang vector data, sehingga semakin tinggi dimensi ruang vector yang diolah, maka akan menimbulkan konsekuensi yang membutuhkan jumlah data dalam berdimensi tinggi juga. 
c. Feasibility. Metode SVM dengan mudah dapat diimplementasikan karena proses dalam menentukan support vector dapat dirumuskan dalam QP problem.   
Beberapa kelemahan pada SVM an tara lain :  
a. Sulit digunakan pada problem yang mempunyai ukuran besar. Dimaksudkan ukuran besar dengan jumlah sample yang diolah  
b. Metode SVM secara teoritik dikembangkan dengan fungsi untuk problem klasifikasi yang menggunakan dua class.  

3. PERANCANGAN DAN IMPLEMENTASI  
Proses algoritma SVM yang harus dilakukan pertama kali yaitu mengambil dataset. Kemudian dilanjutkan dengan proses perhitungan kernel SVM, proses training SVM,  proses testing SVM, dan yang terakhir yaitu tahap evaluasi klasifikasi. Gambar 1 dipaparkan alur proses algoritma Support Vector Machine. 
Gambar 1 . Alur Proses Algoritma Support Vector Machine  
Berdasarkan Gambar 1  proses algoritma support vector machine  tahapan pertama yakni menginpu tkan data training format .xls. Data training di bag i secara acak dari setiap kelas sehingga minimal terdapat 3 data yang mewakili data training dan data testing dari setiap kelas. Setelah menginputkan data set, langkah selanjutnya  yakni melakukan perhitungan kernel. Disini kernel yang digunakan yaitu kernel RBF.  Setelah mela kukan proses perhitungan kernel, langkah selanjutnya yaitu melakukan perhitungan data training dengan menggunakan Sequential Training SVM . Setelah melakukan tahapan perhitungan sequential training SVM, langkah selanjutnya yaitu melakukan perhitungan testing SVM, dan akan meng hasilkan keluaran berupa hasil klasifikasi. 

4. PENGUJIAN DAN ANALISIS  
Pada penelitian ini dilakukan pengujian terhadap rasio data, pengujian terhadap kernel, pengujian parameter lamda,  pengujian parameter gamma,  pengujian parameter complexity, dan pengujian terhadap jumlah iterasi.   
4.1 Pengujian Rasio Data  
Pada pengujian pertama digunakan untuk mengetahui perbandingkan tingkat akurasi dari dataset yang digunakan. Dataset yang akan digunakan baik data training maupun data testing yang berjumlah sebanyak 122 dan akan dibagi sesuai dengan perbandingan rasio yang telah ditentukan guna untuk melihat hasil akurasi terbaik. Perbandingan rasio yang akan digunakan yaitu rasio 90%:10%,  80%:20%, 70%:30%, 60%:40%, 50%:50%, 40%:60%, 30%:70%, 20%:80%, 10%:90%. Pengujian juga 
dilakukan dengan menggunakan kernel RBF dan nilai parameter pada sequential training yang digunakan dalam pengujian ini yaitu nilai ðœ†=0.5 y =  0.01 C = 1 ðœ€ = 1.10-10 iterasi = 50 
Gambar_2.
Grafik  2. Hasil Pengujian Rasio Data 
Berdasarkan Grafik 2 diperoleh nilai akurasi yang terbaik terdapat pada rasio data 80%:20% dengan nilai akurasi sebesar 93.328%. Data training dan data testing yang digunakan dipilih secara acak dari setiap kelas, sehingga minimal terdapat tiga data yang mewakili data training dan data latih dari setiap kelas untuk data uji yang digunakan.  Sehingga dapat disimpulkan bahwa secara keseluruhan algoritma support vector machine menghasilkan nilai tingkat akurasi yang lebih tinggi dan lebih konsisten. Hal ini disebabkan oleh komposisi data yang digunakan pada data training maupun data testing tidak jauh berbeda.  
4.2 Pengujian Kernel  
Pengujian terhadap jenis kernel yang digunakan, dimana pengujian tersebut dilakukan guna untuk mengetahui jenis kernal yang mana yang memperoleh hasil terbaik. Nilai parameter yang digunakan pada sequential training SVM pada pengujian ini adalah nilai ðœ†=0.5 y =  0.01 
C = 1 ðœ€ = 1.10-10 iterasi = 50 dengan rasio data 
80%:20%.   
Grafik 3. Hasil Pengujian  Kernel  
Berdasarkan Grafik 3 diperoleh nilai akurasi yang paling optimal terdapat pada kernel RBF dengan nilai akurasi sebesar 93.328. Hal ini dapat disimpulkan bahwa kernel RBF lebih cocok digunakan pada data seperti jenis penelitian ini dibandingkan dengan jenis kernel yang lainnya seperti kernel polynimial degree, polynomial degree 2, dan kernel li near. 
4.3 Pengujian ð€ (lamda)  
Pengujian parameter lamda dilakukan guna untuk mengetahui skenario mana yang memperoleh hasil terbaik untuk nilai parameter lamda yakni 0.1, 0.5, 1, 10, 50, 200, 500, 1000. Nilai parameter yang digunakan pada sequential training  SVM pada pengujian ini adalah nilai y =  0.01 C = 1 ðœ€ = 1.10-10 iterasi = 50 dengan rasio data 80%:20%. 
87,1 93,375,4 83,6 84,2 88 83,176,468,2020406080100
90% :
10%80% :
20%70% :
30%60% :
40%50% :
50%40% :
60%30% :
70%20% :
80%10% :
90%Akurasi (%)
Rasio DataPengujian Rasio Data
Rata Rata Akurasi
56.66 32.216.566.693.328050100
Polynomial Polynomial degree Linear RBF Akurasi (%) Pengujian Kernel Rata Rata Akurasi   
Grafik  4. Hasil Pengujian  Parameter Lamda  
Berdasarkan Grafik 4 diketahui bahwa nilai rata-rata tingkat akurasi yang paling tinggi sebesar 93.33 yaitu terdapat pada nilai lamda  0.1 dan 0.5. Disini dapat disimpulkan bahwa semakin besar nilai  lamda  tidak juga membuat nilai akurasi menjadi baik, karena apabila semakin besar nilai lamda  akan membuat proses  komputasi pada tahap perhitungan matriks hessian semakin lama. Hal ini disebabkan oleh adanya augmented factor (lamda) yang menjadikan sistem menjadi sangat lambat dalam mencapai nilai konvergen sehingga dapat menimbulkan ketidakstabil an dalam proses pembelajaran yang dilakukan.   
4.4 Pengujian y (Gamma)  
Pengujian terhadap parameter sequential training SVM yaitu parameter  ð‘¦ (gamma). Pengujian tersebut dilakukan guna untuk mengetahui skenario mana yang memperoleh hasil terbaik untuk nilai parameter gamma yakni 0.001, 0.01, 0.1, 0.5, 1, 5, 10, 50. Nilai parameter yang digunakan pada sequential training SVM pada pengujian ini adalah ni lai ðœ† =  0.1  C = 1  ðœ€ = 1.10-10  iterasi = 50 dengan rasio data 80%:20%.   
Grafik 5. Hasil Pengujian Parameter Gamma   
Berdasarkan G rafik 5 diketahui bahwa rata-rata nilai tingkat akurasi yang paling tinggi sebesar 94.442 yaitu terdapat pada nilai gamma  0.1 sedangkan untuk nilai akurasi terbaik sebesar 100 pada nilai gamma 0.01, 0.1, 0.5, dan 1. Pada pengujian parameter gamma  = 0.001 mendapatkan hasil dengan nilai rata-rata akurasi yang sangat kecil, hal ini disebabkan nilai yang diperoleh dari perhitungan kernel RBF sangat besar sehingga menyebabkan algoritma menjadi sulit dalam mendapatkan kekonsistenan dari hyperplane  
4.5 Pengujian C (Complexity)  
Pengujian terhadap parameter sequential training SVM yaitu parameter  ð¶ (Complexity). Pengujian tersebut dilakukan guna untuk mengetahui skenario mana yang memperoleh hasil terbaik untuk nilai parameter complexity yakni 0.01, 0.1, 1, 10, 30, 50, 70, 100. Nilai parameter yang digunakan pada sequential training SVM pada pengujian ini adala h nilai ðœ† =  0.1  y = 0.1   ðœ€ = 1.10-10  iterasi = 50 dengan 
rasio data 80%:20%  
Grafik 6.  Hasil Pengujian Parameter Complexity   
Berdasarkan Grafik 6 pada Gambar 6 diketahui bahwa nilai rata-rata tingkat akurasi yang paling tinggi yaitu sebesar 94.442. Pengujian ini digunakan dengan tujuan untuk meminimalkan nilai error  dan memperkecil nilai slock variabel, hal itu relatif penting diperlukan untuk memaksimalkan margin dan meminimalkan jumlah slock. Apabila nilai C mendekati angka 0 maka lebar margin yang terdapat pada bidang pemisah (hyperplane) menjadi maksimal, sehingga nilai C dapat digunakan untuk memperkecil nilai error pada proses training saat perhitungan nilai w (weight) dan nilai bias.  
4.6 Pengujian Jumlah Iterasi  
Pengujian terhadap jumlah iterasi. 
Pengujian tersebut dilakukan guna untuk 93,3 93,3 89,9 87,7 87,7 87,7 87,7 87,7020406080100 Akurasi (%)
Nilai Lamda Pengujian Parameter Lamda Rata Rata Akurasi
61,193,3 94,488,882,269,9 72,2 72,2020406080100
0.001 [0.01] [0.1] [0.5] 1 5 10 50 Akurasi (%) Nilai Gamma Pengujian Parameter Gamma Rata Rata Akurasi
92,282,294,4
69,963,357,7 57,7 56,6
020406080100
[0.01] [0.1] [1] [10] [30] [50] [70] [100] Akurasi (%)
Nilai Complexity Pengujian Parameter Complexity Rata Rata Akurasi mengetahui skenario mana yang memperoleh hasil terbaik. Nilai parameter yang digunakan pada sequential training SVM pada pengujian ini adalah nilai ðœ† =  0.1  C = 1  y = 0.1    ðœ€ = 1.10-10  iterasi = 50 dengan rasio data 80%:20% . 
Grafik 7.  Hasil Pengujian Jumlah Iterasi   
Berdasarkan Grafik 7 diketahui bahwa nilai rata-rata tingkat akurasi tinggi yaitu sebesar 94.442. Pada pengujian ini dengan data yang digunakan dapat disimpulkan bahwa terjadinya konvergen mulai pada iterasi ke 5. Hal itu dikarenakan saat jumlah iterasi bertambah terjadi, rasio support vector berjalan seimbang dan beberapa data tidak terletak jauh berbeda dari bidang pemisah (hyperpelane). Namun pada pengujian ini nilai iterasi maksimum sangat berpengaruh terhadap perubahan nilai pada nilai ð›¼ (alpha) karena diperlukan untuk mendapatkan nilai ð›¼i yang konvergen.  

5. KESIMPULAN  
Berdasarkan hasil penelitian mengenai klasifikasi penyakit gigi dan mulut dengan menggunakan metode support vector machine dapat disimpulkan bahwa : 
1. Metode Support Vector Machine dapat diterapkan pada permasalahan klasifikasi penyakit gigi dan mulut dengan hasil terbaik dan memberikan hasil akurasi sebesar rata rata 94.442% dengan nilai parameter pada sequential training SVM yaitu ðœ† (lamda) = 0.1, y (gamma) = 0.1, C (Complexity) = 1, ðœ€ (epsilon) = 1.10-10 dengan itermax = 50 dan rasio data 80%:20% dengan memperoleh hasil pengujian yang mulai konvergen pada jumlah iterasi ke 5.  
2. Proses klasifikasi penyakit gigi dan mulut ini menggunakan dataset  yang masih terbatas yakni sebesar 122  data untuk semua kelas sehingga terdapat sekitar 30 data untuk setiap kelas dengan jumlah parameter sebanyak 16. Pada penelitian ini menggunakan empat kelas yaitu kelas pulpitis, gingivitis, nekrosis pulpa dan periodontitis.  
3. Pada pengujian kernel hasil yang paling optimal terdapat pada kernel RBF dengan nilai akurasi rata-rata sebesar 93.329%. Dapat disimpulkan bahwa kernel RBF lebih cocok pada data jenis penelitian ini sebab kernel RBF mampu memprediksi kelas pada data itu sendiri, yang artinya mampu mengklasifikasikan tepat sesuai dengan kelas aslinya, dan lebih mempunyai performa lebih baik jika dibandingkan dengan kernel linear atau polynomial. Hal ini disebabkan karena data yang ada pada penelitian ini memiliki pola yang cenderung tetap, sedangkan ke rnel polynomial lebih cenderung pada data yang mempunyai sebaran data yang cenderung tidak tetap atau pola yang naik turun.  

6.  DAFTAR PUSTAKA   
Elly, S., Mira, K. S. & Alfian, A. G., 2015. Implementasi Metode Support Vector Machine untuk Melakukan Klasifikasi Kemacetan Lalu Lintas Pada Twitter. Makassar, S1 Universitas Telkom.  
F, R., 2012. Perbandingan Klasifikais Tingkat Keganasan Breast Cancer dengan Menggunakan Regresi Logistik Ordinal dan Support Vector Machine. s.l., s.n.  
Imelda, A. M. & Muhammad, A. M., Juni 2015. Penerapan Metode Support Vector Machine (SVM) Menggunakan Kernel Radial Basis Function (RBF) Pada Klasifikasi Tweet. Jurnal Sains, Teknologi dan Industri, Vol. 12, No. 2(ISSN 1693 -2390), p. pp.189 â€“ 197. 
Kesehatan, K., 2012. Buku Panduan Pelatihan Kader Kesehatan Gigi dan Mulut di Masyarakat. Republik Indonesia, s.n.  Laksita, A. A., (2015). Implementasi Algoritma SVM (Support Vector Machine) untuk Mengetahui Tingkat Resiko Penyakit Stroke. Malang, S1 Universitas Brawijaya.  
Lita, 2016. Penyakit Gigi dan Mulut. [Online]  Available at: http://halosehat.com/penyakit/penyakit-gigi-dan-mulut/jenis-jenis-penyakit-gigi-dan-mulut) [Diakses 9 april 2017].  88,894,4 94,4 94,4 94,4 94,4 94,4 94,4020406080100
[2] [5] [10] [50] [75] [100] [200] [500]Akurasi (%)
Jumlah IterasiPengujian Jumlah Iterasi Rata Rata Akurasi  
Fakultas Ilmu Komputer, Universitas Brawijaya  Nugroho, A., Witarto, A. & Handoko, D., 2003. Support Vector Machine -Teori dan Aplikasinya. s.l., s.n.  
Ratih, L., 2012. Hubungan Kebersihan Mulut dengan Penyakit Sistemik dan Usia Harapan. [Online]  Available at: http://poltekkes -denpasar.ac.id/files/JSH/V9N1/Ratih%20Larasati1%20JSH%20V9N1.pdf.  [Diakses 12 April 2017].  Riskesdas, 2013. Situasi Kesehatan Gigi dan Mulut. [Online]  
Available at: http://www.depkes.go.id/resources/download/pusdatin/infodatin/infodatin -gilut.pdf.  [Diakses 6 mei 2017].  
Sembiring, K., September 2007. Penerapan Teknik Support Vector Machine untuk Pendeteksian Intrusi pada Jaringan. Bogor, S1 Teknik Informatika, Sekalah Teknik Elektro dan Informatika, ITB.  
Siagian, R. Y., 2011. Klasifikasi Parket Kayu Jati Menggunakan Metode Support Vector Machine (SVM). Jawa Barat, Skripsi, Jurusan Teknik Informatika, Fakultas Teknologi Industri, Universitas .  
Vijaya kumar S, W. S., 1999. Sequential Support Vector Classifiers and Regression. Proc. International Conference on Soft Computing, Issue (SOCO'99),Genoa, Italy,, pp. pp.610-619,.  
Weiss, G. & Davidson, B., 2010. Data Mining. [Online]  
Available at: strorm.cis.fo rdham.edu/gweiss/publications.html  [Diakses 16 maret 2017].  
Winarko2 & Suwanto, R. E., Oktober 2014. 
Klasterisasi, Klasifikasi dan Peringkasan Teks Berbahasa Indonesia. Prosiding Seminar Ilmiah Nasional Komputer dan Sistem Intelijen (KOMMIT 2014), Vol. 8(ISSN : 2302-3740).  
Yamin, F. I., 2012. Tinjauan Pustaka Bab 2, Pulpitis. [Online]  Available at: http://repository.unhas.ac.id/bitstream/handle/123456789/2709/8.%20BAB%20II%20Tinjauan%20Pustaka.docx?sequence=8).  
[Diakses 10 april 2017].",klasifikasi,"Support Vector Machine, SVM",penyakit gigi dan mulut,akurasi
Klasifikasi Daun Dengan Perbaikan Fitur Citra Menggunakan Metode K-Nearest Neighbor,"Klasifikasi Daun Dengan Perbaikan Fitur Citra Menggunakan Metode K-Nearest Neighbor

Febri Liantoni

Abstract
Plants are the most important part in life on earth as oxygen supplier to breathe, groceries, fuel, medicine and more. Plants can be classified based on its leaves shape. Classification process is required well data extraction feature, so it needs fixing feature process at pre-processing level. Combining median filter and image erosion is used for fixing feature process. Whereas for feature extraction is used invariant moment method. In this research, it is used leaves classification based on leaves edge shape. K-Nearest Neighbor Method (KNN) is used for leaves classification process. KNN method is chosen because this method is known rapid in training data, effective for large training data, simple and easy to learn. Testing the result of leaves classification from image which is on dataset has been built to get accuracy value about 86,67%. 

Index Terms Classification, Median Filter, Invariant Moment,  K-Nearest Neighbor.

I. Pendahuluan
Ilmu tentang tumbuhan mengalami kemajuan yang pesat, bidang pengetahuan yang sebelumnya hanya merupakan cabang ilmu tumbuhan saja, sekarang telah menjadi bidang ilmu yang berdiri sendiri. Salah satunya adalah Morfologi Tumbuhan yang mempelajari bentuk dan susunan tubuh tumbuhan. Bentuk tepi daun bias digunakan untuk acuan klasifikasi daun. Tumbuhan berguna sebagai penyedia oksigen untuk bernafas, sebagai bahan makanan, bahan bakar, obat-obatan, kosmetik dan lebih banyak lagi. Proses klasifikasi tumbuhan dapat dilakukan dengan cara mengidentifikasi citra bentuk daun dari  tumbuhan itu sendiri. Cara pengambilan gambar daun dari tumbuhan tersebut, maka dapat dilakukan langkah-langkah pengenalan pola daun dengan cara mengenali karakteristik struktural daun seperti bentuk dan tekstur daun tersebut. [1], [2].Proses klasifikasi tumbuhan dapat dilakukan dengan cara mengidentifikasi gambar bentuk daun dari tumbuhan. Dengan cara tersebut maka dapat dilakukan langkah-langkah pengenalan pola daun dengan mengenali karakteristik struktural daun seperti bentuk dan tekstur sebuah daun. Metode untuk melakukan pemrosesan terhadap citra masukan dengan pemanfaatan teknik pengolahan citra digital dilakukan untuk menganalisa karakteristik struktural daun. Perkembangan teknologi untuk teknik pengolahan citra juga berkembang pesat. Berbagai teknik dikembangkan untuk mempermudah pekerjaan manusia, baik sebagai pengolah citra, analis citra maupun penggguna citra untuk berbagai tujuan dan keperluan. Seringkali citra yang digunakan tidak dalam kondisi yang ideal untuk dikaji dikarenakan banyaknya gangguan, dapat berupa bayangan, foto atau gambar kabur, kurang jelasnya kenampakan obyek sehingga dapat menimbulkan masalah dan mempengaruhi hasil interpelasi serta akan mempengaruhi analisa dan perencanaan yang akan dilakukan, maka diperlukan berbagai teknik pengolahan citra untuk memperoleh citra yang ideal. Teknik pengolahan citra digital ini dilakukan pada tahapan praproses citra sampai didapatkan bentuk tepian dan ciri struktural dari masing-masing daun. Metode yang digunakan pada ekstraksi  fitur ini adalah pengenalan fitur  morfologi digital [3] yang digunakan menggunakan metode Moment Invariant . Setelah itu dilakukan ekstraksi fitur dari citra daun tersebut sehingga didapatkan informasi struktural daun yang kemudian digunakan sebagai data pengelompokkan. Sistem pengenalan dan pengklasifikasian daun tumbuhan yang otomatis sangat berguna karena dapat mendukung pengklasifikasian tumbuhan dengan cepat. Daun merupakan salah satu ciri tumbuhan yang unik dan mudah diamati dan cukup representatif sehingga bisa dijadikan obyek untuk ekstraksi fitur tumbuhan. Ekstraksi fitur obyek yang tepat sangat mempengaruhi baik buruknya hasil klasifikasi tumbuhan. Beberapa penelitian tentang pengelompokkan bentuk tumbuhan, umumnya menggunakan metode jaringan saraf  tiruan seperti yang dilakukan Stephen dkk tahun 2011, Kadir dkk tahun 2011, Husin dkk tahun 2012, Chaki dkk tahun 2011 [1],[2],[3],[4]. Metode jaringan saraf tiruan banyak digunakan karena metode ini dikenal lebih cepat secara substansial. Akan tetapi penentuan jumlah hidden layer yang digunakan berpengaruh pada hasil, serta dibutuhkan parameter jumlah epoch yang besar sehingga membutuhkan komputasi yang lebih tinggi. Pada tahun 2012, Arunpriya melakukan penelitian pengenalan tumbuhan menggunakan algoritma Support Vector Machine (SVM) [5]. Metode SVM yang bersifat linear classifier  dan secara teoritik hanya dikembangkan untuk permasalah dua kelas[6]. Pada penelitian ini klasifikasi akan dilakukan untuk citra daun dengan metode K-Nearest Neighbor (KNN). Proses klasifikasi berdasarkan fitur bentuk tepi daun. Metode KNN melakukan klasifikasi terhadap objek berdasarkan data pembelajaran yang objek terdekat. Sebelum tahapan klasifikasi terlebih dahulu dilakukan tahapan praproses citra dan ektraksi fitur citra tepi daun agar didapatkan nilai masukan yang tepat untuk tahapan klasifikasi spesies daun berdasarkan citra daun. 

II. Metode
A. Ekstraksi Fitur Invariant Moment
Ekstraksi fitur yang digunakan adalah moment invariant. Proses ini dilakukan untuk menghasilkan nilai-nilai fitur berupa vektor dari citra biner. Fitur yang digunakan yaitu seven moment invariant yang akan menghasilkan tujuh nilai pada vektor fitur. Proses pengenalan sebuah obyek di dalam 
sebuah citra setelah proses segmentasi, sering terbentur pada permasalahan posisi obyek, rotasi sumbu obyek, dan perubahan skala dari obyek. Posisi obyek yang bergeser atau berputar maupun ukurannya yang lebih kecil atau lebih besar daripada dapat menyebabkan kesalahan dalam pengenalan atau identifikasi obyek.Pada penggunaan perhitungan nilai 2 (dua) 
dimensi momen sample gambar  M x M  dari fungsi kontinu  f(x,y),(x,y=0,...M-1) didapatkan Persamaan 1. Momen dapat menggambarkan suatu obyek dalam hal area, posisi, orientasi  dan  parameter terdefinisi lainnya. Dengan mendapatkan sejumlah informasi momen, baik momen tingkat ke nol (m00) dan ke satu (m10 ) dan (m01)  atau  momen  sentral,  dan  momen  pada tingkat â‰¥ 2 atau moment invariant dari sebuah obyek, maka obyek tersebut dapat didentifikasi sekalipun telah  mengami pergeseran (translasi), perputaran (rotasi) maupun perubahan skala. Dari moment f(x,y) akan ditranslasikan dengan nilai (a,b) sehingga didapatkan perhitungan baru seperti Persamaan 2. Dari central moment utama yaitu m_pq atau Î¼_pq dikomputasi melalui proses subtitusi terhadap nilai a = -x dan nilai b=-y maka akan didapatkan perhitungan pada Persamaan 3. Ketika proses normalisasi maka nilai penskalaan yang digunakan dalam perhitungan berubah, ditunjukkan pada Persamaan 4. Kemudian dari proses tersebut maka didapatkan nilai seven moment invariant  dengan perhitungan pada Persamaan 5.
B. K-Nearest Neighbor (KNN)
Algoritma K-Nearest Neighbor (KNN) adalah sebuah metode untuk melakukan klasifikasi terhadap objek berdasarkan data pembelajaran yang jaraknya paling dekat dengan objek tersebut. Data pembelajaran diproyeksikan ke ruang berdimensi banyak, dimana masing-masing dimensi merepresentasikan fitur dari data. Algoritma KNN termasuk metode yang menggunakan algoritma supervised  [7][8][9]. Perbedaan antara supervised learning dengan unsupervised learning adalah pada supervised learning  bertujuan untuk menemukan pola baru dalam data dengan menghubungkan pola data yang sudah ada dengan data yang baru. Sedangkan pada unsupervised learning, data belum memiliki pola apapun, dan tujuan unsupervised learning untuk menemukan pola dalam sebuah data [7][8][9].. Tujuan dari algoritma KNN adalah untuk mengklasifikasi objek baru berdasarkan atribut dan training samples [8][9].. Dimana hasil dari sampel uji yang baru diklasifikasikan berdasarkan mayoritas dari kategori pada  KNN. Pada proses pengklasifikasian, algoritma ini tidak menggunakan model apapun untuk dicocokkan dan hanya berdasarkan pada memori. Algoritma KNN menggunakan klasifikasi ketetanggaan sebagai nilai prediksi dari contoh data uji yang baru [7][8][9]. Jarak yang digunakan adalah jarak Euclidean Distance . Jarak Euclidean adalah jarak yang paling umum digunakan pada data numeric. Algoritma KNN merupakan algoritma yang menentukan nilai jarak pada pengujian data testing  dengan data training berdasarkan  nilai terkecil dari nilai ketetanggaan terdekat [10]. 

III. Perancangan sistem
Pada penelitian ini data yang digunakan berupa gambar daun dengan latar belakang berwarna putih. Dataset yang digunakan yaitu berupa citra daun hijau yang terdiri atas 5 jenis (5 kelas). Data citra yang digunakan sebanyak 50 foto citra. Sistem klasifikasi citra daun menggunakan metode K-Nearest Neighbor  terdiri dari beberapa proses meliputi praproses, ekstraksi fitur dan tahap klasifikasi. Contoh data yang digunakan seperti ditunjukkan pada Gambar 1. 
Gambar 1. Contoh data daunISSN 2085-4552
A. Praproses
Praproses dilakukan dengan tujuan untuk mengolah data masukan sehingga dapat digunakan untuk proses ekstraksi fitur. Terdapat beberapa langkah yang dilakukan untuk praproses yaitu pengubahan citra pada ruang warna RGB ke ruang warna grayscale, melukakan median filter, pembuatan citra biner, dan melakukan perbaikan beberapa piksel gambar dengan metode erosi citra. Dari tahapan praproses akan didapatkan citra biner yang akan digunakan pada ekstraksi fitur. Tahapan yang dilakukan pada praproses ditunjukkan pada Gambar 2.
Gambar 2. Tahapan praproses
Tahap awal praprose dengan mengubah citra ke dalam grayscale. Pemrosesan ini dilakukan untuk mengubah domain piksel citra menjadi 8 bit skala abu-abu. Untuk konversi tersebut digunakan seperti ditunjukkan pada Persamaan 6.
B. Klasifikasi K-Nearest Neighbor (KNN).
Pada penelitian ini digunakan metode K-Nearest Neighbor (KNN). Metode KNN dilakukkan dengan membandingkan data uji dengan data training . Salah salah tahap awal yang harus dilakukkan adalah menentukan jumlah nilai K. Tahapan algortima KNN yang dilakukkan ditunjukkan pada Gambar 3.
Gambar 3. Tahapan algoritma KNN

IV . Hasil dan pembahasan
Pengujian dilakukan pada tahap praproses dan tahap klasifikasi. Hasil dari praproses digunakan sebagai data pada metode klasifikasi. Pengujian ini bertujuan untuk mengetahui keberhasilan sistem dalam klasifikasi daun. Skenario uji coba yang dilakukan dengan cara data dipisahkan menjadi dua bagian yaitu 70% digunakan sebagai data latih dan 30% digunakan sebagai data uji. Data latih digunakan untuk ekstraksi fitur sedangkan data uji coba digunakan untuk menguji ketepatan system dalam melakukkan klasifikasi daun. Hasil klasifikasi tersebut akan dicatat dan dibandingkan dengan klasifikasi yang sebenarnya. Dari hasil klasifikasi kemudian dihitung akurasinya.
A. Hasil Praproses
Pada praproses dilakukkan pengolahan gambar untuk beberapa tahapan. Meliputi proses grayscale , median filter, binarisasi dan erosi citra. Contoh citra hasil konversi dari RGB ke citra grayscale  seperti ditunjukkan pada Gambar 4.
Gambar 4. Konversi RGB ke Grayscale
Citra grayscale  hasil konversi kemudian dilakukkan proses median filter dengan tujuan untuk menghilangkan noise  dari citra. Contoh citra hasil perbaikan dengan median filter ditunjukkan pada Gambar 5.
Gambar 5. Perbaikan dengan Median Filter
Proses binarisasi citra grayscale dikonversi kecitra hitam putih. Citra hasil binarisasi ditunjukkan pada Gambar 6.
Gambar 6. Proses binarisasi citra
Tahapan selanjutnya dilakukan proses erosi. Proses ini bertujuan untuk memperbaiki citra hasil dari proses binarisasi. Proses ini dilakukan dengan cara menghilangkan struktur daun sehingga didapatkan obyek yang jelas.. Citra hasil perbaikan dengan proses erosi ditunjukkan pada Gambar 7.
Gambar 7. Proses erosi citra
Hasil proses erosi citra dilakukkan operasi reverse untuk mendapatkan citra dengan warna putih dengan latar belakang hitam. Secara keseluruhan praproses yang dilakukkan ditunjukkan pada 
Gambar 8. Setelah tahapan praproses selasai kemudian dilakukan ekstraksi fitur daun menggunakan metode invariant moment.
Gambar 8. Hasil praproses
B. Hasil Ekstraksi Fitur
Tahap ekstraksi fitur telah berhasil menghasilkan vektor fitur yang berisi tujuh nilai dari invariant moment . Contoh nilai pada ekstraksi fitur yang dihasilkan oleh sistem ditunjukkan pada Tabel 1.
C. Hasil Klasifikasi
Pengujian klasifikasi dilakukan terhadap 15 data uji. Data uji akan diklasifikasikan terhadap data training . Proses klasifikasi yang dilakukan menggunakan metode K-Nearest Neighbor  (KNN). Hasil pengujian klasifikasi daun berdasarkan nilai moment invariant  ditunjukkan pada Tabel 2.
Tabel 2. Hasil pengujian klasifikasi dengan menggunakan metode K-Nearest Neighbor  (KNN)
Daun Kelas Hasil Sebenarnya Sistem Benar Salah
daun1 1 1 1 0
daun2 1 1 1 0
daun3 1 1 1 0
daun4 2 4 0 1
daun5 2 2 1 0
daun6 2 2 1 0
daun7 3 3 1 0
daun8 3 3 1 0
daun9 3 3 1 0
daun10 4 4 1 0
daun11 4 4 1 0
daun12 4 2 0 1
daun13 5 5 1 0
daun14 5 5 1 0
daun15 5 5 1 0
Berdasarkan hasil pengujian terhadap 15 percobaan didapatkan 13 obyek yang terklasifikasi dengan benar dan 2 obyek yang salah terklasifikasi. Data yang tidak terklasifikasi dengan benar yaitu pada daun4 dan daun12. Dari hasil pengujian ini maka didapatkan akurasi sistem sebesar 13/15 = 86,67%.

V. Simpulan
Dari hasil pengujian yang telah dilakukan meliputi praproses, ekstraksi fitur dan klasifikasi didapatkan kesimpulan.
1) Penggunaaan median filter dan erosi citra mampu memperbaiki citra daun, sehingga dapat mempermudah proses ekstraksi fitur dan klasifikasi. 
2) Pengujian klasifikasi dengan menggunakan metode K-Nearest Neighbor  (KNN) didapatkan nilai akurasi sebesar 86,67%, hasil ini menunjukkan metode KNN mampu melakukkan klasifikasi daun dengan baik.
Saran
Saran penelitian berikutnya adalah perbaikan fitur citra untuk mendeteksi sidik jari, tulisan, tanda tangan atau wajah seseorang. Selain itu juga bisa dikembangkan  ke arah Optical Character Recognition  (OCR). Perbaikan fitur bisa dilakukkan pada proses pembentukan segmen karakter yang dibedakan menjadi garis, kurva atau loop. OCR dapat digunakan untuk mengenali tulisan teks cetak, sehingga jika terjadi kehilangan data dapat mengembalikan dokumen yang hilang dengan mengenali dokumen secara otomatis. 

Daftar Pustaka
[1] Stephen G. W., Forrest S. B., Eric Y . Xu, Yu-Xuan W., Yi-F. C. and Qiao-Liang X., â€œA Leaf Recognition Algorithm for Plant Classification Using Probabilistic Neural Networkâ€, IEEE International Symposium, pp 11-16, July, 2007..
[2] A. Kadir, Lukito E. N, Adhi N, â€œLeaf Classification 
Using Shape, Color, and Texture Featuresâ€, International Journal of Computer Trends and Technology, July to Aug, 2011.
[3] Z. Husin, A. Y . M. Shakaff, A. H. A. Aziz, R. S. 
M. Farook, M. N. Jaafar, U.  Hashim, A. Harun, â€œEmbedded Portable Device For Herb Leaves Recognition Using Image Processing Techniques And Neural Network Algorithmâ€, Science Direct on Computers and Electronics in Agriculture, hal 18â€“29, 2012.
[4] Chaki J, Parekh R, â€œPlant Leaf Recognition using Shape based Features and Neural Network classifiersâ€, International Journal of Advanced Computer Science and Applications, vol 2, no 10, 2011.
[5] ArunPriya C, Balasaravanan T, â€œAn Efficient ULTIMATICS, Vol. VII, No. 2 | Desember 2015104 Classification Using Support Vector Machineâ€, Proceedings of the International Conference on Pattern Recognition, Informatics and Medical Engineering, hal 21-23, Maret, 2012.
[6] Theodoridis, Sergios. and Koutroumbas, Kontantinos., â€œPattern Recognitionâ€, 2nd Edition, New York, USA: Academic Press, 2003
[7] Wu X, Kumar V ., â€œThe Top Ten Algorithms in Data Miningâ€, New York:CRC Press
[8] Larose D., â€œDiscovering Knowledge in Dataâ€, USA:John Wileyâ€™s and Son 
[9] Han J and Kamber M., â€œData Mining:Concept and Techniquesâ€. New York:Morgan Kaufmann Publisher 
[10] Goujon G, Chaoqun, Jianhong W., â€œData Clustering :Theory, Algorithms, and Applicationsâ€, Virginia: ASA",klasifikasi,K-Nearest Neighbor,data citra,akurasi
CONVOLUTIONAL NEURAL NETWORK  PADA KLASIFIKASI SIDIK JARI MENGGUNAKAN RESNET-50,"CONVOLUTIONAL NEURAL NETWORK  PADA KLASIFIKASI SIDIK JARI MENGGUNAKAN RESNET-50

Novelita Dwi Miranda1, Ledya Novamizanti2, Syamsul Rizal3 

Abstract  
Fingerprint recognition is part of biometric technology. The most popular fingerprint classification is the Henry classification system. Henry divides fingerprints based on their pattern lines into five classes namely arch (A), tented arch (T), left loop (L), right loop (R), and whorl (W  This study uses a Convolutional Neural Network (CNN) with a Residual Network -50 (ResNet -50) architectural model to develop a fingerprint classification system. The dataset used was obtained from the National Institutes of Standards and Technology (NIST) website in the form of an 8-bit grayscale fingerprint image. The test results show that the initial processing of Contrast Limited Adaptive Histogram Equalization (CLA HE) in the CNN model can improve the accuracy performance of the fingerprint classification system by 11.79%. In the image without CLAHE, the validation accuracy is 83.26%, while the image with CLAHE has th e validation accuracy of 95.05% .  

Keywords : CLAHE,  CNN, fingerprint, henry classification system, Resnet-50   
 
1. PENDAHULUAN  
Biometrik merupakan teknologi untuk mengidentifikasi karakteristik unik pada diri manusia. Karakteristik unik tersebut  antara lain pola sidik jari, bentuk geometri tangan, kunci frekuensi suara, pola iris , dan retina mata yang umumnya berbeda pada setiap individu  [1]. Cara kerja teknologi biometrik  adalah dengan deteksi pola,  sehingga sering digunakan sebagai sistem keamanan untuk menjaga kerahasiaan data identitas seseorang. Salah satu teknologi biometrik yang  sering  digunakan dalam sistem keamanan  adalah identifikasi sidik jari.   Pada tahun 1892 , Sir Francis Galton menetapkan bahwa sidik jari merupakan ciri perseorangan yang tidak berubah. Galton merupakan orang pertama yang melakukan penelitian tentang sidik jari. Pada tahun 1901, Sir Edwar Henry mengembangkan metode perumusan Galton yang dikenal  dengan â€œ Henry classification system â€. Henry telah mengklasifikasikan pola sidik jari menjadi lima kategori yaitu arch (A), tented arch  (T), left loop  (L), right loop  (R), dan whorl  (W) [2].  Deteksi pola sidik jari ini dimanfaatkan oleh pihak kepolisian dalam  membuat rumus sidik jari . Rumus tersebut  digunakan sebagaai identitas data kriminal seseorang. Namun hingga saat ini, proses pendeteksian pola sidik jari  masih dilakukan secara manual , yaitu  dengan me ngamati  satu per satu sidik jari. Hal ini sangat tidak efisien dari sisi waktu dan bergantung pada kemampuan individu. Untuk memudahkan proses pengenalan pola sidik jari, maka dirancang sistem  klasifikasi  sidik jari secara otomatis menggunakan pengolahan citra digital.  Deep learning  sudah terbukti akurat dalam berbagai penelitian klasifikasi citra sidik jari. Beberapa algoritma deep learning  yang sering digunakan seperti Recurrent Neural Network (RNN), Generative Adversarial Networks (GAN), dan Convolutional  Neural Network  (CNN). John M. Shrein  [3] menggunakan preprocesing  pada CNN dengan arsitektur LeNet-5, sehingga  diperoleh  
akurasi 95,9% . Preprocessing  dapat meningkatkan tingkat akurasi . Xiaomeng Guo, Fan Wu, dan Xiaoyong Tang  [4] menggunakan metode CNN dengan memodifikasi arsitektur CaffeNet menjadi FCTP-Net yang terdiri dari 4 convolutional layer, 3 max-pooling layer , dan 3 fully-connected layer. 
Sehingga didapatkan akurasi sebesar 91,5% . Hasil ini lebih tinggi dibanding arsitektur LeNet sebesar 16,69%, AlexNet sebesar 57,84, dan CaffeNet sebesar 81,77%. Pada  penelitian [4], perubahan jumlah layer pada CNN mempengaruhi performa  sistem .  Penelitian oleh P. Nahar, S.Tanwani, dan NS Chaudhari [5] dengan membandingkan arsitektur ResNet-50, CoarseNet, FineNet, dan  Unified FingerNet tanpa preprocessing  sehingga didapatkan akurasi tertinggi pada ResNet-50 sebesar 90%, CoarseNet dan FineNet sebesar 73,45%, serta Unified FingerNet sebesar 89%, sebanding dengan penelitian Mubeen Ghafoor  dkk [6] menggunakan arsitektur 
ResNet-50 dan mendapat akurasi  91,3%. Penelitian oleh Wang-Su Jeon dan Sang-Yong Rhee [7] menggunakan tiga bentuk model. Hasil pengujian diperoleh bahwa  model 1 berupa arsitektur VGGNet dasar memiliki akurasi 82,1% dengan waktu belajar 8 jam 21 menit, model 2 yaitu VGGNet dengan preprocessing  dihasilkan akurasi 94,2% dengan waktu 8 jam 48 menit,  dan model 3 yaitu VGGNet dengan teknik ensemble bining menghasilkan akurasi 98,3% dengan waktu 10 jam 2 menit.  Pada penelitian [5],[6], ResNet -50 memiliki hasil akurasi yang cukup baik untuk percobaannya. Pada  penelitian [3],[7], gambar yang dilakukan preprocessing  hasilnya memiliki tingkat akurasi yang lebih tinggi dibanding  tanpa preprocessing .  Berdasarkan hasil penelitian -penelitian tersebut, maka penelitian ini  merancang sistem  untuk  klasifikasi sidik jari melalui citra digital yang melalui 
tahap preprocessing  terlebih dahulu kemudian diklasifikasi menggunakan metode CNN dengan arsitektur  ResNet-50. Klasifikasi  menggunakan 5 kelas sesuai Henry classification system , yaitu: arch, left loop , right loop,  tented arch,  dan whorl.   
 
2. METODE PENELITIAN  
Penelitian ini dibagi menjadi 4 tahap, yaitu tahap pengambilan data, tahap  preprocessing  yaitu proses peningkatan kualitas citra. Tahap selanjutnya yaitu klasifikasi  menggunakan CNN dengan arsitektur ResNet-50. Kemudian tahap  pengujian sistem menggunakan dua skenario pengujian. Gambar 1 merupakan blok diagram tahapan penelitian.   
Gambar 1. Metode Penelitian  
2.3. Dataset Sidik Jari  
Dataset dalam penelitian  ini di dapatkan melalui  website  National Institute of Standards and Technology  (NIST)  berupa citra sidik jari grayscale 8-bit berukuran 512Ã— 512 pi ksel [8]. Total dataset yang digunakan sejumlah 2100 citra dengan  429 citra berpola arch, 403 citra berpola tented arch , 402 citra berpola left loop, 410 citra berpola right  loop, dan 456 citra berpola whorl. Hal tersebut dengan mempertimbangkan kualitas citra , yaitu kejelasan 
garis pola, dan ukuran pola pada citra . Gambar 2 merupakan contoh dataset dari NIST untuk setiap kelas  sidik jari . 
Gambar 2. Dataset sidik jari NIST   
Arch  adalah bentuk pokok sidik jari yang semua 
garisnya datang dari satu sisi pola, cenderung 
mengalir ke sisi yang lain , dan bergelombang naik di 
tengah-tengah. Pola arch diklasifikasikan menjadi 4 tipe yaitu radial arch, tented arch, plain arch, dan Arch  (A) 
Left loop {L)  
Right loop (R)  
Tented arch (T)  
Whorl (W) 
ulnar arch. Hampir 50% dari seluruh sidik jari terdiri dari pola arch. Loop  adalah bentuk pokok sidik jari dimana  satu garis atau lebih datang dari salah satu sisi pola. Bentuk  loop melengkung dan menyentuh suatu garis bayangan yang ditarik antara delta dan core (inti) , serta  cenderung kembali ke sisi semula. Pola loop diklasifikasikan  menjadi 4 tipe yaitu plain loop, lateral pocket loop, twinned loop, dan a central packet loop . Persentasenya 60% hingga 65% dari seluruh sidik jari terdiri dari pola loop.  Whorl  adalah bentuk pokok sidik jari yang membentuk formasi melingkar di sekitar core. Pola whorl diklasifikasikan lagi menjadi 4 tipe yaitu plain whorl, central pocket loop whorl, accidental whorl, dan double pocket loop whorl. Persentasenya sekitar 30% hingga 35% dari seluruh sidik jari terdiri dari bentuk whorl  [9].  
2.4. Preprocessing  
Pada penelitian ini, sistem klasifikasi  sidik jari ditambahkan  tahap  preprocessing , agar akurasi dapat lebih optimal. Preprocessing  bertujuan untuk  meningkatkan kualitas citra,  sehingga memudahkan dan mempercepat kinerja sistem dalam  mengenali pola sidik jari. Semua dataset  dilakukan  grayscale  kemudian  diproses  dengan canny edge detection dan Contrast Limited Adaptive Histogram Equalization (CLAHE) . Gambar 3 menjelaskan alur kerja pada tahap preprocessing.  
Gambar 3. Alur kerja tahap preprocessing   
Citra grayscale  merupakan  citra hasil proses normalisasi dari 3-layer  dari citra berwarna  (RGB)  menjadi 1 layer . Citra grayscale  berisikan matriks data yang nilai-nilai didalamnya mewakili intensitas setiap piksel dengan  nilai antara 0 sampai 255 . Jika nilai semakin mendekati 0 artinya  mendekati  warna hitam dan jika nilai semakin mendekati 255  artinya mendekati  warna putih. Setiap pi ksel pada citra grayscale  membutuhkan 8-bit memori  [10].  Canny edge detection  merupakan deteksi tepi yang bertujuan mencari garis tepi  pada suatu citra secara optimal. Canny hanya memberi satu tanggapan untuk satu tepi dengan memilih titik tepi berdasarkan pendekatan threshold.   Deteksi tepi ini  mampu menghilangkan noise  karena menggunakan tapis Gaussian pada awal  proses , tahap ini diseb ut denoise  yang dapat dihitung dengan persamaan (1). 
ðº(ð‘¥,ð‘¦)=1
2Ï€Ïƒ2ð‘’âˆ’ð‘¥2+ð‘¦2
2ðœŽ2  (1) 
dengan 1
2Ï€Ïƒ2 merupakan konstanta koefisien normalisasi Gaussian. Kemudian menghitung amplitudo gradien dan arah gradien citra. Arah gradien mengambil 4 parameter suduk ya itu 0o, 45o, 90o, dan 135o, secara matematis dapat didefinisikan dengan  persamaan  (2) dan (3) . 
ðº=âˆšðºð‘¥2+ðºð‘¦2  (2) 
ðœƒ=tanâˆ’1(ðºð‘¥
ðºð‘¦) (3) 
dengan ðºð‘¥ dan ðºð‘¦  adalah sepasang array konvolusi. citra.  Lalu terjadi penindasan yang menghilangkan piksel non-tepi dan hanya menyisakan beberapa 
bagian. Dan ter akhir dilakukan pemilihan hysteresis threshold . Sehingga canny dapat memberikan nilai loss yang rendah , karena piksel-piksel tepi yang ditemukan saat deteksi dan tepi sebenernya berjarak sangat pendek  [11]. 
Gambar 4 Distribusi excess pixel ke area bawah clip limit   
CLAHE  merupakan pengembangan dari metode Adaptive Histogram Equalization  (AHE). CLAHE memberikan solusi pada masalah peningkatan kontras yang berlebihan pada AHE dengan memberikan nilai batas atau clip limit  pada histogram. Clip limit menyatakan batas maksimum tinggi suatu histogram, dapat dihitung dengan persamaan (4).  
ð›½=ð‘€
ð‘(1+ð›¼
100(ð‘ ð‘šð‘Žð‘¥ âˆ’1)) (4) 
dengan M adalah luas region size , N adalah nilai grayscale  (256), dan ð›¼ adalah clip factor  yang menyatakan penambahan batas limit histogram  bernilai antara 0 -100. Histogram yang memiliki nilai diatas nilai clip limit dianggap sebagai excess pixel 
[12]. Akibatnya histogram jadi merata, karena didistribusikan ke area bawah clip limit yang diilustrasikan pada Gambar 4.  
2.5. Pelatihan Model  
Pelatihan model merupakan  proses pelatihan mengenali objek dan mengklasifikasikannya sesuai  dengan kelasnya . Penelitian ini menggunakan salah satu algoritma deep learning yaitu Convolutional Neural Network  (CNN) dengan  arsitektur ResNet-50. CNN merupakan  salah  jenis jaringan saraf yang bisa  digunakan untuk mendeteksi objek  pada sebuah citra. Alur kerja  CNN untuk klasifikasi citra  adalah dengan mengelompokkan citra tersebut berdasarkan kesamaannya, kemudian  dilakukan pengenalan objek dalam beberapa sample . Gambar 5 merupakan blok diagram CNN dengan arsitektur ResNet-50. Secara umum arsitektur CNN dibagi menjadi dua bagian  yaitu  feature detection layers dan classification layer. Feature detection layer melakukan perubahan citra menjadi angka yang kemudian  dilakukan perhitungan matriksnya. Features detection layer menampilkan tiga tipe operasi pada sebuah data input  yaitu  convolutional layer, pooling layer, dan rectified linear unit  (ReLU).  Ketiga operasi ini dilakukan secara berulang, dengan setiap lapisan mempelajari untuk mendeteksi fitur yang berbeda. Pada classification layer terdapat fully connected layer yang menghasilkan keluaran vektor dimensi K . Dimensi K adalah jumlah kelas yang dapat membuat jaringan tersebut dapat memprediksi. Vektor ini berisi probabilitas untuk setiap kelas dari citra yang diklasifikasikan.  
Gambar 5. Blok diagram CNN ResNet-50  
Convolution layer menempatkan citra input melalui serangkaian convolutional filter, yang masing-masing mengaktifkan fitur tertentu dari sebuah citra [13]. Parameter yang digunakan  pada Gambar 5 dalam convolution layer adalah stride. Perhitungan konvolusi dapat menggunakan 
persamaan (5).  
â„Ž(ð‘¥)=ð‘“(ð‘¥)âˆ—ð‘”(ð‘¥) (5) 
dengan â„Ž(ð‘¥) adalah weight parameter , hasil 
konvolusi dari ð‘“(ð‘¥) dan ð‘”(ð‘¥). ð‘“(ð‘¥) adalah citra input 
dan ð‘”(ð‘¥) adalah filter.  
Pooling  adalah proses menyederhanakan keluaran dengan melakukan down sampling nonlinear  dan mengurangi jumlah parameter. Pooling  digunakan untuk menghilangkan informasi tidak penting. Terdapat dua jenis  pooling  yang sering digunakan,  yaitu  average pooling  dan max pooling . Konsep max pooling yaitu membuat matriks baru berukuran lebih kecil dengan cara mengambil fitur terbesar pada sebuah layer. Dalam implementasinya, max pooling mengambil piksel terbesar yang kemudian  disusun menjadi matriks baru  [13], diilustrasikan pada Gambar 6. 
Gambar 6. Konsep Max Pooling   
Gambar 6 menunjukkan operasi max pooling pada citra berukuran 4 Ã—4, menggunakan filter 2 Ã—2, dan nilai stride 2 yang menandakan pergeseran baris dan kolom sebanyak 2.  Rectified Linear Unit  (ReLU)  berfungsi untuk  memungkinkan  pelatihan data lebih cepat dan efektif dengan memetakan nilai negatif ke nol dan mempertahankan nilai positif  [13]. ReLU dapat didefinisikan dengan persamaan (6). 
ð‘“(ð‘¥)=ð‘šð‘Žð‘¥ (0,ð‘¥) (6) 
Fully connected layer merupakan lapisan dimana semua  saraf aktivasi dari lapisan sebelumnya terhubung dengan saraf pada lapisan selanjutnya. FC-layer biasanya dilakukan setelah proses convolution layer dan pooling layer. Hasil dari proses convolution layer  dan pooling layer  berupa feature map  yang  dijadikan masukan pada  FC-layer. Secara umum 
keluaran pada FC -layer dapat ditentukan dengan persamaan  (7).  
â„Ž(ð‘¥)=ð‘”(ð‘+âˆ‘ð‘¤ð‘–ð‘¥ð‘– ð‘– )  (7) 
dengan ð‘” sebag ai fungsi aktivasi , ð‘ sebagai bias , ð‘¤ð‘– 
sebagai nilai masukan/nilai fitur,  dan ð‘¥ð‘– sebagai nilai bobot koneksi saraf. Softmax  berfungsi untuk memetakan angka yang didapat dari perhitungan fully connected layer ke dalam sebuah probabilitas yang menunjukkan kelasnya. Fungsi aktivasi softmax digunakan untuk  proses klasifikasi yang mempunyai berbagai kelas  
[13]. Tahap  pelatihan model ResNet-50 menggunakan 5 jenis konvolusi. Semua citra mengalami normalisasi menjadi 224 Ã—224 piksel. Fungsi aktivasi yan g digunakan pada  fully-connected  layer  yaitu flatten  yang  mengubah output multi 
dimension array dari proses pelatihan  menjadi array satu dimensi. Setelah citra  melalui fully connected layer , hasilnya  dijadikan input fungsi aktivasi softmax  untuk untuk menghitung probabilitas dari data hasil pelatihan terhadap objek yang terdiri dari  5 kelas  [14]. 
2.6. Fungsi Optimasi  
Fungsi Optimasi merupakan fungsi yang digunakan untuk meningkatkan proses pembelajaran pada sistem. Setiap algoritma optimasi menggunakan nilai learning rate  tertentu yang  menentukan kemampuan sistem belajar secara cepat ataupun lambat. Penelitian ini  menggunakan tiga jenis optimasi yaitu Root Mean Square Propagation  (RMSprop ), Adaptive Moment Estimation  (Adam ), dan Stochastic Gradient Descent  (SGD ). RMS prop merupakan modifikasi AdaGrad yang bekerja lebih baik untuk pengaturan non-convex dengan mengubah akumulasi gradien menjadi exponentially weighted moving average. Nilai learning rate standar pada SGD adalah 0,001. Berikut perhitungan pembaruan RMSprop pada persamaan (8), (9), dan (10).  
ð‘Ÿ=ðœŒð‘Ÿ+(1âˆ’ðœŒ)ð‘”âŠ™ð‘”     (8) 
âˆ†ðœƒ=âˆ’ð›¼
ð›¿+âˆšð‘ŸâŠ™ð‘”  (9) 
ðœƒ=ðœƒ+âˆ†ðœƒ  (10) 
dengan  ð‘Ÿ adalah accumulate squared gradient , ðœŒ 
adalah decay rate , âˆ†ðœƒ adalah compute update, ð›¼ 
adalah learning rate , ð›¿ adalah konstanta bernilai 
10âˆ’7, dan ðœƒ adalah parameter inisial. Adam merupakan kombinasi dari RMSprop dan momentum. Adam adalah  hasil penurunan metode SGD yang didasarkan pada estimasi adaptif momen orde pertama dan kedua.  algoritma optimasi yang 
menghitung tingkat pembelajaran secara adaptif untuk setiap parameter. Adam menyimpan rata-rata gradien proses sebelumnya secara eksponensial sama seperti RMSp rop. Nilai learning rate standar pada Adam adalah 0,001  [15]. Rumus perhitungan optimasi Adam ditunjukkan pada persamaan (11). 
ðœƒð‘¡+1=ðœƒð‘¡âˆ’ðœ•
âˆšð‘£^
ð‘¡+ðœ€.ð‘š^
ð‘¡   (11) 
dengan ðœƒð‘¡+1 adalah parameter hasil pembaruan, ðœƒð‘¡ 
adalah parameter hasil pembaruan sebelumnya, Î· adalah learning rate , ð‘š^
ð‘¡ adalah gradien kuadrat 
momen orde pertama, ð‘£^
ð‘¡ gradien kuadrat momen orde 
kedua, dan ðœ€ merupakan scalar kecil untuk mencegah pembagian dengan nol. Persamaan (11) menunjukkan perhitungan optimasi Adam dalam memperbarui nilai error  dalam proses pelatihan dengan memanfaatkan nilai gradien pada momen orde pertama dan orde kedua.  SGD  merupakan salah satu variasi dari optimasi gradient decent  yang selalu melakukan pe mbaruan  parameter untuk setiap data yang sedang dilatih . Saat melakukan pembaruan parameter, SGD tidak melakukan perulangan sehingga kinerjanya lebih cepat untuk dataset berjumlah besar . Nilai learning rate standar pada SGD adalah 0,01. Proses pembaruan parameter pada SGD dapat didefinisikan pada persamaan (12).  
ðœƒ=ðœƒâˆ’ðœ‚âˆ—ð›»ðœƒð½(ðœƒ
dengan ðœƒ adalah parameter hasil pembaruan, Î· adalah 
learning rate, ð‘¥(ð‘–) dan ð‘¦(ð‘–) merupakan data yang 
sedang dilakukan pelatihan.  
2.7. Pengujian Sistem  
Untuk mendapatkan model sistem terbaik diperlukan parameter uji sebagai nilai pembanding untuk setiap model. Parameter performa yang digunakan  dalam  penelitian  ini yaitu akurasi  dan loss. 
1. Akurasi  
Akurasi merupakan salah satu parameter uji yang menentukan kelayakan dari sebuah sistem  dalam mengklasifikasikan pola sidik jari . Akurasi  (A) dapat dihitung  dengan persamaan  (13).  
ð´=ð‘
ð‘›Ã—100%  (13) 
dengan A adalah  persentase tingkat kebenaran,  b adalah  jumlah data yang diklasifikasi dengan  benar, dan n adalah  jumlah keseluruhan data.   
2. Loss 
Loss merupakan parameter uji yang digunakan untuk menghitung data yang tidak terdeteksi (loss) saat proses pelatihan maupun pengujian. Pada penelitian ini menggunakan jenis  sparse categorical cross entropy  loss. Secara matematis perhitungan loss dapat dituliskan dengan persamaan  (14).  
ð¿(ð›©)=âˆ’âˆ‘ð‘¦ð‘–
ð‘–=1ð‘˜
log(ð‘¦^
ð‘–) (14) 
dengan ð¿(ð›©) sebagai loss, ð‘¦ð‘– sebagai jumlah data 
terdeteksi dengan benar, dan ð‘¦^ð‘– sebagai jumlah data  
terdeteksi . 

3. HASIL DAN PEMBAHASAN  
Spesifikasi perangkat yang digunakan pada pengujian  sistem ini, yaitu bahasa pemrograman  Python  3.7.7 , software  Anaconda Navigator , dan hardware , dengan spesifikasi : processor  IntelÂ® Coreâ„¢ i5 -10210u CPU  @ 1.60GHz (8 CPUs), ~2.1GHz , memori  4096MB RAM, GPU IntelÂ® UHD Graphics dan Radeon 530 Series  
3.1. Pengujian Preprocessing  
Bagian ini  merupakan pengujian tentang pengaruh adanya  preprocessing pada citra sebelum  proses klasifikasi. Preprocessing yang digunakan yaitu canny edge detection  dan CLAHE . Pengujian ini membandingkan hasil citra original dengan citra hasil preprocessing.  Optimasi yang digunakan SGD  dengan default  learning rate 0,01, dan epoch  25. Epoch  merupakan satu siklus proses  pembelaj aran dari seluruh dataset training . Proses pembelajaran yang berulang-ulang bertujuan untuk mencapai konvergensi nilai bobot  [16]. Tabel 1 merupakan hasil pengujian preprocessing  terhadap performa akurasi dan loss.  
Tabel  1. Pengaruh  Preprocessing  terhadap Performa  
Citra  Akurasi  Loss  training 
(%) valid asi 
(%) training  validasi 
Original  93,56  83,26  0,191  0,631  
Canny  95,31  77,83  0,155  0,762  
CLAHE  99,52  95,05  0,016  0,229  
Berdasarkan Tabel 1, hasil terbaik untuk  pengujian preprocessing  adalah CLAHE  yang memiliki akurasi pelatihan 99,52%, akurasi validasi  95,05%, loss pelatihan 0, 016, dan loss validasi 0, 229. Untuk canny edge detection  menghasilkan  akurasi pelatihan 95,31%, akurasi validasi 77,83%, loss pelatihan 0,1 55 dan loss validasi 0,762. Sedangkan untuk citra asli menghasilkan akurasi pelatihan 93,56% , akurasi validasi 83,26% , loss pelatihan 0,191, dan loss validasi 0,63 1. Adanya preprocessing pada citra sebelum proses klasifikasi dapat jauh lebih mengoptimalkan hasil akurasi dan me minimalkan loss. Berdasarkan hasil pengujian preprocessing, CLAHE  dinilai sebagai preprocessing paling baik untuk meningk atkan kualitas citra pada pola sidik jari. Hasil pengujian CLAHE terhadap performa akurasi dan loss dapat dilihat pada Gambar 7 dan 
Gambar 8. Hasil pada preprocessing CLAHE dipengaruhi oleh nilai clip limit . Semakin besar clip limit maka peningkatan piksel pada citra juga semakin besar. Jika clip limit  besar, maka  excess pixel lebih sedikit, sehingga tidak banyak histogram yang didistribusikan ke area bawah clip limit. Citra hasil CLAHE memiliki kontras yang lebih baik 
dibandingkan dengan canny, sehingga garis pola sidik jari lebih terlihat jelas. Canny melakukan pendekatan threshold untuk menghilangkan noise tidak ada proses penajaman citra didalamnya, jadi dianggap kurang untuk memperjelas garis -garis pola sidik jari. Adanya preprocessing  di tahap awal juga dapat meringankan beban perangkat, dimana penggunaan preprocessing dapat menambah tingkat akurasi cukup tinggi meskipun sistem klasifikasi dengan arsitektur layer sedikit.  
Gambar 7. Performa CLAHE  terhadap akurasi  
Gambar 8. Performa  CLAHE  terhadap loss 
3.2. Pengujian Fungsi Optimasi  
Bagian ini  merupakan pengujian terhadap pengaruh fungsi optimasi. Optimasi  yang digunakan yaitu SGD, RMSprop, dan Adam. Semua optimasi  menggunakan learning rate 0,01 untuk mengetahui kinerja setiap optimasi pada learning rate yang sama. Dalam pengujian ini digunakan citra CLAHE yang memiliki hasil terbaik pada s kenario sebelumnya. Tabel 2 merupakan hasil pengujian fungsi optimasi .  
Tabel 2. Hasil Pengujian Fungsi Optimasi  
Optimasi  Akurasi  Loss  training 
(%) valid asi 
(%) train ing  valid asi 
SGD  99,52  95,05 0,016  0,229  
RMSprop  96,98  74,29  0,108  1,716  
Adam  96,42  77,83  0,117  1,375  
Berdasarkan Tabel 2, optimasi SGD  memiliki akurasi pelatihan 99,52%, akurasi validasi  95,05%, loss pelatihan 0,016, dan loss validasi 0,229. Untuk RMSprop menghasilkan akurasi pelatihan 96,98%, akurasi validasi 74,29%, loss pelatihan 0,108, dan loss validasi 0,716. Sedangkan untuk Adam menghasilkan akurasi pelatihan 96,42%, akurasi 
validasi 77,83%, loss pelatihan 0, 117, dan loss validasi 1,375.  Performa Adam dan RMSprop tidak jauh berbeda , karena Adam merupakan  kombinasi antara RMSprop d engan  momentum.  Adam  dan RMSprop melakukan pe nyimpan an rata-rata gradien proses sebelumnya secara eksponensial  sehingga kinerjanya cenderung lebih lambat diban ding SGD. SGD tidak melakukan perulangan sehingga kinerjanya lebih cepat, terutama untuk jumlah data yang besar. Pada penelitian ini nilai learning rate  yang digunakan sebesar 0,01 . Nilai ini merupakan nilai standar pada SGD, namun tidak untuk RMSprop dan Adam memiliki standar learning rate sebesar 0,001. Gambar 9 merupakan performa akurasi untuk optimasi SGD, RMSprop dan Adam.  
Gambar 9. Performa akurasi optimasi SGD, RMSprop, dan Adam  
Berdasarkan hasil pengujian, optimasi  SGD memiliki performa terbaik  dibanding  RMSprop  dan Adam  untuk klasifikasi pola sidik jari menggunakan model CNN dengan arsitektur ResNet-50. 

4. KESIMPULAN  
Penelitian ini mengusulkan sistem klasifikasi pola sidik jari otomatis menggunakan metode CNN dengan arsitektur ResNet-50. Sistem dapat mengidentifikasi 5 pola sidik jari  dengan  akurasi pelatihan 99,52 %, akurasi validasi 95,05%, loss pelatihan 0,016, dan loss validasi 0,229 . Hasil ini didap atkan dengan menggunakan  preprocessing CLAHE , learning rate 0,01, dan optimasi SGD . Dari hasil  pengujian, bahwa  preprocessing  CLAHE  pada citra dan penggunaan fungsi optimasi  SGD  dapat meningkatkan performa sistem klasifikasi sidik jari.   

DAFTAR PUSTAKA   
[1] R. Clarke, â€œRo ger Clarke â€™ s Human Id in Info. Systems Human Identification in Information Systemsâ€¯: Management Challenges and Public Policy Issues Introduction Roger Clarke â€™ s Human Id in Info . Systems In troduction Human Identity and Human Identification * Human ,â€ pp. 1 â€“20, 1994.  
[2] N. A. Alias and N. H. M. Radzi, â€œFingerprint classification using Support Vector Machine,â€ Proc. 2016 5th ICT Int. Student Proj. Conf. ICT -ISPC 2016 , pp. 105 â€“108, 2016, doi: 10.1109/ICT -ISPC.2016.7519247.  
[3] J. M. Shrein, â€œFingerprint classification using 
convolutional neural networks and ridge orientation images,â€ 2017 IEEE Symp. Ser. Comput. Intell. SSCI 2017 - Proc. , vol. 2018-Janua, no. c, pp. 1 â€“8, 2018, doi: 10.1109/SSCI .2017.8285375.  
[4] X. Guo, F. Wu, and X. Tang, â€œFingerprint pattern identification and classification,â€ ICNC -FSKD 2018 - 14th Int. Conf. Nat. Comput. Fuzzy Syst. Knowl. Discov. , no. 
1984, pp. 1045 â€“1050, 2018, doi: 10.1109/FSKD.2018.8687199.  
[5] P. Nahar, S. Tanwani, and N. S. Chaudhari, â€œFingerprint Classification Using Resnet50,â€ Int. J. Res. Anal. Rev. , vol. 5, no. 04, pp. 1521 â€“1535, 2018.  
[6] M. Ghafoor et al. , â€œFingerprint Identification With Shallow Multifeature View Classifier,â€ IEEE Trans.  Cybern. , vol. PP, pp. 1 â€“13, 2019, doi: 10.1109/TCYB.2019.2957188.  
[7] W. S. Jeon and S. Y. Rhee, â€œFingerprint 
pattern classification using convolution neural network,â€ Int. J. Fuzzy Log. Intell. Syst., vol. 17, no. 3, pp. 170 â€“176, 2017, doi: 10.5391/IJFIS .2017.17.3.170.  
[8] NIST Special Database 4, â€œNIST 8 -Bit Gray 
Scale Images of Fingerprint Image Groups (FIGS),â€2019. https://www.nist.gov/srd/nist-special-database-4 (accessed Maret. 11, 2020).  
[9] S. R. Borra, G. J. Reddy, and E. S. Reddy, â€œA 
broad survey on fingerprint recognition systems,â€ Proc. 2016 IEEE Int. Conf. Wirel. Commun. Signal Process. Networking, WiSPNET 2016 , pp. 1428 â€“1434, 2016, doi: 10.1109/WiSPNET.2016.7566372.  
[10] P. N . Andono , Pengolahan Citra Digital. Penerbit Andi, Yogyakarta, 2017 . 
[11] S. A. Syakry, M. Syahronir, and M. Mulyadi, â€œPerbandingan Performa Segmentasi Citra Sidik Jari Menggunakan Deteksi Tepi Metode Sobel Dengan Metode Canny,â€ J. Infomedia , vol. 1, no. 2 , pp. 35 â€“40, 2016, doi: 10.30811/.v1i2.332.  
[12] G. F. C. Campos, S. M. Mastelini, G. J. Aguiar, R. G. Mantovani, L. F. de Melo, and S. Barbon, â€œMachine learning 
hyperparameter selection for Contrast Limited Adaptive Histogram Equalization,â€ Eurasip J. Ima ge Video Process. , vol. 2019, no. 1, 2019, doi: 10.1186/s13640-019-0445-4. 
[13] S. Albawi, T. A. Mohammed, and S. Al-Zawi, â€œUnderstanding of a convolutional neural network,â€ in Proceedings of 2017 International Conference on Engineering and Technology, ICE T 2017 , 2018, vol. 2018-Janua, pp. 1 â€“6, doi: 10.1109/ICEngTechnol.2017.8308186.  
[14] X. Ou et al. , â€œMoving Object Detection Method via ResNet-18 with Encoder-Decoder Structure in Complex Scenes,â€ IEEE Access , vol. 7, pp. 108152 â€“108160, 68   Jurnal Teknik Informatika (JUTIF ), Vol. 1, No. 2, Desember 2020 , hlm. 61-68 2019, doi: 10.1109/ACCESS.2019.2931922.  
[15] L. A. Andika, H. Pratiwi, and S. S. Handajani, 
â€œKlasifikasi Penyakit Pneumonia Menggunakan Metode Convolutional Neural Network Dengan Optimasi Adaptive Momentum,â€ Indones. J. Stat. Its Appl. , vol. 3, no. 3, pp. 331 â€“340, 20 19, doi: 10.29244/ijsa.v3i3.560.  
[16] M. E. Abdulfattah, L. Novamizanti, S. Rizal, Super Resolution pada Citra Udara Menggunakan Convolutional Neural 
Network,"""" ELKOMIKA , Vol. 8, No. 3, 2020.",klasifikasi,"Convolutional Neural Network, ResNet-50",dataset sidik jari,akurasi
IMPLEMENTASI METODE CONVOLUTIONAL NEURAL NETWORK UNTUK KLASIFIKASI  TANAMAN PADA CITRA RESOLUSI TINGGI,"IMPLEMENTASI METODE CONVOLUTIONAL NEURAL NETWORK UNTUK KLASIFIKASI  TANAMAN PADA CITRA RESOLUSI TINGGI

Erlyna Nour Arrofiqoh dan Harintaka   

ABSTRAK   
Citra resolusi tinggi dari teknologi UAV (Unmanned Aerial Vehicle) dapat memberikan hasil yang baik dalam ekstraksi informasi sehingga dapat digunakan untuk monitoring  dan updating  data suatu wilayah.  Pengambilan  informasi dari citra  dengan interpretasi visual sangat bergantung pada interpreter.  Kendala utama interpretasi secara manual adalah saat melakukan pengenalan objek secara visual, khususnya pada objek tanaman per tanian. Kesalahan h asil asumsi interpreter dapat terjadi  ketika citra yang diekstraksi memiliki objek yang kompleks dan memiliki karakter fisik yang hampir mirip apabila dilihat dari foto udara yang hanya memiliki band RGB  (Red, Green,  dan Blue). Penelitian ini mencoba mengimplementasikan pendekatan klasifikasi semantik  secara otomatis yang dapat membedakan jenis tanaman sebagai  alternatif pengenalan objek berdasarkan  metode  deep learning  menggunakan Convolutional Neural Network (CNN). Metode CNN  merupakan  salah satu metode deep learning  yang mampu melakukan proses  pembelajaran mandiri untuk pengenalan objek, ekstraksi objek dan klasifikasi serta dapat diterapkan pada citra resolusi tinggi yang memiliki model distribusi nonparametrik.  Pada penelitian ini, diterapkan algoritma CNN untuk membedakan jenis tanaman  dengan memberikan label semantik dari objek jenis tanaman. Penelitian menggunakan 5 kelas jenis tanaman, yaitu kelas tanaman padi, bawang merah, kelapa, pisang, dan cabai. Proses learning  jaringan mengh asilkan akurasi 100% terhadap data training . Pengujian terhadap data validasi menghasilkan akurasi 93% dan akurasi terhadap data tes 82%. Hasil penelitian ini  menu njukkan bahwa penggunaan metode CNN berpotensi untuk pendekatan pengenalan objek secara otomatis dalam membedakan jenis tanaman sebagai bahan pertimbangan interpreter dalam menentukan objek pada citra . 

Kata kunci: Convolutional neural network , deep learning , citra resolusi tinggi, klasifikasi  

ABSTRACT   
High-resolution imagery  from UAV (Unmanned Ae rial Vehicle)  technology can provide good results in extracting information for monitoring and updating  data. Taking information from the image uses visual interpretation is highly dependent on the interpreter. The main obstacle when doing manual interpretation is visual object recognition, especially for object of agricultural plant . The assumption from the interpreter can have errors when the image have  complex object and have similar physical characters when viewed from aerial photographs that only have RGB (Red, Green,  and Blue) bands. This research tries to implement 
imagery extraction for the semantic classification  in automatically approach that can distinguish plant type as an alternative of  object  recognition  to help interpreter based on deep learni ng using Convolutional Neural Network (CNN). CNN method is one of the deep learning  method  which perform independent learning process for object recognition, object extraction and classification also can be applied in high resolution images which  have nonparametric distribution model. In this study, CNN algorithm applied to labelling different  plant type. Plant type that used in this study consist of 5 class es, such as coconut, rice, banana, red union and chili. Learning process obtained 100% accuracy toward training data. Testing on validation data 
produces accuracy 93% and test data produces accuracy 82%. The results showed that CNN method have potential in automatic object recognition to determine agricultural plant on the image.  

Keywords : Convolutional neural network, deep learning , high resolution imagery, classification

PENDAHULUAN  
Perkembangan teknologi penginderaan jauh yang pesat membuat citra resolusi tinggi semakin mudah untuk didapatkan, contohnya dengan teknologi UAV ( Unmanned Aerial Vehicle ). 
Teknologi UAV dapat menghasilkan  foto udara dengan waktu yang cepat, biaya yang lebih murah,  dan memungkinkan dilakukan kembali pada lokasi yang sama dengan waktu temporal yang  singkat.  Foto udara dari teknologi UAV dapat digunakan untuk monitoring  dan updating  data suatu wilayah  (Giordan  et al. , 2017) . Untuk keperluan pengambilan informasi, perlu dilakukan klas ifikasi pada foto udara. Klasifikasi pada citra resolusi tinggi dilakukan dengan interpretasi visual. Interpretasi visual merupakan kombinasi antara intuisi, mata dan pikiran manusia untuk membuat 
keputusan dan penilaian terhadap suatu objek tertentu, deng an menggunakan pengalaman dan pengetahuan sebagai pedomannya  (Tso & Mather, 2009).  Kendala utama saat melakukan interpretasi secara manual adalah saat  melakukan pengenalan objek secara visual, khususnya pada objek tanaman pertanian. Tanaman yang memiliki karakteristik fisik yang sama  sulit untuk dibedakan apabila dilihat dari foto udara yang hanya memiliki band RGB. Dibutuhkan uji lapangan untuk memastikan jenis tanaman tersebut agar hasilnya akurat. Namun apabila jumlah tanaman yang sulit dibedakan banyak dan lokasi pemotretan jauh, hal tersebut menjadi kurang efisien. Oleh karena itu penelitian ini mencoba untuk melakukan pendekatan klasifikasi semantik  secara otomatis sebagai alternatif pengenalan objek yang dapat membedakan jenis tanaman untuk bahan pertimbangan bagi interpreter saat melakukan klasifikasi  sebelum dilakukan uji lapangan.  Yalcin & Razavi  (2016)  melakukan klasifikasi tanaman menggunakan metode CNN  (Convolutional Neural Network ). Penelitian tersebut menggunakan foto objek tanaman yang dipotret dari samping. Hasil penelitian tersebut menunjukkan bahwa metode CNN dapat melaku kan klasifikasi lebih baik dari pada metode SVM (Support Vector Machine ). Metode CNN merupakan salah satu metode deep learning  yang mampu melakukan proses pembelajaran mandiri untuk pengenalan objek, ekstraksi objek dan klasifikasi  serta dapat diterapkan pada citra resolusi tinggi yang memiliki model distribusi nonparametrik  (Zhang et al., 2018). Penelitian ini  mengimplemetasikan  algoritma CNN untuk melakukan klasifikasi semantik dengan memberikan label semantik dari objek jenis tanaman. Kelas klasifikasi yang digunakan pada penelitian terdiri dari 5 kelas, yaitu kelas tanaman padi, cabai, bawang merah, pisang  dan kelapa  yang diperoleh dari citra resolusi tinggi menggunakan teknologi UAV . Pengujian terhadap implementasi metode CNN untuk membedakan jenis tanaman ini dilakukan pada training  jaringan, kemudian jaringan tersebut diuji dengan data validasi. Jaringan yang telah diuji dengan data validasi kemudian diterapkan untuk memproses  data tes. Pengujian dilakukan dengan metode stratified cross validation  untuk mengukur akurasi berdasar kan matriks konfusi . Hasil kajian ini diharapkan bermanfaat sebagai pendekatan untuk  membantu int erpreter dalam menentukan objek  yang sulit diinterpretasi secara visual . Sehingga diperoleh efisiensi dalam melakukan klasifikasi citra. 
Convolutional Neural Network  (CNN)  
Convolutional Neural Network  (CNN)  termasuk dalam jenis  deep learning  karena kedalaman jaringannya. Deep learning  adalah cabang dari machine learning  yang dapat mengajarkan  komputer untuk melakukan pekerjaan selayaknya manusia, seperti komputer dapat belajar dari proses training  (Deng & Yu, 2013) . CNN merupakan operasi  konvolusi yang menggabungkan beberapa lapisan pemrosesan, menggunakan beberapa elemen yang beroperasi secara paralel dan terinspir asi oleh sistem saraf biologis  (Hu et al. , 2015) . Pada CNN setiap neuron dipresentasikan dalam bentuk 2 dimensi, sehingga metode ini cocok untuk pemrosesan dengan input berupa  citra (Maggiori et al. , 2016) . Arsitektur jaringan dengan menggunakan CNN ditunjukkan pada Gambar 1 . Struktur CNN  terdiri dari input,  proses ekstraksi fitur, proses klasifikasi  dan output . Proses ekstraksi dalam CNN terdiri dari beberapa lapisan tersembunyi  atau hidden layer, yaitu lapisan konvolusi, fungsi aktifasi  (ReLU), dan pooling . CNN bekerja secara hierarki, sehingga output pada lapisan konvolusi pertama digunakan sebagai input pada lapisan konvolusi selanjutnya. Pada proses  klasifikasi terdiri dari fully-connected  dan fungsi aktivasi ( softmax ) yang outputnya  berupa hasil klasifikasi  (Katole et al.,2015) . Lapisan Konvolusi  
Lapisan konvolusi menggunakan  filter untuk mengekstraksi objek  dari citra input . Filter ini berisi bobot yang digunakan untuk mendeteksi karakter dari objek seperti tepi, kurva, atau warna.  Konvolusi akan menghasilkan transformasi linear dari citra input yang sesuai dengan informasi spasial pada data. Filter diaplikasikan secara berulang sehingga menghasilkan serangkaian bidang receptive . Terdapat parameter yang dapat diubah untuk memodifikasi sifat tiap lapisan , yaitu  
Sumber : Krizhevsky  et al. (2012)  
Gambar 1. Arsitektur CNN.   
ukuran filter, stride  dan padding . Stride  mengontrol bagaimana filter diterapkan pada data input dengan bergerak sepanjang ukuran  piksel yang telah ditentukan. Padding  adalah penambahan ukuran piksel dengan nilai tertentu disekitar  data input agar hasil dari bidang  receptive  tidak terlalu kecil sehingga tidak banyak informasi yang hilang.  Nilai ini biasanya nol sehingga disebut dengan zero padding . Hasil dari bidang receptive  berupa data tunggal . Output dari proses konvolusi ini dijadikan sebagai input untuk  lapisan  konvolusi selanjutnya  (Castelluccio et al., 2015) . Ilustrasi proses stride  dan padding  ditampilkan pada Gambar 2  dan Gambar 3 .  
Gambar 2 . Operasi konvolusi dengan stride  1 (a) Input data 5x5 (b) filter 3x3 (c) bidang receptive 3x3 .  
Gambar 3.  Operasi zero padding  2 pada data 3x3 . 
Fungsi Aktifasi ReLU  
ReLU ( Rectification Linear Unit ) merupakan operasi untuk mengenalkan nonlinearitas dan meningkatkan representasi dari model. Fungsi aktivasi ReLU adalah f(x) = max(  0,x )(Heaton, 2015) . Nilai output dari neuron bisa dinyatakan 
sebagai 0 jika inputnya adalah negatif. Jika nilai input adalah positif, maka output dari neuron adalah nilai  input akt ivasi itu sendiri  (Kim et al. , 2016) . 
Pooling  
Pooling  atau subsampling  adalah pengurangan ukuran matriks. Terdapat dua macam pooling  yang sering dig unakan yaitu average pooling  dan max pooling  (Bejiga et al. , 2017) . Nilai yang diambil pada average pooling  adalah nila rata-rata sedangkan pada max pooling  adalah nilai maksimal  (Zhi et al., 2016) . 
Fully Connected Layer  
Lapisan fully connected layer  merupakan kumpulan dari proses konvolusi  (Hijazi et al. , 2015) . Lapisan ini mendapatkan input dari proses sebelumnya untuk menentukan fitur mana yang paling berkorelasi dengan kelas tertentu.  Fungsi dari lapisan ini adalah untuk menyatukan semua  node menjadi satu  dimensi  (Albelwi & Mahmood, 2017) . 
Fungsi Aktivasi Softmax  
Fungsi aktivasi softmax  digunakan untuk  mendapatkan hasil klasifikasi. Fungsi aktivasi menghasilkan nilai yang diinter pretasi sebagai probabilitas yang belum dinorma lisasi untuk tiap kelas. Nilai kelas dihitung dengan menggun akan fungsi softmax  (Vedaldi & Lenc, 2015) , yang ditunjukan oleh Persamaan 1 . 
â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦.. .(1) 
dimana:  
yijk =vektor yang berisi nilai antara 0 dan 1 . 
x =vektor ya ng berisi nilai yang didapatkan 
dari lapisan  fully-connected  terakhir . 
Fungsi kesalahan klasifikasi  dihitung dengan Persamaan 2 : 
-2
dimana:  
l(x,c)  =membandingkan prediksi (x) dan label (c) . Geomatika Volume 24 No.2 November  2018: 61-68 
64 x  =vektor dari probabilitas akhir .  
p(k)  =xk,  
k =1. 
C=banyak kelas . 
Untuk mengontrol overfitting , pooling  layer digunakan untuk mengurangi representasi ukuran spasial dan mengurangi jumlah parameter. Lapisan dropout  memberikan aturan untuk  menghilangkan atau menjaga neuron dengan beberapa nilai 
probabilitas  p yang bernilai antara 0 dan 1 (Srivastava et al., 2014) . Lapisan dropout berguna untuk memudahkan penggolongan kelasnya.  

METODE  
Pada penelitian ini data yang digunakan menggunakan foto udara  hasil perekaman dengan menggunakan teknologi UAV dengan jenis kamera Canon PowerShot S100 . Data diambil dari satu scene   citra RGB dengan koreksi geometrik  4,64 mm  seluas 311 ha dan resolusi  spasial  6,5 cm. Lokasi penelitian berada di daerah Kretek, Daerah Istimewa Yogyakarta. Data meliputi foto dari 5 jenis tanaman , yaitu  kelapa, pisang , padi,  cabai dan bawang merah . Penampakan 5 jenis tanaman tersebut dapat dilihat pada Gambar 4. Penampakan pada gambar tersebut merupakan penampakan dari foto udara UAV sedangkan penampakan dari  samping merupakan foto yang diambil di  lapangan dengan menggunakan kamera. Pembuatan model CN N dilakukan dengan menggunakan software Matlab 2017b.  
Tampak atas  Tampak samping     
(A)     
(B)    
(C)  
(D)  
(E) 
Gambar 4.  Kelas jenis tanaman : (A) padi, (B) bawang merah, (C) cabe, (D) pisang, dan (E) kelapa.  Langkah Kerja  
Gambar 5.  Diagram alir penelitian. 
tidak Training 
parameter  
iya 
Overfitting  Mulai 
Data 
Training  Data pre-processing  
CNN model  Data Validasi  Data Test  
Selesai  Evaluasi  
jaringan  Evaluasi  
jaringan  Network  
Modifikasi  tidak iya 
modifikasi  Network  
Hasil 
Klasifikasi  Data input  Pemilihan sampel data  Implementasi Alur pengerjaan penelitian ini  dimulai dari pemilihan data sampel yang digunakan sebagai input untuk data training , validasi dan pengujian/tes.  Kemudian merancang jaringan dengan metode CNN untuk melakukan klasifikasi semantik pada objek tanaman. Rancangan jaringan CNN diaplikasikan dengan data training, agar komputer dapat belajar mengenali objek. 
Apabila pembelajaran jaringan diper oleh hasil yang baik dalam membedakan jenis objek tanaman, maka jaringan tersebut kemudian dilakukan uji coba terhadap data validasi. Apabila data validasi juga menunjukkan hasil yang baik maka jaringan dapat digunakan untuk klasifikasi pada data tes (Gambar 5). 
Pengambilan Sampel untuk Data Input  
Input data yang digunakan dalam jaringan ini berupa sampel gambar dari lima jenis tanaman, yaitu kelapa, pisang, cabai, bawang merah, dan padi yang diperoleh dari satu  scene  foto udara dengan menggunakan teknologi  UAV. Data objek masing-masing kelas diambil secara random  pada foto udara tersebut.  Ukuran gambar sampel untuk pemrosesan jaringan adalah 227x227 piksel. Data untuk masing-masing kelas berjumlah 100 data sehingga keseluruhan data berjumlah 500 gambar. Data dari lima kelas tersebut dibagi menjadi tiga  jenis kelompok data, yaitu data training, data validasi, dan data tes. Pemba gian kelompok data untuk proses training  sebesar 70%, data untuk proses validasi sebesar 20%, dan data untuk proses pengujian atau tes sebesar 10% dari total keseluruhan data.  Data training  digunakan untuk melakukan proses pembelajaran  jaringan, kemudian dievaluasi. Apabila akurasi  pada proses training model jaringan belum baik maka perlu dilakukan modifikasi pada lapisan  CNN, paramet er jaringan  dan pada sampel datanya . Apabila hasil akurasi sudah baik maka dilakukan proses selanjutnya yaitu pengujian dengan data validasi . Data validasi adalah data yang tidak digunakan pada  proses training . Apabila akurasi dari data validasi ini kurang  baik, mungkin terjadi overfitting , oleh karena itu jaringan perlu dimodifikasi lagi . Apabila hasilnya sudah baik maka dapat dig unakan untuk memproses data tes . Data tes berisi  sekumpulan sampel  data yang ingin diketahui jenis klasifikasinya.   
Arsitektur Jaringan  CNN  
Arsitektur jarin gan pada penelitian ini menggunakan struktur dari Alexnet. Alexnet dikembangkan oleh (Krizhev sky et al., 2012)  yang merupakan basis dari arsitektur CNN modern yang cukup sukses untuk visual recognition . Untuk mengatasi kekurangan pada proses training data citra resolusi tinggi, perlu pengaturan pada beberapa lapisan dan mengekplorasi parameter untuk training data agar model CNN dapat menampilkan performa yang baik  dan mencegah gradien menjadi tidak stabil, khusu snya pada jaringan yang dalam . Struktur model CNN disajikan pada Tabel 1 . Jaringan  terdiri dari lapisan input ,  5 lapisan konvolusi, 3 fully connected  layer, dan lapisan output.  Pada lapisan input, data yang digunakan adalah data training . Kemudian data input diproses pada lapisan konvolusi pertama dengan menggunakan max pooling  dan fungsi aktivasi ReLU. Output pada lapisan konvolusi pertama dijadikan sebagai input pada proses konvolusi kedua. Proses konvolusi tersebut berlanjut sampai dengan konvolusi kelima. Kemudian hasil dari proses konvolusi dikumpulkan pada lapisan fully connected . Pada lapisan ini ditentukan fitur yang memiliki korelasi  dengan kelas tertentu sehingga hasil akhir dari proses ini adalah fitur yang terklasifikasi dalam lima kelas.  
Tabel 1. Struktur model CNN . 
Lapisan  Ukuran piksel  Node 
Input  227 x 227 x 3   
Conv1  11 x 11x 3  96 
Max Pool1  3 x 3  
Conv2 5 x 5 x 48 256 
Max Pool2  3 x 3  
Conv3  3 x 3 x 256 384 
Conv4  3 x 3 x 192 384 
Conv5  3 x 3 x 192 256 
Max Pool3  3 x 3  
FC6  4096 
FC7  4096 
FC8-n(class)   5 
Output  227 x 227 x 3   

HASIL  DAN  PEMBAHASAN  
Implementasi CNN  
Terdapat tiga tahap dalam mengim plementasikan CNN, yaitu training, validasi  dan tes. Tahap training  adalah tahap utama untuk melatih jaringan mempelajari data input. Kemudian jaringan tersebut diuji pada data validasi. Apabila memberikan hasil yang baik, maka jaringan  tersebut dapat  digunakan untuk melakukan klasifikasi data dengan data tes.  
Data Latih  (Data Training)  
Data latih yang digunakan adalah 70% dari total keseluruhan data sehingga didapat data latih sebanyak 350 gambar  dengan masing-masing kelas sebanyak 70 sampel . Komputasi di lakukan menggunakan mode single GPU . Proses training  menggunakan parameter sebagai berikut:  
learning rate  : 0,0001   
mini-batch size  : 10 
MaxEpochs  : 5  
Hasil training  disajikan pada Tabel 2.  Training  jaringan memberikan akurasi yang baik. Gr afik dari akurasi dan kesalahan proses training  disajikan pada Gambar 6. 
Tabel 2. Hasil training  jaringan CNN . 
Epoch  Iterasi  Waktu (s)  Error Accuracy  
1 1 7,44 1,5915  20,00%  
2 50 35,47  0,7838  80,00%  
3 100 65,42  0,3052  90,00%  
5 150 97,62  0,1115  90,00%  
5 175 111,11  0,0480  100,00%  
Gambar 6. Grafik akurasi dan kesalahan training.  
Data  Validasi  
Proses validasi jaringan  menggunakan 100  data untuk menguji jaringan  dengan masing-masing kelas sebanyak 20 sampel . Data tersebut tidak diikutkan dalam proses training . Dari proses ini didapatkan akurasi yang baik yaitu 93.00 % dengan jum lah data yang benar sebanyak 93 . Pada Gambar 7 disajikan matriks konfusi data validasi.   
Gambar 7.  Matriks konfusi dari data validasi . 
Data Tes  Interpreter dapat memasukkan sampel data yang ingin diketahui jenis klasifikasinya pada jaringan, kemudian jaringan akan mengeluarkan label jenis tanaman berdasarkan data yang dimasukkan.  Hasil label klasifikasi yang keluar dari jaringan dapat untuk bahan pertimbangan  interpreter  dalam menentukan  jenis objek tanaman yang sulit dibedakan secara visual. Pada penelitian ini skenario data tes  menggunakan 50 data dengan masing -masing kelas sebanyak 10 sampe l. Pengujian ini menghasilkan akurasi 82% dengan jumlah objek yang benar sebanyak 41  data. Hasil akurasi klasifikasi pada data tes digambarkan pada Gambar 8 dan hasil klasifikasi semantik pada data tes disajikan pada Gambar 9.  
Gambar 8.  Matriks konfusi dari data tes .  
(A)  
(B) 
Gambar 9 . Hasil klasifikasi semantik pada data tes (A) dan sampel data tes p ada foto UAV (B).
Pada hasil pengujian data tes, kesalahan terbanyak terdapat pada pengklasifikasian pohon pisang. Tanda kotak berwarna kuning pada Gambar 9  menunjukkan kesalahan klasifikasi pada objek pohon pisang. Jaringan memprediksi objek tanaman pisang sebagai tanaman kelapa. Dari 10 data sampel tanaman pisang di  lapangan,  5 diantaranya diprediksi sebagai tanaman kelapa. Jaringan sulit membedakan objek tersebut karena kedua tanaman tersebut memiliki karakter fisik 
yang hampir sama pada foto UAV.  Visualisasi Lapisan  
Metode CNN merupakan model yang kompleks . Pengetahuan mengenai operasi dan perilaku jaringan dalam mencapai performa yang baik, kurang mendapatkan pemahaman yang jelas 
bagaimana jaringan dapat bekerja. Oleh karena itu perlu trial and error  dalam menentukan parameter-parameter jaringan agar didapat hasil yang baik. Perlu pangamatan selama proses training  berlangsung . Pengamatan training  pada tiap lapisan dapat dilakukan dengan cara menvisualisasikannya. Bobot dari proses konvolusi atau fully connected  layer dapat divisualisasikan untuk menaksir bagaimana baiknya model dapat dilatih. Mo del training  yang baik biasanya memiliki filter yang halus dan kontinu dimana model overfitting  akan ditampilkan pola dengan banyak 
noise (Zeiler & Fergus, 2014) . Visualisasi proses training  pada tiap lapisan dilakukan dengan cara memproyeksikan kembali fitur aktivasi ke awal proses training  jaringan. Pada Gambar 10 merupakan visualisasi proses training  
pada lapisan konvolusi pertama dan lapisan konvolusi kedua. Pada konvolusi pertama dilakukan proses awal ekstraksi informasi yang berupa informasi tepi, bentuk kurva, dan warna.  Proses ektraksi informasi yang semakin dalam dilakukan oleh lapisan konvolusi kedua, lapisan konvolusi ketiga, lapisan konvolusi keempat dan lapisan konvolusi kelima. Visualisasi proses training  pada lapisan ini disajikan pada Gambar  11. Penyatuan dari keseluruhan node dilakukan oleh lapisan fully-connected  untuk menentukan node mana yang paling berkorelasi dengan kelas tertentu. Pada Gambar 12 disajikan visualisasi lapisan fully-connected keenam, ketujuh, dan kedelapan. Pada lapisan fully-connected  kedelapan ditentukan jenis kelas yang paling sesuai.   
Gambar 10.   Visualisasi lapisan konvo lusi pertama dan konvolusi kedua .  
Gambar 11 .  Visualisasi lapisan konvolusi ketiga, keempat, dan kelima .  
Gambar 12 . Visualisasi lapisan fullyconnected  keenam, ketujuh, dan kedelapan . 

KESIMPULAN  
Hasil implementasi  metode CNN untuk klasifikasi  semantik jenis tanaman  pada citra resolusi tinggi  yang diperoleh dari teknologi UAV  menunjukkan bahwa arsitektur CNN dapat mengklasifikasikan lima  jenis tanaman secara otomatis  dengan memberikan label pada data .  Evaluasi kerja terhadap arsitektur jaringan CNN pada data tes  menghasilkan akurasi 82%. Untuk skenario data tes dengan jumlah  masing-masing kelas sebanyak sepuluh  sampel, metode CNN dapat memberikan hasil yang cukup baik dalam melakukan proses pengenalan objek dan klasifikasi tanaman, namun masih terdapat ke salahan. Kesalahan prediksi paling banyak terdapat pada kelas pisang yang diprediksi sebagai kelas kelapa.  Dari tampilan citra UAV  yang memiliki koreksi geometrik 4,64 mm  ini, bentuk fisik kedua objek tersebut memiliki karakteristik penampakan yang mirip dan jarak kedua objek berdekatan sehingga menyebabkan jaringan salah memprediksi . 
Ketersediaan objek jenis tanaman dalam jumlah banyak pada foto udara yang dipakai untuk pemrosesan jaringan dan kondisi dari foto udara yang bebas dari noise juga berpengaruh dalam mendapatkan data sampel untuk proses training. Pada penelitian ini data diambil dari citra RGB yang masih dalam satu scene  pada arah sudut datang matahari yang sama  sehingga color balancing dapat terjaga  dan citra dalam keadaan bebas awan untuk memin imalisir kesalahan terhadap  bayangan yang dapat mempengaruhi nilai intensitas objek, mengingat UAV mengudara dibawah ketinggian awan.  Jumlah data training  dapat mempengaruhi akurasi jaringan.  Semakin banyak data training  maka jaringan akan semakin banyak belajar sehingga ketelitian akan semakin baik . Namun  
diperlukan peralatan komputasi yang besar untuk melakukan proses training  jaringan  pada data yang banyak. Penelitian  ini hanya menentukan klasifikasi semantik untuk membantu interpreter dalam menentukan jenis objek tanaman. Interpreter memasukkan sampel data objek yang ingin diketahui klasifikasinya, kemudian jaringan memberikan jawaban nama objek tersebut.  Sehingga dapat membantu interpreter yang tidak mengetahui kondisi jenis tanaman di  lapangan sebagai  bahan pertimbangan dalam melakukan digitasi objek pertanian.  

UCAPAN TERIMA KASIH  
Penulis mengucapkan terima kasih kepada PPRT BIG yang telah mengizinkan penggunaan  data UAV untuk penelitian ini.  

DAFTAR PUSTAKA  
Albelwi, S., & Mahmood, A. (2017). A Framework for Designing the Architectures of Deep Convolutional Neural Networks. Entropy , 19, 242.  
Bejiga, M. B., Zeggada, A., Nouffidj, A., & Melgani, F. 
(2017). A convolutional neural network approach for assisting avalanche search and rescue operations with UAV imagery. Remote Sensing , 9(2). https://doi.org/10.3390/rs9020100  
Castelluccio, M., Poggi, G, Sansone, C., Verdoliva, L. 
(2015). Land Use Classification in Remote Sensing Images by Convolutional Neural Networks. Diambil dari https://arxiv.org/pdf/1508.00092.pdf  Deng, L., & Yu, D. (2013). Deep Learning: Methods and Applications. Foundations and TrendsÂ® in Signal Processing , 7(3â€“4), 197 â€“387. 
https://doi.org/10.1136/bmj.319.7209.0a  
Giordan, D., Manconi, A., Remond ino, F., & Nex, F. 
(2017). Use of unmanned aerial vehicles in monitoring application and management of natural hazards. Geomatics, Natural Hazards and Risk , 8(1), 1 â€“4. https://doi.org/10.1080/19475705.2017.1315619  
Heaton, J. (2015). Artificial Intelligence  for Humans: 
Deep learning and neural networks of Artificial Intelligence for Humans Series . Createspace Independent Publishing Platform.  
Hijazi, S., Kumar, R., & Rowen, C. (2015). Image Recognition Using Convolutional Neural Networks. Cadence Whitepaper , 1â€“12. Hu, F., Xia, G. S., Hu, J., & Zhang, L. (2015). 
Transferring deep convolutional neural networks for the scene classification of high-resolution remote sensing imagery. Remote Sensing , 7(11), 14680â€“14707. https://doi.org/10.3390/rs71114680  
Katole, A. L., Yellapragada, K. P., Bedi, A. K., Kalra, S. S., & Siva Chaitanya, M. (2015). Hierarchical Deep Learning Architecture for 10K Objects Classification. Computer Science & Information Technology ( CS & IT ) , (September), 77 â€“93. https://doi.org/10.5121/csit .2015.51408  Kim, J., Sangjun, O., Kim, Y., & Lee, M. (2016). Convolutional Neural Network with Biologically Inspired Retinal Structure. Procedia Computer Science , 88, 145 â€“154. https://doi.org/10.1016/j.procs.2016.07.418  
Krizhevsky, A., Sutskever, I., and Hinton, G. E. (2012). 
ImageNet Classification with Deep Convolutional Neural Networks. Proceedings of the Twenty-Sixth Annual Conference on Neural Information Processing Systems. Lake Tahoe, NY, USA, 3 â€“8 December 2012 , 1097â€“1105.  
Maggiori, E., Tarabalka, Y ., Charpiat, G., & Alliez, P. 
(2016). Convolutional Neural Networks for Large-Scale Remote-Sensing Image Classification. IEEE Transactions on Geoscience and Remote Sensing , 55(2), 645 â€“657. https://doi.org/10.1109/TGRS.2016.2612821  Srivastava, N., Hinton, G ., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. (2014). Dropout: A Simple Way to Prevent Neural Networks from Overfitting. Journal of Machine Learning Research , 15, 1929â€“1958. https://doi.org/10.1214/12 -AOS1000  
Tso, B., & Mather, P. M. (2009). Classi fication Methods 
for Remotely Sensed Data, Second Edition . CRC Press Taylor & Francis Group . Boca Raton.  Vedaldi, A., & Lenc, K. (2015). MatConvNet: Convolutional Neural Networks for MATLAB. In Proceedings of the 23rd ACM International Conference on Multim edia (hal. 689â€“692). New York, NY, USA: ACM. https://doi.org/10.1145/2733373.2807412  
Yalcin, H., & Razavi, S. (2016). Plant classification using 
convolutional neural networks. 2016 Fifth International Conference on Agro-Geoinformatics (Agro -Geoinformatics) , 1 â€“5. https://doi.org/10.1109/Agro -Geoinformatics.2016.7577698  
Zeiler, M. D., & Fergus, R. (2014). Visualizing and Understanding Convolutional Networks. In D. Fleet, T. Pajdla, B. Schiele, & T. Tuytelaars (Ed.), Computer Vision -- ECCV 2014  (hal. 818â€“833). Cham: Springer International Publishing.  Zhang, C., Sargent, I., Pan, X., Gardiner, A., Hare, J., & Atkinson, P. M. (2018). VPRS -Based Regional Decision Fusion of CNN and MRF Classifications for Very Fine Resolution Remotely Sensed Images. IEEE Transacti ons on Geoscience and Remote 
Sensing , 1 â€“15. https://doi.org/10.1109/TGRS.2018.2822783  
Zhi, T., Duan, L. Y., Wang, Y., & Huang, T. (2016). Two -
stage pooling of deep convolutional features for image retrieval. In 2016 IEEE International Conference on Image P rocessing (ICIP)  (hal. 2465â€“2469). https://doi.org/10.1109/ICIP.2016.7532802",klasifikasi,"convulutional neural network, CNN",foto udara hasil perekaman,"akurasi, accuracy"
PENERAPAN MODEL KLASIFIKASI METODE NAIVE BAYES TERHADAP PENGGUNAAN AKSES INTERNET,"PENERAPAN MODEL KLASIFIKASI METODE NAIVE BAYES TERHADAP PENGGUNAAN AKSES INTERNET

Heliyanti Susana1), Nana Suarna2), Fathurrohman3), Kaslani4)  

ABSTRAK   
SMA N 1 Plumbon di peruntukkan untuk membantu dan memermudah siswa dalam belajar sehingga tidak kalah dengan kota-kota besar justru menjadikan siswa malas belajar dan meningkatkan ragam  dari kenakalan siswa. bagaimana memodelkan klasifikasi dengan beberapa algoritma dalam studi kasus ini menerapkan algoritma naive bayes untuk menganalisa hak akses internet siswa, dari penerapan metode tersebut dapat dilihat akurasi kemudian dapat mengana lisa pemakaian berdasarkan umur Naive Bayes merupakan salah satu metode machine learning yang menggunakan perhitungan probabilitas. Konsep 
dasar yang digunakan oleh Naive bayes adalah Teorema Bayes, yaitu melakukan klasifikasi dengan melakukan perhitungan nilai probabilitas hasil dari penelitian ini memiliki akurasi sebesar 89.83%  Hasil Prediksi Ya dan ternyata Ya sebanyak 34. Hasil Prediksi Ya dan ternyata Tidak sebanyak 6. Hasil Prediksi tidak dan ternyata Ya sebanyak 0. Hasil Prediksi tidak dan ternyata  tidak sebanyak 19. hasil dari prediksi dengan uji 59 data baru maka mendapatkan  hasil ya sebanyak  40 siswa dan tidak ada  19 siswa  
   
Kata Kunci : Datamining, Internet, Algoritma Naive Bayes  
 
ABSTRACT  
SMA N 1 Plumbon is intended to help and facilitate students in learning so that they are not inferior to big cities, it makes students lazy to learn and increases the variety of student delinquency. How to model classification with several algorithms in this case study applies the naive Bayes algorithm to analyze students' internet access rights, from the application of this method, it can be seen the accuracy then can analyze usage based on age. Naive Bayes is a machine learning method that uses probability calculations. The basic concept used by Naive Bayes is the Bayes Theorem, which is to classify by calculating the 
probability value of the results of this study which has an accuracy of 72.88%, namely the Prediction Results Yes and it turns out to be 22. Prediction Results Yes and not as many as 4. Prediction results are not and it turns out that Yes as many as 12. Prediction results are not and it turns out that there are not as many as 21. The results of the prediction by using 59 new data will get the results of yes as many as 26 students and no 33 students  
  
Keywords : Datamining, Internet, Naive Bayes Algorithm.  

I. PENDAHULUAN    
Internet merupakan salah satu hasil dari kecanggihan dan kemajuan ilmu pengetahuan dan teknologi buatan manusia. Internet adalah singkatan dari Interconnected Networking yang apabila diartikan dalam Bahasa Indonesia berarti rangk aian komputer yang terhubung di dalam beberapa rangkaian jaringan. Sekolah merupakan wadah untuk menciptakan manusia yang bermutu dan berpendidikan. Siswa dan siswi berinteraksi di dalamnya menjadikan sekolah sebagai salah satu lingkungan bagi mereka dalam  berkembang, bergaul dan belajar. Lingkungan sekolah yang baik akan menjadikan siswa-siswinya 
menjadi orang yang berguna sehingga banyak sekolah-sekolah yang menyediakan fasilitas yang terbaik untuk memfasilitasi kebutuhan siswanya, salah satunya yaitu menyediakan akses internet dengan mudah agar siswa-siswinya tidak ketinggalan seperti halnya pelajar di kota-kota besar dan negara-negara besar lain. Penelitian terdahulu yaitu dari asniati, sudarmi suud b, jahada pada jurnal bening volume 4 nomor 1 januari 2 020 dengan judul pengaruh penggunaan internet terhadap kenakalan remaja (siswa) tujuan penelitian adalah untuk mendeskripsikan dan menganalisis pengaruh penggunaan internet terhadap kenakalan remaja (siswa) sma negeri 2 tomia. Penelitian ini bersifat expos t facto yang bertujuan untuk mencari informasi tentang hubungan sebab akibat dari suatu peristiwa. Populasi dalam penelitian ini adalah seluruh siswa kelas xi ips sma negeri 2 tomia yang terbagi 4 kelas yang berjumlah 125 orang sedangkan sampel penelitian sebanyak 32 orang yang diambil dengan menggunakan teknik purposive sampling. Teknik pengumpulan data yang digunakan dalam penelitian ini adalah angket yaitu angket penggunaan internet dan kenakalan remaja siswa. Dari hasil analisis data yaitu analisis regr esi dapat disimpulkan bahwa ada pengaruh yang signifikan penggunaan internet siswa terhadap kenakalan remaja sma negeri 2 tomia. Hal ini menunjukan bahwa semakin tinggi penggunaan internet maka semakin tinggi 
pula kenakalan remaja siswa di sma negeri 2 tomia kabupaten wakatobi. Besarnya kontribusi penggunaan internet terhadap kenakalan remaja siswa di sma negeri 2 tomia adalah sebesar 32,8% [ 1] Penelitian yang sejenis juga di utarakan oleh mukti ratna dewi pada jurnal riset dan aplikasi matematika e-issn: 2581 -0154 Dengan judul klasifikasi akses internet oleh anak-anak dan remaja dewasa di jawa timur menggunakan support vector machine Pada tahun 2018 penetrasi pengguna internet di indonesia naik sebesar  10,12% dibanding tahun sebelumnyan dengan pengguna terbanyak berada di pulau jawa yang mencapai 55%. Kelompok usia pengguna internet terbanyak berturut -turut berada pada usia 15 hingga 19 tahun, umur 20 hingga 24 tahun, dan anak-anak yang berumur 5 hingga  9 tahun. Berdasarkan penelitian yang dilakukan oleh nurrahman (2017), faktor-faktor yang secara signifikan mempengaruhi penggunaan internet di jawa timur antara lain adalah umur, 
jenjang pendidikan, perbedaan tempat tinggal antara perkotaan dan pedesaan,  status pekerjaan, perangkat yang digunakan dalam mengakses internet dalam tiga bulan terakhir serta kepemilikan bangunan. Untuk mengetahui besar tingkat pengguna internet maka perlu dilakukan pengelompokkan berdasarkan faktor-faktor yang mempengaruhinya. Oleh karena itu, penelitian ini melakukan klasifikasi akses internet oleh anak-anak dan remaja usia 6 hingga 21 tahun di jawa timur berdasarkan faktor-faktor yang signifikan menggunakan support vector machine (svm) dengan fungsi kernel radial basis fuction  (rbf). Berdasarkan nilai auc sebesar 0,92, kinerja model svm yang terbentuk tergolong sangat bagus (excellent) dengan nilai akurasi, sensitivitas, dan spesifisitas berturut-turut sebesar 86,45% Fokus penelitian ini ialah bagaimana memodelkan klasifikasi dengan beberapa algoritma dalam studi kasus ini menerapkan algoritma naive bayes untuk menganalisa hak akses internet siswa, dari penerapan metode tersebut dapat dilihat akurasi kemudian dapat menganalisa pemakaian berdasarkan umur.  

II. LANDASAN TEORI  
Internet adalah sebuah jaringan komunikasi public dan global yang menyediakan koneksi langsung  kepada siapa saja melalui Local area network (LAN) dan Internet Service Provider (ISP) pengertian  internet dalam arti sederhana adalah komunikasi antara konsumen, marketer, dan jutaan organisasi lainnya. Internet memungkinkan orang untuk menyesuaikan cara mereka berkomunikasi, apakah hanya  dengan satu orang atau dengan seluruh target pasar, dengan cepat dan mudah. Internet mengarah pada jaringan fisik yang menghubungkan komputer -komputer di seluruh dunia. Internet terdiri dari  infrastruktur jaringan server dan komunikasi widearea yang saling terhubung, digunakan untuk  menyimpan dan mengirimkan informasi dalam jumlah yang besar melalui inte rnet. Jadi, internet  merupakan jaringan global yang menghubungkan pengguna komputer di seluruh dunia dengan  menggunakan protokol standar dalam berkomunikasi yaitu protokol TCP/IP  Keuntungan Internet keuntungan dari internet dapat diringkas dengan istilah 6C, yang terdiri dari :  
a. Cost Reduction Pengurangan kebutuhan penjualan dan pemasaran dapat ditangani melalui operator telepon dan pengurangan biaya cetak dan distribusi materi komunikasi pemasaran, semuanya dapat dipublikasikan melalui website.  
b. Capability Internet menyediakan peluang baru untuk produk-produk dan layanan baru serta pencarian pangsa pasar baru.  
c. Competitive advantage Jika sebuah perusahaan memperkenalkan kemampuan baru sebelum pesaingnya, maka perusahaan akan memperoleh keuntungan sebe lum pesaingnya memiliki kemampuan yang sama.  
d. Communications improvement Mencakup peningkatan komunikasi dengan pelanggan, pemasok, karyawan, dan distributor.  
e. Control Internet dan intranet dapat menyediakan penelitian pemasaran yang lebih baik melalui pelacakan perilaku pelanggan dan cara staf perusahaan memberikan pelayanan.  
f. Customer service improvement Dapat dicapai dengan menggunakan query database yang interaktif. 
Contohnya : ketersediaan stock atau pertanyaan-pertanyaan mengenai layanan pelanggan. Data mining adalah suatu istilah yang digunakan untuk menemukan pengetahuan yang tersembunyi di dalam database. Data mining merupakan proses semi otomatik yang menggunakan teknik statistik, matematika, kecerdasan buatan, dan machine learning untuk mengekstrasi dan menidentifikasi informasi pengetahuan potensial dan berguna yang bermanfaat yang tersimpan di dalam database besar [ 3]. Data mining adalah kegiatan menemukan pola yang menarik dari data dalam jumlah besar, data dapat disimpan dalam database, data wareh ouse, atau penyimpanan informasi lainnya. Data mining berkaitan dengan bidang ilmu-ilmu lain, seperti database system, data warehousing, statistik, machine learning, information retrieval, dan komputasi tingkat tinggi. Selain itu, data mining didukung ol eh ilmu lain seperti neural [6] network, pengenalan pola, spatial data analysis, image database, signal.  Klasifikasi  adalah suatu fungsionalitas data mining yang menghasilkan  model untuk memprediksi kelas atau kategori dari objek-objek didalam basis data . Klasifikasi merupakan proses yang terdiri dari dua tahap, yaitu tahap pembelajaran dan tahap pengklasifikasian. Pada tahap pembelajaran, sebuah algoritma 
klasifikasi akan membangun sebuah model klasifikasi dengan cara menganalisis training data. Tahap pembelajaran dapat juga dipandang sebagai tahap pembentuakan fungsi atau pemetaan Y=F(X) dimana Y adalah kelas hasil prediksi dan X adalah tuple yang ingin diprediksi kelasnya. Selanjutnya pada tahap pengklasifikasian, model yang telah dihasilkan akan diguna kan untuk melakukan pengklasifikasian.  klasifikasi adalah proses pencarian sekumpulan model yang menggambarkan dan membedakan kelas data dengan tujuan agar model tersebut dapat digunakan untuk memprediksi kelas dari  suatu obyek yang belum diketahui kelasnya.  Naive Bayes merupakan salah satu metode machine learning yang menggunakan perhitungan probabilitas. Konsep dasar yang digunakan oleh Naive bayes adalah Teorema Bayes, yaitu 
melakukan klasifikasi dengan melakukan perhitungan nilai probab ilitas p C c D d ( | ) = = i j , yaitu probabilitas kategori ci jika diketahui dokumen dj. Klasifikasi dilakukan untuk menentukan kategori c ï¥ C dari suatu dokumen d ï¥ D dimana C = {c1, c2, c3, â€¦, ci} dan D = {d1, d2, d3, â€¦, dj} . Penentuan dari kategori sebuah dokumen dilakukan dengan mencari nilai maksimum dari p C c D d ( | ) = = i j pada P={ p C c D d ( | ) = = i j | c ï¥ C dan d ï¥ D}. Nilai probabilitas p C c D d ( | ) = = i j dapat dihitung dengan persamaan dengan p D d C c ( | ) = = j i merupakan nilai probabilitas dari kemunculan dokumen dj jika diketahui 
dokumen tersebut berkategori ci, p C c ( ) = i adalah nilai probabilitas kemunculan kategori ci, dan p D d ( ) = j adalah nilai probabilitas kemunculan dokumen dj. NaÃ¯ve Bayes mengangga p sebuah dokumen sebagai kumpulan dari kata-kata yang menyusun dokumen tersebut, dan tidak memperhatikan urutan kemunculan kata pada dokumen, sehingga perhitungan probabilitas p D d C c ( | ) = = j i dapat dianggap sebagai hasil perkalian dari probabilitas  kemunculan kata-kata pada dokumen dj. Sebuah dokumen dapat dituliskan sebagai dj = {w1j, w2j, w3j, â€¦, wkj}, sehingga probabilitas p C c D d ( | ) = = i j dapat dituliskan Rapidminer merupakan platform  perangkat lunak yang dikembangkan oleh perusahaan de ngan nama yang sama, yang menyediakan lingkungan terpadu untuk pembelajaran mesin ( machine learning ), pembelajaran mendalam ( deep learning ), penambangan text ( text mining ), dan analisis prediktif ( predictive analytic ). Aplikasi ini digunakan untuk aplikasi  bisnis dan komersial serta untuk penelitian, pendidikan, pelatihan, pembuatan prototype dengan cepat, dan pengembangan aplikasi serta mendukung semua langkah proses pembelajaran mesin termasuk persiapan data, visualisasi hasil, validasi dan pengoptimalan.[3] 
 
III. METODE PENELITIAN  
Adapun teknik pengumpulan data merupakan suatu cara yang dilakukan oleh peneliti untuk memperoleh data-data yang diperlukan. Dalam penelitian ini teknik yang digunakan antara lain sebagi berikut :  
1. Survey  
Survey penelitian dilakukan dengan meminta ijin kepada kepala sekolah menengah atas 1 negeri plumbon  
2. Sumber data  
Sumber data pada penelitian ini menggunakan Data Primer  Metode analisis data yang digunakan di penelitian ini adalah analisis deskriptif dalam menyeleksi data kuantitatif. Dalam fungsinya analisis deskriptif digunakan untuk mendeskripsikan atau memberi gambaran dari data yang terkumpul dari fakta fakta yang ada, data yang dimaksud adalah data sekunder  yang berupa data kuantitatif yang bentuk angka-angka dapat digunakan untuk operasi matematika.  
Metode pengembangan data mining yang digunakan untuk menganalisis data dalam penerapan data mining ini menggunakan proses tahapan knowledge disc overy in databases (KDD) yang terdiri dari Data, Data Cleaning,  Data transformation, Data mining, Pattern evolution, knowledge.  
berikut merupan hal â€“ hal yang perlu di lakukan dalam penelitian berdasarkan tahapan knowledge discovery in databases :  
1. Data  
Data merupakan sekumpulan data operasional yang diperlu sebelum dilakukan sebelum tahap penggalian informasi dalam Knowledge Discovery Database (KDD) dimulai.  
2. Data Cleaning  
Proses data cleaning merupakan proses Pembersihan data yang bertujuan untuk menghila ngkan data yang tidak memiliki nilai (null), data yang salah input, data yang tidak relevan, duplikat data dan data yang tidak konsisten  
3. Data transformation  
Data transformation dilakukan dengan memberikan inisialisasi terhadap data yang memiliki nilai nominal menjadi bernilai numerik.  
4. Data Mining.  
Pada fase ini yang dilakukan adalah menerapkan algoritma atau metode pencarian pengetahuan. Ini adalah langkah penting di mana teknik kecerdasan diterapkan untuk mengekstrak pola informasi yang berpotensi berguna  dari data yang dipilih.  
5. evaluation  
Pada tahap evaluasi, akan diketahui apakah hasil daripada tahap data mining dapat menjawab tujuan yang telah ditetapkan. Untuk itu akan dilakukan profilisasi pada setiap cluster yang telah terbentuk, untuk diketahui karakteristik pada kelompok tersebut. Disamping itu untuk diketahui kesesuaian dengan jalur perminatan akan dilakukan analisis lebih lanjut untuk dihubungkan dengan atribut perminatan, Sehingga diharapkan mendapatkan informasi atau pola yang berguna sebagai acuan pemutakhiran data.  
6. Knowledge  
Tahap terakhir dari proses data mining adalah bagaimana memformulasikan keputusan atau aksi dari hasil analisis yang didapat.  
 
IV. HASIL DAN PEMBAHASAN  
Populasi pada penelitian ini yang dilakukan pada sekolah menengah atas negeri 1 plumbon kabupaten cirebon dengan menggunakan kelas X (Sepuluh), Kelas XI (Sebelas) dan Kelas XII (Dua Belas) dengan jumlah siswa perempuan sebanyak 632 dan siswa laki laki sebanyak 266 jadi total siswa sebanyak 898 siswa. Simple random sampling atau pengambilan sampel acak sederhana adalah teknik penarikan sampel yang memberikan kesempatan yang sama bagi setiap anggota populasi. Teknik sampling yang digunakan pada penelitian ini menggunakan random sampling artinya mengambil beberapa sample dari kelompok kelas X (Sepuluh) sebanyak 90 sample, Kelas XI (Sebelas) sebanyak 90 sample dan Kelas XII (Dua 
Belas) sebanyak 90 sample. Maka sample yang digunakan adalah sebanyak 270. Data preprocesing bertujuan untuk menganalisa data dari kuisoner yang telah diisi oleh siswa, dengan 
beberapa atribut umur, jenis kelamin, kelas,  apakah menggunakan handphone di 3 bulan terakhir, apakah menggunakan laptop di 3 bulan terakhir, apakah mengakses internet.  Dari data tersebut di peroleh sebagai berikut :   
Tabel 1 Data Keinginan konsumen   
Untuk mempermudah proses menganalisa data menggunakan algorita naive bayes maka perlu dilakukan data cleaning atau preprocesing, dengan tujuan menghilangkan noise atau missing value.  Dari preprocesing dari data sebanyak 270 maka yang dapat digunakan ialah 196 dari 196 tersebut 70% akan 
dijadikan dataset latih dan 305 dijadikan dataset uji.  
Data transformation dilakukan dengan memberikan inisialisasi terhadap data yang memiliki nilai nominal menjadi bernilai numerik. Pada penelitian ini  mengganti jenis type data menjadi integer bertujuan untuk memudahkan dalam pengelompokan.  Data yang sudah diolah kemudian diuji dengan menggunakan aplikasi rapidminer.  
No Umur Jenis Kelamin Kelas Tempat tinggal gunakan HP Gunakan Laptop Akses Internet
1 17 Laki Laki 10 Pedesaan tidak ya ya
2 17 Perempuan 10 Perkotaan ya ya tidak
3 18 Perempuan 11 Pedesaan tidak ya ya
4 19 Laki Laki 12 Perkotaan ya tidak ya
5 17 Perempuan 10 Perkotaan ya ya tidak
6 17 Perempuan 10 Perkotaan ya ya tidak
7 18 Perempuan 11 Pedesaan tidak ya ya
8 17 Perempuan 10 Pedesaan ya ya ya
9 17 Laki Laki 10 Perkotaan tidak tidak tidak
10 18 Perempuan 11 Pedesaan tidak tidak tidak
â€¦.â€¦. â€¦. â€¦. â€¦. â€¦. â€¦. â€¦. 
Gambar  1 Desain Datamining   
Berdasarkan gambar diatas menjelaskan bahwa proses desain datamining, pada tahap ini ialah melakukan drag and drop data set yang ada di repository ke dalam menu bar proses.    
Gambar  2 Hasil Akurasi   
Berdasarkan gambar di atas menjelaskan bahwa akurasi pada penelitian ini sebesar 89,83% dengan rincian detail sebagai berikut :  
a. Hasil Prediksi Ya dan ternyata Ya sebanyak 34.  
b. Hasil Prediksi Ya dan ternyata Tidak sebanyak 6.  
c. Hasil Prediksi tidak dan ternyata Ya sebanyak 0.  
d. Hasil Prediksi tidak dan ternyata tidak sebanyak 19.  
Tabel . Nilai Confidence 
Berdasarkan tabel diatas menjelasan Data statistik hasil dari penerapan algoritma naive bayes menjelaskan yang tidak ke tidak  sebanyak  19 siswa, dari data 19 tersebut terdiri dari rata-rata umur 18 tahun. Kemudian rata-rata yang tidak ke tidak  menggunakan internet yang jenis kelaminnya mayoritas atau seluruh adalah perempuan. Rata-rata yang tidak ke tidak  menggunakan internet adalah kelas XI (sebelas). Sedangkan mayoritas alamatnya pedesaan. Data statistik hasil dari penerapan algoritma naive b ayes menjelaskan yang tidak ke ya  sebanyak  6 siswa, dari data 6 tersebut terdiri dari rata-rata umur 17 tahun. Kemudian rata-rata yang tidak ke ya menggunakan internet yang jenis kelaminnya mayoritas atau seluruh adalah Laki Laki. Rata-rata yang tidak ke  ya menggunakan internet adalah kelas X (sepuluh). Sedangkan mayoritas alamatnya perkotaan. Data statistik hasil dari penerapan algoritma naive bayes menjelaskan yang ya ke ya  sebanyak  34 siswa, dari data 34 tersebut terdiri dari rata-rata umur 17 tahun sebanyak 27 siswa dan umur 19 tahun sebanyak 7 siswa. Kemudian rata -rata yang ya ke ya menggunakan internet yang jenis kelaminnya laki laki sebanyak 7 dan Perempuan Sebanyak 19 siswa. Rata-rata yang ya ke ya menggunakan internet adalah 
kelas X (sepuluh) se banyak 27 siswa dan kelas 12 sebanyak 7 siswa. Sedangkan mayoritas alamatnya perkotaan sebanyak  18  dan  alamat dari pedesaan sebanyak 6.  

V. KESIMPULAN  
Dari hasil penelitian yang telah dilakukan,  penulis dapat menarik beberapa kesimpulan sebagai berikut  
a. Penerapan model klasifikasi metode naive bayes adalah sebagai berikut: 
1) Menginput data latih pada rapid miner, 
2) Melakukan Data Selection & Cleaning, 
3) Melakukan Data Transformation, 
4) Mengolah Data Mining, 
5) Melakukan Interprotation.  
b. Akurasi pada pene litian ini sebesar 89.83% sebagai berikut: 1) Hasil Prediksi Ya dan ternyata Ya 
sebanyak 34. Hasil Prediksi Ya dan ternyata Tidak sebanyak 6. Hasil Prediksi tidak dan ternyata Ya sebanyak 0. Hasil Prediksi tidak dan ternyata tidak sebanyak 19, 2) hasil dar i prediksi dengan uji 59 data baru maka mendapatkan  hasil ya sebanyak  40 siswa dan tidak ada  19 siswa.  
c.  
. 
Nogunakan 
HPprediction 
(gunakan HP)confidence 
(tidak)confidence (ya) Umur Jenis Kelamin KelasTempat 
tinggalGunakan 
LaptopAkses 
Internet
1 ya ya0.02501981
5842730535 0.9749801841572695 17.0 Perempuan 10.0 Perkotaan ya ya
2 ya ya0.02971781
03034365370.9702821896965634 17.0 Perempuan 10.0 Perkotaan tidak tidak
3 ya ya0.01680561
47429746020.9831943852570253 19.0 Laki Laki 12.0 Perkotaan tidak ya
4 tidak tidak0.93307312
50433630.06692687495663693 18.0 Perempuan 11.0 Pedesaan ya ya
5 ya ya0.01878439
31836408180.9812156068163592 17.0 Perempuan 10.0 Perkotaan ya tidak
6 tidak tidak0.93307312
50433630.06692687495663693 18.0 Perempuan 11.0 Pedesaan ya ya
7 ya ya0.29546174
752782150.7045382524721785 17.0 Perempuan 10.0 Pedesaan ya ya
8 ya ya0.02971781
03034365370.9702821896965634 17.0 Perempuan 10.0 Perkotaan tidak tidak
9 ya ya0.01680561
47429746020.9831943852570253 19.0 Laki Laki 12.0 Perkotaan tidak ya
10 tidak tidak0.93307312
50433630.06692687495663693 18.0 Perempuan 11.0 Pedesaan ya ya
â€¦.â€¦. â€¦. â€¦. â€¦. â€¦. â€¦. â€¦. â€¦. â€¦. â€¦.

DAFTAR PUSTAKA  
Format dasar untuk buku : 
[1]  Asosiasi Penyelenggara Jasa Internet Indonesia (APJII), """"Survei APJII yang Ditunggutunggu, Penetrasi Internet Indonesia 2018,"""" Buletin APJII , p. 1, Mei 2020  
[2]  Asosiasi Penyelenggara Jasa Internet Indonesia, """"Penetrasi dan Profil Perilaku Pengguna Internet di Indonesia,"""" Asosiasi Penyelenggara Jasa Internet Indonesia, Jakarta, Infografis 2019.  
[3]  Ryan R. Nurrahman, """"Analisis Faktor -Faktor yang Mempenharuhi Kepala Rumah Tangga Jawa Timur dalam Mengakses Internet Tahun 2017,"""" Institut Teknologi Sepuluh No pember, Surabaya, Tugas Akhir 2017.  
[4]  Octavia Dian Pratama Nia Anggraini, """"Analisis Faktor -Faktor yang Mempengaruhi Anak-Anak dan Remaja di Jawa Timur Dalam Mengakses Internet Menggunakan Regresi Logistik Biner,"""" Institut Teknologi Sepuluh Nopember, Sur abaya, Tugas Akhir 2019.  2018.  
[5]  Budi Santosa, Data Mining : Teknik Pemanfaatan Data untuk Keperluan Bisnis/Studi , 1st ed. Yogyakarta: Graha Ilmu, 2007.  
[6]  Darmawan, Rudi. (2008). Modul Teknologi Informasi dan Komunikasi. Solo: Hayati.  
[7]  Gunarsa,  Singgih. (2004). Psikologi Perkembangan Anak dan Remaja. Jakarta: BPK Gunung Mulia.  
[8]  Haryono, H. (2012). Mendayagunakan Internet, Edisis Revisi. Surabaya: Hi-Fest Publishing.  
[9]  Haryono, H (2006). Mendayagunakan Internet. Surabaya: Hi-Fest Publishing.",klasifikasi,naive bayes,data primer metode analisis,akurasi
Klasifikasi dan Klastering Penjurusan Siswa SMA Negeri 3 Boyolali,"Klasifikasi dan Klastering Penjurusan Siswa SMA Negeri 3 Boyolali

Yusuf S. Nugroho, Syarifah N. Haryati

ABSTRAK
SMA N 3 Boyolali merupakan salah satu sekolah menengah di kota Boyolali yang saat ini telah memiliki 2 jurusan yaitu IPA dan IPS. Penjurusan siswa ini dapat mengarahkan peserta didik agar lebih fokus dalam mengembangkan kemampuan diri dan minat yang dimiliki. Pemilihan jurusan yang tidak tepat bisa sangat merugikan siswa terhadap minat dan karir mereka di masa mendatang. Dengan penjurusan tersebut diharapkan dapat memaksimalkan potensi, bakat atau talenta individu, sehingga dapat memaksimalkan nilai akademisnya. Berdasarkan latar belakang tersebut, maka dengan menerapkan teknik data mining diharapkan dapat membantu siswa untuk menentukan jurusan yang tepat sesuai dengan kriteria yang ditetapkan. Adapaun teknik data mining yang digunakan dalam penentuan jurusan ini menggunakan 3 buah metode yaitu Algoritma C4.5, Naive Bayes dan Algoritma K-Means. Sedangkan atribut yang digunakan terdiri dari Gender, Minat, Rata-rata nilai IPA, Rata-rata nilai IPS, nilai Psikotest IPA, nilai Psikotest IPS, Asal Sekolah dan Jurusan. Analisis  dilakukan dengan bantuan aplikasi RapidMiner 5 untuk mengetahui nilai-nilai perbandingan terhadap metode yang digunakan. Hasil penelitian menggunakan perbandingan 3 metode menunjukkan bahwa berdasarkan nilai precision, metode naive bayes lebih baik dibandingkan dengan metode yang lain dengan nilai 77,51%. Sedangkan berdasarkan nilai recall dan accuracy, decision tree lebih baik dibandingkan dengan  metode yang lain dengan nilai recall sebesar 90,80% dan nilai accuracy sebesar 79,14%. Variabel yang paling berpengaruh dalam menentukan penjurusan yaitu rata-rata nilai IPA sehingga perlu dijadikan pertimbangan bagi pihak sekolah untuk menentukan jurusan siswa.                                                                
Kata Kunci: algoritma C4.5, algoritma K-Means, data mining, jurusan SMA, naive bayes                                                                
1. PENDAHULUAN                                  
Kemajuan teknologi informasi telah menyebabkan banyak orang dapat memperoleh data dengan mudah bahkan cenderung berlebihan. Data tersebut semakin lama semakin banyak dan terakumulasi, akibatnya pemanfaatan data yang terakumulasi tersebut menjadi tidak optimal [1]. Sebagai contoh perusahaan retail yang akan memberikan brosur penawaran barang-barang yang dijual ke pelanggan sesuai basis data pelanggan yang mereka punya. Jika perusahaan retail tersebut mempunyai satu juta data pelanggan dan masing-masing pelanggan tersebut dikirimkan sebuah brosur penawaran dimana biaya pengiriman brosur tersebut adalah dua ribu rupiah, maka biaya yang akan dikeluarkan oleh perusahaan tersebut adalah dua juta rupiah per bulan. Dari penggunaan dana tersebut mungkin hanya sepertiganya atau bahkan 8% saja yang secara efektif  membeli penawaran tersebut [2]. SMAN 3 Boyolali yang berdiri sejak tahun 1989 merupakan salah satu Sekolah Menengah Atas di Kota Boyolali yang terletak di Jalan Perintis Kemerdekaan, Pulisen, Boyolali. Saat ini SMA tersebut telah memiliki dua jurusan yaitu IPA dan IPS. Penjurusan siswa ini bertujuan untuk mengarahkan peserta didik agar lebih fokus mengembangkan kemampuan diri dan minat yang dimiliki. Jurusan yang tidak tepat bisa sangat merugikan siswa dan karirnya di masa mendatang. Dengan penjurusan tersebut diharapkan dapat memaksimalkan potensi, bakat atau talenta individu, sehingga juga akan memaksimalkan nilai akademisnya. Penentuan jurusan ini akan berdampak terhadap kegiatan akademik selanjutnya dan mempengaruhi pemilihan bidang ilmu atau studi bagi siswa-siswi yang ingin melanjutkan ke perguruan tinggi nantinya. Penentuan jurusan yang dilakukan selama ini mempunyai banyak kelemahan, antara lain berdasarkan keinginan siswa tanpa melihat latar belakang nilai akademisnya saja. Sehingga jurusan yang dipilih terkadang menjadi masalah bagi siswa di kemudian hari, sebagai contoh nilai akademik yang tidak maksimal, pemilihan program studi saat melanjutkan ke jenjang perguruan tinggi yang terkendala akibat jurusan SMA yang tidak sesuai, dan lain-lain. dalam data mining  (DM), dapat digali suatu informasi strategis yang dapat digunakan untuk menentukan penjurusan siswa. Informasi hasil analisis dapat digunakan untuk menemukan peluang-peluang yang baru serta menemukan rencana strategis dalam proses dilakukan oleh manusia masih memiliki keterbatasan, terutama pada kemampuan manusia dalam menampung jumlah data yang ingin diolah. Selain itu bisa juga terjadi kesalahan akibat ketidaktelitian yang dilakukan. Salah satu cara mengatasi masalah ini adalah dengan menggunakan teknik data mining  yang bisa digunakan untuk pengolahan data menjadi sumber informasi strategis dengan metode NODVLÃ€NDVLGDQNODVWHULQJ'DWDPLQLQJGDSDWPHPEDQWXsebuah organisasi yang memiliki data melimpah untuk memberikan informasi yang dapat mendukung pengambilan keputusan [3]. Dalam bidang analisis perusahaan dan manajemen resiko, data mining digunakan untuk merencanakan keuangan dan evaluasi aset, merencanakan sumber daya (resources planning ) dan memonitor persaingan [4]. Berdasarkan permasalahan tersebut, maka dalam penelitian ini dilakukan perbandingan 3 metode untuk penjurusan siswa menggunakan teknik data mining , yaitu metode decision tree  dengan algoritma C.4.5, naive bayes dan clustering  dengan algoritma k-means. Hasil yang diperoleh dapat memberikan informasi strategis bagi siswa yang dapat mendukung keputusan untuk menentukan jurusan serta memudahkan bagi pihak sekolah untuk mengarahkan siswa dalam hal penjurusan tersebut.                                                                
2. METODE                                                
2.1 PENENTUAN ATRIBUTE                                
Atribut-atribut yang digunakan untuk perbandingan metode dalam data mining  ini ditentukan sesuai dengan kebutuhan analisis. Adapun daftar atribut yang digunakan dapat dilihat pada tabel 1. Ada dua jenis variabel dalam proses ini, yaitu:                                                        
a) Variabel dependen (Y)                        
Variabel dependen (Y) adalah variabel yang nilainya tergantung atau terikat berdasarkan nilai-nilai variabel lainnya.                                                 
b) Variabel independen (X)                        
Variabel independen (X) adalah variabel yang nilainya tidak tergantung dari nilai-nilai variabel lainnya. 7DEHO  Keterangan atribut yang digunakan $WULEXW -HQLV9DULDEOH
Jurusan Y                                        
Gender X1                                        
Minat X2                                        
Rata-rata IPA X3                                
Rata-rata IPS X4
Psikotes IPA X5
Psikotes IPS X6                                        
Asal sekolah X7                                                
2.2 PENENTUAN JUMLAH SAMPLE                        
Untuk mendapatkan sampel yang dapat menggambarkan dan mewakili jumlah populasi menggunakan bantuan metode slovin dengan nilai maksimal e = 5%. Metode slovin dalam [5] ditunjukkan pada persamaan 1.  
                        
Keterangan:                                                 
n  = jumlah sampel N = jumlah keseluruhan data / populasi e   = galat kesalahan (ditentukan sebesar 5%)                
2.3  PENGUMPULAN DATA                                
Jumlah data siswa SMAN 3 Boyolali selama 5 tahun diketahui sebanyak 1240 siswa. Dengan menggunakan persamaan 1, maka dapat dihitung jumlah sampel yang diambil yaitu sebanyak 302 siswa yang digunakan data sampling .                        
2.4 ANALISIS DATA                                
Tahap perbandingan metode data mining  dilakukan dengan melakukan perhitungan menggunakan 3 algoritma yaitu algoritma C4.5, Naive Bayes , dan K-Means . Algoritma C4.5 merupakan salah satu algoritma dalam metode decision tree  yang dihitung dengan penentuan atributnya menggunakan information gain  berdasarkan entropi dari masing-masing atribut yang telah ditentukan dengan persamaan 2 dan 3 [6].
-2                                                
-3                                                
Sementara itu, algoritma naive bayes  merupakan SHQJNODVLÃ€NDVLDQGHQJDQPHWRGHSUREDELOLWDVGDQVWDWLVWLN untuk memprediksi peluang di masa depan [7]. Adapun algoritma ini dapat dihitung menggunakan persamaan 4.                

Sedangkan algoritma K-Means  merupakan salah satu metode clustering  non-hirarki yang mengelompokkan data 
nN                                                
ne=+12                                                
Entropy y p p p p p p nn ( ) log log ... log=âˆ’ âˆ’ âˆ’ âˆ’ 12 122 2 2                                                
gain y A entropy yyc                                
yentropy yc                                                
c nilai A(, ) () ( )                                
()=âˆ’âˆ‘                                        
âˆˆ                                                
PS XPX H PH                                        
PX(| )(|) . ()                                        
().ODVLÃ€NDVLGDQ.ODVWHULQJ3HQMXUXVDQ6LVZD60$1HJHUL%R\\RODO L.+$=$1$+,1)250$7,.$_2QOLQH,661         9RO,1R_'HVHPEHU *DPEDU 
Probabilitas penjurusan siswa menggunakan Naive Bayes
3.3 KLASTERING PENJURUSAN SISWA                        
Hasil klastering menunjukkan bahwa kelompok penjurusan siswa berjumlah 5 klaster dengan masing-masing jumlah data berbeda antara satu klaster dengan klaster yang lainnya seperti ditunjukkan pada gambar 3. Berdasarkan pembagian klaster tersebut dapat dilihat dalam bentuk satu atau lebih klaster [8]. Menurut [1], metode K-Means  dapat mempartisi data ke dalam cluster sehingga data yang memiliki karakteristik yang sama dikelompokkan ke dalam satu cluster yang sama dan data yang mempunyai karateristik yang berbeda dikelompokan ke dalam cluster yang lain. Pembagian kelompok klaster menggunakan persamaan Euclidean distance space  (persamaan 5) yang sering digunakan dalam perhitungan jarak, hal ini dikarenakan hasil yang diperoleh merupakan jarak terpendek antara dua titik yang diperhitungkan.                        
-5                                                                
3. HASIL                                                
3.1 POHON KEPUTUSAN PENJURUSAN SISWA                
+DVLO SURVHV NODVLÃ€NDVL SHQMXUXVDQ VLVZD GHQJDQ
algoritma C4.5 ditunjukkan pada gambar 1. Berdasarkan hasil pohon keputusan pada gambar 1, dapat dilihat bahwa atribut yang memiliki pengaruh paling tinggi untuk PHQHQWXNDQNODVLÃ€NDVLSHQMXUXVDQVLVZDDGDODKQLODLUDWDrata IPA. Hal ini ditunjukkan dengan variabel tersebut yang menempati sebagai simpul akar ( root node ).*DPEDU3RKRQNHSXWXVDQXQWXNNODVLÃ€NDVLSHQMXUXVDQVLVZD
*DPEDU3RKRQNHSXWXVDQXQWXNNODVLÃ€NDVLSHQMXUXVDQVLVZD
3.2 DISTRIBUSI PROBABILITAS PENJURUSAN SISWA        
'LVWULEXVL GDWD NODVLÃ€NDVL SHQMXUXVDQ VLVZD
menggunakan naive bayes  berdasarkan nilai rata-rata IPA dan IPS ditunjukkan pada gambar 2. Gambar tersebut menunjukkan bahwa distribusi terbanyak untuk jurusan IPS berasal dari siswa yang memiliki nilai rata-rata IPA         
QLODLÂ”GDQQLODLUDWDUDWD,36QLODLÂ”        
du x x ik jk kp                                        
#NAME?                                        
=âˆ‘()2                                
1                                                
bahwa klaster yang memiliki anggota terbanyak adalah klaster 3 yaitu sebanyak 109 dari 302 data, sedangkan yang memiliki anggota paling sedikit adalah klaster 2 yaitu sebanyak 16 dari 302 data.                                        
*DPEDU Cluster Model Text View  menggunakan K-Means        

4. DISKUSI                                                
4.1 PERHITUNGAN ALGORITMA C4.5                        
Berdasarkan hasil pohon keputusan pada gambar 1 dapat diketahui bahwa rata-rata IPA memiliki memiliki pengaruh paling tinggi untuk menentukan jurusan di SMA tersebut. Hal ini ditunjukkan dengan atribut rata-rata IPA menempati sebagai root node.  Adapun rata-rata IPS sebagai internal root SHUWDPD SDGD UDWDUDWD ,3$ QLODLÂ” gender sebagai internal root pertama pada rata-rata IPA QLODL!VHGDQJNDQSDGDUDWDUDWD,3$QLODLÂ”WLGDNterdapat internal node  dikarenakan hasil entropi dari variabel tersebut adalah 0, sehingga menghasilkan leaf  node  yaitu IPS.                                                
1) Menentukan simpul akar (Root Node)                
Perhitungan nilai entrophy dan information gain setiap atribut untuk menentukan simpul akar dihitung menggunakan persamaan 2 dan 3. Atribut yang memiliki nilai information gain  paling tinggi dipilih sebagai simpul akar.
7DEHO Keterangan atribut yang digunakan        
$WULEXW 1LODL,QIRUPDWLRQ*DLQ                        
Gender 0,172                                        
Minat 0,054                                        
Rata-rata IPA 0,207Rata-rata IPS 0,023                
Psikotes IPA 0,003                                
Psikotes IPS 0,009                                        
Asal sekolah 0,011                                
Berdasarkan tabel 2 dapat diketahui bahwa atribut Rata-rata IPA memiliki nilai gain yang tertinggi. Sehingga dipilih sebagai simpul akar.2) Menentukan internal node pertama Penentuan internal node pada cabang rata-rata,3$QLODLÂ” GLGDSDWNDQ QLODL  information gain seperti  pada tabel 3. Atribut yang memiliki nilai information gain  yang tertinggi dipilih sebagai internal node. 7DEHO Nilai information gain  penentuan atribut sebagai internal node  pertama
$WULEXW1LODL,QIRUPDWLRQ*DLQ                
&DEDQJ5DWDUDWD,3$QLODLÂ”                
Gender 0,170                                        
Minat 0,063                                        
Rata-rata IPS 0,220
Psikotes IPA 0,029
Psikotes IPS 0,034                                        
Asal sekolah 0,040                                
Hasil perhitungan dalam tabel 3 dapat disimpulkan bahwa atribut Rata-rata IPS merupakan internal nodeSDGDUDWDUDWD,3$QLODLÂ”NDUHQD memiliki nilai gain yang tertinggi dibandingkan dengan atribut yang lain.
3) Menentukan internal node kedua                
Menentukan internal node  kedua  pada  rata-rata,3$QLODLÂ”GDQUDWDUDWD,36QLODLÂ”didapatkan nilai information gain  seperti pada tabel 4. Nilai information gain  dalam tabel 4 menunjukkan bahwa atribut Gender merupakan internal node  pada FDEDQJUDWDUDWD,3$GDQUDWDUDWD,36QLODLÂ”karena memiliki nilai gain yang tertinggi dibandingkan dengan atribut yang lain. 7DEHO Nilai information gain  penentuan atribut sebagai    internal node  kedua $WULEXW1LODL,QIRUPDWLRQ*DLQ &DEDQJ5DWDUDWD,3$ QLODLÂ” GDQ5DWDUDWD,36QLODLÂ”                        
Gender 0,386                                        
Minat 0,245                                        
Psikotes IPA 0,065
Psikotes IPS 0,060                                        
Asal sekolah 0,114                                        
4) Menentukan leaf  node                        
Menentukan leaf  node  pada rata-rata IPA dan IPS QLODLÂ”GHQJDQ gender  laki-laki..ODVLÃ€NDVLGDQ.ODVWHULQJ3HQMXUXVDQ6LVZD60$1HJHUL%R\\RODO L.+$=$1$+,1)250$7,.$_2QOLQH,661         9RO,1R_'HVHPEHU 7DEHO  Nilai information gain  penentuan atribut sebagai internal node  berikutnya $WULEXW1LODL,QIRUPDWLRQ*DLQ &DEDQJ5DWDUDWD,3$QLODLÂ” GDQ5DWDUDWD,36QLODLÂ”GDQ*HQGHU/DNLODNL                        
Minat 0,000                                        
Psikotes IPA 0,000                                
Psikotes IPS 0,000                                        
Asal sekolah 0,000                                        
Dari hasil dalam tabel 5 dapat disimpulkan bahwa gender  laki-laki menghasilkan leaf  node  jurusan IPS, dikarenakan hasil dari semua information gain  bernilai 0, sementara probabilitas siswa jurusan IPA dalam data tidak ada.        
4.2 PERHITUNGAN ALGORITMA NAIVE BAYES                
Menggunakan data pelatihan yang ada dan dengan menerapkan metode naive bayes maka dapat dilakukan prediksi terhadap data uji. Sebagai contoh adalah jika terdapat siswa dengan data sebagai berikut: gender laki ODNLPLQDW,36QLODLUDWDUDWD,3$QLODLÂ”QLODLUDWDUDWD,36QLODLÂ”QLODLSVLNRWHVW,3$VNRUÂ”nilai psikotest IPS skor>65, asal sekolah wilayah II, maka jurusan siswa tersebut dapat diprediksi. Tabel 6 menunjukkan nilai FRQÃ€GHQFH  atau nilai HMAP ( Hypothesis Maximum Apriori Probability ) yang dapat digunakan sebagai dasar melakukan prediksi jurusan siswa. 7DEHO  Nilai FRQÃ€GHQFH HMAP  terhadap data uji3UREDELOLW\\1LODL&RQÃ€GHQFH+0$3P (X1 = Laki-laki, X2 = IPS, X3 = QLODLÂ”         QLODLÂ”         6NRUÂ”         6NRU!         Wilayah II | Y = IPA) 0,000                                
P (X1 = Laki-laki, X2 = IPS, X3 =                 
QLODLÂ”         QLODLÂ”         6NRUÂ”         6NRU!         Wilayah II | Y = IPS) 0,000 Berdasarkan nilai HMAP yang ditunjukkan pada tabel 6 untuk masing-masing probability  terhadap jurusan, maka dapat dihasilkan nilai prediksi adalah jurusan IPS. Hal ini dapat diketahui berdasarkan nilai HMAP untuk jurusan IPS yaitu sebesar 0,0000542 yang lebih besar dibandingkan dengan nilai HMAP untuk jurusan IPA yaitu sebesar 0,000000117.        
4.3 PERHITUNGAN ALGORITMA K-MEANS                
Algoritma K-Means digunakan untuk mengetahui pola pengelompokan jurusan siswa berdasarkan nilai Distance Performance  terhadap variabel-variabel yang diajukan. Distance performance dalam metode klastering dapat dihitung jika nilai pada setiap variabel memiliki tipe numerik. Sehingga data yang digunakan dalam proses ini adalah data numerik.Pada metode ini, pengelompokan data penjurusan siswa dilakukan perhitungan dengan beberapa tahap yaitu:        
a. Menentukan jumlah klaster                        
Klaster yang diinginkan dalam proses ini ditentukan sebanyak 5 klaster (nilai k).b. Menentukan nilai centroid Tabel 6 adalah nilai centroid  dari masing-masing variabel independen pada masing-masing kelompok data.7DEHO Nilai centroid  tiap klaster        &OXVWHU1LODL&HQWURLG7LDS9DULDEHO                                                               1-60 7 9,2 10 11,6 12,4 18 7,2        
61-120 7,2 10,2 10,6 11,6 11,8 19 12,2                
121-180 6,8 9,2 9,2 11 14,6 21,2 13,2                
181-240 7,2 9,4 9,8 12 12,6 17,4 10,4                
241-302 8,8 10 7,2 11 13,6 18,6 8,8                
Tahap berikutnya adalah mencari jarak antar data untuk melakukan pengelompokan data dengan menggunakan persamaan 5. Hasil perhitungan digunakan untuk mencari nilai jarak Euclidean . Suatu data yang memiliki jarak terdekat dengan data lain maka dapat dikelompokkan menjadi satu klaster. Sehingga pada tahap ini menghasilkan sebuah model klaster ( cluster model ) untuk mengetahui kelompok-kelompok jurusan siswa berdasarkan variabel-variabel bebas yang diajukan. Gambar 3 adalah model klaster yang terbentuk.                
4.4 PERBANDINGAN TIGA METODE DI ATAS                
Perbandingan ketiga metode diperlukan dalam penelitian ini untuk mengetahui metode yang paling baik berdasarkan kriteria nilai Accuracy, Precision  dan Recall . Tabel 8 adalah nilai masing-masing kriteria pada 3 metode yang digunakan. Berdasarkan hasil perbandingan pada tabel 8 dapat disimpulkan bahwa metode Decision Tree  lebih baik digunakan untuk penelitian ini dikarenakan  memiliki nilai accuracy  dan recall yang lebih tinggi dibandingkan dengan metode lainnya. Sedangkan  metode naive bayes  memiliki nilai precision  yang lebih tinggi dibandingkan dengan metode yang lain. 7DEHO  Perbandingan 3 metode berdasarkan accuracy, precision dan recall                        
.RPSRQHQ1LODL                                        
$FFXUDF\\1LODL                                
3UHFLVLRQ1LODL                                        
5HFDOO                                                
Decision Tree 79,14% 75,51% 90,80%                
Naive Bayes 76,82% 77,51% 80,37%                        
K-Means 36,40% 64,25% 25,40%                                

5. KESIMPULAN                                        
Berdasarkan hasil penelitian yang dilakukan maka GDSDWGLVLPSXONDQWHODKGLSHUROHKNODVLÃ€NDVLSHQMXUXVDQsiswa menggunakan metode decision tree+DVLONODVLÃ€NDVL menunjukkan bahwa variabel yang paling tinggi pengaruhnya terhadap penjurusan siswa adalah nilai rata-rata IPA. Hal ini dibuktikan dengan variabel nilai rata-rata IPA menempati sebagai simpul akar pada diagram pohon keputusan. Proses klastering telah menghasilkan 5 kelompok klaster yang terdiri dari klaster 0 sampai dengan klaster 4 yang masing-masing terdiri dari 24, 53, 16, 109, dan 100 siswa dengan total 302 data siswa. Klaster yang memiliki anggota terbanyak adalah klaster 3, sedangkan yang memiliki anggota paling sedikit adalah klaster 2. Berdasarkan nilai accuracy  dan recall, metode decision tree lebih baik dibandingkan dengan metode yang lain dengan nilai accuracy  sebesar 79,14% dan nilai recall sebesar 90,80%.  Berdasarkan nilai precision , metode naive bayes  lebih baik dibandingkan dengan metode yang lain dengan nilai 77,51%.                                                                
DAFTAR PUSTAKA                                                
>@ <61XJURKRDQG6HW\\DZDQ.ODVLÃ€NDVL0DVD6WXGLMahasiswa Fakultas Komunikasi dan Informatika, Jurnal Komunikasi dan Teknologi Informasi (KomuniTi) ISSN: 2087-085X, Volume VI No. I Maret, 2014.
[2]  P . BÃ¼hlman and B. Yu, Analyzing Bagging, The Annals of  Statistics, Vol. 30 no. 4, hal 927-961, 2002.        
[3]  D. Kiron, R. Shockley, N. Kruschwitz, G. Finch, and M. Haydock, Analytics: The Widening Divide, MIT Sloan Management Review, 53(2), 1-22, 2012.                        
[4] D. Anggraini, Analisis Perubahan Kelompok Berdasarkan Perubahan Nilai Jual Pada Bloomberg Market Data dengan Menggunakan Formal Concept Analysis, Report Paper, 2009.
[5] Y . S. Nugroho, Analisis Faktor-Faktor Yang Mempengaruhi Tingkat Daya Beli Konsumen Terhadap Listrik Pada Sektor Rumah Tangga: Studi Kasus Kota Salatiga. Thesis, Universitas Gadjah Mada, 2009.                                        
[6] Ranny dan Budi, Pemilihan Diet Nutrien bagi Penderita Hipertensi Menggunakan Metode .ODVLÃ€NDVL'HFLVLRQ7UHH-XUQDO7HNQLN,769RO No.1, 2012.                        
[7] Bustami, Penerapan Algoritma Naive Bayes untuk 0HQJNODVLÃ€NDVL 'DWD 1DVDEDK  $VXUDQVL -XUQDOPenelitian Teknik Informatika, 2013.                
[8] Y . Agusta, K-Means: Penerapan Permasalahan dan Metode Terkait, Jurnal Sistem dan Informatika Vol.3 hal : 47-60, 2007.","klasifikasi, klastering","C4.5, Naive Bayes, K-Means",siswa SMA Negeri 3 Boyolali,"recall, accuracy"
Klasifikasi Jenis Kayu Menggunakan Support Vector Machine  Berdasarkan Ciri Tekstur Local Binary Pattern,"Klasifikasi Jenis Kayu Menggunakan Support Vector Machine  Berdasarkan Ciri Tekstur Local Binary Pattern

Neneng1, Novia Utami Putri2, Erliyan Redi Susanto3  

Abstrak  
Indonesia merupakan negara yang kaya akan sumber daya alam, salah satunya adalah kayu. Kayu maupun produk dari kayu merupakan komoditas unggulan ekspor. Mengingat banyaknya jenis kayu yang memiliki tekstur yang hampir sama, maka diperlukan pemahaman untuk mengenalinya. Identifikasi jenis kayu saat ini pada umumnya masih dilakukan manusia secara visual. Kemampuan mengidentifikasi jenis kayu harus dilakukan secara ber ulang-ulang dan membutuhkan waktu proses latihan yang lama. Keterbatasan kemampuan manusia dalam mengidentifikasi jenis kayu yang belum terampil secara visual terkadang berpen garuh terhadap hasil yang diinginkan bagi dunia industri. Saat ini teknologi pengolahan citra digital telah banyak digunakan untuk melakukan klasifikasi jenis kayu berdasarkan teksturnya. Pada penelitian ini 
metode local binary pattern (LBP) digunakan untuk melakukan klasifikasi jenis kayu. Metode ini akan menghasilkan ciri tekstur yang akan digunakan sebagai masukan dalam proses pelatihan dan pengujian menggunakan support vector machine (SVM). Ciri tekstur yang digunakan dalam metode LBP ini adalah mean, standar deviasi, skewness, energi, dan entropi . Data citra jenis kayu yang digunakan dalam penelitian ini adalah jenis kayu bayur, cempaka, damar, meranti, dan merbau. Citra kayu tersebut diambil secara manual menggu nakan kamera digital dengan jarak pengambilan 20 cm . Hasil akurasi klasifikasi terhadap citra jenis kayu bayur, cempaka, damar, meranti, dan merbau dalam penelitian ini dengan jarak ke tetanggaan R=1 adalah sebesar 91,3% berada pada parameter sigma 0,3. Sedangkan hasil error terkecil hasil klasifikasi adalah sebesar 8,7%.   
 
Kata kunci:  Kayu, tekstur, SVM, Citra, LBP  
  
Abstract  
Indonesia is a country rich in natural resources, one of which is timber. Wood and wood products are the leading export commodities. Given the many types of wood that have almost the same texture, understanding is needed to recognize them. Currently, the identification of wood species is generally still done by humans visually. The ability to identify wood species must be done repeatedly and requires a long training process. The limited ability of humans to identify unskilled wood species visually sometimes affects the desired results for the industrial world. Currently, digital image processing technology has been widely used to classify wood  types based on their texture. In this study, the local binary pattern (LB P) method was used to classify wood species. This method will produce texture features that will be used as input in the training and testing process using a support vector machine (SVM). Texture features used in this LBP method are the mean, standard deviation, skewness, energy, and entropy. Image data of wood species used in this study were bayur, cempaka, damar, meranti and merbau. The wood image was taken manually using a digital camera with a distance of 20 cm . The results of the classification accuracy of the image types of bayur wood, cempaka, damar, meranti, and merbau in this study with a neighbouring distance of R = 1 were 91.3%  in the sigma parameter of 0.3. Meanwhile, the smallest error in the classification results was 8.7%. 
 
Keywords : Wood, texture, SVM, Citra, LBP          

1. Pendahuluan 
Kayu merupakan sumber kekayaan alam Indonesia yang banyak dimanfaatkan baik oleh industri kecil maupun industri besar. Dewasa ini hutan tanaman yang menanam berbagai jenis kayu baik dari jenis unggulan setempat (native species)  maupun dari jenis eksotik ( exotic species ) makin berkembang, contohnya hutan rakyat, hutan kemasyarakatan, dan hutan 
industri. Dengan demikian, maka keberagaman jenis kayu sebagai sumber bahan baku industri menjadi lebih banyak. Untuk itu, maka diperlukan pemahaman mengenai jenis-jenis kayu bagi industri pengolahan kayu maupun pihak-pihak terkait yang menggunakan kayu sebagai bahan baku [1]. 
Identifikasi jenis kayu saat ini pada umumnya masih dilakukan manusia secara visual. Kemampuan mengidentifikasi jenis kayu harus dilakukan secara berulang-ulang dan 
membutuhkan waktu proses latihan yang lama. Keterbatasan kemampuan  manusia dalam mengidentifikasi jenis kayu yang belum terampil secara visual terkadang berpen garuh terhadap 
hasil yang diinginkan bagi dunia industri. Identifikasi jenis kayu pada umumnya  dilakukan berdasarkan beberapa ciri secara umum yang dibagi ke dalam dua kelom pok yakni ciri umum dan ciri anatomi [2] .  Saat ini teknologi pengolahan citra digital telah banyak digunakan untuk melakukan  klasifikasi jenis kayu berdasarkan teksturnya. Hal ini tentu akan dapat membantu pekerjaan manusia yang dilakukan secara manual. Salah satu metode yang dapat digunakan untuk melakukan klasifikasi berdasarkan tekstur adalah local binary patern (LBP). Metode LBP adalah metode yang diperkenalkan oleh Ojala et al untuk klasifikasi ciri tekstur [3]. Keuntungan dari metode LBP  adalah invarian untuk perubahan skala abu-abu monotonik, kompleksitas 
komputasi yang rendah dan multi skala yang nyaman. Filosofi LBP adalah sederhana dan elegan dengan menyatukan metode struktur statistik dan tradisional [4]. Metode LBP pada penelitian terdahulu telah digunakan untuk deteksi  adanya cacat pada kayu. Penelitian ini dilakukan untuk menjawab permasalahan yakni proses pemilahan kayu mentah yang masih dilakukan dengan manual menggunakan tenaga manusia, sehingga membutuhkan waktu yang cukup lama dan tidak efisien. Hasil akhir menunjukkan bahwa sistem dapat mendeteksi adanya cacat pada kayu dengan tingkat akurasi tertinggi adalah 89,4%, FAR 
sebesar 7,6% dan FRR sebesar 3%, dengan waktu komputasi rata-rata sistem sebesar 0,3069 detik [5]. Klasifikasi jenis kayu jati, sengon, mahoni dan mindi pada penelitian terdahulu telah dilakukan menggunakan back-propagation neural network berdasarkan fitur Gray Level Co-Occurrence Matrices. Metode klasifikasi yang digunakan adalah Back-Propagation Neural Network serta fitur Gray Level Co-Occurrence Matrix. Hasil penelitian ini menunjukkan nilai rata-rata akurasi yaitu 96.13% [6]. Penelitian mengenai ekstraksi citra kayu juga telah dilakukan sebelumnya pada jenis kayu jati, mahoni, mindi, dan albasia untuk menentukan fitur dan arah sudut yang lebih efisien dan efektif dalam mengidentifikasi spesies kayu. Jenis fitur yang diuji dalam penelitian adalah Angular Second Moment (ASM), Contrast, IDM/Homogenitas, Entropi, K orelasi dengan arah komputasi yakni 0, 45, 90, dan 135 derajat GLCM. Hasil percobaan menunjukk an bahwa sudut yang dipilih adalah 0, 45, dan 90 derajat dan fitur adalah IDM dan Entropy [7] . Mesin pembelajaran untuk melakukan klasifikasi tekstur citra yang dapat digunakan diantaranya adalah logika fuzzy, jaringan syaraf tiruan, algoritma genetika, dan  support vector 
machine  (SVM) [8]. Penelitian terdahulu mengenai metode SVM telah dilakukan oleh Neneng, dkk [9] dan [10]. SVM dalam penelitian ini digunakan untuk melakukan klasifikasi terhadap citra daging kambing, daging kerbau, daging kuda, dan daging sapi deng an jarak pengambilan 20 cm, 30 cm, dan 40 cm. Penelitian ini menghasilkan tingkat pengenalan terbaik yakni 87,5% berada pada jarak pengambilan 20 cm dengan jarak piksel tetangga  d=2 pada arah GLCM 135 
derajat. Sedangkan penambahan kanal warna yakni hue, saturation, dan value  (HSV)  pada klasifikasi citra daging ini, menghasilkan  klasifikasi terbaik yakni 75,6% yang berada pada arah GLCM 45 derajat dengan jarak piksel tetangga d=3 dan arah GLCM 1 35 derajat dengan jarak 
piksel tetangga d=2.  Dalam penelitian ini, metode LBP dan SVM digunakan untuk melakukan klasifikasi citra lima jenis kayu yaitu bayur, cempaka, damar, meranti, dan merbau.  Citra jenis kayu tersebut diambil secara manual menggunakan kamera digital dengan jarak peng ambilan 20 cm tanpa penambahan cahaya. Jumlah data yang digunakan adalah 750 citra untuk seluruh jenis kayu dengan rincian 150 citra untuk masing-masing jenis kayu. Citra jenis kayu tersebut dimasukkan ke dalam sistem yang selanjutnya akan dihitung ciri teksturnya menggunakan  LBP. Ciri tekstur LBP yang digunakan adalah mean, standar deviasi, skewness, energi, dan entropi. Ciri tekstur tersebut selanjutnya akan di klasifikasikan menggunakan metode SVM. Untuk menghitung ciri 
tekstur LBP, perangkat lunak dikembangkan menggunakan Visual Studio 2015 dengan bahasa program C#. Sedangkan SVM menggunakan accord learning library . 
 
2. Metode Penelitian 
Kerangka penelitian yang digunakan dalam penelitian ini meliputi metode yang diusulkan, indikator, dan tujuan. Metode ekstraksi ciri tekstur yang digunakan dalam penelitian ini adalah LBP dengan indikator yaitu mean, standar deviasi, skewness, energi, dan entropi . 
Sedangkan metode klasifikasi yang digunakan adalah SVM dengan indikator yakni tipe kernel RBF dan parameter sigma. Tujuan dari penelitian ini adalah untuk mendapatkan nilai tertinggi hasil akurasi klasifikasi. Kerangka penelitian disajikan dalam gambar 1.    
Gambar 1. Kerangka penelitian  
Tahapan penelitian meliputi pengambilan citra jenis kayu, pra pengolahan, perancangan dan pembuatan aplikasi klasifikasi jenis kayu, ekstraksi ciri tekstur menggunakan 
LBP, pelatihan dan pengujian menggunakan SVM, dan hasil akhir adalah hasil klasifikasi. Tahapan penelitian dijelaskan pada pada gambar 2: 
Gambar 2. Tahapan penelitian 
Pengambilan citra jenis kayu dilakukan menggunakan kamera digital secara manual. Jarak pengambilan citra kayu adalah 20 cm dengan lensa kamera berada di atas kayu. Pengambilan citra kayu dilakukan tanpa penambahan cahaya. Jumlah citra yang digunakan dalam penelitian ini untuk masing-masing kayu bayur, cempaka, damar, meranti, dan merbau adalah 150 citra. Dengan demikian, jumlah citra untuk seluruh kayu yang digunakan adalah 750 citra.  Tahapan pra pengolahan citra memiliki serangkaian proses yaitu pemotongan citra dan 
perubahan ukuran citra. Ukuran asli citra kayu ini adalah 4000 x 6016 piksel. Selanjutnya ukuran citra asli ini dikonversi menjadi 2400 x 1700 piksel sebelum dilakukan pemotongan citra yang dibutuhkan. Ukuran pemotongan citra yang digunakan dalam penelitian ini adalah 200 x 200 piksel. Tahap pra pengolahan ini dilakukan secara otomatis menggu nakan perangkat lunak klasifikasi yang dikembangkan. Hasil pemotongan citra kayu bayur, cempaka, damar, meranti, dan merbau dengan ukuran 200 x 200 piksel disajikan dalam Gambar 3. 
Gambar 3. Hasil Pemotongan Citra Kayu 
Perangkat lunak klasifikasi jenis kayu ini dikembangkan menggunakan Visual Studio  2015 dengan bahasa programnya adalah C#, dan basis data yang  digunakan adalah Microsoft 
Acces. Perangkat lunak ini digunakan untuk melakukan pra pengolahan data, ekstraksi ciri tekstur menggunakan LBP, dan klasifikasi menggunakan SVM. Ekstraksi ciri tekstur yang dilakukan menggunakan metode LBP. Indikator ciri yang 
digunakan adalah mean, standar deviasi, skewness, energi, dan entropi. Ekstraksi ciri tekstur yang didapatkan selanjutnya akan digunakan untuk proses klasifikasi. Tahap pelatihan dan pengujian jenis kayu dalam penelitian ini dilak ukan menggunakan metode SVM. Proses pelatihan menggunakan fungsi kernel RBF deng an beberapa nilai parameter. Sedangkan proses pengujian dilakukan untuk mengklasifikasi atau menentukan jenis kayu sesuai dengan citra aslinya sehingga dapat diketahui prosenta setingkat akurasi benar dan salah terhadap hasil klasifikasi citra. Data latih untuk masing-masing citra kayu berjumlah 130 citra dengan total data latih adalah 650 citra. Sedangkan data uji untuk masing-masing citra kayu adalah 30 citra dengan total data uji sebanyak 150 citra. Hasil ekstraksi ciri LBP dari masing-masing citra kayu dijadikan sebagai data input untuk melakukan pengujian menggunakan SVM sehingga didapatkan nilai akurasi tertinggi dari proses klasifikasi. Waktu respon untuk melakukan pelatihan dan pengujian dengan total data  latih sebanyak 650 citra dan data uji sebanyak 150 citra adalah kurang lebih 1 menit. Hasil klasifikasi citra jenis kayu bayur, cempaka, damar, meranti, dan merbau akan diketahui nilai akurasi tertingginya pada nilai parameter sigma tertentu yang digunakan dalam pengujian.  

3. Hasil dan Analisis 
Hasil klasifikasi dilakukan terhadap citra kayu bayur, cempaka, damar, meranti, dan merbau dengan jumlah masing-masing 150 citra, sehingga total data seluruh adalah 750 citra. Klasifikasi dilakukan menggunakan SVM untuk mengetahui nilai akurasi ter tinggi. Hasil klasifikasi menggunakan parameter sigma 0,1 sampai dengan 6,0 dengan jarak ketetanggaan R=1, disajikan dalam tabel 1. 
Tabel 1 . Hasil klasifikasi menggunakan SVM 
Sigma  Hasil Klasifikasi % 
Sigma  Hasil Klasifikasi % 
Sigma  Hasil Klasifikasi % 
Benar Salah  Benar Salah  Benar Salah 
0,1 82 18  2,1 84 16  4,1 84 16 
0,2 90,7 9,3  2,2 84 16  4,2 83,3 16,7 
0,3 91,3 8,7  2,3 84 16  4,3 83,3 16,7 
0,4 90,7 9,3  2,4 84 16  4,4 83,3 16,7 
0,5 90 10  2,5 84 16  4,5 83,3 16,7  
0,6 89,3 10,7  2,6 84 16  
4,6 83,3 16,7 
0,7 88,7 11,3  2,7 84 16  4,7 83,3 16,7 
0,8 88,7 11,3  2,8 84 16  4,8 83,3 16,7 
0,9 86,7 13,3  2,9 84 16  4,9 83,3 16,7 
1 86 14  3 84,7 15,3  5 83,3 16,7 
1,1 86,7 13,3  3,1 84,7 15,3  5,1 83,3 16,7 
1,2 86 14  3,2 84,7 15,3  5,2 83,3 16,7 
1,3 86 14  3,3 85,3 14,7  5,3 83,3 16,7 
1,4 86 14  3,4 84,7 15,3  5,4 83,3 16,7 
1,5 86 14  3,5 84,7 15,3  5,5 83,3 16,7 
1,6 84,7 15,3  3,6 84,7 15,3  5,6 83,3 16,7 
1,7 84,7 15,3  3,7 84,7 15,3  5,7 80,7 19,3 
1,8 84,7 15,3  3,8 84,7 15,3  5,8 80,7 19,3 
1,9 85,3 14,7  3,9 83,3 16,7  5,9 80 20 
2 84 16  4 84 16  6 79,3 20,7 
Dari Tabel 1 di atas terlihat hasil klasifikasi yang paling akurat berada pada sigma 0,3 yaitu sebesar 91,3% untuk hasil klasifikasi benar dan 8,7% untuk hasil klasifikasi salah . Grafik perhitungan hasil klasifikasi tersebut disajikan pada gambar 4.  
Gambar 4. Grafik perhitungan klasifikasi 
Hasil pengujian citra kayu bayur, cempaka, damar, meranti, dan merbau dengan jumlah data masing-masing 30 citra menggunakan parameter sigma 0,3 dengan jar ak ketetanggaan R=1 disajikan dalam tabel 1.   
Tabel 1. Hasil pengujian citra kayu 
No Nama Jenis KelasJenis 
(Hasil)Kelas 
(Hasil)No Nama Jenis KelasJenis 
(Hasil)Kelas 
(Hasil)
1 Bayur_20_1.jpg Bayur 0 Bayur 0 51 Cempaka_20_114.jpg Cempaka 1 Cempaka 1
2 Bayur_20_100.jpg Bayur 0 Bayur 0 52 Cempaka_20_116.jpg Cempaka 1 Cempaka 1
3 Bayur_20_101.jpg Bayur 0 Bayur 0 53 Cempaka_20_117.jpg Cempaka 1 Cempaka 1
4 Bayur_20_103.jpg Bayur 0 Bayur 0 54 Cempaka_20_12.jpg Cempaka 1 Cempaka 1
5 Bayur_20_104.jpg Bayur 0 Bayur 0 55 Cempaka_20_120.jpg Cempaka 1 Merbau 4
6 Bayur_20_105.jpg Bayur 0 Bayur 0 56 Cempaka_20_121.jpg Cempaka 1 Merbau 4
7 Bayur_20_106.jpg Bayur 0 Bayur 0 57 Cempaka_20_122.jpg Cempaka 1 Cempaka 1
8 Bayur_20_107.jpg Bayur 0 Bayur 0 58 Cempaka_20_123.jpg Cempaka 1 Merbau 4
9 Bayur_20_108.jpg Bayur 0 Bayur 0 59 Cempaka_20_124.jpg Cempaka 1 Cempaka 1
10 Bayur_20_109.jpg Bayur 0 Bayur 0 60 Cempaka_20_134.jpg Cempaka 1 Cempaka 1
11 Bayur_20_11.jpg Bayur 0 Bayur 0 61 Damar_20_01.jpg Damar 2 Damar 2
12 Bayur_20_110.jpg Bayur 0 Bayur 0 62 Damar_20_03.jpg Damar 2 Damar 2
13 Bayur_20_111.jpg Bayur 0 Bayur 0 63 Damar_20_04.jpg Damar 2 Damar 2
14 Bayur_20_112.jpg Bayur 0 Bayur 0 64 Damar_20_05.jpg Damar 2 Damar 2
15 Bayur_20_113.jpg Bayur 0 Cempaka 1 65 Damar_20_06.jpg Damar 2 Damar 2
16 Bayur_20_115.jpg Bayur 0 Bayur 0 66 Damar_20_07.jpg Damar 2 Cempaka 1
17 Bayur_20_116.jpg Bayur 0 Bayur 0 67 Damar_20_08.jpg Damar 2 Damar 2
18 Bayur_20_118.jpg Bayur 0 Bayur 0 68 Damar_20_09.jpg Damar 2 Damar 2
19 Bayur_20_12.jpg Bayur 0 Bayur 0 69 Damar_20_10.jpg Damar 2 Damar 2
20 Bayur_20_120.jpg Bayur 0 Damar 2 70 Damar_20_101.jpg Damar 2 Damar 2
21 Bayur_20_121.jpg Bayur 0 Bayur 0 71 Damar_20_102.jpg Damar 2 Damar 2
22 Bayur_20_122.jpg Bayur 0 Bayur 0 72 Damar_20_103.jpg Damar 2 Damar 2
23 Bayur_20_123.jpg Bayur 0 Bayur 0 73 Damar_20_104.jpg Damar 2 Damar 2
24 Bayur_20_124.jpg Bayur 0 Bayur 0 74 Damar_20_105.jpg Damar 2 Damar 2
25 Bayur_20_125.jpg Bayur 0 Bayur 0 75 Damar_20_107.jpg Damar 2 Damar 2
26 Bayur_20_126.jpg Bayur 0 Bayur 076Damar_20_11.jpg Damar2Damar2
27 Bayur_20_128.jpg Bayur 0 Bayur 0 77 Damar_20_11.jpg Damar 2 Damar 2
28 Bayur_20_129.jpg Bayur 0 Bayur 0 78 Damar_20_110.jpg Damar 2 Damar 2
29 Bayur_20_131.jpg Bayur 0 Bayur 0 79 Damar_20_111.jpg Damar 2 Damar 2
30 Bayur_20_132.jpg Bayur 0 Bayur 0 80 Damar_20_112.jpg Damar 2 Damar 2
31 Cempaka_20_02.jpg Cempaka 1 Merbau 4 81 Damar_20_113.jpg Damar 2 Damar 2
32 Cempaka_20_03.jpg Cempaka 1 Merbau 4 82 Damar_20_117.jpg Damar 2 Damar 2
33 Cempaka_20_04.jpg Cempaka 1 Cempaka 1 83 Damar_20_118.jpg Damar 2 Damar 2
34 Cempaka_20_05.jpg Cempaka 1 Cempaka 1 84 Damar_20_12.jpg Damar 2 Damar 2
35 Cempaka_20_07.jpg Cempaka 1 Cempaka 1 85 Damar_20_121.jpg Damar 2 Damar 2
36 Cempaka_20_08.jpg Cempaka 1 Cempaka 1 86 Damar_20_122.jpg Damar 2 Damar 2
37 Cempaka_20_09.jpg Cempaka 1 Cempaka 1 87 Damar_20_123.jpg Damar 2 Damar 2
38 Cempaka_20_10.jpg Cempaka 1 Cempaka 1 88 Damar_20_124.jpg Damar 2 Damar 2
39 Cempaka_20_100.jpg Cempaka 1 Cempaka 1 89 Damar_20_125.jpg Damar 2 Damar 2
40 Cempaka_20_101.jpg Cempaka 1 Cempaka 1 90 Damar_20_13.jpg Damar 2 Damar 2
41 Cempaka_20_102.jpg Cempaka 1 Cempaka 1 91 Meranti_20_03.jpg Meranti 3 Cempaka 1
42 Cempaka_20_103.jpg Cempaka 1 Cempaka 1 92 Meranti_20_04.jpg Meranti 3 Meranti 3
43 Cempaka_20_104.jpg Cempaka 1 Cempaka 1 93 Meranti_20_05.jpg Meranti 3 Meranti 3
44 Cempaka_20_105.jpg Cempaka 1 Merbau 4 94 Meranti_20_06.jpg Meranti 3 Meranti 3
45 Cempaka_20_106.jpg Cempaka 1 Cempaka 1 95 Meranti_20_07.jpg Meranti 3 Meranti 3
46 Cempaka_20_108.jpg Cempaka 1 Cempaka 1 96 Meranti_20_08.jpg Meranti 3 Meranti 3
47 Cempaka_20_109.jpg Cempaka 1 Cempaka 1 97 Meranti_20_09.jpg Meranti 3 Meranti 3
48 Cempaka_20_110.jpg Cempaka 1 Cempaka 1 98 Meranti_20_10.jpg Meranti 3 Meranti 3
49 Cempaka_20_111.jpg Cempaka 1 Cempaka 1 99 Meranti_20_100.jpg Meranti 3 Meranti 3
50 Cempaka_20_113.jpg Cempaka 1 Merbau 4 100 Meranti_20_101.jpg Meranti 3 Meranti 
Dari hasil pengujian 150 citra kayu yang disajikan dalam tabel 1 di atas, terlihat ba hwa 137 citra kayu teridentifikasi benar sesuai dengan gambar aslinya, dan 13 citra teridentifikasi salah tidak sesuai dengan gambar aslinya. Dengan demikian maka pada parameter sigma 0, 3 hasil akurasi klasifikasi adalah sebesar 91,3%. 
 
4. Kesimpulan 
Kesimpulan yang didapat berdasarkan hasil pembahasan dalam penelitian ini adalah sebagai berikut: 
1. Ciri tekstur LBP yang digunakan dalam penelitian ini adalah mean, stan dar deviasi, skewness, energi, dan entropi. Tingkat keakuratan klasifikasi citra kayu bayur, cempaka, damar, meranti, dan merbau yang diambil dengan jarak 20 cm berdasarkan pengujian data menggunakan jarak ketetanggaan R=1 adalah sebesar 91,3% terletak p ada parameter sigma 0,3.  
2. Nilai error terkecil berdasarkan hasil klasifikasi citra kayu bayur, cempaka, damar, meranti, dan merbau adalah sebesar 8,7% yang berada pada parameter sigma 0,3.  
 
Daftar Pustaka 
[1] I. S. and W. A. 2008, Petunjuk Praktis Sifat-Sifat Dasar Jenis Kayu Indonesia A Handbook of Selected Indonesian Wood Species . PT Pustaka Semesta Persada. 
[2] Y. I. Mandang, R. Damayanti, T. E. Komar, and S. Nurjanah, â€œPedoman Identifikasi Kayu Ramin dan Kayu Mirip Ramin,â€ p. 54, 2008.  
[3] M. HeikkilÃ¤, M. PietikÃ¤inen, and C. Schmid, â€œDescription of interest regions with local binary patterns,â€ Pattern Recognit. , 2009, doi: 10.1016/j.patcog.2008.08.014. 
[4] Y. Mu, S. Yan, Y. Liu, T. Huang, and B. Zhou,  €œDiscriminative local binary patterns for No Nama Jenis Kelas Jenis (Hasil)Kelas 
(Hasil)No Nama Jenis KelasJenis 
(Hasil)Kelas 
(Hasil)
101 Meranti_20_102.jpg Meranti 3 Meranti 3 126 Merbau_20_08.jpg Merbau 4 Merbau 4
102 Meranti_20_103.jpg Meranti 3 Meranti 3 127 Merbau_20_09.jpg Merbau 4 Merbau 4
103 Meranti_20_104.jpg Meranti 3 Meranti 3 128 Merbau_20_10.jpg Merbau 4 Merbau 4
104 Meranti_20_106.jpg Meranti 3 Meranti 3 129 Merbau_20_100.jpg Merbau 4 Merbau 4
105 Meranti_20_107.jpg Meranti 3 Meranti 3 130 Merbau_20_101.jpg Merbau 4 Merbau 4
106 Meranti_20_109.jpg Meranti 3 Cempaka 1 131 Merbau_20_102.jpg Merbau 4 Merbau 4
107 Meranti_20_110.jpg Meranti 3 Meranti 3 132 Merbau_20_103.jpg Merbau 4 Merbau 4
108 Meranti_20_111.jpg Meranti 3 Meranti 3 133 Merbau_20_105.jpg Merbau 4 Merbau 4
109 Meranti_20_113.jpg Meranti 3 Meranti 3 134 Merbau_20_106.jpg Merbau 4 Merbau 4
110 Meranti_20_114.jpg Meranti 3 Meranti 3 135 Merbau_20_108.jpg Merbau 4 Merbau 4
111 Meranti_20_115.jpg Meranti 3 Damar 2 136 Merbau_20_109.jpg Merbau 4 Merbau 4
112 Meranti_20_116.jpg Meranti 3 Meranti 3 137 Merbau_20_11.jpg Merbau 4 Merbau 4
113 Meranti_20_118.jpg Meranti 3 Meranti 3 138 Merbau_20_110.jpg Merbau 4 Merbau 4
114 Meranti_20_12.jpg Meranti 3 Meranti 3 139 Merbau_20_111.jpg Merbau 4 Merbau 4
115 Meranti_20_120.jpg Meranti 3 Meranti 3 140 Merbau_20_113.jpg Merbau 4 Merbau 4
116 Meranti_20_121.jpg Meranti 3 Meranti 3 141 Merbau_20_115.jpg Merbau 4 Merbau 4
117 Meranti_20_123.jpg Meranti 3 Meranti 3 142 Merbau_20_116.jpg Merbau 4 Merbau 4
118 Meranti_20_125.jpg Meranti 3 Meranti 3 143 Merbau_20_118.jpg Merbau 4 Merbau 4
119 Meranti_20_126.jpg Meranti 3 Meranti 3 144 Merbau_20_119.jpg Merbau 4 Merbau 4
120 Meranti_20_127.jpg Meranti 3 Meranti 3 145 Merbau_20_121.jpg Merbau 4 Merbau 4
121 Merbau_20_02.jpg Merbau 4 Merbau 4 146 Merbau_20_127.jpg Merbau 4 Merbau 4
122 Merbau_20_03.jpg Merbau 4 Merbau 4 147 Merbau_20_13.jpg Merbau 4 Merbau 4
123 Merbau_20_04.jpg Merbau 4 Merbau 4 148 Merbau_20_131.jpg Merbau 4 Merbau 4
124 Merbau_20_06.jpg Merbau 4 Merbau 4 149 Merbau_20_134.jpg Merbau 4 Merbau 4
125 Merbau_20_07.jpg Merbau 4 Merbau 4 150 Merbau_20_137.jpg Merbau 4 Merbau 4       
human detection in personal album,â€ 2008, doi: 10.1109/CVPR.2008.4587800.  
[5] F. N. Achsani et al. , â€œDeteksi Adanya Cacat Pada Kayu Menggunakan Metode Local Binary Pattern,â€ e-Proceeding Eng. , vol. 2, no. 1, pp. 298 â€“305, 2015. 
[6] R. A. Pramunendar, D. P. Prabowo, D. Pergiwati, and K. Latifa, â€œKlasifikasi Jenis Kayu Menggunakan Back-Propagation Neural Network Berdasarkan Fitur Gray Level Co- 
Occurrence Matrix,â€ 2017.  
[7] S. Santosa, Martono, M. B. Utomo, and B. S. Budi, â€œSeleksi Arah Sudu t Komputasi dan 
Fitur GLCM pada Ekstraksi Citra Kayu Jati, Mahoni, Mindi, dan Sengon,â€ J. Wahana Tek. Sipil , vol. 23, no. 2, pp. 77 â€“87, 2018. 
[8] M. Seetha, Muralikrishna, B. L. Deekshatulu, B. L. Malleswari, Nagaratna, and  P. Hegde, â€œArtificial Neural Networks and Other Methods of Image Classification,â€ Theor. Appl. Inf. Technol. , 2008. 
[9] N. Neneng, K. Adi, and R. Isnanto, â€œSupport Vector Machine Untuk Klasifikasi Citra Jenis Daging Berdasarkan Tekstur Menggunakan Ekstraksi Ciri Gray Level Co-Occur rence 
Matrices (GLCM),â€ J. Sist. Inf. BISNIS , 2016, doi: 10.21456/vol6iss1pp1- 10. 
[10] Neneng, Y. Fernando, â€œKlasifikasi Jenis Daging Berdasarkan Analisis Citra Tekstur Gray Level Co-Occurrence Matrices ( Glcm ) Dan Warna,â€ in Seminar Nasional Sains dan Teknologi 2017 , 2017, no. Fakultas Teknik Universitas Muhammadiyah Jakarta, pp. 1 â€“7.",klasifikasi,"local binary pattern, LBP, support vector machine, SVM",citra kayu bayur,akurasi
Klasifikasi Berita Online dengan menggunakan Pembobotan TF-IDF dan Cosine Similarity ,"Klasifikasi Berita Online dengan menggunakan Pembobotan TF-IDF dan Cosine Similarity

Bening Herwijayanti1, Dian Eka Ratnawati2, Lailil Muflikhah3 

Abstrak  
Dalam klasifikasi berita online dengan menggunakan pembobotan tf-idf dan cosine similarity ini mendapatkan referensi penelitian sebelumnya mengenai klasifikasi berita online menggunakan algoritma single pass clustering , dimana data yang akan digunakan berasal dari  website  berita online  yaitu kompas.com. Karena banyaknya berita yang dimasukkan ke dalam website, sehingga terkadang berita tersebut terposting tidak sesuai dengan kategorinya. Human error  akan menjadi masalah berita yang salah posting . Selain kesalahan posting  pengelompokan berita online juga penting untuk kenyamanan user untuk mencari berita sesuai dengan kategorinya.  Menerapkan klasifikasi  berita online 
dengan menggunakan tf-idf dan cosine similarity , memerlukan proses preprocessing  yaitu tokenizing, stopword  dan stemming  dapat memperkecil term sehingga mempercepat proses perhitungan pembobotan term menggunakan tf-idf dan mempercepat proses cosine simil arity. Tujuannya adalah 
untuk mempermudahkan human error  serta mengurangi terjadinya kesalahan pengkategorian. klasifikasi  mampu mengelompokkan berita dengan tingkat akurasi sebesar 91.25%.  

Kata Kunci: klasifikasi  berita online, TF-IDF, Cosine Similarity  

Abstract  
In discussing the online news by using the weighting of tf-idf and cosine of this similarity the previous research reference on online news information using single pass clustering algorithm, where the data to be used comes from the online news website that is kompas.com. Because of the many news that is on the website, so sometimes the news is posted not in accordance with the category. Human error will be the problem of wrong news posting. In addition to posting errors online news groupings are also important for the convenience of users to search for news according to their category. Implementing online news stories using tf -idf and cosine similarities, preprocessing processesie tokenizing, stopword and stemming can reduce the term process of speeding the weighting of terms using tf -idf and accelerating the cosine process of similarity. The goal is to facilitate human error as well as reduce caution categorization. The value is able to classify news with accreditation rate of 91.25%.  

Keywords : online news classification, TF-IDF, Cosine Similarity   
 
1. PENDAHULUAN  
Dalam klasifikasi  berita online dengan menggunakan pemmbobotan tf-idf dan cosine similarity  ini mendapatkan referensi penelitian mengenai klasifkasi berita online  menggunakan algoritma single pass clustering , dimana data yang akan digunakan diambil dari salah satu website  berita online  yaitu kompas.com. Pada penelitian sebelumnya  yang dilakukan oleh Agus Zaenal Arifin dan Ari Novan Setiono  yang menjelaskan bahwa berita yang mempunyai event yang sama cenderung mengelompok menjadi satu cluster , nilai batas  atau yang disebut dengan treshold  yang paling bagus digunakan adalah 0,0175  dengan nilai recall sebesar 76% dan nilai precission sebesar 87% sehingga disimpulkan bahwa single pass clustering cukup handal untuk digunakan dalam 
mengklasifikasikan event.  Referensi berikutnya yaitu jurnal dengan judul â€œpembuatan web portal sindikasi berita Indonesia dengan klasifikasi metode single pass clustering â€ menjelaskan bahwa single pass clustering sangat tepat untuk klasifikasi dengan tingkat kemiripan berita dengan recall precesion 79% dengan nilai recall  rata-rata 76% dan precision rata-rata 87%.  Dari pengertian tf-idf dan cosine similarity dianggap cocok untuk klasifikasi  berita online . 
Karena banyaknya berita yang di masukkan  ke dalam website, sehingga terkadang berita tersebut terposting tidak sesuai dengan kategorinya . Human error  akan menjadi masalah berita yang salah posting . Selain kesalahan  posting  klasifikasi  berita online  juga penting untuk kenyamanan user untuk  mencari berita sesuai dengan kategorinya.  Seperti yang terjadi pada postingan yang ada di kompas.com 
dengan judul berita â€œ Ridwan Kamil Berikan Kadeudeuh"""" untuk Persib â€ yang diposting tanggal 21 Maret 2017 jam 21.31 WIB terdapat kesalahan kategori posting karena judul beserta isi dari artikel tersebut tersebut seharusnya masuk dalam kategori news  olahraga sedangkan yang terjadi kategori tersebut masuk kategori news  regional. Harapannya dengan dibuat sistem ini bertujuan untuk meminimallisir kesalahan dalam klasifikasi  pada berita online .  Oleh karena itu, agar tidak terjadi kesalahan dalam pengkategorian terhadap berita online  yang ada, klasifikasi pada skripsi ini akan  menerapkan suatu pengkategorian suatu berita online  dengan menggunakan pembobotan tf-idf dan cosine  similarity.  

2. LANDASAN TEORI  
2.1 Text mining  
Text mining merupakan proses analisis dalam data yang berupa teks dimana sumber data didapatkan dari dokumen ( Ronen Feldman, 2007 ). Konsep text mining  biasanya digunakan dalam klasifikasi dokumen tekstual dimana dokumen-dokumen tersebut akan diklasifikasikan sesuai dengan topik dokumen 
tersebut. Dengan bantuan text mining  suatu artikel dapat diketahui jenis kategorinya melalui kata-kata yang terdapat pada artikel tersebut. Kata-kata yang dapat mewakili isi dari artikel tersebut dianalisa dan dicocokkan pada basis data kata kunci yang telah ditentukan sebelumnya. Sehingga dengan adanya text mining  dapat membantu melakukan 
pengelompokkan suatu dokumen dengan waktu yang singkat.  Tahapan  dalam melakukan analisa pada text mining yaitu melakukan pengumpulan data kemudian melakukan ekstraksi terhadap fitur yang akan digunakan ( Ronen Feldman, 2007 ). Adapun teknik yang digunakan dalam ekstraksi fitur yaitu melakukan pembersihan data mulai dari tokenizing , stop words removal  dan stemming . Selanjutnya yaitu melakukan 
transform data dengan pembobotan terhadap term yang telah dibersihkan. Kemudian dilanjutkan dengan reduksi data . Tahap terakhir yaitu melakukan analisis  terhadap proses klasifikasi untuk merepresentasikan hasil informasi yang ditemukan.  
2.2 Procesing data  
Processing  bertujuan untuk mendapatkan dataset yang dapat diolah dengan cepat dan menghasilkan kesimpulan yang tepat.  Salah satu proses processing data yang dapat dilakukan adalah pemilihan fitur ( feature selection ). Ada beberapa tahapan dalam pemilihan fitur, antara lain: Tokenizing, merupakan tahap pemotongan string input untuk memisah kalimat menjadi kata. Stopword, Pada tahap ini dilakukan proses menghilangkan kata yang tidak penting dalam teks. Untuk proses ini diperlukan suatu kamus kata-kata yang menyimpan kata-kata yang bisa dihilangkan. Stemming, merupakan  tahapan yang melakukan proses untuk mengubah kata turunan menjadi kata dasar.  
2.3 Pembobotan Term Frequency Inverse Document Frequency (Tf-Idf) 
Data yang telah melalui tahap preprocessing  harus berbentuk numerik. Untuk mengubah data tersebut menjadi numerik yaitu 
menggunakan metode pembobotan TF-IDF. Metode Term Frequency Invers Document Frequency  (TF-IDF)  merupakan metode yang 
digunakan menentukan seberapa jauh keterhubungan kata (term) terhadap  dokumen  dengan memberikan bobot setiap kata [1]. 
Metode TF-IDF ini menggabungkan dua konsep yaitu frekuensi kemunculan sebuah kata di dalam sebuah dokumen dan inverse frekuensi dokumen yang mengandung kata tersebut  (Fitri, 
2013) . Dalam perhitungan bobot menggunakan TF-IDF, dihitung terlebih dahulu nilai TF perkata dengan bobot masing -masing kata adalah 1. Sedangkan nilai IDF diformulasikan pada Persamaan (1).  
dftdword IDF log) (ï€½
 (1)   
) (word IDFadalah nilai IDF dari setiap kata yang akan di cari, td adalah jumlah keseluruhan dokumen yang ada, df jumlah kemuculan kata pada  semua dokumen.  
2.4 Cosine Similarity  
Model ruang vektor dan pembobotan tf-idf digunakan untuk merepresentasikan nilai numerik dokumen sehingga kemudian dapat dihitung kedekatan antar dokumen. Kemiripan antar dokumen dihitung menggunakan suatu fungsi ukuran kemiripan ( similarity measure ). Semakin besar hasil fungsi similarity , maka kedua objek yang dievaluasi semakin mirip, 
demikian pula sebaliknya. Ukuran ini memungkinkan perankingan dokumen sesuai dengan kemiripan (relevansi)nya terhadap query. Kualitas hasil dari dokumen yang didapatkan sangat tergantung pada fungsi similarity  yang digunakan.  

3. PERANCANGAN SISTEM  
Pada bab  ini akan dibahas mengenai perancangan sistem, yaitu formulasi penyelesaian masalah secara sederhana, 
perancangan antarmuka pengguna, serta perancangan pengujian sistem. Gambar  merupakan diagram alir proses klasifikasi 
dokumen berita online  secara umum menggunkan pembobotan tf-idf dan cosine similarity .  
Start
Tokenizing
Stopword Removal
Stemming
Pembobotan (Tf-Idf)
Single Pass 
ClusteringBerita Online
EndHasil 
Kleasifikasi 
Gambar 1 Diagram Alir Klasifikasi Berita Online   
3.1 Tokenizing  
Tokenizing  merupakan tahap pemotongan string input untuk memisah kalimat menjadi kata  dan penghapusan karakter tanda baca, berikut merupakan asumsi dari proses tokenizing yang diambil dari salah satu data studi .  
Mulai
Masukkan 
teks berita
Cek berita yang gabung akhir 
Memisahkan setiap kata yang bergabung 
Teks 
Berita terpisah Menghilangkan tanda baca  
Gambar 2  Diagram alir Tokenizing   
3.2 Stopword Removal  
Dalam proses ini dilakukan proses menghilangkan kata yang tidak penting dalam teks. Untuk proses ini diperlukan suatu kamus kata-kata yang menyimpan kata -kata yang bisa dihilangkan  atau dengan kata lain kata â€“kata yang tidak penting .  
mulai
Proses 
pencocokan 
tokenTerm[index] 
dengan stoplist
(tokenTerm[index] == token)
(index > tokenTerm.size())false
Hapus kata Tidak Penting
Daftar kata 
Penting
akhirtrue
trueDaftar Kata dalm 
bentuk Index
FALSE 
Gambar 3  Diagram Alir Stopword Removal  
3.3 Stemming  
Proses stemming  merupakan proses yang berfungsi untuk menghilangkan imbuhan seperti awalan dan akhiran proses stemming akan  di jelaskan dalam gambar alur seperti pada gambar 4 berikut:   
mulai
Term
Hapus awalanJika kata dasar?
Kata Dasar
akhirNo
Jika kata dasar?
Hapus akhiranNoYes
Yes 
Gambar 4  Diagram Alir Stemming   
3.4 Proses Pembobotan (TF-IDF)  
Dalam perhi tungan bobot menggunakan TF-IDF, dihitung terlebih dahulu nilai TF perkata dengan bobot masing -masing kata adalah 1. Sedangkan nilai IDF diformulasikan pada persamaan 2. dimana ) (word IDF adalah nilai IDF dari setiap kata yang akan di cari, td adalah jumlah keseluruhan dokumen yang ada, df jumlah kemuculan kata pada semua dokumen. Setelah mendapat nilai TF dan IDF, maka untuk mendapatkan bobot akhir dari TF-IDF diformulasikan pada persamaan 1 dimana w  (wordi) adalah nilai bobot dari setiap kata, TF  
(wordi) adalah hasil perhitungan dari TF. IDFi adalah hasil dari perhitungan IDF. Berikut merupakan proses perhitung bobot menggunakan metode TF-IDF:  
mulai
Term
Hitung Jumlah Kemunculan 
Term Setiap Dokumen
Jumlahkah Setiap Kemuculan kata 
yang sama pada semua dokumenTF
DF
Hitung Jumlah 
Dokumen
D
IDF=DF / D
IDF
Proses 
pembobotan
W = TF * IDF
akhirBobot Term
(W) 
Gambar 5 Diagram Alir  TF-IDF  
3.5 Cosine similarity  
Dalam proses cosine similarity yang menjadi masukan adalah bobot dari term setiap data, bobot term tersebut digunakan dala proses perhitungan jarak kemiripan dengan kata klaster, 
kemudian dari setiap nilai akan menentukan centroid setiap klaster . Berikut merupakan proses perhitungan cosine similarity :  
Start
Bobot Dokumen Bobot query
Hitung Panjang Vektor 
DokumenHitung Panjang Vektor 
Query
Similarity = totalbobot /panjang vektor dokumen * panjang vektor query
Bobot Dokumen
End 
Gambar 6  diagram alir cosine similarity  

4. IMPLEMENTASI  
4.1 Implementasi  Halaman Utama  
Halaman utama merupakan halaman yang  berfungsi  untuk menampilkan judul aplikasi, dan  menu utama aplikasi, gambar 7 ini merupakan penjelasan dari implementasi halaman utama:    
Gambar 7  Implementasi Antarmuka Halaman Utama   
4.2 Implementasi Halaman Data Berita  
Halaman data berita berfungsi untuk menampilkan data berita yang menjadi data training, implementasi data berita dapat di lihat pada gambar 8 berikut.   
Gambar 8  Implementasi Antarmuka Halaman Data 
Berita   
4.3 Implementasi Halaman Data Test  
Halaman data test merupakan halaman yang berfungsi untuk menampilkan form  masukan data test berupa berita, implementasi data test dapat di lihat pada gambar 9 dan hasil data test dapat dilihat pada gambar  10 berikut:   
Gambar 9  Implementasi Antarmuka Halaman Data 
Test 
Gambar 10  Implementasi Antarmuka hasil data test   
4.4 Implemetasi Halaman klaster  
Halaman klaster  merupakan halaman yang akan menjelas kan tentang proses perhitung klaster  sampai dengan proses perhitung akurasi, implementasi halaman klaster  dapat di lihat pada gambar 11 berikut.  
Gambar 11  implementasi antarmuka klaster  
 
5. PENGUJIAN  
Hasil pengujian  akurasi  seperti pada tabel  1 
berikut:  
Tabel 1  hasil pengujian  
Pengujian  Data latih  Data uji  Akurasi  
Pengujian 1  90%  10%  80%  
Pengujian 2  80%  20%  90%  
Pengujian 3  70%  30%  100%  
Pengujian 4  60%  40%  95%  
Rata-rata  91.25%   
Grafik hasil pengujian akurasi dapat dilihat pada 
gambar 12 berikut:  
Gambar 12 Grafik hasil pengujian   
5.1  Analisis Hasil Pengujian  
Berdasarkan  pengujian yang telah dilakukan  sebanyak  4 kali percobaan seperti yang sudah dilakukan pada tabel pengujian. Adapun penjelasan dari setiap percobaan adalah 
sebagai berikut:  
1. Pada  percobaan  I, peneliti  mencoba  jumlah  data training  pada  datababse  sebanyak 46 data. Dengan pembagian data latih 90% dan data uji 10% Didapatkan hasil  akurasi  sebesar 80%.   
2. Pada  percobaan  2, peneliti  mencoba  jumlah  data training  pada  datababse  sebanyak 41 data. Dengan pembagian data latih 80% dan data uji 20% Didapatkan hasil  akurasi sebanyak 90%   
3. Pada  percobaan  3, peneliti  mencoba  jumlah  data training  pada  datababse  sebanyak 36 data. Dengan pembagian data latih 70% dan data uji 30% Didapatkan hasil akurasi sebanyak 100%   
4. Pada  percobaan  4, peneliti  mencoba  jumlah  data training  pada  datababse  sebanyak 31 data. Dengan pembagian data latih 60% dan data uji 40% Didapatkan hasil akurasi sebesar 95%  Dari pengujian I, II, III, dan IV diketahui bahwa semakin banyak jumlah data uji maka semakin tinggi tingkat akurasi. Oleh karena itu hasil dari pengujian pada tabel 6.6 mempunyai rata-rata 91.25% dan mempunyai tingkat akurasi paling tinggi pada pengujian ke 3 .  

6. KESIMPULAN  
Berikut adalah kesimpulan yang dapat diambil dari hasil yang telah didapatkan dari perancangan, implementasi dan pengujian yang telah dilakukan yaitu :  
1. Untuk Menerapkan pengelompokkan berita online dengan menggunakan algoritma Single Pass Clustering  memerlukan proses preprocessing yaitu tokenizing, stopword dan stemming . Preprocessing tersebut  dapat memperkecil term sehingga  bisa mempercepat proses perhitungan pembobotan term menggunakan tf-idf dan mempercepat proses cosine similarity.  
2. Dari pengujian  I, II, III, dan IV diketahui bahwa semakin banyak jumlah data uji maka semakin tinggi tingkat akurasi. hasil rata-rata pengujian 91.25% dan mempunyai tingkat akurasi paling tinggi pada pengujian ke 3 dengan akurasi 100 %. Hal tersebut dapat terjadi  karena hasil  pada kategori data hasil sistem sesuai dengandata asli.   

DAFTAR PUSTAKA  
Arifin Agus Zainal , Setiono Ari novan (2002). Klasifikasi dokumen berita kejadian berbahasa Indonesia dengan algoritma single pass clustering, Proceeding of seminar on intelegent Technology and Its Applications (SITIA), Teknik Elektro, Institut Teknologi Sepuluh . 
Februariyanti Henry, Zuliarso Eri (2013.)Klastering dokumen berita dari web menggunakan Algoritma single pass clustering , teknologi Informasi, Universitas Stikubank.  
Februariyanti Henry, Zuliarso Eri (2012.)klastering berita online tentang bencana dengan algoritma single pass clustering, teknologi Informasi, Universitas Stikubank.  
Feldman, Ronen , Sanger, dkk. (2007). The Text Mining Handbook Advanced Appro aches in Analyzing Unstructured Data.  Cambridge University Press, New York.  
Fitri, Meisya. (2013). Perancangan Sistem Temu Balik Informasi Dengan Metode Pembobotan Kombinasi Tf-Idf Untuk Pencarian Dokumen Berbahasa Indonesia. Universitas Tanjungpura : Sema rang.  
Ifada Noor, Husni, Liyantanto Rahmady (2011). Pembuatan Web Portal Sindikasi Berita 050100150 Pengujian 1 Pengujian 2 Pengujian 3 Pengujian 4 AKURASI, Teknik Informatika,Universitas Truojoyo.  
Klampanos I A., Joemon M. J,  C. J. Keithvan Rijsbergen, (2006). Single Pass Clustering for peer-to-peer Information 
Retrieval: The Effenct Of Document Ordering, Processings of the firs international conference on scalable information systems . Lentera Kecil, (2015). pengertian media online. 
LenteraKecil.com/pengertian_media_online/. Diakses pada tanggal 20 Februari 2017.  
Mahayasa I Nyoman  , Jasa Lie , (2016) Sistem Pendukung Keputusan Perekrutan Pegawai Menggunakan Perangkingan Madm Topsis Dan  Klasifikasi Naive Bayes , Manajemen Sistem Informasi Dan Komputer Universitas Udayana, Denpasar.  
W.B. Frakes,  and Yates  Baeza, R. (1992) Information Retrieval , Data Structures and Algorithm, Prentice Hall, Englewood New Jersey . 
Zhang J., Jianfeng G., Ming Z., Jiaxing W., (2001). Improving the Effectiveness of Information Retrieval with Clustering and Fusion, Computational Linguistics and Chinese Language Processing , Vol. 6, No. 1, February 2001, pp. 109 -125.",klasifikasi,"TF-IDF, cosine similarity",data berita,akurasi
Perancangan Sistem Klasifikasi Penyakit Jantung Mengunakan Naive Bayes,"Perancangan Sistem Klasifikasi Penyakit Jantung Mengunakan Naive Bayes

Mufti Ari Bianto *1, Kusrini2, Sudarmawan3 

Abstrak  
Serangan Jantung adalah salah satu penyakit yang paling mematikan tercatat di dunia, terdapat jumlah kasus baru Penyakit Jantung sebanyak 43,32% serta jumlah kematian sebanyak  12,91%. Pada tahun 2013 jumlah penderita Penyakit Jantung di Indonesaia sejumlah 61.682 orang, pada umumnya jumlah penderita penyakit ini terus meningkat dikarenakan kurangnya pengetahuan atau informasi tentang penyakit jantung tersebut, oleh karena itu dibutuhkan sebuah sistem yang dapat memberikan informasi serta klasifikasi penyakit secara dini yang dapat digunakan untuk klasifikasi apabila seseorang ingin mengetahui informasi ataupun gejala awal 
serangan jantung. Metode naive bayes merupakan salah satu metode yang digunakan untuk melakukan klasifikasi berdasarkan probabilitas atau kemungkinan dari data sebelumnya, selain pendekatannya sederhana metode tersebut juga dapat melakukan klasifikasi secara baik. Mekanisme pengujiannya yaitu membagi 303 data ke dalam 5 subset yang akan divalidasi dengan 5-fold cross validation. Hasil akhir dari penelitian ini adalah penerapan sistem klasifikasi dengan menggunakan metode naive bayes yang akan menghasilkan nilai rata-rata akurasi sebesar 90,61%, presisi sebesar 87, 44 %, dan recall sebesar 87,95%.  

Kata Kunci : klasifikasi, penyakit jantung, naive bayes Classifier  

Abstract  
Heart attack is one of the most deadly diseases recorded in the world, there are a  number of new cases of heart disease as much as 43.32% and the number of deaths as much as 12.91%. In 2013 the number of sufferers of heart disease in Indonesia amounted to 61,682 people, in general the number of sufferers of this disease continues to increase due to lack of knowledge or information about heart disease, therefore we need a system that can provide information and classification of diseases early that can be used for classification if someone wants to find out information or early symptoms of a heart attack. Naive Bayes method is one of the methods used to classify based on the probability or likelihood of previous data, in addition to a simple 
approach the method can also do a good classification. The testing mechanism is to divide 303 data into 5 subsets that will be validated by 5- fold cross validation. The final result of this study is the application of the classification system using the Naive Bayes method which will produce an average accuracy value of 90.61%, a precision of 87.44%, and a recall of 87.95%.  

Keywords : classification, heart disease, naive bayes 

1. PENDAHULUAN  
1.1. Latar Belakang  
Serangan Jantung adalah salah satu penyakit yang paling mematikan di dunia [1] dan salah satu penyakit yang banyak penderitanya adalah Penyakit Jantung.  Di Indonesia, Penyakit Jantung adalah kasus penyakit yang paling sering dijumpai pada perempuan dewasa [2]. Berdasarkan data kasus penyakit di Indonesia dari GLOBOCAN (IARC) pada tahun 2012, 
terdapat jumlah kasus baru serangan Jantung sebanyak 43,30% dan jumlah kematian sebesar 12,90%. Pada tahun 2013 jumlah penderita penyakit Penyakit Jantung sebesar 61.682 orang, 
dengan penderita terbanyak berdasarkan provinsi, yaitu Jawa Tengah dengan jumlah kasus sebesar 11.511 kasus. Dari data diatas dapat diketahui bahwa banyak orang yang belum 
menanggapi penyebab penyakit ini dengan serius, dan setelah melakukan pemeriksaan kesehatan, dokter mendeteksi adanya penyakit dengan stadium yang sudah tinggi [3]. Banyak alternatif cara untuk mencegah bahkan menyembuhkan peny akit-penyakit tersebut, seperti operasi, penyinaran dan khemoterapi [2]. Namun, kurangnya akses informasi/media menjadi alasan penderita terlambat untuk memeriksakan diri ke dokter [1].  Terdapat hubungan antara kurangnya akses informasi/media dengan keter lambatan pemeriksaan awal Penyakit Jantung [1].  Kurangnya akses untuk mencari informasi tentang penyakit serangan jantung ini menyebabkan peningkatan angka kematian setiap tahunnya. Karena itu, dibutuhkan sebuah sistem klasifikasi yang dapat memberikan in formasi tentang penyakit serangan jantung serta dapat melakukan pengecekan klasifikasi secara dini tentang penyakit serangan jantung yang dialami oleh seseorang [3]. Untuk melakukan sebuah klasifikasi sistem membutuhkan metode yang tepat dalam mengelola pengetahuan yang diadopsi dari pakar sehingga diperoleh hasil yang akurat. Salah satu metode yang dapat digunakan dalam penelitian ini adalah penerapan Naive Bayes Classifier, dimana metode Naive Bayes Classifier merupakan suatu pendekatan yang cukup sederhana dan baik dalam melakukan pelatihan data untuk klasifikasi [4]. Sedangkan Naive Bayes Classifier juga dapat dikatakan menghitung kemungkinan kelas atau kategori klasifikasi data atau dapat dijelaskan seperti atribut kelas atau kategori yang diberi label [5].  Beberapa penelitian yang menerapkan Naive Bayes Classifier sudah banyak diteliti. Seperti pada penelitian yang diimplementasikan oleh Muhamad, yang mengemukaan Naive Bayes mempunyai banyak keunggulan, diantaranya memiliki akurasi yang tinggi dengan be ntuk 
algoritma yang sederhana namun cepat menyelesaikan masalah, namun validasi pengujian yang dilakukan dalampenelitian tersebut hanya satu kali. Mekanisme pengujian dilakukan dengan menggunakan 123 dataset dengan parameter akurasi saja, peneliti akan mel akukan pengujian dengan mekanisme membagi 303 data kedalam 5 subset yang akan divalidasi dengann 5-fold cross validation dengan parameter pengujian akurasi, presisi dan recall [6]. Peneltian selanjutnya adalah percobaan yang diimplementasikan oleh Li dkk yang menjelaskan bahwa algoritma naive bayes dapat digunakan untuk mengelola dataset dengan jumlah besar, algoritma naive bayes mampu menghasilkan akurasi lebih dari 78%, hasil tersebut didapatkan melalui seleksi fitur terlebih dahulu sebelum melakukan klasifikasi sehingga dapat meningkatkan performa dari algoritma naive bayes [7]. Sedangkan pada penelitian yang dilakukan nuraini lebih baik diimplementasikan pada data dengan jumlah yang besar serta dapat melakukan penganganan data yang bersifat kurang lengkap dan lumayan baik pada suatu atribut yang memiliki noise dan tidak relevannya pada sebuah data [8].  Berdasarkan latar belakang yang telah dijelaskan sebelumnya maka pada penelitian ini akan dilakukan penelitian pembuatan sistem klasifikasi penyakit jantung menggunakan Naive Bayes Classifier. Dengan tujuan memberikan kontribusi penelitian melalui konfigurasi penerapan model algoritma dengan mekanisme validasi pengujian yang berbeda dari penelitian sebelumnya untuk hasil tingkat akurasi, presisi, dan recall  yang lebih akurat.  
1.2. Landasan teori  
1.2.1.  Naive Bayes  
Naive Bayes merupakan sebuah metode dengan pendekatan 2 penafsiran yang sedikit berbeda. Menurut penjelasan Bayes, model ini menjelaskan seberapa jauh tingkat derajat 
kepercayaan pada suatu subjektif harus dapat merubah secara rasional ketika adanya suatu petunjuk atau tujuan baru. Sedangkan penjelasan frekuentis, model ini mengartikan bahwa 
representasi sebagai invers probabilitas melalui dua scenario kejadian [9].  Naive merupakan dasar dari statistika Bayes dan dapat diterapkan dalam banyak bidang 
seperti  sains , rekayasa, ilmu ekonomi, teori permainan kedokteran, hukum, dan lain sebagainya. 
1. Menentukan  Envidence Tunggal (E) dan hipotesa tunggal (H) seperti pada persamaan 1   
ðð(ð‡ð‡|ð„ð„)=ððï¿½ð„ð„ï¿½ð‡ð‡ï¿½ð±ð±ðð(ð‡ð‡)
ðð(ð„ð„)   (1) 
Penjelasan:  
P(H.|.E), Kemungkinan hipotesaH terjadi jika envidence E terpenuhi  
P(E.|.H) , Kemungkinan munculnya envidence E jika hipotesis H terjadi  
P(H.), KemungkinanhipotesaH tanpa melihat envidence apapun  
P(E.) , Kemungkinan envidence E tanpa melihatapapun  
2. Mencari Envidence tunggal (E) d an hipotesa  ganda (H1, H2,...Hn)  seperti pada persamaan 2  
ðð(ð‡ð‡ð¢ð¢|ð„ð„)=ððï¿½ð„ð„ï¿½ð‡ð‡ï¿½ ð±ð± ðð(ð‡ð‡)
ï¿½ððï¿½ð„ð„ï¿½ð‡ð‡ï¿½ ð±ð± ðð(ð‡ð‡ð¤ð¤)ð§ð§
ð¤ð¤=ðŸðŸ   (2) 
Penjelasan  
P(Hi|E),  Kemungkinan hipotesaHi  benar terjadi jika diberikan envidence E  
P(Ei.|.H),  Kemungkinan munculnya envidence E jika diketahui hipotesaHi Benar  
P(Ei.|.H), Kemungkinan Hi benar terjadi Hi  
N, jumlah kemungkinan yang akan terjadi  
3. Mencari Envidence ganda dan tunggal ganda  seperti pad a persamaan 3  
ðð(ð‡ð‡ð¢ð¢|ð„ð„ðŸðŸð„ð„ðŸðŸâ€¦.ð„ð„ð¦ð¦)=ðð(ð„ð„ðŸðŸ|ð‡ð‡ð¢ð¢) ð±ð± ðð(ð„ð„ðŸðŸ|ð‡ð‡ð¢ð¢) ð±ð± ...ðð(ð„ð„ðŸðŸ|ð‡ð‡ð¢ð¢) ð±ð± ðð(ð‡ð‡)
ï¿½ðð(ð„ð„ðŸðŸð„ð„ðŸðŸâ€¦.ð„ð„ð¦ð¦|ð‡ð‡ð¤ð¤)  ð±ð± ðð(ð‡ð‡ð¤ð¤)ð§ð§
ð¤ð¤=ðŸðŸ  (3)  
Namun pada  pengaplikasian yang dilakukan  tidak akan mungkin terjadi  dikarenakan  harus memiliki pengetahuan semua kemungkinan bersyarat melalui semua kemungkinan yang 
dikombinasikan, maka rumus perhitungan tersebut diubah menjadi seperti  persamaan  4.  
ðð(ð‡ð‡ð¢ð¢|ð„ð„ðŸðŸð„ð„ðŸðŸâ€¦.ð„ð„ð¦ð¦)=ðð(ð„ð„ðŸðŸ|ð‡ð‡ð¢ð¢) ð±ð± ðð(ð„ð„ðŸðŸ|ð‡ð‡ð¢ð¢) ð±ð±â€¦ð±ð± ðð(ð„ð„ð’Žð’Ž|ð‡ð‡ð¢ð¢) ð±ð± ðð(ð‡ð‡)
ï¿½ðð(ð„ð„ðŸðŸ|ð‡ð‡ð¢ð¢) ð±ð± ðð(ð„ð„ðŸðŸ|ð‡ð‡ð’Œð’Œ) ð±ð±â€¦ð±ð± ðð(ð„ð„ð’Žð’Ž|ð‡ð‡ð’Œð’Œ) ð±ð± ðð(ð‡ð‡)ð§ð§ 
ð¤ð¤=ðŸðŸ  (4) 
1.2.2.  Klasifikasi 
Klasifikasi merupakan metode untuk menentukan sebuah anggota kedalam suatu kelas tertentu yang telah ditentukan sebelumnya. Anggota tersebut dimasukan kedalam kelas tertentu berdasarkan persamaan karakter dari data terserbut. Teknik klasifikasi banyak digunakan dalam penerapan sistem klasif ikasi untuk kasus tertentu. Dalam klasifikasi pembagian dataset dibagi  menjadi 2 yaitu data latih dan data uji, dimana semua dataset akan dibagi kedalam dua cluster untuk dilakukan pelatihan dan pengujian terhadap data tersebut. Pembagian data tersebut juga akan menentukan hasil akurasi dari penerapan suatu metode dalam Teknik klasifikasi tersebut [10].       

2. METODE PENELITIAN  
Pada tahap ini peneliti akan melakukan studi literatur tentang metode klasifikasi naive bayes. Penerapan metode ini merupakan mesin pemb elajaran yang sering digunakan untuk 
mengklasifikasi atau meramalkan sesuatu. Parameter yang digunakan dalam pengujian penelitian ini yaitu: Akurasi, presisi, recall dan waktu, yang dihasilkan dari penerapan naive bayes dalam klasifikasi penyakit serangan jantung.  
2.1. Metode Penelitian  
Metode penelitian yang akan digunakan dalam  penelitian ini adalah metode penelitian kuantitatif, dimana peneliti akan melakukan penelitian secara tersistemmatis, terstruktur, dan 
dijelaskan secara rinci tentang perancangan sebuah  sistem klasifikasi dengan menggunakan metode naive bayes untuk klasif ikasi penyakit jantung.  Penelitian dilakukan dengan cara pengumpukan dataset dari dataset pada UCI -Machine -
Learning dengan format Comma Sparated Value (CSV) yang berisikan 303 record dan terbagi menjadi 2 kelas serta 15 atribut, yaitu age, trestbps, chol,  sex, cpfbsthalach, exang, oldpeak, slope, c, thal, restecg, num. Hasil akhir penelitian adalah Analisa hasil tingkat akurasi, presisi dan recall yang divalidasi dengan menggunakan 5-FOLD Cross-Validation yang akan dianalisa kedalam suatu bentuk angka, tabel dan grafik diagram untuk menjelaskan kesimpulan penelitian yang diperoleh.  
2.2. Metode Pengumpulan Data  
Pada tahap pengumpulan data menggunakan tahap eksperimen, namun selain itu peneliti juga mengumpulkan data awal sebagai bahan referensi malalui observasi,  wawancara, dan studi pustaka kepada praktisi yang terkait langsung dengan bidangnya. Tahap eksperimen dilakukan dengan menerapkan Naive bayes sebagai metode yang akan diimplementasikan.  Kemudian hasil penggabungan kedua model algoritma tersebut dievaluasi  berdasarkan tingkat Akurasi, Presisi, dan Recall untuk dilihat hasil perbandingannya. Proses pengumpulan data dimulai dari wawancara kepada pihak terkait untuk mendapatkan parameter-parameter yang akan diteliti, dan dilanjutkan dengan proses pengamambilan data pada objek yang akan diteliti. Dalam kasus ini penliti mengambil data klasifikasi penyakit jantung dari UCI-Machine-Learning yang akan diimplementasikan sebagai 
dataset. Dataset yang diperoleh tersebut akan dijadikan model data untuk melakukan pengga bungan pada kedua model algoritma yang akan diteliti.  
2.3. Metode Analisis Data  
Tahap analisis data yang akan dilakukan adalah membandingkan hasil eksperimen mulai dari awal sampai akhir. Eks perimen dimulai dari melakukan cleaning atau pembersihan pada data 
yang telah dikumpulkan. Tahap selanjutnya akan dilakukan transformasi data, dimana pada tahap ini akan dilakukan pengclusteran kemudian dibagi menjadi beberapa group atau kemlompok data. Setelah data berhasil dikelompokan, selanjutnya akan dilakukan proses pe modelan dimana data yang sudah dikelompokan akan diubah menjadi nilai -nilai yang dipisahkan dengan tanda koma atau Comma Sparated Value (CSV) sebagai format data input ke dalam database.  Setelah proses pemodelan data atau memasukan data di suatu database selesai dilakukan, maka proses yang dilakukan selanjutnya yaitu menerapkan model algoritma Naive bayes menggunakan data yang telah diperoleh. Kedua model algoritma ini akan digabungkan dengan menggunakan 5-FOLD Cross-Validation. Metode ini membagi secara acak 5 subset dan kemudian setiap subset n=1 akan menjadi data training sedangkan n= 2, 3, â€¦ ,5 akan menjadi data testing. Kemudian dilakukan sebanyak 5 iterasi dengan data tes ting n+1 dan syarat data testing 
tidak sama dengan data training. Penarikan kesimpulan dilakukan berdasarkan hasil evaluasi pada kedua model algoritma yang terpilih dengan menggunakan pengukuran nilai-nilai performa akurasi, presisi, recall dan waktu. Hasi l pengukuran tersebutakan dijadikan acuan atau pedoman dalam menentukan hasil atau klasifikasi pada penelitian ini.  
2.4. Alur Penelitian  
Alur pada tahap ini berisi diagram proses urutan alur penelitian secara rinci dan detail yang dapat mencakup algoritma, rute , pemodelan-pemodelan, desain yang terdapat pada perancangan sistem. Alur penelitian  pada sistem prediksi klasifikasi penyakit jantung ditunjukan di Gambar 1 dan Gambar 2.   
Gambar 1. Metode Penelitian  
Penjelasan singkat alur atau metode penelitian seperti berikut:  
1. Diagnosing  
Pada tahap an ini peneliti melakukan  sebuah  studi literatur melalui proses  membaca buku, jurnal, makalah serta laporan yang terkait dengan topik penelitian . Kemudian melakukan pengumpulan data dan informasi seperti melakukan wawancara, dokumentasi dan observasi. Selanjutnya dilakukan proses definisi kebutuan dengan malakukan identifikasi data yang dibutuhkan, melihat prosedur yang sedang berjalan, menganalisis sistem yang sedang berjalan serta membuat hasil evaluasi si stem tersebut.  
2. Action Planning  
Pada tahap ini berisikan proses desain sistem dan software seperti pemod elan metode  Naive bayes , pemodelan proses dengan Unified Modeling Language ( UML ) seperti usecase 
diagram dan activity diagram  serta perancangan User Interface.  
3. Evaluating  
Pada tahap ini dilakukan pengimplementasian  untuk didapatkan hasil penelitian dengan  pengukuran performa Akurasi, presisi, recall dan waktu berupa nilai angka, tabel dan diagram.  
4. Specifying Learning  
Pada tahap ini dilakukan proses dokumentasi dan publikasi thesis berisi hasil peneltian yang sudah diterapkan. 

3. HASIL DAN PEMBAHASAN 
3.1. Perancangan Sistem  
Pada proses ini akan dibuat suatu perancangan dari sistem klasifikasi penyakit serangan jantung melalui penerapan naive bayes dengan menggunakan usecase pada Gambar 2 sebagai 
pejelasan kebutuhan fungsional , dan activity  diagram pada Gambar 3 sebag ai penggambaran alur atau aktifitas pada sistem.   
Gambar 2. Usecase Diagram  
Pada Gambar 2 menerangkan tentang funsionalitas yang akan dibuat dan dirancang dengan pembuatan 5 menu yang diimplementasikan kedalam sistem, dimana terdapat menu pengaturan (setting) yang berfungsi untuk mengatur pembatasan jumlah dataset yang akan diolah dan dilakukan training. Pada system tersebut terdapat menu yang berfungsi untuk mengelola dataset seperti menambahkan dan menghapus dataset, menu prediction untuk melakukan prediksi atau klasifikasi penyakit jantung dan validation untuk melakukan validasi hasil berupa akurasi, presisi, dan recall. Akan tetapi menu prediction dan validation hanya dapat dilakukan ketika proses pada menu training dijalankan, menu training sendiri bet ujuan untuk dapat menemukan bobot yang akan digunakan dalam proses klasifikasi dan validasi.  Pada Gambar 3 menerangkan alur klasifikasi penyakit jantung yang mana pengguna membuka dan mengklik  menu klasifikasi dan sistem akan menampikan menu klasifikasi, selanjutnya user harus mengimport dataset dengan format CSV. Proses selanjutnya user akan melakukan input nilai parameter age, trestbps, chol, sex, cpfbsthalach, exang, oldpeak, slope, c, 
thal, restecg, num. Kemudian sistem akan melakukan training dengan dataset untuk mendapatkan bobot untuk kemudian diklasifikasi menggunakan naive bayes untuk menemukan hasil klasifikasi atau prediksi. Setelah mendapatkan hasil yang ditampilkan oleh sistem ke user, user dapat melakukan klasifikasi ulang atau menyelesaikan proses klasifikasi tersebut.  
Gambar 3. ActivityDiagram Klasifikasi (Prediksi)  
3.2. Analisis  Model Data  
Data yang akan diimplementasikan dalam penelitian merupakan data pada UCI Machine Learning dengan tema penyakit serangan jantung yang berjumlah 303 dataset de ngan pembagian 
kelas kedalam 2 kelas yaitu terjangkit serta tidak terjangkit dan 15 atribut, dengan detail data seperti berikut:  
1. (umur)  
2. (jenis kelamin) jenis kelamin (1 = laki -laki
3. (cp) tipe nyeri dada  
a. Nilai 1: khas angina  
b. Nilai 2: angina a tipikal  
c. Nilai 3: nyeri non -angina  
d. Nilai 4: tanpa gejala  
4. (trestbps) tekanan darah istir ahat (saat otot jantung istirahat) (dalam mm Hg saat masuk  ke 
RSUD)  
5. (chol) serum kolestoral (seluruh jumlah kolesterol dalam darah) dalam m/ dl  
6. (fbs) (gula darah puasa /  sebelum makan > 120m/dl) (1 = benar
7. (restecg) beristirahat hasil elektrok ardiografi (alat pemeriksa otot jantung)  
a. Nilai 0: normal  
b. Nilai 1: memiliki kelainan  gelombang ST-T (inversi gelombang T dan / atau ST  
8. (thalach) denyut jantung maksimum te rcapa i 
9. (exang) olahraga yang diinduksi angina (1 = ya
10. (oldpeak) ST depresi yang disebabkan oleh olahraga relatif terhadap istirahat.  
11. (slope/kemiringan) kemiringan segmen ST latihan puncak  
a. Nilai 1: menanjak  
b. Nilai 2: datar  
c. Nilai 3: downsloping  
12. (ca) jumlah pembuluh darah (0-3) dijelaskan dengan fluoroskopi  
13. (thal) 3 = normal
14. (num) (atribut yang diprediksi)  diagnosis penyakit jantung (status penyakit angiografi)  
a. Nilai 0: <50% penyempitan diameter  
b. Nilai 1 :> penyempitan diameter 50%  
3.3. Pengujian Sistem  
Model pengujian sistem dilakukan melalui beberapa percobaan dalammenentukan hasil nilai akurasi, presisi serta recall. Pengujian dilakukan dengan menggunakan 5-FOLD Cross-Validation, pembagian data dilakukan dengan membagi 303 data menjadi 5 bagian seperti pada Tabel 1.  
Tabel 1. Hasil Pengujian Sistem  
No Data  Akurasi (%)  Presisi (%)  Recall (%)  
1 60 88,62  86,37  86,46  
2 120 89,04  86,56  87,62  
3 180 91,48  87,29  88,19  
4 240 91,89  88,01  88,43  
5 303 92,02  88,98  89,03 
Rata-Rata 90,61  87,44  87,95  
Berdasarkan hasil pada Tabel 1 Diperolah hasil subset 1 pada 60 data dengan nilai akurasi 88,62%, presisi 86,37% dan recall 86,46%, subset 2 pada 120 data dengan nilai akurasi 89,04%, presisi 86,56%, dan recall 87,62%, subset 3 pada 180 data dengan nilai akurasi 91,48%, presisi 87,29%, dan recall 88,19%. Dan pada subset ke 4, terdapat 240 data dengan nilai akurasi 91,89%, presisi 88,01%, dan recall 88,43%, sedangkan untuk hasil tertinggi pada subset 5 dengan 240 data dengan nilai akurasi 92,02%, presisi 88,98%, dan recall 89,03%.  Berdasarkan hasil yang terlah diperoleh diatas diperoleh hasil rata-rata untuk pengujian 5 subset dengan nilai rata-rata akurasi sebesar 90,61%, presisi sebesar 87,44 %, recall sebesar 87,95%. Berda sarkan hasil tersebut terbentuk grafik pada Gambar 4.   
Gambar 4. Hasil Pengujian Sistem  
88.6289.0491.4891.89
86.37 86.5687.2988.01
86.4687.6288.1988.43
8384858687888990919293
60 Data 120 Data 180 Data 240 DataHasil Pengujian Sistem
Akurasi (%) Presisi (%) Recall (%)

4. KESIMPULAN  
Melalui hasil penelitian telah dijelaskan dan dilakukan pada pembuatan sistem klasifikasi penyakit jantung menggunakan naive bayes. Pembuatan sistem ini  menyimpulkan nilai hasil 
akurasi dengan rata- rata akurasi  senilai 90,61%, rata-rata hasil nilai presisi senilai 87,44% dan rata-rata nilai recall senilai 87,95% dengan konfigurasi data yang terdapat pada UCI Machine Learning yang berisi 2 kelas klasifikas i dan 15 atribut dengan jumlah 303 data  

5. SARAN  
Berdasarkan hasil penelitian didapatkan saran untuk penambahan algoritma optimasi lain untuk menambah tingkat akurasi, presisi, dan recall. Penerapan algoritma baik berupa penggabungan ataupun optimasi algoritma diharapkan dapat meningkatkan nilai performa algoritma tersebut dalam melakukan klasifikasi.  

DAFTAR PUSTAKA  
[1] Pemerintah Indonesia, 2009, Pedoman Pengendalian Penyakit Jantung dan Pembuluh Darah dalam Keputusan Menteri Kesehatan (KEMENKES), Lembaran RI Tah un 2019 No. 854, Sekretariat Negara, Jakarta.  
[2] Yahya, A. F., 2010, Menaklukkan Pembunuh No. 1 Mencegah dan Mengatasi Penyakit Jantung Koroner Secara Tepat , Qanita Publisher, Bandung. 
[3] Kasron, 2013, Kelainan dan Penyakit Jantung: Pencegahan serta Pengobatannya , Nuha Medika, Yogyakarta.  
[4] Praningki, T., Budi, I., 2017, Sistem Prediksi Penyakit Kanker Serviks Menggunakan CART, Naive Bayes, dan K -NN., Citec Journal , No.2, Vol.4, Hal. 83- 93 
[5] Prasetyo, Y., Haryanto, H., 2017, Visualisasi Berbasis Naive Bayes Untuk Pemetaan Penyebaran Penyakit Infeksi Saluran Pern afasan Akut, Jurnal Ilmiah SISFOTENIKA , No.1, 
Vol 7, Hal. 74- 84  
[6] Muhamad, H., Prasojo, A. A., Sugianto, N. A., Surtiningsih, L., Cholissodin, I., 2017, Optimasi NaÃ¯ve Bayes Classifier Dengan Menggunakan Partic le Swarm Optimization Pada Data Iris,  Jurnal Te knologi Informasi dan Ilmu Komputer (JTIIK) , No. 3, Vol. 4, Hal. 180-184
[7] Li, X., Ling, C. X., Wang, H, 2016, The Convergence behavior of Naive Bayes on Large Sparse Datasets,  Journal ACM Transactions on Knowle dge Discovery from Data (TKDD) , 
No. 1, Vol. 11, Hal. 853- 858. 
[8] Nuraeni, N., 2017, Penentuan Kelayakan Kredit Dengan Algoritma NaÃ¯ve Bayes Classifier: Studi Kasus Bank Mayapada Mitra Usaha Cabang PG, Jurnal Teknik Komputer AMIK BSI , 
No. 1, Vol. 3, Hal. 9- 15 
[9] Kusumadewi, S., 2003, Artificial Intellegence T eknik dan Aplikasi, Graha Ilmu, Yogyakarta.  
[10] Turban, E., 2005., Decision Support System and Intelligent Systems , edisi Bahasa Indonesia jilid 1, Penerbit Andi, Yogyakarta.",klasifikasi,naive bayes,data klasifikasi penyakit jantung,"akurasi, presisi, recall"
Implementasi Algoritma Klasifikasi K-Nearest Neighbor (KNN) Untuk Klasifikasi Seleksi Penerima Beasiswa,"Implementasi Algoritma Klasifikasi K-Nearest Neighbor (KNN) Untuk Klasifikasi Seleksi Penerima Beasiswa

Saifur Rohman Cholil1, Titis Handayani2, Rastri Prathivi3, Tria Ardianita4 

ABSTRAK  
Pemberian beasiswa kepada siswa Sekolah Menengah Atas (SMA) sudah umum dilakukan. Hal ini terjadi sejak adanya dana pendidikan 20% dari Kementrian Pendidikan dan Kebudayaan (Kemendikbud). Selain untuk batuan kepada siswa yang kurang mampu, beasiswa juga di berikan kepada siswa yang mempunyai 
prestasi akademik maupun prestasi non akademik. Pemberian beasiswa yang terjadi selama ini baik di SMA ataupun yang lain masih menggunakan perhitungan dan pengolahan data secara manual. Proses perhitungan secara manual memungkinkan adanya penerima  beasiswa  yang tidak tepat sasaran. Pengolahan penerimaan beasiswa bisa menggunakan sebuah algoritma data mining untuk mengklasifikasikan  calon penerima  beasiswa  berdasarkan  data yang diambil dari data siswa  penerima beasiswa sebelumnya (data training) dengan data yang diambil dari calon penerima beasiswa (data testing). Penelitian ini bertujuan membantu proses seleksi beasiswa di SMA menggunakan algoritma K-Nearest Neighbor (KNN) supaya penerima beasiswa tepat sasaran. Algoritma KNN bisa memberikan  kebutuhan data yang akurat  dan informasi yang diperlukan untuk menyeleksi  calon penerima beasiswa. 
Hasil dari penelitian ini adalah adalah terseleksinya 30 orang dari 89 data yang telah dilakukan klasifikasi.  Pengujian sistem  menggunakan pengujian akurasi metode confusion matrix  dengan hasil pengujian sebesar 90.5%. Hal ini menunjukkan bahwa algoritma KNN bisa digunakan untuk mengklasifikasikan seleksi penerimaan beasiswa.  

Katakunci : algoritma, beasiswa, data mining, KNN  
 
ABSTRACTS  
Providing scholarships to high school students (SMA) is common. This happened since there was a 20% education fund from the Ministry of Education and Culture (Kemendikbud). In addition to rocks to underprivileged students, scholarships are also given to students who have academic and non -academic achievements. Scholarships that have occurred so far both in high school and others still use manual calculation and data processing. The manual calculation process allows for scholarship recipients who are  not on target. Processing scholarship receipts can use a data mining algorithm to classify prospective scholarship recipients based on data taken from previous scholarship recipient student data (training data) with data taken from prospective scholarship  recipients (data testing). This study aims to help the scholarship selection process in high school using the K-Nearest Neighbor (KNN) algorithm so that 
scholarship recipients are on target. The KNN algorithm can provide accurate data and information needed to select prospective scholarship recipients. The result of this research is the selection of 30 people from 89 data that has been classified. System testing uses the accuracy of confusion matrix testing with 90.5% test results. This shows that the KNN algorithm can be used to classify scholarship 
acceptance selections.  

Keywords : algorithms, data mining, KNN, scholarship   
 
1. PENDAHULUAN   
Klasifikasi yang  didasarkan  pada  sistem informasi merupakan teknik memetakan (mengklasifikasikan) data  ke  dalam  satu  atau beberapa kelas yang sudah didefinisikan 
sebelumnya. Ada banyak teknik klasifikasi  yang dapat digunakan, diantaranya adalah K-Nearest Neighbor  (KNN). Konsep penelitian dengan algoritma KNN telah banyak dilakukan oleh peneliti-peneliti sebelumnya diantaranya yaitu, algoritma KNN digunakan untuk pengenalan pola, pengenalan teks, pengolahan  objek dan lain-lain. Algoritma KNN dianggap mempunyai kesederhanaan  dalam pengolahan data training dan data testing dalam jumlah yang  sangat 
besar (Tang, Jing, Li, & Atkinson, 2016). Algoritma KNN mampu melakukan training pada dataset penyakit diabetes   untuk   melihat   dampak   negatif   hilangnya nilai   imputasi   dan   solusi   untuk    penyembuhan. Akurasi  
algoritma  KNN diatas  rata-rata yang  diterapkan  untuk klasfikasi penerima beasiswa PPA dan BBM (Sumarlin, 2016).  Algoritma KNN merupakan metode yang digunakan untuk melakukan  klasifikasi  data berdasarkan jarak terpendek terhadap objek data. Penentuan nilai  K yang  terbaik  untuk  
algoritma   ini berdasarkan pada data yang ada. Nilai K yang tinggi dapat mengurangi efek noise pada  klasifikasi,  bisa juga membuat   bat asan   antara setiap   klasifikasi   menjadi lebih kabur (Anshori, Regasari, & Putri, 2018). Algoritma KNN merupakan algoritma berbasis contoh atau non parametric dan dianggap metode paling sederhana di dalam proses data mining (Tharwat, Mahdi, Elhoseny, &  Hassanien, 2018). Algoritma KNN salah satu metode klasifikasi data yang mudah diimlementasi pada jumlah data yang kecil, tetapi jika dataset yang diolah banyak dan kompleks maka algoritma KNN memiliki kelemahan dan waktu yang tidak efisien (Yahya & Hidaya nti, 2020). Metode KNN menggunakan ukuran jarak yang sesuai untuk mengklasifikasikan data baru. Jarak tetangga 
terdekat K dihitung dan label kelas dari tetangga terdekat diprediksi sebagai label kelas dari instance baru. Akurasi KNN sangat terpengaruh dengan memilih jumlah K tetangga terdekat. Jika terdapat nilai K yang kecil, maka akan sensitif terhadap noise  dan jika terlalu besar, dapat menyebabkan bias model (Anshori et al., 2018). Algoritma KNN merupakan algoritma berbasis memori yang menggunakan iterasi pada data sampai atribut atau parameter data yang terdekat ditemukan. Jarak minimum data yang diproses pada data testing akan dibandingkan dengan data training  dengan jarak yang terdekat (Suwirmayanti, 2017).  Algoritma KNN digunakan untuk memprediksi harga jual tanah dengan cara menentukan pilihan dalam proses pe milihan tanah yang strategis dengan harga yang sesuai (R Novita & Harsani, 2018). Algoritma KNN 
digunakan untuk prediksi penjualan furniture sehingga dapat mengurangi waktu pemrosesan dan  algoritma tersebut bisa memberikan   akurasi   yang baik   dalam   sampel    pengujian yang telah dilakukan (Hutami & Astuti, 2016). Algoritma KNN digunakan untuk mengk lasifikasikan pemasaran dengan hasil dan akurasi menggunakan metode cross validition  dengan hasil yang baik (Mustakim, 2016).  Pemberian beasiswa kepada siswa SMA sudah umum dilakukan. Beasiswa diberikan kepada siswa yang tidak mampu, siswa yang mempunyai prestasi akademik maupun non akademik. Pemberian beasiswa yang terjadi selama ini masih menggunakan perhitungan dan pengolahan data secara manual. Proses perhitungan secara manual memungkinkan adanya penerima  beasiswa  yang tidak tepat sasaran. Pengolahan penerimaan beasiswa bisa menggunakan sebuah algoritma data mining untuk mengklasifikasikan  calon penerima  beasiswa  berdasarkan  data training  yang diambil  dari data siswa  penerima beasiswa sebelumnya (dataset) dengan data testing yaitu data yang diam bil dari calon penerima beasiswa.  Penelitian ini bertujuan membantu proses seleksi beasiswa di SMA menggunakan algoritma K-Nearest Neighbor  (KNN) supaya penerima beasiswa tepat sasaran. Keunikan yang terdapat dalam penelitian ini adalah mampu memetakan atau mengklasifikasikan data menjadi beberapa kelas yang didefinisikan sebelumnya.  Saifur Rohman Cholil , et.al. 

2. METODE PENELITIAN  
Beberapa cara digunakan untuk pengukuran jarak antara data baru (data testing) dengan data lama (data training), antara lain manhattan distance  (city block distance ) dan euclidean  distance . Pengukuran jarak yang paling sering digunakan adalah euclidean distance.  Jarak euclidean distance  didefinisikan seperti pada persamaan 1 (Suwirmayanti, 2017).   
ð‘‘ð‘–=âˆšâˆ‘ (ð‘¥1âˆ’ð‘¥2)2 ð‘
ð‘–=1 (1)  
Keterangan :  
d  = jarak  
i  = variabel data  
p  = dimensi data  
x1  = sampel data  
x2  = data uji   
Proses perhitungan nilai akurasi dapat dilakukan dengan menggunakan persamaan 2.   
ð‘Žð‘˜ð‘¢ð‘Ÿð‘Žð‘ ð‘– = ð‘—ð‘¢ð‘šð‘™ð‘Ž â„Ž ð‘˜ð‘™ð‘Žð‘ ð‘–ð‘“ð‘–ð‘˜ð‘Žð‘ ð‘–  ð‘ð‘’ð‘›ð‘Žð‘Ÿð‘—ð‘¢ð‘šð‘™ð‘Ž â„Ž ð‘‘ð‘Žð‘¡ð‘Ž  ð‘¢ð‘—ð‘– ð‘¥ 100%  (2)  
Algoritma KNN memiliki beberapa kelebihan diantaranya ketangguhan terhadap data training yang memiliki banyak noise dan data dalam jumlah yang besar. Kelemahan dari algoritma KNN adalah perlu menentukan jumlah tetangga terdekat dari target data, yang disimbolkan dengan nilai parameter K, data training yang didasarkan pada  hasil perhitungan jarak kurang akurat karena harus memilih, mencoba dan menentukan jenis jarak yang digunakan dan atribut mana yang dipakai untuk mendapatkan hasi yang perhitungan jarak yang terbaik, serta biaya komputasi yang tinggi karena membutuhkan perhitungan jarak dari tiap query instance  pada keseluruhan contoh data training.  Algoritma KNN merupakan salah satu metode supervised learning  karena  hasil query instance  perlu diklasifikasikan berdasarkan mayoritas dari kategori  KNN.  Pengumpulan data menggunakan metode observasi. Data primer diperoleh dari bagian kepegawaian SMA Islam Sultan Agung I Semarang. Data primer yang dijadikan contoh dalam penelitian ini adalah data siswa calon penerima beasiswa tahun ajaran 2017/2018 dan tahun ajaran 2018/2019. Tahap perancangan penelitian yang dilakukan untuk memberikan gambaran secara jelas dapat ditunjukkan pada gambar 1 . Dalam penelitian ini menggunakan data training yang yang berjumlah 101 data. Dan data testing berjumlah 89 data. Untuk metode pengolahan data menggunakan metode KNN untuk klasifikasi. Algoritma KNN dapat dilihat pada Gambar 2 berikut ini. 
Gambar 1.  Tahapan Penelitian  
Gambar 2.  Flowchart Algoritma KKN   
Berikut penjelasan setiap tahapan dari algoritma KNN : (1). Menentukan jumlah tetangga terdekat yang disimbolkan dengan  nilai parameter K.  Nilai pada parameter  K  yang akurat untuk algoritma ini tergantung pada data training yang digunakan Menghitung dan menentukan nilai kuadrat jarak data testing objek terhadap data training yang diberikan dengan menggunakan persamaan 1 (3). Melakukan pengurutan dari hasil perhitungan no 2 secara ascending (urut dari nilai rendah ke nilai tinggi) Mengumpulkandata pada kategori Y (Klasifikasi tetangga terdekat berdasarkan nilai K) Kategori Y yang paling banyak muncul menjadi hasil akhir  dari klasifikasi.  
 
3. HASIL DAN PEMBAHASAN   
3.1. Pengolahan Data Awal  
Data calon penerima beasiswa yang terlihat seperti Tabel 1 adalah data mentah yang belum diolah dengan metode KNN. Data 
penerima beasiswa Tahun Akademik 2017/2018 dijadikan sebagai data training  sedangkan data pendaftar beasiswa Tahun Akademik 2018/2019 seperti yang terlihat pada Tabel 2 dijadikan sebagai data testing . Pengisian kolom nilai raport didasarkan pada rata-rata nilai raport semester Gasal dan nilai raport semester Genap. Penilaian kolom Prestasi akademik diisi berdasarkan 5 parameter yaitu Kurang berprestasi, Prestasi tingkat sekolah, Prestasi tingkat kota, Prestasi tingkat propinsi dan Prestasi tingkat nasional. Pengisian nilai prestasi akademik ditunjukkan oleh Tabel 3. Prestasi akademik didasarkan pada prestasi siswa dalam mengikuti lomba-lomba akademik yang diselenggarakan baik tingkat sekolah, tingkat kota, tingkat propinsi maupun tingkat nasional. Diantaranya ada lomba olympiade sains, cerdas cermat, lomba mata pelajaran, lomba membaca puisi dan lain-lain.  Penilaian kolom prestasi non akademik diisi 
berdasarkan 4 parameter yaitu Kurang berprestasi, Prestasi tingkat kota, Prestasi tingkat propinsi dan Prestasi tingkat nasional. Pengisian nilai prestasi non akademik ditunjukkan oleh Tabel 4. Prestasi non akademik didasarkan pada prestasi siswa dalam mengikuti lomba-lomba non akademik yang diselenggarakan baik tingkat kota, tingkat propinsi maupun tingkat nasional. Diantaranya ada lomba pramuka, lomba olahraga lomba kepemimpinan dan lain-lain.  Pengisian kolom penghasilan orangtua didasarkan pada pendapatan orangtua setiap bulannya. Penilaian tersebut diisi berdasarkan 5 parameter yaitu Penghasilan diatas 4 juta/bulan, Penghasilan 3-4 juta/bulan, Penghasilan 2-3 juta/bulan, Penghasilan 1 -2 juta/bulan dan Penghasilan kurang dari 1 juta/bulan. Pengisian nilai penghasilan orangtua ditunjukkan oleh Tabel 5.  Pengisian kolom kepribadian didasarkan pada sikap kepribadian selama di sekolah. Penilaian tersebut diisi berdasarkan lima parameter yaitu Sangat kurang, Kurang, Cukup, Baik dan Sangat baik. Pengisian nilai kepribadian ditunjukkan oleh Tabel 6.    
Tabel 1.  Data Training  
No NIS Nama  Nilai 
Raport  Akademik  Non Akademik  Penghasilan Ortu  Kepribadian  Status Beasiswa  
1 15291  Abdigusti R. M.  83,38  3 1 2 4 Tidak Beasiswa  
2 15429  Achmad Alfarizi  83,06  2 1 3 4 Tidak Beasiswa  
3 15361  Akmal F.  82,69  2 1 2 4 Tidak Beasiswa  
4 15432  Alfian R.  82,50  2 2 4 4 Tidak Beasiswa  
5 15435  Arif R.  82,44  2 3 4 4 Beasiswa  
6 15364  Arya Aldi  82,38  2 1 1 4 Tidak Beasiswa  
7 15438  Dharma N. P.  82,19  2 1 2 3 Tidak Beasiswa  
8 15299  Dogan S.  82,19  2 1 3 3 Tidak Beasiswa  
9 15367  Fadhil S.  82,00  2 2 3 5 Tidak Beasiswa  
10 15303  Garuda B. N.  81,81  2 3 4 5 Beasiswa  
11 15303  Hamzah A.  81,75  2 1 5 4 Tidak Beasiswa  
12 15309  Humam M.  81,69  2 1 1 3 Tidak Beasiswa  
13 15370  Husen T. A.  81,63  2 1 3 4 Tidak Beasiswa  
14 15371  Irfan R.Putra  81,31  2 1 5 3 Tidak Beasiswa  
15 15312  Jovian Chandara  74,88  1 1 5 3 Tidak Beasiswa  
16 15642  M. Fariz Sukma  74,81  1 2 4 5 Tidak Beasiswa  
17 15375  Maskharis  74,75  1 1 2 4 Tidak Beasiswa  
18 15378  Mohamad Adrian  74,75  1 1 2 4 Tidak Beasiswa  
19 15441  Mohamad Akmal  74,69  1 1 2 3 Tidak Beasiswa  
20 15448  M. Faiz S.  74,54  1 1 1 4 Tidak Beasiswa   
Tabel 2.  Data Testing 
No NIS Nama  Nilai Raport  Akademik  Non Akademik Penghasilan Ortu  Kepribadian  
1 15861  Adi Haryanto  75,23  3 1 2 4 
2 15862  Afiandani N.  80,00  2 1 3 4 
3 15863  Ahmad Kristiyan  74,23  2 1 2 4 
4 15864  Ahmad Thariq Z.  77,56  2 2 4 4 
5 15865  Athaya Adeer  76,00  2 3 4 4 
6 15866  BAyu Adi L.  88,25  2 1 1 4 
7 15867  Bima Adi S.  75,45  2 1 2 3 
8 15868  Chandra Yudha  74,00  2 1 3 3 
9 15869  Daffa Tsani  72,35  2 2 3 5 
10 15870  Davin Yusuf  72,66  2 3 4 5 
11 15871  Ginanjar  76,40  2 1 5 4 
12 15872  Irfan A.  81,00 2 1 1 3 
13 15873  Krishan Yudha  75,20  2 1 3 4 
14 15874  Lufi Darmawa  70,45  2 1 5 3 
15 15875  M. Deva Prabwo  85,00  1 1 5 3 
16 15876  M. Fadil  74,80  1 2 4 5 
17 15877  Maskharis  72,50  1 3 3 5 
18 15878  Mohamad Rafi  73,15  1 1 2 4 
19 15879  Mohamad Reza  84,23  1 1 2 3 
20 15880  Rizqi Fadillah  81,45  1 1 4 3 
Tabel 3.  Prestasi akademik  Parameter  Nilai  
Kurang Berprestasi  1 
Prestasi Tingkat Sekolah  2 
Prestasi Tingkat Kota  3 
Prestasi Tingkat Propinsi  4 
Prestasi Tingkat Nasional  5  
Tabel 4. Prestasi Non Akademik  Parameter  Nilai  
Kurang Berprestasi  1 
Prestasi Tingkat Kota  2 
Prestasi Tingkat Propinsi  3 
Prestasi Tingkat Nasional  4 
Tabel 5.  Parameter Penghasilan Orangtua  Parameter  Nilai  
Penghasilan > 4 juta/bulan  1 
Penghasilan 3 -4 juta/bulan  2 
Penghasilan 2 -3 juta/bulan  3 
Penghasilan 1 -2 juta/bulan  4 
Penghasilan < 4 juta/bulan  5 
Tabel 6.  Parameter Nilai Kepribadian  Parameter  Nilai  
Sangat kurang  1 
Kurang  2 
Cukup  3 
Baik  4 
Sangat baik  5  
3.2. Perhitungan Euclidean Distance  
Data penerima beasiswa Tahun Akademik 2017/2018 dijadikan sebagai data training sedangkan data pendaftar beasiswa Tahun Akademik 2018/2019 dijadikan sebagai data testing. Proses perhitungan euclidean distance dilakukan dengan menggunakan rumus persamaan 1 seperti contoh perhitungan di 
bawah ini dan hasilnya ditunjukkan oleh Tabel 7 dengan nilai K=30 . Data testing yang digunakan sebagai contoh  perhitungan adalah data dengan nomor 1, NIS : 15858 atas nama Adi Hariyanto.  
   = 8,15   
Tabel 7.  Perhitungan Euclidean Distance  
No NIS Nama  Nilai E D  Sorting  KNN  Klasifikasi  
1 15291  Abdigusti Rachman Maulana    8,150  64 Tidak  - 
2 15429  Achmad Alfarizi  7,957  63 Tidak  - 
3 15361  Akmal Fikri Nugroho  7,527  59 Tidak  - 
4 15432  Alfian Reza Fahluzi Yusuf  7,672  61 Tidak  - 
5 15435  Arif Roshyan Nuruddin  7,809  62 Tidak  - 
.. .. .. .. .. .. .. 
.. .. .. .. .. .. .. 
.. .. .. .. .. .. .. 
10 15394  Zhilal Algeiba  5,264  35 Tidak  - 
Perhitungan dari nilai euclidean distance selanjutnya diurutkan berdasarkan tetangga terdekat dari nilai K. Berikutnya dilakukan klasifikasi apakah termasuk mendapatkan 
beasiswa atau tidak berdasarkan nilai K. Dengan menggunakan data testing nomor 1 dengan NIS : 15858 atas nama  Adi Hariyanto yang dikategorikan tidak mendapatkan beasiswa maka didapatkan hasil perhitungan metode KNN dengan K=30, siswa yang mendapatkan beasiswa tidak ada, sedangkan siswa yang tidak mendapatkan beasiswa sebanyak 30 orang. Jika data testing diubah berdasarkan data nomor 56 dengan NIS : 15913 atas nama Orisza Sativa maka didapatkan hasil siswa yang mendapatkan beasiswa sebanyak 22 orang dan yang tidak 
mendapatkan beasiswa sebanyak 8 orang.   
3.3. Implementasi Sistem  
Implementasi sistem adalah proses penerapan ke dalam bentuk program pada perangkat lunak. Berikut implementasi yang dilakukan pada perangkat lunak bentuk antarmuka aplikasi dan server programnya. Program menggunakan bahasa python dan 
tampilan web menggunakan Django.  Implementasi program yang pertama kali dilakukan adalah menyalakan server pada command windows seperti pada Gambar 2. Selanjutnya buka browser untuk memanggil file seperti pada Gambar 3.   
3.4. Evaluasi Metode KNN  
Pada penelitian ini telah dilakukan evaluasi atau pengujian metode KNN dengan menghitung nilai akurasi metode KNN dengan metode confusion matrix . Hasil dari evaluasi ini dapat terlihat pada gambar 4 dan gambar 5 . Pada gambar 5 dan gambar 6 menunjukkan  hasil dari perhitungan KNN dengan pengujian menggunakan metode confusion matrix  pada data training. Sedangkan gambar 7 dan gambar 8 merup akan hasil pengujian KNN dengan confusion matrix  pada data testing. Hasil evaluasi perbandingan pengujian data training  dan data testing ditunjukkan pada tabel 7. 
Gambar 2.  Server Aplikasi  
Gambar 3.  Aplikasi KNN  
Gambar 5.  Evaluasi Dengan Confusion Matrix  Pada  Data Training  
Gambar 6.  Hasil Scatter Plot Data Training  
Gambar 7.  Evaluasi Dengan Confusion Matrix  Pada  Data Testing  
Gambar 8.  Hasil scatter plot data testing  
Tabel 7. Perbandingan hasil evaluasi data training dan data testing  Method AUC  CA F1 Precission  Recall  Sampling  Data  
KNN  1 97%  95%  97%  93%  
Cross Validation  Training  97%  89%  82%  81%  83%    Training 
Hasil dan perbandingan dengan penelitian lain adalah metode ini telah banyak digunakan dalam menyelesaikan suatu masalah. Misalnya pada penelitian yang melibatkan KNN untuk 
perekomendasian laptop yang menunjukkan kepuasan terhadap hasil rekomendasi itu sebesar 85% ( Raharja, Juardi, & Agung, 2019). Hal ini menujukkan bahwa metode KNN dapat memberikan hasil yang akurat dan dapat dipertanggungjawabkan.  
 
4. KESIMPULAN   
Kesimpulan dari penelitian ini terciptanya aplikasi untuk seleksi data penerima beasiswa dengan menggunakan algoritma  KNN. Evaluasi algoritma KNN menggunakan metode confussion matrix  menunjukkan hasil dari perhitungan rata-rata akurasi dari metode KNN ini sebesar 90,5%. Evaluasi perbandingan data training dan testing pada metode KNN dengan cross validation sampling  memperlihatkan hasil perhitungan rata â€“ rata precision  sebesar 89%.  
 
5. REFERENSI   
Anshori, L., Regasari, R., & Putri, M. (2018). Implementasi Metode K-Nearest Neighbor untuk Rekomendasi Keminatan 
Studi ( Studi Kasusâ€¯: Jurusan Teknik Informatika Univ .... Jurnal Pengembangan Teknologi Informasi Dan Ilmu Komputer (J -PTIIK) Universitas Brawijaya , 2(7), 2745 â€“2753.  N. L. G. P. Suwirmayanti. (2017) â€œPene rapan Metode K -Nearest Neighbor Untuk Sistem Rekomendasi Pemilihan Mobil,â€ Techno. Com , vol. 16, no. 2, pp. 120 â€“131.  
Hutami, R., & Astuti, E. Z. (2016). Implementasi 
Metode K -Nearest Neighbor Untuk Prediksi Penjualan Furniture Pada CV.Octo Agung Jepara. Universitas Dian 
Nuswantoro Semarang . 
Mustakim, G. O. F. (2016). Algoritma K-Nearest Neighbor Classification Sebagai Sistem Prediksi Predikat Prestasi Mahasiswa, 13(2), 195 â€“202.  
Sumarlin, S. (2016). Implementasi Algoritma K-Nearest Neighbor Sebagai Pendukung  Keputusan Klasifikasi Penerima Beasiswa PPA dan BBM. Jurnal Sistem Informasi 
Bisnis , 5(1), 52 â€“62. 
https://doi.org/10.21456/vol5iss1pp52 -62
Suwirmayanti, N. L. G. P. (2017). Penerapan 
Metode K-Nearest Neighbor Untuk Sistem Rekomendasi Pemilihan Mobil. 
Techno. Com , 16(2), 120 â€“131.  Tang, Y., Jing, L., Li, H., & Atkinson, P. M. (2016). A multiple -point spatially weighted k-NN method for object-based classification. International Journal of  Applied Earth Observation and Geoinformation , 52, 
263â€“274. https://doi.org/10.1016/j.jag.2016.06.017
Tharwat, A., Mahdi, H., Elhoseny, M., & Hassanien, A. E. (2018). Recognizing human activity in mobile crowdsensing 
environment using optimized k-NN algori thm. Expert Systems with Applications , 107, 32 â€“44. https://doi.org/10.1016/j.eswa.2018.04.017
Y. Yahya and W. Puspita Hidayanti (2020). â€œPenerapan Algoritma K-Nearest Neighbor Untuk Klasifikasi Efektivitas Penjualan Vape (Rokok Elektrik) pada â€˜Lombok Vape On,â€™â€ Infotek  J. Inform. dan Teknol. , vol. 3, no. 2, pp. 104 â€“114, 2020, doi: 10.29408/jit.v3i2.2279.  
A. Q. Sesilia Novita R, Prihastuti Harsani. (2018) .â€œPenerapan K-Nearest Neighbor ( KNN ) untuk Klasifikasi Anggrek Berdasarkan Karakter Morfologi Daun da n Bunga,â€ vol. 15, no. 1, pp. 118 â€“125.  
C. A. Rahardja, T. Juardi, and H. Agung. (2019). 
â€œImplementasi Algoritma K-Nearest Neighbor Pada Website Rekomendasi Laptop,â€ J. Buana Inform. , vol. 10, no. 1, 
p. 75, 2019, doi: 10.2400 2/jbi.v10i1.1847 .",klasifikasi,"K-Nearest Neighbor, KNN","data siswa penerima beasiswa, data calon penerima beasiswa","precision, recall, akurasi"
IMPLEMENTASI DATA MINING UNTUK KLASIFIKASI MASA STUDI MAHASISWA MENGGUNAKAN ALGORITMA K-NEAREST NEIGHBOR,"IMPLEMENTASI DATA MINING UNTUK KLASIFIKASI MASA STUDI MAHASISWA MENGGUNAKAN ALGORITMA K-NEAREST NEIGHBOR

Inna Alvi Nikmatun  

ABSTRAK                                          
Akreditasi merupakan salah satu bentuk penilaian mutu dan kelayakan program studi  di perguruan tinggi . Ketepatan waktu mahasiswa dalam menyel esaikan studi dan proporsi mahasiswa yang menyelesaikan studi dalam batas masa studi termasuk dalam elemen penilaian akreditasi. Hal tersebut
menunjukkan  diperlukan pemantauan terhadap masa  studi mahasiswa. Rata-rata masa studi mahasiswa di Departemen Informatika Universitas Diponegoro masih di atas 4 tahun sehingga perlu dilakukan evaluasi dengan membangun aplikasi  pengklasifikasian masa studi mahasiswa. Dengan mempertimbangkan keseimbangan data maka pengklasi fikasian masa studi mahasiswa menggunakan kelas target masa studi <5 tahun dan >= 5 tahun.  Pada penelitian ini menggunakan data riwayat mahasiswa tahun angkatan 2007 sampai dengan 2011 yang telah lulus dengan jumlah data sebanyak 377 orang dengan 72 atribut nilai mata kuliah dan  1 kelas target  berupa masa studi . Penelitian ini dilakukan  dengan mengikuti tahap pengerjaan  data mining  yang mengacu pada  proses knowledge discovery in database  (KDD) . Pengklasifikasian dilakukan dengan menggunakan algoritma K-Nearest Neighbor. Aplikasi data mining berhasil dibangun dengan hasil percobaan menunjukkan bahwa hasil klasifikasi masa studi terbaik diperoleh dengan memilih atribut dari semua mata kuliah pilihan dengan nilai akurasi 75.95% .                                                  
Kata kunci:  mahasiswa, masa studi, KDD, k-nearest neighbor .                                         

ABSTRACT                                  
Accreditation is one form of assessment  of the quality and feasibility of study programs in higher education. Timeliness of students in completing studies and the proportion of students completing studies within the study period are included in the accreditation assessment element. This shows that it is necessary to monitor the student's study period. The average study period of students in the Informatics  Department of Diponegoro University is still over 4 years so it needs to be evaluated by building an application to classify student study periods. By considering the balance of data, the classifications of study periods of students use the target class of the study period <5 years and> = 5 years. In this study using historical data of students from 2007 to 2011 who have graduated with a total data of 377 people with 72 attributes of course values and 1 target class in the form of study period. This research was conducted by following the stages of data mining work that refers to the process of knowledge discovery in database (KDD). Classification is done using the K-Nearest Neighbor algorithm. Data mining applications were successfully built with experimental results showing that the best study period classification results were obtained by selecting attributes from all elective courses with an accuracy value of 75.95%.                  

Keywords: students, study period, KDD, k-nearest neighbor . 

1. PENDAHULUAN                                  
Program studi melaksanakan fungsi Tridarma Perguruan Tinggi yaitu pendidikan, penelitian dan pengabdian kepada masyarakat, serta mengelola iptek selaras yang sesuai dengan bidang studi tersebut. Untuk itu program studi harus mampu mengatur diri sendiri dalam meningkatkan dan menjamin mutu program studi. Mahasiswa merupakan aset bagi aplikasi pendidikan perguruan tinggi untuk itu perlu diperhatikan kelulusan mahasiswanya . Penilaian akreditasi ketepatan waktu menyelesaikan studi, proporsi 422 mahasiswa yang menyelesaikan studi dalam  batas masa studi termasuk dalam elemen penilaian akreditasi pada program studi  [1]. Penga ruh masa studi yang tepat waktu terhadap penilaian akreditasi perguruan tinggi maupun program studi sangat besar sehingga perlu dilakukan  mekanisme evaluasi untuk optimasi ketepatan masa studi mahasiswa. Data mahasiswa dan data kelulusan mahasiswa dapat menghasilkan informasi yang berlimpah, informasi yang tersembunyi dapat diketahui dengan cara melakukan pengelolaan pada data tersebut. Berdasarkan data yang diperoleh dari Departemen Ilmu Komputer/ Informatika  Universitas Diponegoro, pada mahasiswa tahun angkatan  2007 sampai dengan 2011 dengan  jumlah kelulusan 377  orang diperoleh informasi rata-rata masa studi mahasiswa masih di atas 4 tahun . Oleh karena itu perlu dilakukan analisis faktor-faktor yang mendukung tepat waktu dan juga faktor sebaliknya yang menyebabkan tidak tepat waktu . Penelitian terdahulu yang berkaitan dengan prediksi ketepatan kelulusan mahasiswa mendapatkan hasil akurasi dan 84% menggunakan algoritma K-NN [2] dan 82.08% dengan menggunakan algoritma naive bayes  [3].  Algoritma K-NN adalah salah satu algoritma yang sederhana untuk memecahkan masalah klasifikasi, algoritma K-NN sering menghasilkan hasil yang kompetitif dan signifikan  [4], dengan keunggulan tersebut maka  penelitian ini membangun  aplikasi klasifikasi masa studi mahasiswa menggunakan algoritma k-nearest neighbor  dengan atribut yang digunakan adalah nilai mata kuliah mahasiswa .                                 

2. TINJAUAN  PUSTAKA                                          
Pada tinjauan pustaka menyajikan hasil kajian pustaka yang berhubungan dengan teori-teori dalam pembuatan penelitan.  Pada bagian  ini di jelaskan konsep data mining , klasifikasi, k-nearest neighbor, k-fold cross validation, confusion matrix, dan korelasi pearson .                 
2.1 Data Mining                                          
Data mining  merupakan proses penggalian informasi dan berguna dari set data besar yang melibatkan konsep interdisipliner yang relatif baru yang melibatkan analisis data dan penemuan pengetahuan dari database dan menggunakan pendekatan multi-sisi yang mencakup analisis statistik, visualisasi data, penemuan pengetahuan, pengenalan pola dan manajemen basis data  [5]. Data Mining  mempunyai beberapa model proses yang digunakan untuk mengarahkan pelaksanaan data mining , model proses yang biasa digunakan adal ah Knowledge Discovery Databases (KDD), CRISP-DM dan SEMMA  [6]. Pada penelitian ini memakai model proses Knowledge Discovery Databases yang mempunyai 9 langkah yang dapat dilihat pada Gambar 1.                          
Gambar  1. Tahapan KDD  [6]                         
Berikut adalah penjelasan dari setiap  tahapan pada KDD : 
a. Domain Understanding and KDD Goals .         
Tujuan ditentukan dari sudut pandang user dan digunakan untuk mengembangkan dan pemahaman tentang domain aplikasi dan pengetahuan sebelumnya.                                  
b. Selection and Additions                          
Tahap kedua berfokus pada penentuan data target dan subset dari data sampel atau variabel.                          
c. Preprocessing: Data Cleaning 
Pembersihan dan preprocessing  data merupakan operasi dasar untuk menyelesaikan data yang konsisten tanpa noisy .          
d. Transformation                                  
Transformasi data dari satu bentuk ke bentuk lainnya sehingga data diimplementasikan dengan mudah.                  
e. Data Mining (Chosing the Suitable Data Mining Task)
Memillih metode data mining  yang sesuai berdasarkan tujuan tertentu yang telah didefinisikan pada tahap pertama, contoh dari metode data mining  adalah classification , regression , clustering  dan summarization .                 
f. Data Mining (Chosing the Suitable Data Mining Algorithm)  Memilih algoritma yang tepat untuk pencarian pola-pola data, algoritma yang dipilih berdasarkan kecocokan kriteria dengan metode data mining .                                         
g. Data Mining (Imploying Data Mining Algorithm)          
Pada tahap ini algoritma yang telah dipilih diimplementasikan .                                 
h. Evaluation and Interpretation                  
Tahap ini berfokus pada interpretasi dan evaluasi yang mencakup pemeriksaan apakah pola atau informasi yang ditemukan bertentangan dengan hipotesa yang ada sebelumnya.  i. Discovered Knowledge                          
Penggunaan pengetahuan yang ditemukan dari proses KDD, dimana memutuskan apa yang akan dilakukan dengan pengetahuan dihasilkan .                                                 
2.2 Klasifikasi                                          
Klasifikasi adalah sebuah proses untuk menemukan model yang menggambarkan dan membedakan kelas dari konsep data. Model ini diturunkan berdasarkan analisis satu set data pelatihan, model ini digunakan untuk memprediksi label kelas objek yang label kelasnya belum diketahui  [7].                         
2.3 K-Nearest Neighbor                                  
K-Nearest Neighbor (K-NN) merupakan salah satu algoritma  yang digunakan dalam masalah pengklasifikasian. Prinsip kerja K-NN ialah mencari jarak terdekat antar data yang akan dievaluasi dengan tetangga terdekat dalam data pelatihan  [8]. Algoritma K-Nearest Neighbor  (K-NN) adalah salah  satu algoritma  paling sederhana untuk memecahkan masalah klasifikasi dan sering menghasilkan hasil yang kompetitif dan signifikan  [4]. Untuk  menghitung jarak menggunakan j arak Euclidean . Rumus jarak Euclidean  didefinisikan dalam Persamaan (1):                                                 
-1                                                
Keterangan:                                          
 = data latih                                                  
  = data uji                                          
i    = variabel data                                          
d  = jarak                                                  
p = dimensi data                                          
2.4 K-fold Cross Validation                                  
K-fold cross validation  merupakan sebuah metode yang digunakan untuk mengetahui rata-rata keberhasilan pengklasifikasian dengan melakukan pembagian dataset secara acak menjadi k himpunan bagian  [9]. Kesalahan generalisasi pada K-fold cross validation , dan ditetapkan K menjadi 10 dengan dua alasan:                                          
a. untuk menyeimbangkan antara biaya komputasi dan estimasi yang di andalkan                                  
b. untuk perbandingan yang adil pada data latih dan data uji  Untuk 10-fold cross validation , dataset dibagi menjadi 10 lipatan yang saling terpisah dengan ukuran yang hampir sama. Dalam setiap run, 9 subset digunakan untuk pelatihan dan sisanya untu k validasi  [10]. Diagram 10-fold cross validation  dapat dilihat pada Gambar 2 . 
Gambar 2. Diagram 10-fold Cross Validat ion [10]         
2.5 Confusion Matrix                                          
Confusion Matrix merupakan salah satu cara untuk menganalisis kinerja model klasifikasi  [7]. Confusion Matrix dapat dilihat pada Gambar 3.                 
Gambar  3. Confusion Mat rix [7]                 
Akurasi dihitung dengan membandingkan jumlah data yang benar terklasifikasi dengan jumlah data keseluruhan. Cara perhitungannya dapat dilihat pada persamaan (2).         
-2                                                        
Precision  didefinisikan sebagai ukuran ketepatan. Jika data diprediksi positif, seberapa seringkah data prediksi itu benar. Nilai precision  dapat dilihat pada persamaan (3). 
-3                                        
Sedangkan recall  adalah ukuran kelengkapan. Dari jumlah data sebenarnya yang bernilai positif, sebanyak apakah data yang diprediksi positif.  Nilai recall  dapat dilihat pada persamaan (4).                                                 
-4                                                
Keterangan:                                                  
TP   = nilai true positives                                  
TN  = nilai true negatives                          
FP  = nilai false po sitives                                  
FN  = nilai false negatives                                  
P + N  = jumlah data                                 
2.6 Korelasi Pearson                                  
Korelasi pearson  merupakan matrik statistik yang mengukur kekuatan dan hubungan linear antara dua variabel acak. Korelasi pearson  telah diterapkan di berbagai indeks dalam statistik , seperti analisis data, klasifikasi, clustering , decision making , analisis keuangan, penelitian biologi dan lain-lain [11]. Rumus korelasi pearson  dapat dilihat pada persamaan (5). Interval koefisien korelasi dapat dilihat pada Tabel 1.
-5                                                        
Keterangan:                                                  
r   = Koefisien korelasi product moment                  
  = Jumlah total variabel x                                  
  = Jumlah total variabel  y                         
  = Jumlah antara skor x dan y                         
N   = Jumlah subjek/sampel                          
Tabel 1. Interval koefisien korelasi [12]          
Interval Koefisien Korelasi  Tingkat Hubungan                 
0,00 â€“ 0,199  Sangat Rendah                         
0,20 â€“ 0,399  Rendah                                  
0,40 â€“ 0,599  Sedang                                  
0,60 â€“ 0,799  Kuat                                          
0,80 â€“ 1,00 Sangat Kuat                                  

3. METODE PENELITIAN                                  
Metode penelitian yang digunakan pada penelitian ini menggunakan model proses data mining yaitu Knowledge Discovery Databases  (KDD ), yang terdiri  dari tahapan memahami domain dan tujuan, penggunaan data set dan penentuan target, pembersihan data dan pemrosesan awal data, pemilihan metode data mining , pemilihan algoritma data mining , implementasi algoritma data mining , evaluasi dan interpretasi                                                   
3.1 Memahami Domain Dan Tujuan                  
Berdasarkan data nilai mata kuliah mahasiswa Departemen Ilmu Komputer/ Informatika angkatan 2007 sampai dengan 2011 total jumlah kelulusan mahasiswa angkatan tersebut sejumlah 377 mahasiswa. Pada penelitian ini menggunakan data mah asiswa Departemen Ilmu Komputer/ Informatika angkatan 2007 sampai dengan 2011 dengan data mahasiswa yang cukup lengkap. Penelitian ini akan menggunakan k-nearest neghbor untuk mengklasifikasikan masa studi pada mahasiswa Departemen Ilmu Komputer/ Informatika yang kemudian hasil klasifikasi dapat digunakan sebagai salah satu alat evaluasi bagi departemen . 3.2 Penggunaan Dataset Dan Penentuan Target          
Dataset yang digunakan dalam proses KDD adalah data nilai mata kuliah yang didapat dari SIA Undip yang meliputi n ilai mata kuliah pada angkatan 2007 sampai dengan 2011 Pemilihan data nilai mahasiswa pada tahun 2007 sampai dengan 2011 dikarenakan pada tahun tersebut mempunyai kelengkapan data. Data mentah yang didapat sebelum dilakukan preprocessing berjumlah 27.842 d Imana terdapat beberapa atribut yaitu ta, jalur, nim, kmk, mk, nilai bobot, nilai asli, aktif dan smt untuk contoh data awal sebelum dilakukan preprocessing  dapat dilihat pada Tabel 3.1. Data yang akan digunakan pada penelitian ini adalah data nilai mata k uliah mahasiswa dengan atribut kode mata kuliah atau kmk, untuk penentuan kelas ta rget didasarkan pada persentase data dengan lama studi <=4 tahun sebesar 6.4% sedangkah <5 tahun sebesar 25% dari persentase tersebut kemudian ditentukan kelas target pada penelitian ini adalah <5 tahun dan >=5 tahun agar kelas target tidak terlampau jauh dimana didapat jumlah kelas <5 sebanyak 94 dan >=5 sebanyak 283. Untuk mendapat data yang dapat digunakan pada proses penelitian ini dilakukan preprocessing  data dengan cara penyederhanaan bentuk data yang akan dibahas pada sub-bab selanjutnya dimana hasil dari penyederhanaan menggunakan metode pivot yang akan digunakan pada penelitian ini .                                         
3.3 Pembersihan Dan Pemrosesan Awal Data                  
Dari data tersebut dilakukan proses pembersihan data dan preprocessing  untuk menangani missing value  dan noise dan data yang tidak konsisten agar menghasilkan data yang berkualitas .                                 
3.3.1 Pivot Data                                          
Data yang berjumlah 27.842 data yang kemudian dipivot menjadi 377 data yang nantinya akan dipakai untuk penel itian ini dengan cara memfilter mahasiswa dengan keterangan LULUS dan tidak memakai mahasiswa dengan keterangan NON_AKTIF dan AKTIF dan menggunakan nilai 2.0 sampai dengan 4.0 dan menggunakan nilai terbaik dari nilai mata kuliah perbaikan sesuai dengan peraturan akademik Universitas Diponegor o [13] pada Pasal 31 ayat (4) butir  d yang menyebutkan bahwa â€œMahasiswa dinyatakan lulus mata kuliah, apabila mendapat nilai minimal Câ€ dan Pasal 17 ayat 6 â€œSetiap Mahasiswa Program sarjana wajib lulus semua mata kuliah dan sejumlah mata kuliah pilihan yang tercakup dalam kurikulum program studiâ€, dan Pasal 31 ayat (4) butir f menyebutkan bahwa â€œMahasiswa yang mendapat nilai D,C,B dapat melakukan perbaikan pada semester regular  atau remidi pada semester berjalan, dan nilai yang dipakai adalah nilai  yang terbaikâ€. Pada penelitian ini mengguna kan 2 kelas yaitu <5 dan >=5 yang didapat dari semester mahasiswa, dimana semester kurang dari 10 menjadi kelas <5 dan lebih besar dari sama dengan 10 menjadi kelas >=5 . Berikut adalah langkah-langkah dilakukannya pivot:                          
a. Menggabungkan semua data nilai mata  kuliah mahasiswa dari angkatan 2007 sampai dengan 2011 .                 
b. Menghapus data yang bernilai 0 pada kolom nilai bobot.   c. Menghapus data yang bernilai -1 pada kolom nilai bobot.  d. Menghapus data yang bernilai 1 pada kolom nilai bobot  
e. Menggunakan data mahasiswa yang berstatus LULUS          
f. Mengonversi seluruh data ke kurikulum 2007          
g. Menghapus kolom jalur, mk, nilaiasli, aktif          
h. Menghilangkan duplikasi data dan diambil yang paling besar (dari duplikasi data)                                  
i. Membentuk pivot berdasarkan NIM (Nilai Induk Mahasiswa)  j. Menentukan Kelas                                  
k. Menghapus kolom Nim, ta, smt                  
3.3.2 Replace Missing Value                          
Pada data yang diperoleh terdapat beberapa data yang masih kosong atau tidak ada nilainya. Missing value  merupakan informasi yang tidak tersedia untuk sebuah kasus, missing value dapat terjadi karena penolakan dari respon den untuk menjawab pertanyaan yang diajukan, kesalahan saat pengumpulan data misalnya pertanyaan terlewat sehingga tidak memperolah jawaban, kesalahan saat entri data, informasi yang tidak diberikan, sulit dicari atau memang informasi tersebut tidak ada  [14]. Penanganan missing value dapat dilakukan dengan berbagai cara. Salah satu penanganan missing value adalah dengan mengisi nilai yang kosong dengan metode imputasi mean , mean merupakan salah satu metode yang paling umum digunakan, metode mean  dilakukan dengan mengisi data yang missing dalam suatu variabel dengan nilai mean dari semua nilai yang diketahui dari variabel tersebut  [15]. Pada penelitian ini menggunakan imputasi yaitu nilai mean sebagai pengganti pada data yang bernilai kosong untuk mata kuliah wajib dan mengisi nilai yang kosong dengan nilai 0 untuk mata kuliah pilihan penggantian missing value dengan nilai 0 pada mata kuliah pilihan dilakukan karena pada data yang missing untuk mata kuliah pilihan berarti tidak mengambil mata kuliah pilihan tersebut.  Alur proses replace missing value  mata kuliah wajib ditunjukkan pada Gambar 4.  Gambar  4. Alur Proses Replace Missing Value                  
3.4 Pemilihan Metode Data Mining                  
Tahap ini merupakan tahap pemilihan metode data mining. Terdapat beberapa metode pada data mining diantaranya klasifikasi, klastering, asosiasi, regresi dan lain-lain, Dari data yang diperoleh sudah terdapat target dimana dapat dikategorikan termasuk data supervised learning yang bertujuan untuk menemukan pola baru dalam data dengan menghubungkan pola data yang sudah ada dengan data baru. Supervised learning merupakan sinonim untuk klasifikasi, supervised learning sebuah metode dimana pengetahuan didapat dari label yang terdapat pada set data pelatihan [4]. Metode klasifikasi merupakan salah satu metode supervised learning maka dipilih metode klasifikasi untuk mem bantu menangani status masa studi pada mahasiswa .                 
3.5 Pemilihan Algoritma Data Mining                          
Algoritma yang digunakan pada penelitian ini adalah K-Nearest Neighbor . Algoritma K-Nearest Neighbor merupakan salah satu algoritma dari metode klasifikasi yang bertujuan untuk mengklasifikasikan objek baru berdasarkan jarak antara data latih dan data uji. Algoritma K-NN merupakan algoritma yang digunakan untuk mengklasifikasikan objek baru berdasarkan atribut dan data training .                 
3.6 Implementasi Algoritma Data Mining                  
Pada tahap ini dilakukan penerapan algoritma data mining , dari data yang telah  di olah sebelumnya , seperti dilakukannya penanganan missing value . Data yang dihasilkan pada proses tersebut kemudian digunakan untuk implementasi menggunakan algoritma K-Nearest Neighbor . Berikut adalah tahapan algoritma K-Nearest Neighbor  :                 
a. Menggunakan data latih, data uji dan jumlah k.         
Pada tahap pertama yaitu menggunakan data latih, data uji dan jumlah k tetangga terdekat K-NN.                 
b. Menghitung jarak Euclidean antara data uji dengan data  latih                                         
Menghitung  jarak menggunakan rumus jarak euclidean distance pada persamaan 1.                                          
c. Mengurutkan hasil perhitungan jarak Euclidean secara ascending                                          
Dari hasil perhitungan jarak, hasil tersebut diurutkan secara ascending  atau dari terkecil ke terbesar untuk  mengetahui kedekatan jarak dengan data uji.                  
d. Mengambil sejumlah k data dari hasil pengurutan  Berdasarkan hasil jarak yang telah diurutkan secara ascending diambil sebanyak K tetangga terdekat          
e. Menentukan Kelas berdasarkan kelompok mayoritas  
Hasil dari pemil ihan tetangga terdekat sebanyak k tetangga menjadi penentu kelas dari data uji.  
3.7 Evaluasi dan Interpretasi                                  
Pada tahap ini dilakukan evaluasi dan dilakukan interpretasi terhadap hasil dari klasifikasi masa studi. Pada evaluasi melibatkan perhitungan nilai  akurasi, precision  dan recall  dari data tersebut dengan menggunakan metode evaluasi K-fold cross validation  dengan k-fold = 10.  Tahap interpretasi merupakan tahap visualisasi dari hasil evaluasi yang dilakukan.                                                  
3.8 Penggunaan Pengetahuan yang Ditemukan                  
Pada  tahap penggunaan knowledge  merupakan tahap akhir dari model KDD, hasil dari pengembangan algoritma yang telah dilakukan diimplementasikan ke  dalam sebuah aplikasi klasifikasi masa studi mahasiswa                          

4. HASIL DAN PEMBAHASAN                                  
Pada bab ini akan diuraikan hasil penelitian dan pembahasan mengenai penelitian yang telah dilakukan meliputi skenario pengujian yang bertujuan untuk melakukan pengujian terhadap akurasi dari penerapan algoritma K-Nearest Neighbor pada dataset yang digunakan. Skenario pengujian meliputi peng ujian akurasi dari variasi-variasi atribut yang digunakan . Terdapat 6 skenario yang dilakukan pada penelitian ini untuk mendapatkan akurasi terbaik dari algoritma yang digunakan.  4.1 Skenario Pengujian 1                                  
Pada Pengujian 1 dilakukan untuk mengetahui performa K-Nearest Neighbor dengan menggunakan seluruh atribut yang ada pada dataset dengan menggunakan model k-fold cross validation  dengan nilai k = 10 dan tetangga terdekat sejumlah k=3 sampai dengan k=29 dengan nilai k tetan gga bernilai ganjil. Perhitungan yang dilakukan  akan menghasilkan nilai akurasi, precision  dan recall . Hasil skenario pengujian 1 dapat dilihat pada Gambar 5. 
Gambar  5. Hasil Skenario Pengujian 1                          
Dari Gambar di  atas ditampilkan hasil rata-rata pada akurasi, precision  dan recall . Parameter yang dijadikan performa akurasi. Sehingga didapat k terbaik untuk skenario 1 pada k=11 dengan performa akurasi 75.41%, precision  91.61% dan recall  79.24%.                                  
4.2 Skenario Pengujian 2                                  
Pada Pengujian 2 dilakukan untuk mengetahui performa K-Nearest Neighbor denga n menggunakan atribut mata kuliah semester 1 sampai dengan semester 4  dengan menggunakan model k-fold cross validation  dengan nilai k = 10 dan tetangga terdekat sejumlah k=3 sampai dengan k=29 dengan nilai k tetangga bernilai ganjil. Perhitungan yang dilakukan akan menghasilkan nilai akurasi, precision  dan recall . Hasil skenario pengujian 2 dapat dilihat pada Gambar 6. Gambar   6.  Hasil Skenario Pengujian 2                 
Dari Gambar di  atas ditampilkan hasil rata-rata pada akurasi, precision  dan recall . Parameter yang  dijadikan performa akurasi. Sehingga didapat k terbaik untuk skenario 2 pada k=29 dengan performa akurasi 72.75%, precision  95.30% dan recall  75.43%.                                  
4.3 Skenario Pengujian 3                                  
Pada Pengujian 1 dilakukan untuk mengetahui performa K-Nearest Neighbor dengan menggunakan atribut mata kuliah hanya wajib dengan menggunakan model k-fold cross validation  dengan nilai k = 10 dan tetangga terdekat sejumlah k=3 sampai dengan k=29 dengan nilai k tetan gga bernilai ganjil. Perhitungan yang dilakukan akan menghasilkan nilai akurasi, precision  dan recall . Hasil skenario pengujian 3 dapat dilihat pada Gambar 7.                                 
Gambar  7. Skenario Pengujian 3                         
Dari Gambar di  atas ditampilkan hasil rata-rata pada akurasi, precision  dan recall . Parameter yang dijadikan performa akurasi. Sehingga didapat k terbaik untuk skenario 3 pada k=5 dengan performa akurasi 71.38%, precision  78.45% dan recall  82.34%.                                          
4.4 Skenario Pengujian 4                                  
Pada Pengujian 1 dilakukan untuk mengetahui performa K-Nearest Neighbor dengan menggunakan atribut semua mata kuliah pilihan  dengan menggunakan model k-fold cross validation  dengan nilai k = 10 dan tetangga terdekat sejumlah k=3 sampai dengan k=29 dengan nilai k tetan gga bernilai ganjil. Perhitungan yang dilakukan akan menghasilkan nilai akurasi, precision  dan recall . Hasil skenario pengujian 4 dapat dilihat pada Gambar 8. 
Gambar  8. Skenario Pengujian 4                         
Dari Gambar di  atas ditampilkan hasil rata-rata pada akurasi, precision  dan recall . Parameter yang dijadikan performa akurasi. Sehingga didapat k terbaik untuk skenario 4 pada k=23 dengan performa akurasi 75.95%, precision  97.27% dan recall  77.17%.                                  
4.5 Skenario Pengujian 5                                  
Pada Pengujian 1 dilakukan untuk mengetahui performa K-Nearest Neighbor dengan menggunakan atribut mata kuliah relasi  dengan menggunakan model k-fold cross validation  dengan nilai k = 10 dan tetangga terdekat sejumlah k=3 sampai dengan k=29 dengan nilai k tetangga bernilai ganjil. Perhitungan yang dilakukan akan menghasilkan nilai akurasi, precision  dan recall . Hasil skenario pengujian 5 dapat dilihat pada  Gambar 9.                         
Gambar  9. Skenario Pengujian 5                         
Dari Gambar di  atas ditampilkan hasil rata-rata pada akurasi, precision  dan recall . Parameter yang dijadikan performa akurasi. Sehingga didapat k terbaik untuk skenario 4 pada k=19 dengan performa akurasi 74.65 %, precision  96.34% dan recall  76.17%                                  
4.6 Skenario Pengujian 6                                  
Pada Pengujian 1 dilakukan untuk mengetahui performa K-Nearest Neigh bor dengan menggunakan atribut mata kuliah komdas dengan menggunakan model k-fold cross validation  dengan nilai k = 10 dan tetangga terdekat sejumlah k=3 sampai dengan k=29 dengan nilai k tetan gga bernilai ganjil. Perhitungan yang dilakukan akan menghasilkan nilai akurasi, precision  dan recall . Hasil skenario pengujian 6 dapat dilihat pada Gambar 10. 
Gambar  10. Skenario Pengujian 6                         
Dari Gambar di  atas ditampilkan hasil rata-rata pada akurasi, precision  dan recall . Parameter yang dijadikan performa akurasi. Sehingga didapat k terbaik untuk skenario 4 pada k=9 dengan performa akurasi 75.15%, precision  93.15% dan recall  77.65%. Dari ke enam skenario di  atas dapat dianalisa bahwa kategori mata kuliah yang memiliki informasi akurat mengenai masa studi adalah mata kuliah pilihan yang memiliki nilai akurasi tertinggi dibanding dengan skenario lainnya yaitu 75.95%. Grafik akurasi terbaik  pada setiap skenario dapat dilihat pada Gambar 11.                 
Gambar  11. Grafik Performa Terbaik Setiap Skenario          

5. KESIMPULAN                                          
Kesimpulan yang dapat diambil dari penelitian mengenai klasifikasi masa studi mahasiswa menggunakan algoritma K-Nearest Neighbor  adalah sebagai berikut:          
a. Dengan mengacu proses data mining Knowledge Discovery Databases telah  dibangun  sebuah perangkat lunak yang dapat melakukan klasifikasi masa studi mahasiswa.                  
b. Dari enam skenario percobaan yang telah dilakukan diperoleh  nilai akurasi tertinggi pada skenario yang menggunakan atribut mata kuliah pilihan yaitu 75.95% .         
c. Berdasarkan nilai akurasi tertinggi menggunakan semua mata kuliah pilihan dapat disimpulkan bahwa mata kuliah pilihan sangat berpengaruh pada masa studi mahasiswa.  

DAFTAR PUSTAKA                                  
[1] BAN-PT, â€œBuku 3B -Borang Fakultas-Sekolah Tinggi (Versi 08 -04-2010),â€ Ban-Pt. 2008.                          
[2] A. G. Novianti and D. Prasetyo, â€œPenerapan Algoritma K-Nearest Neighbor (K-NN) untuk Prediksi Waktu Kelulusan M ahasiswa,â€ Semin. Nas. APTIKOM , no. November, pp. 108 â€“113, 2017.                                          
[3] Y. S. Nugroho, â€œDATA MINING MENGGUNAKAN ALGORITMA NAÃVE BAYES UNTUK KLASIFIKASI KELULUSAN MAHASISWA UNIVERSITAS DIAN NUSWANTORO,â€ vol. 75, no. 3 PART A, pp. 1 â€“3, 2014.                                                  
[4] D. A. Adeniyi, Z. Wei, and Y. Yongquan, â€œAutomated Web Usage Data Mining and Recommendation System Using K -Nearest Neighbor (KNN) Classification Method,â€ Appl. Comput. Informatics , 2016.                                          
[5] S. Jambekar and Z. Saquib, â€œApplication of Data Mining Techniques for Prediction  of Crop Production in India,â€ vol. 7, no. 4, pp. 66 â€“69, 2018.                          
[6] U. Shafique and H. Qaiser, â€œA Comparative Study of Data Mining Process Models (KDD, CRISP-DM and SEMMA),â€ Int. J. Innov. Sci. Res. ISSN , vol. 12, no. 1, pp. 2351 â€“8014, 2014.                                          
[7] J. Han, M. Kamber, and J. Pei, Data Mining Concepts and Techniques , vol. 84. 2013.                                  
[8] T. Rismawan, A. W. Irawan, W. Prabowo, and S. Kusumadewi, â€œSistem Pendukung Keputusan Berbasis Pocket PC Sebagai Penentu Status Gizi Menggunakan Metode KNN (K-Nearest Neighbor),â€ teknoin , vol. 13, pp. 18 â€“23, 2008.  [9] R. Kohavi, â€œA Study of Cross -Validation and Bootstrap for Accuracy Estimation and Model Selection,â€ Appear. Int. Jt. Conf. Articial Intell. , vol. 5, pp. 1 â€“7, 1995.  
[10] Y. Zhang and S. Wang, â€œDetection of Alzheimerâ€™s Disease by Displacement Field and Machine Learning,â€ PeerJ , vol. 3, p. e1251, 2015.                          
[11] H. Zhou, Z. Deng, Y. Xia, and M. Fu, â€œA New Sampling Method in Particle Filter Based on Pearson Correlation Coefficient,â€ Neurocomputing , vol. 216, pp. 208 â€“215, 2016.                                                  
[12] Sugiyono, Statistik Untuk Penelitian . 2007.          
[13] R. U. Diponegoro, â€œPeraturan Akademik Bidang Pendidikan Program Sarjana Universitas Diponegoro,â€ 2017.  [14] T. Hendrawati, â€œKajian Metode Imputasi dalam Menangani Missing Data,â€ Pros. Semin. Nas. Mat. dan Pendidik. Mat. UMS , pp. 637 â€“642, 2015.                  
[15] E. Acuna and C. Rodriguez, â€œThe Treatment of Missing Values and Its Effect in The Classifier Accuracy,â€ Classif. Clust. Data Min. Appl. , no. 639 â€“647, pp. 1 â€“9, 2004. ",klasifikasi,"Knowledge Discovery in Database, KDD, K-Nearest Neighbor, KNN",data nilai mata kuliah,"akurasi, precision, recall"
Klasifikasi Berita Hoax Dengan Menggunakan Metode Naive Bayes,"Klasifikasi Berita Hoax Dengan Menggunakan Metode Naive Bayes

Hery Mustofa1  Adzhal Arwani Mahfudh2 

Abstract  
Hoaxes contain false news or non-sourced news. Today, hoaxes are very widely spread through internet media. The development of information technology that has so quickly triggered the spread of hoax information through the internet has become uncontrolled.  So we need an intelligent system that can classify hoax news content that is spread through internet media. The hoax classification process can 
be done through the preprocessing stage then weighting the word and classification using naive bayes. Measurements were made using the 10-ford cross validation method. The results obtained from these measurements, it is known that the value of fold 6 has the highest accuracy, which is equal to 85.28% which is classified as relevant documents as much as 307 and irrelevant as much as 53 or an error rate of 14.72%. While the average value based on hoax news and true news value precision 0.896 and recall 0.853  
 
Keywords  :  hoax, klasifikasi, naive bayes, text minning  
 
Abstrak  
Hoax dapat berarti  berita bohong atau berita yang tidak  mempunyai  sumber. Saat ini, hoax sangat banyak tersebar melalui media internet. Perkembangan teknologi informasi yang begitu cepat memicu penyebaran informasi hoax melalui internet menjadi tidak terkontrol. Sehingga di perlukan suatu sistem cerdas yang dapat melakukan klasifikasi konten berita hoax yang tersebar melalu media internet. Proses klasifikasi hoax dapat dilakukan melalui tahap preprocessing kemudian pembobotan kata dan dilakukan klasifikasi menggunakan naive bayes. Pengukuran dilakukan dengan metode 10-ford cross validation. Dari pengukuran tersebut diperoleh hasil , nilai fold 6 mempunyai keakuratan tertinggi, yaitu sebesar 85.28 % yang mana dokumen terklasifikasi yang relevan sebanyak 307 dan dokumen tidak rel evan sebanyak 53  atau error rate sebesar 14.72%. Sedangkan nilai rata -rata berdasarkan dokumen berita hoax dan dokumen berita benar nilai precision 0,896 dan recall 0.853.  
 
Kata kunci :   hoax, klasifikasi, naive bayes text minning  

1. PENDAHULUAN  
Dalam Kamus Besar Bahasa Indonesia ( KBBI ) hoax  mempunyai  
makna berita bohong, berita tidak bersumber. (Kemendikbud, 2019)   Hoax adalah informasi sesat dan berbahaya . Hoax  dapat  menyesatkan persepsi  atau pandangan  manusia dengan menyampaikan  atau menyebarkan  informasi palsu sebagai suatu kebenaran.  (Afriza & Adisantoso, 2018)  Secara garis besar hoax adalah berita yang menyesatkan karena tidak mempunyai  sumber yang bisa dipertanggungjawabkan dan bukti yang jelas. Berita hoax sengaja diciptakan oleh segelintir orang untuk memperoleh keuntungan pribadi demi tujuannya tercapai.  Saat ini berita hoax banyak tersebar melalui internet . Perkembangan teknologi informasi yang begitu cepat, memicu penyebaran informasi melalu internet  yang tidak terkontrol, salah satu di dalamnya informasi dokumen yang mengandung hoax. Di Indonesia Teknologi informasi telah  berkembang den gan sangat  pesat di mana jumlah pengguna internet di Indonesia saat ini semakin terus bertambah. Menurut survei yang telah dilakukan oleh  lembaga  Asosiasi Penyelenggara Jasa Internet Indonesia (APJII) pada tahun 2017 dijelaskan bahwa penetrasi pengguna internet Indonesia mencapai 143,26  juta jiwa atau 54,56% dari total populasi penduduk Indonesia 262 juta orang. (Asosiasi Penyelenggara Jasa Internet Indonesia (APJII) , 2017)   Untuk mengetahui berita informasi hoax atau fakta yang tersebar di internet, diperlu kan metode klasifikasi dokumen secara manual maupun secara otomatis oleh sistem.  Klasifikasi dokumen yaitu proses  atau metode dalam  menemukan  sekumpulan model yang mendeskripsikan dan membedakan kelas-kelas data sesuai dengan kategori yang dimilikinya. (Asosiasi Penyelenggara Jasa Internet Indonesia (APJII) , 2017)  Tujuan dari klasifikasi adalah untuk melakukan prediksi kelas dari obyek yang belum diketahui kelas dan karakteristik tipe datanya. Identifikasi konten hoax sudah dilakukan oleh komunitas internet yang tergabung di situs turnbackhoax.id. Situs tersebut dikelola oleh MAFINDO (masyarakat anti hoax Indonesia), sumber konten berasal dari laporan dari forum di jejaring sosial Facebook dengan nama FAFHH (forum anti fitnah hasut dan hoax).  Metode identitas atau klasifikasi yang dilakukan pada situs turnbackhoax.id masih dilakukan secara manual, sehingga jika informasi semakin berkembang akan kesulitan dikarenakan informasi yang masuk semakin banyak. Dalam penelitian ini kan dilakukan klasifikasi menggunakan model pendekatan data mining sehingga klasifikasi dapat dilakukan oleh sistem secara otomatis.  Data mining  adalah suatu  proses ekstraksi atau penggalian data yang belum diketahui  sebelumnya. (Connoly & Begg, 2015)  Data tersebut digali informasinya berdasarkan database besar untuk diambil keputusan yang penting. Sedangkan klasifikasi adalah kumpulan model  Klasifikasi Berita Hoax Dengan Menggunakan Metode Naive Bayes yang dapat melakukan ilustrasi atau menggambarkan  dan membedakan kelas data atau konsep, dengan tujuan mampu menggunakan model untuk  melakukan  prediksi kelas dari objek yang label kelasnya tidak diketahui. Model tersebut didasarkan pada pola analisis kumpulan data latih. (Han & Kamber, 2000)   Sebelum berita di lakukan klasifikasi maka diperlukan tahap preprocessing . Preprocessing mempunyai tahapan sebagai berikut, yaitu yang pertama case folding, kedua tokenizing/parsing, ketiga filtering  dan ke empat  stemming . Proses stemming  menjadi tahapan paling penting di dalam tahap preprocessing dikarenakan pada stemming  terjadi proses penghilangan kata imbuhan sehingga kata menjadi kata dasar. (Triawati, 2009)  Model klasifikasi  yang  akan  digunakan  dalam penelitian ini adalah metode klasifikasi naive bayes . Naive bayes  telah banyak digunakan pada data medis, jaringan komputer dan teks dikarenakan kesederhanaan, efektif dan kompabilitas menangkap visualisasi model data. (Abraham, 2009) Penelitian terkait dengan klasifikasi konten berita pernah dilakukan sebelumnya, yaitu penelitian menggunakan metode naive bayes  untuk klasifikasi berita  olahraga dengan enhanced  confix stripping stemmer . Terdapat 2 jenis dokumen berita yaitu berita latih dan berita uji. Berita latih didapat dari situs berita olahraga sport.detik.com. Peneliti mengambil 151 berita latih dari 6 kategori yaitu sepakbola, basket, raket, motoGP, formula 1 dan berita olahraga lainnya. Penelitian ini menggunakan datasets sebanyak 18 berita yang dipilih acak  atau random . Dari 18 berita yang diujikan , diketahui  terdapat 14 berita yang bernilai benar. Dari Penelitian itu dapat disimpulkan bahwa keakuratan klasifikasi naive bayes  dengan enhanced confix stripping stemmer sebesar 77%.  (Pramudita, Putro, & Makhmud, 2018)   Penelitian selanjutnya klasifikasi hoax pada  dokumen  berita bahasa indonesia yang  mempunyai tema kesehatan dengan menggunakan metode Modified K-Nearest Neighbor .  Proses klasifikasi hoax ini memiliki 
beberapa tahapan  yaitu  dimulai dari  tahap preprocessing , pembobotan dan klasifikasi dengan menggunakan metode Modified K-Nearsest Neighbor . Datasets yang digunakan diperoleh  dari  jejaring sosial dan portal berita yang berjumlah 51 berita telah dilabeli oleh pakar  secara manual  dan 67 dilabeli oleh tim hoax  buster secara manual serta  52 berita yang dilabeli oleh  sistem secara otomatis . Dari penelitian itu diperoleh hasil  sebagai berikut. Pengujian  terbaik dengan  nilai k berjumlah 4, dengan precision  sebesar 0,83 recall  sebesar 0,75, dan f-measure  sebesar 0.79 serta menghasilkan akurasi  akurasi sebesar 75%. (Prasetyo & Adikara, 2018)  Berdasarkan paparan di atas, diketahui bahwa klasifikasi naive bayes  memberikan akurasi lebih tinggi dibandingkan dengan klasifikasi K-Nearsest Neighbor . Oleh karena itu, dalam penelitian ini akan dilakukan klasifikasi berita hoax menggunakan naive bayes  . Tujuannya adalah untuk mengetahui tingkat akurasi metode  naive bayes digunakan untuk  klasifikasi berita hoax berbahasa Indonesia.  
 
2. METODE  
Metode penelitian ini akan menggunakan algoritma naive bayes  dengan data masukan berupa dokumen teks. Setelah itu dokumen teks dilakukan preprocessing  dengan tanpa menggunakan steming . Setelah itu, kemudian dilakukan proses pembobotan kata pada data latih  (data training ). Selanjutnya dilakukan klasifikasi teks berita tersebut dengan menggunakan algoritma naive bayes . Pengukuran dilakukan dengan menggunaka metode 10-Ford Cross Validation . Hasil akhir dari proses klasifikasi  menggunakan naive bayes  akan menghasilkan output  berupa berita  yang sudah terlabeli  hoax dan fakta. Tahapan sistem dapat  terlihat  seperti pada gambar 1.  

3. KERANGKA TEORI  
Di dalam kerangka teori akan dibahas dan dikupas beberapa hal atau istilah  terkait dasar teori yang digunakan di dalam penelitian.    
3.1  Berita  
Berita dapat berupa  informasi terbaru yang dapat menarik pembaca dan disampaikan lewat media seperti internet, koran, layar kaca, jejaring sosial, atau media  lainya. Sebuah berita harus memuat  unsur berikut, yaitu : 5W+1H  (what, who, when, where, why dan How ). (Cahya, 2012) 
Gambar 1  
Metode Penelitian   
3.2  Hoax  
Berita yang mengandung makna berita bohong, berita tidak bersumber disebut hoax . (Kemendikbud, 2019)   Informasi yang sesat dan berbahaya karena menyesatkan persepsi manusia dengan menyampaikan informasi palsu sebagai kebenaran  disebut Hoax  (Afriza & Adisantoso, 2018)  Berita Hoax merupakan  manipulasi berita yang sengaja dibuat dengan tujuan untuk memberikan informasi yang salah  sehingga menyesatkan atau mengaburkan persepsi masyarakat . 
3.3  Preprocessing  
Preprocessing  adalah proses melakukan perubahan dari dokumen teks menjadi term index  dengan tujuan untuk menghasilkan set term index  sehingga dapat digunakan sebagai  key word  untuk mengawali sebuah dokumen.  (Fauzi, t.thn.)  Tahapan preprocessing  adalah sebagai berikut :   
3.3.1 Parsing  
Dokumen sebelum di proses, proses awal yaitu dilakukan parsing . Proses pemotongan struktur dokumen menjadi beberapa komponen yang terpisah  disebut sebagai parsing .   
3.3.2  Tokenisasi  
Proses tokenisasi  yaitu  proses penghilangan  angka,  tanda baca, dan karakter selain huruf alfabet. Kemudian proses  tokeninsasi  selanjutnya  yaitu  pemotongan string input  berdasarkan tiap kata penyusunya. Dikarena kan karakter tersebut merupakan suatu pemisah kata ( delimeter ) yang mana tidak memiliki kegunaan terhadap pemrosesan teks. Tahapan selanjutnya yaitu case folding . Case folding  yaitu  proses perubahan huruf  besar menjadi kecil , di mana semua kata yang mengandung huruf besar diubah menjadi huruf kecil. Tahapan case folding  terakhir yaitu tahapan cleaning  mempunyai fungsi  menghilangkan informasi yang tidak berhubungan dengan dokumen . Sebagai contoh yaitu  code script, link, HTML  dan lain sebagainya.  
3.3.2  Filtering  dan Stopword Removal  
Di dalam tahapan ini melaku kan proses stoplist  atau stopword.  Proses tersebut adalah melakukan penghilangan kata-kata yang tidak penting dengan pendekatan bag-of-word . Hasil dari stoplist  adalah wordlist  yang berisi kata penting.   
3.3.3 Stemming  
Stemming  merupakan suatu teknik untuk mentransformasi kata-kata dalam sebuah dokumen teks menjadi bentuk kata dasar. Proses stemming berbeda-beda dalam tiap bahasa .  Setiap bahasa memiliki aturan-aturan yang berbeda dalam 
penggunaan kata berimbuhan  dan mempunyai aturan-aturan sendiri . Bahasa Perancis memiliki perbedaan aturan penggunaan tata bahasa dengan Bahasa Arab. Pada Bahasa Indonesia kopleksitas ada pada variasi imbuhan .  Hal tersebut menjadi  penting dalam pembentukan kata dasarnya.    
3.4  Pembobotan Kata  
Pembobotan kata  yaitu penghitungan kata pada jumlah kemunculan masing-masing token  dalam dokumen. Pembobotan kata yang paling banyak dipakai yaitu skema term  frequency-inverse document  frequency  (TF-IDF). Term  frequency  (TF) didefinisikan sebagai jumlah kemunculan suatu kata/istilah dalam suatu dokumen. (Fauzi, t.thn.)    
3.5  Term Frequency  
Merupakan banyaknya tingkat kemunculan kata t dalam suatu  dokumen d. Rumus term frequency  dapat dilakukan persamaan  matematika  sebagai berikut :   
Keterangan :  
ð‘Šð‘¡ ð‘“ ð‘¡,ð‘‘= Jumlah Frekuensi 
kemunculan kata t dalam dokumen d  
3.6  Invers Document Frequency  
Inverse  document frequency  atau IDF  adalah banyak dokumen yang mengandung kata/ token /term  t. Rumus IDF dapat  dinotasiakan sesuai  pada persamaan berikut :   
ð‘–ð‘‘ð‘“ð‘¡= log 10ð‘
ð‘‘ ð‘“ð‘¡   
Keterangan :  
ð‘–ð‘‘ð‘“ð‘¡  =  Banyaknya dokumen yang 
memuat t 
ð‘  =  Jumlah total dokumen   
3.7  TF.IDF Weighting  
TF.IDF  Weighting  adalah  bobot hasil perkalian dari ð‘¡ ð‘“ ð‘¡,ð‘‘ dan ð‘–ð‘‘ð‘“ð‘¡, rumus TF.IDF  Weighting  dapat dinotasikan pada persamaan  (3) dan normalisasinya dapata dinotasikan pada persamaan (4).   
ð‘–ð‘‘ð‘“ð‘¡= log 10ð‘
ð‘‘ ð‘“ð‘¡           (3)  
ð‘Šð‘¡,ð‘‘
= ð‘Šð‘¡ ð‘‘
âˆšâˆ‘=1 ð‘Šð‘¡,ð‘‘ð‘‘2ð‘›
ð‘¡ (4) 
3.8  Cousine Similarity  
Merupakan proses untuk menghitung besarnya derajat kemiripan antara dokumen dan query. Nilai cousine similarity  dapat dihitung  berdasarkan perhitungan besarnya nilai fungsi cosine terhadap sudut yang dibentuk oleh dua  buah  vektor. Jika ditarik pada penelitian ini cousine similarity  adalah sebuah representasi dari beberapa dokumen antar data 
latih. Rumus untuk menghitung tingkat kemiripan dokumen satu dengan dokumen lain di notasikan  pada per samaan (5) dan 
normalisasinya dapat dinotasikan pada  persamaan (6).   
ð‘Šð‘¡ ð‘“ ð‘¡,ð‘‘= { 1+ð‘™ð‘œð‘” 10ð‘¡ð‘“ð‘¡,ð‘‘,
0,         ð‘–ð‘“ ð‘¡ð‘“ð‘¡,ð‘‘>0
ð‘œð‘¡â„Žð‘’ð‘Ÿð‘¤ð‘–ð‘ ð‘’    
3.9  Naive Bayes  
Bentuk analisis data yang mengekstrak model untuk menggambarkan kelas data  dapat disebut sebagai klasifikasi . Sedangkan,  model yang dibangun meliputi proses pengklasifikasian dan  proses  prediksi kategori berdasarkan label  kelas. Klasifikasi dapat di aplikasikan ke dalam berbagai bidang seperti deteksi penipuan, target marketing, prediksi kerja dan lainnya.  Naive Bayes Classifier   atau NBC  merupakan proses pengklasifikasian probabilitas sederhana yang  mengacu  pada Teory  Bayes . Teori tersebut menyatakan bahwa kemungkinan terjadinya suatu peristiwa sama dengan probabilitas intrinsik (dihitung dari data yang tersedia sekarang) dikalikan probabilitas bahwa hal serupa akan terjadi lagi di masa depan (berdasarkan pengetahuan yang terjadinya di masa lalu).  Naive bayes  adalah algoritma pembelajaran probabilitas yang berasal dari teori Keputusan Bayesian. Probabilitas d berada di kelas c, P (c | d), dihitung sebagai   
ð‘ƒ(ð‘|ð‘‘)
âˆð‘ƒ (ð‘) âˆ ð‘ƒ(ð‘¡ð‘˜| ð‘)ð‘š
ð‘˜=1 (7)  
Di mana ð‘ƒ(ð‘¡ð‘˜| ð‘) adalah probabilitas  bersyarat  dari  fitur  ð‘¡ð‘˜ yang ada dalam pesan kelas  c dan 
ð‘ƒ (ð‘) adalah  
probabilitas  sebelumnya dari  pesan  yang terjadi  di kelas  c. ð‘ƒ(ð‘¡ð‘˜| ð‘) dapat digunakan untuk  mengukur 
kontribusi tk  ke dalam c, di mana c kelas  yang benar . Dalam  klasifikasi  teks kelas pesan ditentukan  dengan mencari  kemungkinan besar  atau  maksimal  posteriori  (MAP)  kelas ð¶ð‘€ð´ð‘ƒ didefinisikan  Persamaan di bawah ini melibatkan banyak perkalian probabilitas bersyarat, salah satu fitur   dapat menghasilkan perhitungan titik bawah mengambang. Dalam prakteknya perkalian probabilitas di konversi ke dalam logaritma probabilitas oleh karena itu persamaanya didefinisakan  
3.10  Pengukuran  
Model klasifikasi yang telah dibangun perlu dilakuakan evaluasi atau pengukuran. Proses tersebut untuk mengetahui  atau mengukur  seberapa bagus model tersebut dalam melakukan klasifikasi yang di inginkan.  Dalam melakukan evaluasi  kinerja  klasifikasi  khususnya klasifikasi teks umumnya dilakukan dengan  mengacu pada  accuracy atau dengan precision and recall  (Minner, Delen, & Elder, 2012) . Nilai accuracy ð¶ð‘€ð´ð‘ƒ = arg ð‘ƒ(ð‘|ð‘‘)=argð‘šð‘Žð‘¥ð‘âˆˆ{ð‘ð‘™ ,ð‘ð‘  } ð‘ð‘âˆˆ{ð‘ð‘™ ,ð‘ð‘  }ð‘šð‘Žð‘¥ ð‘ƒ (ð‘)âˆ ð‘ƒ(ð‘¡ð‘˜| ð‘)ð‘š
ð‘˜=1 ð¶ð‘€ð´ð‘ƒ = argð‘šð‘Žð‘¥
ð‘âˆˆ{ð‘ð‘™ ,ð‘ð‘  }  
[logð‘ƒ(ð‘)+âˆ‘ð‘™ð‘œð‘”ð‘ƒ (ð‘¡ð‘˜| ð‘)ð‘š
ð‘˜=1]  
merepresentasikan seberapa banyak keseluruhan   dokumen  yang dapat  diklasifikasikan dengan benar. Semakin tinggi nilai accuracy yang dihasilkan  maka semakin bagus dan akurat model tersebut dalam melakukan klasifikasi. Persamaan untuk mendapatkan nilai accuracy dapat dinotasikan sebagai berikut:  
= ð‘‡ð‘œð‘¡ð‘Žð‘™  ð‘˜ð‘Žð‘¡ð‘Ž  ð‘¦ð‘Žð‘›ð‘”  ð‘‘ð‘–ð‘˜ð‘™ð‘Žð‘ ð‘–ð‘“ð‘–ð‘˜ð‘Žð‘ ð‘–ð‘˜ð‘Žð‘›  ð‘ð‘’ð‘›ð‘Žð‘Ÿ
ð‘‡ð‘œð‘¡ð‘Žð‘™  ð·ð‘œð‘˜ð‘¢ð‘šð‘’ð‘› 
Pada klasifikasi teks  pengukuran precision dan recall merupakan metrik evaluasi yang paling banyak digunakan .  Sebagai contoh: terdapat dua kelas A dan B, precision yaitu jumlah sampel berkategori A yang diprediksi dengan benar sebagai A dibanding dengan jumlah total data yang diprediksi  sebagai A, sedangkan recall yaitu jumlah sampel berka tegori A yang  diprediksi  dengan benar dibandingkan dengan jumlah total sampel A. Dalam melakukan pengukuran ini , biasanya dibangun table confusion matrix yang terdiri atas banyaknya baris data uji yang diprediksi benar dan tidak benar oleh model klasifikasi yang digunakan.   
Tabel 1  
Confuion Matrix  
Relevant  Non 
relevant  
Retrieved  True 
positives  
(TP)  
False positives  
(FP)  
Not retrieved  
False negatives  
(FN)  
Trus negatives  
(TN)  
Precision dan recall dapat merepresentasikan nilai keakuratan model pada setiap kelas. Sedangkan untuk mengetahui akurasi secara keseluruhan digunakan pengukuran FI yang merupakan pengukuran tunggal dari kombinasi precision dan recall .  
 ð´ð‘ð‘¢ð‘Ÿð‘Žð‘ ð‘¦  
ð‘ƒ= ð‘‡ð‘ƒ
(ð‘‡ð‘ƒ+ð¹ð‘ƒ) (10)  
ð‘…= ð‘‡ð‘ƒ
(ð‘‡ð‘ƒ+ð¹ð‘) (11)   
Gambar 2  
Proses  Transformasi String to Vector  dalam Tool  Weka
Gambar 3  
Pengujian 10-Fold Cross Validation  
4. PEMBAHASAN  
Data berita hoax yang digunakan dalam penelitian ini diperoleh secara manual dari situs turnbackhoax.com. Data berita hoax diambil dari bulan November 2018 sampai dengan Februari 2019 berisi judul, tanggal berita terbit, dan label. Data yang diambil total sebanyak 300 di labeli oleh para pakar yang disebut sebagai data latih  dan data tes. Dari 300 data tersebut terdapat 297 dokumen berita berkategori hoax, dan 63 dokumen berkategori fakta. Dokumen tersebut dikumpulkan dalam bentuk format spreadsheet .  Dari 300 data berita tersebut akan diolah menggunakan Tool Weka 3.8.1 . Pertama yang dilakukan, yaitu melakukan tahap preprocessing .  Tahap tersebut dimulai dari tahap parsing  yaitu melakukan pemotongan dokumen, di mana data berformat spreeadsheet  di rubah menjadi format .arff   sesuai dengan format dokumen yang kompatibel Tool Weka 3.8 .   Setelah itu, dilakukan tahap tokenisasi. Tahap tersebut akan melakukan proses penghilangan tanda baca, spasi dan lain sebagainya. Selanjutnya dilakukan proses stop word , ya itu dokumen yang mengandung kata hoax dihilangkan, supaya tidak mengganggu hasil akurasi. Dari hasil preprocessing  semua dokumen berita dapat terbentuk attribut sebanyak 1650 atribut. Seperti terlihat sesua pada gambar 2.  Tahapan selanjutnya, dilakukan proses transformasi kalimat ke dalam matrix vector . Dari proses transformasi tersebut, diketahui TF dan IDF. Setelah itu, dilakukan proses klasifikasi dengan naive bayes . Tahapan terakhir yaitu pengukuran dengan untuk menentukan nilai accuracy, precision and recall serta terbentuk conffusion matrix . Pengujian dalam penelitian ini  menggunakan metode  10-Fold Cross Validation  dengan mengubah nilai Fold  untuk dicari nilai akurasi terbaik. Hasil pengujian 10-Fold Cross Validation  sesuai terlihat sesuai pada gambar  3. Hasil  pengujian dengan metode 10-Fold Cross Validation , diketahui bahwa nilai pengujian terbaik didapat dengan nilai fold 6 dengan nilai keakuratan sebesar 85.28 % yang mana diketahui dokumen terklasifikasi yang relevan sebanyak 307 dan yang tidak relevan sebanyak 53  atau error rate  sebesar 14.72%. Sedangkan nilai terendah didapat dari nilai fold 7 dengan nilai keakuratan 80.85% yang mana diketahui dokumen terklasifikasi yang relevan sebanyak 291 dan tidak relevan sebanyak 69  dokumen atau error rate  sebesar 19,17%.  Nilai rata-rata berdasarkan dokumen berita hoax dan dokumen berita benar dengan metode pengujian 10-Fold Cross Validation  dengan nilai fold 6  didapat nilai precision  0,896, recall  0.853 dan F-Measure 0.865.  Hasil dapat terlihat pada Tabel  confusion matrix   tersaji dalam tabel 2.  
Tabel 2  Confusion Matrix   
Prediksi 
Hasil  Hasil Aktual  
Fakta  H 
Fakta  55 8 
Hoax  45 252   
 
5. PENUTUP  
Metode naive bayes  dapat digunakan pada sistem klasifikasi berita dengan masukan berupa teks dengan diawali tahap preprocessing  yang berupa parsing, tokenization, stopword , dan pembobotan kata ( term weighting ). Kemudian dilakukan klasifikasi dengan metode naive bayes . Tahap  terakhir yaitu dilakukan pengukuran dengan  menggunakan pengujian 10-fold cross validation . Dari hasil penelitian diketahui nilai fold 6 memberikan nilai akurasi dengan hasil terbaik dengan hasil  dengan nilai keakuratan sebesar 85.28 % yang mana terklasifikasi dokumen yang relevan sebanyak 307 dan yang tidak relevan sebanyak 53  atau error rate  sebesar 14.72%. Sedangkan nilai rata-rata berdasarkan berita hoax dan berita benar nilai precision  0,896 dan recall 0.853.  Dalam penentuan klasifikasi, sistem sangat bergantung dengan frekuensi kata dalam dokumen. Dalam penelitian selanjutnya jumlah data berita bisa ditambah dengan mencantumkan isi konten berita, jumlah kata semakin banyak akan mempengaruhi nilai akurasi.  Dalam penelitian ini, dikarenakan keterbatasan jumlah dokumen yang hanya berjumlah 360 dokumen, maka perlu   dilakukan penelitian lanjutan  dengan menambah  total  jumlah dokumen. Sehingga sistem semakin memiliki dataset  yang beragam.  Dokumen yang diambil dalam penelitian ini masih bersifat umum, sehingga perlu dilakukan kajian penelitian dengan menggunakan konten dokumen yang bersifat khusus atau konten berita yang sebelumnya sudah terklasifikasi. Misalnya konten berita khusus kesehatan, konten berita khusus politik, konten berita khusus agama, dan sebagainya.    Selain itu, perlu dilakukan penelitian tentang stemming atau pencarian kata pada bentuk kata dasar  khusus untuk bahasa Indonesia. Dengan dilakukan stemming akan mereduksi jumlah suku kata atau attribut . Dengan suku kata yang semakin berkurang akan mempengaruhi hasil  klasifikasi konten berita hoax.   

REFERENCES  
Abraham, S. R. (2009). Effective Discretization and Hybrid Feature Selection Using Naive Bayesian Classifier For Medical Data Mining. International Journal of Computational Intelligence Research 4 . 
Afriza, A., & Adisantoso, J. (2018). Metode Klasifikasi Ro cchio untuk Analisis Hoax. Jurnal Ilmu Komputer Agri -Informatika, Volume 5 Nomor 1 , 1-10. Asosiasi Penyelenggara Jasa Internet Indonesia (APJII) . (2017). Infografis Penetrasi dan Pengguna Internet Indonesia.   
Cahya, I. (2012). Menulis Berita di Media Mass a. Citra Aji Pratama.  
Connoly, T. C., & Begg, C. E. (2015). Database System: A Practical Approach to Design, Implementation, and Management.   
Fauzi, A. (t.thn.). Text Mining 2017/2018 . Diambil kembali dari http://malifauzi.lecture.ub.ac.id/2017/09/text -min ing-20172018/  
Han, J. W., & Kamber, M. (2000). Data Mining: Concepts and Techniques.   
Han, J., & Kamber, M. (2006). Data Mining : Conceps and Techniques.  San Francisco: Elsevier Inc. 
Kemendikbud, K. (2019, Juni 25). Hasil Pencarian - KBBI Daring . Diambil kembali dari 
https://kbbi.kemdikbud.go.id/entri/hoaks  
Minner, G., Delen, D., & Elder, J. (2012). Excerpt from: Practical Text Mining and Statistical Analysis for Non -Structured Text Data Applications.   
Pramudita, Y. D., Putro, S. S., & Makhmud, N. (2018). Klasifikasi Berita Olahraga Menggunakan Metode Naive Bayes dengan Enhanced Confix Stripping Stemmer. Jurnal Teknologi Informasi dan Ilmu Komputer, Vol. 5, No. 3 , 269 -276.  
Severin, W. J., & James, J. T. (1998). Communication Theories: Origins, Methode, Uses  (2th ed). New York: Longman Inc.  
Ting, S. L., Ip, W. H., & Tsang, A. H. (2011). Is NaÃ¯ve Bayes a Good Classifier for Document Classification? International Journal of Software Engineering and Its Applications, 5(3). 
Triawati, C. (2009). Metode Pembobotan Statical Concept Based unuk Klastering dan Kategorisasi Dokumen Berbahasa Indonesia. Institide Teknologi Telkom.  Bandung.",klasifikasi,Naive Bayes,berita,"precision, recall"
Penerapan Algoritma Naive Bayes Untuk Klasifikasi Penyakit Diabetes Mellitus  ,"Penerapan Algoritma Naive Bayes Untuk Klasifikasi Penyakit Diabetes Mellitus  
  
Achmad Ridwan

Abstract
Diabetes Mellitus atau kencing manis adalah penyakit metabolisme disebabkan oleh kadar gula tinggi didalam darah. Gula darah disimpan atau digunakan untuk energi yang berasal dari darah yang dipindahkan ke sel manusia oleh hormon insulin . ketika terserang Diabetes, pada tubuh manusia insulin tidak biasa dihasilkan secara cukup bahkan tubuh tidak dapat menggunakan insulin tersebut secara benar sesuai kebutuhan. Diabetes Mellitus terdaftar sebagai penyakit penyumbang kematian terbesar terbesar didunia. Diabetes Mellitus dapat diklasifikasikan berdasarkan kemungkinan terkenanya dari atribut gejala diawal fasenya. penyakit ini bisa dideteksi karena banyak gejala yang terdeteksi. Data yang digunakan pada analisis ini merupakan data dari dataset UCI Machine Learning yaitu Early Stage Diabetes Risk tahun 2020 dan terdiri 17 attribut. Analisis yang dilakukan meliputi data preprocessing, model, dan evaluasi. Pengujian Metode klasifikasi pada riset adalah Naive Bayes Classification. Hasil klasifikasi menunjukkan akurasi sebesar 90.20% dan nilai AUCnya yaitu 0,95 

Keywords : Data Mining, Klasifikasi, Nauve Bayes, Diabetes Mellitus  

I. PENDAHULUAN 
Diabetes adalah penyakit dimana insulin tidak dapat diproduksi oleh pankreas dan digunakan oleh tubuh atau ketika tubuh manusia tidak dapat menggunakan insulin yang telah dibuat oleh pankreas dengan baik. Insulin merupakan hormon yang diciptakan oleh pankreas, yang berfungsi seperti kunci agar glukosa dari makanan yang manusia makan mengalir ke sel-sel dari darah dalam tubuh yang yang kemudian menghasilkan energi. Makanan yang mengandung karbohidrat diproses menjadi glukosa dalam darah. glukosa dibantu insulin  masuk ke dalam sel. Ketika tubuh tidak bisa memproduksi insulin  dan bahkan menggunkan dengan benar menyebabkan meningkatnya kadar glukosa dalam darah. Sehingga pada waktujangka panjang, kadar glukosa tinggi dalam darah dapat merusak organ pada tubuh dan kegagalan fungsi organ dan jaringan.Beberapa peneliti membagi diabetes menjadi diabetes tipe 1, tipe 2, dan diabetes gestasional [1]. Diabetes gestasional adalah jenis diabetes yang hanya terjadi pada kehamilan karena perubahan hormonal. Gejala umum diabetes adalah poliuria, polidipsia, polifagia, penurunan berat badan mendadak (biasanya tipe 1), kelemahan, obesitas (biasanya tipe 2), penyembuhan tertunda, penglihatan kabur, gatal, iritabilitas, sariawan genital, paresis parsial, otot kaku, alopecia , dll. [2]. Di era 4.0 , teknologi komputer dapat membantu kita untuk mendeteksi penyakit secara akurat dan dapat menghemat waktu. Penambangan data adalah bidang penting dalam ilmu komputer yang digunakan untuk prediksi. Ini adalah proses menemukan data baru dari data Achmad Ridwan yang sebelumnya diketahui melalui analisis data [3]. Untuk memprediksi suatu penyakit dengan pendekatan data mining diperlukan gejala yang disertai dengan data klinis. Gejala merupakan faktor yang sangat penting untuk pasien baru dan prediksi tahap awal dengan data gejala. Kami juga membutuhkan data klinis untuk menganalisisnya  Salah satu algoritma data mining adalah  NaÃ¯ve Bayes. Metode Naive Bayes digunakan mengklasifikasikan penyakit Diabetes Mellitus  Research ini menganalisis klasifikasi Naive Bayes untuk mengklasifikasi gejala awal penyakit Diabetes Mellitus sehingga mendapatkan akurasi yamg di dapat dari hasil proses evaluasi.  

II. KAJIAN LITERATUR 
A. Data Mining 
Data mining adalah sebuah ilmu yang mempelajari alur kerja pengalian data atributnya yang saling berkaitan untuk menemukan  pengetahuan atau menemukan sebuah pola  dari suatu data yang besar. penggalian  dari data ke pengetahuan dapat disimpulkan mempunyai 3 kunci yaitu : Data karena data tersebut adalah fakta yang terekam dan tidak membawa arti Informasi merupakan rangkuman penjelasan dan statistik dari data. Pengetahuan  ini merupakan hasil dari penggalian dari data Nama lain dari data mining adalah Knowledge Discovery in Data, ada juga tentang Big data atau bussines intelijen, Knowledge Extraction dan pattern analisis atau information harvesting . Konsep dari data mining yaitu himpunan data yang telah terhimpun banyak sekali kemudian dengan metode data mining yang ada diproses dengan  rumus/algoritma data-data tersebut diambil atau diekstraksi untuk menjadi di sebuah pengetahuan. Pengetahuan Itulah bisa untuk diambil untuk sebuah tujuan tertentu. Pengaturan tersebut sangat berguna untuk berbagai keperluan .  
B. Algoritma Naive Bayes  
Algoritma naive bayes adalah algoritma pembelajaran mesin untuk masalah klasifikasi yang terutama digunakan untuk klasifikasi teks yang melibatkan kumpulan data pelatihan berdimensi tinggi. Beberapa contohnya adalah analisis sentimental penyaringan spam dan mengklasifikasikan tidak hanya dikenal karena Kesederhanaannya tetapi juga untuk Efektivitasnya. Dengan algoritma Naive bayes dapat membangun model dengan cepat dan menjadikannya algoritma prediksi yang paling cepat untuk dipelajari. Algoritme ini menggunakan  probabilitas suatu objek . Mengapa disebut algoritma naive bayes karena membuat asumsi bahwa kemunculan fitur tertentu tidak tergantung pada kemunculan fitur lain bahkan jika ciri-ciri ini bergantung satu sama lain atau pada keberadaan ciri-ciri lainnya, semua sifat ini secara individual berkontribusi pada probabilitas dan itulah mengapa disebut naif Algoritma ini  mengacu pada ahli statistik dan filosof Thomas Bayes. Dasar dari algoritma naive bayes adalah teorema dasar yang secara alternatif dikenal sebagai aturan Bayes atau Hukum bayes algoritma ini adalah metode untuk menghitung probabilitas kondisional yaitu probabilitas suatu peristiwa berdasarkan pengetahuan sebelumnya yang tersedia [4] . Naive Bayes memiliki kemampuan yang cepat dalam membuat model, mempunyai kemampuan memprediksi dan juga menyediakan metode baru dalam mengeksplor dan memahami data. Algoritma Naive Bayes hanya mendukung pada atribut yang bertipe data discrete atau discretized, atau tidak mendukung atribut yang bernilai continuous (numerik) dan semua atribut dapat menjadi independen, menjadi atribut yang memberi kontribusi kepada atribut yang diprediksi. Secara singkat algoritma naive bayes classification adalah pengklasifikasi kumpulan data  statistika yang mana  untuk memprediksi semua probabilitas tiap anggota suatu class. Neural Network Dan Decision Tree memiliki persamaan kekuatan klasifikasi dengan Naive Bayes yang didasarkan pada teorema Bayes. Naive Bayes memiliki bukti kecepatan  dan akurasi yang tinggi saat digunakan  ke dalam kumpulan data  data yang besar[5].   Rumus teorema Naive bayes :  X         =  Data dengan class yang belum diketahui H           = Hipotesis data X merupakan suatu class spesifik   P(H|X)  = Probabilitas hipotesis H berdasarkan  kondisi x (posteriori prob.)   P(H)      =    Probabilitas hipotesis H (prior prob.)   P(X|H) =  Probabilitas X berdasarkan kondisi    tersebut   P(X)     =     Probabilitas dari X  
C. Rapid Miner 
Rapidminer adalah sebuah paket tools machine learning praktis yang berfungsi untuk penelitian pendidikan dan berbagai aplikasi. Rapidminer mampu menyelesaikan masalah data mining di dunia nyata khususnya klasifikasi yang mendasari pendekatan mesin learning. perangkat lunak ini ditulis dalam hierarki   Java dengan metode berorientasi objek dan dapat berjalan hampir di semua platform sistem operasi. Rapidminer sangat mudah digunakan serta diterapkan pada tingkatan yang berbeda. Rapidminer mengimplementasi algoritma pembelajaran yang dapat diterapkan pada data sheet dari command Line. Rapidminer mengandung tools  untuk preprocessing data, klasifikasi,  klastering, Regresi, Asosiasi dan Visualisasi . Rapidminer dapat melakukan Processing pada data, memasukkannya dalam skema pembelajaran dan menganalisa classifier yang dihasilkan dan performansinya. semua itu itu tanpa menulis kode program sama sekali. Contoh penggunaan Rapidminer adalah dengan menerapkan sebuah metode pembelajaran ke dataset dan menganalisa hasilnya untuk memperoleh informasi tentang data atau menerapkan beberapa metode dan membandingkannya performansi untuk dipilih.tools yang dapat digunakan untuk preprocessing dataset membuat pengguna berfokus pada algoritma yang digunakan tanpa terlalu memperhatikan detail seperti pembacaan data dari file implementasi algoritma filtering dan penyediaan kode untuk evaluasi hasil mengikuti model rilis Linux.  
D.   Evaluasi Algoritma 
Klasifikasi Data Mining 
D.1 Evaluasi Confusion Matrix 
Untuk melakukan evaluasi terhadap model klasifikasi berdasarkan perhitungan objek testing mana yang diprediksi benar dan tidak benar. Confusion Matrix berisi informasi tentang aktual (actual) dan prediksi (predicted) pada sistem klasifikasi. Kinerja sistem seperti ini biasanya dievaluasi dengan menggunakan data pada matriks. Perhitungan dimasukan  kedalam tabel Confusion Matrix [6]. Gambaran tentang  Confusion Matrix di  Tabel  berikut : Tabel 2.1 Confusion Matrix Klasifikasi yang memprediksi kelas Kelas :Ya        Kelas: tidak OBSERVED                Kelas : ya                      a      b KELAS  (Benar Positive-TP) (Salah Negative-FN) Kelas: Tidak      c  d  (salah Positif -Fp)(Ya  negative-TN)  Pada Tabel 2.1  Prediksi  Salah  positif adalah tuple positif di data set yang mengklasifikasikan negatif salah. Negatif  adalah  positif mengklasfikasikan jumlah tuple negatif  . Dan untuk benar  Positif adalah positif di data set  mengklasifikasikan  kolom positif didata set  , True negatives merupakan negatif di data set  mengklasifiksikan tupel negatif  Proses  berikutnya akan dihitung akurasi, spesifik, PPV, NPV. Sensitivity adalah proses perhitungan pembandingankan jumlah tuple  yang positif. Sedangkan specificity adalah proses (1) perhitungan pembandingankan negatif terhadap jumlah tuple negatif. Selanjutnya PPV adalah perbandingan  kasus dengan hasil diagnosa positif, Negatives Predictive  adalah perbandingan dimana kasusyang sama dengan hasil diagnosis negatif.  Confusion  matrix  berfungsi untuk membuat   penilaian  kerja  model klasifikasi yang mempunyai   jumlah  objek  yang diramal dengan benar  dan  salah  [7].  Akurasi kelas minoritas dapat menggunakan metrik recall  Rumus-rumus  yang  digunakan  untuk  melakukan penghitungannya adalah: Akurasi adalah perbandingan jumlah prediksi yang benar. Semua ditentukan dengan mengimplementasikan  rumus akurasi berikut:    Sensitivity disebut juga dengan  recall. Jika  sensitivity 100% sama artinya  dengan pengklasifikasian menganggap  kasus yang diamati positif. Sebai contoh semua orang memiliki tumor ganas dianggap sakit.   Presisi adalah tingkat positif salah adalah perbandingan  nilai positif yang salah diklasifisikan pada kasus negatif , yang perhitungannya  menggunakan Rumus  :   
D. 2 (Dua) Kurva ROC  
Kurva ROC digunakan untuk menilai hasil prediksi, kurva ROC adalah teknik untuk menggambarkan , mengatur, dan memilih pengklasifikasian berdasarkan kinerja mereka[8]. Kurva ROC adalah tool dua dimensi di dunia data mining yang digunakan untuk menilai kinerja klasifikasi yang menggunakan dua class keputusan, tiap objek dipetakan ke salah satu elemen dari himpunan pasangan, positif atau negatif.  Pada gambar  kurva ROC, True Positif  rate diplot pada sumbu Y dan False Positif  rate diplot pada sumbu X. Menurut Gorunescu Dalam metode  klasifikasi data mining , hasil AUC dapat dibagi menjadi beberapa kelompok [9]: 1. 0,90 - 1,00 = Klasifikasi Sangat Baik 2. 0,80 - 0,90 = Klasifikasi Baik 3. 0,70 - 0,80 = Klasifikasi Sedang 4. 0,60 - 0,70 = Klasifikasi Buruk 5. 0,50 - 0,60 = Kegagalan  
III. METODOLOGI PENELITIAN 
Pendekatan utama dalam penelitian ini yaitu pendekatan kualitatif dan pendekatan kuantitatif. Dalam penelitian ini metode yang digunakan yaitu metode penelitian kuantitatif. Tujuan dari penelitian ini adalah melakukan klasifikasi dan evaluasi model algoritma Naive Bayes untuk mengetahui akurasi algoritma Naive Bayes dalam mengklasifikasikan  penyakit Diabetes Mellitus. 
A. Sumber Data  
Sumber data yang digunakan pada penelitian ini adalah data dari dataset UCI Machine Learning Repository .Dataset yang digunakan adalah Early stage diabetes risk prediction dataset dimana  file tersebut bernama diabetes_data_upload.csv. Variabel yang digunakan pada penelitian ini adalah sebanyak 17 variabel dengan jumlah data sebanyak 520. Ini termasuk data tentang orang-orang termasuk gejala yang dapat menyebabkan diabetes. Kumpulan data ini dibuat dari kuesioner langsung kepada orang-orang yang baru saja menjadi penderita diabetes, atau yang masih nondiabetes tetapi memiliki sedikit atau lebih gejala.  
B. Kerangka Pemikiran 
Kerangka penelitian dari penelitian bisa kita lihat pada Gambar  dibawah ini :  
-2
(4) (3) 
Gambar 3.1 Kerangka Pemikiran Adapun kerangka pemikiran pada  Gambar  3.1 dapat dijelaskan sebagai  berikut : 
1. Preprocessing 
Preprocessing data dilakukan dengan cara menangani nilai yang hilang mengikuti teknik mengabaikan tupel dengan nilai yang tidak lengkap. Setelah praproses, total 500 instans telah tersisa. Diantaranya, 314 adalah nilai positif dan 186 adalah nilai negatif. Deskripsi detail dari dataset dan atributnya ditunjukkan pada Tabel 4.1. Dua variabel kelas digunakan untuk mengetahui apakah pasien memiliki risiko diabetes (positif) atau tidak (negatif).    
2. Model Tool 
RapidMiner diterapkan pada  Dataset  yang baru untuk  di Training maupun di Testing  pada Algoritma Naive Bayes, serta untuk menganilisis hasilnya  antara lain Kesalahan klasifikasi (Classification Error),  nilai akurasi Probabilitas maksimal tiap kelas, Recall dan Presisinya  3. Evaluasi Kemudian Dataset  diuji/dievaluasi dengan Confusion Matrix serta diukur tingkat akurasinya.  

IV. HASIL DAN PEMBAHASAN 
Variabel data penelitian yang digunakan pada penelitian ini disajikan pada Tabel 4.1 yakni sebagai berikut.  
Tabel 4.1 Deskripsi Variable Dataset No. Atribut Value 1 Age 1.20â€“35, 2.36â€“45, 3.46â€“55,4.56â€“65,  6.above 65 2 Sex 1.Male, 2.Female 3 Polyuria 1.Yes, 2.No. 4 Polydipsia 1.Yes, 2.No. 5 Sudden weight loss 1.Yes, 2.No. 6 Weakness 1.Yes, 2.No. 7 Polyphagia 1.Yes, 2.No. 8 Genital thrush 1.Yes, 2.No. 9 Visual blurring 1.Yes, 2.No. 10 Itching 1.Yes, 2.No. 11 Irritability 1.Yes, 2.No. 12 Delayed healing 1.Yes, 2.No. 13 Partial paresis 1.Yes, 2.No. 14 Muscle stiffness 1.Yes, 2.No. 15 Alopecia 1.Yes, 2.No. 16 Obesity 1.Yes, 2.No. 17 Class 1.Positive, 2.Negative.  Dari Tabel 4.1 Ada 16 variabel dataset gejala dan 1 variabel class penentu klasifikasi. 
A. Preprocessing  
Dari dataset yang akan di analisis dijadikan sebagai   Data Training dan Data Testing yang ada di klasifikasikan oleh algoritma Naive Bayes  Adapun contoh data training dan data testing dapat di lihat pada tabel 4.2 : Tabel 4.2 Data Training dan Testing   No. Atribut Value 1 2 1 Age 40 58 2 Sex male female 3 Polyuria no no 4 Polydipsia yes yes 5 Sudden weight loss yes yes 6 Weakness yes yes 7 Polyphagia no no 8 Genital thrush no no 9 Visual blurring yes yes 10 Itching yes yes 11 Irritability no no 12 Delayed healing no no 13 Partial paresis yes yes 14 Muscle stiffness yes yes 15 Alopecia no no 16 Obesity no no 17 Class negatif positif  Setelah praproses, total 500 data yang  telah tersisa. Diantaranya, 314 adalah Class nilai positif dan 186 adalah Class nilai negatif.  
B. Model 
Setelah Praprocessing, data Training dan Data Testing akan  kita proses klasifikasi menggunakan aplikasi Rapidminer  Adapun hasil dari Confunsion Matrix.nya : Tabel 4.3 Tabel Hasil Class Recall dan Precision    true Positive true Negative class precision pred. Positive 32 2 94.12% pred. Negative 3 14 82.35% class recall 91.43% 87.50%   Dari Tabel 4.3 didapatkan Class Precision =  82.35%, dan Class Recall: 87.50%  
C. Evaluasi 
Hasil dari evaluasi pengklasifikasian dengan Naive Bayes menghasilkan :  
Gambar 4.1 Akurasi Naive Bayes Dari gambar diatas didapatkan akurasi untuk mengklasifisikan Dataset Diabetes yaitu 90,20% Adapun hasil dari pengujian ini juga menghasilkan gambar 4.2 dibawah ini   
Gambar 4.2 Kurva Roc  
Model Naive Bayes  Kurva ROC (Reciver Operating Characteristic) diatas menunjukkan algoritma Naive Bayes memiliki nilai AUC sebesar 0.955 yang artinya Excellent Classification (Sangat Bagus) Dalam hasil penelitian, menunjukkan Naive Bayes memberikan  akurasi yang bagus untuk prediksi penyakit diabetes pada UCI dataset Machine Learning Repository.   

V. KESIMPULAN 
Terdapat 16 atribut  yang  mempengaruhi  Klasifikasi dataset Early stage diabetes risk prediction yaitu Age, Gender, Polyuria, Polydipsia, sudden weight loss, weakness, Polyphagia, Genital thrush, visual blurring, Itching, Irritability, delayed healing, partial paresis, muscle stiffness, Alopecia, Obesity, class.  Penelitian ini menggunakan Algoritma Naive Bayes untuk pengklasifikasian Dataset Early Stage Diabetes Risk Prediction. Dari  520  data  kotor  setelah  dilakukan  pembersihan  data  tidak  lengkap  dan  melalui proses  seleksi  sesuai  yang  dibutuhkan  dalam  analisa  Dataset Stage Diabetes   maka  didapat  data 500  data  bersih. 90, 20% Accuracy
Naive Bayes. Dari hasil proses Klasifikasi permodelan algoritma naive bayes terhadap Dataset Stage Diabetes   menghasilkan Class Precision =  82.35%, dan Class Recall: 87.50% Hasil evaluasi klasifikasi ini menghasilkan akurasi untuk mengklasifisikan Dataset Diabetes yaitu 90,20% ini artinya Klasifikasi permodelan algoritma Naive Bayes terhadap Dataset Stage Diabetes sudah bagus akurasinya, tetapi perlu peningkatan akurasi dengan Assemble atau dengan cara yang lain.  Kurva ROC (Reciver Operating Characteristic) Klasifikasi permodelan algoritma Naive Bayes terhadap Dataset Stage Diabetes menunjukkan algoritma Naive Bayes memiliki nilai AUC sebesar 0.955 yang artinya Excellent Classification (Sangat Bagus).                        

DAFTAR PUSTAKA 
[1] World Health Organization, â€œGlobal Report on Diabetes,â€ Isbn, 2016, doi: ISBN 978 92 4 156525 7. 
[2] American Diabetes Association, â€œ2016 American Diabetes Association (ADA) Diabetes Guidelines Summary Recommendation from NDEI,â€ Natl. Diabetes Educ. Initiat., 2016. 
[3] D. T. Larose, Data Mining Methods and Models. 2006. 
[4] S. Kusumadewi, â€œKLASIFIKASI STATUS GIZI MENGGUNAKAN NAIVE BAYESIAN CLASSIFICATION,â€ CommIT (Communication Inf. Technol. J., 2009, doi: 10.21512/commit.v3i1.506. 
[5] A. Naik and L. Samant, â€œCorrelation Review of Classification Algorithm Using Data Mining Tool: WEKA, Rapidminer, Tanagra, Orange and Knime,â€ Procedia Comput. Sci., vol. 85, pp. 662â€“668, 2016, doi: 10.1016/j.procs.2016.05.251. 
[6] A. Luque, A. Carrasco, A. MartÃ­n, and A. de las Heras, â€œThe impact of class imbalance in classification performance metrics based on the binary confusion matrix,â€ Pattern Recognit., 2019, doi: 10.1016/j.patcog.2019.02.023. 
[7] F. Gorunescu, â€œData mining: Concepts, models and techniques,â€ Intell. Syst. Ref. Libr., 2011, doi: 10.1007/978-3-642-19721-5. 
[8] Z. H. Hoo, J. Candlish, and D. Teare, â€œWhat is an ROC curve?,â€ Emerg. Med. J., 2017, doi: 10.1136/emermed-2017-206735. 
[9] A. Ridwan, P. N. Andono, and C. Supriyanto, â€œOptimasi Klasifikasi Status Gizi Balita Berdasarkan Indeks Antropometri Menggunakan Algoritma Naive,â€ Teknol. Inf., 2018.",klasifikasi,naive bayes,early stage diabetes risk,"akurasi, AUC"
DECISION TREE  DAN ADABOOST PADA KLASIFIKASI PENERIMA PROGRAM BANTUAN SOSIAL,"DECISION TREE  DAN ADABOOST PADA KLASIFIKASI PENERIMA PROGRAM BANTUAN SOSIAL

Laila Qadrini1), Andi Seppewali2), Asra Aina3) 

Abstrak 
Kemiskinan adalah masalah sosial yang masih belum terselesaikan di negara berkembang khususnya di indonesia. Kemiskinan telah hadir dalam realitas kehidupan manusia dengan bentuk dan kondisi yang sangat memprihatinkan, Karena kemiskinan memang tidak bisa dihilangkan begitu saja. Dengan adanya permasalahan terhadap Negara berkembang terutama kemiskinan. Maka pemerintah membuat kebijakan-kebijakan atau program-program untuk memberantas masalah tersebut. Diantaranya adalah Bantuan langsung tunai atau biasa disebut BLT. Bantuan Langsung Tunai (BLT) dapat dipahami sebagai pemberian sejumlah uang (dana tunai) kepada masyarakat miskin setelah pemerintah memutuskan untuk menaikkan harga BBM dengan jalan mengurangi subsidi namun selisih dari subsidi itu diberikan kepada masyarakat miskin. Melihat dari program pemerintah tersebut, upaya pemberantasan kemiskinan di negara Indonesia ini cukup menarik simpati masyarakat. Hal ini menjadi salah satu objek yang menarik untuk diteliti dan dikaji lebih lanjut. Untuk menentukan klasifikasi tingkat penduduk miskin terdapat banyak metode yang dapat digunakan. Salah satunya yang digunakan pada penelitian ini yaitu Decision Tree  dan Adaboost . 

Kata Kunci: Klasifikasi, BLT, Decision Tree , Adaboost   
 
PENDAHULUAN 
Kemiskinan adalah masalah sosial yang masih belum terselesaikan di negara berkembang khususnya di indonesia. 
Kemiskinan telah hadir dalam realitas kehidupan manusia dengan bentuk dan kondisi yang sangat memprihatinkan, Karena 
kemiskinan memang tidak bisa dihilangkan begitu saja. Dengan adanya permasalahan terhadap Negara berkembang terutama 
kemiskinan. Maka pemerintah membuat kebijakan-kebijakan atau program-program untuk memberantas masalah tersebut. Diantaranya adalah Bantuan langsung tunai atau biasa disebut BLT. Bantuan Langsung Tunai (BLT) dapat dipahami sebagai pemberian sejumlah uang (dana tunai) kepada masyarakat miskin setelah pemerintah memutuskan untuk menaikkan harga BBM dengan jalan mengurangi subsidi namun selisih dari subsidi itu diberikan kepada masyarakat miskin. BLT merupakan implementasi dari Instruksi Presiden Nomor 3 Tahun 2008 tentang pelaksanaan program bantuan langsung tunai (BLT) untuk rumah tangga sasaran (RTS) dalam rangka kompensasi pengurangan subsidi BBM. Program BLT-RTS ini dalam pelaksanaanya harus langsung menyentuh dan memberikan manfaat langsung kepada masyarakat miskin (yang terkategori sebagai RTS), mendorong tanggung jawab social bersama dan dapat menumbuhkan kepercayaan masyarakat kepada pemerintah yang secara konsisten mesti benar-benar memperhatikan Rumah Tangga Sasaran yang pasti merasakan beban berat sebagai akibat dari kenaikan harga BBM. Program BLT dirancang sebagai pengganti kenaikan biaya hidup ketika terjadi kenaikan harga BBM oleh karena itu, besaran BLT dihitung sebagai kenaikan biaya hidup penduduk miskin disebabkan kenaikan harga (inflasi) yang diakibatkan langsung maupun tidak langsung oleh kenaikan harga BBM. Melihat dari program pemerintah tersebut, upaya pemberantasan kemiskinan di negara Indonesia ini cukup menarik simpati masyarakat. Hal ini menjadi salah satu objek yang menarik untuk diteliti dan dikaji lebih lanjut. Menteri Desa, Pembangunan Daerah Tertinggal dan Transmigrasi (Mendes PDTT) Abdul Halim Iskandar mengatakan, penyaluran Bantuan Langsung Tunai (BLT) Dana Desa per 21 Juli 2020 telah mencapai Rp 10,83 triliun. Menurut dia, sebanyak 81 persen keluarga penerima manfaat (KPM) BLT Dana Desa merupakan penerima yang baru pertama kali mendapatkan bantuan dari pemerintah. Mereka masuk kategori keluarga miskin, namun tidak terdata untuk mendapatkan jaring pengaman sosial.(Kompas, Diakses 21 Juli 2020) sedangkan realita di lapangan tingkat kemiskinan di Indonesia tahun 2018 masih di angka 9,66%.  Kemiskinan bagi pemerintah Indonesia termasuk masalah yang sulit untuk diselesaikan karena kurangnya pemahaman berbagai pihak tentang penyebab kemiskinan itu sendiri, sehingga program penanggulangan kemiskinan tidak didasarkan pada penyebabnya yang berbeda-beda secara lokal. Upaya yang dilakukan pemerintah dalam mengatasi kemiskinan di Indonesia yaitu dengan program bantuan sosial meliputi BLT (Bantuan Langsung Tunai), PKH (Program Keluarga Harapan), Raskin (Beras Miskin), dan sebagainya. Berdasarkan Data dari Bappenas 2014, masalah kemiskinan saat ini disebabkan oleh beberapa faktor, antara lain: ketidaktepatan sasaran dalam penentuan penerimaan program, mekanisme pendampingan program belum optimal, koordinasi dan pelaksanaan program belum terintegrasi dan prioritas pendanaan untuk program perlindungan sosial yang masih terbatas. (Elly et al, 2020). Untuk menentukan klasifikasi tingkat penduduk miskin terdapat banyak metode yang dapat digunakan. Salah satunya yaitu K-NN dan Gradient Boosted Trees. Berdasarkan penelitian sebelumnya yang dilakukan oleh Yunus, dkk (2019) tentang Data Mining untuk Memprediksi Hasil Produksi Buah Sawit pada PT Bumi Sawit Sukses menggunakan Metode K-Nearest Neighbor (K-NN) menghasilkan output dari Rapidminer dengan akurasi 85,15% (Yunus, Akbar, & Andri, 2019). Menurut penelitian sebelumnya yang dilakukan oleh saikin dan kusrini mengenai Karakteristik Data Traveller didapatkan hasil kualifikasi metode K-NN dengan pengujian confusion matrixdidapatkan nilai akurasi sebesar 84% (Saikin & Kusrini, 2019). Berdasarkan penelitian terdahulu dari masing-masing metode yang digunakan menghasilkan akurasi yang rendah. Kombinasi antara Decision Tree dan Adaboost diperlukan untuk memperoleh nilai akurasi yang lebih tinggi.  
 
LANDASAN TEORI 
2.1 Decision Tree  
Decision Tree  adalah sebuah diagram alir yang berbentuk seperti struktur pohon yang mana setiap internal node  menyatakan pengujian terhadap suatu atribut, setiap cabang menyatakan output dari pegujian tersebut dan leaf node  menyatakan kelas-kelas atau distribusi kelas. Node yang paling atas disebut sebagai root node  atau node akar. Sebuah root node  akan memiliki beberapa edge  keluar tetapi 
tidak memiliki edge  masuk, internal node akan memiliki satu edge masuk dan beberapa edge  keluar, sedangkan leaf node hanya akan memiliki satu edge  masuk tanpa memiliki edge  keluar. Decision Tree digunakan untuk mengklasifikasikan suatu sampel data yang belum diketahui kelasnya ke dalam kelas-kelas yang sudah ada. Algoritma - algoritma dalam 
Decision Tree . Ada banyak algoritma pada klasifikasi Decision Tree ini. Suatu algoritma biasanya dikembangkan untuk meningkatkan kinerja algoritma yang sudah ada. Penentuan algoritma yang terbaik dalam Decision Tree tentunya tidak bisa ditentukan secara mutlak tetapi sangat tergantung dengan karakteristik training set-nya. Beberapa algoritma Decision Tree yang cukup populer antara lain : ID3, C4.5, dan CART. 
2.2 Algoritma C4.5 
Algoritma ini dikembangkan untuk memperbaiki algoritma ID3. Algoritma ini berbasiskan keputusan biner seperti yang terlihat dalam CLS. Jadi selain memiliki karakteristik seperti ID3, C4.5 juga memiliki beberapa karakteristik yang berbeda yang merupakan perbaikan dari karakteristik ID3. Berikut ini beberapa karakteristik C4.5 yang juga merupakan perbaikan terhadap ID3 : 
â€¢ Dapat me nangani atribut numerik 
â€¢ Dapat menangani missing value  
â€¢ Melakukan pruning untuk memperoleh model yang paling efisien 
â€¢ Menggunakan kriteria gain ratio untuk menentukan jenis split yang terbaik. 
2.3 Karakteristik Decision Tree  
Berikut ini adalah beberapa karakteristik Decision Tree secara umum : 
â€¢  Decision Tree merupakan suatu pendekatan nonparametrik untuk membangun model klasifikasi  
â€¢  Teknik yang dikembangkan dalam membangun Decision Tree memungkinkan untuk membangun model secara cepat dari training set  yang berukuran besar. 
â€¢ Decision Tree dengan ukuran tree yang kecil relatif mudah untuk menginterpretasinya. 
â€¢ Decision Tree memberikan gambaran yang ekpresif dalam pembelajaran fungsi nilai diskret. 
â€¢ Algoritma Decision Tree cukup robbust terhadap munculnya noise  terutama untuk metode yang dapat menangani masalah overfitting . 
â€¢ Adanya atribut yang berlebihan tidak terlalu mengurangi akurasi Decision Tree .   
â€¢  Karena sebagian algoritma Decision Tree menggunakan pendekatan top down, yaitu partisi dilakukan secara rekursif maka jumlah record  menjadi lebih kecil. Pada leaf node , jumlah record mungkin akan terlalu kecil untuk dapat membuat keputusan secara statistik tentang representasi kelas dari suatu node. 
â€¢  Sebuah subtree  dapat direplikasi beberapa kali dalam Decision Tree tetapi ini akan menyebabkan Decision Tree menjadi lebih kompleks dan lebih sulit untuk diinterpretasi. (Sibaroni, 2008:8). 
Dalam proses pengambilan keputusan, Decision Tree  digunakan sebagai alat visual dan analitis, untuk memprediksi nilai target. (Witten, 2011). Algoritma C4.5 adalah algoritma populer dalam klasifikasi data mining. Algoritma C4.5 menggunakan kriteria information gain untuk memilih atribut yang akan digunakan dalam pemisahan objek. Atribut yang mempunyai information gain  paling tinggi dibandingkan dengan atribut pada data lain, maka atribut tersebutlah yang dipilih sebagai pemecahan. Decision Tree  (Pohon Keputusan) sesuai digunakan untuk kasus-kasus dimana output nya bernilai diskrit (Agustinus, 2012). 
2.4 Adaptive Boosting (Adaboost ) 
Adaptive Boosting  ( Adaboost ) merupakan salah satu dari beberapa varian pada algoritma boosting (Chezian & Kumar, 2014). Adaboost  merupakan ensemble learning  yang sering digunakan pada algoritma boosting. Boosting  bisa dikombinasikan dengan classifier  algoritma yang lain untuk meningkatkan performa klasifikasi. Tentunya secara intuitif, penggabungan beberapa model akan membantu jika model tersebut berbeda satu sama lain. Adaboost  dan variannya telah sukses diterapkan pada beberapa bidang (domain) karena dasar teorinya yang kuat, presdiksi yang akurat, dan kesederhanaan yang besar. Langkah-langkah pada algoritma Adaboost  adalah sebagai berikut. 
a. Input: Suatu kumpulan sample penelitian 
dengan label {(ð‘¥ð‘–, ð‘¦ð‘–), â€¦ , (ð‘¥ð‘, ð‘¦ð‘)}, suatu  component learn  algoritma, jumlah perputaran T. 
b. Initialize : Bobot suatu sampel pelatihan 
ð‘¤ð‘–1=1ð‘â„, untuk semua ð‘– =  1, . . . , ð‘  
c. Do for  t= 1, ...,T 
d. Gunakan component learn  algoritma untuk melatih suatu komponen klasifikasi, pada sample  bobot pelatihan. 
e. Hitung kesalahan pelatihannya pada â„Žð‘¡: ðœ€ð‘¡=
âˆ‘ð‘¤ð‘–ð‘¡ ð‘
ð‘– , ð‘¦ð‘–â‰  â„Ž ð‘¡(ð‘¥ð‘–) 
f. Tetapkan bobot untuk component classifier 
â„Žð‘¡= ð›¼ ð‘¡=1
2ð‘™ð‘›(1âˆ’ðœ€ ð‘¡
ðœ€ð‘¡) 
g. Update  bobot sample  pelatihan ð‘¤ð‘–ð‘¡+1=
ð‘¤ð‘–ð‘¡ð‘’ð‘¥ð‘ {âˆ’ð›¼ ð‘¡ð‘¦ð‘–â„Žð‘¡(ð‘¥ð‘–)}
ð¶ð‘¡, ð‘– = 1, . . . , ð‘ ð¶ ð‘¡ adalah suatu  
 konstanta normalisasi. 
h. Output:  ð‘“(ð‘¥) = ð‘ ð‘–ð‘”ð‘› (âˆ‘ ð›¼ð‘¡â„Žð‘¡(ð‘¥)ð‘‡
ð‘¡=1 ) 
2.5 Akurasi, Presisi, dan Recall 
1) Akurasi, Presisi, dan Recall   
Akurasi dapat didefinisikan sebagai tingkat kedekatan antara nilai prediksi dengan nilai aktual. Presisi menunjukan tingkat ketepatan atau ketelitian dalam pengklasifikasian. Sedangkan recall  berfungsi untuk mengukur proporsi positif aktual yang benar diidentifikasi. Untuk mengukur akurasi, presisi, dan recall  biasanya digunakan confusion matrix . Confusion matrix  adalah alat ukur berbentuk matrix yang digunakan untuk mendapatkan jumlah ketepatan klasifikasi terhadap kelas dengan algoritme yang dipakai. Berikut akan disajikan bentuk confusion matrix pada Tabel 1. 
Tabel 1. Bentuk Confusion Matrix Dari Dua Kelas 
Pada Tabel 1 nilai TP ( true positive ) dan TN (true negative ) menunjukan tingkat ketepatan klasifikasi. Umumnya semakin tinggi nilai TP dan TN semakin baik pula tingkat klasifikasi dari akurasi, presisi, dan recall . Jika label prediksi keluaran bernilai benar ( true) dan nilai sebenarnya bernilai salah ( false ) disebut sebagai false positive (FP). Sedangkan jika prediksi label keluaran bernilai salah ( false ) dan nilai sebenarnya bernilai benar ( true) maka hal ini disebut sebagai false negative (FN) (Han & Kember, 2013). Berikut formulasi untuk menghitung akurasi, presisi, dan recall pada pembentukan model klasifikasi ditunjukan pada Persamaan (1), Persamaan (2), dan Persamaan (3).  
Akurasi =ð‘‡ð‘ƒ+ð‘‡ð‘
ð‘‡ð‘ƒ+ð‘‡ð‘+ð¹ð‘ƒ+ð¹ð‘Ã—100%    
-1 
Presisi =ð‘‡ð‘ƒ
ð‘‡ð‘ƒ+ð¹ð‘ƒ Ã—100%     
-2 
Recall =ð‘‡ð‘ƒ
ð‘‡ð‘ƒ+ð¹ð‘Ã—100%             (3)  
A. Kurva ROC  
Kurva ROC ( receiver operating characteristic ) adalah salah satu alat ukur untuk menilai kemampuan sistem klasifikasi. Kurva ROC sering digunakan untuk mengevaluasi pengklasifikasian karena memiliki kemampuan evaluasi algoritma dengan cukup baik . Kurva ROC merupakan grafik perbandingan antara sensitivity  (true positive rate  (TPR)) yang diterjemahkan kedalam sumbu vertikal atau sumbu koordinat y dengan specificity  (false positive rate  (FPR)) yang diterjemahkan dalam bentuk kurva (Witten et al, 2011). Berikut formulasi dari sensitivity  dan specificity dipaparkan pada Persamaan (4), dan Persamaan (5) .  
Sentivity =ð‘‡ð‘ƒ
ð‘‡ð‘ƒ+ð¹ð‘Ã—100%    
-4
 Specificity =ð‘‡ð‘ƒ
ð‘‡ð‘ƒ+ð¹ð‘Ã—100%    
-5
Kurva ROC dapat digunakan sebagai komparasi beberapa metode (classifier) Confusion Matrix Nilai Sebenarnya 
True  False 
Nilai 
Prediksi True TP ( True 
Positive ) 
Correct 
result  FP ( False 
Positive ) 
Unexpected 
result  
False FN ( False 
Negative ) 
Missing 
result  TN ( True 
Negative ) 
Correct 
absence of 
result  
ataupun model classifier yang memiliki perbedaan parameter guna mendapatkan model yang paling baik. Berikut adalah contoh penerapan komparasi performansi dari dua classifier  yang berbeda pada Gambar 1. 
Gambar 1. Komparasi Classifier dengan Kurva ROC  
Pada Gambar 1 dapat dilihat bahwa terdapat dua buah classifier yang disimbolkan dengan garis putus-putus dan garis utuh. Jika pada Gambar 1 menunjukan letak koordinat (0,1) hal tersebut mewakili sensitivity  dan specificity  sebesar 100%. Untuk menghitung dan memastikan classifier  mana yang lebih unggul maka digunakan penghitungan AUC ( area under curve ). AUC ( area under curve ) adalah luas area dibawah kurva. Luas dari AUC selalu berada diantara nilai 0 hingga 1. AUC dihitung berdasarkan gabungan luas trapesium titik-titik (sensitivity  dan specificity ). Pada Gambar 1 memperlihatkan bahwa garis yang utuh memiliki area dibawah kurva yang lebih besar dibandingkan garis yang putus-putus, hal ini berarti bahwa tingkat performansi klasifikasi dari classifier  yang dilambangkan dengan garis utuh lebih baik dibandingkan tingkat performansi klasifikasi dari classifier  yang dilambangkan dengan garis putus-putus. Berikut adalah standar Tabel kategori pengklasifikasian berdasarkan nilai AUC pada Tabel 2  
Tabel 2. Kategori Pengklasifikasian 
Berdasarkan Nilai AUC  
Nilai AUC Kategori 
Pengklasifikasian 
0.90 - 1.00 Excellent 
0.80 - 0.90 Good 
0.70 - 0.80 Fair 
0.60 - 0.70 Poor 
0.50 - 0.60 Fail 
 
METODE PENELITIAN 
Penelitian ini dilakukan untuk pengembangan evaluasi dan pemecahan masalah yaitu meningkatkan akurasi pada pelaksanaan program bantuan sosial agar tepat sasaran. Berikut ini adalah tahapan penelitian yang dilakukan:  
Gambar 1. Metode Penelitian 
 
HASIL DAN PEMBAHASAN 
Sumber Data 
Penelitian ini menggunakan data sekunder penduduk Desa yang memperoleh Bantuan Langsung Tunai di Kelurahan Banggae, Data yang digunakan dalam penelitian ini adalah data Tahun 2020. Variabel yang digunakan adalah numerik dan kategorik. 
Variabel Penelitian 
Pada penelitian ini menggunakan data penduduk desa yang diperoleh dari kantor kelurahan, sebagai berikut: 
a. Pendidikan: Tidak SD, SD, SLTP, SLTA, S1 
b. Luas Lantai: Kurang dari 13 ð‘š2, Sama 13 ð‘š2, Lebih dari 13 ð‘š2 
c. Jenis Lantai: Keramik, Semen, Tanah 
d. Jenis Dinding: Bambu, Tembok 
e. Jenis Penerangan: Non PLN, PLN 
f. Bahan Bakar Masak: Kayu, Gas 
g. Sumber Air Minum : Sumur, Ledeng 
h. Jenis Jamban: Umum, Bersama, Sendiri 
i. Pendapatan: 0 sampai 1,5 juta, 1,5 sampai 3 juta, lebih dari 3 juta 
j. Pekerjaan: Tidak Bekerja/Buruh, Petani, Pedagang, Wiraswasta, Pegawai 
Pra-pemrosesan Data 
Prapemrosesan data adalah mengeksplor dan memahami data yang akan diolah hingga data tersebut layak untuk melaju ketahap pemodelan, Hal ini merupakan langkah awal pada proses klasifikasi data. Penelitian ini menggunakan penggabungan dua metode yaitu metode Decision Tree  dan Adaboost . Pada Seleksi Fitur digunakan untuk menyeleksi data yang rusak/tidak lengkap menggunakan fitur Input Missing Value """" dan """" Rename Unused Value """" dengan menggunakan metode Decision Tree sehingga didapatkan data set murni. Mentranformasikan data dari numerik ke nominal dan lakukan normalisasi menentukan bentuk data yang paling tepat. Selanjutnya membagi data training dan data testing  dengan perbandingan 80%:20%. Pemrosesan data dilakukan dengan menggabungkan metode Adaboost dalam proses validasi sehingga diperoleh akurasi yang lebih tinggi dari pengolahan masing-masing metode. Hasil yang diperoleh dari masing-masing perhitungan masing-masing metode adalah sebagai berikut: Tabel 2. Perhitungan Metode Decision Tree 
Tabel 3. Perhitungan Metode Adaboost  
Accuracy :  95.00%     
True Tidak 
Miskin True 
Miskin Class 
Precision 
Pred Tidak 
Miskin 94 6 94% 
Pred Miskin 0 20 100% 
Class 
Recall 100% 77%    
Tabel 4. Perbandingan Akurasi 
No Metode 
Klasifikasi Akurasi 
1 Decision Tree 94.17% 
2 Adaboost 95% 
 
KESIMPULAN  
Berdasarkan hasil penelitian yang telah dilakukan dapat disimpulkan bahwa:  
1. Metode klasifikasi Decision tree  dan Adaboost  sama sama memiliki hasil akurasi yang baik yaitu sebesar 94% dan 95%
2. Metode klasifikasi Decision tree  dan Adaboost  tepat digunakan untuk menentukan penerima bantuan sosial secara tepat  
 
DAFTAR PUSTAKA 
[1] Chezian, D.R.M., & Kumar, K.S. 2014. Support Vector Machine and K-Nearest Neighbour Based Analysis for the 
Prediction of Hypothyroid. International Journal of Pharma and Bio Sciences . 5(4)(B) 447-453. 
[2] Elly Firasari, Umi Khultsum, Monikka Nur Winnarto Risnandar, Kombinasi K-NN dan Gradient Boosted Trees  untuk Klasifikasi Penerima Program Bantuan Sosial Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK). Vol. 7, No. 6, Desember 2020, hlm. 1231-1236. 
[3] I.H.  Witten,  E.  Frank,  and  M.A.  Hall,  â€œData  Mining  Practical Machine Learning Tools and Techniquesâ€, Third Edition, Elsevier Publisher, USA, 2011. Accuracy :  94.17%    
True 
Tidak 
Miskin True 
Miskin Class Precision 
Pred 
Tidak 
Miskin 98 7 93% 
Pred 
Miskin 0 15 100% 
Class 
Recall 100% 68%       
[4] J. Agustinus, â€œSistem Deteksi Intrusi Jaringan dengan Metode Support Vector Machineâ€, M. Eng, Thesis, Jurusan Ilmu Komputer. FMIPA UGM, Yogyakarta, 2012. 
[5] J. Han, and M. Kamber, â€œData mining: Concepts and Techniquesâ€, Third Edition, Morgan Kaufmann Publishers, San Fransisco, 2013. 
[6] Kurniawan, Dios, Pengenalan Machine Learning dengan Python, PT. Elex Media Komputindo, Jakarta, 2020. 
[7] Saikin, & Kusrini. 2019. Model Data Mining Untuk Karekteristik Data Traveller Pada Perusahaan Tour And Travel (Studi Kasus : Lombok Ceria Holiday). Jurnal Manajemen Informatika & Sistem Informasi, 2(2), 61 â€“68. 
[8] Yunus, A., Akbar, M., & Andri. 2019. Data Mining Untuk Memeprediksi Hasil Produksi Nuah Sawit Pada Pt Bumi Sawit Saukses (Bss) Menggunakan Metode K-Nearest Neighbor. Bina Darma Conference on Computer Science, 198 â€“207.",klasifikasi,"decision tree, adaboost",data sekunder penduduk desa,"accuracy, akurasi, recall"
SMOTE: METODE PENYEIMBANG KELAS PADA KLASIFIKASI DATA MINING,"SMOTE: METODE PENYEIMBANG KELAS PADA KLASIFIKASI DATA MINING

Amalia Anjani Arifiyanti, Eka Dyar Wahyuni 

Abstrak
Kasus dengan kelas observasi yang memiliki kemunculan jarang seperti penipuan dan penyakit cenderung data yang muncul tidak seimbang antara satu kelas dengan kelas lain. Metode sampling merupakan salah satu metode untuk menangani ketidakseimbangan ini. Salah satu metode sampling yang 
digunakan adalah oversampling dengan SMOTE. Dengan metode ini, kelas minoritas direplikasi sebanyak kelas mayoritas. Keseimbangan data pada semua kelas berdampak pada performa model klasifikasi. Pada penelitian ini, model klasifikasi yang dihasilkan oleh logistic linear, KNN, dan Naive Bayes menunjukkan bahwa metode SMOTE meningkatkan performa model klasifikasi, sedangkan decision tree tidak menunjukkan hasil yang berbeda baik sebelum oversampling maupun setelah oversampling. 
 
Kata Kunci : Data Mining, Imbalanced Class, Klasifikasi, Oversampling, SMOTE . 
 
Klasifikasi, yang merupakan salah satu permasalahan dalam data mining yang diselesaikan dengan mempergunakan metode supervised learning  sangat bergantung pada data latih. Data latih itu sendiri, jumlah distribusi data untuk masing-masing kelas sangat jarang memiliki jumlah yang sama. Dalam kondisi nyata, sangat sering ditemui, jumlah dataset masing-masing kelas berbeda [1]. Kondisi ini disebut dengan imbalanced data (ketidakseimbangan data). Imbalanced data  (ketidakseimbangan data) adalah salah satu masalah utama yang muncul dalam deteksi anomali pada dataset yang bersifat real time. Dataset dianggap tidak seimbang jika salah satu kelasnya memiliki dominasi yang sangat besar dibandingkan dengan kelas lainnya [2]. Ketidakseimbangan data ini biasanya muncul pada kasus prediksi penipuan, spam, penyakit, teroris, dsb. Hal ini muncul karena kasus spam yang ingin diprediksi jumlah kemunculannya sedikit jika dibandingkan dengan kasus yang non spam (kemunculannya dominan). Karena kemunculan kelas minor ini sangat  minim, classifier yang dibangun menjadi kurang terlatih dan karenanya memberikan prediksi yang tidak akurat. Bahkan pada beberapa kasus multi class classifier, ketidakseimbangan data ini menghasilkan representasi yang rendah dari suatu data dan akhirnya data ini cenderung diabaikan sama sekali [3]. Sebagian besar, algoritma pengklasifikasi cenderung secara implisit menganggap bahwa data yang diproses memiliki distribusi yang seimbang, karenanya pengklasifikasi standar lebih condong kearah data yang jumlah kelasnya dominan. Secara umum, ada 2 cara untuk menangani dataset yang tidak seimbang, yaitu di tingkat algoritmik atau tingkat data [2], [4], [5]. Pendekatan pada tingkat algoritmik adalah ketika algoritma machine learning  dimodifikasi agar dapat mengakomodasi ketidakseimbangan data. Algoritma yang umumnya dimodifikasi adalah C4.5, Naive Bayes, Random Forest, Neural Network K-Means [6], dan sebagainya.  Pendekatan pada tingkat data melibatkan resampling untuk mengurangi ketidakseimbangan kelas. Dua teknik pengambilan sampel dasar yang digunakan pada tingkat data adalah random oversampling (ROS) dan random undersampling   (RUS). ROS akan menduplikasi secara acak data dari kelas yang minoritas [4], [7]. ROS bisa menjadi pilihan yang baik ketika data yang dimiliki tidak banyak, tetapi mungkin menyebabkan overfitting  karena metode ini membuat salinan/duplikat yang sama persis dari data yang berasal dari kelas minoritas [7]. Sementara itu, untuk memodifikasi distribusi kelas, RUS akan membuang data (yang berasal dari kelas yang bersifat mayoritas) secara acak. Kekurangan dari RUS adalah dapat menyebabkan underfitting , karena menghapus informasi yang mungkin berharga [7]. Secara umum, metode oversampling  memberikan hasil yang lebih baik daripada metode under sampling [8]. Salah satu metode modifikasi dari oversampling  adalah Synthetic Minority Oversampling Technique  (SMOTE). Teknik ini mirip dengan ROS, perbedaannya ada pada sampel yang dihasilkan, tidak diduplikat secara random dari sampel yang sudah ada, tetapi sampel tersebut dibuat dengan mempergunakan konsep nearest neighbour . Beberapa penelitian sudah mencoba mengimplementasikan metode SMOTE ini dan juga beberapa modifikasinya [9] seperti FSMOTE [5], SMOTE-TL-ENN, SMOTE RSB, Borderline-SMOTE dan Safe Level SMOTE [10].  
SMOTE  
Metode ini diusulkan pertama kali pada tahun 2002 oleh Chawla, dimana kelas minoritas di-oversampling-kan dengan 
membuat â€œdata training sintetisâ€. Data training sintetis tersebut dibuat berdasarkan k-nearest neighbor . Pembangkitan data training sintetis yang berskala numerik berbeda dengan kategorik. Data numerik diukur berdasarkan jarak kedekatannya dengan jarak Euclidean sedangkan data kategorik dengan memperhitungkan nilai modusnya [11].  
Pengukuran Evaluasi 
Sebagian besar ukuran evaluasi untuk permasalahan klasifikasi mempergunakan confussion matrix  [10], [11]. Dari confussion matrix ini, dapat diperoleh nilai akurasi, precision dan recall. Jika hanya mempertimbangkan nilai akurasi, model prediksi yang dihasilkan, tidak dapat digunakan di lingkungan produksi karena nilai ini sangat menyesatkan [13]. Karena akurasi bukanlah metrik terbaik untuk digunakan ketika mengevaluasi dataset yang tidak seimbang, metrik yang dapat memberikan wawasan yang lebih baik adalah confussion matrix, precision dan recall [10], [7]. Penelitian ini bertujuan untuk membuktikan apakah diperlukan teknik resampling jika dihadapkan pada situasi ketidakseimbangan data dengan cara menguji performa ( precision, recall, F1 score, kurva ROC dan AUC) dari berbagai macam algoritma classifier.   

I. Metodologi  
Tahapan pada penelitian ini dapat dilihat pada gambar 1 berikut ini.  
Praproses Data
Data Latih Data Uji
SMOTE
Pembuatan 
Model 
Klasifikasi
Evaluasi Model
Gambar 1. Tahap Penelitian  
Dataset dan Praproses Data 
Dataset yang digunakan pada penelitian ini merupakan dataset yang dipublikasikan pada https://www.cs. purdue.edu/commugrate/data/credit_card/. DataminingContest2009.Task2.Train.Inputs.zip merupakan dataset untuk atribut prediksi dan DataminingContest2009.Task2.Train. Targets.zip untuk atribut kelas. Dataset tersebut merupakan data mengenai penipuan kartu kredit. Jumlah instances dalam dataset berjumlah 1000, dengan total null berjumlah 1. Dataset memiliki 19 atribut yang digunakan sebagai atribut prediksi dan 1 atribut target klasifikasi. Dari 19 atribut prediksi, dua atribut diantaranya bersifat nominal. Pada atribut target klasifikasi terdapat dua kelas yaitu kelas 1 dan 0. Kelas 1 berarti transaksi penipuan dan 0 berarti bukan transaksi penipuan. Kelas 0 berjumlah 97346 dan kelas 1 berjumlah 2654. Proporsi kelas 0 dan kelas 1 adalah 97 : 3. Hal ini menunjukkan bahwa dataset tersebut tidak seimbang. Dataset diproses terlebih dahulu sebelum dilakukan proses klasifikasi. Praproses pada penelitian ini dilakukan dengan cara menghapus instance yang mengandung nilai Null, menghapus atribut yang tidak relevan dengan atribut target, dan terakhir melakukan encoding pada atribut yang bersifat nominal. Metode encoding menggunakan metode one-hot encoding . Hasil setelah praproses adalah kelas 0 berjumlah 97345 dan kelas 1 berjumlah 2654 dan jumlah atribut prediksi berjumlah 70 dengan 1 atribut target.  
Pembagian Data 
Data yang telah melalui tahap praproses data, kemudian dibagi menjadi dua dataset yaitu data latih dan data uji. Data latih digunakan untuk pembuatan model klasifikasi. Pada penelitian ini, model klasifikasi dibuat berdasarkan beberapa classifier yaitu Logistic Regression, K-Nearest Neighbor (KNN), Decision Tree, dan Gaussian Naive Bayes. Pembagian data mengunakan metode hold-out dengan proporsi data latih dan data uji adalah 70:30. Dari pembagian tersebut maka jumlah data latih dan data uji untuk masing-masing kelas dapat dilihat pada tabel 1.  
Tabel 1 Proporsi Pembagian Data 
Data Latih 
(70%) Data Uji 
-30%
Kelas 0 68133 29212 
Kelas 1 1866 788 
Proses pembagian data dilakukan sebelum proses oversampling  dengan metode SMOTE. Jika oversampling  dilakukan sebelum pembagian data, maka data sintetis hasil penambahan data akan muncul pada data latih dan data uji. z  
SMOTE 
Oversampling  digunakan pada data latih. Metode SMOTE digunakan untuk menambah data sintetis pada dataset kelas minor (dalam kasus ini adalah kelas 1), sehingga jumlah instances pada kelas minoritas menjadi sama dengan jumlah instances pada kelas mayoritas (dalam kasus ini adalah kelas 0). Hal ini dilakukan agar data pada kedua kelas seimbang. Data sintetis tersebut hanya ditambahkan pada data latih.  
Evaluasi 
Model klasifikasi yang telah dibangun kemudian dievaluasi dengan menggunakan metric pengukuran akurasi, precision, recall, dan f-measure  serta ditambah dengan menggunakan metode pengukuran dengan menghitung AUC ( Area Under Curve ) pada ROC. 
 
II. Hasil dan Pembahasan  
Pembuatan model klasifikasi dilakukan dengan empat classifier yaitu logistic regression, KNN, decision tree, dan gaussian naive bayes. Hasil evaluasi dapat dilihat pada tabel 2 berikut ini.  
Tabel 2 Evaluasi Model Klasifikasi 
Jenis classifier Akurasi Precision Recall F1 
Tanpa diseimbangkan  
Logistic regression 0.977 0.816 0.185 0.302 
KNN 0.980 0.691 0.426 0.527 
Decision tree 0.968 0.438 0.480 0.403 
Naive Bayes 0.945 0.186 0.322 0.236 
Diseimbangkan dengan SMOTE 
Logistic regression 0.748 0.070 0.703 0.128 
KNN 0.872 0.124 0.640 0.207 
Decision tree 0.962 0.395 0.475 0.338 
Naive Bayes 0.829 0.080 0.525 0.139 
Jika dilihat pada tabel hasil tersebut, model yang dihasilkan dari data yang tidak diseimbangkan memiliki nilai akurasi yang sangat tinggi dibandingkan  dengan model yang dibangun dari data latih yang diseimbangkan dengan SMOTE. Akurasi yang tinggi tersebut namun dibarengi dengan nilai recall yang sangat rendah. Salah satu yang dapat dimaknai dalam hal ini adalah model yang dihasilkan tersebut mampu mengklasifikasikan kelas mayoritas dengan benar namun tidak mampu memprediksi kelas minoritas. Hal ini menunjukkan bahwa pada kasus kelas yang tidak seimbang, akurasi bukanlah alat pengukuran yang sesuai untuk menilai apakah model klasifikasi yang dihasilkan memiliki performa yang baik atau tidak untuk memprediksi kasus yang baru.  Hasil model pada jumlah kelas yang diseimbangkan dengan metode SMOTE, mengalami penurunan signifikan pada nilai akurasi kecuali pada classifier decision tree. Penurunan signifikan ini juga terjadi pada nilai presisi akan tetapi nilai recall mengalami peningkatan cukup signifikan. Hal ini menunjukkan bahwa model tidak hanya condong terhadap kelas mayoritas, sedangkan pada model klasifikasi presisi dan recall sebaiknya memiliki keseimbangan yang ditunjukkan pada nilai f1. Jika dilihat pada hasil evaluasi performa tersebut maka dapat dinyatakan bahwa classifier decision tree memiliki performa yang stabil. Nilai akurasi tidak jauh berbeda pada data sebelum diseimbangkan dengan data yang telah diseimbangkan. Decision tree juga menghasilkan nilai precision dan recall yang cukup seimbang jika dibandingkan dengan model yang dihasilkan oleh classifier yang lain.   Evaluasi performa model klasifikasi juga dapat dinilai menggunakan metode kurva ROC dengan menghitung Area Under Curve (AUC). Metode kurva ROC ini menggambarkan true positive rate (TPR) dibandingkan dengan false positive rate (FPR). TPR merupakan sensitivity atau recall (probability of detection ), sedangkan FPR dinyatakan sebagai probability of false alarm . Jika digambarkan dalam bentuk kurva ROC maka semakin mengarah ke pojok kiri atas semakin baik yaitu memiliki nilai TPR yang tinggi. Batas pada kurva ROC adalah 0.5 yang digambarkan sebagai garis diagonal. AUC adalah luas area di bawah curve ROC yang merupakan salah satu representasi dari kurva ROC. Model klasifikasi dinilai sempurna jika nilai AUC bernilai 1. Hasil model klasifikasi mengalami peningkatan AUC yang signifikan dari data yang belum diseimbangkan dengan data yang telah diseimbangkan. Nilai AUC pada model yang dihasilkan oleh logistic regression mengalami peningkatan paling tinggi, diikuti oleh KNN dan gaussian naive bayes. Hal ini berbeda dengan decision tree yang mengalami penurunan walaupun penurunan nilai AUC-nya tidak signifikan. Hasil AUC dari masing-masing classifier dapat dilihat pada tabel 3. Berdasarkan beberapa model evaluasi performa model klasifikasi yang telah dilakukan baik pada data yang belum diseimbangkan maupun data yang telah diseimbangkan, dapat dinyatakan bahwa model klasifikasi yang dihasilkan berdasarkan data yang tidak seimbang bukanlah model klasifikasi yang baik. Untuk classifier logistic regression, KNN, dan gaussian naive bayes menghasilkan model klasifikasi yang lebih baik jika data diseimbangkan. Decision tree menghasilkan model klasifikasi yang tidak jauh berbeda baik pada saat data belum seimbang maupun data telah diseimbangkan. Decision tree menghasilkan model dengan performa yang baik walaupun data tidak seimbang. Hal ini terjadi karena decision tree mempelajari hirarki if-else, sehingga memaksa kedua kelas dipelajari dengan seimbang.   
Tabel 3 Nilai AUC 
Jenis classifier  AUC 
Tanpa diseimbangkan 
Logistic regression  0.59 
KNN 0.71 
Decision tree 0.73 
Naive Bayes 0.64 
Diseimbangkan dengan SMOTE 
Logistic regression  0.73 
KNN 0.76 
Decision tree  0.72 
Naive Bayes 0.68 
Gambar 2 Kurva ROC Tanpa Oversampling  dengan SMOTE 
Gambar 3 Kurva ROC Oversampling  dengan SMOTE 
 
III. Kesimpulan 
Ketidakseimbangan jumlah data pada masing-masing kelas dalam dataset yang digunakan untuk membuat model klasifikasi dapat menghasilkan model yang memiliki performa kurang baik karena model tersebut hanya mampu memprediksi kelas mayoritas dengan baik namun tidak dapat memprediksi kelas minoritas. Metode SMOTE dapat digunakan untuk menyeimbangkan data tersebut. Hasilnya adalah model klasifikasi yang telah diseimbangkan dengan metode SMOTE memiliki performa lebih baik dibandingkan jika tidak dilakukan penyeimbangan data. Hal tersebut berlaku untuk classifier logistic regression, KNN, dan naive bayes, akan tetapi decision tree tidak menunjukkan perubahan yang signifikan. Decision tree menghasilkan model yang memiliki performa baik pada kedua skenario yakni data tidak seimbang dan data yang telah diseimbangkan. 
 
IV. Daftar Pustaka 
[1] â€œHow to handle Imbalanced Classification Problems in machine learning?â€ [Online]. Available: https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/. [Accessed: 23-Jan-2020]. 
[2] A. Somasundaram and U. S. Reddy, â€œData Imbalance: Effects and Solutions for Classification of Large and Highly Imbalanced Data,â€ Proc. 1st Int. Conf. Res. Eng. Comput. Technol. (ICRECT 2016), no. November, pp. 28â€“34, 2016. 
[3] A. FernÃ¡ndez, V. LÃ³pez, M. Galar, M. J. Del Jesus, and F. Herrera, â€œAnalysing the classification of imbalanced data-sets with multiple classes: Binarization techniques and ad-hoc approaches,â€ Knowledge-Based Syst., vol. 42, pp. 97â€“110, Apr. 2013. 
[4] B. W. Yap, K. A. Rani, H. A. Abd Rahman, S. Fong, Z. Khairudin, and N. N. Abdullah, â€œAn application of oversampling , undersampling, bagging and boosting in handling imbalanced datasets,â€ in Lecture Notes in Electrical Engineering, 2014, vol. 285 LNEE, pp. 13â€“22. 
[5] A. Saifudin, S. Wahono, â€œPendekatan Level Data untuk Menangani Ketidakseimbangan Kelas pada Prediksi Cacat Softwareâ€, Journal of Software Engineering.â€, vol. 1, pp. 76-85, 2015. 
[6] C. A. Sugianto, â€œAnalisis Komparasi Algoritma Klasifikasi Untuk Menangani Data Tidak Seimbang Pada Data,â€ Techno.COM, vol. 14, no. 4, pp. 336â€“342, 2015. 
[7] â€œDealing with Imbalanced Data - Towards Data Science.â€ [Online]. Available: https://towardsdatascience.com/methods-for-dealing-with-imbalanced-data-5b761be45a18. [Accessed: 23-Jan-2020]. 
[8] R. Siringoringo, â€œKlasifikasi Data Tidak Seimbang Menggunakan Algoritma Smote dan K-Nearest Neighbor,â€ vol. 3, no. 1, pp. 44â€“49, 2018. 
[9] B. Santoso, H. Wijayanto, K. A. Notodiputro, and B. Sartono, â€œSynthetic oversampling  Methods for Handling Class Imbalanced Problemsâ€¯: A Review,â€ in IOP Conference Series: Earth and Environmental Science, vol. 58, no. 1, 2017. 
[10] â€œHaving an Imbalanced Dataset? Here Is How You Can Fix It.â€ [Online]. Available: https://towardsdatascience.com/having-an-imbalanced-dataset-here-is-how-you-can-solve-it-1640568947eb. [Accessed: 23-Jan-2020]. 
[11] â€œHandling imbalanced datasets in machine learning - Towards Data Science.â€ [Online]. Available: https://towardsdatascience.com/handling-imbalanced-datasets-in-machine-learning-7a0e84220f28. [Accessed: 23-Jan-20",klasifikasi,"SMOTE, logistic linear","https://www.cs. purdue.edu/commugrate/data/credit_card/, DataminingContest2009.Task2.Train.Inputs.zip, DataminingContest2009.Task2.Train. Targets.zip","akurasi, precision, recall, f1"
Klasifikasi Penyakit Mata Menggunakan Convolutional Neural Network  (CNN),"Klasifikasi Penyakit Mata Menggunakan Convolutional Neural Network  (CNN)

Fani Nurona Cahya *,  Nila Hardi , Dwiza Riana, Sri Hadianti  

Abstrak                                          
Gangguan pada mata atau disebut juga penyakit mata adalah suatu kondisi yang mampu mempengaruhi jangka waktu hidup bagi sebagian orang. Gangguan mata atau penyakit mata banyak sekali jenisnya, diantaranya yaitu katarak , glaukoma  dan retina disease . Gangguan atau penyakit mata tersebut merupakan penyebab kebutaan yang paling sering terjadi. Melihat dari uraian tersebut, penting sekali untuk mendeteksi penyakit mata atau kelaianan sebelum terjadi kebutaan. Penelitian ini bertujuan untuk klasifikasi penyakit mata menggunakan Convolutional Neural Network (CNN)  berarsitekstur Alexnet dengan pembaruan berupa menggunakan 4 kelas yang membutuhkan 3 tahap proses yaitu melakukan tahap pre-processing  yang menghasilkan ukuran citra menjadi 224x224px. Tahap selanjutnya adalah ekstraksi fitur dengan 3 layer yaitu Convutional Layer, Pooling Layer, Fully Connected Layer , Pada implementasi CNN menggunakan 150 epoch. Hasil akurasi dari penelitian klasifikasi penyakit mata menggunakan  metode CNN adalah 98.37% .                                                                 
Kata kunci: penyakit mata , klasifikasi, convolutional neural network  (CNN)                                                                  
Abstract                                          
An eye disorder, also called a disease of the eye, is a condition that can affect the lifespan of some people. Eye disorders or diseases of which there are many types, including kataraks, glaukoma  and retina disease . This eye disorder or disease is the most common cause of blindness. Seeing from the description. It is very important to detect eye disease or negligence before blindness occurs This study aims to classify eye disease s using the Alexnet textured Convolutional Neural Network (CNN) with an update in the form of using 4 classes that require 3 stages of the process, namely conducting ahap pre-processing  which results in an image size of 224x224px. The next stage is Feature  Extraction with 3 layers, namely Convutional Layer, Pooling Layer, Fully Connected Layer, the implementation of the Convolutional Neural Network implementation uses 150 epochs. The accuracy of the eye disease classification study using the Convolutional Neural Network method was 98.37%.  

Keywords:  eye disease , classification, convolutional neural network (CNN) .                                                                 
1 Pendahuluan                                          
Gangguan mata  banyak se kali jenisnya, diantaranya  katarak , glaukoma  dan retina disease . Katarak  merupakan keadaan dimana terjadi kekeruhan pada serabut atau bahan lensa didalam kapsul lensa  [1]. Berdasarkan data yang didapatkan dari Kementrian Kesehatan RI, sebanyak 50% penyebab kebutaan di Indonesia yaitu  katarak . Secara global,  Negara  Indonesia  sendiri  kini menempati posisi  kedua sebagai negara yang  jumlah penderita katarak nya tinggi setelah Negara Etiopia  [2]. Kasus yang terjadi di negara Indonesia khususnya di Nusa Tenggara Timur (NTT) prevalensi katarak  yang terjadi yaitu  sebesar 2,3% dengan  adanya  tiga penyebab  utama penderita katarak  ini belum melakuan proses operasi yaitu dikarenakan oleh ketidaktahuan s sebanyak  41,4% , tidak mampu untuk membiayai operasi sebanyak 14,1%, yang terakhir yaitu  ketidakberanian  sebanyak  5,7%  [3]. Berdasarkan uraian tersebut, dapat diartikan bahwa penyakit mata yang di sebut katarak  ini kasusnya cukup tinggi dikarenakan cukup banyak  penderita katarak  justru tidak menyadari bahwa dirinya mengidap  penyakit tersebut . tidak dapat dilakukan pencegahan terhadapa penyakit katarak ,akan tetapi penyakit katarak  dapat disembuhkan  denganproses  operasi  [4]. Selain katarak  penyakit mata lainnya yaitu glaukoma. Glaukoma itu sendiri merupakan salah satu kelainan  pada  mata yang dapat berupa suatu neuropati kronik yang  juga ditandai dengan terjadinya pencekungan  pada  diskus optikus , menciutnya lapang pa ndang, serta  biasanya disertai dengan peningkatan tekanan intraokular [5]. Glaukoma juga merupakan penyebab kebutaan kedua setelah katarak . Lalu penyakit mata lainnya yaitu retina disease  yang merupakan gangguan pada bagian retina di dalam mata yang berpengaruh buruk terhadap penglihatan seseorang [6]. Melihat dari uraian sebelumnya, penting sekali untuk mendeteksi penyakit mata atau kelaianan pada mana  sebelum terjadi kebutaan. Sudah cukup banyak peneliti yang melakukan penelitian mengenai penyakit mata, diantaranya yaitu  Penelitian deteksi katarak  ini dapat  juga dilakukan mengguanakan citra digital. Citra digital dapat diuraikan sebagai  bentuk diskrit dari  suatu  citra analog baik berupa koordinatnya maupun  berupa  nilai intensitas cahayanya [7]. Seiring dengan perkembangan zaman, teknologi berkembang dengan pesat saat ini. Dengan perkembangan teknologi sekarang ini memudahkan semua orang mengakses apa saja.  Salah satu teknologi yang telah ditemukan yaitu pengolahan citra  menggunakan citra  digital . Identifikasi yang dilakukan pada sebuah citra memnag sudah  cukup  lama dikembangkan , salah satunya  yaitu  dengan cara membedakan tekstur pada citra tersebut.  Pada tekstur citra dapat dibedakan oleh bebarapa factor, diantaranya yaitu kerapatan, keseragaman, kekasaran dan keteraturan [8]. komputer tidak dapat  secara langsung  membedakan  suatu  tekstur  pada suatu objek  seperti halnya  yang dapat dilakukan oleh penglihatan manusia, oleh sebab itu  digunakan suatu analisis tekstur guna  mengetahui suatu pola dari sebuah  citra digital. Analisis tekstur  juga akan menghasilkan  sebuah nilai  dari suatu  ciri atau karakteristik tekstur yang selanjutnya  dapat kenali dan kemuadian diolah oleh  komputer untuk  masuk kedalam  proses klasifikasi [9]. Secara umum klasifikasi bisa di artikan sebagai suatu  proses pengelompokan , dalam arti lain klasifikasi memisahkan suatu objek yang berbeda . Klasifikasi  bekerja dengan cara  menganalisis sifat numerik  dari sebuahfiturserta mengatur data menjadi berbagai macam  kategori  [10]. Topik yang sedang  hangat dalam dunia Machine Learning salah satu nya adalah Deep Learning , penyebabnya adalah kapabilitas  deep learning  yang  cukup  signifikan dalam  melakukan pemodelanpada berbagai data kompleks seperti citra dan suara. problem yang ditemui dalam coputer vision yang telah lama di cari peneyelesaiannyayaitu proses  klasifikasi ob jek pada suatu citra secara umum. Pada saat ini  Convolutional Neural Network (CNN)  merupakan metode deep learning yang memiliki hasil paling signifikan dalam pengenalan citra. [11] Melihat dari uraian sebelumnya, dalam penelitian ini penulis  mencoba  melakukan pembaruan untuk menerapkannya  pada eksperimen dengan citra fundus yang di dapatkan dari [12]. Penelitian ini akan  melakukan proses pengklasifikasian dari dataset citra fundus mata berbagai macam ciri untuk pengklasifikasian antara mata normal, katarak , glaukoma  dan retina disease  dengan  menggunkan Model Convolutional Neural Network (CNN) . Hal tersebut dikarenakan Mod el Convolutional Neural Network (CNN) bekerja dengan cara berusaha untuk meniru kan sebuah  sistem pengenalan citra pada visual cortex manusia sehingga  dapat  memiliki kemampuan mengolah informasi citra  layaknya manusia . Manfaat dari penelitian ini yaitu menjadi lebih efisien dan memudahkan dalam proses peng klasifikasian sesuai dengan yang di harapkan  khususnya dalam  bidang  kesehatan  yaitu klasifikasi penyakit mata . Pengklasif ikasian juga bisa diperoleh dengan  waktu yang tepat dan akurasi yang lebih tinggi menggu nakan  metode yang di usulkan  pada penelitian ini.                                                                  
2 Tinjauan Literatur                                  
Pertama dilakukan Penelitian oleh[13]yang mencoba mendeteksi indikasi adanya katarak  dan juga mengklasifikasikan dari citra digital katarak  dalam dua kategori, dua kategori tersebut yaitu         nuclear dan cartical. Pengukuran bentuk bundar ini rntan akan ukuran dan bentuk objek misalnya ketika citra mata berada dalam kondisi tidak utuh seperti tertutup objek lain atau pengambilan citra yang kurang jelas oleh kamera olehkamera. Pada penelitian ini berhasil mendapatkan tingkat akurasi 94.96% . Kemudian pada Penelitian yang dilakukan oleh [14]yang dilakukan oleh peneliti fokus pembuatan pada sistem deteksi katarak  otomatis jarak jauh dengan cara memanfaatkan teknologi cloud.  Pada penelitian selanjutnya  yang dilakukan oleh [15]bertujuan untuk mengklasifikasikan mata normal, katarak , dan pasca katarak . Terdapat empat fitur yang dideteksi antara lain Small Ring Area, 
Big Ring Area , dan Edge Pixel Count dengan menggunakan dua metode ambang untuk mendeteksi tepian yang kuat dan lemah kemudian menghitung jumlah pixel yang putih pada keluaran dari deteksi tepian, dan juga object perimeter. Penentuan SRA dan BRA juga metode ekstraksi yang menggunakan threshold performanya bisa dipengaruhi oleh translasi dan ukuran citra. Meskipun  ketiga metode yang dipaparkan tersebut telah berhasil mendeteksi mata katarak  dengan baik, namun metode-metode tersebut membutuhkan citra digital yang telah dikondisikan dalam kondisi tertentu apabila kondisi tersebut tidak tercapai maka dapat mengakibatkan menurunnya performa. Penelitian tersebut mengembangkan metode pendeteksian katarak  dengan menggunakan citra digital yang 1.diambil dengan bebas , dan 2. Berdasarkan visible light dapat diambil dengan kamera umum . Penelitian ini berfokus pada model klasifikasi mata katarak dan mata normal dengan pengolahan citra digital dalam format JPG/JPEG yang lebih umum, dan relatif lebih murah juga mudah diperoleh menggunakan metode yang lebih tahan terhadap translasi dan perubahan ukuran, serta mampu bekerja dengan baik menggunakan citra digital dalam kondisi bebas.          

3 Metode Penelitian                                  
Menggunakan CNN agar dapat mengklasifikasi penyakit mata. Metode yang diusulkan dalam penelitian ini dapat di gambarkan seperti pada gambar 1:                  
Gambar  1. Metode Penelitian                                  
A.  Dataset                                          
Dataset ini melalui beberapa seleksi di antara beberapa dataset yang di dapatkan dari [12]. Alasan memilih dataset ini karena penelitian ini baru beberapa kali dikembangkan sehingga peneliti ingin mencoba untuk mengembangkannya. Penelitian ini memaparkan tentang katarak . Dataset ini berumlah 610 dataset yang terbagi dari 4 kelas. Penelitian ini memaparkan  klasifikasi perbedaan mata normal, katarak, glaucoma dan retina disease . Dimana pengklasifikasian ini akan sangat bermanfaat dan membantu mendeteksi penyakit mata secara tepat dan akurat.  Contoh citra yang digunakan dapat dilihat pada Gambar 2 .                         
Gambar  2. Contoh Dataset  Tiap Kelas                          
B. Pre-processing                                  
Pre-processing  merupakan salah satu tahapan yang penting untuk data pada proses. Terkadang pada data tersebut terdapat berbagai permasalahan yang dapat menggangu hasil dari proses. Pre-processing  merupakan salah satu tahapan menghilangkan permasalahan-permasalahan yang dapat mengganggu hasil daripada proses data.  Pada tahapan ini dilakukan analisis terhadap pra proses data masukan sebelum masuk ke dalam tahap klasifikasi. Adapun tahapan-tahapan pre-processing  yang  dilakukan adalah grayscale, thresholding, segmentasi, dan resize .                         
C. Convolutional Neural Network (CNN)          
CNN  adalah pengembangan dari Multilayer Perceptron  (MLP) yang didesain untuk mengolah data dua dimensi. CNN termasuk dalam jenis Deep Neural Network  karena kedalaman jaringan yang tinggi dan banyak diaplikasikan pada data citra . CNN pertama kali dikembangkan dengan nama NeoCognitron  oleh Kunihiko Fukushima, seorang peneliti dari NHK Broadcasting Science Research Laboratories,  Kinuta, Setagaya, Tokyo, Jepang  [16]. Arsitektur CNN yang digunakan pada penelitian ini yaitu arsitektur Alexnet dapat d ilihat padaGambar 3. Gambar  3. Arsitektur Alexnet                                  
D. Konsep Convolutional Neural Network (CNN)          
Cara kerja CNN memiliki kesamaan pada MLP, namun dalam CNN setiap neuron dipresentasikan ke dalam bentuk dua dimensi, tidak sama seperti MLP setiap neuron hanya berukuran satu dimensi. Operasi linear pada CNN menggunakan operasi konvolusi, sedangkan bobot tidak lagi satu dimensi saja, tetapi berbentuk empat dimensi yang merupakan kumpulan kernel konvolusi seperti pada Gambar 4, Dimensi bobot pada CNN adalah : neuron input x neuron output  x tinggi x lebar Karena sifat proses konvolusi, maka CNN hanya bisa di pakai pada data yang memiliki struktur dua dimensi seperti citra dan suara .                                         
Gambar  4. Proses Konvulusi pada CNN                          
E. Arsitektur Jaringan CNN                          
JST terdiri dari berbagai layer dan beberapa neuron di  tiap masing-masing layer. Hal tersebut tidak bisa ditentukan dengan aturan yang pasti dan berlaku berbe da-beda dalam data yang berbeda [17]. Sebuah CNN terdiri dari beberapa layer.  Berdasarkan arsitektur [18], ada empat  macam layer utama dalam sebuah CNN hanya saja  yang diterapkan pada penelitian ini ada tiga macam lapisan  diantara nya :         
1) Convolution Layer                          
Convolution Layer melakukan operasi konvulusi pada output dari layer sebelumnya. Layer tersebut merupakan proses utama yang mendasari sebuah CNN. Bobot di layer tersebut menspesifikasikan kernel konvolusi yang dipakai, sehingga kernel konvolusi bisa dilatih berdasarkan input pada CNN . Tujuan melakukan  konvolusi terhadap  data citra yaitu  untuk mengekstraksi fitur dari citra input . Konvolusi dapat  menghasilkan transformasi linear  dari data input sesuai informasi spasial pada data. Bobot dilayer tersebut menspesifikasikan kernel  konvolusi yang di pakai , sehingga kernel konvolusi bisa dilatih berdasarkan  input pada CNN.  Penggambaran operasi kovolusi dapat dilihat pada gambar 5. Gambar  5. Operasi Kovolusi                                  
2) Subsampling Layer                                  
Subsampling  merupakan proses mereduksi ukuran sebuah data citra. Pada pengolahan citra, subsampling bertujuan untuk meningkatkan invariansi posisi dari fitur. Max pooling  membagi output dari convolution layer  menghasilkan beberapa grid kecil selanjutnya mengambil nilai maksimal dari setiap grid untuk menyusun matriks citra yang telah diredukasi seperti yang ditunjukan pada gambar                          
6. Kemudian hasil dari proses tersebut dapat dilihat di kumpulan grid sebelah kanannya                  
Gambar  6. Operasi Max Pooling                  
Springenberg dkk  pada penelitiannya [19] penggunaan pooling layer di CNN hanya untuk  bertujuan mereduksi ukuran citra sehingga dapat dengan mudah diganti dengan sebuah convolution layer dengan stride yang sama dengan pooling layer yang bersangkutan.                                  
3) Fully Connected Layer Fully                  
Layer tersebut merupakan layer yang biasanya dipakai dalam penerapan MLP dan bertujuan untuk melakukan transformasi p ada dimensi data agar dapat diklasifikasikan secara linear. Disetiap neuron pada convolution layer perlu ditransformasi menjadi data satu dimensi terlebih dahulu sebelum dapat dimasukkan kedalam sebuah fully connected layer . Dengan itu menyebabkan kehilangan data informasi spasialnya dan menjadi tidak reversibel, fully connected layer  hanya bisa diimplementasikan di akhir jaringan. Convolution layer  dengan ukuran kernel 1 x 1 menjalankan fungsi yang sama dengan sebuah fully connected layer  namun dengan teta p mempertahankan karakter spasial dari  data.                 
F. Proses Training                                  
Proses training adalah  tahapan dimana CNN dilatih untuk memperoleh akurasi yang lebih tinggi dari klasifikasi yang dilakukan . Pada tahapan ini terd apat proses feed forward dan proses backpropagation . Untuk melakukan  proses feedforward diperlukan jumlah dan ukuran layer  yang akan dibentuk, ukuran subsampling , citra vektor yang diperoleh. Hasil dari proses feedforward berupa bobot yang akan digunakan untuk mengevaluasi proses neural netw ork.         
1) Proses Feedforward                                  
Proses feed forward merupakan tahap pertama dalam proses training. Proses ini akan menghasilkan beberapa lapisan digunakan untuk mengklasifikasi data citra yang mana menggunakan bobot dan bias yang telah diperbaharui dari proses  backpropagation.                          
2) Proses Backpropagation                          
Proses backpropagation adalah tahap kedua dari proses training. Pada tahapan ini seperti yang telah dijelaskan, hasil proses dari feedforward di-trace kesalahannya dari lapisan output hingga lapisan pertama.                  
3) Perhitungan Gradient                  
Proses gradient untuk jaringan konvolusi adalah proses untuk menghasilkan nilai biast dan bobot yang baru dan akan diperlukan saat training.                                  
G. Proses Testing                                  
Proses testing merupakan proses klasifikasi yang menggunakan bias dan bobot dari hasil proses training. Sehingga akhir dari hasil proses ini menghasilkan akurasi dari klasifikasi yang dilakukan, data yang gagal diklasifikasi, nomor citra yang gagal diklasifikasi, dan bentuk network yang terbentuk dari proses feedforward. Lapisan  output sudah fully connected dengan label yang sudah ada. .                                                                 
4 Hasil dan Pembahasan                          
A. Arsitektur CNN                                  
Arsitektur CNN yang digunakan pada penelitian ini yaitu arsitektur Alexnet dengan model yang diterapkan dapat dilihat pada Gambar 7.                                 
Gambar  7. Model yang diterapkan                          
B.  Distribusi Data Train, Test, dan Valid                  
Pada tahap pre â€“processing  citra di resize  ukurannya menjadi 224x22 px . dengan ukuruan citra yang seragam guna memudahkan dalam komputasi. Selain itu ukuran citra yang seragam juga dapat memudahkan pada tahap pengenalan.  Selanjutnya masuk ke distribusi data yang dapat dilihat pada Tabel 1                                                   Tabel  1. Distribusi Data Train, Test, dan Valid  
Dataset                                                  
610                                                        
Train  Test                                                 
430                                                        
121 Train  Valid                                          
439 50                                                 
Berdasarkan Tabel 1  data training dan validasi tersebut digunakan dalam proses training, tuning, dan evaluasi model CNN sedangkan data test digunakan untuk menguji performa dari model hasil training tersebut. Setelah mendapatkan citra dengan ukuran yang seragam dan distribu si  data citra, selanjutnya masuk kedalam tahap pengklasifikasian . Pada tahap ini peneliti menggunakan parameter seperti yang 
terlihat pada Tabel 2 .                         
Tabel 2. Parameter                                  
Ukuran Citra  Epoch  batch_size  Optimizer          
224x224 px 150 Epoch  32 Adam                          
Berdasarkan  parameter yang digunakan dengan arsitektur Alexnet dan model yang diterapkan, didapat hasil seperti yang terlihat pada Gambar 8.                                          (a)     (b)                                                 
Gambar  8. (a) Grafik Loss (b) Grafik Akurasi          
Berdasarkan Gambar 8, dapat jelaskan bahwa klasifikasi penyakit mata menggunakan Convolutional Neural Network (CNN)  menghasilkan akurasi 98.37% Untuk mengetahui performa klasifikasi maka dilakukan evaluasi terhadap klasifikasi metrik dan confusion matrix sebagaimana dapat dilihat pada Gambar 9                                                            (a)      (b)                                         
Gambar  9. (a) klasifikasi metrik (b) Confusion metric Berikut Contoh hasil klasifikasi pada data testing  dapat dilihat pada Gambar 10                                 
Gambar  10. Hasil klasifikasi CNN (Alexnet)          
Dapat dilihat dari Gambar 10 ternyata klasifikasi penyakit mata menggunakan CNN masih terdapat kesalahan dalam pengenalannya. Kesalahan tersebut terdapat pada kelas katarak  yang ternyata dikenali sebagai kelas normal .         

5 Kesimpulan                                                  
Dari hasil penelitian klasifikasi penyakit mata menggunakan metode CNN dengan arsitektur model AlexNet, dengan pembaruan berupa menggunakan 4 kelas yaitu normal, katarak ,glaucoma  dan retina disease dilanjutkan dengan melakukan tahapan pre-processing  mengubah ukuran citra menjadi 224x224px. Langkah selanjutnya feature extraction  dengan 3 lapisan yaitu lapisan convutional , lapisan pooling , lapisan fully connected  sesuai dengan arsitektur yang diusulkan. Pada tahapan implementasi CNN menggunakan 150 epo ch, Hasil akurasi dari penelitian klasifikasi penyakit mata menggunakan metode CNN sebesar 98.37% .         

Referensi                                                  
[1] N. Maloring, A. Kaawoan, and F. Onibala, â€œHubungan Pengetahuan Dan Sikap Dengan Kepatuhanperawata n Pada Pasien Post Operasi Katarak  Di Balai Kesehatan Mata Masyarakat Sulawesi Utara,â€ J. Keperawatan UNSRAT , vol. 2, no. 2, p. 113824, 2014.                                          
[2] V. Wirawan and Y. E. Soelistio, â€œModel Klasifikasi Mata Katarak  dan Normal Menggunakan Histogram,â€ J. Ultim. , vol. 9, no. 1, pp. 33 â€“36, 2017, doi: 10.31937/ti.v9i1.561.                                          
[3] Riskesdas., â€œRiset Kesehatan Dasar (RISKESDAS) 2013. Laporan Nasional,â€ Ris. Kesehat. Dasar , 2013.          
[4] A. Allen, D., & Vasavada, â€œ Katarak  and surgery for katarak . BMJ,â€ (Clinical Res. Ed.). https//doi.org/10.1136/bmj.333.7559.128 , 2006.          
[5] L. W. Pusvitasari, A. Agung, and M. Putrawati, â€œProfil pasien glaukoma di Poliklinik Mata Rumah Sakit Indera Provinsi Bali Periode Januari 2014 -Juni 2015,â€ E-Jurnal Med. Udayana , no. April, pp. 189 â€“193, 2018.          
[6] M. I. Al Bukhory, â€œPendeteksian Eksudat pada Retina dengan Fungsi Surf sebagai Salah Satu         Ciri untuk mendiagnosa Diabetik Retinopati,â€ vol. 4, no. 1, pp. 978 â€“979, 2018.                                                  
[7] R. Gonzalez, R., & Woods, â€œDigital image processing.,â€ Prentice Hall. https:// doi.org/10.1016/0734 -189X(90)90171 -Q, 2008.                  
[8] Y. Garis K, I. Santoso, R.R. Isnanto, â€œKlasifikasi Citra dengan Matriks Ko -Okurensi Aras Keabuan (Gray Level Co -Occurrence Matrix -GLCM) pada Limakelas Biji -Bijian,â€ 2011.                                                  
[9] I. Permatasari dan T. Sutojo, â€œPengenalan Ciri Garis Telapak Tangan Menggunakan Ekstraksi Fitur (GLCM) dan Metode (KNN),â€ 2016.                                  
[10] D. Syahid, Jumadi, and D. Nursantika, â€œSistem Klasifikasi Jenis Tanaman Hias Daun Philodendron Menggunakan Metode K-Nearest Neighboor (KNN) Berdasarkan Nilai Hue, Saturation, Value (HSV),â€ JOIN , vol. I, no. 1, pp. 20 â€“23, 2016.                                                   [11] W. S. Eka Putra, â€œKlasifikasi Citra Menggunakan Convolutional Neural Network (CNN) pada Caltech 101,â€ J. Tek. ITS , vol. 5, no. 1, 2016, doi: 10.12962/j23373539.v5i1.15696.                                 
[12] Jr2ngb, â€œ katarak  dataset katarak  image dataset,â€ https://www.kaggle.com/jr2ngb/ katarak dataset , 2019.  
[13] A. Patwari, Anayet U., Muammer D. Arif, N.A. Chowdhury and & I. I. Arefin, â€œDetection, Categorization, and Assessment of Eye Katarak s Using Digital Im age Processing.,â€ First Int. Conf. Interdiscip. Res. Dev. Thailand. , 2011.                                          
[14] & S. K. G. Kolhe, S., â€œRemote Automated Katarak  Detection System Based on Fundus Images.,â€ Int. J. Innov. Res. Sci. Eng. Technol. Vol. 5, pp. 10334 -10341. , 2016.  [15] J. Nayak,  â€œAutomated Classification of Normal, Katarak  and Post Katarak  Optical Eye Image using SVM Classifier.,â€ Ann. der Phys. 322(10)891921. , 2013.  
[16] K. Fukushima, â€œNeocognitron: A Self -Organizing Neural Network Model for a Mechanism of Pattern Recognition Un affected by Shift in Position,â€ Biol. Cybern. , 1980.  [17] D. Stathakis, â€œHow Many Hidden Layers And Nodes,â€ Int. J. Remote Sens. , 2008.                                  
[18] Stanford University, â€œAn Introduction to Convolutional Neural Network,â€ Vis. Imaging Sci.Technol. Lab, Stanford Un iv. [Online .                         
[19] J. T. Springenberg, â€œA. Dosovitskiy, T. Brox and M. Riedmiller, """"Striving For Simplicity: The All Convolutional Net,â€ ICLR 2015,  2015.",klasifikasi,"convulutional neural network, CNN, AlexNet",penyakit mata,akurasi
PENERAPAN ALGORITMA KLASIFIKASI NEAREST NEIGHBOR (K-NN) UNTUK MENDETEKSI PENYAKIT JANTUNG,"PENERAPAN ALGORITMA KLASIFIKASI NEAREST NEIGHBOR (K-NN) UNTUK MENDETEKSI PENYAKIT JANTUNG

MEI LESTARI  

Abstrak
Data WHO menyatakan bahwa sebanyak 7,3 juta penduduk dunia meninggal dikarenakan penyakit jantung. Meskipun penyakit jantung merupakan penyakit yang tidak menular, penyakit ini merupakan jenis penyakit yang mematikan nomor satu di dunia. Penyakit jantung disebut juga dengan penyakit jantung koroner, penyakit ini terjadi bila darah ke otot jantung terhenti/tersumbat, sehingga mengakibatkan kerusakan berat pada jantung (Rajkumar & Reena, September 2010) . Penerapan Algoritma Klasifikasi Nearest Neighbor (K-NN) diharapkan dapat mengatasi masalah efektifitas dan akurasi dalam mendeteksi penyakit jantung. Pada penelitian ini digunakan algoritma K-NN dengan k = 9 pada 100 data pasien penyakit jantung. Hasil penelitian diperoleh nilai akurasi sebesar 70% serta nilai  AUC sebesar 0.875 yang masuk kedalam klasifikasi baik, sehingga algoritma K-NN dapat digunakan dan diterapkan untuk mendeteksi penyakit jantung.  
 
Abstract. 
Data from WHO states that 7,3 million people die because of Heart Disease. Although Heart Disease i s not contagious, this kind of disease is the number 1 disease causing death. Heart disease is  also called as coroner disease. It happens when the blood drifting to the heart muscles stops so that it causes heart disorder (Rajkumar & Reena, September 2010) . The application of Nearest  Neighbor classification (K-NN) algorithm is expected to overcome the problems on the affectivity and accuracy in detecting heart disease. In this research, the K-NN with K = 9 is used on 100 patients of heart disease. The result revealed is that the accuracy is 70% and the AUC is 0.875 which belong to the good classification. Hence, K-NN algorithm can be used and applied in detecting heart disease.  
 
Keywords : Nearest Neighbor, Jantung, Algoritma, Akurasi.  
 
PENDAHULUAN  
Jantung merupakan organ manusia yang berperan dalam sistem peredaran darah. Penyakit jantung adalah sebuah kondisi dimana jantung tidak dapat melaksanakan tugasnya dengan baik. Data WHO menyatakan bahwa sebanyak 7,3 juta penduduk dunia meninggal dikarenakan penyakit jantung. Meskipun penyakit jantung merupakan penyakit yang tidak menular, penyakit ini merupakan jenis penyakit yang mematikan nomor satu di dunia.  Penyakit jantung disebut juga dengan penyakit jantung koroner, penyakit ini terjadi bila darah ke otot ja ntung terhenti/tersumbat, sehingga mengakibatkan kerusakan berat pada jantung (Rajkumar & Reena, September 2010) . Penyebab utama penyakit jantung adalah penggunaan tembakau, fisik tidak aktif, diet yang tidak sehat dan penggunaan alkohol, resiko penyakit jantung bertambah dengan meningkatnya usia, tekanan darah tinggi, mempunyai kolesterol tinggi, dan kelebihan berat badan.  Algoritma Nearest Neighbor  (K-NN) merupakan algoritma klasifikasi berdasarkan kedekatan jarak suatu data dengan data yang lain. Pada algoritma K-NN, data berdimensi Faktor Exactaq,jarak dari data tersebut ke data yang lain dapat dihitung. Nilai jarak inilah yang digunakan sebagai nilai kedekatan/kemiripan antara data uji dengan data latih. Nilai K pada K-NN berarti K-data terdekat dari data uji.  
Untuk  menangani masalah efektifitas dan akurasi dalam mendeteksi penyakit jantung maka dibuatlah sistem pendeteksi penyakit jantung menggunakan algoritma klasifikasi nearest neighbor  (K-NN).  Dalam penelitian ini, pertanyaan yang diajukan adalah â€œApakah algoritma nearest neighbor  dapat diterapkan pada otomatisasi sistem pendeteksi penyakit jantung?â€, â€œBagaimana tingkat akurasi pendeteksian penyakit jantung menggunakan algoritma nearest neighbor ?â€. 
 
TINJAUAN PUSTAKA  
Algoritma Nearest Neighbor  
External variable secara langsung akan mempengaruhi persepsi manfaat dan prsepsi kemudahan dari pengguna. Persepsi kemudahan penggunaan dipengaruhi oleh variabel eksternal yang berkenaan dengan karakteristik sistem yang meningkatkan 
penggunaan dari teknologi, seperti mouse,  touch screen, menu dan selain itu, pelatihan individu juga akan mempengaruhi kemudahan penggunaan. Semakin banyak pelatihan yang diterima individu, semakin besar tingkat kemudahan dalam penggunaan.  Tujuan algoritma KNN adalah mengklasifikasikan obyek baru  berdasarkan atribut dan training sample.  Clasifier  tidak menggunakan model apapun untuk dicocokkan dan hanya berdasarkan pada memori. Diberikan titik query , akan ditemukan sejumlah k obyek atau (titik training) yang paling dekat dengan titik query. Klasif ikasi menggunakan voting terbanyak diantara klasifikasi dari k obyek. Algoritma KNN menggunakan klasifikasi ketetanggaan sebagai nilai prediksi dari query instance  yang baru. Algoritma metode KNN sangatlah sederhana, bekerja berdasarkan jarak terpendek dari query instance ke training sample  untuk menentukan KNN-nya. 
Nilai k yang terbaik untuk algoritma ini tergantung pada data. Secara umum, nilai k yang tinggi akan mengurangi efek noise pada klasifikasi, tetapi membuat batasan antara setiap klasifikasi menj adi semakin kabur. Nilai k yang bagus dapat dipilih dengan optimasi parameter, misalnya dengan menggunakan cross-validation . Kasus khusus dimana klasifikasi diprekdisikan berdasarkan training data yang paling dekat (dengan kata lain, k=1) disebut algoritma  Nearest Neighbor.  
Kelebihan KNN (K-Nearest Neighbor):  
1. Tangguh terhadap training  data yang memiliki banyak noise . 
2. Efektif apabila training  datanya besar.  Kelemahan KNN (K-Nearest Neighbor):  
1. KNN perlu menentukan nilai dari parameter k (jumlah dari tetangga terdekat).  
2. Training  berdasarkan jarak tidak jelas mengenai jenis jarak apa yang harus digunakan.  
3. Atribut mana yang harus digunakan untuk mendapatkan hasil terbaik.  
4. Biaya komputasi cukup tinggi karena diperlukan perhitungan jarak dari  tiap query instance pada keseluruhan training sample.  Untuk lebih jelasnya algoritma K -NN dapat dilihat pada gambar 1.
Gambar 1. algoritma K-NN  
1. Tentukan parameter K 
2. Hitung jarak antara data yang akan dievaluasi  dengan semua pelatihan  
3. Urutkan jarak yang terbentuk (urut naik)  
4. Tentukan jarak terdekat sampai urutan K 
5. Pasangkan kelas yang b ersesuaian  
6. Cari jumlah kelas dari tetangga yang terdekat dan tetapkan kelas tersebut sebagai kelas data yang akan dievaluasi   
Rumus KNN:  
ï€¨ï€©ïƒ¥
ï€½ï€­ ï€½p
ii i i x x d
12
1 2
â€¦(1)  
Keterangan:  
1x  = Sampel Data  
2x
#NAME?
i = Variabel Data  
d = Jarak  
p = Dimensi Data  
 
METODE  
Data utama diperoleh dari University of California Irvine Machine learning data repository . Sedangkan data pendukung diambil dari buku, jurnal dan publikasi lainnya. Sampel dari penelitian ini adalah data profile penderita penyakit jantung, data tersebut bersifat publik yang didapatkan dari University of California Irvine machine learning data repository . Pengolahan data dalam penelitian ini adalah proses pengelompokan data-data yang telah dikumpulkan sebelumnya dengan tujuan untuk menentukan variabel -variabel yang akan digunakan beserta himpunan -himpunan yang termasuk kedalam variabel-variabel yang digunakan. Terdapat 13 atribut yang digunakan dalam mendiagnosa penyakit Data Training  Start  
Input data testing  
Tetapkan nilai k = 9  
Hitung jarak kedekatan  
Pilih kelas mayoritas  
End 
Urutkan Jarak jantung yaitu Age, Sex, Chest Pain Type, Tresting Blood Pressure, Serum cholestoral dalam mg/dl, Fasting blood sugar>120 mg/dl, Resting electrocardiographic result, The Slope of the peak exer cise ST segment, Excercise Induced Angina, Old Peak, CA (Number  of Major Vessels), Maximum Heart Rate, Achieved (Thalac), Thal  Terdapat 100 data pasien penyakit jantung yang diolah menggunakan algoritma 
Klasifikasi Nearest Neighbor (KNN) dengan k = 9.  

HASIL DAN PEMBAHASAN  
Pada penelitian ini digunakan 110 records  pasien. 100 records  digunakan sebagai data latih ( training data ) dan 10 records  digunakan sebagai data uji ( testing data ). Untuk menentukan apakah seorang pasien terkena penyakit jantung digunakan  9 data terdekat atau K= 9. Klasifikasi dilakukan dengan menggunakan mayoritas suara diantara klasifikasi dari K objek. Algoritma KNN menggunakan klasifikasi ketetanggaan sebagai prediksi terhadap data baru. Dari 9 data tersebut diperoleh kelas mayoritas, maka data uji tersebut masuk kedalam kelas mayoritas. Contoh perhitungan kedekatan atau jarak antar  atribut adalah sebagai berikut:   
Tabel 1. Contoh Data Latih  
AGE SEX CHEST PAIN TYPE  RESTING BLOOD PREASURE SERUM CHOLESTORAL FASTING BLOOD SUGAR  RESTING ELECTROCARDIOGRAPHIC MAXIMUM HEART RATE  EXERCISE OLDPEAK SLOPE CA THAL CLASS 
70 1 4 130 322 0 2 109 0 2,4 2 3 3 2 
67 0 3 115 564 0 2 160 0 1,6 2 0 7 1 
57 1 2 124 261 0 0 141 0 0,3 1 0 7 2 
Tabel 2. Contoh Data Uji  
AGE SEX CHEST PAIN TYPE  RESTING BLOOD PREASURE SERUM CHOLESTORAL FASTING BLOOD SUGAR  RESTING ELECTROCARDIOGRAPHIC MAXIMUM HEART RATE  EXERCISE OLDPEAK SLOPE CA THAL CLASS 
44 0 3 108 141 0 0 175 0 0,6 2 0 3 1 
Perhitungan kedekatan kasus antara data training dengan data uji adalah sebagai berikut:  
Kuadrat jarak data training baris ke -1 dengan data uji =  
(70-44)2+(1-0)2+(4-3)2+(130 -108)2+(322 -141)2+(0-0)2+(2-0)2+(109 -175)2+(0-0)2+(2,4 -0,6)2+(2-2)2+(3-0)2+(3-3)2 = 38295,24  
Evaluasi dan Validasi   
Tabel 3. Hasil Evaluasi dan Validasi   
Untuk mengukur tingkat akurasi klasifikasi metode yang digunakan antara lain confusion matrix . Perhitungan kedekatan kasus pada data training dengan kasus pada data 
testing, diketahui dari 10 data 4 data  termasuk kedalah kelas â€œ1â€ atau terkena penyakit jantung dan 6 data termasuk kedalam kelas â€œ2â€ yaitu normal atau tidak terkena penyakit jantung.  Perhitungan kedekatan data training dengan kasus pada data testing  3 data diprediksikan masuk kedalam kelas â€œ1â€ tetapi ternyata termasuk kedalam kelas â€œ2â€. Dari 100 data training dan 10 data testing dan menggunakan metode K-NN dengan nilai K = 9  diperoleh tingkat akurasi sebesar 70%.  Tabel  4 berikut merupakan tabel coffusion matrix untuk metode K-NN.  
Tabel 4. Cofussion Matrix  
Kelas  
Prediksi  Kelas sebenarnya  
1 2 
1 4 3 
2 0 3 
Kurva berikut merupakan kurva ROC untuk perhitungan cofussion matrix. Nilai AUC pada data mining dibagi menjadi beberapa kelompok yaitu sangat baik untuk nilai 0.90-1.00, klasifikasi baik untuk nilai 0.80 -0.90, klasifikasi cukup untuk nilai 0.70 -0.80, klasifikasi buruk untuk nilai 0.60 -0.70 dan klasifikasi salah untuk nilai 0.50 -0.60 (Gorunescu, 2011). Pada kurva terlihat nilai AUC adalah 0.875 sehing ga dapat disimpulkan metode KNN termasuk kedalam klasifikasi baik.   
NO AGE SEX CHEST PAIN TYPE RESTING BLOOD PREASURE  SERUM CHOLESTORAL  FASTING BLOOD SUGAR RESTING ELECTROCARDIOGRAPHIC MAXIMUM HEART RATE  EXERCISE OLDPEAK SLOPE CA THAL KLASIFIKASI DIKLASIFIKASIKAN SEBAGAI 
1 44 0 3 108 141 0 0 175 0 0,6 2 0 3 1 1 
2 67 1 4 120 237 0 0 71 0 1 2 0 3 2 2 
3 49 0 4 130 269 0 0 163 0 0 1 0 3 1 1 
4 57 1 4 165 289 1 2 124 0 1 2 3 7 2 2 
5 63 1 4 130 254 0 2 147 0 1,4 2 1 7 2 2 
6 48 1 4 124 274 0 2 166 0 0,5 2 0 7 2 1 
7 51 1 3 100 222 0 0 143 1 1,2 2 0 3 1 1 
8 60 0 4 150 258 0 2 157 0 2,6 2 2 7 2 1 
9 59 1 4 140 177 0 0 162 1 0 1 1 7 2 1 
10 45 0 2 112 160 0 0 138 0 0 2 0 3 1 1 
Gambar 2. Kurva ROC dengan Metode KNN  
 
PENUTUP  
Dalam penelitian ini dilakukan penerapan algoritma K -NN dengan k = 9 pada data pasien untuk mendeteksi penyakit jantung. Kedekatan antara kasus pada data training dan data uji dilakukan untuk menentukan kelas data uji tersebut. Untuk mengukur kinerja algor itma tersebut dilakukan dengan menggunakan cofusion matrix  dan kurva ROC, diperoleh nilai akurasi 70%  dan termasuk klasifikasi baik karena memiliki nilai AUC 0.875.  Terdapat saran yang dapat diterapkan guna penelitian selanjutnya, yaitu, dilakukan komparasi terhadap algoritma atau metode data mining lainnya dalam mendeteksi penyakit jantung, untuk mengetahui algoritma mana yang lebih akurat dan efisien, sehingga dapat ditentukan algoritma yang tepat untuk mendeteksi penyakit jantung.  
 
DAFTAR PUSTAKA  
Bramer, Max. 2007. Principles of Data Mining . London : Springer  Gorunescu, Florin. 2011. Data Mining: Concepts, Models, and Techniques . Verlag 
Berlin Heidelberg : Springer  Han, J.,&Kamber, M. 2006.  Data Mining Concept and Tehniques . San Fransisco : Morgan K auffman.  Kusrini  & Luthfi,  E. T. 2009. Algoritma Data Mining . Yogyakarta : Andi Publishing.  
Sumathi, & S., Sivanandam, S.N. 2006. Introduction to Data Mining and its Applications . Berlin Heidelberg New York: Springer .",klasifikasi,"Nearest Neighbor, K-NN, KNN",University of California Irvine Machine learning data,"akurasi, AUC"
Klasifikasi Citra Daun Herbal Dengan Menggunakan Backpropagation Neural Networks Berdasarkan Ekstraksi Ciri Bentuk,"Klasifikasi Citra Daun Herbal Dengan Menggunakan Backpropagation Neural Networks Berdasarkan Ekstraksi Ciri Bentuk

Arief Herdiansah1*, Rohmat Indra Borman2, Desi Nurnaningsih1, Alfry Aristo J Sinlae3, Rosyid Ridlo Al Hakim4 

Abstrak   
Sejak zaman dahulu hingga sekarang tanaman herbal telah dimanfaatkan untuk pengobatan dan telah diterapkan di dunia kesehatan sampai saat ini . Seluruh bagian tumbuhan dapat digunakan sebagai obat, salah satunya adalah daunnya. Namun, masih banyak orang yang belum mengenal daun  herbal daun obat tersebut. Hal ini dikarenakan daun sekilas terlihat  hampir sama, sehingga sulit untuk membedakannya . Sebenarnya jika dicermati, daun memiliki ciri-ciri yang dapat dibedakan antara daun satu dengan yang lain. Tujuan penelitian ini yaitu  unuk mengklasifikasikan  citra jenis daun herbal  menggunakan algoritma Backpropagation Neural Network (BNN) 
dengan ekstraksi ciri bentuk memanfaatkan  parameter metric dan eccentricity . BNN merupakan jenis algoritma pembeljaran  terawasi yang terdari dari  beber apa lapisan  dan menggunakan output error sebagai pengubah  nilai bobot  ke arah belakang . Pada penelitian ini pada  ekstraksi ciri  bentuk yang menjadi masukan untuk algortima BNN  akan melalui  operasi morfologi untuk memperbaiki hasil segmentasi agar hasil kla sifikasi lebih optimal . Hasil pengujian menunjukkan akurasi sebesar 88,75 %, ini menunjukkan model yang dikembangkan dapat mengklasifikasikan daun herbal  dengan baik.  

Kata Kunci : Klasifikasi Citra

Abstract  
Since ancient times until now herbal plants have been used for treatment and have been applied in the world of health to this  day. All parts of the plant can be used as medicine, one of which is the leaves. However, there are still many people who are not familiar with the medicinal leaves. This is because the leaves at first glance look almost the same, making it difficult to tell them apart . Actually, if you look closely, the leaves have characteristics that can be distinguished from one leaf to another. The purpose of this study is to classify images of herbal leaf species using the Backpropagation Neural Network (BNN) algorithm with shape feature extraction  utilizing metric and eccentricity parameters. BNN is a type of supervised learning algorithm that consists of several layers and uses an error output as a modifier of the weight value backwards. In this study, the extraction of shape features that become input for the BNN algorithm will go through morphological operations to improve the segmentation results so that the classification results are more optimal. The test results show an accuracy of 88.75%, this shows the developed model can classify herbal leaves well.  

Keywords : Image Classification

1. PENDAHULUAN  
Pada masa pandemi Covid -19 obat tradisional berupa ramuan dan tanaman herbal kian populer sebagai salah satu 
alternatif meningkatkan imun atau daya tahan tubuh. Tanama herbal merupakan tanaman yang berkhasiat sebagai obat dan digunakan untuk menyembuhkan atau mecegah suatu penyakit [1]. Sejak zaman dahulu hingga sekarang tanaman herbal telah dimanfaatkan untuk pengobatan dan telah diterapkan di dunia kesehatan sampai saat ini. Bahkan WHO menyebutkan penggunaan obat herbal pada negara maju mencapai 65% dan 80% pada negara berkembang mencapai 80%  [2]. Tercatat hampir  10% atau sekitar 350.000 spesies dari seluruh tumbuhan berpembuluh dapat digunakan sebagai obat  [3]. Tanaman obat yang sudah dikenal di dunia mencapai sekitar 40 .000 jenis obat herbal  dan sekitar 30.000 tanama obat tersebut diyakini terdapat  di Indonesia  [4]. Seluruh bagian tumbuhan dapat digunakan sebagai obat, salah satunya adalahdaunnya. Daun adalah  salah satu bagian dari tanaman  yang tumbuh pada dahan , biasan ya memiliki  warna hijau yang  fungsinya sebagai penangkap  energi dari sinar matahari yang digunakan sebagai  fotosintesis. Berdasarkan uji klinis, daun mengandung  vitamin, mineral dan antioksidan yang secara alami dapat membantu menjaga kesehatan tubuh  manusia. Pemerintah melalui Kementrian Kesehatan telah mengeluarkan â€œKeputusan Menteri Kesehatan Republik Indonesia Nomor HK.01.07/Menkes/187/2017 â€ tentang â€œFormularium Ramuan Obat Tradisional Indonesia â€. Berdasarkan Keputusan Menteri  tersebut  terdapat beberapa daun yang ditetapkan sebagai ramuan obat tradisonal atau herbal.  Namun, beberapa masyarakat  belum mengenal daun  herbal daun obat tersebut. Hal ini dikarenakan daun sekilas terlihat  hampir sama, sehingga sulit untuk membedakannya  [5]. Sebenarnya jika di cermati, daun  memiliki ciri-ciri yang dapat dibedakan  antara daun satu dengan yang lain. Maka diperlukan suatu sistem yang dapat mengklasifikasikan  dan daun berdasarkan citranya  sehingga lebih mudah dalam memberikan informasi mengenai jenis daun  tersebut. Hal ini dapat diatasi melalui penerapan  teknologi pengolahan citra digital.  Pengolahan citra digital merupakan  bidang yang mempelajari pembentukan, pengelolaan dan menganalisa citra agar mendapatkan informasi yang dapat dimanfaatkan  [6]. Salah satu implementasi pengo lahan citra adalah  klasifikasi. Klasifikasi citra merupakan proses untuk pengelompokan sejumlah pixel atau picture element pada sebuah  citra menjadi  kelas-kelas  pada masing-masing kelas mendiskripsikan  suatu entitas yang mempunya karakter agar dapat  dikenali [5]. Pendekatan  yang dapat dimanfaatkan dalam peneyelesaian klasifikasi citra adalah jaringan syaraf tiruan  (neural network ). Neural network  merupakan  pendekatan  komputasi yang mengadopsi pola kerja  jaringan syaraf manusia  [7]. Jaringan syaraf tiruan menerapkan  perhitungan dasar non -linier yang dikenal dengan istilah  neuron dan saling berkaitan  sehingga seperti  jaringan saraf pada manus ia [8]. Salah satu algoritma jaringan syaraf tiruan yang paling populer digunakan untuk klasifikasi adalah algoritma Backpropagation Neural Network  (BNN). BNN adalah  jenis algoritma pembelajaran supervised /terawasi yang memiliki banyak lapisan  [9]. BNN menggunakan output error  untuk mengubah nilai bobotnya ke arah belakang.  Algoritma BNN pada beberapa penelitian sebelumnya menunjukkan dapat bekerja dengan baik untuk kasus 
klasifikasi dan identifikasi citra . Penelitian sebe lumnya , mengenai  penglasifikasian  buku berbahasa Indonesia berdasarkan sampulnya menggunakan algoritma Backpropagation Neural Network  (BNN)  [10]. Dari hasil pengujian akurasi menggunakan satu hidden layer dan 15 neuron adalah 63,31%. Sedangkan untuk 2 hidden layer dengan kombinasi 15 dan 35 neuron memiliki akurasi 79,89%. Penelitian lain terkait klasifikasi citra kain tenun songket khas Lombok dengan menggunakan algoritma Backpropagation Neural Network  (BNN)  [11]. Penelitian ini menunjukkan bahwa peningkatan jumlah neuron dapat meningkatkan jumlah akurasi. Berdasarkan uji coba menggunakan 100 neuron, mendapatkan 100% keberhasilan yang dapat diklasifikasikan.  Selain jumlah neuron, ekstraksi ciri juga sangat berpengaruh dalam meningkatkan akurasi. Penelitian selanjutnya, mengenai klasifikasi citra anggrek dengan menerapkan algoritma Backpropagation Neural Network  (BNN) . Pada penelitian ini, hasil akurasi menunjukkan nilai sebesar 86,7%, yang didapatkan dari perbandi ngan antara jumlah citra yang dapat diklasifikasi dengan tepat dan tidak .  Pada penelitian ini juga memperlihatkan bahwa algoritma BNN akan optimal jika pemilihan ekstraksi ciri yang tepat, sehingga dapat menjadi masukan algoritma BNN.  Penelitian ini bertujuan untuk mengklasifikasikan jenis daun herbal  menggunakan algoritma Backpropagation Neural Network  (BNN) . Berdasarkan penelitian sebelumnya, menunjukkan bahwa ekstraksi ciri menjadi salah satu faktor pendukung optimalisasi klasifikasi fikasi yang dihasilkan algoritma BNN. Pada penelitian ini akan menerapkan algoritma BNN dengan ekstraksi ciri bentuk menggunakan parameter metric  dan eccentricity  yang mampu mengekstraksi ciri bentuk dan pada ekstraksi ciri dilakukan operasi morfologi untuk memperbaik i hasil segmentasi  agar hasil klasifikasi 
lebih optimal . 

2. METOD OLOGI PENELITIAN  
2.1 Tahapan Penelitian  
Untuk melakukan penelitian agar dapat tercapai  tujuan yang telah ditetapkan,  maka tahapan penelitian harus dapat 
tersusun dan terencana dengan baik. Gambar 1 berikut ini, merupakan bagan tahapan penelitian yang dijalankan .  
Gambar 1.  Tahapan Penelitian  
2.1.1  Akuisisi Citra  
Tahap pertama yaitu  proses akuisisi citra daun herbal yang digunakan sebagai dataset . Data citra daun herbal  yang 
digunakan adalah daun yang direkomendasikan oleh Kementerian Kesehatan Republik Indonesia berdasarkan â€œKeputusan Menteri Kesehatan Republik Indonesia Nomor HK.01.07/Menkes/187/2017 â€ tentang â€œFormularium Ramuan Obat Tradisional  Indonesia â€. Terdapat banyak daun yang ada pada Keputusan Menteri tersebut, tetapi yang akan digunakan untuk membangun prototipe klasifikasi jenis tanaman herbal  ini menggunakan empat jenis daun herbal yang 
mudah ditemukan . Empat jenis daun yang digunakan untuk klasifikasi diantaranya: daun jambu biji, daun sirih, daun Evaluasi
Menghitung Tingkat AkurasiKlasifikasi Citra
Algoritma Backpropagation Neural Network (BNN)Ekstraksi Ciri
Dengan Parameter Metric danEccentricity Perbaikan Hasil Segmentasi
Menggunakan 
Operasi Morfologi
Segmentasi Citra
Menggunaka Metode Thresholding
Akuisis Citra
Pengumpulan Dataset 
pepaya dan daun kunyit.  Proses akuisi citra dengan melakukan pengambilan  gambar dengan cara memotret tanaman 
herbal  dengan tingkat cahaya yang sama, kemudian dilakukan croping sesuai dengan kebutuhan. Distribusi dataset 
dilakukan dengan menggunakan persentase  0% data latih dan 40% untuk data uji  [12]. Data uji memiliki persentase 
lebih besar dengan tujuan agar model mampu melakukan pembelajaran terhadap pola lebih optimal, sedangkan data latih untuk mengukur kinjerja dari model dengan data baru.  Dataset yang sudah dikumpulkan sebanyak 200 citra, dengan 
pemabagian data uji sebanyak 200 citra dengan masing-masing kelas sebanyak 50 citra  dan data latih sebanyak 80 citra dengan masing-masng kelas sebanyak 20 citra.  
2.1.2 Segmentasi Citra  
Tahapan selanjutnya yaitu proses segmentasi citra, dimana pada tahap ini untuk memisahkan satu objek dengan objek yang lain. Objek dipisahkan berdasarkan batas wilayah yang memiliki bentuk atau susunan yang sama. Output  dari tehapan segmentasi  yaitu  berupa  citra biner, dengan  objek yang diidentifikasi mempunyai  nilai 1  dan background nya  mempunyai  nilai 0 [5]. Teknik segementasi citra yang digunakan yaitu metode thresholding . Thresholding  memiliki 
tujuan  untuk mendapatkan  nilai threshold  yang tepat, sehingga menghasilkan citra yang dapat dibedakan antara objek dari background . Proses transformasi citra ke dalam bentuk biner memudahkan untuk melakukan ekstraksi ciri [13]. 
Proses thresholding sebenarnya adalah proses kuantisasi citra dengan menggunakan rumus presamaan (1) dan (2). 
)bw ( b*x int=
-1
)a ( b256int=
-2
Dimana  w merupakan  nilai dari derajat keabuan sebelum thresholding , sedangkan  x menunjukkan  nilai derajat 
keabuan hasil  thresholding  
2.1.3 Perbaikan Hasil Segmentasi  
Agar maksimal dalam proses ekstraksi ciri maka hasil segmentasi dilakukan perbaikan dengan menggunakan operasi 
morfologi . Operasi morfologi citra merupakan sebuah  proses yang memiliki tujuan agar dapat merubah  bentuk objek pada 
citra asli. Operasi morfologi data diterapkan baik pada citra biner maupun citra grayscale. Terdapat beberapa tipe untuk melakukan perbaikan segmentasi, diantaranya dilation , erotion , closing , dan opening . Secara teori, untuk melakukan operasi morfologi pada operasi dilation , erotion , closing , dan opening  dapat dilakukan melaui persamaan (3), (4), (5) dan 
(6). 
ð´âŠ•ðµ          (3) 
ð´âŠðµ          (4) 
ð´â‹…ðµ=(ð´âŠ•ðµ)âŠðµ        (5) 
ð´âˆ˜ðµ=(ð´âŠðµ)âŠ•ðµ        (6) 
Dimana A merupakan sebuah matriks  citra awal sedangkan  dan B merupakan  structuring element , dimana  matriks 
operator yang digunakan sebagai perbaikan hasil segmentasi.  
2.1.4 Ekstraksi Ciri  
Tahapan ini adalah tahapan dimana akan diidentifikasi  ciri/karakter pembeda agar obejk dapat dibedakan dengan objek yang lain . Ciri yang telah terekstraksi selanjutnya  digunakan untuk  parameter atau pun nilai masukan pada tahapan klasifikasi. Satu diantara karakter objek yang dapat diidentifikasi adalah fitur  bentuk. Dalam mengekstraksi ciri bentuk digunakan  parameter metric  dan eccentricity . Parameter metric  didapatkan dari  nilai perbandingan antara luas dan keliling pada sebuah  objek . Sedangkan parameter eccentricity  didapatkan dari  nilai perbandingan antara jarak fokus elips minor dan fokus elips mayor pada sebuah  objek . Nilai metric  dan eccentricity  dapat dihitung melalui rumus  (7) dan ( 8). 
22
1abeâˆ’=
-7
CAMï‚´=ï°4
-8
Dimanaa merupakan  sumbu minor , sedangkan b merupakan  sumbu mayor. Untuk notasi  A menunjukkan  luas sedangkan  C menunjukkan  keliling.  
2.1.5 Klasifikasi Citra  
Backpropagation Neural Network  (BNN)  adalah algoritma suervised learning  yang memiliki  lapisan input , lapisan 
tersembunyi, dan lapisan output  kemudian melakukan perubahan  bobot yang menghubungkan pada  masing-masing   
lapisan  [14]. Pendekatan backpropagation melakukan evaluasi dari kontribusi kesalahan masing -masing neuron pada  sebuah deret data . Metode ini bertujuan untuk dapat melakukan modifikasi terhadap bobot , agar dapat terjadi pelatihan  
jaringan neural untuk bisa  memetakan output  secara tepat   [15]. Gambar 2 berikut ini merupakan contoh arsitektur 
backpropagation .   
Gambar 2. Arsitektur Backpropagation Neural Network  (BNN)  
Gambar 2, merupakan contoh arsitektur BNN yang memerlihatkan  bahwa sanya  x1, x2, x3 adalah lapisan input , dan z1, z2, z3 adalah lapisan tersembunyi, sedangkan y1 adalah lapisan output . Pada lapisan-lapisan jaringan tersebut  dihubungkan oleh bobot masing -masing  lapisan . Model BNN dapat menggunakan persamaan ( 9). 
ïƒ·ïƒ·
ïƒ¸ïƒ¶
ïƒ§ïƒ§
ïƒ¨ïƒ¦+ïƒ·
ïƒ¸ïƒ¶ïƒ§
ïƒ¨ïƒ¦+ =ïƒ¥ïƒ¥
= =p
jk ijn
ii j j jk k k w vx vfw  f y
10
10
-9
2.1.6 Evaluasi  
Tahap ini merupakan tahap dimana keefektifan dari algoritma yang dikembangkan akan diuji. Hasil klasifikasi dari algoritma yang dikembangkan akan diuji keakuratannya . Tingkat akurasi  digunakan agar dapat diketahui kedekatan hasil pengujian atau rata -rata hasil uji dengan nilai sebenarnya  [16]. Untuk menguji akurasi menggunakan persamaan (10).  
%100ï‚´=TPCPAccuracy
-10
Dimana, CP ( Corect Predictio ) merupakan  jumlah prediksi yang benar. Sedangkan TP  (Total Prediction ) merupakan  jumlah  total keseluruhan  prediksi.  

3. HASIL DAN PEMBAHASAN  
Untuk melakukan klasifikasi citra daun herbal, langka pertama diawali dengan pengumpulan dataset.  Distribusi dataset dilakukan dengan menggunakan persentase 60% data latih dan 40% untuk data uji . Dataset yang sudah dikumpulkan sebanyak 200 citra, dengan pemabagian data uji sebanyak 200 citra dengan masing -masing kelas sebanyak 50 citra dan data latih sebanyak 80 citra dengan masing -masng kelas sebanyak 20 citra.  Proses pengumpulan dataset  dengan 
melakukan pengambilan  gambar dengan cara memotret tanaman herbal  dengan tingkat cahaya yang sama, kemudian  dilakukan croping sesuai dengan kebutuhan.  Data citra daun herbal  yang digunakan adalah daun yang direkomendasikan oleh Kementerian Kesehatan Republik Indonesia berdasarkan â€œKeputusan Menteri Kesehatan Republik Indonesia Nomor 
HK.01.07/Menkes/187/2017 â€ tentang â€œFormularium Ramuan Obat Tradisional Indonesia â€, namun hanya diambil e mpat 
jenis daun yaitu : daun jambu biji, daun sirih, daun pepaya dan daun kunyit.  Tabel 1 berikut ini merupakan sampel dataset yang digunakan.  
Tabel 1.  Sampel Dataset Daun  Herbal  
Jenis Daun Herbal  Sampel Citra  
Daun Jambu Biji  
Daun Sirih  
Daun Pepaya   
Daun Kunyit  
Setelah dataset dikumpulkan , dilanjutkan dengan  melakukan  pelatihan  terhadap model yang dikembangkan . Model akan diimplementasikan dengan menggunakan aplikasi Matlab. Algoritma yang digunakan dalam klasifikasi yaitu Backpropagation Neural Network  (BNN) . Dimana  algoritma ini melakukan pelatihan terawasi yang terdiri dari beberapa  
lapisan  dan menggunakan output error  untuk mengubah nilai bobot  ke arah belakang . Pola input  dipelajar melalui tiga 
fase, yaitu:  fase maju, fase m undur dan fase modifikasi bobot . Arsitektur model yang dibangun akan dicari model dengan  nilai akurasi pelatihan yang paling maksimal. Arsitektur model yang dibangun akan menerima 120 citra pelatihan sebagai input  dengan 4 kelas sebagai output  (daun jambu biji, daun sirih, daun pepaya dan daun kunyit ). Dari hasil pelatihan jaringan BNN  arsitektur yang paling optimal adalah  100 epoch  dengan 9  itertions  dan 2 hidden layer. Gambar 6 di bawah ini merupakan arsitektur model yang paling optimal dalam proses pelatihan.   
Gambar 3.  Arsitektur Backpropagation Neural Network  (BNN)  Untuk Klasifikasi Daun Herbal  
Selanjutnya, model akan diuji dengan memasukkan data uji yang digunakan sebanya  80 citra, dimana terdapat empat kelas maka untuk masing-masing kelas sebanyak 20 citra yang digunakan untuk data uji . Dalam proses klasifikasi diawali dengan segmentasi citra. Segmentasi citra menggunakan metode  thresholding . Keluaran dari tahapan ini adalah citra biner dengan nilai intensitas pixel  yaitu  0 dan 1, dengan tujuan untuk memisahkan objek dari background . Setelah citra tersegmentasi dilakukan operasi morfologi untuk memperbaiki hasil segmentasi  agar mempermudah dalam proses ekstraksi ciri. Tabel  2 dibawah ini merupakan  sampel  hasil segmentasi citra untuk masing-masing kelas . 
Tabel 2. Sampel Hasil Segmentasi  
Citra Asli  Hasil Segmentasi  
Setelah dihasilkan citra yang telah tersegmentasi atau citra biner yang memiliki pixel perbeda antara background dan objeknya, selanjutnya akan dilakukan ekstraksi ciri. Sebelum melakukan ekstraksi ciri, pixel yang telah terindetifikasi 
sebagai objek yang akan diekstraksi akan dikemablikan kedalam citra RGB. Hal ini untuk mempermudah dalam melakukan ekstraksi ciri berdasarkan bentuknya. Ekstraksi ciri  bentuk dengan menerapkan  parameter metric  dan  eccentricity . Tabel 3 berikut hasil citra dengan objek yang terindetifikasi dikembalikan pada format RGB agar memudahkan poses perhitungan metric  dan  eccentricity . 
Tabel 2. Sampel Hasil Citra Untuk Ekstraksi Ciri  
Segmentasi Citra  Citra Untuk Ekstraksi Ciri  
Kemudian, setelah mendapatkan nilai metric  dan eccentricity  hasil ini akan menjadi inputan untuk algoritma Backpropagation Neural Network  (BNN)  melakukan klasifikasi.  Untuk dapat menguji model dengan mudah, model 
diimplementasikan pada softwre matlab dalam bentuk  GUI. Gambar 4 berikut ini, merupakan user interface sistem 
klasifikasi yang dikembangkan.   
Gambar 4. GUI Sistem Klasifikasi Daun Herbal  
Tahapan selanjutnya adalah  evaluasi, dimanan akan dilakukan  uji akurasi  dari model  yang dikembangkan. Sistem akan diuji akurasinya menggunakan persamaan ( 10) yang telah dibahas sebelumnya. Dari data uji yang ada  akan dicocokkan antara data aktual dengan hasil klasifikasi yang dihasilkan oleh model . Hasil pengujian akirasi dari klasifikasi 4 kelas jenis daun herbal  dapat dilihat pada Tabel 4.  
Tabel 4. Hasil Uji Akurasi  
Jenis Daun Herbal  Jumlah Prediksi Benar  Akurasi (%)  
Daun Jambu Biji  17 85 
Daun Sirih  18 90 
Daun Pepaya  19 95 
Daun Kunyit  17 85 
71 88,75   
Gambar 6.  Grafik Akurasi Setiap Kelas Jenis Daun Herbal  
Pada Gambar 6, menunjukkan bahwa rata-rata akurasi hasil uji akurasi  yang menggambarkan kedekatan hasil pengujian atau rata-rata hasil uji dengan nilai sebenarnya  diperoleh nilai sebesar  88,75%. Hasil tersebut kemudian dikonversi dalam kategori hasil klasifikasi dengan acuan sebagai berikut: Baik, dengan rentang nilai  antara 76% hingga  100%
Kurang Baik, memiliki nilai kurang dari 40%  [17]. Maka, akurasi dari model klasifikasi daun herbal menggunakan 
algoritma Backpropagation Neural Network  (BNN)  dengan ekstraksi ciri bentuk melalui parameter metric  dan 
eccentricity  masuk dalam kategori baik. Algoritma Backpropagation Neural Network  (BNN)  memiliki keunggulan 
mampu dalam menyelesaikan permasalahan kompleks, ini dikarenakan jaringan dengan algoritma ini melakukan 
859095
85
Daun Jambu Biji Daun Sirih Daun Pepaya Daun Kunyit 
pelatihan melalui pendekatan supervised sehingga dapat memeplajari  pola input  melalui fase maju, fase mundur dan fase modifikasi bo bot. Meskipun hasil akurasi masuk dalam kategori baik, tetapi tingkat error atau kesalahannya mencapai 11,25 %. Berdasarkan dari hasil pengujian, faktor -faktor penyebab error atau keselahan tersebut diantaranya : (1) jumlah data latih dan data uji masih tergolong  sedikit
digunakan, jika citra tidak jelas atau noise  maka ekstraksi yang dilakukan tidak optimal background  mengalami kesulitan dalam  proses klasifikasi.  

4. KESIMPULAN  
Penelitian ini telak melakukan klasifikasi  jenis daun herbal  menggunakan algoritma Backpropagation Neural Network  
(BNN) . Algoritma BNN  mampu menyeles aikan permasalahan kompleks , karena jaringan dengan algoritma ini melakukan 
pelatihan melalui pendekatan supervised sehingga dapat memeplajari pola input  melalui fase maju, fase mundur dan fase modifikasi bobot sehingga menghasilkan klasifikasi yang optimal. Untuk mendukung kinerja algoritma BNN digunakan ekstraksi ciri bentuk menggunakan parameter metric  dan eccentricity  yang mampu mengekstraksi ciri bentuk sehingga mampu mendapatkan ciri yang dapat dikenali. Agar ekstraksi ciri bentuk dapat bekerja dengan baik, setelah tahapan 
segementasi dilakukan perbaikan hasil segmentasi dengan  operasi morfologi . Hasil pengujian menunjukkan akurasi 
sebesar 88,75 %, ini menunjukkan model yang dibangun dapat mengklasifikasikan daun herbal  dengan baik . Namaun, 
perlu ada perbaikan untuk penelitian selanjutnya agar mendapatkan model yang lebih baik. Beberapa saran untuk 
penelitian selanjutnya diantaranya: menggunakan ekstraksi ciri tidak hanya bentuk tetapi juga mempertimbangkan ciri 
tekstur, menggunakan algortima deep learning agar model dapat mengenali pola lebih maksimal dan menambahkan 
jumlah kelas daun herbal serta meningkatkan jumlah data latih dan data uji.  

REFERENCES  
[1] F. Bahalwan and N. Y. Mulyawati, â€œJenis Tumbuhan Herbal dan Cara Pengolahannya (Studi Kasus di Negeri Luhutuban Kecamatan Kepulauan Manipa Kabupaten Seram Bagian Barat),â€ J. Biol. Sci. Educ. , vol. 7, no. 2, pp. 162 â€“177, 2018.  
[2] A. R. Oktaviani et al. , â€œPengetahuan dan Pemilihan Obat Tradisional Oleh Ibu -Ibu di Surabaya,â€ J. Farm. Komunitas , vol. 8, no. 1, pp. 1 â€“8, 2021.  
[3] E. S. Manzano, J. A. G. Cardenas, and F. M. Agugliaro, â€œWorldwide Research Trends on Medicinal Plants,â€ Int. J. Enviromental Res. Public Heal. , vol. 17, no. 3376, pp. 1 â€“20, 2020.  
[4] R. I. Borman, F. Rossi, Y. Jusman, A. A. A. Rahni, S. D. Putra, and A. He rdiansah, â€œIdentification of Herbal Leaf Types Based on Their Image Using First Order Feature Extraction and Multiclass SVM Algorithm,â€ in 1st International Conference on Electronic and Electrical Engineering and Intelligent System (ICE3IS) Identification , 2021, pp. 12 â€“17. 
[5] R. I. Borman, R. Napianto, N. Nugroho, D. Pasha, Y. Rahmanto, and Y. E. P. Yudoutomo, â€œImplementation of PCA and KNN Algorithms in the Classification of Indonesian Medicinal Plants,â€ in ICOMITEE 2021 , 2021, pp. 46 â€“50. 
[6] S. Ratna, â€œP engolahan Citra Digital dan Histogram Dengan Phyton dan Text Editor Phycharm,â€ Technologia , vol. 11, no. 3, pp. 181â€“186, 2020.  
[7] N. Wiliani, A. Sani, and A. T. Andyanto, â€œKlasifikasi Kerusakan Dengan Jaringan Syaraf Backpropagation pada Permukaan Solar P anel,â€ J. Ilmu Pengetah. dan Teknol. Komput. , vol. 5, no. 1, pp. 89 â€“94, 2019.  
[8] S. H. Hasanah and S. M. Permatasari, â€œBackpropagation Artificial Neural Network Classification Method in Statistics Students of Open University,â€ BAREKENG J. Ilmu Mat. dan Te rap., vol. 14, no. 2, pp. 243 â€“252, 2020.  
[9] H. Mayatopani, R. I. Borman, W. T. Atmojo, and A. Arisantoso, â€œClassification of Vehicle Types Using Backpropagation Neural Networks With Metric and Ecentricity Parameters,â€ J. Ris. Inform. , vol. 4, no. 1, pp. 6 5â€“70, 2021.  
[10] I. P. B. D. Purwanta, C. K. Adi, and N. P. N. P. Dewi, â€œBackpropagation Neural Network for Book Classification Using the Image Cover,â€ Int. J. Appl. Sci. Smart Technol. , vol. 2, no. 2, pp. 179 â€“196, 2020.  
[11] B. Imran and M. M. Efendi, â€œTh e Implementation of Extraction Feature Using GLCM and Back -Propagation Artificial Neural Network to Clasify Lombok Songket Woven Cloth,â€ J. TECHNO Nusa Mandiri , vol. 17, no. 2, pp. 131 â€“136, 2020.  
[12] N. S. B. Kusrorong, D. R. Sina, and N. D. Rumlaklak, â€œK ajian Machine Learning Dengan Komparasi Klasifikasi Prediksi Dataset Tenaga Kerja Non -Aktif,â€ J-ICON , vol. 7, no. 1, pp. 37 â€“49, 2019.  
[13] M. Wati, Haviluddin, N. Puspitasari, E. Budiman, and R. Rahim, â€œFirst -order Feature Extraction Methods for Image Text ure and Melanoma Skin Cancer Detection,â€ J. Phys. Conf. Ser. , vol. 1230, no. 1, 2019.  
[14] P. Prasetyawan, I. Ahmad, R. I. Borman, A. Ardiansyah, Y. A. Pahlevi, and D. E. Kurniawan, â€œClassification of the Period Undergraduate Study Using Back -propagation N eural Network,â€ in Proceedings of the 2018 International Conference on Applied Engineering, ICAE 2018 , 2018.  
[15] S. Setti and A. Wanto, â€œAnalysis of Backpropagation Algorithm in Predicting the Most Number of Internet Users in the World,â€ JOIN (Jurnal Onli ne Inform. , vol. 3, no. 2, pp. 110 â€“115, 2019.  
[16] R. I. Borman and B. Priyopradono, â€œImplementasi Penerjemah Bahasa Isyarat Pada Bahasa Isyarat Indonesia (BISINDO) Dengan Metode Principal Component Analysis (PCA),â€ J. Inform. J. Pengemb. IT , vol. 03, no. 1, pp. 103 â€“108, 2018.  
[17] D. Nurnaningsih, D. Alamsyah, A. Herdiansah, and A. A. J. Sinlae, â€œIdentifikasi Citra Tanaman Obat Jenis Rimpang dengan Euclidean Distance Berdasarkan Ciri Bentuk dan Tekstur,â€ Build. Informatics, Technol. Sci. , vol. 3, no. 3, pp . 171 â€“178, 2021.",klasifikasi,Backpropagation Neural Network,citra daun herbal,akurasi
Klasifikasi Penyakit Jantung Menggunakan Metode Artificial Neural Network,"Klasifikasi Penyakit Jantung Menggunakan Metode Artificial Neural Network

David Galih Pradanaa,1, Muhammad Luthfi Alghifaria,2, Muhammad Farhan Junaa,3, Shulun Dwisiwi Palagunaa,4 

I. Pendahuluan  
Jantung adalah organ vital yang berfungsi sebagai pemompa darah untuk memenuhi kebutuhan oksigen dan nutrisi ke seluruh tubuh. Apabila jantung mengalami gangguan, peredaran darah dalam tubuh dapat terganggu sehingga menjaga kesehatan jantung sangatlah penting agar terhindar dari berbagai jenis penyakit jantung. Penyakit jantung adalah sebuah kondisi yang menyebabkan jantung tidak dapat melaksanakan tugasnya dengan baik. Hal ini disebabkan matinya sebagian otot jantung yang di sebabkan karena penyempitan arteri koroner. Penyebab penyakit jantung pada umumnya terdapat dua faktor resiko yaitu faktor resiko yang tidak dapat diubah dan dapat diubah. Faktor resiko yang tidak dapat diubah antara lain usia, jenis kelamin, serta genetik  atau keturunan. Sedangkan faktor resiko yang dapat diubah adalah hipertensi, kolesterol tinggi, obesitas, diabetes, kurang aktivitas fisik, dan konsumsi alkohol berlebih. Serangan jantung adalah salah satu penyakit yang paling mematikan di dunia dan salah  satu penyakit yang banyak penderitanya adalah penyakit jantung dengan angka kematian mencapai 12,90% dari semua penyakit jantung. Kurangnya akses untuk mencari informasi tentang penyakit jantung ini menyebabkan peningkatan angka kematian setiap tahunya. Karena itu dibutuhkan sebuah sistem klasifikasi yang dapat memberikan informasi tentang penyakit jantung serta dapat melakukan pengecekan klasifikasi secara dini tentang penyakit jantung yang dialami oleh seseorang [6]. Untuk melakukan sebuah klasifikasi sistem membutuhkan metode yang tepat dalam mengelola pengetahuan yang diadopsi dari pakar sehingga diperoleh hasil yang akurat. Salah satu metode yang dapat 
digunakan dalam klasifikasi ini adalah metode ANN (Artificial Neural Network). Penelitian ini mencoba  
untuk menghitung akurasi metode ANN jika diimplementasikan pada kasus klasifikasi penyakit jantung.  

II. Metode  
A. Data Mining  
Data Mining adalah proses pengumpulan dan pengolahan data yang bertujuan untuk mengekstrak informasi penting pada data [1]â€“[10]. Proses pengumpulan dan ekstraksi informasi tersebut dapat dilakukan menggunakan perangkat lunak dengan bantuan perhitungan statistika, matematika, ataupun teknologi Artificial 
Intelligence (AI). Secara global, penyebab kematian nomor satu setiap tahunnya adalah penyakit jantung. Penyakit jantung adalah sebuah kondisi yang menyebabkan jantung tidak dapat melaksanakan tugasnya dengan baik.  Klasifikasi merupakan salah satu bidang ilmu pada datamining dimana proses klasifikasi dilakukan dengan melakukan training terlebih dahulu pada sebagai data training dilanjutkan dengan proses testing untuk data yang baru.  Artificial Neural Network (ANN) merupakan model penalaran yang didasarkan pada otak manusia. Penelitian ini mencakup pengukuran performa (akurasi, presisi, recall dan f-score) metode ANN dengan 304 data pasien penyakit jantung yang diperoleh dari pusat dataset Kaggle. Hasil dari pengukuran performa diperoleh nilai akurasi 73,77%, presisi 80,43%, 
recall 84,0 9% dan f1-score sebesar 82,22% . 

Kata Kunci : ANN, Analisis performa, Data Mining, Jantung, Validasi  

Klasifikasi Penyakit Jantung Menggunakan Metode Artificial Neural Network  
B. Artificial Neural Network (ANN)  
Algoritma Artificial Neural Network (ANN) merupakan model penalaran yang didasarkan pada otak manusia  [11]â€“[13]. ANN terdiri dari sejumlah prosesor sangat sederhana dan saling berhubungan yang disebut neuron. Neuron yang terhubung dengan pembobotan (weight) melewati sinyal dari neuron satu ke neuron yang lain. ANN merupakan model yang meniru cara kerja jaringan neural biologis. Dengan melakukan proses belajar jaringan syaraf tiruan dapat mengatur dirinya untuk menghasilkan suatu respon yang konsisten terhadap rangkaian masukkan. Jaringan saraf tiruan dirancang dan dilatih untuk memiliki kemampuan seperti manusia. Setiap neuron dapat memiliki beberapa masukan dan mempunyai satu keluaran. Jalur masukan pada suatu neuron bisa berisi data mentah atau data hasil olahan neuron sebelumnya. Sedangkan hasil keluaran suatu neutron dapat berupa hasil akhir atau berupa bahan masukkan bagi neutron berikutnya.  Jaringan neuron buatan terdiri atas kumpulan grup neuron yang tersusun dalam 3 lapisan yaitu:  
ï‚·  Lapisan Input (Input Layer) berfungsi sebagai penghubung jaringan ke dunia luar (sumber data). Neuron-neuron ini tidak melakukan apapun pada data, hanya meneruskan data ini ke lapisan berikutnya.  
ï‚· Lapisan Tersemb unyi (Hidden Layer). Suatu jaringan dapat memiliki lebih dari satu hidden layer atau bahkan tidak bisa punya sama sekali. Jika jaringan memiliki beberapa lapisan tersembunyi, maka lapisan tersembunyi paling bawah yang menerima  dari input dari input layer.  
ï‚· Lapisan Output (Output Layer). Prinsip kerja pada lapisan ini sama dengan prinsip kerja pada hidden layer dan ini juga digunakan fungsi sigmoid. Tetapi keluaran dari lapisan ini sudah dianggap dari keluaran proses . 
Hasil klasifikasi ANN dengan parameter kemudian akan diuji validitasnya menggunakan Confusion Matrix berupa Precision, Recall, dan Accuracy [14]â€“[23].  
1) Akurasi  
Akurasi didefinisikan sebagai tingkat kedekatan antara nilai prediksi dengan nilai actual.  
2) Presisi  
Presisi didefinisikan se bagai rasio item relevan yang dipilih terhadap semua item yang terpilih. Presisi dapat diartikan sebagai kecocokan antara permintaan informasi dengan jawaban terhadap permintaan tersebut.  
3) Recall  
Recall didefinisikan sebagai rasio dari item relevan yang d ipilih terhadap total jumlah item relevan yang tersedia . 
4) F-Measure  
Measure adalah harmonic mean antara nilai presisi dan recall, F-measure juga kadang disebut dengan nama F1-Score.  
               ))              )) 
                 ) 
                ) 
                             )                ) 
Keterangan Variabel :  
TP : True Positive  
TN : True Negative  
FP : False Positive  
FN : False Negative  
Receiver Operating Characteristic (ROC) digunakan untuk mengetahui tingkat sensitivity dan specificity dari klasifikasi. Sensitivity adalah proporsi jumlah positif benar yang diidentifikasikan dengan benar. Sedangkan specificity adalah proporsi negatif benar yang diidentifikasikan dengan benar. Perhitungan sensitivity dan specificity dapat dihitung dengan menggunakan rumus di bawah ini:  
Sensitivity (%) =                            
                                          
Specificity (%0 =                            
David Galih Pradan a, et. al.  
C. Rancangan Model  
Rancangan atau model pada penelitian ini seiring dengan alur proses metode ANN dimana dimulai dari 
mengumpulkan dataset, visualisasi dataset, split atau membagi dataset dataset, implementasi metode ANN dan 
menghitung performa metode ANN pada dataset tersebut. Flowchart model ditunjukkan pada Gambar  1 
berikut.  
 
Gambar 1.  Flowchart Model  
D. Sample dan Data  
Data yang diolah pada penelitian ini memiliki beberapa atribut seperti CP (jenis nyeri dada), trestbps (tekanan darah istirahat (dalam mmHg saat masuk ke rumah sakit)), chol (kolesterol serum dalam mg/dl), fbs (gula darah pu asa > 120 mg/dl) (1 = benar(detak jantung maksimum tercapai), exang (angina akibat olahraga (1 = ya yang diinduksi oleh olahraga relatif terhadap istiraha t). Data tersebut diperoleh dari website kaggle yang dipublish pada tahun 2018 dan dikelola oleh Bi Developer at Vision B.I.  
E. Teknik Analisis  
Teknik analisis dilakukan dengan cara menghitung performa metode ANN dimana performa yang diukur yaitu akurasi, recall, presisi dan f-measure menggunakan scikit -learn library sebagai machine learning tools. Tahap awal yang dilakukan adalah mengumpulkan data,data yang kami  gunakan pada penelitian ini menggunakan data dari website kaggle. Selanjutnya adalah melakukan split data dimana 10% digunakan untuk data testing dan 90% digunakan sebagai data training. Tahap selanjutnya adalah menerapkan algoritma ANN menggunakan data testing dan data training. Pada tahap terakhir dilakukan perhitungan performa dari seluruh data test ing. Tabel dibawah menunjukkan beberapa perintah yang akan dijalankan dengan library scikit-learn library.  
Tabel 1.   
Load  dataset = pd.read_csv('drive/MyDrive/DATASET/heart.csv')  
Split  x = dataset.iloc[:, 2:].values  
y = dataset.iloc[:, 1].values  
x_train,x_test,y_train,y_test=train_test_split(x,y,test_siz e = 0.2,  
random_state = 0)  
Test y_pred = classifier.predict(x_test)  
y_pred = (y_pred > 0.5)  
Result : plt.plot (range(150),history.history['accuracy'])  
plt.title('History Accuracy')  
plt.ylabel('accuracy')  
plt.xlabel('epoch')  
plt.show()  
Train  classifier = Sequential(  
classifier.add(Dense(units=16,activation='relu')) 
classifier.add(Dense(units=16,activation='relu')) 
classifier.add(Dense(units=1,activation='sigmoid'))  
Resul
tcm = confusion_matrix(y_test, y_pred)  
sns.heatmap(cm, annot=True)  
plt.savefig('a.png')  
precision_score(y_test, y_pred)  
recall_score(y_test, y_pred)  
f1_score(y_test, y_pred)  
 
III. Hasil dan Pembahasan  
Kesimpulan pengujian dilakukan setelah proses metode AN N terdapat 45 data benar 61 data yang ditampilkan dengan heatmap  seperti pada Gambar 2 . Hasil uji performa dan val idasi ditampilkan pada Tabel 2 dan Tabel 3 .  
Gambar 2.  Heatmap  
Table uji Validasi  Tabel 2.  
Accuracy  73,77%  
Recall  84,09%  
Precision  80,43%  
F1-Score  82,22%  
ROC  Tabel 3.   
Sensitivity(%)  80,43%  
Specificity(%)  53,33%  
History accuracy ditunjukkn pada Gambar 3 .  
Gambar 3.  History Accuracy  
History loss ditunjukkan pada Gambar 4 .  
Gambar 4.  History loss  

IV. Kesimpulan  
Berdasarkan hasil penelitian ini maka penulis dapat menarik beberapa kesimpulan, nilai akurasi paling yaitu sebesar 73,77% dan nilai presisi 80,43% recall 84,09% dan F-measure 82,22%. Pada penelitian selanjutnya dapat mengimplementasikan penelitian ke tahap selanjutnya berupa decision support system serta dapat menghitung usability aplikasi . 

Daftar Pustaka  
[1] M. M. Baharuddin, T. Hasanuddin, and H. Azis, â€œAnalisis Performa Metode K -Nearest Neighbor untuk Identifikasi Jenis Kaca,â€ Ilk. J. Ilm. , vol. 11, no. 28, pp. 269 â€“274, 2019.  
[2] Rizky Ade Putranto, Triastiti Wuryandari, and Sudarno, â€œPerbandingan Analisis Klasifikasi Antara Decision Tree Dan Support Vector Machine Multiclass Untuk Penentuan Jurusan Pada Siswa Sma,â€ J. Ga ussian , vol. 4, no. 4, pp. 1007 â€“1016, 2015.  
[3] W. Safira Azis and  dan Dedy Atmajaya, â€œPengelompokan Minat Baca Mahasiswa Menggunakan Metode K-Means,â€ Ilk. J. Ilm. , vol. 8, no. 2, pp. 89 â€“94, 2016.  
[4] S. Chugh, K. Arivu Selvan, and R. K. Nadesh, â€œPrediction of heart disease using apache spark analysing decision trees and gradient boosting algorithm, â€ IOP Conf. Ser. Mater. Sci. Eng. , vol. 263, no. 4, pp. 0 â€“10, 2017, doi: 10.1088/1757 -899X/263/4/042078.  
[5] H. Zhang, â€œThe optimality of Naive Bayes,â€ Proc. Seventeenth Int. Flor ida Artif. Intell. Res. Soc. Conf. FLAIRS 2004 , vol. 2, pp. 562 â€“567, 2004.  60 
[6] Y. Salim, Y. Puspitasari, H. Azis, and R. Anas, â€œThe use of augmented reality to educate preschoolers on preventing den tal malocclusion,â€ Bull. Soc. Informatics Theory Appl. , vol. 3, no. 2, pp. 56 â€“60, 2019.  
[7] L. Nurhayati and H. Azis, â€œPerancangan Sistem Pendukung Keputusan Untuk Proses  Kenaikan Jabatan Struktural Pada Biro Kepegawaian,â€ Semin. Nas. Teknol. Inf. dan Multimed. , pp. 6 â€“7, 2016.  
[8] H. Azis and R. Wardoyo, â€œPenerapan Network Steganography Menggunakan Metode Modifikasi LACK Dan Layanan Message Authentication Code Pada Voip Network Steganography System with modification of LACK and Message Authentication Code on VoIP,â€ Semin. Nas. Komun. dan Inform. , pp. 13 â€“19, 2015.  
[9] H. Azis, F. T. Admojo, and E. Susanti, â€œAnalisis Perbandingan Performa Metode Klasifikasi pada Dataset Multiclass Citra Busur Panah,â€ Techno.Com , vol. 19, no. 3, 2020.  
[10] F. Muharram, H. Azis, and A. R. Manga, â€œAnalisis Algoritma pada Proses Enkripsi dan Dekripsi File Menggunakan Advanced Encryption Standard (AES),â€ Pros. Semin. Nas. Ilmu Komput. dan Teknol. Inf., vol. 3, no. 2, pp. 112 â€“115, 2018.  
[11] D. D. Novita, A. B. Sesunan, M. Telaumbanua, S. Triyono, and T. W. Saputra, â€œIdentifikasi Jenis Kopi Menggunakan Sensor E -Nose Dengan Metode Pembelajaran Jaringan Syaraf Tiruan Backpropagation,â€ J. Ilm. Rekayasa Pertan. dan Biosist. , vol. 9, no. 2, pp. 205 â€“217, 2021, doi: 10.29303/jrpb.v9i2.241.  
[12] Herman et al. , â€œComparison of Artificial Neural Network and Gaussian NaÃ¯ve Bayes in Recognit ion of Hand -Writing Number,â€ Proc. - 2nd East Indones. Conf. Comput. Inf. Technol. Internet Things Ind. EIConCIT 2018 , no. 1, pp. 276 â€“279, 2018, doi: 10.1109/EIConCIT.2018.8878651 . 
[13] I. Fauzan, â€œArtificial Intelligence (AI) Pada Proses Pengawasan dan Pengendalian Kepegawaian - Sebuah Eksplorasi Konsep Setelah Masa Pandemi Berakhir,â€ J. Civ. Serv. , vol. 14, no. 1, pp. 31 â€“42, 2020.  
[14] F. Tangguh and Y. Islami, â€œAnalisis performa algoritma Stochastic Gradient Descent ( SGD ) dalam mengklasifikasi tahu berformalin,â€ Indones. J. Data Sci. , vol. 3, no. 1, pp. 1 â€“8, 2022.  
[15] H. Nursan and Muslim, â€œPenerapan Metode Digital Watermarking dan Privilege pada Dokumen Skripsi,â€ Indones. J. Data Sci. , vol. 1, no. 1, pp. 19 â€“22, 2020.  
[16] N. Litha and T. Hasanuddin, â€œAnalisis Perf orma Metode Moving Average Model untuk Prediksi Jumlah Penderita Covid -19,â€ Indones. J. Data Sci. , vol. 1, no. 3, pp. 87 â€“95, 2020.  
[17] Sugiarti and Mirnawati, â€œImplementasi Algoritma Goverment Standa rd ( GOST ) dalam Pengamanan File Dokumen,â€ Indones. J. Data Sci. , vol. 1, no. 2, pp. 52 â€“56, 2020.  
[18] Hasran, â€œKlasifikasi Penyakit Jantung Menggunakan Metode K -Nearest Neighbor,â€ Indones. J. Data Sci., vol. 1, no. 1, pp. 1 â€“4, 2020.  
[19] K. Ilunga, T. Lumbala, and K. Mulenda, â€œApplication of Big data to configuration management in a PLM context,â€ Indones. J. Data Sci. , vol. 3, no. 1, pp. 9 â€“16, 2022.  
[20] A. Maulida, â€œPenerapan Metode Klasifikasi K -Nearest Neigbor pada Dataset Penderita Penyakit Diabetes,â€ Indones. J. Data Sci. , vol. 1, no. 2, pp. 29 â€“33, 2020.  
[21] A. Prasetya Wibawa, W. Lestar, A. Bella Putra Utama, I. Tri Saputra, and Z. Nabila Izdihar, 
â€œMultilayer Perceptron untuk Prediksi Sessions pada Sebuah Website Journal Elektronik,â€ Indones. J. Data S ci., vol. 1, no. 3, pp. 57 â€“67, 2020, doi: 10.33096/ijodas.v1i3.15.  
[22] I. P. Putri, â€œAnalisis Performa Metode K - Nearest Neighbor (KNN) dan Crossvalidation pada Data Penyakit Cardiovascular,â€ Indones . J. Data Sci. , vol. 2, no. 1, pp. 21 â€“28, 2021, doi: 10.33096/ijodas.v2i1.25.  
[23] D. Cahyanti, A. Rahmayani, and S. Ainy, â€œAnalisis performa metode Knn pada Dataset pasien pengidap Kanker Payudara,â€ Indones. J. Data Sci. , vol. 1, no. 2, pp. 39 â€“43, 2020.",klasifikasi,"Artificial Neural Network, ANN","penyakit jantung, kaggle","akurasi, accuracy, recall, precision, F1-Score"
Metode Seleksi Fitur Untuk Klasifikasi Sentimen Menggunakan Algoritma  Naive Bayes : Sebuah Literature Review,"Metode Seleksi Fitur Untuk Klasifikasi Sentimen Menggunakan Algoritma  Naive Bayes : Sebuah Literature Review

Fitria Septianingrum*, Agung Susilo Yuda Irawan 

Abstrak
Pada zaman revolusi industri 4.0 seperti saat ini, di mana internet merupakan suatu kebutuhan bagi masyarakat dalam 
menjalani kehidupan sehari-hari. Intensitas dari penggunaan internet yang tinggi di lingkungan masyarakat, maka menyebab kan persebaran suatu informasi didalamnya pun dapat tersebar secara luas dan cepat. Adanya persebaran informasi yang cepat di internet maka  sejalan pula dengan pertumbuhan data digital yang semakin besar, sehingga opini-opini publik 
yang terdapat  didalamnya menjadi hal yang penting. Karena, dari data digital tersebut dapat diolah dengan analisis sentimen guna memperoleh suatu informasi yang bermanfaat mengenai isu yang sedang berkembang di lingkungan masyarakat ataupun untuk mengetahui opini publik terhadap suatu produk perusahaan.  Banyaknya penelitian terkait analisis sentimen yang menerapkan algoritma Naive Bayes  guna menyelesaikan masalahnya, maka peneliti tertarik untuk melakukan  penelitian mengenai penggunaan seleksi fitur terhadap algoritma tersebut. Maka dari  itu, dilakukannya penelitian ini guna mengetahui seleksi fitur apa yang paling optimal ketika di kombinasikan dengan algoritma Naive Bayes  dengan menggunakan metode  penelitian  Systematic Literature Review  (SLR). Hasil penelitian ini disimpulkan bahwa metode seleksi fitur yang paling optimal ketika dikombinasikan dengan  algoritma Naive Bayes adalah metode Particle Swarm Optimization  (PSO) dengan  nilai rata-rata akurasi 89.08%.  

Kata Kunci : Analisis Sentimen 

Abstract
In the era of the industrial revolution 4.0 as it is today, where the internet is a necessity for people to live their daily lives. The high intensity of internet use in the community, it causes the distribution of information in it to spread widely and quickly. The rapid distribution of information on the internet is also in line with the growing growth of digital data, so that the public opinions contained therein become important things. Because, from this digital data, it can be processed with sentiment analysis in order to obtain useful information about issues that are developing in the community or to find out public opinion on a company's product. The number of studies related to sentiment analysis that applies the Naive Bayes algorithm to solve the problem, so researchers are interested in conducting research on the use of feature selection for the algorithm. Therefore, this research was conducted to determine what feature selection is the most optimal when combined with the Naive Bayes algorithm using the Systematic Literature Review (SLR) research method. The results of this study  concluded that the most optimal feature selection method when combined with the Naive Bayes algorithm is the Particle Swarm Optimization (PSO) method with an average accuracy value of 89.08%.  

Keywords : Sentiment Analysis 

Review  
1. PENDAHULUAN  
Pada  zaman serba internet  seperti  saat ini,  di mana perkembangan teknologi berkembang semakin pesat dan cepat ke arah yang serba digital [1], penggunaan internet khususnya sosial media tentunya tidak  lagi menjadi hal yang awam bagi masyarakat Indonesia. Hal ini dapat dibuktikan  dengan hasil survei yang dilaksanakan oleh Hootsuite di tahun 2021 yang menunjukkan bahwa pengguna aktif platform  media sosial di Indonesia saat ini mencapai angka 170 juta pengguna. Berbagai macam aktivitas yang dilakukan masyarakat di sosial media, tentu dapat menghasilkan sebuah data digital setiap harinya yang berasal dari interaksi sosial yang dibangun melalui media sosial itu sendiri . Opini merupakan pendapat pribadi dari seseorang mengenai suatu topik atau hal yang ada [2] dan opini publik saat ini menjadi suatu hal yang penting bagi perkembangan suatu perusahaan ataupun bagi 
kebijakan-kebijakan yang akan diambil oleh suatu pemerintahan. Data-data digital tersebut dapat berupa sebuah opini publik mengenai suatu isu yang sedang trending  di kalangan masyarakat, ataupun penilaian , komentar,  dan 
opini seorang konsumen terhadap suatu produk atau jasa yang mereka gunakan dari sebuah perusahaan  produk dan jasa tersebut . Salah satu platform  penghasil data digital terbanyak yaitu Media Sosial [3]. Maka dari itu, opini publik saat ini merupakan hal yang penting karena dapat mempengaruhi proses branding  dari suatu perusahaan ataupun penilaian dari masyarakat terhadap kebijakan pemerintahan  dan tokoh publik di Indonesia.  Setelah mengetahui pentingnya opini publik saat ini, banyak peneliti -peneliti yang mulai melakukan penelitian di bidang text mining khususnya analisis sentimen untuk melakukan klasifikasi sentimen ke dalam kelas positif, negatif, ataupun netral. Salah satu  algoritma yang dapat  digunakan dalam mengklasifikasi kalimat sentimen yaitu algoritma Naive Bayes  [4]. Karena  algoritma ini didasarkan pada asumsi penyederhanaan bahwa nilai atribut secara kondisional saling  bebas apabila diberi nilai output dan keuntungan dari penggunaan algoritma Naive Bayes  yaitu metode ini hanya membutuhkan training  data yang kecil dalam menentukan estimasi parameter dalam proses pengklasifikasian [5] . Sedangkan kekurangan dari algoritma Naive Bayes  yaitu sangat sensitif dalam proses pemilihan fitur, sehingga untuk mengatasinya yaitu dengan cara dikombinasikan dengan metode seleksi fitur [6]. Penggunaan seleksi fitur sendiri dapat berpengaruh terhadap tingkat akurasi algoritma karena dengan adanya  yang memiliki informasi penting didalamnya. Penelitian ini akan melakukan Literature Review  terhadap metode seleksi fitur yang dikombinasikan dengan algoritma Naive Bayes  untuk mengetahui seleksi fitur apa yang paling 
optimal ketika dikombinasikan dengan algoritma tersebut dalam melakukan analisis sentimen publik melalui media sosial.  Pengumpulan data dilakukan dengan cara melakukan studi literatur terhadap referensi yang dikumpulkan dan paper yang digunakan pada penelitian ini merupakan paper dengan rentang waktu tahun publikasi mulai dari tahun 2016 â€“ 2020. Sedangkan jumlah artikel penelitian yang digunakan dijadikan perbandingan akurasi nya yaitu sebanyak 25 artikel. Adapun metode seleksi fitur yang akan dijadikan bahan perbandingan yaitu sel eksi fitur Information Gain, Particle Swarm Optimization  (PSO), Chi Square , dan N-Gram . Tujuan penelitian ini yaitu untuk melakukan analisis perbandingan seleksi fitur yang dikombinasikan dengan algoritma Naive Bayes  untuk melakukan analisis sentimen.  

2. METODOLOGI PENELITIAN  
Penelitian ini merupakan suatu Systematic Literature Review  (SLR). Sumber data yang digunakan berasal dari beberapa artikel penelitian yang telah diakses  dari bulan Februari -April  2021  melalui beberapa platform seperti Google Scholar, Research Gate,  IEEE  Xplore, dan IOP Science  berupa penelitian-penelitian sebelumnya yang telah dilakukan mengenai analisis sentimen dengan menggunakan seleksi fitur dan algoritma Naive Bayes  berupa artikel ilmiah, skripsi, ataupun proceeding . Adapun alur penelitian yang digunakan pada penelitian SLR  ini dapat dilihat pada Gambar 1 di bawah ini.  
PERENCANAAN
Identifikasi Masalah
Pengembangan Protokol 
Review
PELAKSANAAN
Identifikasi Literatur yang Relevan
Seleksi Literatur yang Digunakan
Klasifikasi Literatur 
Review  dan Analisis Literatur
Visualisasi Hasil Analisis
PELAPORAN
Penulisan paper  SLR
Pemilihan Jurnal yang Tepat
Gambar 1. Alur Penelitian  
2.1 Tahap Perencanaan   
Pada tahap pertama yaitu tahap perencanaan akan dilakukan proses identifikasi masalah mengenai penelitian dengan topik analisis sentimen menggunakan Algoritma Naive Bayes  dan juga pencarian artikel terkait topik tersebut. Adapun kata kunci yang digunakan dalam melakukan pencarian artikel yaitu :  
a. Analisis Sentimen dengan Algoritma Naive Bayes dan Seleksi Fitur  
b. Optimalisasi Algoritma Naive Bayes dengan Penggunaan Seleksi Fitur  
c. Implementasi Algoritma Naive Bayes pada Analisis Sentimen dari Media Sosial  
d. Pengaruh Penggunaan Seleksi Fitur Terhadap Kinerja Algoritma Naive Bayes  
2.2 Tahap Pelaksanaan   
Selanjutnya pada tahap pelaksanaan terdiri dari 5 tahap, yaitu diantaranya :  
a. Mengidentifikasi literur yang relevan dengan topik penelitian ini yaitu mengenai analisis sentimen dengan 
algoritma naive bayes .  
b. Melakukan seleksi dari literatur -literatur yang telah didapatkan berdasarkan relevansi topik dan juga tahun 
publikasi paper tersebut.  
c. Kemudian literatur-literatur yang telah diseleksi tersebut akan di klasifi kasikan berdasarkan topik dan tahun 
publikasi penelitian yang telah ditentukan.  
d. Melakukan proses review  artikel dan juga melakukan analisis dari literatur-literatur yang ada.  
e. Membuat visualisasi dari hasil analisis tersebut.  
2.3 Tahap Pelaporan  
Tahap terak hir yaitu pelaporan di mana pada tahap ini akan dilakukan penyusunan paper SLR dari proses literature 
review yang telah dilakukan dan juga memilih jurnal yang tepat untuk mempublikasikan paper yang telah dibuat 
tersebut. 
3.1 Hasil Pencarian dan Klasifikasi Artikel  
Berdasarkan  hasil pencarian artikel melalui platform Google Scholar sesuai dengan kata kunci yang digunakan, diperoleh data berupa artikel ilmiah, proceeding, dan skripsi dengan jumlah 25 penelitian . Artikel ilmiah tersebut dipublikasikan pada tahun 2016 sampai tahun 2020 dan memiliki topik penelitian mengenai analisis sentimen dengan menggunakan algoritma naive bayes dan seleksi fitur. Berdasarkan  25 artikel penelitian yang telah terkumpul  dan diakses mulai bulan Februari hingga April tahun 2021 , kemudian dilakukan proses klasifikasi berdasarkan seleksi fitur yang digunakan pada penelitian tersebut, dan juga tahun publikasi dari artikel-artikel tersebut yang dapat dilihat pada Tabel 1 dan Tabel 2 di bawah ini.  
Tabel 1. Klasifikasi Artikel 
Berdasarkan Seleksi Fitur yang Digunakan  
No Seleksi Fitur yang Digunakan  Jumlah  
1 Information Gain (IG) 10 
2 Particle Swarm Optimization (PSO)  8 
3 Chi Square  4 
4 N-Gram  3 
Tabel 2. Klasifikasi Artikel Berdasarkan Tahun Publikasi  
No Tahun Publikasi Penelitian  Jumlah  
1 2016  1 
2 2017  6 
3 2018  4 
4 2019  6 
5 2020  8 
Dari hasil klasifikasi di atas, maka dapat dibuat visualisasi datanya yang tertera pada Gambar 1 dan Gambar 
2 di bawah ini.  
Gambar 2. Diagram Klasifikasi Artikel Penelitian Berdasarkan Seleksi Fitur   
Gambar 3. Diagram Klasifikasi Artikel Penelitian Berdasarkan Tahun Publikasi  
40%
32%16%12%Klasifikasi Artikel Penelitian Berdasarkan 
Seleksi Fitur
Information Gain Particle Swarm Optimization
Chi Square N-Gram
4%
24%
16%
24%32%Klasifikasi Artikel Penelitian Berdasarkan 
Tahun Publikasi
2016 2017 2018 2019 2020 
Pada tahap ini akan dilakukan review  dan analisis perbandingan tingkat akurasi algoritma Naive Bayes  berdasarkan seleksi fitur yang digunakan pada penelitian analisis sentimen yang dapat dilihat pada Tabel 3 berikut.  
Tabel 3.  Perbandingan Tingkat Akurasi Algoritma Naive Bayes  Berdasarkan Metode Seleksi Fitur  
No Penulis (Tahun)  Judul  Jumlah 
Dataset  Seleksi Fitur  Tingkat Akurasi  
1 (Putri, Mubarok, & Adiwijaya, 2017) [7] Klasifikasi Sentimen Ulasan Buku Berbahasa Inggris Menggunakan  Information Gain  dan Naive Bayes  1000  Information Gain  88.28%  
2 (Negara, Muhardi, & Putri, 2020) [8] Analisis Sentimen Maskapai Penerbangan Menggunakan Metode Naive Bayes  Dan Seleksi Fitur Information Gain 1000  Information Gain  86.5%  
3 (Attabi, Muflikhah, & Fauzi, 2018) [9] Penerapan Analisis Sentimen untuk Menilai Suatu Produk pada Twitter  Berbahasa Indonesia dengan Metode Naive Bayes Classifier  dan Information Gain   200 Information Gain  74% 
4 (Utama, Rosiyadi, Aridarma, & Prakoso, 2019) [10] Sentimen Analisis Kebijakan Ganjil Genap Di Tol Bekasi Menggunakan Algoritma Naive Bayes  Dengan Optimalisasi Information Gain  440 Information Gain  79.55%  
5 (Syakuro, 2017) [11]  Analisis Sentimen Masyarakat Terhadap E-Commerce  Pada Media Sosial Menggunakan Metode Naive Bayes Classifier  Dengan Seleksi Fitur Information Gain  3000  Information Gain  88.8%  
6 (Zaman, 2020) [12]  Klasifikasi Opini Terhadap Kebijakan Publik Merdeka Belajar Pada Jejaring Sosial Twitter  Menggunakan Metode Naive Bayes  Dengan Seleksi Fitur Information Gain  273 Information Gain  81.48%  
7 (Khalida & Setiawati, 2020) [13]  Analisis Sentimen Sistem E-Tilang Menggunakan Algoritma Naive Bayes  Dengan Optimalisasi Information Gain   276 Information Gain  41.82%  
8 (Widya Sihwi, Prasetya Jati, & Anggrainingsih, 2018) [14] Twitter Sentiment Analysis of Movie Reviews Using Information Gain and Naive Bayes Classifier   8231 Information Gain  82.19%  
9 (Syahriani, Yana, & Santoso, 2020) [15] Sentiment Analysis of Facebook Comments on Indonesian Presidential Candidates Usi ng the Naive Bayes Method  300 Information Gain  83.67%  
10 (Andilala, 2016) [16]  Movie Review Sentimen Analisis Dengan Metode NaÃ¯ve Bayes Base on Feature Selection   2000  Information Gain  95.70%  
11 (Taufik, 2017) [17] Optimasi Particle Swarm Optimization  
Sebagai Seleksi Fitur Pada Analisis Sentimen Review  Hotel Berbahasa Indonesia Menggunakan Algoritma Naive Bayes  200 Particle Swarm Optimization  96.92%   
12 (Nugroho, Istiadi, & Marisa, 2020) [18] Optimasi Naive Bayes Classifier  untuk Klasifikasi Teks pada e-government  Menggunakan Particle Swarm Optimization 200 Particle Swarm 
Optimization  87.44%  
13 (Hayuningtyas & Sari, 2019) [19] Analisis Sentimen Opini Publik Bahasa Indonesia Terhadap Wisata TMII Menggunakan Naive Bayes  dan PSO 100 Particle Swarm Optimization  94.02%  
14 (Cahyono, 2017) [20] Analisis Sen timen Pada Sosial Media Twitter Menggunakan Naive Bayes Classifier  Dengan Feature Selection Particle Swarm Optimization  Dan Term Frequency  3300  Particle Swarm Optimization  97.48%  
15 (Solecha, 2019) [21]  Analisa Sentimen Dengan Algoritma 
Naive Bayes Classifier  Berbasis Particle Swarm Optimization  Untuk Review  Restoran 200 Particle Swarm Optimization  88.50%  
16 (Betesda, 2020) [22] Peningkatan Optimasi Sentimen Dalam 
Pelaksanaan Proses Pemilihan Presiden Berdasarkan Opini Publik Dengan Menggunakan Algoritma Naive Bayes dan Particle Swarm Optimization 260 Particle Swarm Optimization  71.15%  
17 (Aulianita & Rifai, 2018) [23] Optimasi Particle Swarm Optimization  Pada Naive Bayes  Untuk Sentiment Analysis Furniture 200 Particle Swarm Optimization  93.50%  
18 (Saputra, 2019) [24] Analisis Sentimen E-Wallet  Pada Google Play  Menggunakan Algoritma Naive Bayes  Berbasis Particle Swarm Optimization 300 Particle  Swarm Optimization  83.60%  
19 (Hidayat, 2017) [25] Kombinasi Seleksi Fitur Chi Square Dengan Algoritma Naive Bayes  Untuk Analisis Sentimen Komentar Facebook 1000  Chi Square  91% 
20 (Kisworini, 2020) [26] Peningkatan Performa Naive Bayes Dengan Seleksi Atribut Menggunakan Chi Square Untuk Klasifikasi Loyalitas Pelanggan GRAB 331 Chi Square  99.51%  
21 (Amrullah, Sofyan Anas, & Hidayat, 2020) [27] Analisis Sentimen Movie Review  Menggunakan Naive Bayes Classifier  Dengan Seleksi Fitur Chi Square 1400  Chi Square  64.40%  
22 (Nisa, Darwiyanto, & Asror, 2019) [28] Analisis Sentimen Menggunakan Naive Bayes Classifier  dengan Chi-Square Feature Selection  Terhadap Penyedia Layanan Telekomunikasi 1200  Chi Square  85.5%  
23 (Agung Nugroho, 2018) [29] Analisis Sentimen Pada Media Sosial Twitter  Menggunakan Naive Bayes Classifier  Dengan  Ekstrasi Fitur N-Gram 300 N-Gram  92% 
24 (Indhiarta, 2017) [30] Penggunaan N-Gram  Pada Analisa 
Sentimen Pemilihan Kepala Daerah 600 N-Gram  82.3% Bayes   
25 (Irvantoro, Saifudin, & Umilasari, 2019) [31] Feature Selection  Menggunakan Chi Squared dan N-Gram Dengan Algoritma Naive Bayes Classifier Untuk Analisis Sentimen Review  Produk Elektronik  600 N-Gram 89% 
3.3 Visualisasi Hasil Analisis  
Berdasarkan hasil analisis perbandingan di atas maka dapat dibuat visualisasi dari rata -rata tingkat akurasi algoritma Naive Bayes yang dikombinasikan dengan 4 jenis metode seleksi fitur guna mengetahui metode seleksi fitur terbaik apabila dikombinasikan d engan algoritma Naive Bayes . Grafik rata-rata akurasi tersebut dapat dilihat pada gambar 4 di bawah ini.   
Gambar 4. Rata-Rata Akurasi dari Penggunaan Metode Seleksi Fitur Pada Algoritma Naive Bayes  

4. KESIMPULAN  
Berdasarkan literature  review  yang telah dilakukan dari 25 artikel ilmiah dapat diketahui bahwa seleksi fitur Particle Swarm Optimization  (PSO) merupakan metode seleksi fitur yang cocok dan menghasilkan hasil terbaik  apabila dikombinasikan dengan algoritma klasifikasi Naive Bayes. Tingkat akurasi dapat dipengaruhi oleh jumlah dataset yang digunakan dan juga metode seleksi fitur yang digunakan. Berdasarkan  grafik perbandingan rata-rata nilai akurasi tersebut dapat diketahui bahwa kombinasi antara algoritma Naive Bayes  dengan sele ksi fitur Particle Swarm Optimization  (PSO) memiliki nilai paling tinggi yaitu 89.08%. Sedangkan rata-rata akurasi dari metode seleksi fitur N-Gram  berada dibawah PSO dengan tingkat akurasi 87.77%, kemudian di bawah N-Gram  terdapat metode seleksi fitur Chi Square  dengan tingkat akurasi 85.10% dan rata -rata akurasi dari seleksi fitur Information Gain yaitu 80.20%.  

UCAPAN TERIMAKASIH  
Terima kasih disampaikan kepada Bapak Agung Susilo Yuda Irawan selaku dosen Fakultas Ilmu Komputer Universitas Singaperbangsa Karawang yang telah mendukung terlaksananya penelitian ini dan juga teman-teman yang telah memberikan saran dan masukan serta membantu penulis dalam penyusunan artikel ini.  

REFERENCES    
[1] R. Mahendrajaya, G. A. Buntoro, and M. B. Setyawan, â€œAnalisis Sentimen Pengguna Gopay Menggunakan Metode Lexicon Based Dan Support Vector Machine,â€ Komputek , vol. 3, no. 2, p. 52, 2019, doi: 10.24269/jkt.v3i 2.270.  
[2] H. Himawan, W. Kaswidjanti, A. Sentimen, M. Sosial, and L. Based, â€œMetode Lexicon Based Dan Support Vector Machine Untuk Menganalisis Sentimen Pada Media Sosial Sebagai Rekomendasi Oleh-Oleh Favorit,â€ vol. 2018, no. November, pp. 235 â€“244, 2018.  
[3] A. K. Fauziyyah, â€œAnalisis Sentimen Pandemi Covid19 Pada Streaming Twitter Dengan Text Mining Python,â€ J. Ilm. 80.20 89.08 85.10 87.77 74.00 76.00 78.00 80.00 82.00 84.00 86.00 88.00 90.00 Rata-Rata Akurasi Rata-Rata Akurasi Algoritma Naive Bayes Dengan Seleksi Fitur
Information Gain Particle Swarm Optimization Chi Square N-Gram
[4] F. Ratnawati, â€œImplementasi Algoritma Naive Bayes Terhadap Analisis Sentimen Opini Film Pada Twitter,â€ INOVTEK Polbeng - Seri Inform. , vol. 3, no. 1, p. 50, 2018, doi: 10.35314/isi.v3i1.335.  
[5] S. Rahayu, J. J. Purnama, H. M. Nawawi, and F. S. Nugraha, â€œAlgoritma NaÃ¯ve Bayes Classifier Untuk Memprediksi Gejala Autism Spectrum Disorders Pada Anak-Anak,â€ Pros. Semin. Nas. Rekayasa dan Teknol. (TAU SNAR -TEK) , vol. ISSN:, no. November, 2019.  
[6] D. A. Muthia, â€œSentiment Analysis on Closure of Illegal Movie Streaming Sites Using NaÃ¯ve Bayes Algorithm,â€ J. Pilar Nusa Mandiri , vol.  16, no. 1, pp. 123 â€“128, 2020, doi: 10.33480/pilar.v16i1.1306.  
[7] L. R. Putri, M. S. Mubarok, and Adiwijaya, â€œKlasifikasi Sentimen Ulasan Buku Berbahasa Inggris Menggunakan Information Gain Dan Naive Bayes,â€ e-Proceeding Eng. , vol. 4, 2017 . 
[8] A. B. P. Negara, H. Muhardi, and I. M. Putri, â€œAnalisis Sentimen Maskapai Pen erbangan Menggunakan Metode Naive Bayes dan Seleksi Fitur Information Gain,â€ J. Teknol. Inf. dan Ilmu Komput. , vol. 7, no. 3 . 
[9] A. W. Attabi, L. Muflikhah, and M. A. Fauzi, â€œPenerapan Analisis Sentimen untuk Menilai Suatu Produk pada Twitter Berbahasa Indonesia dengan Metode NaÃ¯ve Bayes Classifier dan Information Gain,â€ J. Pengemb. Teknol. Inf. dan Ilmu Komput. , vol. 2, no. 11, pp.  4548 â€“4554, 2018.  
[10] H. S. Utama, D. Rosiyadi, D. Aridarma, and B. S. Prakoso, â€œSentimen Analisis Kebijakan Ganjil Genap Di Tol Bekasi Menggunakan Algoritma Naive Bayes Dengan Optimalisasi Information Gain,â€ J. Pilar Nusa Mandiri , vol. 15, no. 2, 
pp. 247 â€“254, 2019, doi: 10.33480/pilar.v15i2.705.  
[11] A. Syakuro, â€œAnalisis Sentimen Masyarakat Terhadap E-Commerce Pada Media Sosial Menggunakan Metode Naive Bayes Classifier ( NBC ) Dengan Seleksi Fitur Information Gain ( IG ), pp. 1 â€“89, 2017.  
[12] M. R. T. Za man, â€œKlasifikasi Opini Terhadap Kebijakan Publik Merdeka Belajar Pada Jejaring Sosial Twitter Menggunakan Metode Naive Bayes Dengan Seleksi Fitur Information Gain,â€ 2020.  
[13] R. Khalida and S. Setiawati, â€œAnalisis Sentimen Sistem E -Tilang Menggunakan Alg oritma Naive Bayes Dengan 
Optimalisasi Information Gain,â€ J. Inform. Inf. Secur. , vol. 1, no. 1, pp. 19 â€“26, 2020, doi: 10.31599/jiforty.v1i1.137.  
[14] S. Widya Sihwi, I. Prasetya Jati, and R. Anggrainingsih, â€œTwitter Sentiment Analysis of Movie Reviews Using Information Gain and NaÃ¯ve Bayes Classifier,â€ Proc. - 2018 Int. Semin. Appl. Technol. Inf. Commun. Creat. Technol. Hum. Life, iSemantic 2018 , pp. 190 â€“195, 2018 . 
[15] Syahriani, A. A. Yana, and T. Santoso, â€œSentiment analysis of facebook comments on indo nesian presidential candidates using the naÃ¯ve bayes method,â€ J. Phys. Conf. Ser. , vol. 1641, no. 1, 2020, doi: 10.1088/1742 -6596/1641/1/012012.  
[16] A. Andilala, â€œMovie Review Sentimen Analisis Dengan Metode NaÃ¯ve Bayes Base on Feature Selection,â€ Pseudoc ode, vol. 3, no. 1, pp. 1 â€“9, 2016, doi: 10.33369/pseudocode.3.1.1 -9. 
[17] A. Taufik, â€œOptimasi Particle Swarm Optimization Sebagai Seleksi Fitur Pada Analisis Sentimen Review Hotel 
Berbahasa Indonesia Menggunakan Algoritma NaÃ¯ve Bayes,â€ J. Tek. Komput. AMI K BSI , vol. III, no. 2, pp. 40 â€“47, 2017.  
[18] K. S. Nugroho, I. Istiadi, and F. Marisa, â€œNaive Bayes classifier optimization for text classification on e -government using particle swarm optimization,â€ J. Teknol. dan Sist. Komput. , vol. 8, no. 1, pp. 21 â€“26, 2020, doi: 
10.14710/jtsiskom.8.1.2020.21 -26. 
[19] R. Y. Hayuningtyas and R. Sari, â€œAnalisis Sentimen Opini Publik Bahasa Indonesia Terhadap Wisata Tmii Menggunakan NaÃ¯ve Bayes Dan Pso,â€ J. Techno Nusa Mandiri , vol. 16, no. 1, pp. 37 â€“42, 2019 . 
[20] Y. Cahy ono, â€œAnalisis Sentiment pada Sosial Media Twitter Menggunakan NaÑ—ve Bayes Classifier dengan Feature 
Selection Particle Swarm Optimization dan Term Frequency,â€ J. Inform. Univ. Pamulang , 2017. 
[21] K. Solecha, â€œAnalisa Sentimen Dengan Algoritma NaÃ¯ve Bayes Classifier Berbasis Particle Swarm Optimization Untuk 
Review Restoran,â€ J. Speed â€“ Sentra Penelit. Eng. dan Edukasi , vol. 11, no. 1 . 
[22] Betesda, â€œP eningkatan  Optimasi  Sentimen  Dalam  Pelaksanaan  Proses  Pemilihan  Presiden  Berdasarkan  Opini Publik  Dengan  Menggunakan  Algoritma  Naive Bayes Dan Particle Swarm Optimization ,â€ 2020.  
[23] R. Aulianita and A. Rifai, â€œOptimasi Particle Swarm Optimization Pada Naive Bayes Untuk Sentiment Analysis 
Furniture,â€ Inf. Manag. Educ. Prof. , vol. 3, no. 1, pp. 31 â€“40, 2018.  
[24] S. A. Saputra, â€œSentiment Analysis Analisis Sentimen E-Wallet Pada Google Play Menggunakan Algoritma Naive Bayes 
Berbasis Particle Swarm Optimization,â€ J. RESTI (Rekayasa Sist. dan Teknol. Informasi) , vol. 3, no. 3, pp. 377 â€“382, 2019.  
[25] R. Hidayat, â€œKom binasi Seleksi Fitur Chi Square Dengan Algoritma Naive Bayes Untuk Analisis Sentimen,â€ vol. 1, pp. 72â€“81, 2017.  
[26] R. Y. Kisworini, â€œPeningkatan Performa Naive Bayes Dengan Seleksi Atribut Menggunakan Chi Square Untuk 
Klasifikasi Loyalitas Pelanggan GRAB ,â€ J. Informatics, Inf. Syst. Softw. Eng. Appl. , vol. 2, no. 2, pp. 69 â€“75, 2020 . 
[27] A. Z. Amrullah, A. Sofyan Anas, and M. A. J. Hidayat, â€œAnalisis Sentimen Movie Review Menggunakan Naive Bayes 
Classifier Dengan Seleksi Fitur Chi Square,â€ Jurnal , vol. 2, no. 1, pp. 40 â€“44, 2020 . 
[28] A. Nisa, E. Darwiyanto, and I. Asror, â€œAnalisis Sentimen  Menggunakan Naive Bayes Classifier dengan Chi -Square Feature Selection Terhadap Penyedia Layanan Telekomunikasi,â€ e-Proceeding Eng. , vol. 6, no. 2, pp. 8650 â€“8659, 2019.  
[29] A. Nugroho, â€œAnalisis Sentimen Pada Media Sosial Twitter Menggunakan Naive Bayes Classifier Dengan Ekstrasi Fitur N-Gram,â€ J-SAKTI (Jurnal Sains Komput. dan Inform. , vol. 2, no. 2, p. 200, 2018 . 
[30] W. C. Indhiarta, â€œPenggunaan N -Gram Pada Analisa Sentimen,â€ pp. 1 â€“18, 2017.  
[31] D. Irvantoro, I. Saifudin, and R. Umilasari, â€œFeature Se lection Menggunakan Chi Squared dan N -Gram Dengan 
Algoritma Naive Bayes Classifier Untuk Analisis Sentimen Review Produk Elektronik,â€ vol. 53, no. 9, pp. 1689 â€“1699, 2019.  
",klasifikasi,"Naive Bayes, Particle Swarm Optimization, PSO, N-Gram",artikel penelitian,akurasi
SISTEM REKOMENDASI PADA E-COMMERCE MENGGUNAKAN K-NEAREST NEIGHBOR,"SISTEM REKOMENDASI PADA E-COMMERCE MENGGUNAKAN K-NEAREST NEIGHBOR

Chandra Saha Dewa Prasetya  

Abstrak  
Semakin banyaknya informasi produk yang ada di internet menghadirkan tantangan baik pembeli maupun pebisnis online dalam lingkungan e-commerce. Pembeli sering mengalami kesulitan saat mencari produk di internet karena banyaknya produk yang dijual di internet. Selain itu, pebisnis online sering mengalami kesulitan karena memiliki data mengenai produk, pembeli, dan transaksi yang sangat banyak, sehingga menyebabkan pebisinis online mengalami kesulitan untuk mempromosikan produk yang tepat pada target pembeli tertentu. Sistem rekomendasi dikembangkan untuk mengatasi permasalahan tersebut dengan berbagai metode seperti Collaborative Fltering , Content based , dan Hybrid . Metode Collaborative Fltering  menggunakan data rating pembeli, Content Based menggunakan konten produk seperti judul atau deskripsi, dan Hybrid  menggunakan keduanya sebagai dasar rekomendasi. Dengan menggunakan basis data graf, maka model sistem rekomendasi dapat dirancang dengan berbagai metode pendekatan sekaligus. Pada penelitian ini, algoritma k-Nearest Neighbor digunakan untuk menentukan top -n rekomendasi produk untuk setiap pembeli. Hasil dari penelitian ini metode Content Based mengungguli metode lain karena data yang digunakan sparse , yaitu kondisi dimana jumlah rating yang diberikan pembeli relatif sedikit terhadap banyaknya produk yang tersedia pada e-commerce . 

Kata kunci : sistem rekomendasi, k-nearest neighbor, collaborative filtering, content based . 

Abstract  
The growing number of product information available on the internet brings challenges to both customer and online businesses in the e -commerce environment. Customer often have dificulty when looking for products on the internet because of the number of products sold on the internet. In addition, online businessman often experience dificulties because they has much data about products, customers and transactions, thus causing online businessman have dificulty to promote the right product to a particular customer target. A recommendation system was developed to address those problem with various methods such as Collaborative Filtering, Content Based, and Hybrid. Collaborative filtering method uses customers rating data, content based using product content such as title or description, and hybrid using both as the basis of the recommendation. In this research, the k -nearest neighbor algorithm is used to determine the top -n product recommendations for each buyer. The result of this research method Content Based outperforms other methods because the sparse data, that is the condition where the number of rating given by the customers is relatively little compare d the number of products available in e-commerce . 

Keywords : recomendation system, k-nearest neighbor, collaborative filtering, content based . 

1. PENDAHULUAN   
Semakin banyaknya informasi produk yang ada di internet menghadirkan tantangan baik pembeli maupun pebisnis online dalam lingkungan e-commerce. Pembeli sering mengalami kesulitan saat mencari produk di internet karena  banyaknya produk yang dijual di internet. Pebisnis online sering 
mengalami kesulitan karena memiliki data mengenai produk, pembeli, dan transaksi yang sangat banyak, sehingga menyebabkan pebisinis online mengalami kesulitan untuk mempromosikan produk yang tepat pada target pembeli tertentu. Menurut Knijnenburg et al. (2012) sistem rekomendasi secara otomatis dapat mengalisis penggunaan data calon pembeli untuk menyaring konten halaman web,  mengkategorisasi pesan newsgroup, dan merekomendasikan informasi. Sistem rekomendasi menganalisis data menganai 
produk atau interaksi pengguna dan produk untuk menemukan hubungan antara produk dan pengguna. Hasil yang diterima akan ditampilkan sebagai rekomendasi.  Konsep sistem rekomendasi telah digunakan oleh berbagai bisnis online seperti amazon.com dan ebay.com sebagai alat bisnis. Sistem rekomendasi dilaporkan telah meningkatkan penjualan produk dan membangun loyalitas pembeli (Mobasher, 2007). Dalam sistem rekomendasi terdapat beberapa metode yang sering diguna kan yaitu Collaborative Filtering , Content Based , dan Hybrid . Collaborative Filtering menggunakan riwayat pemilihan atau riwayat penilaian sebagai dasar untuk menentukan brought to you by CORE View metadata, citation and similar papers at core.ac.uk rekomendasi. Content Based  menggunakan kesamaan produk untuk ditawarkan kepada pembeli . Sedangkan metode Hybrid  menggabungkan metode dua atau lebih metode untuk menghasilkan rekomendasi yang lebih baik.  Pengembangan sistem rekomendasi sering mengalami 2 tantangan. Yang pertama bagaimana menggambarkan berbagai macam informasi mengenai produk dan pengguna dan bagaimana. 
Selain itu bagaimana membangun sebuah model yang fleksibel untuk digunakan dengan berbagai metode pendekatan yang berbeda. Pada penelitian ini akan digunakan algoritma k-nearest neighboard untuk menemukan top -n rekomendasi pro duk untuk setiap pembeli. Algoritma K-Nearest Neighbor  (KNN) memiliki beberapa kelebihan yaitu kemudahan, efektivitas, intuitif, dan performa klasifikasi yang kompetitif dalam banyak domain (Imandoust dan Bolandraftar, 2013).  

2. DASAR TEORI  
Sistem rekomendasi  membantu pengguna untuk mengidentifikasi  
2.1 Sistem Rekomendasi  
Sistem rekomendasi membantu pengguna untuk mengidentifikasi produk yang sesuai dengan kebutuhan, kesenangan, dan keinginan user. Sistem rekomendasi akan membimbing user untuk menemukan produk  yang relevan dan berguna dari banyaknya produk yang tersedia .  Menurut sejak pertama Tang et al. (2013) kali ditemukan pada tahun 1990, ada banyak penelitian mengenai sistem rekomendasi dilakukan. Sistem rekomendasi mulai diaplikasikan ke berbagai bidang  dengan metode yang berbeda seperti Content Based , Collaborative Filtering , dan Hybrid . Sistem rekomendasi yang menggunakan metode Content Based menggunakan kesamaan produk untuk ditawarkan kepada penggguna. Namun, metode Content Based memiliki kelemahan yaitu ketika fitur konten yang tersedia terbatas, maka akurasi rekomendasi yang dihasilkan cukup rendah (Yuan et al., 2014).  Collaborative Filtering  adalah metode yang paling sering digunakan untuk membangun sistem rekomendasi. Metode ini bergantung pada riwayat pemilihan atau riwayat penilaian (Sudan Khoshgoftaar, 2009) . Metode Hybrid  menggabungkan metode Content Based  dan Collaborative Filtering  untuk menghasilkan rekomendasi yang lebih baik (Tang et al., 2013).  
2.2  Vector Space Model  
Vector Space Model adalah model aljabar untuk merepresentasikan teks  dokumen sebagai vektor dan setiap dimensi sesuai dengan sebuah istilah yang  terpisah dalam sebuah ruang vektor. Jika sebuah istilah ada dalam suatu dokumen,  maka nilai dari vektor tersebut tidak nol. Misal kan kita mempunyai n istilah berbeda  pada lexicon . Kemudian lexicon , â„“ , merepresentasikan sebuah kumpulan dari istilah  dan dapat didefinisikan pada Persamaan (1).  
â„“={ð‘¡1,ð‘¡2,ð‘¡3,â€¦,ð‘¡ð‘›} (1)  
Kemudian, sebuah vektor  ð‘‘ð‘–âƒ—âƒ—  didefinisikan pada 
persamaan (2) . 
ð‘‘iâƒ—âƒ—âƒ— ={ð‘¤1ð‘–,ð‘¤2ð‘–,ð‘¤3ð‘–,â€¦,ð‘¤ð‘›ð‘–} (2) 
dimana ð‘¤ð‘˜ð‘– merepresentasikan bobot istilah   ke-
k pada dokumen i . Vector Space Model merupakan dasar dalam operasi information retrieval seperti klasifikasi  atau klastering dokumen (Danisman dan Alpkocak, 2008).  
2.3 Cosine Similarity  
Setelah dokumen direpresentasikan sebagai vektor, maka derajat kesamaan antara dua dokumen dapat dihitung sebagai korelasi antara 2 vektor yang sesuai. Hal ini dapat diukur sebagai dua sudut antar vektor yang disebut Cosine Similarity . Cosine  similarity  adalah salah satu metode yang paling populer yang sering diterapkan pada teks dokumen untuk keperluan temu balik informasi dan klastering. Untuk mencari  cosine similarity antara dua dokumen  ð‘¡ð‘Žâƒ—âƒ—âƒ—  dan ð‘¡ð‘âƒ—âƒ—âƒ—  ditunjukkan pada Persamaan (3).  
SIM (ð‘¡ð‘Žâƒ—âƒ—âƒ— ,ð‘¡ð‘âƒ—âƒ—âƒ— )= ð‘¡ð‘Žâƒ—âƒ—âƒ—âƒ—  .  ð‘¡ð‘âƒ—âƒ—âƒ—âƒ— 
|ð‘¡ð‘Žâƒ—âƒ—âƒ—âƒ—âƒ—âƒ— | ð‘¥ |ð‘¡ð‘âƒ—âƒ—âƒ—âƒ— | (3) 
dimana ð‘¡ð‘Žâƒ—âƒ—âƒ—âƒ—  dan ð‘¡ð‘âƒ—âƒ—âƒ—âƒ—  adalah  vektor multi 
dimensional dari kumpulah istilah T =  
{ð‘¡1,ð‘¡2,ð‘¡3,â€¦,ð‘¡ð‘›}. Setiap dimensi pada vektor 
merepresentasikan istilah dengan bobotnya pada  dokumen yang bernilai non negatif. Hasil  dari Cosine Similarity  bernilai non negatif  dan berada diantara nilai 0 dan 1 (Huang, 2008).  
2.4 KNN  
Algoritma KNN adalah salah satu algortima yang sering digunakan untuk melakukan klasifikasi. Algoritma termasuk dalam algoritma lazy learning yang  mudah untuk diimplemen tasikan (Alkhatib et al., 2013) .  Dalam penggunaan algoritma KNN data dibagi menjadi dua bagian yaitu data latih dan data uji. Data latih digunakan algoritma untuk melakukan dasar prediksi, sedangkan data uji terdiri dari nilai yang diprediksi oleh algoritma (Imandoust dan Bolandraftar, 2013). Data latih diubah menjadi vektor dan sebuah jarak dihitung menggunakan beberapa metode, seperti euclidean distance  atau cosine similarity . Langkah -langkah algoritma KNN:  
1. Menentukan parameter k ( jumlah tetangga terdekat)  196    Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK) , Vol. 4, No. 3, September  2017 , hlm. 194-200  
2. Hitung jarak data latih dengan semua data uji 
3. Urutkan jarak tersebut berdasarkan nilai yang terkecil sejumlah k.  
4. Tentukan kelompok data uji berdasarkan label mayoritas pada k.  
2.4 Evaluasi  
Metode yang paling dasar dan sering digunakan untuk mengukur performa sistem adalah precision dan recall ( Christopher  et al, 2008). Gagasan ini dapat dijelaskan dengan confusion matrix pada Tabel 1.  
Tabel 1.  Confussion matrix  
Prediksi  
Relevan  Tidak Relevan  
Relevan  True Positive  False Positive  
Tidak Relevan  False Negative  True Negative  
Jika data positif dan diprediksi positif akan dihitung sebagai True Positive (TP), tetapi jika data itu diprediksi negatif maka akan dihitung sebagai False Negative (FN). Jika data negatif dan diprediksi negatif akan dihitung sebagai true negative, tetapi jika data tersebut diprediksi positif maka akan dihitung sebagai False Positive (FP).  Dari Tabel 1 dapat dihitung nilai precision , recall , dan F-measure . Precision  adalah bagian dari dokumen yang terambil secara benar. Persamaan (4) adalah persamaan untuk menghitung nilai 
precision.  
ð‘ð‘Ÿð‘’ð‘ð‘–ð‘ ð‘–ð‘œð‘› =ð‘‡ð‘ƒ
ð‘‡ð‘ƒ+ð¹ð‘ƒ (4) 
Recall  adalah bagian dari dokumen yang relevan yang terambil. Persamaan (5) adalah persamaaan untuk mengitung nilai recall . 
ð‘Ÿð‘’ð‘ð‘Žð‘™ð‘™=ð‘‡ð‘ƒ
ð‘‡ð‘ƒ+ð¹ð‘ (5)  
F-measure  adalah nilai yang mewakili kinerja sistem yang merupakan rata -rata dari nilai precision  dan recall  (Christopher  et al, 2008 ). Persamaan (6) adalah persamaan untuk menghitung nilai F-measure . 
ð¹âˆ’ð‘šð‘’ð‘Žð‘ ð‘¢ð‘Ÿð‘’=2ð‘ƒð‘…
ð‘ƒ+ð‘… (6) 

3. DATASET  
Dataset yang digunakan diambil dari laman Stanford Network Analysis Platform (SNAP) yang berisi metadata produk produk pada e-commerce amazon pada musim panas 2005 . Untuk setiap produk terdapat beberapa informasi berikut yaitu judul, salesrank, kategori, group, dan review produk seperti meliputi waktu, rating, dan pembeli. Cuplikan data ditunjukkan pada Gambar 1.    
Gambar 1. Cuplikan data yang digunakan  

4. PERANCANGAN SISTEM  
Pada penelitian ini, praprocessing dilakukan terhadap dataset yang berformat txt ke menjadi 3 data yaitu data produk, data pembeli, dan data transaksi. Data yang telah diolah kemudian disimpan dalam format comma separated value  (csv).  Kemudian proses 5-fold cross validation  dilakukan pada data transaksi yang terdiri dari id pembeli, id produk, dan rating produk untuk  membagi dataset menjadi data train dan data test. Data train adalah data yang  digunakan untuk membentuk model. Model ini merupakan repres entasi pengetahuan  yang akan digunakan untuk prediksi kelas data baru yang belum pernah ada. Data test  adalah data yang digunakan untuk mengukur sejauh mana model dapat melakukan  prediksi dengan benar.  Selanjutnya data transaksi pembeli diubah menjadi vektor dengan dimensi union produk yang 
akan dibandingkan. Vektor tersebut kemudian dibandingkan dengan vektor lain menggunakan cosine similarity . Pada data produk, terdapat beberapa fitur yang dapat digunakan untuk mencari similarity yaitu judul, grup, dan ka tegori. Untuk 
masing-masing fitur tersebut dilakukan pembobotan TF-IDF.  Selanjutnya dilakukan vektorisasi dengan dimensi union dari kata yang dibandingkan. Cosine similarity  kemudian dilakukan untuk mengetahui similarity antara dua vektor yang dibandingkan.. Selanjutnya algoritma KNN dengan metode Collaborative Filtering , Content Based , atau Hybrid  
dijalankan untuk mencari top -n rekomendasi dengan kepada suatu pembeli. Metode Collaborative Filtering  menggunakan similarity antar pembeli sebagai dasar rekomendasi.  Metode Content Based  menggunakan similarity antar produk sebagai dasar rekomendasi. Sedangkan metode Hybrid  menggabungkan hasil dari Collaborative Filtering  dan Content Based  sebagai dasar rekomendasi. Data test hasil dari proses 5-fold cross ation  digunakan sebagai masukan untuk melakukan prediksi. Hasil dari prediksi kemudian dihitung nilai presisi , recall , dan F-measure  untuk mengetahui performa metode yang digunakan. Perancangan sistem pada penelitian ini ditunjukkan pada Gambar 2.   
Mulai
Input data
Mengubah data menjadi data produk, pembeli, dan transaksi
Split data pembelian menjadi data train dan test
Mengubah data pembelian menjadi vektor
Mencari nilai similarity antar pembeli dengan cosine similarity
Praproses data produk dan pembobotan TF-IDF
Mencari nilai similarity antar produk dengan cosine similarity
Data test
Prediksi data pembelian
Evaluasi
Selesai
Model
Gambar 2. Perancangan  Sistem 
 
5. PENGUJIAN DAN HASIL  
Pengujian dilakukan untuk mengetahui performa metode Collaborative Filtering , Content Based , dan Hybrid . Pengujian dilakukan dengan menghitung nilai precision , recall , dan F-measure  dari masing-masing metode. Proses pengujian dilakukan dengan metode 5-fold Cross Validation yaitu membagi data menjadi 5 bagian, kemudian satu bagian pertama dijadikan data latih dan data lainnya menjadi data uji.  Kemudian bagian kedua dijadikan  data train dan bagian lainnya dijadikan data test, begitu seterusnya sampai bagian kelima. Sehingga persentase data yang digunakan untuk penelitian ini adalah 80% data train dan 20% data test. Untuk setiap pembeli akan diberikan rekomendasi produk sebanya k 10, 30, 50, 80, dan 100 dari total 9467 produk yang digunakan pada penelitian ini.  
5.1. Contoh Pengujian  
Untuk setiap pembeli pada data pengujian akan diberikan rekomenda si produk. Selanjutnya akan dicari nilai precision  dan recall  untuk setiap pembeli.  Pengujian dilakukan menggunakan parameter k yaitu 10, 30, 50, 80, 100. Contoh  hasil pengujian ditunjukkan pada  Tabel 2 .  
Tabel 2. Contoh pengujian  
Kode pembeli  Rekomendasi  Produk dibeli  
18059, 7448 ,  
13886, 34371 , 
34772 , 24475, 
17361, 30919 , 
21314, 12432  
12301, 12344  7448 , 1231  
34772 , 1213   
12021, 2341  
10231, 2134   
A1JTG  
Dari Tabel 2 nilai precision  dan recall  kemudian 
dihitung sebagai yaitu precision  = 2/(2 + 10) = 0,1 6 
dan recall  = 2/(2 + 8) = 0,20 . Proses pengujian untuk setiap percobaan  dilakukan terhadap 1323 pembeli. Nilai rata-rata precision  dan recall  adalah nilai precision dan recall  pada percobaan  tersebut. Nilai F-measure  untuk 
percobaan tersebut kemudian dicari menggunakan  nilai rata -rata precision dan recall . 
5.2. Pengujian Meto de Collaborative  Filtering  
Pada sistem rekomendasi menggunakan metode ini, didapatkan hasil seperti Tabel  3.  
Tabel 3. Pengujian Metode Collaborative Filtering  
k precision  recall  F-measure  
10 0.028  0.053  0.036  
30 0.025  0.138  0.0424  
50 0.023  0.218  0.0425  
80 0.022  0.334  0.0420  
100 0.021  0.404  0.041  
Dari Tabel 3, metode Collaborative Filtering  menghasilkan precision  terbaik pada percobaan dengan parameter k=10 yaitu sebesar 0.028. Recall  terbaik  dihasilkan pada percobaan menggunakan k=100 yaitu sebesar 0.404. F-measure  terbaik dihasilkan pada percobaan dengan parameter k=50 yaitu sebesar 0.0425.  Nilai precision  terendah dihasilkan pada percobaan dengan parameter k=100  yaitu sebesar 0.021. Nilai recall dan F-measure terendah dihasilkan pada percobaan  dengan parametet k=10 yaitu sebesar 0.053 dan 0.036.  Performa metode Collaborative Filtering  ditunjukkan pada Gambar 3.
Gambar 3. Performa Collaborative Filtering   
Gambar 3 menunjukkan semakin semakin rendah nilai k maka nilai precision  dan F-measure kan semakin tinggi. Namun nilai recall  akan semakin  rendah. Hal ini disebabkan karena semakin tinggi nilai k, maka nilai false positive yaitu barang yang direkomendasikan namun tidak dibeli akan semakin tinggi.  
5.3. Pengujian Metode Content Based  
Pada sistem rekomendasi menggunakan metode ini, didapatkan hasil seperti Tabel  4. 
Tabel 4. Pengujian Metode Content Based   
k precision  recall  F-measure  
10 0.080  0.148  0.103  
30 0.044  0.242  0.075  
50 0.031  0.284  0.057  
80 0.024  0.345  0.045  
100 0.021  0.377  0.040  
Dari Tabel 4, metode Content Based  menghasilkan precision , dan F-measure  terbaik pada percobaan menggunakan parameter k=10 yaitu sebesar 0.080  dan 0.103. Recall  tertinggi dihasilkan pada percobaan menggunakan k=100 yaitu  sebesar 0.377. Sedangkan nilai precision , dan F-measure  terendah dihasilkan pada  percobaan menggunakan nilai k=100 yaitu sebesar 0 .0212 dan 0.040. Recall  terendah dihasilkan pada percobaan menggunakan k=10 yaitu sebesar 0.148.  Performa metode Content Based  ditunjukkan pada Gambar 4.  
Gambar 4. Performa Content Based   
Dari Gambar 4 dapat disimpulkan semakin rendah nilai k maka nilai  precision  dan F-measure  akan semakin tinggi. Namun nilai recall  akan semakin   rendah. Hal ini disebabkan karena semakin tinggi nilai k, maka nilai false positive  yaitu barang yang direkomendasikan namun tidak dibeli akan semakin tinggi.  
5.4. Pengujian Metode Hybrid  
Pada sistem rekomendasi menggunakan metode ini, didapatkan hasil seperti Tabel  5. 
Tabel 5 . Pengujian Metode Hybrid  
K precision  recall  F-measure  
10 0.072  0.1323  0.093  
30 0.036  0.192  0.061  
50 0.026  0.233  0.057  
80 0.023  0.329  0.043  
100 0.020  0.353  0.038   
Dari Tabel 5 , metode Hybrid  menghasilkan precision , dan F-measure  terbaik pada percobaan menggunakan parameter k=10 yaitu sebesar 0.072 dan 0.093. Recall  tertinggi dihasilkan pada percobaan menggunakan k=100 yaitu sebesar  0.353. Sedangkan nilai precision , dan F-measure  terendah dihasilkan pada percobaan  menggunakan nilai k=100 yaitu 
sebesar 0.020 dan 0.038. Recall  terendah dihasilkan  
pada percobaan menggunakan k=10 yaitu sebesar 0.132.  Performa metode Hybrid  ditunjukkan pada Gambar 5.   
Gambar 5 . Performa Hybrid   
Dari Gambar 5 dapat disimpulkan semakin rendah nilai k maka nilai  precision  dan F-measure  akan semakin tinggi. Namun nilai recall  akan semakin  rendah. Hal ini disebabkan karena semakin tinggi nilai k, maka nilai false positive  yaitu barang yang direkomendasikan namun tidak dibeli akan 
semakin tinggi.  
5.5. Perbandingan Performa  Ketiga Metode  
Dari ke tiga metode yang diujikan, maka nilai rata-rata F-measure  yang  dihasilkan dapat dibandingkan untuk mengetahui performa metode mana yang  menghasilkan hasil terbaik. Pada Gambar 6 merupakan hasil perbandingan sistem  rekomendasi dari ketiga metode yang diaplikasikan.  
Tabel 6.4 menunjukkan bahwa metode Content Based  menghasilkan nilai F-measure  tertinggi pada parameter k=10 yaitu sebesar 0.1   03. Sedangkan sistem rekomendasi menggunakan metode Collaborative Filtering  dengan parameter k=10 menghasilkan nilai F-measure  paling rendah yaitu sebesar 0.036.  
Gambar 6. Perbandingan F-measure  ketiga metode   
Pada penelitian ini metode Content Based menghasilkan F-measure yang lebih baik dari metode Collaborative Filtering  dan Hybrid  karena data pembelian sangat sparse . Kondisi tersebut terjadi karena jumlah transaksi setiap pembeli relatif sedikit dibandingkan banyaknya produk yang tersedia. Pada penelitian ini, seorang pembeli rata-rata hanya 
memberikan rating terhadap 38 produk dari 9467 produk yang tersedia. Data yang sparse  tersebut mengakibatkan turunnya performa metode Collaborative Filtering . Sedangkan metode Content Based  dapat menghasilkan performa yang lebih baik saat data pembelian yang dilakukan oleh seorang pembeli sedikit. Hal ini disebabkan karena metode ini menentukan rekomendasi berdasarkan data produk seperti judul, grup, dan kategori.  

6. KESIMPULAN  DAN SARAN  
Berdasarkan dataset yang digunakan pada penelitian ini, didapatkan bahwa  metode Content Based  menghasilkan nilai rata -rata precision dan F-measure  paling tinggi dibandingkan Collaborative Filtering  dan Hybrid  pada k=10 yaitu  sebesar 0.080 dan 0.148. Sedangkan recall tertingi dihasilkan dengan metode  Collaborative Filtering  pada k=100 yaitu 0.404.  Dari  percobaan yang dilakukan pada ketiga 
metode apabila nilai k yang semakin tinggi, maka nilai recall  yang dihasilkan juga semakin tinggi. Hal ini disebabkan karena semakin banyak rekomendasi produk yang diberikan kepada pembeli, maka nilai true positive yaitu barang yang direkomendasikan dan dibeli akan meningkat. Selain itu nilai false positive tidak mempengaruhi recall  sehingga nilainya tetap tinggi.  Pada penelitian  ini, masih terdapat sejumlah keterbatasan dan kekurangan.  Salah satu kelemahan menggunakan algoritma  KNN adalah  nilai parameter 
k perlu dicari terlebih dahulu untuk mendapatkan hasil yang paling optimal . Selain itu biaya komputasinya juga cukup tinggi karena perhitungan jarak dilakukan antara data uji dengan setiap data latih. Penelitian selanjutnya dapat menggunakan data yang lebih besar dari penelitian  ini. Selanjutnya metode lain seperti adjusted cosine similarity dapat diterapkan untuk mencari bobot similarity antar produk maupun antar pembeli untuk meningkatkan nilai precision , recall , dan F-measure .  
 
7. DAFTAR PUSTAKA  
ALKHATIB, K., NAJADAT, H., HMEIDI, I. & SHATNAWI, M.K.A . 2013. Stock price  prediction using k-nearest neighbor (kNN) algorithm. International Journal of Business, Humanities and Technology , 3(3), 32-44. 
CHOI, K., YOO, D., KIM, G. & SUH, Y. 2012. A hybrid online -product  recommendation  system: Combining implicit rating -based collaborative filtering  and sequential pattern analysis. Electronic Commerce Research and Applications , 11(4), 309-317. 
CHRISTOPHER, D.M., PRABHAKAR, R. & HINRICH, S.C.H.Ãœ.T.Z.E.  2008. Introduction to information retrieval. An Introduction To Information Retrieval , 151, 177. 
DANISMAN, T. & ALPKOCAK, A.  2008, April. Feeler: Emotion classification of text  using vector space model. In AISB 2008 Convention Communication, Interaction and Social Intelligence  (Vol. 1, p. 53).  
DESYAPUTRI, D.M., ERWIN, A., GALINIUM, M. & NUGRAHADI, D . 2013, October.  News recommendation in Indonesian language based on user click behavior. In  Information Technology and Electrical Engineering , 164-169. 
HUANG, A.  2008, April. Similarity measures for text document clustering.  In Proceedings of the sixth new zealand computer science research student  conference  (NZCSRSC20 08), Christchurch, New Zealand. 49 -56. 
IMANDOUST, S.B. & BOLANDRAFTAR, M . 2013. Application of k -nearest neighbor (knn)  approach for predicting economic events: Theoretical background. International  Journal of Engineering Research and Applications , 3(5), 605-610. 
KNIJNENBURG, B. P., WILLEMSEN, M. C., GANTNER, Z., SONCU, H., & NEWELL , C., 2012.  Explaining the user experience of recommender systems. User Modeling and User -Adapted Interacti on, 22(4 -5), 441-504. 
LUND, S.S. & TANDBERG, Ã˜.  2015. Design of a Hybrid Recommender System: A  Study of the Cold -Start User Problem (Masterâ€™s thesis, NTNU).  200    Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK) , Vol. 4, No. 3, September  2017 , hlm. 194-200  
MA, K.  2016. Content -based Recommender System for Movie Website.  M
OBASHER, B . 2007. Data mining for  web personalization. In The adaptive web , 90-135. Springer Berlin Heidelberg.  
SAHAL, R., SELIM, S. & ELKORANY, A.  2014. An Adaptive Framework for Enhancing  Recommendation Using Hybrid Techniques. International Journal of Computer  Science & Information Technology , 6(2), 51. 
SU, X. & KHOSHGOFTAAR, T.M . 2009. A survey of collaborative filtering techniques.  Advances in artificial intelligence, 2009 , 4. 
TANG, J., HU, X. & LIU, H . 2013. Social recommendation: a review. Social Network  Analysis and Mining , 3(4) , 1113 -1133.  
VAINIONPÃ„Ã„, I., & DAVIDSSON, S.  2014. Stock market prediction using the K Nearest  Neighbours algorithm and a comparison with the moving average formula.  
YANG, X., GUO, Y. & LIU, Y . 2013. Bayesian -inference -based recommendation in  online social  networks. IEEE Transactions on Parallel and Distributed Systems , 24(4), 
642-651. 
Yin, H., Sun, Y ., Cui, B., Hu, Z. & Chen, L.  2013, August. Lcars: a location  content - aware recommender system. In Proceedings of the 19th ACM SIGKDD  international conference  on Know ledge discovery and data mining , 221 -229. ACM.  
YUAN, Q., CONG, G. & LIN, C.Y.  2014, August. COM: a generative model for  group recommendation. In Proceedings of the 20th ACM SIGKDD international  conference on Knowledge discovery and data mining , 163-172. ACM.",sistem rekomendasi,"K-Nearest Neighbor, KNN, Collaborative Filtering, Content Based, Hybrid, Cosine Similarity",data produk ada e-commerce amazon,"precision, recall, F-measure"
SISTEM REKOMENDASI UNTUK TOKO ONLINE KECIL DAN MENENGAH,"SISTEM REKOMENDASI UNTUK TOKO ONLINE KECIL DAN MENENGAH

Yaya Suharya, Yudi Herdiana1, Novianti Indah Putri2, Zen Munawar3 

Abstrak
Sistem pemberi rekomendasi sering digunakan di toko elektronik untuk menyarankan produk serupa atau terkait, produk yang berpotensi menarik bagi pelanggan tertentu, atau serangkaian produk untuk kampanye pemasaran. Sistem rekomendasi telah menjadi bagian yang tidak dapat dipisahkan dari hampir semua sistem berbasis informasi serta e-commerce pada umumnya. Sebagian besar sistem pemberi rekomendasi menggunakan metode penyaringan kolaboratif untuk memberikan informasi personalisasi. Metode penyaringan kolaboratif adalah cara yang sangat efisien dan nyaman untuk mencapai personalisasi karena tidak perlu memperkenalkan informasi semantik tentang produk atau menghubungkan produk dan pengguna secara manual. Namun teknik penyaringan kolaboratif memang membutuhkan matriks padat untuk mengembalikan rekomendasi yang relevan. Penelitian ini mengusulkan cara 
menggabungkan beberapa jenis informasi untuk meningkatkan densitas matriks input. Solusi yang disajikan berfokus pada toko online kecil dan menengah yang dapat mengambil manfaat dari hasil yang disaji kan ketika mereka ingin menerapkan sistem rekomendasi dalam aplikasi mereka . 
 
Kata Kunci  : Teknologi informasi, atribut informasi, pemrosesan informasi, toko online. 
 
1. Pendahuluan   
Sistem rekomendasi telah menjadi bagian yang tak terpisahkan dari hampir semua sistem berbasis informasi serta e-commerce  pada umumnya (Munawar, Rustiyana, Herdiana, & Putri, 2021) . Sistem pemberi rekomendasi berguna untuk memberikan rekomendasi produk yang akan yang dipilih berdasarkan preferensi masa lalu, riwayat pembelian, dan informasi demografis  (Munawar, Putri, & Musadad, 2020) . Dalam 
beberapa tahun terakhir, jumlah aplikasi personalisasi telah meningkat pesat, terutama di bidang perdagangan elektronik di mana personalisasi menjadi faktor keberhasilan yang penting (Manber, Patel, & Robison, 2000) . Personalisasi berarti penyaringan informasi untuk setiap orang tertentu untuk memberikan pelanggan interaksi yang disesuaikan atau dipersonalisasi dengan produk, layanan, situs web, dan karyawan perusahaan . Konsep personalisasi adalah persyaratan mendasar untuk toko online . Toko online  sering disebut juga dengan e-commerce . Secara komersial, e-commerce  dapat disebut sebagai kegiatan yang  berusaha menciptakan transaksi yang panjang antara perusahaan dan individu, juga melibatkan pertukaran uang, barang  (Munawar, 2018) . Berbeda dengan toko tradisional, toko elektronik tidak dapat menyediakan kontak pribadi dan konsultasi individu yang merupakan sarana penting dari manajemen hubungan pelanggan. Penggalian pengetahuan produk dapat memandu pengguna saat melakukan pencarian suatu produk (Munawar, 2019b ). Mudah-mudahan, toko online  dapat memanfaatkan mekanisme personalisasi yang dapat, setidaknya sebagian, mengkompensasi kelemahan kontak virtual dan membantu mengelola hubungan pelanggan secara efisien.  Dampak teknologi informasi modern di perusahaan luas dan diwujudkan dalam cara yang paling bervariasi (Putri, Fudsyi, Komalasari, & Munawar, 2021) . Sistem pemberi rekomendasi sering diguna kan di toko elektronik untuk menyarankan produk serupa yang terkait atau berpotensi menarik untuk pelanggan tertentu atau serangkaian produk untuk kampanye pemasaran. Pada Era komputerisasi ini kebutuhan manusia akan informasi dan perkembangan teknologi di  bidang teknologi informasi dan komunikasi  (Musadad et al., 2021) . Pengguna bisa mengakses toko online maka perlu menggunakan program aplikasi. Penggunaan program apli kasi dapat mempermudah dalam pencatatan, perbaikan, serta penghapusan data  (Munawar, 2020) . Sebagian besar sistem pemberi rekomendasi menggunakan metode penyaringan kolaboratif untuk memberikan informasi yang dipersonalisasi. Aplikasi bisa berjalan 
dengan baik bila sudah dilakukan pengujian sistem. Proses pengujian dilakukan untuk memastikan apakah sistem berjalan sesuai rencana awal yang telah dibuat atau tidak dan  untuk mengetahui letak kesalahan yang ada pada sistem  (Munawar, 2019a) . Secara umum, sistem rekomendasi sangat berguna bagi pengguna yang belum atau kurang pengalaman serta kurang pengetahuan dalam memilih banyak alternatif dan untuk mengevaluasi alternatif, yang lebih relevan daripada yang lain  (Putri, Rustiyana, Herdiana, & Munawar, 2021). Titik awal untuk penyaringan ko laboratif adalah m-by-n-matrix disebut matriks rating  dengan m mengacu pada pelanggan (baris) dan n mengacu pada produk (kolom). Dengan menggunakan teknik yang berbeda, persamaan antara produk (teknik berbasis item) atau antara pengguna (teknik berbasis pengguna) dihitung.  Informasi dimasukkan oleh pelanggan secara langsung sedangkan informasi implisit diambil dari interaksi pengguna dengan toko. Metode analitik kuantitatif yang diterapkan untuk mengeksplorasi pengembangan penelitian yang menyelidiki teknologi informasi  dan komunikasi  (Komalasari, Munawar, & Putri, 2021) . Informasi eksplisit termasuk peringkat produk yang diberikan oleh pelanggan, informasi implisit termasuk pesanan dan analisis clickstream. Metode penyaringan kolaboratif adalah cara yang sangat efisien dan nyaman untuk mencapai personalisasi karena tidak perlu memperkenalkan informasi semantik tentang produk atau menghubungkan produk dan pengguna secara manual. Interaksi pelanggan dengan toko adalah satu -satunya informasi yang diperlukan, namun, teknik penyaringan kolaboratif memang membutuhkan matriks peringkat yang padat untuk mengembalikan rekomendasi terkait. Persyaratan memiliki matriks peringkat yang padat untuk menggunakan metode penyaringan kolaboratif bermasalah untuk sistem toko online kecil dan menengah yang tidak dapat mengumpulkan informasi yang cukup tentang pelanggan mereka. Untuk 
memperjelas masalah ini, penelitian  ini menyajikan eksperimen yang dilakukan untuk mendapatkan informasi implisit dan eksplisit. Tujuan dari penelitian  ini adalah untuk membandingkan densitas matriks rating dari sumber data yang berbeda dan kemudian, untuk menggabungkan informasi eksplisit dan implisit untuk meningkatkan densitas matriks rating. Kombinasi informasi pengguna yang berbeda memungkinkan toko online  kecil dan menengah untuk secara signifikan meningkatkan kepa datan matriks peringkat dan, oleh karena itu, kualitas rekomendasi.   

2. Sistem Rekomendasi   
Tujuan dari sistem rekomendasi adalah untuk merekomendasikan produk sesuai dengan preferensi pengguna. Area yang luas dari sistem pemberi rekomendasi telah diperken alkan pada pertengahan 1990-an oleh beberapa penelitian  awal tentang 
penyaringan kolaboratif (Resnick & Varian, 1997), (Shardanand & Maes, 1995) . Sedangkan istilah sistem pemberi rekomendasi lebih umum karena terdiri dari penyaringan berbasis konten, penyaringan kolaboratif, serta pendekatan hibrida. Klasifikasi Sistem Rekomendasi . Sistem rekomendasi dapat diklasifikasikan dalam tiga kelompok berdasarkan pendekatan yang digunakan untuk menghasilkan rekomendasi (Adomavicius, G., Tuzhilin, 2005) : Pendekatan penyaringan berbasis konten ,  Pendekatan penyaringan kolab oratif  dan Pendekatan hibrida . Untuk atribut pendekatan penyaringan berbasis konten ditugaskan untuk setiap produk. Dengan menggunakan teknik temu kembali informasi pada atribut -atribut tersebut dimungkinkan untuk memperoleh kesamaan antar produk, sehingga  dua produk dengan atribut yang sama 
memiliki tingkat kesamaan (Basu, Hirsh, & Cohen, 1998) . Dengan  Sistem Informasi masalah keakuratan, kecepatan informasi dapat diatasi  (Munawar, Ismirani Fudsyi, & Zainal Musadad, 2016) . Keuntungan dari pemfilteran berbasis  konten adalah kemungkinan untuk mendefinisikan secara tepat hubungan antar produk, yaitu untuk cross atau up-selling. Namun keuntungan ini muncul dengan harga tinggi. Di satu sisi, pendekatan ini membutuhkan definisi manual dari sejumlah besar informasi tambahan, mis. kata kunci dan atribut untuk setiap produk. Informasi ini harus selalu up-to-date. Di banyak organisasi, teknologi informasi korporat memiliki peran pelaksana utama dibandingkan dengan pemikiran strategis dan inovatif (Putri, Herdiana, Munawar, & Komalasari, 2021) . Di sisi lain, pemfilteran berbasis konten menggunakan teknik penambangan data yang rumit un tuk menghasilkan informasi yang dipersonalisasi.   Berbeda dengan pemfilteran berbasis konten, pendekatan pemfilteran kolaboratif hanya membutuhkan informasi tentang interaksi dan transaksi pengguna seperti peringkat produk, pesanan, atau informasi aliran klik untuk memberikan rekomendasi. Informasi ini terus diberikan oleh pengguna saat menjelajahi situs web, membeli atau menilai produk. Perbedaan utama lainnya adalah bahwa pendekatan penyaringan kolaboratif didasarkan pada informasi konteks pelanggan. Jadi  kekuatan dari pendekatan ini adalah otomatisasi penuh dan semantik berbasis penggunanya. Namun pendekatan ini membutuhkan sejumlah data tertentu untuk memberikan hasil yang berharga, yaitu jumlah pelanggan dan yang lebih penting kuantitas transaksi pengguna (sering disebut masalah cold start  dan masalah first-rater ).  Penyaringan Kolaboratif Berbasis Pengguna dan Berbasis Item . Pendekatan penyaringan kolaboratif dapat diimplementasikan menggunakan metode berbasis pengguna atau berbasis item. Keduanya menga mbil sebagai input matriks peringkat dengan pelanggan di dimensi baris dan produk di dimensi kolom. Matriks dua dimensi ini mewakili hubungan antara pengguna dan produk baik berdasarkan peringkat produk, produk yang dibeli, atau data aliran klik. Jika peri ngkat produk dipertimbangkan, setiap 
elemen di persimpangan produk dan pelanggan akan berisi nilai antara -1 dan +1 yang mewakili penilaian pelanggan untuk produk di mana -1 menunjukkan ketidaksukaan yang kuat dan +1 sebagai kasih sayang yang kuat. Tabel  1 menunjukkan contoh matriks peringkat.   
Tabel 1. Contoh Matriks Penilaian   
DVD Lost In 
Transaction  DVD Supremasi 
Bourne  DVD Kehidupan 
Akuatik  
Mr. Smith  0 +0,5 0 
Mr. Johnson  -0,5 -1 +0,5 
Mrs. Miller  +1 +0,5 0 
Dalam contoh, Mr. Miller adalah penggemar berat produk DVD Lost in Translation karena dia menilainya dengan nilai tertinggi (+1). Namun, Mr. Johnson tidak menyukai produk tersebut dan karena itu menilainya rendah ( -0,5). Prinsip yang sama berlaku untuk pesanan dan informasi aliran klik dengan setiap sel berisi nilai antara 0 dan +1. Dengan demikian +1 menunjukkan pembelian suatu produk dan 0 berarti produk yang belum dibeli. Dalam hal data aliran klik, nilai antara 0 dan +1 menginformasikan seberapa sering pengguna mengunjungi halaman web yang beri si produk tertentu.  Saat menerapkan metode berbasis pengguna, pada langkah pertama, kesamaan antar pengguna dihitung. Perhitungan ini dapat dicapai dengan menerapkan rumus matematika yang berbeda. Dalam tulisan ini, kesamaan antara pengguna dinilai menggunakan metode kosinus (Resnick & Varian, 1997) . Setelah kesamaan antara semua pengguna tel ah dihitung matriks baru dengan pelanggan pada kedua dimensi dan kesamaan sebagai entri dikembalikan (lihat Tabel  2).  
Tabel 2. Kesamaan Antar Pelanggan   
Mr. Smith  Mr. Johnson  Mrs. Miller  
Mr. Smith  +1 _1 +1 
Mr. Johnson  -1 +1 -0,8 
Mrs. Miller  +1 +1 -0,8 
Gambar 2: Kesamaan antar pelanggan   
Berdasarkan matriks ini, setiap pengguna dapat mengekstrak grup pengguna yang paling mirip (tetangga terdekat). Kelompok ini kemudian digunakan pada langkah kedua untuk mendapatkan rekomendasi produk. Prinsip rekomend asinya cukup jelas jika Mr. Smith sangat mirip dengan Mrs. Miller dan jika Mrs. Miller sangat menyukai produk yang belum dibeli oleh Mr. Smith, kemungkinan Mr. Smith juga menyukai 
produk ini agak tinggi. Metode berbasis pengguna mengembalikan rekomendasi yang dipersonalisasi karena setiap pengguna menerima proposisi berdasarkan profilnya. Dalam contoh , kemungkinan besar Mr. Smith menyukai produk DVD Lost in Translation karena dia sangat mirip dengan Mrs. Miller yang menilai produk ini tinggi.   Berbeda dengan metode berbasis pengguna, metode berbasis item secara langsung memperoleh kesamaan antara produk. Sekali lagi, beberapa pendekatan matematis dapat digunakan untuk menghitung kesamaan ini. Dalam penelitian  ini, metodologi telah dipilih. Metodologi ini menghitung probabilitas bahwa produk X akan dibeli jika produk Y telah dibeli. Ini mewakili rekomendasi yang tidak dipersonalisasi karena setiap pengguna yang melihat produk tertentu akan mendapatkan rekomendasi yang sama. Metode berbasis i tem sering disebut  dengan moto Pelanggan yang membeli item 
ini juga membeli item berikut  (Deshpande & Karypis, 2004) . Pengantar yang lebih dalam tentang algoritma umum yang digunakan untuk penyaringan kolaboratif berbasis pengguna dan berbasi s item serta analisis  (Sarwar, Karypis, Konstan, & Riedl, 2000) .  

3. Rekomendasi Eksperimen  
Tujuan dari eksperimen pemberi rekomendasi adalah untuk mengambil informasi implisit dan eksplisit dalam skenario kasus nyata. Informasi eksplisit dimasukkan oleh pelanggan secara langsung melalui peringkat bintang 5 yang umum. Informasi implisit disimpulkan dari perilaku pelanggan di toko online, yaitu pemesanan  dan data clickstream.  Pengaturan eksperimen , percobaan dimulai dengan mendirikan toko online yang berisi 149 DVD film. Semua DVD berisi film yang dirilis dalam 7 tahun terakhir. Hampir 200 siswa diminta untuk bergabung dalam eksperimen dan 83 setuju untuk  berpartisipasi. Eksperimen dibagi menjadi dua bagian:  Pada bagian pertama, semua siswa harus membeli DVD yang sudah mereka miliki secara virtual. Bagian ini dilakukan untuk mendapatkan informasi order dan clickstream.  Pada bagian kedua, setiap siswa harus  menilai 5 produk yang disajikan kepadanya. Jika siswa mengetahui film tersebut, ia diminta untuk menilainya dengan nilai mulai dari satu hingga lima bintang. Pada bagian pertama percobaan, 462 produk dibeli oleh 83 siswa yang berpartisipasi. Seorang sisw a rata -rata membeli kemudian 5,57 produk. Secara keseluruhan, 109 produk berbeda dipesan, artinya 40 produk tidak terjual sama sekali (hampir 28,8%). Selama bagian kedua percobaan, 99 peringkat untuk 58 produk berbeda telah dikirimkan. Untuk menghitung rekomendasi, algoritma penyaringan kolaboratif berbasis pengguna dan berbasis item telah diimplementasikan.  Informasi pesanan dan aliran klik diperoleh dengan menelusuri dan membeli DVD . Kepadatan Matriks dengan Sumber Informasi Tunggal . Dengan 149 produk yang tersedia dan 83 siswa yang berpartisipasi, matriks penilaian R berisi 149 x 83 = 12367 sel. Seperti yang telah disebutkan, tiga sumber informasi yang berbeda telah digunakan untuk mengisi matriks 
peringkat:  Peringkat produk yang diberikan oleh pelanggan , item yang dibeli berasal dari pesanan , informasi aliran klik .  Peringkat produk adalah sumber informasi terbaik yang dapat diperoleh toko online karena mencerminkan penilaian akhir pelanggan untuk produk tertentu. Sayangnya informasi ini jarang terjadi ka rena pelanggan biasanya hanya menilai produk yang telah mereka beli dan hanya sekelompok kecil pengguna yang menggunakan fungsi ini. 99 
peringkat percobaan menggunakan model bintang lima didefinisikan ke dalam matriks peringkat sebagai berikut: -1 untuk sa tu bintang, -0,5 untuk dua bintang, 0 untuk tiga 
bintang, +0,5 untuk empat bintang dan +1 untuk lima bintang. Dengan menggunakan informasi ini, bahkan 1% dari semua elemen matriks peringkat tidak terisi. Dengan menggunakan informasi peringkat produk, kepad atan matriks terlalu rendah untuk memungkinkan rekomendasi yang berharga. Informasi pesanan juga merupakan cara yang baik untuk mendapatkan preferensi pelanggan. Informasi ini mudah diakses dan jauh lebih padat daripada peringkat produk. Namun terkadang orang membeli produk yang sebenarnya tidak mereka sukai. Ini adalah kasus untuk film yang belum mereka tonton dan mereka pikir mereka akan menyukainya. Oleh karena itu peringkat eksplisit lebih dapat diandalkan daripada informasi pesanan. Dalam matriks peni laian, 462 produk yang dibeli oleh 83 siswa diberi tanda +1. Dalam percobaan, setiap siswa memesan rata-rata 5,57 produk dari 149 produk yang tersedia. Menggunakan informasi barang yang dibeli menghasilkan kepadatan matriks 3,74%. Kepadatan matriks ini adalah nilai realistis untuk sistem toko online kecil dan menengah. Nilai ini memungkinkan penghitungan rekomendasi yang valid, namun kepadatan yang lebih tinggi akan memungkinkan pencocokan yang lebih baik antara pelanggan dan hasil yang lebih akurat.   Data clickstream adalah jenis informasi terakhir yang dapat mengarah pada definisi 
selera pengguna. Ini adalah sumber informasi yang paling substansial tetapi juga paling meragukan. Namun ada korelasi antara halaman web yang dikunjungi dan minat pengguna, terut ama jika pengguna mengunjungi beberapa kali halaman produk yang sama. Untuk mencerminkan informasi ini ke dalam matriks peringkat, setiap kali pelanggan mengunjungi halaman produk, sel yang sesuai meningkat sebesar 0,1. Dengan menggunakan informasi clickst ream, matriks peringkat mencapai kepadatan 6,2%. Kepadatan Matriks dengan Sumber Informasi gabungan . Masalah sistem toko kecil dan menengah adalah pertentangan antara kualitas sumber dan kepadatan matriksnya. Untuk 
mengatasi masalah ini, kombinasi dari berbagai sumber dapat dicapai untuk menggunakan informasi terbaik yang tersedia dan untuk meningkatkan kepadatan matriks.   Matriks peringkat gabungan dapat diperoleh dengan mengikuti aturan:  
1. Jika pelanggan telah menilai produk, informasi peringkat digunakan. Karena peringkat adalah informasi yang paling berharga, peringkat itu melampaui pesanan dan informasi aliran klik. Definisi nilai ini didefinisikan dalam subbagian terakhir. Jika pelanggan tidak menilai produk, kami melanjutkan dengan (2).  
2. Jika pela nggan telah membeli produk, nilai 0,8 ditetapkan. Perintah adalah indikator terbaik kedua, mereka mengungguli informasi clickstream. Perhatikan bahwa nilai 0,8 ditetapkan alih -alih nilai +1 dari subbagian terakhir. Hal ini dilakukan untuk memasukkan sediki t ketidakpastian dari informasi pesanan. Jika pelanggan tidak membeli produk, kami melanjutkan dengan (3). 
3. Jika pelanggan telah mengunjungi halaman produk, nilai antara 0,1 dan 0,6 diatur mengikuti aturan subbagian terakhir. Informasi clickstream adalah  informasi yang 
kurang relevan tetapi berguna jika tidak ada peringkat atau pesanan yang tersedia. Jika pelanggan belum mengunjungi halaman produk, sel matriks tidak diinisialisasi. Dengan menggabungkan tiga sumber informasi yang tersedia, dimungkinkan untuk mencapai kepadatan matriks 6,8%. Kombinasi ini tidak hanya meningkatkan kepadatan matriks sebesar 0,6 pada informasi clickstream tetapi juga memberikan kualitas informasi yang jauh lebih baik. Peringkat eksplisit memiliki dampak yang jauh lebih baik da ripada peringkat implisit (Herlocker, Jo nathan L.â€¯Alâ€¯
menerapkan juga peringkat implisit, matriks peringkat yang dihasilkan menjadi lebih padat.  Banyak peneliti lain mengandalkan matriks peringkat yang memiliki kepadatan jauh lebih tinggi. Contohnya adalah database MovieLens (Beenen et al., 2004)  atau dataset EveryMovie yang banyak digunakan (Pennock, Lawrence, & Giles, 2000) , berisi 2,8 juta peringkat dari lebih dari 70.000 pengguna. Ini mengarah ke rata-rata 40 peringkat per pengguna. Ini lebih dari 4 kali lebih baik dari kombinas i terbaik kami. Selain itu, semua peringkat dari set data EveryMovie bersifat eksplisit.  Kombinasi yang diusulkan dari sumber informasi memungkinkan pada saat yang sama untuk meningkatkan kepadatan matriks peringkat (yaitu menghindari masalah mulai dingin dan masalah peringkat pertama) dan untuk meningkatkan kualitas kualitas informasi di dalam matriks. Pendekatan ini dapat memungkinkan sistem toko online kecil dan menengah untuk sepenuhnya memanfaatkan pendekatan penyaringan kolaboratif.   
 
4. Kesimpulan  
Penelitian  ini menunjukkan bagaimana informasi implisit dan eksplisit yang berbeda dapat digabungkan untuk meningkatkan matriks peringkat. Kombinasi dilakukan dengan menggunakan data kasus nyata yang diperoleh dari percobaan. Hasil dari 
penelitian  ini dapat  digunakan oleh vendor toko online lainnya yang bertujuan untuk menerapkan sistem rekomendasi dalam aplikasi mereka.  Fokus penelitian pada toko online kecil dan menengah. Sistem ini seringkali tidak mampu menggunakan pendekatan penyaringan berbasis konten karena investasi yang tinggi untuk memelihara informasi terkait produk. Di sisi lain, dengan menggunakan pendekatan penyaringan kolaboratif mereka menghadapi masalah kepadatan matriks. Kombinasi informasi implisit dan eksplisit seperti yang dilakukan dalam  penelitian  ini menawarkan cara yang sederhana dan efisien untuk meningkatkan hasil rekomendasi.   
Pendekatan yang disajikan dapat diperluas dengan langkah-langkah berikut:  Penelitian  ini berkonsentrasi pada penyaringan kolaboratif. Dengan menggunakan pendekatan hibrid, hasilnya dapat ditingkatkan. Namun, pendekatan penyaringan berbasis konten jauh lebih rumit untuk diterapkan. Selain itu, semua pendekatan hibrida mendapat manfaat dari pekerjaan ini karena bagian penyaringan kolaboratif ditingkatkan.   Cara yang jelas untuk meningkatkan rekomendasi dilakukan dengan menggunakan 
algoritma yang lebih baik. Dalam percobaan, kami menggunakan algoritma standar dan berkonsentrasi pada matriks input. Ada banyak pendekatan yang telah terbukti lebih baik daripada yang standar. Ini bisa menjadi cara lain untuk meningkatkan hasil.  Untuk mendapatkan hasil yang lebih baik, pelanggan harus diminta untuk memberikan peringkat eksplisit. Untuk mendorong mereka, mereka bisa mendapatkan manfaat seperti kupon atau diskon. Terkadang, manajer perusahaan kecil dan menengah mengenal pelanggan mereka dengan cukup baik. Dengan menyediakan cara untuk secara eksplisit menilai produk 
tertentu untuk mereka, kepadatan matriks peringkat dapat ditingkatkan.  Untuk kedepannya, kami tertarik untuk  membandingkan hasil kami dengan data toko online nyata lainnya. Oleh karena itu, kami berencana untuk meminta toko online lain untuk memberikan data (anonim) mereka kepada kami. Arah penelitian lain yang menarik adalah penggunaan teknologi fuzzy untuk men ciptakan pendekatan hybrid dimana 
ketidakjelasan digunakan untuk mengatasi masalah pemeliharaan informasi terkait produk.   Cara yang jelas untuk meningkatkan rekomendasi dilakukan dengan menggunakan 
algoritma yang lebih baik. Dalam percobaan, kami menggun akan algoritma standar dan berkonsentrasi pada matriks input. Ada banyak pendekatan yang telah terbukti lebih baik daripada yang standar. Ini bisa menjadi cara lain untuk meningkatkan hasil.  Untuk mendapatkan hasil yang lebih baik, pelanggan harus diminta untuk memberikan peringkat eksplisit. Untuk mendorong mereka, mereka bisa mendapatkan manfaat seperti kupon atau diskon.  Terkadang, manajer perusahaan kecil dan menengah mengenal pelanggan mereka dengan cukup baik. Dengan menyediakan cara untuk secara eksplisit menilai produk tertentu untuk mereka, kepadatan matriks peringkat dapat ditingkatkan.  Untuk kedepannya, kami tertarik untuk membandingkan hasil kami dengan data toko online nyata lainnya. Oleh karena itu, Arah penelitian lain yang menarik adalah peng gunaan teknologi fuzzy  untuk menciptakan pendekatan hybrid dimana ketidakjelasan digunakan untuk mengatasi masalah pemeliharaan informasi 
terkait produk.  
  
Daftar Pustaka  
Adomavicius, G., Tuzhilin, A. (2005).  Toward the Next Generation of Recommender Systems: A Survey of the State -of-the-Art and Possible Extensions. IEEE Transactions on Knowledge and Data Engineering , 17(6), 734 â€“749. 
https://doi.org/10.1109/tkde.2005.99  
Basu, C., Hirsh, H., & Cohen, W. W. (199 8). Recommendation as Classification: Using Social and Content -Based Information in Recommendation. Proceedings of the 1998 Workshop on Recommender Systems , 11â€“15. Menlo Park: Cambridge university press.  
Beenen, G., Ling, K., Wang, X., Chang, K., Frankowsk i, D., Resnick, P., & Kraut, R. E. (2004). Using social psychology to motivate contributions to online communities. Proceedings of the ACM Conference on Computer Supported Cooperative Work, CSCW , 212 â€“221. https://doi.org/10.1145/1031607.1031642  
Deshpande, M., & Karypis, G. (2004). Item -based top -N recommendation algorithms. ACM Transactions on Information Systems , 22(1), 143 â€“177. https://doi.org/10.1145/963770.963776  
Herlocker, Jonathan L.â€¯Collaborative filtering recommender systems. ACM Transactions on Information Systems , 22(1), 5 â€“53. https://doi.org/10.1007/978 -3-540-72079 -9_9 
Komalasari, R., Munawar, Z., & Putri, N. I. (2021). Review Penelitian Teknologi Informasi , Komunikasi dan Covid 19  menggunakan teknik Bibliometrik. Jurnal ICTâ€¯: Information Communication & Technology , 20(1), 34 â€“41. Retrieved from 
https://ejournal.ikmi.ac.id/index.php/jict -ikmi/article/view/303/pdf  
Manber, U., Patel, A., & Robison, J. (2000). The Business of Personalization: Experience with Personaliza tion of Yahoo!, Communications of the ACM. Communication of The ACM , 43(8), 35 â€“39. https://doi.org/10.2307/j.ctvct0023.26  
Munawar, Z. (2018). Keamanan Pada E -Commerce Usaha Kecil dan Menengah. Tematik , 5(1), 1 â€“16. https://doi.org/10.38204/tematik.v5i1.144  
Munawar, Z. (2019a). Aplikasi Registrasi Seminar Berbasis Web Menggunakan QR Code pada Universitas XYZ. TEMATIK - Jurnal Teknologi Informasi Dan Komunikasi , 6(2), 128 â€“150. https://doi.org/10.38204/tematik.v6i2.246  
Munawar, Z. (2019b). Meningkatkan Kinerja Individu melalui Kritik/Saran menggunakan Recommender System. TEMATIK - Jurnal Teknologi Informasi Dan Komunikasi , 6(1), 20 â€“37. https://doi.org/10.38204/tematik.v6i1.185  
Munawar, Z. (2020). Mekanisme Keselamatan, Keamanan dan Keberlanjutan untuk Sistem Siber Fisik. TEMATIK - Jurnal Teknologi Informasi Dan Komunikasi , 7(1), 
57â€“88. https://doi.org/10.38204/tematik.v7i1.371  
Munawar, Z., Ismirani Fudsyi, M., & Zainal Musadad, D. (2016). Perancangan Basis Data untuk Sistem Informasi Persediaan ATK pada PT. SPP. Jurnal Teknologi Informasi Dan Komunikasi , 3(1), 86 â€“99. Retrieved from http://jurnal.plb.ac.id/index.php/tematik/article/view/219  
Munawar, Z., Putri, N. I., & Musadad, D. Z. (2020). Meningkatkan Rekomendasi Menggunakan Algoritma Perbedaan Topik. J-SIKA| Ju rnal Sistem Informasi Karya Anak Bangsa , 02(02), 17 â€“26. Retrieved from https://ejournal.unibba.ac.id/index.php/j -sika/article/view/378  
Munawar, Z., Rustiyana, Herdiana, Y., & Putri, N. I. (2021). Sistem Rekomendasi Hibrid Menggunakan Algoritma Apriori Mining Asosiasi. TEMATIK - Jurnal Teknologi Informasi Dan Komunikasi , 8(1), 69 â€“80. 
https://doi.org/10.38204/tematik.v8i1.567  
Musadad, D. Z., Wiganda, J., Munawar, Z., Putri, N. I., Informatika, M., Informatika, M., â€¦ Bandung, B. (2021). Aplikasi Pemeriksaan Ba rang Promo Berbasis Android 
Di PT XYZ. J-SIKA â€¯: Jurnal Sistem Informasi Karya Anak Bangsa , 03(1), 33 â€“42. Retrieved from http://ejournal.unibba.ac.id/index.php/j -sika/article/view/532  
Pennock, D. M., Lawrence, S., & Giles, C. L. (2000). Collaborative Filtering by Personality Diagnosisâ€¯: A Hybrid Memor y- and Model -Based Approach . 473 â€“480. 
Putri, N. I., Fudsyi, M. I., Komalasari, R., & Munawar, Z. (2021). Peran Teknologi Informasi Pada Perubahan Organisasi dan Fungsi Akuntansi Manajemen. Jurnal Riset Akuntansi Dan Bisnis , 7(2), 47 â€“58. Retrieved from https://jurnal.plb.ac.id/index.php/JRAK/article/view/625  
Putri, N. I., Herdiana, Y., Munawar, Z., & Komalasari, R. (2021). Teknologi Pendidikan dan Transformasi Digital di Masa. Jurnal ICT â€¯: Information Communication & 
Technology , 20(7), 53 â€“57. Retrieved from 
https://ejournal.ikmi.ac.id/index.php/jict -ikmi/article/view/306/pdf  
Putri, N. I., Rustiyana, Herdiana, Y., & Munawar, Z. (2021). Sistem Rekomendasi Hibrid Pemilihan Mobil Berdasarkan Profil Pengguna dan Profil Barang. TEMATIK - Jurnal Teknologi Informasi Dan Komunikasi , 8(1 SE -Articles), 56 â€“68. 
https://doi.org/10.38204/tematik.v8i1.566  
Resnick, P., & Varian, H. R. (1997). Recommender Systems. Communications of the 
ACM , 40(3), 56 â€“58. https://doi.org/10.1145/245108.245121  
Sarwar, B., Karypis, G., Konstan, J., & Riedl, J. (2000). Analysis of recommendation algorithms for e-commerce . 158 â€“167. https://doi.org/10.1145/352871.352887  
Shardanand, U., & Maes, P. (1995). Social information filltering: Algorithms for automating word of mouth. Proceedings of the ACM CHI Conference on Human Factors in Computing Systems , 210 â€“217. https://doi.org/10.1145/223904.223931",sistem rekomendasi,"penyaringan kolaboratif, fuzzy","pemesanan, clickstream",
Sistem Rekomendasi Pemilihan Laptop dengan Metode WASPAS,"Sistem Rekomendasi Pemilihan Laptop dengan Metode WASPAS

Kevin Arista Chandra1, Seng Hansun2

ABSTRACT
The invention of computers has revolutionalized our lives. As technological advancements continues to develop, computers had been shrinking in size as PC computers had developed into laptop computers. In order to collect information on an individuals behavior as well as preferences when it comes to their choice on laptops, a survey is conducted through questionnaire distribution. The survey result states that a majority of the respondents had claimed to have experienced difficulties in choosing a laptop that fits their personal preferences. Based on the aforementioned issues, a web based laptop recommender system is built as a solution. The aforementioned system was built using WASPAS Method which is a unique combination of the WSM method and WPM method. This method has been proven to be successfully implemented as a solution for MCDM (Multi Criteria Decision Making) problems. Programming languages used in the development of this system are HTML, PHP, and Javascript. User satisfaction test results indicated mostly positive responses from the respondents towards the system. The user satisfaction test results has the Cronbachâ€™s Alpha value of 0.83, stating that the test results are considered reliable. Also, validity test results confirms the validity of the obtained data. 
 
Keywords : 
Laptop, MCDM, Recommendation System, WASPAS, Website
 
INTISARI
Komputer merupakan sebuah penemuan revolusioner yang memberikan banyak kontribusi bagi kehidupan manusia. Seiring berkembangnya teknologi, komputer berevolusi menuju ukuran yang lebih kecil, dari komputer desktop hingga komputer laptop. Untuk mengetahui perilaku dan preferensi masyarakat dalam memilih laptop, dilakukan survei sederhana menggunakan angket. Berdasarkan hasil survei, sebagian besar responden mengaku pernah mengalami kesulitan dalam memilih laptop yang sesuai dengan keinginan responden. Oleh karena itu, dibangun sebuah sistem rekomendasi laptop berbasis web. Pembangunan sistem ini dilakukan menggunakan metode WASPAS (Weighted Aggregated Sum Product Assesment). Metode WASPAS merupakan penggabungan dari metode WSM dan WPM. Metode ini digunakan untuk menyelesaikan permasalahan MCDM (Multi Criteria Decision Making). Bahasa pemrograman yang digunakan untuk pembangunan website ini antara lain HTML, PHP, dan Javascript. Hasil uji kepuasan pengguna terhadap sistem yang dibangun menunjukkan bahwa mayoritas responden memberikan penilaian positif. Hasil perhitungan Cronbachâ€™s Alpha terhadap hasil uji kepuasan pengguna menghasilkan nilai sebesar 0,83 yang menunjukkan bahwa hasil uji kepuasan pengguna tergolong reliable. Selain itu, uji validitas menunjukkan bahwa data yang diperoleh tergolong valid.  

Kata kunci: Laptop, MCDM, Sistem Rekomendasi, WASPAS, Website 
 
I. PENDAHULUAN
Komputer merupakan sebuah penemuan revolusioner yang memberikan banyak kontribusi bagi kehidupan manusia. Seiring berkembangnya teknologi, komputer berevolusi menuju ukuran 
yang lebih kecil, dari komputer desktop hingga komputer laptop. Sejak tahun 1980, komputer portabel telah banyak diminati oleh masyarakat. Namun, setiap individu memiliki perilaku yang berbeda-beda dalam memilih laptop. Untuk mengetahui perilaku dan preferensi masyarakat dalam memilih laptop, dilakukan survei yang dilakukan menggunakan angket melalui sarana Google Forms. Berdasarkan hasil survei yang disebarkan secara acak melalui sosial media, dari 31 orang responden, sebanyak 87,1% mengaku pernah merasa kesulitan dalam memilih laptop yang sesuai dengan keinginan pribadi responden. Oleh karena itu, dibangun sistem rekomendasi yang bertujuan untuk memberikan saran pilihan laptop berdasarkan kriteria yang diinginkan oleh pengguna. Input dari sistem ini berupa kriteria-kriteria laptop yang diinginkan user, beserta bobot penilaian untuk setiap kriteria. Lalu sistem akan mengeluarkan output berupa rekomendasi laptop yang sesuai dengan kriteria-kriteria tersebut. Terdapat beberapa penelitian serupa yang membahas pemilihan laptop, seperti yang dilakukan oleh Setiawan dan Hansun [1], Hartanto dan Prasetiyowati [2], serta Kusnadi dan Kurniawan [3]. Berdasarkan penelitian yang dilakukan oleh Kusnadi dan Kurniawan [3] diperoleh saran untuk mengembangkan penelitian tersebut dengan menggunakan algoritma lain atau penggabungan algoritma untuk meningkatkan akurasi dan waktu proses atau respon sistem. Adapun simpulan dari penelitian serupa lainnya yang dilakukan oleh Fauzan [4] dengan judul Rancang Bangun Sistem Rekomendasi Pemilihan Smartphone Menggunakan Metode WASPAS Berbasis Web menunjukkan bahwa sistem yang dibangun memiliki koefisien Cronbachâ€™s Alpha sebesar 0,87 dan disimpulkan sistem tersebut reliable. Metode WASPAS (Weighted Agregated Sum Product Assesment) merupakan salah satu metode MCDM (Multi Criteria Decision Making). Zavadskas dkk. [5] mengatakan bahwa diperkirakan metode WASPAS memiliki akurasi 1,3 kali lebih besar dibanding metode Weighted Product Model dan mencapai 1,6 kali lebih besar dibanding Weighted Sum Model. Oleh karena itu, sistem rekomendasi yang dibangun pada penelitian ini dilakukan dengan menggunakan metode WASPAS dengan basis Web. Data yang digunakan dalam pembangunan sistem bersumber dari online shop www.bhinneka.com karena toko online ini telah dijadikan sumber data pada penelitian yang dilakukan oleh Kusnadi dan Kurniawan [3]. Sedangkan kriteria-kriteria yang digunakan didapat dari hasil penelitian tersebut yaitu harga, harddisk, processor, layar (monitor), Random Access Memory (RAM), berat, baterai dan garansi. Laptop yang dijadikan bahan pertimbangan memiliki sistem operasi Windows. 
 
II. LANDASAN TEORI  
A. WASPAS 
Berikut merupakan penyelesaian perhitungan menggunakan metode WASPAS yang terdiri atas 4 (empat) langkah utama [5].
1. Normalisasi.
Langkah pertama, nilai kriteria diubah ke dalam bentuk yang telah dinormalisasi dengan persamaan (1) di bawah ini  
Ì…= 
-1
Keterangan:  
merupakan nilai kriteria sebelum normalisasi 
Ì…
merupakan nilai kriteria yang telah dinormalisasi  menunjukkan alternatif ke-i  
menunjukkan kriteria ke-j 
Persamaan (1) di atas digunakan untuk kriteria benefit. Kriteria benefit berarti kriteria yang semakin diinginkan apabila nilai kriteria tersebut tinggi sedangkan kriteria cost berarti kriteria yang semakin diinginkan apabila nilai kriteria tersebut rendah. Normalisasi untuk kriteria cost dilakukan dengan persamaan (2) di bawah ini  
Ì…= 
-2 
2. 
Perhitungan dengan WSM menggunakan rumus pada persamaan -3
berikut  
=
âˆ‘
Ì…
âˆ™ 
-3 
Keterangan:
Ì… 
merupakan nilai kriteria yang telah dinormalisasi  
merupakan bobot kriteria  
menunjukkan alternatif ke-i  
menunjukkan kriteria ke-j 
3. Perhitungan dengan WPM dengan rumus pada persamaan-4 berikut  
=
âˆ
(
Ì…
)
(
4
)
4. Perhitungan nilai WASPAS dengan menggabungkan hasil perhitungan WSM dan WPM dengan menggunakan rumus pada persamaan (5) berikut  
=
âˆ™
+
(
(
1
âˆ’
)
âˆ™
-5 
Keterangan:
merupakan nilai WASPAS  
merupakan hasil perhitungan menggunakan WSM  
merupakan hasil perhitungan menggunakan WPM 
merupakan bilangan real antara 0 hingga 1

III. METODE PENELITIAN 
Metodologi penelitian yang digunakan pada penelitian ini adalah sebagai berikut: 
1. Studi Literatur 
Studi literatur dilakukan dengan membaca e-book, artikel, jurnal ilmiah, maupun referensi dari penelitian-penelitian terkait yang mendukung penelitian ini. 
2. Pengumpulan Data 
Pengumpulan data untuk penelitian ini dilakukan dengan survei angket melalui Google Forms menggunakan teknik Accidental Sampling. Penyebaran angket ini bertujuan untuk mengetahui perilaku masyarakat umum terhadap pemilihan laptop. Adapun data-data laptop yang diperlukan akan diambil dari toko online www.bhinneka.com 
3. Perancangan dan Pembangunan Sistem 
Perancangan sistem dilakukan dengan penyusunan diagram flowchart, DFD (Data Flow Diagram), dan ERD (Entity Relationship Diagram). Pembangunan sistem dilakukan menggunakan bahasa pemrograman PHP, Javascript, CSS, dan HTML. 
4. Pengujian dan Evaluasi 
Pada tahap ini akan dilakukan uji coba untuk melihat kesesuaian hasil yang didapat dari jalannya proses sistem yang telah dirancang dan meminimalisir kesalahan maupun kekurangan yang terdapat dalam perancangan sistem. 
5. Penulisan dan Dokumentasi 
Laporan penelitian disusun sebagai dokumentasi hasil pelaksanaan langkah-langkah di atas. 
 
IV.   HASIL PENELITIAN DAN PEMBAHASAN
Adapun perangkat lunak (software) yang digunakan dalam pembangunan website ini adalah sebagai berikut: 
ï‚· Sistem Operasi: Microsoft Windows 10 64-bit 
ï‚· Text Editor: Sublime Text 3 
ï‚· Desain diagram: Draw.io, PowerDesigner 
ï‚· Web server software: Apache 
ï‚· Web browser: Google Chrome 
ï‚· PHP versi 7.2.10 
Sementara perangkat keras (hardware) yang digunakan adalah sebagai berikut: 
ï‚· Komputer: Laptop Lenovo Y700 
ï‚· Processor: IntelÂ®Coreâ„¢ i7-6700HQ CPU @ 2.60GHz 
ï‚· Kapasitas RAM (Random Access Memory): 16 GB
ï‚· GPU (Graphics Processing Unit): NVIDIA GeForce GTX 960M 12 GB 
ï‚· HDD (Hard Disk Drive): 1 TB   
Gambar 1. Tampilan Halaman Home  
Tampilan halaman Home atau halaman utama web dapat dilihat pada Gambar 1 di atas. Di bagian tengah halaman yang terletak diantara header dan footer terdapat carousel yang berisi gambar dan tulisan yang dapat diklik untuk pindah ke halaman yang sesuai dengan teks. Selain itu pengguna juga dapat berpindah halaman menggunakan tombol-tombol yang berada pada bagian header halaman. Tampilan halaman Rekomendasi dapat dilihat pada Gambar 2 di bawah. Pada halaman Rekomendasi, pengguna disajikan pilihan filter yang berfungsi untuk menyaring data berdasarkan merek laptop. Adapun preferensi pengguna dapat diukur dengan menggunakan skala Likert dengan nilai minimum 1 atau Sangat Tidak Penting hingga 5 atau Sangat Penting. Adapun skala preferensi pengguna untuk masing-masing kriteria dibuat berdasarkan penelitian yang dilakukan oleh [2]. Pengguna diperlukan untuk mengisi semua skala Likert sebelum dapat menampilkan rekomendasi dengan menekan tombol Submit yang berada di bagian bawah halaman, sedangkan filter bersifat opsional. 
Gambar 2. Tampilan Halaman Rekomendasi
Setelah pengguna mengisi semua skala likert dan menekan tombol Submit, sistem akan menampilkan hasil rekomendasi kepada pengguna pada halaman Hasil. Tampilan halaman Hasil dapat dilihat pada Gambar 3 di bawah.
Gambar 3. Tampilan Halaman Hasil
Hasil rekomendasi sistem ditampilkan dalam bentuk card yang berjumlah lima buah dengan urutan peringkat dari sebelah kiri ke sebelah kanan. Di dalam masing-masing card, terdapat gambar serta spesifikasi laptop yang direkomendasikan kepada pengguna. Pada bagian bawah halaman terdapat tombol untuk kembali ke halaman Rekomendasi. Pengguna juga dapat berpindah ke halaman lainnya dengan menekan tombol pada header halaman. Uji coba yang dilakukan pada penelitian ini terdiri dari 2 macam yaitu Uji Skenario dan Uji Kepuasan Pengguna. Uji Skenario dilakukan dengan melakukan perhitungan manual terhadap data sampel serta input yang ditentukan secara acak. Uji Skenario bertujuan untuk menguji ketepatan perhitungan pada metode WASPAS. Sedangkan Uji Kepuasan Pengguna dilakukan dengan mengumpulkan data dari responden yang telah menggunakan sistem yang bertujuan untuk mengukur kepuasan responden. Uji kepuasan pengguna dilakukan dengan penyebaran angket kepada pengguna yang telah menggunakan sistem. Hill [6] menyatakan bahwa jumlah sampel yang direkomendasikan lebih besar dari 30 dan kurang dari 500. Pada penyebaran angket ini, terdapat 35 responden yang telah menjawab lima buah pertanyaan. Pertanyaan-pertanyaan yang diajukan bertujuan untuk mengukur kepuasan pengguna berdasarkan landasan teori yang dinyatakan oleh Nelima, dkk [7] mengenai faktor-faktor yang mempengaruhi kepuasan pengguna. Masing-masing pertanyaan diajukan dalam bentuk pernyataan dengan skala jawaban mulai dari 1 (Sangat Tidak Setuju) hingga 5 (Sangat Setuju). Pertanyaan-pertanyaan yang diajukan kepada responden dapat dilihat pada Tabel 1 di bawah.  
Tabel 1. Pertanyaan Angket 
No Pertanyaan 
1 Sistem yang dibangun mudah digunakan 
2 Tampilan informasi dan antarmuka sistem sudah baik 
3 Instruksi dalam penggunaan sistem sudah jelas 
4 Sistem telah menyediakan informasi secara tepat dan akurat 
5 Sistem yang dibangun tergolong bermanfaat  
Hasil penyebaran angket dapat dilihat pada Tabel 2 berikut ini.  
Tabel 2. Hasil Penyebaran Angket 
Nilai 
P1 
P2 
P3 
P4 
P5 
1
1
-2,90%
3
-8,60% 
1 
-2,90% 
1 
-2,90% 
1 
-2,90% 
2 
1
-2,90% 
2 
-5,70% 
1 
-2,90% 
2 
-5,70% 
1 
-2,90% 
3 
13 
-37,10% 
5 
-14,30% 
13 
-37,10% 
3 
-8,60% 
2 
-5,70% 
4 
17 
-48,60% 
22 
-62,80% 
15 
-42,80% 
21 
-60% 
14 
-40% 
5 
3 
-8,50% 
3 
-8,50% 
5 
-14,30% 
8 
-22,80% 
17
-48,50%
Berdasarkan tabel diatas dapat disimpulkan bahwa secara mayoritas responden menjawab Setuju untuk kelima pertanyaan yang diajukan. Persentase terbesar untuk jawaban Sangat Setuju terletak pada Pertanyaan 5, sedangkan persentase terbesar untuk jawaban Sangat Tidak Setuju terletak pada Pertanyaan 2. Dari hasil pengumpulan data, diperoleh hasil perhitungan koefisien reliabilitas Cronbachâ€™s Alpha sebesar 0,83 yang menunjukkan bahwa hasil uji coba kepuasan pengguna tergolong reliable. Kemudian untuk menguji validitas data yang diperoleh dari hasil uji kepuasan pengguna, dilakukan uji validitas dengan melakukan perhitungan koefisien korelasi Pearson Product Moment antara total nilai dengan nilai yang diberikan reponden untuk masing-masing pertanyaan. Hasil uji validasi dapat dilihat pada Tabel 3 di bawah.  
Tabel 3. Hasil Uji Validitas 
No Pertanyaan Nilai Koefisien Korelasi Keterangan 
1 0,76 Valid 
2 0,74 Valid 
3 0,74 Valid 
4 0,89 Valid 
5 0,78 Valid  
Berdasarkan pernyataan dalam penelitian yang dilakukan oleh Gumulya dan Widiastuti [8], nilai-nilai yang diperoleh untuk pertanyaan yang memiliki koefisien korelasi lebih besar atau sama dengan 0,3 dinyatakan valid. 
 
IV. KESIMPULAN 
Berdasarkan hasil penelitian yang dilakukan, disimpulkan bahwa sistem rekomendasi laptop dengan metode WASPAS berbasis web telah berhasil dibangun. Dari hasil uji kepuasan pengguna yang dilakukan melalui penyebaran angket, mayoritas responden menjawab Setuju untuk kelima pertanyaan yang merujuk kepada faktor-faktor yang mempengaruhi kepuasan pengguna [7]. Dari hasil penyebaran angket, didapat nilai koefisien reliabilitas Cronbachâ€™s Alpha sebesar 0,83 yang menunjukkan bahwa  sistem  hasil  uji  coba  kepuasan pengguna  tergolong reliabel. Selain itu, uji validitas menunjukkan bahwa data yang diperoleh tergolong valid. Untuk penelitian selanjutnya, disarankan untuk ditambahkan fitur insert data yang memungkinkan sistem untuk mengambil data secara otomatis dari sumber data, sehingga backend website tidak diperlukan. Disarankan pula untuk menyelidiki lebih lanjut mengenai nilai lambda yang lebih optimal untuk sistem rekomendasi serupa yang menggunakan metode WASPAS. 
 
DAFTAR PUSTAKA 
[1] Setiawan, H. dan Hansun, S. (2014). Rancang Bangun Aplikasi Rekomendasi Pembelian Laptop dengan Metode Fuzzy Database Model Tahani Berbasis Web. Komputa - Jurnal Ilmiah Komputer dan Informatika, 3(2), 86-95. 
[2] Hartanto, T. dan Prasetiyowati, M.I. (2012). Sistem Pendukung Keputusan Pemilihan Laptop Berbasis Web dengan Metode Analytical Hierarchy Process (Studi Kasus: SAMCO COMPUTER). ULTIMATICS, 4(2), 7-15.
[3] Kusnadi, A. dan Kurniawan, E. (2017). Implementation of Topsis Method in Web Based System Recommendations for Students Laptop Selection (Case Study: Bhinneka.com). IJNMT, 4(1), 42-45. 
[4] Fauzan, M.A. (2017). Rancang Bangun Sistem Rekomendasi Pemilihan Smartphone dengan Metode WASPAS Berbasis Web. Skripsi. Universitas Multimedia Nusantara, Tangerang. 
[5] Zavadskas, E.K., Turskis, Z., Antucheviciene, J., dan Zakarevicius, Z. (2012). Optimization of Weighted Aggregated Sum Product Assessment. ELEKTRONIKA IR ELEKTROTECHNIKA, 122(6), 3-6. 
[6] Hill, R. (1998). WHAT SAMPLE SIZE is â€˜ENOUGHâ€™ in INTERNET SURVEY RESEARCH? Interpers. Comput. Technol. J., 6(3-4), 1-10. 
[7] Nelima, P., Mbugua, S.M., dan Kilwake, J. (2016). Factors Affecting Information Systems User Satisfaction in Kenyan Universities. J. Emerg. Trends Comput. Inf. Sci., 7(2), 116-127. 
[8] Gumulya, J. dan Widiastuti, M. (2013). Pengaruh Konsep Diri Terhadap Perilaku Konsumtif Mahasiswa Universitas Esa Unggul. Jurnal Psikologi, 11(1), 50-65.",sistem rekomendasi,WASPAS,preferensi masyarakat dalam memilih laptop,nilai koefisien reabolotas
Penerapan Metode K-Nearest  Neighbor Untuk Sistem Rekomendasi  Pemilihan  Mobil Implementation of K-Nearest Neighbor Method for Car Selection Recommendation System,"Penerapan Metode K-Nearest  Neighbor Untuk Sistem Rekomendasi  Pemilihan  Mobil Implementation of K-Nearest Neighbor Method for Car Selection Recommendation System

Ni Luh Gede Pivin Suwirmayanti  

Abstrak  
Memiliki mobil bagi sebagian besar kalangan masyarakat  bagaikan suatu hal yang pokok dimana dapat membantu mereka dalam beraktivitas khususnya dalam bekerja. Banyaknya varian 
mobil yang ada membuat konsumen atau calon pembeli mengalami kesulitan dalam menentukan pilihan secara tepat dan pasti. Bagi calon pembeli baik perseorangan atau perusahaan ingin secara cepat mendapatkan pilihan mobil sesuai selera atau kebutuhan yang diperlukan.  Kemampuan penerapan metode untuk sistem pendukung keputusan merupakan salah satu alternatif yang tepat saat ini. Algoritma K-Nearest Neighbor (K-NN) ini dipilih karena metode K-NN merupakan suatu bentuk model pendukung keputusan yang dapat megklasifikasikan data berdasarkan jarak terdekat. Sistem ini dirancang untuk membantu calon pembeli dalam memilih mobil berdasarakan tujuan pembelian berupa mobil untuk bisnis, mo bil keluarga, dan mobil angkutan barang, harga, tahun pembuatan, kapasitas penumpang, warna, kapasitas mesin, jenis transmisi. â€œPenerapan Metode K-Nearest Neighbor Untuk Sistem Rekomendasi Pemilihan Mobilâ€ membantu memberikan bayangan ataupun referensi kep ada user atau calon pembeli dalam menentukan pemilihan mobil sesuai kebutuhan.   
 
Kata kunci : KNN, Rekomendasi, Pemilihan, Mobil.  
 
Abstract  
Having a car for most of the community is like a basic thing which can help them in their activities, especially in the work.  The number of variants of existing car makes consumers or prospective buyers have difficulty in determining how accurately and surely. For prospective buyers of either an individual or company wants to quickly get the car selection according to taste or needs required. The applicability of the method for decision support system is one alternative right now. K-Nearest Neighbor algorithm (K-NN) have been selected for K-NN method is a form of 
decision support models to data by the shortest distance. The system is designed to help prospective car buyers in choosing a destination on the terms of the purchase of a car for business, family cars, and car transportation of goods, price, year of manufacture, passenger capacity, color, engine capacity, type o f transmission. """"  Implementation of K-Nearest Neighbor Method for Car Selection  Recommendation System"""" help provide shade or a reference to a user or a prospective buyer in determining the selection of the car as needed.  
 
Keywords: KNN, Recommendations, Selection, Car.  

1. PENDAHULUAN  
Salah satu kebutuhan akan pentingnya pengambilan keputusan adalah dalam penentuan pemilihan mobil. Mobil kependekan dari otomobil yang berasal dari bahasa Yunani â€˜autosâ€™ ( sendiri ) dan Latin â€˜movÃ©reâ€™ ( bergerak ). Mobil merupakan salah satu alat transportasi darat yang penting dan banyak dipakai untuk beraktivitas karena mobil bias digunakan untuk membawa barang dalam jumlah banyak atau menggunakannya untuk tujuan â€“tujuan produktif lainnya, seperti memperlancar jalannya usa ha/bisnis, mengajak keluarga bepergian, dan lain sebagainya. Mobil, selain lebih memudahkan urusan kita dalam bepergian, baik untuk urusan pekerjaan maupun urusan rumah tangga, juga menghindarkan dari resiko kehujanan dan kepanasan.  Memiliki mobil bagi sebagian besar kalangan masyarakat  bagaikan suatu hal yang pokok dimana dapat membantu mereka dalam beraktivitas khususnya dalam bekerja. Oleh karena itu, para produsen mobil berlomba lomba untuk menciptakan mobil dengan keunggulan dan kelebihan yang berbeda sehingga dipasaran jumlah mobil ini sangat banyak dan bervariasi. Dengan banyaknya varian mobil yang ada membuat konsumen atau calon pembeli mengalami kesulitan dalam menentukan pilihan secara tepat dan pasti. Kendala yang sering dialami bagi calon pembeli adalah harus memilih beberapa mobil yang diinginkan secara manual. Bagi calon pembeli baik perseorangan atau perusahaan ingin secara cepat mendapatkan pilihan mobil sesuai selera atau kebutuhan yang diperlukan.  Disamping adanya beragam pilihan tersebut , para konsumen juga dihadapkan dengan banyaknya kriteria yang berpengaruh dalam menentukan pilihan mobil misalnya harga, warna, kapasitas mesin, jumlah penumpang dan lain â€“lain. Kemampuan sistem pendukung keputusan merupakan salah satu alternatif yang tepat saat ini.  Atas permasalahan diatas, untuk membantu user atau calon pembeli dalam hal pemilihan dan memberikan wawasan tentang mobil yang sesuai keinginannya dibutuhkan suatu analisis pengambilan keputusan dari berbagai alternative yang ada. Maka sebuah sistem pendukung keputusan yang dapat merekomendasikan kepada pihak calon pembeli dalam menentukan mobil pilihannya secara cepat, tepat dan akurat. Sistem yang dikembangkan menggunakan algoritma K-Nearest Neighbor (K-NN). Metode ini dipilih karena metode K-NN merupakan suatu bentuk model pendukung keputusan yang dapat mengklasifikasikan data berdasarkan jarak terdekat. K-NN adalah rumus yang paling sederhana yang sering digunakan dalam pengimplementasian pencarian jarak. Rumus yang digunakan dalam perhitungan K-NN adalah rumus Euclidean Distance.  Penelitian terkait dengan judul â€œSistem Pendukung Keputusan Berbasis Sms Untuk Menentukan Status Gizi Dengan Metode K -Nearest Neighborâ€, dalam penelitian membahas mengenai Status gizi seseorang dapat ditentukan mel alui variabel-variabel yang berpengaruh dengan perhitungan menggunakan  salah  satu  metode  klasifikasi  yang  digunakan  dalam  pengambilan  keputusan  dan  dapat  dikerjakan  oleh  komputer,  yaitu  K-Nearest  Neighbor  (KNN). Dengan memanfaatkan kebera daan teknologi SMS, maka user dapat mencari tahu status gizinya dengan alternatif  yang  cepat,  mudah,  dan  murah serta sudah melalui proses pengujian[1].  Terkait degan sistem rekomendasi, berdasarkan penelitian dengan judul â€œ A tourist recommendation and planning application â€ berisikan tentang rekomendasi wisata untuk menawarkan para wisatawan daftar tempat -tempat yang menarik yang dapat digunakan untuk referensi bagi wisatawan [2].  Berdasarkan latar belakang di atas, maka penulis mengambil penelitian den gan judul â€œPenerapan Metode K-Nearest Neighbor Untuk Sistem Rekomendasi Pemilihan Mobilâ€. Dapat menampilkan informasi berdasarakan tujuan pembelian yang meliputi mobil untuk bisnis, mobil 
keluarga, dan mobil angkutan barang, harga, tahun pembuatan, kapasitas penumpang, warna, kapasitas mesin, jenis transmisi. Sehingga calon pembeli mendapat bayangan ataupun referensi dalam menentukan pemilihan mobil sesuai kebutuhan.  

2. METODE PENELITIAN  
Penelitian ini diawali dengan pendefinisian masalah  dan dilanjutkan dengan penerapan dari metode yang digunakan.  
1. Pengumpulan Data  [3] 
#NAME?
Metode pengumpulan data dan informasi dengan cara menggali pengetahuan atau ilmu dari sumber-sumber seperti buku, karya tulis, jurnal ilmiah, makalah, dan sumber lain yang berhubungan dengan objek penelitian.  
#NAME?
Metode pengumpulan data dengan cara melakukan wawancara atau tanya jawab langsung dengan narasumber dan pihak-pihak yang bersangkutan terkait dengan judul yang diambil penulis.  
#NAME?
Dokumentasi merupakan metode pengumpulan data dengan cara mencatat, mencari data, foto-foto terkait penelitian, dan formulir -formulir, dalam hal ini penulis memperoleh data mengenai data yang terkait .  
2. Analisis Sistem  
Analisa Sistem yaitu menganalisa terhadap pe rmasalahan untuk mengetahui dan menentukan batasan-batasan sistem sehigga dapat menentukan cara yang efektif dalam menyelesaikan permasalah tersebut dan dapat dirancang sebuah sistem informasi.  
3. Penerapan Metode K-Nearest Neighbor. Adapun penerapan metode K-NN melalui beberapa langkah:  
a) Tentukan parameter k  
b) Hitung jarak antara data yang akan dievaluasi dengan semua pelatihan  
c) Urutkan jarak yang terbentuk (urut naik)  
d) Tentukan jarak terdekat sampai urutan k  
e) Pasangkan kelas yang bersesuaian  
f) Cari jumlah kelas dari tetangga yang terdekat dan tetapkan kelas tersebut sebagai kelas data yang akan dievaluasi.   Berikut adalah diagram alur penelitian yang dilakukan: 

3. HASIL DAN PEMBAHASAN  
Gambar 2. Penerapan KNN      
Tahap pertama dimulai dari inputan user yang terdiri dari jawaban dan variabel-variabel yang diberikan oleh sistem. Setelah jawaban diinputkan , proses selanjutnya adalah evaluasi data uji dengan data sample calon pembeli menggunakan perhitungan K-NN. Dalam hal ini yang dijadikan 
evaluasi data uji adalah kebutuhan mobil calon pembeli yang kemudian dibandingkan dengan data sample yang sudah ada. Tahapan dari metode K -Nearest Neighbor adalah  [4] : 
1. Menentukan jumlah parameter k (k=5)  
2. Hitung jarak antara data yang akan di evaluasi dengan semua data sample.  
3. Urutkan jarak yang terbentuk (urut naik).  
4. Pilih 5 sample terdekat.  
5. Pilih merk mobil terbanyak yang ada dalam 5 sample mobil tersebut.  
6. Pilih type mobil terbanyak yang ada dalam 5 sample mobil tersebut.  
Gambar 1 Alur Analisis  
7. Tampilkan Output.   
A. Tahap pertama adalah penentuan paramameter k, misal k = 5. Ini berarti 5 sample mobil yang terdekat akan dijadikan rekomendasi.  
B. Setelah semua kriteria tersebut lengkap, barulah dilakukan perhitungan jarak antara data training dengan data sample mobil yang sudah ada. Dalam perhitungan jarak nanti akan digunakan rumus Euclidean Distance.   
Tabel 1 Data Sample Mobil  
Diatas merupakan beberapa sample data mobil yang didapat pada situs-situs mobil, dari sekian sample yang didapatkan akan dihitung dengan data uji dibawah ini:  
Data uji :      
Tabel 2 Data Uji  
Proses perhitungan jarak data sample dengan data uji mobil dilakukan dengan mencocokan variabel atau kriteria yang diinputkan pengguna dengan data sample mobil yang ada dalam database sistem. Rumus : 
Keterangan :             
 = Sampel Data  
 = Data Uji / Testing  
 = Variabel Data  
 = Jarak  
 = Dimensi Data   
Uji coba data uji dengan data sample  mobil pertama yaitu data uji mobil no : x dengan data mobil no : 001  
Tabel 3 Data Sample dan Data Uji  
Perhitungan Jarak Eucledian  antara data uji mobil x dengan data sample mobil 001 adalah :  
ð‘‘1=âˆšâˆ‘(1)2+(âˆ’0,07175)2+(0,5)2+(âˆ’0,25)2+(1)2+(0,22222222 )2+(1)2 ð‘
ð‘–=1   
ð‘‘1=âˆšâˆ‘1+0,00514806 +0,25+0,0625+1+0,04938271 +1ð‘
ð‘–=1 
1x
2x
i
d
p
ï€¨ï€©ïƒ¥
ï€½ï€­ ï€½p
ii i i x x d
12
1 
 ð‘‘1=âˆšâˆ‘3,36703077ð‘
ð‘–=1 
ð‘‘1=1.83494708  
Di bawah ini adalah jarak antara data uji dengan data sample mobil yang telah dihitung menggunakan perhitungan metode K-NN dengan rum us Euclidean Distance:   
Tabel 4 Data Jarak  Anatar Data Uji   
Setelah jarak data sample mobil dihitung maka dapat diurutkan jarak terdekat seperti tabel dibawah ini.   
Tabel 5 Hasil Perhitungan Jarak  
Setelah diurutkan pilih sebanyak k (=5) sample mobil yang mempunyai jarak terdekat dengan data uji yaitu : Mobil dengan no : 007, 004, 005, 003 dan 002. Merk dan tipe mobil yang paling kecil nilainya ini yang akan di rekomendasikan pada mobil baru.  
3.2 DF D ( Data Flow Diagram )  
Alur data dapat digambarkan dengan menggunakan DFD ( Data Flow Diagram ) untuk perancangannya. Untuk tahap awal perancangan digambarkan  dengan diagram konteks.   
3.3. Entity Relationship Diagram  
Hubungan relasi antar yang saling berhubungan antara satu entitas dengan entitas lainnya digambarkan dengan ERD ( Entity Relationship Diagram  ). 
Gambar 3. Diagram Konteks  
Gambar 4.  Entity Relationship Diagram 
3.4 Struktur File  
Penyimpanan  data  pada  sebuah  aplikasi  akan  membutuhkan  suatu  database  yang  terdiri  dari  beberapa  buah  tabel.  Sebuah  tabel  didalam  database  memiliki  tabel -tabelyang  berisi  data-data  yang  disimpan. Berikut adalah gambaran dari tabel dan tabel yang akan digunakan :   
Tabel 6 Tabel data admin  
No Nama Field  Tipe Data  Ukuran Field  Keterangan  
1 Id_admin  integer   Primary Key 
2 username  varchar  50  
3 password  varchar  50  
4 nama_admin  varchar  50  
5 alamat  varchar  200  
6 no_telp  varchar  50  
7 email  Varchar  50   
Tabel 7 Tabel Hitung  
No Nama Field  Tipe Data  Ukuran Field  Keterangan  
1 id_hitung  integer   Primary Key 
2 kode_mobil  char 3  
3 tujuan  float   
4 harga  float   
5 tahun  float   
6 kapasitas  float   
7 warna  float   
8 mesin  float   
9 transmisi  float   
10 ed float   
Tabel 8 Tabel Merk  
No Nama Field  Tipe Data  Ukuran Field  Keterangan  
1 Id_merk  integer   Primary Key 
2 nama_merk  nchar  20  
3 keterangan  varchar  50  
Tabel 9 Tabel Mobil  
No Nama Field  Tipe Data  Ukuran Field  Keterangan  
1 id_mobil  integer   Primary Key  
2 kode_mobil  char 3  
3 id_tipe  integer    
4 id_merk  integer    
5 tujuan  nchar(10)    
6 harga  integer    
7 thn_buat  integer    
8 kapasitas  integer    
9 warna  varchar  10  
10 mesin  integer    
11 jns_transmisi  nchar  10  
12 gbr image    
13 username  varchar  50  
Tabel 10 Tabel Tipe  
No Nama Field  Tipe Data  Ukuran Field  Keterangan  
1 id_tipe  integer   Primary Key 
2 Nama_tipe  varchar  50  
3 keterangan  varchar  50  
3.5 Desain Antarmuka  
Pada tampilan menu rekomendasi mobil ini untuk sisi user umum  yang memiliki hak akses untuk memasukan kriteria â€“ kriteria yang diinginkan. Ada beberapa kriteria nantinya yang akan dimasukan seperti : Tujuan pembelian mobil, Harga, Tahun pembuatan, Warna, Kapasitas Penumpang, Kapasitas mesin, Jenis transmisi dan  Parameter .   
Gambar 5 Desain Menu Rekomendasi Mobil  
Menu data admin memiliki fungsi sebagai informasi data admin. Pada menu data admin, admin dapat menambah data admin, mengedit data admin, mengganti password admin dan 
menghapus data admin. Untuk mengganti password admin, admin harus mengetahui password awal yang digunakan.  

4. KESIMPULAN   
Dari penelitian yang dilakukan, maka dapat disimpulkan hal-hal sebagai berikut :   
1. Berhasil menerapkan metode K-NN ( K-Nearest Neighbor ) untuk Sistem Rekomendasi Pemilihan Mobil dengan menerapkan menerakan dengan kriteria seperti tujuan pembelian mobil, harga mobil, tahun pembuatan mobil, kapasitas penumpang, warna, kapasitas mesin, 
Gambar 7. Menu Admin  
Gambar  6.  Data Mobil  
jenis transmisi , dan  dapat diim plementasikan sebagai   media rekomendasi dalam pemilihan mobil bagi pembeli.  
2. Perancangan diberikan dalam bentuk Data Flow Diagram  untuk perancangan alur data sistem dan  Entity Relationship Diagram  untuk perancangan database, Strukturr file dan Desain Sistem 
 
5. SARAN  
Untuk penelitian lebih lanjut dapat dikombinasikan dengan metode yang lain selain Metode K-NN ( K-Nearest Neighbor ), seperti algoritma K-Means dan dapat dikembangkan menjadi  suatu aplikasi yang berbasis mobile.  
 
UCAPAN TERIMA KASIH  
Penulis  mengucapkan  terima  kasih  kepada STIKOM  Bali yang  telah  memberi dukungan  financial  terhadap  penelitian  dengan  judul  â€œ Penerapan metode K-NN ( K-Nearest Neighbor ) untuk Sistem Rekomendasi Pemilihan Mobil â€. 
 
DAFTAR PUSTAKA   
[1]   Ninki Hermaduanti,  Sri Kusumadewi. Sistem Pendukung Keputusan Berbasis SMS Untuk  Menentukan Status Gizi Dengan Metode K-Nearest Neighbor. Universitas Islam Indonesia. 
2008.  
[2]     Sebastia, L., Garcia, I., Onaindia, E., Guzman, C. e-Tourism: A tourist recommendation and planning application. International Journal on Artificial Intelligence Tools. 2009.  
[3]      Kristanto, Andri, 2008, Perancangan Sistem Informasi dan Aplikasinya, Edisi Revisi, Yogyakarta:   Gava Media.  
[4]     Kusrini, Emha T. Luthfi, 2009, Algoritma Data Mining. Andi, Yogyakarta : Andi",sistem rekomendasi,"K-Nearest Neighbor, K-NN","mobil, wawancara",
SISTEM REKOMENDASI LAPTOP MENGGUNAKAN COLLABORATIVE FILTERING DAN CONTENT-BASED FILTERING,"SISTEM REKOMENDASI LAPTOP MENGGUNAKAN COLLABORATIVE FILTERING DAN CONTENT-BASED FILTERING

Anderias Eko Wijaya1, Deni Alfian2 

Abstract 
Laptop is needed for students and for office workers because it is better than a desktop computer. In this era, laptops have a variety of brands and specifications that sometimes make people have difficulty in finding, choosing or buying the right laptop for their needs. Therefore there should be a recommendation system that can provide advice or recommendations, based on interest and needs in the search for references. In commonly used algorithm recommendation system is collaborative filtering (CF) and content based filtering (CB). Collaborative filtering is a concept whereby the opinions of other users are used to predict items that a user might like / interest. For content based filtering using the availability of an item's content as a basis for recommendation. In this research, the algorithm for collaborative filtering uses Adjusted-cossine similarity to calculate the similarity between user and weighted sum algorithm for prediction calculation, for content based filtering algorithm used is tf-idf to search availability of existing content. This recommendation system combines collaborative filtering and content based filtering methods using mixed hybrid techniques, the system has also been tested using the blackbox method. The result of the required execution time is influenced by the number of items and content based filtering method has the fastest execution time compared to collaborative filtering and mixed hybrid methods. 
 
Keywords : recommender system, collaborative filtering, content based filtering, mixed hybrid, Adjusted-cossine similarity, weightes sum.  

Abstrak 
Sekarang ini laptop sangat diperlukan baik untuk pelajar maupun bagi para pekerja kantor karena kelebihannya dibandingkan dengan komputer desktop. Dengan semakin 
berkembangnya zaman laptop sekarang ini mempunya beragam merk dan spekulasi yang terkadang membuat orang-orang mengalami kesusahan dan kesulitan dalam mencari, memilih ataupun membeli laptop yang tepat dan sesuai bagi kebutuhannya. Maka dari itu harus ada sebuah sistem rekomendasi( recommendation system ) yang dapat memberikan 
saran ataupun rekomendasi laptop berdasarkan ketertarikan dan kebutuhan dalam pencarian referensi. Dalam sistem rekomendasi algoritma yang umum digunakan adalah collaborative filtering(CF)  dan content based filtering(CB) . collaborative filtering  adalah suatu konsep dimana opini dari pengguna lain yang ada digunakan untuk memprediksi item yang mungkin disukai/diminati oleh seorang pengguna. Sadangkan content based filtering  menggunakan ketersediaan konten sebuah item sebagai basis dalam pemberian rekomendasi. Pada penelitian ini algoritma untuk collaborative filtering menggunakan Adjusted-cossine similarity  untuk menghitung kemiripan antar user dan algoritma weighted sum untuk perhitungan prediksinya, sedangkan untuk content based filtering algoritma yang digunakan adalah tf-idf untuk pencarian ketersediaan kontent yang ada. Sistem rekomendasi ini menggabungkan antara metode collaborative filtering dan content based filtering dengan teknik mixed hybrid, sistem ini juga telah diuji menggunakan metode blackbox. Hasil waktu eksekusi yang dibutuhkan dipengaruhi oleh jumlah item dan metode content based filtering memiliki waktu eksekusi tercepat dibandi ngkan metode collaborative filtering dan mixed hybrid. 
 
Kata kunci : sistem rekomendasi, collaborative filtering, content based filtering, mixed hybrid, Adjusted-cossine similarity, weightes sum . 

PENDAHULUAN   
Sekarang ini laptop sangat diperlukan baik untuk pelajar maupun bagi para pekerja kantor karena kelebihannya dibandingkan dengan komputer desktop. Dengan semakin berkembangnya wqzaman laptop sekarang ini mempunya beragam merk dan spesifikasi yang terkadang membuat orang-orang mengalami kesusahan dan kesulitan dalam mencari, memilih ataupun membeli laptop yang tepat dan sesuai bagi kebutuhannya. Dengan masalah tersebut tentunya orang-orang akan terbantu jika ada yang dapat merekomendasikan laptop yang sesuai bagi kebutuhannya. Maka dari itu harus ada sebuah sistem rekomendasi (recommendation system ) yang dapat memberikan saran ataupun rekomendasi laptop berdasarkan ketertarikan dan kebutukan dalam pencarian referensi. Dalam sistem rekomendasi (recommendation system) algoritma yang umum digunakan adalah collaborative filtering (CF)  dan content based filtering(CB) . collaborative filtering(CF)  terbagi atas dua jenis yaitu user-based CF dan item-based CF. User-based Collaborative Filtering berasumsi bahwa cara yang baik dalam menemukan konten yang dirasa akan disukai oleh konsumen adalah dengan menemukan orang lain dengan ketertarikan yang sama dengan konsumen tersebut, kemudian merekomendasikan hal yang disukai oleh orang lain tersebut kepada konsumen (handrico, 2012). Item-based Collaborative Filtering  berasumsi bahwa jika mayoritas pengguna memberi penilaian beberapa item secara serupa, pengguna yang kita targetkan juga akan memberi penilaian terhadap item-item tersebut secara serupa dengan mayoritas pengguna lain (Sarwar, 2001).. Berbeda dengan content-based filtering  yang mana tidak seperti collaborative filtering  yang menggunakan parameter semacam rating untuk menghasilkan rekomendasi. Melainkan menggunakan deskripsi dari profil pengguna, atau dari deskripsi suatu item untuk menghasilkan suatu rekomendasi (Ricci, 2011).  
Beberapa penelitian yang pernah dilakukan untuk menyelesaikan masalah sistem rekomendasi, diantaranya : sistem rekomendasi pencarian pekerjaan berbasis web menggunakan metode hybrid-based recommendation (nurul,2013) dimana menggabungkan content based dan collaborative filtering  dengan menggunakan algoritma decision tree  dan nears neighbour dalam menghasilkan rekomendasi, selanjutnya 
ada juga yang menggunakan multi-criteria rating  yang di implementasikan menggunkan hybrid (content based dan collaborative Filtering)  pada sistem rekomendasi software antivirus dengan multi-criteria rating  (Arifin,2014), banyak metode kombinasi dalam penggabungan antara content based dan collaborative Filtering  salah satunya menggunakan switching hybrid  dimana sistem memanfaatkan dua metode 
sekaligus, jika salah satu metode gagal menghasilkan prediksi atau memiliki nilai confident yang kecil maka akan 
digunakan metode yang lain, seperti yang digunakan pada sistem rekomendasi pengambilan mata kuliah pilihan menggunakan metode hybrid (Naufal, 2013). Berdasarkan latar belakang di atas, maka didapat sebuah masalah yaitu: 
a) Sulitnya dalam memilih ataupun membeli laptop yang tepat dan sesuai keinginan. 
b) Dibutuhkannya suatu  sistem yang dapat memberikan rekomendasi atau saran dalam memilih ataupun membeli laptop. 
Adapun tujuan dalam penelitian yang dilakuan ini adalah sebagai berikut:  
a) Membuat sebuah sistem rekomendasi laptop menggunakan collaborative filtering dam content based filtering . 
b) Menjelaskan kelebihan dan kekurangan dari setiap metode. Manfaat dari penelitian ini adalah sebagai berikut:  
a) Mempermudah dalam memilih ataupun membeli laptop yang sesuai. 
b) Sebagai salah satu alternatif untuk membantu memberikan rekomendasi dan saran laptop yang sesuai. 
 
METODE PENELITIAN 
Beberapa metodologi untuk pengerjaan Tugas Akhir ini adalah sebagai  berikut : 
1. Identifikasi Masalah 
Pertama-tama masalah yang akan dipecahkan diidentifikasi terlebih dahulu supaya bisa mengetahui secara detail inti dari permasalahan yang akan diselesaikan dan juga bagaimana langkah-langkah dan metode yang akan diambil untuk menyelesaikan masalah tersebut  
2. Perancangan sistem 
Di tahap ini penulis mulai merancang kebutuhan-kebutuhan sistem  seperti dataset yang dibutuhkan, metode-metode yang akan dilakukan, dan  juga hasil yang diharapkan.  
3. Implementasi dan analisis sistem  
Implementasi sistem dilakukan dalam dua tahap sebagai berikut : 
a. Mengimplementasikan dan menguji metode item-based  collaborative filtering dengan langkah-langkah sebagai berikut : 
1. Melakukan pemrosesan data rating dari suatu item untuk mendapatkan data pengguna yang telah merating item.  
2. Menghitung similarity antara item satu dengan lainnya menggunakan metode cosine similarity berdasarkan rating yang diberikan pengguna. 
3. Melakukan perhitungan prediksi rating pengguna pada suatu item menggunakan metode weighted sum.  
b. Mengimplementasikan dan menguji metode content-based filtering dengan langkah-langkah sebagai berikut :  
1. Melakukan pemprosesan data profil pengguna yang digunakan sebagai query.  
2. Menghitung bobot TF-IDF (term frequency-inverse document frequency) pada tiap-tiap content laptop berdasarkan query.  
3. Menggunakan bobot TF-IDF untuk menghasilkan rekomendasi laptop. 
4. Menyimpulkan hasil dari penelitian Setelah hasil dianalisis dan dievaluasi, terdapat sebuat kesimpulan yang bisa diambil dan diharapkan berguna  bagi kemajuan topik yang penulis teliti. 

KAJIAN TEORI 
Collaborative filtering 
Collaborative filtering  adalah suatu konsep dimana opini dari pengguna lain yang ada digunakan untuk memprediksi item yang mungkin disukai/diminati oleh seorang pengguna (Ricci , 2011).  Kualitas rekomendasi yang diberikan dengan menggunakan metode ini sangat bergantung dari opini pengguna lain (neighbor ) terhadap suatu item. Belakangan diketahui bahwa melakukan reduksi neighbor  (yaitu dengan memotong neighbor  sehingga hanya beberapa pengguna yang memiliki kesamaan / similiarity  tertinggi sajalah yang akan digunakan dalam perhitungan) mampu meningkatkan kualitas rekomendasi yang diberikan (Adomavicious dan Kwon, 2007).  
Collaborative filtering memberikan rekomendasi berdasarkan kumpulan dari pendapat, minat dan ketertarikan  beberapa user yang biasanya diberikan dalam bentuk rating yang diberikan user kepada suatu item. Untuk memperoleh data rating dari user yang digunakan dalam sistem rekomendasi, dibedakan menjadi dua cara (Wibowo,2010) yaitu: 
1) Secara Eksplisit , yaitu proses pengumpulan data dimana user memberikan  data secara sadar/ sengaja. 
2) Secara Implisit , yaitu proses pengumpulan data dimana user tidak menyadari bahwa ia telah memberikan masukan terhadap sistem. 
Pendekatan collaborative filtering  pada dasarnya dibagi menjadi dua kategori yaitu user-based collaborative filtering  disebut juga memory-based , dan item based collaborative filtering  yang disebut juga model-based , Pada pendekatan user based collaborative filtering  sistem memberikan rekomendasi kepada user item-item yang disukai atau dirating oleh user â€“ user lain yang memiliki banyak kemiripan dengannya. Misalnya, user a menyukai atau merating item 1,2 dan 3, kemudian user b menyukai item 1,2 dan 4 maka sistem akan merekomedasikan item 3 kepada user b dan item 4 kepada user a. Kelebihan dari pendekantan user based collaborative filtering adalah dapat menghasilkan rekomendasi yang berkualitas baik. Sedangkan kekurangannya adalah kompleksitas perhitungan akan semakin bertambah seiring dengan bertambahnya pengguna sistem, semakin banyak pengguna (user) yang menggunakan sistem maka proses perekomendasian akan semakin lama (handrico, 2012).  
Pendekatan item based collaborative filtering  memberikan rekomendasi berdasarkan kemiripan antar item. Metode ini merupakan metode rekomendasi yang didasari atas adanya kesamaan antara pemberian rating terhadap suatu item dengan item yang pernah dirating user lain (handrico,2009). Item yang telah di rating oleh user akan menjadi patokan untuk mencari sejumlah item lainnya yang berkorelasi dengan item yang telah dirating user. Motivasi kunci dibalik metode ini adalah user akan cenderung menyukai item yang sejenis atau mempunyai korelasi dengan item yang telah disukainya (Sarwar, 2001). Secara umum proses pemberian rekomendasi pada collaborative filtering terdiri atas 2 langkah (Sarwar, 2001), yaitu: Penemuan similar  item dan Penghitungan prediksi. Terdapat beberapa algoritma untuk menemukan similar item, yaitu: (Sarwar,2001)  
1. Algoritma Cosine-based 
Similarity  Pada kasus ini dua item dianggap sebagai 2 vektor. Kesamaan antara 2 item ini diukur dengan menghitung kosinus dari sudut antara 2 vektor item. Item dibandingkan misalnya u dan v, dianggap sebagai sebuah vektor baris dengan anggotanya adalah nilai rating yang diberikan terhadap kedua item tersebut. Dua vektor dikatakan sama jika membentuk sudut atau nilai kosinusnya 1. Dengan kata lain dua item dikatakan mirip jika nilai kosinus dari perhitungan mendekati 1 (Wiranto, 2010).  
Dimana âƒ— dan  
merupakan vektor vektor baris dengan anggota nilai rating pada item i dan item j. Cos (
 ,
 ) merupakan nilai cosinus sudut yang dibentuk vektor baris ratingitemi dan j. 
2. Algoritma Correlation-based Similarity  
Pada algoritma ini kemiripan antara dua item i dan j diukur dengan menghitung korelasi Pearson-r correlation. Agar perhitungan korelasi yang diperoleh akurat, terlebih dahulu dilakukan pemisahan terhadap co-rateditems (item-itemyang keduaitem i dan j nya di-rating oleh user).  
3. Adjusted-cossine similarity  
Persamaan adjusted cosine similarity  digunakan untuk menghitung nilai kemiripan antar item. Perhitungan kemiripan ini merupakan modifikasi dari perhitungan kemiripan berbais vektor dimana dengan melihat fakta bahwa setiap user memiliki skema rating yang berbeda-beda. Terkadang user memberi rating yang tinggi terhadap item a disisi lain user memberi rating yang sangat rendah pada item b. Maka Filtering  Dan Content-Based 
Filtering  dari itu untuk setiap rating dikurangi dengan rata-rata rating yang diberikan user.  
Keterangan :  
sim(i,j)  = Nilai kemiripan antara item i 
dan item j. 
= Himpunan user u yang merating item i dan item j. 
= Rating user u pada item i. 
= Rating user u pada item j. 
= Nilai rata-rata rating user u  
Untuk menghitung nilai kemiripan (similarity) antar 2 item, diperlukan himpunan user yang me-ratingitem tersebut.Nilai yang dihasilkan pada persamaan adjusted-cosine similarity  adalah berkisar antara +1.0 dengan -1.0.Item dianggap saling berkolerasi jika nilai similarty antara kedua item tersebut mendekati +1, begitu juga sebaliknya item dianggap tidak berkolerasi apabila nilai similarty-nya mendekati -1.  Content based filtering Sistem rekomendasi berbasis konten (Content-based Recommendation System ) menggunakan ketersediaan konten (sering juga disebut dengan fitur, atribut atau karakteristik) sebuah item sebagai basis dalam pemberian rekomendasi (Ricci, 2011). Sebagai contoh, sebuah film mempunyai konten seperti genre, author, tahun rilis, dan lain-lain, atau sebuah file dokumen memiliki konten berupa tulisan yang ada di dalamnya.  Metode content-based filtering biasa digunakan untuk merekomendasikan berita, artikel maupun situs web. Metode tersebut akan mengekstrak informasi yang terdapat pada item kemudian membandingkannya dengan informasi item yang pernah dilihat atau disukai oleh user.  Teknik â€“ teknik yang digunakan dalam content-based seperti TF-IDF, Bayesian Classifiers, Cluster analysis, decision trees dan artificial neural networks. Sistem rekomendasi berbasis konten memiliki beberapa kelebihan, yaitu (Afifi, 2014): 
a. Sistem rekomendasi berbasis konten dapat menjelaskan 
bagaimana hasil rekomendasi didapatkan. 
b. Sistem rekomendasi berbasis konten dapat merekomendasikan item-item yang bahkan belum pernah di-rate oleh siapapun. Namun, sistem rekomendasi berbasis konten juga memiliki beberapa kelemahan, yaitu (Arifin, 2014): 
c. Sistem rekomendasi berbasis konten memerlukan sebuah profil user yang berisikan ketertarikan dan minat pengguna. Bagi pengguna baru yang  belum pernah melakukan aktivitas apapun dan tidak memiliki profil user  yang cukup, sistem rekomendasi tidak dapat memberikan rekomendasi  yang handal kepadanya ( Cold Start Problem ).  Hybrid recommendation Masing-masing teknik sistem rekomendasi memiliki kelebihan dan kelemahannya tersendiri. Karenanya, sistem rekomendasi hybrid yang menggabungkan kekuatan dari model dan algoritma yang berbeda untuk mengatasi masalah-masalah yang telah 
disebutkan di atas menjadi target penelitian yang sedang marak dikembangkan (Jannach, 2011). Adapun tujuh teknik kombinasi untuk hybridization (burke, n.d): 
1. Weighted  : bobot dari dua atau lebih metode rekomendasi digabungkan  secara numerik 
2. Switching  : sistem memilih salah satu atau lebih metode rekomendasi dan menerapkan salah satu metode rekomendasi yang dipilih. 
3. Mixed  : teknik rekomendasi dari berbagai metode ditampilkan menampilkannya secara bersamaan. 
4. Feature Combination  : output dari salah satu teknik rekomendasi digunakan sebagai input yang lain. 
5. Feature Augmentatio  : fitur-fitur dari sumber data rekomendasi yang berbeda digabung bersama-sama ke dalam algoritma rekomendasi tunggal. 
6. Cascade  : satu rekomender mengolah rekomendasi yang diberikan oleh  yang lainnya.  
7. Meta-level  : model dipelajari oleh satu rekomender yang digunakan sebagai inputan yang lainnya. 
 
ANALISA 
Collaborative filtering Untuk dapat memberikan rekomendasi laptop menggunkan metode collaborative filtering  dibutuhkan data informasi rating dari setiap user yang telah memberi rating terhapap suatu item atau laptop. Dari data rating terbebut nantinya akan dihitung nilai kemiripannya menggunakan algoritma adjusted cossine similarity  dan melakukan bobot perhitung prediksi menggunakan algoritma weighted sum . langkah-langkah atau proses perhitungan menggunakan metode collaborative filtering  adalah sebagai 
berikut : 
1. pemberian rating 
Dalam hal ini kita membutuhkan data rating yang berisi data user yang telah merating suatu item. Untuk skala pemberian ratingnya adalah antara 1-5, sebagai contoh kita memiliki data nilai rating user terhapap item sebagai berikut :  
Tabel 1 data rating 
laptop a 
laptop b 
laptop c 
laptop d 
laptop e 
laptop f 
rata-rata rating user 1  5 4 3   4 
user 2   3 2 4 1 2,5 
user 3  3    3 3 
user 4 4   1   2,5 
user 5  2 2 4  5 3,25 
user 6  5  4   4,5  
2. menghitung kemiripan antar item Setelah data rating terbentuk langkah selanjutnya adalah menghitung nilai kemiripan antar item menggunakan algoritma adjusted cossine similarity , berikut adalah langkah-langkah dalam menghitung kemiripan dengan algoritma adjusted cossine similarity  : 
Rumus yang digunakan dalam adjusted cossine similarity adalah :  
Keterangan : 
sim(i,j)  = Nilai kemiripan antara item i dan item j. 
= Himpunan user u yang merating item i dan item j. 
= Rating user u pada item i. 
= Rating user u pada item j. 
= Nilai rata-rata rating user u 
Berikut adalah perhitungan algoritma adjusted cossine similarity : Perhitungan nilai kemiripian dilakukan jika terdapat 2 atau lebih rating dari user 
Filtering lain terhadap kedua item tersebut, sebagai contoh kita akan menghitung nilai kemiripan antara laptop a dan 
laptop d. 
dari perhitungan tersebut diperoleh nilai kemiripan antara laptop a dan laptop d adalah -1. Lakukan perhitungan pada semua item hingga  hasilnya menjadi seperti tabel di bawah ini : 
Tabel 2 nilai kemiripan antar item 
laptop a 
laptop b 
laptop c 
laptop d 
laptop e 
laptop f 
laptop a 1 0 0 -1 0 0 
laptop b 0 1 0,78 -0,96 0 -1 
laptop c 0 0,78 1 -0,65 1 -0,94
laptop d -1 -0,96 -0,65 1 -1 0,99 
laptop e 0 0 1 -1 1 -1 
laptop f 0 -1 -0,94 0,99 -1 1  
3. menghitung bobot prediksi 
Setelah kita mendapatkan nilai kemiripan antar item langkah terakhir dalam menghasilkan rekomendasi adalah dengan menghitung nilai bobot prediksi dengan menggunakan algoritma weighted sum. Berikut adalah rumus dari algoritma weighted sum: 
Keterangan : 
= Prediksi untuk user u pada item j. 
= Himpunan item yang mirip dengan item j. 
= Rating user u pada item i. 
= Nilai kemiripan antara item i dan item j. 
Misal kita akan menghitung bobot prediksi user 1 terhadap laptop a sebagai berikut : 
Dari perhitungan di atas kita bisa lihat bahwa bobot prediksi user1 terhadap laptop a adalah -3. Lakukan perhitungan prediksi pada semua user terhadap setiap laptop. Hasilnya dapat dilihat pada tabel 3 dibawah ini:  
Tabel 3 bobot prediksi 
Dari tabel 3 dapat dilihat bahwa yang memiliki bobot nilai yang mendekati 1 adalah item yang akan direkomendasikan, dengan begitu member 1 mendapatkan rekomendasi laptop e, member 2 mendapatkan rekomendasi laptop b dan seterusnya.  
Metode collaborative filtering memiliki beberapa kelebihan yaitu rekomendasi tetap akan berkerja dalam keadaan dimana konten sulit dianalisi sekalipun, namun metode ini juga memiliki kekurangan yaitu membutuhkan parameter rating, sehingga jika ada item baru sistem tidak akan merekomendasikan item tersebut.  
Content based filtering 
Dalam content based filtering  kita tidak membutuhkan parameter rating dalam menghasilkan rekomendasi melainkan dengan deskripsi dari suatu item atau deskripsi dari profil pengguna sesuai dengan konten/fitur yang diinginkannya 
untuk menghasilkan rekomendasi. Untuk mendapatkan data konten dari suatu item atau pun profil pengguna kita bisa menggunakan algoritma TF-IDF dalam pemprosessan datanya dalam mendapatkan nilai bobot pada tiap-tiap laptop. Tahapannya sebagai berikut :  
1. Menentukan query term  
Sebagai contoh misal user1 ingin rekomendasi laptop dengan spesifikasi yang disukainya sebagai berikut : 
Tabel 4 spekulasi user 
Brand apple, asus 
Series Aspire,MacBook-
Air,MacBook-Pro 
OS Linux Mac- OS-X 
Tahun rilis 2016 
Ukuran layar 14 inch 
Resolusi layar 1366-x-768 pixel 
Prossesor Intel-Core- i5 
kecepatan 2.2 Ghz 
Ram 4 GB 
Storage 512 GB 
Harga 6149000 
Dari tebel 4 diatas data dari spekulasi laptop yang user sukai digabungkan untuk menjadi sebuah query , untuk pembuatan dokumennya hanya spesifikasi laptopnya saja yang diambil dan digabungkan untuk menjadi dokumen. 
Tabel 5 dokument data laptop 
Doc Isi dokument 
Q apple, asus|Aspire,MacBook-
Air,MacBook-Pro|Linux Mac-
OS-X|2016|14 ich|1366-x-
768|Intel-Core-i5|2.2 Ghz|4 
gb|512 gb|6149000 
1 Nama : Aspire E5-475G | Core i5-7200U Spesifikasi: acer|aspire|DOS|2015|14 inch|1366 x 768 pixel|Intel Core i5|2.5 Ghz|4 gb|1000 gb|6149000 
2 Nama : Acer Aspire ES1-432-C56Y / C5GA / C52R 
Spesifikasi: acer|aspire|linux|2016|14 inch|1366 x 768 pixel|Intel Celeron|1.1 Ghz|2 gb|500 gb|3150000 
3 Nama : Apple Macbook Pro MF839 Retina Spesifikasi: apple|MacBook Pro|Mac OS X|2014|13 inch|2560 x 1600 pixel|Intel Core i5|2.7 Ghz|8 gb|128 gb|14454000 
4 Nama : Apple MacBook Air MMGG2 Spesifikasi: apple|MacBook Air|Mac OS X|2016|13 inch|1440 x 900 pixel|Intel Core i7|2.2 Ghz|8 gb|512 gb|13954600 
5 Nama : Asus X441SA-BX001D / BX002D / BX003D / BX004D Spesifikasi: asus|x series|DOS|2016|14 inch|1366 x 768 pixel|Intel Celeron|2.48 Ghz|2 gb|500 gb|3185000 
6 Nama : Asus A455LA-WX667D / WX668D / WX669D 
Spesifikasi: asus|x series|DOS|2016|14 inch|1366 x 768 pixel|Intel Core i3|2 Ghz|4 gb|500 gb|4725000  
2. Perhitungan bobot TF-IDF 
Dalam mmenghitung bobot TF-IDF dipakai rumus sebagai berikut: 
Keterangan : 
W : bobot setiap dokumen 
TF : jumlah kemunculan kata atau 
term dalam dokumen 
D = jumlah semua dokumen 
DF = jumlah dokumen yang 
mengandung kata (term) 
IDF = inverse document frequency  
Berikut adalah perhitungan untuk TF, DF dan IDF :  
Tabel 6 perhitungan TF,DF dan IDF 
Query TF DF D/DF IDF IDF+
1 d
1 d
2 d
3 d
4 d
5 d
6Apple     1 1     2 3 0,477121 1,477121
Asus         1 1 2 3 0,477121 1,477121
Aspire 1 1         2 3 0,477121 1,477121
MacBook air       1     1 6 0,778151 1,778151
MacBook pro     1       1 6 0,778151 1,778151
Linux   1         1 6 0,778151 1,778151
2016   1   1 1 1 4 1,5 0,176091 1,176091
Mac OS X     1 1     2 3 0,477121 1,477121
Intel-Core-i5 1   1       2 3 0,477121 1,47712114
inch 1 1     1 1 4 1,5 0,176091 1,1760911366
-x-768 1 1     1 1 4 1,5 0,176091 1,1760912.2 
Ghz       1     1 6 0,778151 1,778151
4 GB 1         1 2 3 0,477121 1,477121512
GB       1     1 6 0,778151 1,7781516149000 1           1 6 0,778151 1,778151 
Selanjutnya menghitung nilai bobot  TF-IDF sebagai berikut :  
Tabel 7 Bobot TF-IDF 
W = TF * IDF + 1 
d1 d2 d3 d4 d5 d6 
0 0 1,47712
1255 1,477
121 0 0 
0 0 0 0 1,477
121 1,477
121 1,47712
1255 1,477
121 0 0 0 0 
0 0 0 1,778
151 0 0 
0 0 1,77815
125 0 0 0 
0 1,778
151 0 0 0 0 
0 1,176
091 0 1,176
091 1,176
091 1,176
091 0 0 1,47712
1255 1,477
121 0 0 1,47712
1255 0 1,47712
1255 0 0 0 1,17609
1259 1,176
091 0 0 1,176
091 1,176
091 1,17609
1259 1,176
091 0 0 1,176
091 1,176
091 0 0 0 1,778
151 0 0 1,47712
1255 0 0 0 0 1,477
1210 0 0 1,778
151 0 0 1,77815
125 0 0 0 0 0 
Jumlah bobot setiap dokumen 8,561697533 6,783546 6,209515015 9,464788 5,005395 6,482516 Hasil dari perhitungan bobot diatas diketahui bahwa nilai bobot tertinggi terdapat pada document 4 bernilai 9,464788, sehingga rekomendasi laptop untuk user1 adalah d4.  Metode content-based filtering memiliki beberapa kelebihan yaitu : dapat memberikakan rekomendasi item yang belum pernah dirating sekalipun, kekurangan metode ini adalah tidak dapat merekomendasikan item bagi user baru yang belum pernah melakukan aktivitas apapun. 
 
HASIL DAN PENGUJI AN 
Implementasi antar muka 
1. Member ( halaman awal )   
Merupakan tampilan awal bagi member saat berhasil login dengan benar. 
Gambar 2 halaman awal bagi member/user  
2. Member (profil likes )   
Merupakan tampilan bagi member untuk mengisi ketertarikan laptop yang diinginkan.  
Gambar 3 halaman profil likesbagi member/user 
3. Member( banding laptop)   
Tampilan yang digunakan untuk membandingan spekulasi laptop.  
Gambar 4 halaman laptop banding bagi member/user  
Pengujian metode 
Pada pengujian metode dilakukan dengan cara membandingkan perhitungan manual dengan perhitungan yang dihasilkan oleh sistem untuk menguji kebenaran sistem rekomendasi laptop menggunakan collaborative filtering  dan content based filtering .  
Hasil pengujian metode 
1. Collaborative filtering 
Berikut adalah perhitungan collaborative filtering  untuk merekomendasikan laptop untuk user1 dibawah ini merupakan data laptop yang dipakai. 
Tabel 8 laptop data 
item Nama 
1 Aspire E5-475G | Core i5-7200U 
2 Acer Aspire ES1-432-C56Y / C5GA / C52R 
3 Apple Macbook Pro MF839 Retina 
4 Apple MacBook Air MMGG2| 
5 Asus X441SA-BX001D / BX002D / BX003D / BX004D /BX005D 
6 Asus A455LA-WX667D / WX668D / WX669D 
7 Sony Vaio SVD13213SG 
8 Sony Vaio SVF14216SG 
9 Dell Inspiron 14-3458  
10 Dell XPS 13 | Core i5-5200U 
Berikut adalah matrix user x item antara rating item user1 dengan pengguna lain : 
Tabel 9 rating user1 dan pengguna lain 
  i
1 i
2 i
3 i
4 i
5 i
6 i
7 i
8 i
9 i
10 Rata-rata 
u1
 3 4 2 5 4 
3
3,5
u
2
5
4
3
4
u
3
2
2
    5 3 
u
4
3
4
3,5
u
5 5 3 
    5 2 
3,75
Kemudian, hitung kemiripan antar item dengan rumus adjusted cossine similarity  : 
berikut adalah matrik kemiripan antar item dari hasil perhitungan diatas : 
tabel 10 kemiripan antar item 
 i1 i2 i3 i4 i5 i6 i7 i8 i
9 I10 
i1  -1 0 0 0 0 1 -1 0 0 
i2 -1  -1 1 -1 -1 -1 0.
95
24 -
1 0 
i3 0 -1  -1 0.
64
71 1 0 -1 0 -1 
i4 0 1 1-  -1 -1 0 1 0 0 
i5 0 -1 0.
64
71 -1  1 0 -
0.
44
7 0 -1 
i6 0 -1 1 -1 1  0 -1 0 0 
i7 1 -1 0 0 0 0  -1 0 0 
i8 -1 0.
95
24 -1 1 -
0.
44
7 -1 -1  0 0 
i9 0 -1 0 0 0 0 0 0  0 
i1
0 0 0 -1 0 -1 0 0 0 0  
hasil perhitungan kemiripan yang dilakukan oleh sistem, terlihat bahwa hasil dari perhitungan manual dan hasil dari perhitungan oleh sistem rekomendasi mimiliki hasil yang sama.   Selanjutnya adalah perhitungan prediksi menggunakan algoritma weighted sum : 
Hasil yang diperoleh dengan menghitung secara manual dengan hasil yang diperoleh oleh sistem sama. Oleh karena itu dapat disimpulkan bahwa implementasi metode collaborative filtering  dalam sistem rekomendasi laptop sudah dilakukan dengan benar. 
2. Content based filtering 
Untuk data laptop yang digunakan sebanyak 10 item dan algoritma content based filtering yang digunakan adalah td-idf, untuk perhitungan manualnya sebagai berikut:data user profil untuk user1:  
Tabel 11 user profil 
Brand Apple Sony 
Series MacBook-Air MacBook-Pro Vaio 
OS Windows-10 Windows-8 
Tahun rilis 2016 
Ukuran layar 14 inch 
Resolusi layar 1366-x-768 pixel 
Prossesor Intel-Core- i5 
kecepatan 2.2 Ghz 
Ram  4 GB 
Storage 1000 GB 
Harga 14454000 Buat query dari data user profil dan dokument ynag diambil hanya spekulasinya saja dari data laptop hasilnya sebagai berikut :  
Table 12 dokument 
Doc Isi dokument 
Q Apple, Sony, Aspire, MacBook-Air, MacBook-Pro, Vaio, Windows-10, Windows-8, 2016, 14-ich, 1366-x-768-pixel, Intel-Core-i5, 2.2-Ghz, 4 gb, 1000-gb, 14454000 
1 Aspire E5-475G | Core i5-7200U acer|aspire|DOS|2015|14 inch|1366 x 768 pixel|Intel Core i5|2.5 Ghz|4 gb|1000 gb|6149000 
2 Acer Aspire ES1- 432-C56Y / C5GA / C52R acer|aspire|linux|2016|14 inch|1366 x 768 pixel|Intel Celeron|1.1 Ghz|2 gb|500 gb|3150000 
3 Apple Macbook Pro MF839 Retina apple|MacBook Pro|Mac OS X|2014|13 inch|2560 x 1600 pixel|Intel Core i5|2.7 Ghz|8 gb|128 gb|14454000 
4 Apple MacBook Air MMGG2 apple|MacBook Air|Mac OS X|2016|13 inch|1440 x 900 pixel|Intel Core i7|2.2 Ghz|8 gb|512 gb|13954600 
5 Asus X441SA-BX001D / BX002D / BX003D / BX004D / BX005D asus|x series|DOS|2016|14 inch|1366 x 768 pixel|Intel Celeron|2.48 Ghz|2 gb|500 gb|3185000 
6 Asus A455LA-WX667D / WX668D / WX669D |asus|x series|DOS|2016|14 inch|1366 x 768 pixel|Intel Core i3|2 Ghz|4 gb|500 gb|4725000 
7 Sony Vaio SVD13213SG |Sony|vaio|window 8|2014|13|1366 x 768 pixel|Intel Core i5|1.6|4|128|24750000 8 Sony Vaio SVF14216SG sony|vaoi|window 8|14|1366 x 768||Intel Core 
i31.9|2|500|7493000 
9 Dell Inspiron 14-3458 | Core i3-4005U dell|Inspiron|DOS|2014|14|1366 x 768|Intel Core i3|2.2|4|500|4640000 
10 Dell XPS 13 | Core i5-5200U dellXPS|Windows 10|2015|13|1366 x 768|Intel Core i5|2.3|8|128|13400000 
Perhitungan manual untuk menentukan nilai TF sebagai berikut : 
Tabel 13 perhitungan nilai TF 
query Tf d
1 d
2 d
3 d
4 d
5 d
6 d
7 d
8 d
9 d
1
0
Apple     1 1             
sony             1 1     
MacBook air       1             
MacBook pro     1               
vaio             1 1     
window 10                   1  
window 8             1 1     
2016   1   1 1 1         
14 inch 1 1     1 1   1 1   
1366-x-768 pixel 1 1     1 1 1 1 1 1 
Intel-Core- i5 1   1       1     1 
2.2 Ghz       1         1   
4 GB 1         1 1   1   
1000 GB 1                   
14454000     1               
Menghitung nilai IDF sebagai berikut: 
Tabel 14 perhitungan nilai IDF DF 
d/df 
Idf 
idf + 1  
2 5 0,698970004 1,698970004 
2 5 0,698970004 1,698970004 
1 10 1 2 
1 10 1 2 
2 5 0,698970004 1,698970004 
1 10 1 2 
2 5 0,698970004 1,698970004 
4 2,5 0,397940009 1,397940009 
6 1,666666667 0,22184875 1,22184875 
8 1,25 0,096910013 1,096910013 
4 2,5 0,397940009 1,397940009 
2 5 0,698970004 1,698970004 
4 2,5 0,397940009 1,397940009 
1 10 1 2 
1 10 1 2 
Perhitungan manual untuk bobot tf-idf sebagai berikut : 
Tabel 15 perhitungan bobot TF-IDF 
W=TF * (idf+1) 
d1 d2 d
3 d
4 d5 d6 d
7 d8 d9 d
1
0
0 0 1,
6
9
8
9
7 1,
6
9
8
9
7 0 0 0 0 0 0 
0 0 0 0 0 0 1,
6
9
8
9
7 1,
69
89
7 0 0 
0 0 0 2 0 0 0 0 0 0 
0 0 2 0 0 0 0 0 0 0 
0 0 0 0 0 0 1,
6
9
8
9
7 1,
69
89
7 0 0 
0 0 0 0 0 0 0 0 0 2 
0 0 0 0 0 0 1,
6
9
8
9
7 1,
69
89
7 0 0 
0 1,
39
79
4 0 1,
3
9
7
9
4 1,
39
79
4 1,
39
79
4 0 0 0 0 
1
22
18
49 1,
22
18
49 0 0 1,
22
18
49 1,
22
18
49 0 1,
22
18
49 1,
22
18
49 0 
1
09
69
1 1,
09
69
1 0 0 1,
09
69
1 1,
09
69
1 1,
0
9
6
9
1 1,
09
69
1 1,
09
69
1 1,
0
9
6
9
1
1
39
79
4 0 1,
3
9
7
9
4 0 0 0 1,
3
9
7
9
4 0 0 1,
3
9
7
9
4
0 0 0 1,
6
9
8
9
7 0 0 0 0 1,
69
89
7 0 
1
39
79
4 0 0 0 0 1,
39
79
4 1,
3
9
7
9 0 1,
39
79
4 0   
4
d1 d2 d
3 d
4 d5 d6 d
7 d8 d9 d
1
0
d1 d2 d
3 d
4 d5 d6 d
7 d8 d9 d
1
0
2 0 0 0 0 0 0 0 0 0 
0 0 2 0 0 0 0 0 0 0 
d1 d2 d
3 d
4 d5 d6 d
7 d8 d9 d
1
0
7
11
46
39 3,
71
66
99 7,
0
9
6
9
1 6,
7
9
5
8
8 3,
71
66
99 5,
11
46
39 8,
9
8
9
7 7,
41
56
69 5,
41
56
69 4,
4
9
4
8
5
 
KESIMPULAN 
Setelah melewati tahap pengimplementasian dan pengujian 
terhadap sistem, maka terdapat beberapa kesimpulan yang ditemukan pada penelitian ini, yaitu : 
1. Dengan teknik penggabungkan secara mixed hybrid  antara metode collaborative filtering  dan content-based filtering  dapat menghasilkan sistem rekomendasi laptop yang mampu menutupi kekurangan dari setiap metode yang digunakan. 
2. Waktu eksekusi yang dibutuhkan dipengaruhi oleh jumlah data, dapat disimpulkan bahwa semakin besar jumlah data yang digunakan maka semakin besar juga waktu eksekusi. Pada hasil waktu eksekusi tersebut dapat disimpulkan bahwa metode content-based filtering memiliki waktu eksekusi lebih cepat dari metode collaborative filtering. 
 
SARAN 
Saran untuk penelitian di bidang sistem rekomendasi selanjutnya, yaitu: 
1. Untuk penelitian selanjutnya dihapapkan untuk menggunkan algoritma yang berbeda dalam merekomendasikan suatu item untuk mendapatkan hasil yang lebih baik. 2. Untuk penelitian selanjutnya dapat menambahkan beberapa parameter dalam memberikan rekomendasi seperti histori, komentar, ataupun likes/dislikes . 
3. Untuk penelitian selanjutnya diharapkan dalam pembuatan user profil dilakukan secara implisit yaitu dimana user tidak menyadari ia telah memberikan masukan terhadap sistem. 
 
DAFTAR PUSTAKA 
Adomavicius, G., & Kwon, Y. (2015). Multi-criteria recommender systems. In Recommender systems handbook  (pp. 847-880). Springer, 
Boston, MA.  Arifin, W. 2014. Implementasi hybrid (content based  dan collaborative filtering )  pada system rekomendasi software antivirus dengan multi-criteria rating. Fakultas ilmu komputer dan teknologi informasi, universitas sumatera utara. Medan. 
Burke, R. (2007). Hybrid web recommender systems. In The adaptive web  (pp. 377-408). Springer, Berlin, Heidelberg.  
Handrico, A. (2012). Sistem rekomendasi buku perpustakaan fakultas sains dan teknologi dengan metode collaborative filtering . Jurusan teknik informatika, Fakultas sains dan Teknologi universitas Islam negeri Sultan  Syarif Kasim Riau. Pekanbaru 
Jannach, D., Karakaya, Z., & Gedikli, F. (2012, June). Accuracy improvements for multi-criteria recommender systems. In Proceedings of the 13th ACM conference on electronic commerce  (pp. 674-689). ACM. 
Ricci, F., Rokach, L., & Saphira, B. (2010). Introduction to recommender systems handbook. In F. Ricci, L. Rokach, B. Saphira, & 27 Wijaya,   
Sistem Rekomendasi Laptop Menggunakan Collaborative Filtering  Dan Content-Based Filtering  
P. B. Kantor (Eds.), Recommender systems handbook  (pp. 1 â€“29). New York: Springer. 
Sarwar, B., Karypis, G., Konstan, J., & Riedl, J. (2001, April). Item-based collaborative filtering recommendation algorithms. In Proceedings of the 10th international conference on World Wide Web  (pp. 285-295). ACM. 
Wibowo, A. (2010). Recommender System di Perpustakaan Universitas Kristen Petra menggunakan Rocchio Relevance Feedback dan Cosine Similarity. In Industrial Electronic Seminar . 
Wiranto, E. (2010). Konsep Multicriteria Collaborative Filtering Untuk Perbaikan Rekomendasi. Seminar Nasional Aplikasi Teknologi Informasi (SNATI).",sistem rekomendasi,"Collaborative Filtering, Content-Based Filtering, tf-idf","data rating, data user, data laptop",
Sistem Rekomendasi Content Based Filtering Menggunakan Algoritma Apriori,"Sistem Rekomendasi Content Based Filtering Menggunakan Algoritma Apriori

Tessy Badriyah, Ronny Fernando, Iwan Syarif  

Abstrak  
Pada saat ini perkembangan e-commerce di Indonesia telah banyak berkembang dan diterima dengan dengan baik di dalam masyarakat. Masyarakat Indonesia sangat terbuka dengan teknologi baru dan juga jumlah pemakai internet di Indonesia semakin meningkat pesat dari tahun ke tahun. Pada saat ini juga telah berdiri banyak sekali perusahaan e-commerce di Indonesia seperti Lazada, Tokopedia, OLX, Bukalapak, Blibli.com dan masih banyak lagi yang lainnya. Masing -masing perusahaan e-commerce tersebut memiliki berbagai macam strategi pemasaran dan bisnis untuk bersaing di pasar dan untuk menarik lebih banyak lagi pembeli di tokonya. Salah satu strategi yang bisa digunakan antara lain dengan 
penggunaan Sistem Rekomendasi. Penelitian ini menerapkan penggunaan sistem rekomendasi pada e-commerce dengan metode content-based filtering yaitu algoritma apriori yang dapat menganalisis pola-pola kombinasi item. Dengan adanya fitur sistem rekomendasi di dalam e-commerce diharapkan agar 
pembeli dapat dengan cepat menemukan barang yang dibutuhkan. Dengan strategi ini e-commerce akan dapat meningkatkan pelayanan dan kepuasan pada pelanggan, serta meningkatkan pendapatan pada e-commerce itu sendiri.  
  
Kata kunci : Sistem Rekomendasi, Algoritma Apriori, Content-based Filtering, E-Commerce   
  
1. Pendahuluan  
Pada saat ini perkembangan e-commerce di Indonesia telah banyak berkembang dan diterima dengan dengan baik di dalam masyarakat. Masyarakat Indonesia sangat terbuka dengan teknologi baru dan juga jumlah pemakai internet di Indonesia semakin meningkat pesat dari tahun ke tahun. Hal ini merupakan kesempatan yang bagus sekaligus menjadi tantangan tersendiri untuk menjadikan e-commerce sebagai media pemasaran dan penjualan online bagi para produsen dan penjual di Indonesia.  Masing-masing perusahaan e-commerce tersebut memiliki berbagai macam strategi pemasaran dan bisnis untuk bersaing di pasar dan untuk menarik lebih banyak lagi pembeli di tokonya. Salah satu strategi yang bisa digunakan antara lain dengan penggunaan Sistem Rekomendasi.  Sistem rekomendasi dalam penelitian ini dibuat dengan menggunakan metode content-based filtering dengan algoritma apriori yang dapat menganalisis pola-pola kombinasi item. Dengan adanya fitur sistem rekomendasi di dalam e-commerce diharapkan agar pembeli dapat dengan cepat menemukan barang yang sesuai dengan ketertarikan pembeli. Dengan strategi ini e-commerce akan dapat meningkatkan 
pelayanan dan kepuasan pada pelanggan, serta meningkatkan pendapatan pada e-commerce itu sendiri.  
 
2. Metode Penelitian  
Pada bagian ini akan dijelaskan landasan teori yang digunakan untuk pembentukan sistem rekomendasi dan perancangan sistem rekomendasi content based filtering yang menggunakan algoritma apriori.   
2.1. Sistem Rekomendasi  
Sistem rekomendasi adalah sebuah aplikasi yang berfungsi untuk memprediksi suatu item yang menarik bagi user, contohnya rekomendasi film, musik, buku, berita dan lain sebagainya.  Ada dua tipe metode yang diterapkan pada sistem rekomendasi, yaitu collaborative filtering dan content based filtering.  Collaborative filtering adalah algoritma sistem rekomendasi dimana rekomendasi diberikan berdasarkan pertimbangan data dari user yang lain.  Sedangkan Content based filtering, pemberian rekomendasi diberikan dengan mengeksplorasi isi dari profil user, deskripsi produk atau hal-hal yang berhubungan dengan pembentukan pilihan user atas sebuah item.  Penelitian ini menggunakan metode content based filtering pada pembentukan item-item yang muncul pada rekomendasi yang diberikan pada user.    
2.1.1. Content-Based Filtering  
Metode content-based filtering membentuk profil penggunanya berdasarkan atribut pembentuk  suatu item. Algoritma metode content-based filtering  dijelaskan dalam tahap-tahap berikut ini :    
(1) Suatu item barang dipisah-pisah berdasarkan  suatu vektor komponen pembentuknya.  
(2) Pengguna akan memberikan nilai suka atau tidak suka pada item tersebut.  
(3) Sistem akan membentuk profil pengguna berdasarkan bobot vektor komponen pembentuk suatu item. Pembuatan profil pengguna dapat menggunakan algoritma  TF-IDF ( term 
frequency -invers document frequency ). TF adalah jumlah term dalam suatu dokumen. Sedangkan nilai IDF dapat dihitung menggunakan rumus:  
ïƒ·ïƒ·
ïƒ¸ïƒ¶
ïƒ§ïƒ§
ïƒ¨ïƒ¦ï€½
iidfnidf log
Dimana :  
n  = jumlah semua  
df = jumlah dokumen yang memiliki term i.   
Sistem akan melakukan penilaian berdasarkan analisis kemiripan profil pengguna dengan vektor komponen pembentuk item. Jika item tersebut akan disukai oleh pengguna maka item tersebut akan direkomendasikan ke pengguna.  Kekurangan utama yang pada metode ini yaitu met ode ini tidak mampu merekomendasikan jenis item yang baru atau belum pernah dilihat kepada seorang pengguna. Hal ini dikarenakan metode ini dibuat berdasarkan item -item yang pernah dinilai oleh pengguna tersebut.   
2.1.2. Association Rule  
Association rule adalah teknik data mining  yang digunakan untuk menemukan aturan asosiatif  di dalam suatu kombinasi item (Kusrini dan Taufiq  Luthfi, 2009). Terdapat beberapa parameter dalam  Association rule yaitu support, confidence dan  correlation. Parameter support dan confidence  digunakan hanya untuk asosiasi data yang  menghasilkan beberapa aturan untuk menentukan  metode. Namun, hasilnya 
dapat ditingkatkan  dengan parameter correlation (Han dan Kamber,  2006).  Suatu kelompok item dalam association ruledinamakan itemset. Su pport adalah nilai penunjang  atau suatu persentase yang menunjukkan besarnya  tingkat kombinasi itemset dari transaksi  keseluruhan. Nilai ini menentukan layak atau  tidaknya suatu itemset untuk dicari nilai  confidence-nya. Apabila nilai support suatu itemset  lebih besar atau sama dengan nilai minimum  support, maka itemset dapat disebut sebagai  frequent itemset, yang tidak memenuhi disebut  infrequent. Confidence adalah nilai kepastian atau  nilai yang menunjukan hubungan antar item.  Confidence dapat dicari setelah ditemukannya pola  frekuensi 
munculnya sebuah item.  Metode dasar analisis asosiasi dibagi menjadi dua  tahap yaitu :   
(1) Analisa frequent item-sets 
Pada tahap ini dilakukan pencarian kombinasi item yang memenuhi syarat minimum dari nilai support dalam database. Minimum support dan minimum confidence nilainya bebas ditentukan sesuai kebutuhan (Larose, 2009).  Nilai support  dari suatu item diperoleh dengan rumus sebagai berikut  
ð’ð®ð©ð©ð¨ð«ð­  (ð€)=âˆ‘ ð“ð«ðšð§ð¬ðšð¤ð¬ð¢  ð¦ðžð§ð ðšð§ðð®ð§ð   ð€ 
âˆ‘ ð“ð«ðšð§ð¬ðšð¤ð¬ð¢ 
Sedangkan, nilai support  dari 2 item diperoleh dari rumus sebagai berikut:  
ð’ð®ð©ð©ð¨ð«ð­  (ð€,ð)=âˆ‘ð“ð«ðšð§ð¬ðšð¤ð¬ð¢  ð¦ðžð§ð ðšð§ðð®ð§ð   ð€ ððšð§  ð 
âˆ‘ ð“ð«ðšð§ð¬ðšð¤ð¬ð¢ 
(2) Pembentukan aturan asosiasi  
Apabila semua pola frekuensi tinggi sudah ditemukan, maka dicari association rule yang memenuhi syarat minimum confidence  dengan cara menghitung confidence  aturan asosiatif 
A ïƒ  B dari support  pola frekuensi tinggi A dan B.  
Nilai confidence  diperoleh dengan rumus sebagai berikut:  
ð‚ð¨ð§ðŸð¢ððžð§ðœðž  (ð€ ïƒ  ð)=âˆ‘ ð“ð«ðšð§ð¬ðšð¤ð¬ð¢  ð¦ðžð§ð ðšð§ðð®ð§ð   ð€ ððšð§  ð 
âˆ‘ ð“ð«ðšð§ð¬ðšð¤ð¬ð¢  ð¦ðžð§ð ðšð§ðð®ð§ð   ð€  
2.1.3. Algoritma Apriori  
Algoritma apriori adalah salah satu jenis metode dalam asosiasi pada data mining.  Berikut ini penjelasan cara kerja algoritma apriori secara umum:  
(1) Pembentukan kandidat itemset, Kandidat k-itemset dibentuk dari kombinasi (k-1)k-itemset yang diperoleh dari iterasi sebelumnya. Satu ciri dari algoritma Apriori yaitu adanya pemangkasan kandidat k-itemset yang subset-nya yang  berisi k-1 item tidak termasuk dalam pola frekuensi tinggi dengan panjang k-1.  
(2) Penghitungan support dari tiap kandidat k -itemset. Support dari tiap kandidat k-itemset diperoleh dengan men-scan database untuk menghitung jumlah transaksi semua item di dalam kandidat k-itemset tersebut. Ini juga merupkan ciri dari algoritma Apriori yang dimana memerlukan penghitungan dengan scan seluruh database sebanyak k-itemset terpanjang.  
(3) Tetapkan pola frekuensi tinggi. Pola frekuensi tinggi yang memiliki k item atau k-itemset ditentukan dari kandidat k-itemset yang support-nya lebih besar dari minimum support .  
(4) Jika tidak d itemukan pola frekuensi tinggi baru maka seluruh proses akan dihentikan. Jika tidak, maka k akan ditambah satu dan kembali ke bagian 1.   
2.2. Perancangan Sistem Rekomendasi  
Penelitian ini membangun sebuah sistem rekomendasi pada e-commerce yang menggunakan algoritma apriori untuk menampilkan rekomendasi produk berdasarkan data transaksi pelanggan. Algoritma Apriori telah dijelaskan pada bab 2.1. 3 sebelumnya.  Dan berikut akan dibahas  perancangan sistem yang merupakan gambaran secara umum serta pembahasan detail dari alur sistem  yang dimulai dengan perancangan diagram umum sistem seperti yang ada pada Gambar 1 berikut ini.  
Gambar  1. Desain Sistem   
Sistem rekomendasi yang ada pada e-commerce ini dapat memberikan 2 macam rekomendasi produk pada pembeli sesuai dengan hak akses yang dimiliki oleh pembeli tersebut yaitu hak akses sebagai Guest dan member seperti yang ditampilkan pada gambar 1. Guest adalah user yang belum terdaftar di 
dalam e-commerce sedangkan member adalah user yang sudah terdaftar di dalam e-commerce dan dapat mengakses fitur -fitur e-commerce yang tidak bisa diakses Guest . Rekomendasi untuk produk yang paling populer adalah rekomendasi untuk Guest dan rekomendasi produk berdasarkan hitory transaksi adalah untuk member . Rekomendasi produk best seller adalah produk-produk yang direkomendasikan berdasarkan jumlah pembelian produk terbanyak sedangkan rekomendasi untuk member adalah produk-produk yang direkomendasikan berdasarkan history transaksi pembelian yang pernah dilakukan oleh seorang member , kemudian sistem akan mengolah data transaksi tersebut dan mencari data transaksi member lain yang memiliki kesamaan produk-produk dengan member tersebut menggunakan algoritma apriori.  
Gambar  2. Data Flow Diagram untuk Pembentukan Rekomendasi   
Data flow diagram dari pembentukan rekomendasi dijelaskan pada Gambar 2, dimana pada tiap tahapannya menerapkan landasan teori dari pembentukan sistem rekomendasi yang telah dijelaskan pada sub bab sebelumnya. 
  
3. Hasil dan Pembahasan  
Bagian berikut ini akan membahas pengujian terhadap sistem rekomendasi yang dibangun pada e-commerce.   
3.1. Spesifikasi Perangkat Lunak  
Berikut ini merupakan spesifikasi perangkat yang digunakan dalam tahap pengujian sistem : 
a. Processor  : Intel Core i3 -2350M, 2.30 GHz  
b. Memory   : 2 GB  
c. Dengan perangkat lunak: Windows 10 , dengan framework Laravel , Composer 1.2 . dan editor 
Sublime Text 3  
3.2.  Pengujian Sistem Rekomen dasi pada e -Commerce  
Tampilan hasil rekomendasi diberikan dalam dua hal yaitu (1) rekomendasi produk dari member yang sudah login ke dalam sistem e-commerce, dan (2) tampilan rekomendasi untuk setiap detail dari produk yang ditampilkan.   
Masing-masing akan dijelaskan berikut ini.  
a. Rekomendasi Produk  Member  
Rekomendasi produk ini akan tampil pada saat member e-commerce  login ke dalam sistem. Rekomendasi produk ditampilkan berdasarkan transaksi pembelian member di e-commerce, sehingga sistem akan menampilkan rekomendasi produk yang bisa jadi berbeda -beda tergantung pada user 
member yang sedang login saat itu.  
Gambar  4. Rekomendasi Produk Member   
b. Rekomendasi di Setiap Detail Produk  
Halaman rekomendasi setiap detail produk akan dita mpilkan rekomendasi produk seperti yang ada pada Gambar 5.  Pada tampilan rekomendasi akan diberikan keterangan, bahwa user yang telah membeli produk tersebut, juga akan membeli produk lain berdasarkan prosentasi kemunculan dari produk lain dari user yang sedang menampilkan detail produk pada saat itu.  
Gambar  5. Rekomendasi di setiap Detail Produk  
 
4. Simpulan  
Penelitian ini menggunakan metode Content based Filtering dengan Algoritma Apriori untuk memberikan rekomendasi produk pada e-commerce.  Berdasarkan hasil pengujian sistem yang telah dilakukan maka dapat diambil kesimpulan bahwa Sistem dapat memberikan rekomendasi produk berdasarkan transaksi belanja yang pernah dilakukan oleh pembeli di e-commerce.  
Berdasarkan hasil pengujian sistem rekomendasi pada e-commerce, maka dapat ditampilkan produk rekomendasi untuk setiap user member yang aktif.  Dan pada setiap detail produk yang ditampilkan, dapat direkomendasikan produk lain berdasarkan prosentasi kemunculan dari produk lain dari user yang sedang menampilkan detail produk pada saat itu.  Penentuan nilai  support dan confidence merupakan nilai yang mempengaruhi banyak sedikitnya rekomendasi produk yang ditampilkan.  Semakin besar nilai support dan confidence yang diberikan maka akan semakin sedikit rekomendasi yang ditampilkan dan semakin kecil nilai support dan confidence yang diberikan maka akan semakin banyak rekomendasi yang ditampilkan.  

Daftar Pustaka  
[1] Tessy Badriyah, E rry Tri  Wijayanto, I wan Syarif, P rima Kristalina . 2017 . A Hybrid Recommendation System for e-Commerce based on Product Description and User Profile , Seventh International Conference on Innovative Computing Technology (INTECH), 2017, 16 -18 Aug. 2017. p.95 -100.  
[2] Fayyad, U., Piatetsky -Shapiro, G. & Smyth, P. 1996.Data Mining to Knowledge Discovery in Databases . AI Magazine, 17(3), 37 -54.  
[3] Gorunescu, F. 2011. Data Mining: Concepts, Models, and Techniques . India: Springer.  
[4] Jiawei Han, Micheline Kamber, and Jian Pei. 2011. Data Mining: Concepts and Techniques (3rd ed.). Morgan Kaufmann Publishers Inc., San Francisco, CA, USA.  
[5] Jonathan Lee Herlocker. 2000. Understanding and Improving Automated Collaborative Filtering Systems.  Ph.D. Dissertation. University of Minnesota. Advisor(s) Joseph A. Konstan. AAI9983577.   
[6] Pasquale Lops , Marco De Gemmis , Giovanni Semeraro . 2011. Content -based recommender systems: State of the art and trends . Recommender Systems Handbook, pp. 73 â€“105.  
[7] Michael J. Pazzani. 1999. A Framework for Collaborative, Content-Based and Demographic Filtering . Artif. Intell. Rev. 13, 5 -6 (December 1999), 393 -408.  
[8] Badrul Sarwar, George Karypis, Joseph Konstan, and John Riedl. 2001. Item-based collaborative filtering recommendation algorithms . In Proceedings of the 10th international conference on World Wide Web (WWW '01). ACM, New York, NY, USA, 285 -295. 
[9] V. M. Robin, V. S. Maarten. 2000. Using Content -Based Filtering for Recommendation . University of Amsterdam, Roeter straat.  
[10] W. Paik, S. Yilmazel, E. Brown, M. Poulin, S. Dubon, and C. Amice. 2001. Applying natural language processing (nlp) based metadata extraction to automatically acquire user preferences . Proceedings of the 1st international conference on Knowledge c apture, pp. 116 â€“122.  
[11] Y. AlMurtadha, M. N. Sulaiman, N. Mustapha, and N. I. Udzir. 2011. Improved web page recommender system based on web usage mining . Proceedings of the 3rd International Conference on Computing and Informatics (ICOCI), pp. 8 â€“9.  
[12] Y. Sero ussi. 2010. Utilising user texts to improve recommendations . User Modeling, Adaptation, and Personalization, pp. 403 â€“406.",sistem rekomendasi,"Content Based Filtering, Apriori, TF-IDF",e-commerce,
SISTEM REKOMENDASI HIBRID MENGGUNAKAN ALGORITMA APRIORI MINING ASOSIASI,"SISTEM REKOMENDASI HIBRID MENGGUNAKAN ALGORITMA APRIORI MINING ASOSIASI

Zen Munawar, Rustiyana1, Yudi Herdiana2, Novianti Indah Putri3 

Abstrak
Sistem rekomendasi telah menjadi bagian yang tak terpisahkan dari hampir semua sistem berbasis informasi serta e-commerce pada umumnya. Berbagai teknik, metodologi, dan algoritma telah dipraktikkan, yang memberikan rekomendasi berdasarkan berbagai parameter. Tujuan dari sistem rekomendasi adalah untuk memanfaatkan informasi dan katalog produk dan memahami preferensi pengguna berdasarkan pilihan mereka, dan merekomendasikan me reka produk yang tidak mungkin untuk dipilih melalui ruang produk secara m anual. Penelitian di bidang ini telah mampu mengidentifikasi berbagai algoritma dan metodologi untuk membuat rekomendasi yang berpusat pada pengguna. Setiap algoritma mencakup serangkaian parameter berbeda yang dipertimbangkan berdasarkan persyaratan tugas tertentu atau domain produk dari sudut pandang personalisasi dan preferensi setiap pengguna. Penelitian ini membahas pendekatan yang ada yang di gunakan oleh berbagai sistem rekomendasi, perbandingannya, dan mengusulkan metod e yang membahas kekurangan praktik yang ada dalam membangun sistem rekomendasi  dengan menggunakan algoritma Apriori dan menggunakan aturan mining asosiasi. 
 
Kata Kunci  : Sistem rekomendasi, algoritma apriori, preferensi, aturan asosiasi. 
 
1. Pendahuluan  
Sistem informasi dan ruang produk saat ini terdiri dari sejumlah besar informasi yang tidak mungkin diukur secara manual. Sistem pemberi rekomendasi berguna untuk memberikan rekomendasi produk yang akan yang dipilih berdasarkan preferensi masa lalu, riwayat pembelian, dan informasi demografis ( Zen Munawar, Putri, & Musadad, 2020). Dengan demikian, rekomendasi kepada pengguna  telah menjadi proses yang tidak dapat dicabut dalam membuat sistem informasi dan katalog e-commerce jauh lebih intuitif dan interaktif dengan pengguna, dan oleh karena itu merupakan bidang penelitian yang berkembang pesat. Secara komersial,  e-commerce dapat disebut sebagai kegiatan yang berusaha menciptakan transaksi yang panjang antara perusahaan dan individu (Zen Munawar, 2018). Berbagai teknik, metodologi, dan algoritma telah 
dipraktikkan, yang memberikan rekomendasi berdasarkan berbagai parameter spesifik pengguna, preferensi mereka, dan item yang mereka sukai, yang berkaitan dengan persyaratan sistem informasi atau e-commerce, tugas  tertentu, atau dari perspektif pengguna dan preferensi mereka yang diperoleh dari peringkat yang terkait dengan setiap metrik parameter. Satu benang merah dalam pe nelitian sistem rekomendasi adalah perlunya menggabungkan teknik rekomendasi untuk mencapai kinerja puncak. Semua teknik rekomendasi yang diketahui memiliki ke kuatan dan kelemahan, dan banyak peneliti telah memilih untuk menggabungkan teknik dengan cara yang berbeda. Penelitian ini melakukan literasi dari berbagai tek nik rekomendasi yang sedang diteliti, menganalisisnya dalam kaitannya dengan data yang me ndukung rekomendasi dan algoritma yang beroperasi pada data tersebut, dan memeriksa berbagai teknik hibridisasi yang telah diusulkan. Analisis ini menunjukkan sejumlah kemungkinan hibrid yang belum dieksplorasi. Selain itu, dapat menunjukkan bahwa peringkat semantik yang disediakan oleh bagian sistem berbasis pengetahuan memberikan dorongan tambahan pada kinerja hibrid. Metode ini digunakan agar meng hasilkan suatu tampilan antarmuka pengguna aplikasi yang sesuai dengan kebutuhan peng guna (Zen Munawar, Fudsyi, & Musadad, 2019). Algoritma Apriori, untuk membangun sistem rekomendasi yang dipersonalisasi, aturan asosiasi sangat penting untuk memprediksi minat pen gguna pada item yang ada dalam dataset yang sedang dievaluasi (Wang, Chuang, Hsu, & Keh, 2004). Aturan asosiasi ini membentuk dasar dari algoritma Apriori yang terkena l. Algoritma menjawab seberapa sering item muncul bersama atau berapa probabilitas  item dibeli bersama. Dinamakan apriori karena berdasarkan kemampuannya untuk mengg unakan pengetahuan sebelumnya tentang properti item dari kumpulan data , ini paling cocok untuk catatan transaksi seperti alat keranjang pasar. Aturan asos iasi untuk algoritma didasarkan pada parameter tertentu seperti kepercayaan dan dukungan  yang terkait dengan probabilitas bersyarat dan frekuensi item yang muncul di set masing-masing. Ketersediaan dataset dan informasi yang begitu besar di web dan internet, Sistem Rekomendasi juga terikat untuk mengikuti berbagai teknik tertentu untuk berbagai jenis fungsinya, dijelaskan sebagai berikut: Kolaboratif,  ini adalah teknik di mana data dari berbagai pengguna berkolaborasi. Data yang terkumpul  dianalisis dan selanjutnya dirumuskan preferensi dan selera kelompok pengguna.  Berdasarkan hasil ini, sistem kolaboratif digunakan untuk merekomendasikan item kepada pengguna lain, dengan preferensi yang sama. Berbasis konten, Metode ini bergantung pada penggunaan kata kunci tertutup. Algoritma yang ditetapkan melacak informasi dari berbagai pengguna 
dan menilai selera berdasarkan hal tersebut. Penget ahuan yang sama membantu sistem berbasis konten untuk merekomendasikan item yang cocok dengan selera yang sama 
dengan menghitung preferensi pengguna lain berdasar kan pencarian kata kunci. Berbasis demografi, dalam pendekatan ini, tidak ada  persyaratan riwayat data pengguna atau jenis apa pun yang terkait. Algoritma dimasukkan dengan kumpulan data dari area demografis tetap bersama dengan survei area yang sama untuk kewaspadaan lebih lanjut. Bertindak di atasnya, sistem pemberi rekome ndasi tersebut dapat menghasilkan hasil yang sama untuk wilayah yang bersangkutan. Berbasis pengetahuan, bekerja pada pengetahuan fungsional yaitu memiliki informasi kebu tuhan pengguna dan deskripsi item dan dengan demikian tugas algoritma adalah membangun hubungan antara kedua ujungnya untuk menyelesaikan transaksi.  Hibrid, merupakan kombinasi dari dua atau lebih dari dua metode yang digunakan untuk memberik an satu pendekatan menuju sistem rekomendasi yang lebih efisien dan andal atau lebih tepatnya menghilangkan kekurangan dalam teknik solo, disebut sebagai sistem rekomendasi hibrid. 

2. Sistem Rekomendasi 
Tujuan dari sistem rekomendasi bukan untuk membentuk rekomendasi, memprediksi peringkat atau peringkat, atau memesan item. Maksud sebenarnya, ini untuk membantu dan membantu pengguna. Mempertimbangkan skenario yang penuh harapan, sistem rekomendasi dapat memberikan layanan untuk propagan da yang lebih besar dan lebih baik dan dengan demikian, hal yang sama dianggap kurang dieksplorasi (Jannach & Adomavicius, 2016), sementara itu memiliki masa depan yang berkembang pesat di masa depan. Dengan bidang pembelajaran mesin yang terus berkembang dan perubahan besar dalam penyimpanan dan penggunaan informasi di  sekitar kita, sistem pemberi rekomendasi mulai memiliki peran penting dan penting untuk dimainkan, yang dapat dilihat sebagai kebutuhan bagi keduanya, bisnis ele ktronik. ritel dan pelanggan berikut mereka (Polatidis & K. Georgiadis, 2013). Mereka me nemukan penerapan maksimal dalam disiplin bisnis berbasis online . Desain merupakan tahapan perantara untuk memetakan spesifikasi atau kebutuhan aplikasi yang akan dibangun (Zen Munawar, 2019a).  Sistem rekomendasi berdasarkan pemfilteran berbasis  konten berfokus pada item yang mirip satu sama lain. Rekomendasi didasarkan pada teknik sederhana ini yang bertujuan untuk mencocokkan deskripsi item dengan profil pengguna berdasarkan minat mereka (Pazzani & Billsus, 2007). Dengan mempelajari profil pengguna secara cermat, item serupa disarankan kepada pengguna. Profil ini diper barui secara berkala dengan mempelajari tanggapan pengguna terhadap item tertentu yang mungkin telah digunakannya. Rekomendasi yang cermat dibuat dengan  mengambil dokumen lain yang serupa dengan yang sebelumnya disukai oleh pengguna . Di sisi lain, penyaringan kolaboratif bekerja dengan asumsi bahwa pengguna de ngan selera dan preferensi yang sama akan merasakan hal-hal yang serupa (Schafer, Frankowski, Herlocker, & Sen, 2007). Pusat data terdiri dari sekelompok server ya ng saling terhubung dan mampu melakukan komputasi kinerja tinggi (Zen Munawar, 2020a). Ada dua jenis sistem kolaboratif: pemfilteran kolaboratif berbasis pengg una dan pemfilteran kolaboratif berbasis item. Pemfilteran kolaboratif berbasis peng guna mengidentifikasi pengguna yang serupa dan kemudian menggabungkan skor peringk at mereka untuk membuat prediksi intuitif kepada pengguna menggunakan algoritma pembelajaran yang diawasi atau tidak diawasi. Pemfilteran kolaboratif berbasis item bekerja dengan cara yang sama, tetapi terlihat menjadi satu set item algoritma ini menghitung seberapa mirip item dengan  item target di bawah rekomendasi (Wei, Ye, Zhang, Huang, & Zhu, 2012). Penelitian se belumnya sudah menyelidiki apakah ada efek signifikan dalam keakuratan model prediktif yang efektif (Zen Munawar, 2017). Setelah itu juga menggabungkan pref erensi pelanggan sebelumnya berdasarkan kesamaan item tersebut.  Individu dapat meminta pendapat mengenai buku, musik, film dari orang lain untuk 
membuat keputusan. Inilah ide inti dari perancangan sistem rekomendasi. Sistem rekomendasi diperlukan karena sebelumnya terdapat ke lemahan pada sistem berbasis konten (Z Munawar, Suryana, Saâ€™aya, & Herdiana, 202 0). Sistem pemberi rekomendasi yang dipersonalisasi menggabungkan ide dari pencari an informasi (Zen Munawar, 2019b). Tantangan untuk solo dan teknik kombinatorial dari berbagai metode dan 
algoritma, para peneliti datang dengan pendekatan hibrid mereka sendiri (Chikhaoui, Chiazzaro, & Wang, 2011) yang merupakan gabungan dari penyaringan kolaboratif berbasis lingkungan, penyaringan berbasis konten, penyaringan demografis, Prediksi peringkat dan masalah Cold Start . Evaluasi dan perbandingan yang dilakukan atas dasar RMS (root mean square ) rumus F-measure, Precision  dan Coverage , secara identik menunjukkan kinerja yang lebih baik dari yang lainnya.  Profil pengguna dan sumber daya yang ada di perpust akaan bertindak sebagai batasan vektor untuk sistem rekomendasi yang berisi frekuensi istilah untuk setiap kata kunci yang signifikan. Juga digunakan adalah pengklasifikasi berbasis k-terdekat Tetangga yang menggunakan pendekatan berbasis jarak dan akurasi untuk membuat keputusan berikut (Shirude & Kolhe, 2016). Metode tersebut di lakukan pada dataset Library dan hasil estimasi ternyata baik dan tidak bias. Algoritma apriori yang terkenal telah dimodifikasi untuk membangun sistem rekomendasi yan g dipersonalisasi (Lazcorreta, Botella, & FernÃ¡ndez-Caballero, 2008). Teknik Aprio ri adalah pendekatan bottom-up  berpengaruh yang bekerja pada aturan asosiasi terte ntu yang terkait dengan berbagai item database. Dalam penelitian ini, penekanan diberikan pada menemukan aturan-aturan tersebut dan membantu ini untuk memberikan rekomendasi yang sesuai bagi pengguna. Penelitian ini mengikuti prosedur dua lan gkah yang digunakan untuk mempelajari perilaku pengguna yang berkaitan dengan  keberadaan aturan asosiasi diikuti dengan menganalisis aturan yang saling terkait untuk lebih memahami semua persyaratan pengguna. 
 
3. Usulan Implementasi  
Masih terdapat masalah yang terkait dengan sistem rekomendasi yang ada (Ghazanfar & Prugel-Bennett, 2010) seperti skalabilitas, rekomen dasi berkualitas buruk, cakupan rendah, dan lain-lain. Dalam penelitian ini bertuju an untuk mempelajari teknik yang sudah ada dari konten berbasis dan penyaringan kola boratif yang dapat digabungkan untuk membentuk sistem hibrid. Namun, untuk membuat  sistem lebih efisien, diusulkan sistem hibrid yang menggunakan algoritma berbasis mining asosiasi bersama dengan teknik yang ada.   Penelitian ini mengusulkan metode dimana data direkomendasikan kepada pengguna berdasarkan peringkat pengguna serupa lainnya dan juga berdasarkan riwayat pengguna sendiri dalam membeli data serupa. Setelah kesamaan  dipelajari dan data dianalisis berdasarkan pengalaman masa lalu, aturan asosiasi digunakan untuk menentukan skor 
yang memprediksi kemungkinan dua item dari kumpulan data dibeli bersama. Sejumlah algoritma seperti K-neighbourhood telah disebarkan dan diperiksa. Pada pengamatan dan perbandingan dengan berbagai prosedur mining, kedua teknik tersebut kemudian digabungkan dan digunakan dengan algoritma Apriori mining asosiasi yang menghasilkan yang terbaik untuk memberikan rekomendasi skala komersial berkualitas baik kepada pengguna. Gambar di bawah ini menjelaskan secara diagram pendekatan yang penulis usulkan dalam penelitian ini. 
Gambar 1. 
Representasi diagram dari metodologi yang diusulkan, di mana algoritma Apriori mining asosiasi diterapkan pada hybrid dari  skema pemfilteran yang ada  Implementasi,  menggunakan Python Jupyter notebook untuk mengimplementasikan kode, membuat rekomendasi yang sesuai berdasarkan minat dan preferensi pengguna. Bagian dari kode menghitung skor asosiasi kumpulan item untuk memprediksi probabilitas dua atau lebih item data yang sering muncul bersama dalam sampel. Pendekatan apriori digunakan sebagai mining asosiasi pada hibrid berbasis konten dan skema penyaringan kolaboratif, dan membantu menghas ilkan set semua item (Hamilton, 2020). Algoritma diberikan sebagai berikut: 
1. Iterasi pertama 
a. Hasilkan kumpulan item kandidat di 1 
b. Simpan item yang sering muncul di 1 iterasi ke- k 
a. Hasilkan kandidat itemset di dari frequent items et di 1 
i. Gabungkan 1 p dengan 1 q, sebagai berikut: 
masukkan ke dalam  
pilih hal.  1, hal.  2,. . . , hal. 1, q. âˆ’1 
Dari Lk-1p, Lk-1q 
Dimana p-item1 = q.  1,. . .p.   âˆ’ 2 = q.  âˆ’ 2, p.  âˆ’ 1 <q.  âˆ’ 1 
ii. Hasilkan semua (k-1)-subsets dari kandidat item sets di  
iii. Pangkas semua kandidat itemset dari di mana beberapa (k-1)-subset dari kandidat itemset tidak ada dalam frequent itemset 1 
b. Pindai database transaksi untuk menentukan dukungan untuk setiap kumpulan item kandidat di k 
c. Simpan kumpulan item yang sering digunakan di k 
Beberapa iterasi dilakukan untuk pencarian di database untuk menemukan frequent 
itemsets dimana k-item set digunakan untuk menghasi lkan k+1-itemsets. Representasi grafis dilakukan dengan menggunakan kluster yang me wakili asosiasi item terdekat dan tertentu dalam dataset. Penelitian yang diimplement asikan selanjutnya memberikan output dalam bentuk grafik batang dan klaster yang pada gilirannya memungkinkan sistem pemberi rekomendasi untuk mengumpulkan kemung kinan dan memberikan 
rekomendasi terbaik dari kumpulan data yang tersedia.  Dunia saat ini tidak lepas dari peran data karena semua dibangun di atas sebuah fondasi data (Zen Munawar, Siswoyo, & Herman, 2017).  E-commerce membutuhkan sejumlah besar data, sering disebut dengan big data. Teknologi big data telah  terbukti  efektif  dalam  memproses berbagai jenis data (Zen Munawar &  Putri, 2020). Sistem akan dirancang dan dipersiapkan untuk implementasi (Zen Munawar, 2020b). Saat ini, sejumlah besar data yang dikumpulkan dan dihasilkan setiap hari menawarkan berbagai peluang analitis bagi organisasi untuk mengungkap informasi yang bermanfaat untuk operasinya (Munawar, Zen and Putri, 2020).  
 
4. Analisis, Hasil dan Pembahasan 
4.1 Analisis 
Awalnya, penelitian mengamati tren di bidang akurasi dan cakupan metodologi yang berbeda, dan hasil praktik rinci mereka diamati ke dalam berbagai kedalaman dengan mengubah persentase data yang digunakan dalam set pelatihan. Diamati bahwa efisiensi dan akurasi dari semua metodologi meningkat seiring  dengan peningkatan persentase. Tren ini muncul seperti yang diharapkan secara alami karena dengan meningkatnya data yang akan digunakan dalam pelatihan dari set pelatihan, kepadatan matriks peringkat semakin meningkat secara menyeluruh, sehingga prediksi sekarang dapat dibuat oleh masing-masing algoritma lebih akurat sebagai algori tma memiliki lebih banyak informasi untuk digunakan dalam penghitungan. 
Gambar 2. 
Tren akurasi prediksi yang menunjukkan ut ilitas marjinal dan titik pengembalian marjinal teknis (Mainak, 2020) 
Pendekatan yang ada dari pemfilteran berbasis konte n dan kolaboratif bersama dengan berbagai kombinasi gabungannya secara inheren memiliki beberapa keterbatasan. Secara praktis, sistem rekomendasi komersial menggun akan kumpulan data yang sangat besar untuk mengakumulasi semua pengguna dengan semua item, hal ini menimbulkan tantangan dalam penghitungan prediksi dan rekomendasi. Ini adalah masalah sparitas data. Karena pilihan pengguna sebelumnya juga diper timbangkan dalam pendekatan untuk membuat rekomendasi yang bagus, pengguna baru  harus menilai sejumlah besar item terlebih dahulu agar sistem dapat memperoleh preferensi secara akurat dan memberikan rekomendasi yang dapat diandalkan. Demik ian pula, item baru juga perlu direkomendasikan oleh pengguna dalam jumlah yang cu kup sehingga dapat disajikan kepada pengguna dengan selera yang sama. Ini mengacu pada masalah cold start .  Dalam algoritma tradisional, masalah yang sangat penting adalah skalabilitas. Mempertimbangkan misalnya sistem dengan jutaan pengguna O (M) bersama dengan jutaan item O (N), kompleksitas algoritma yang dite rapkan sudah menjadi sangat besar untuk komputasi dan penerapan praktis. Jadi, pendek atan hibrid yang menerapkan asosiasi dan teknik pengelompokan lainnya membantu menjaga sistem rekomendasi 
tidak terlalu rumit dan lebih cocok untuk penggunaan praktis dan komersial di mana kumpulan data waktu nyata yang sangat besar digunak an dalam membuat prediksi (Hao, Zhou, Liu, Lyu, & King, 2011). 
Tabel 1. 
Tabel yang menunjukkan perbandingan efisie nsi komputasi dari berbagai algoritma yang dipelajari untuk prediksi (Cacheda, Carneiro, & Andez, 2011)  
Algorithm Prediction Training 
User-based - O(mn) 
Item-based O(mn2)  O(mn2) O(n) 
Similarity fusion  O(n2m+ m2n) O(mn) 
Personality diagnosis  O(m2n) O(n) 
Regression-based  O(mn2) O(n) 
Slope one  O(mn2) O(n) 
LSI/SVD  O((m+ n)3) O(1) 
RSVD  O(mnk) O(1) 
NSVD2  O(mnk)) O(1 
SVD++  O(mn2k) O(1) 
Integrated model  O(mn2k) O(1) 
Cluster-based smoothing  O(mnÎ± +m2n) O(mn) 
Tendencies-based  O(mn) O(1) 
Perbedaan praktis lainnya adalah dalam sesi atau unit agregasi. Penerapan aturan asosiasi dalam pendekatan yang diusulkan membuat pendekatan hibrid sederhana sensitif terhadap sesi. Dalam pemfilteran kolaboratif berbasis pengguna atau item, pengguna adalah unit yang ditunjuk item yang dikonsumsi oleh pengguna yang sama dihitung di semua sesi pengguna, sementara dalam aturan asosiasi, miningbiasanya dilakukan untuk sesi secara individual, ketika item  muncul bersama di sesi yang sama. Dengan demikian, berbagai algoritma dibandingkan te tapi hampir semua algoritma berbasis tetangga terdekat tampak lemah untuk basis  data besar, sehingga menunjukkan masalah sparity dan skalabilitas untuk set data skala komersial. Studi eksperimental dan pengamatan implementasi ini dengan jelas menunjukkan bahwa sistem rekomendasi berdasarkan algoritma Apriori yang ditingkatkan ber sama dengan aturan asosiasi meningkatkan efisiensi mining data secara iteratif untuk mencapai kesatuan dan akurasi rekomendasi. Dengan diterapkannya berbagai jenis sistem rekomender yang telah mampu memenuhi kebutuhan yang dipikirkan darinya, masih datang dengan seperangkat masalah dan batasannya sendiri yang rencananya akan dicari seir ing dengan berjalannya waktu. Keterbatasan seperti (Sharma & Mann, 2013) Masalah Cold Start, Skalabilitas, Sparsity, dan masalah Over-spesialisasi masih mengganggu kerja efisien sempurna dari sistem rekomendasi. Sejauh menyangkut masa depan, sistem p emberi rekomendasi memiliki cakupan yang cerah. Itu dapat dilihat diperluas dan diimplementasikan di berbagai situs 
dan fungsi yang berbeda. Algoritma dapat berlarut-larut ke konten web, mining struktur web, dan berbagai teknik ekstraksi data (Raghani, 2 020). Bagian terpenting dari algoritma pemberi rekomendas i adalah data, dan penyiapan 
kumpulan data. Informasi atau data yang dikumpulkan  dapat diubah dengan mudah menjadi format yang dapat dibaca dengan bantuan alat intelijen bisnis (Putri, Komalasari, & Munawar, 2020). Sebagian besar sistem  yang dihasilkan komputer bersifat eksplisit dan merupakan representasi simbolis untuk pengetahuan terkait tentang domain tertentu (Putri et al., 2020).  
  
5. Kesimpulan   
Sistem rekomendasi merupakan bidang yang terus berkembang karena banyaknya data dan pengguna yang saling berinteraksi dalam bentuk katalog melalui internet. Dengan demikian, rekomendasi yang sesuai yang benar-benar berpusat pada pengguna dan didedikasikan untuk setiap pengguna, secara langsung berarti lebih banyak keterlibatan pengguna di portal rekomendasi tertentu. Dalam pene litian ini, sejumlah metodologi yang secara tradisional digunakan dalam membuat rekomendasi dan prediksi berdasarkan peringkat dan parameter lain telah diba has. Kekurangan dari metode dan algoritma yang ada ini direalisasikan dan perbaikannya menjadi dasar metode rekomendasi yang diusulkan. Penelitian ini menerapkan di Jupyter sistem rekomendasi yang pada dasarnya adalah hibrid dari konten berbasis dan kolaboratif pemfilteran tetapi menerapkan algoritma apriori bersama dengan aturan asosiasi pada berbagai parameter untuk secara komprehensif menganalisis contoh dalam  kumpulan data dan membuatnya 
sangat akurat dan sangat rekomendasi lebih cepat. Tren data di bawah berbagai algoritma untuk prediksi juga telah dipelajari secara teoritis dan telah diamati dengan tepat dalam implementasi program dari sistem yang disebutkan di atas. Penelitian ini mengusulkan metode prediksi dan rekomendasi tersebut  berdasarkan pengguna, peringkat pengguna, dan peringkat lainnya pada parameter pilihan lain yang mengatasi keterbatasan individu dasar dari pendekatan yang ada dengan menggunakan algoritma apriori, dan kemudian menggunakan aturan mining aso siasi untuk memahami kumpulan 
data dengan lebih baik bersama dengan preferensi pe ngguna dan frekuensinya. Dengan demikian, pendekatan hybrid terhadap mining dan prediksi meningkatkan efisiensi sistem secara keseluruhan dan membuat sistem menarik secara signifikan dan pro-pengguna. Penelitian lebih lanjut di bidang ini dap at membantu mengembangkan sistem rekomendasi yang lebih baik dan lebih cepat yang dapat menangani kumpulan data yang lebih besar dan memberikan rekomendasi yang akurat menggunakan berbagai pendekatan hibrid. 
 
Daftar Pustaka 
Cacheda, F., Carneiro, I., & Andez, D. F. (2011). Comparison of collaborative filtering algorithmsâ€¯: Limitations of current techniques and proposals f or scalable , high-
performance recommender systems Comparison of Colla borative Filtering Algorithmsâ€¯: Limitations of Current Techniques and Proposals f or S. 5(1), 1â€“33. https://doi.org/10.1145/1921591.1921593 
Chikhaoui, B., Chiazzaro, M., & Wang, S. (2011). An  improved hybrid recommender system by combining predictions. Proceedings - 25th IEEE International Conference on Advanced Information Networking and A pplications Workshops, WAINA 2011 , 644â€“649. https://doi.org/10.1109/WAINA.2011.12 
Ghazanfar, M. A., & Prugel-Bennett, A. (2010). A sc alable, accurate hybrid recommender system. 3rd International Conference on Knowledge Discovery  and Data Mining, WKDD 2010 , (2), 94â€“98. https://doi.org/10.1109/WKDD.2010.117  Hamilton, H. (2020). Apriori Itemset Generation. Co mputer Science 831: Knowledge Discovery in Databases. Retrieved April 20, 1BC, fr om KDD Web website: http://www2.cs.uregina.ca/~hamilton/courses/831/inde x.html 
Hao, M., Zhou, D., Liu, C., Lyu, M. R., & King, I. (2011). Recommender systems with social regularization. Proceedings of the 4th ACM International Conference  on Web Search and Data Mining, WSDM 2011 , 287â€“296. https://doi.org/10.1145/1935826.1935877 
Jannach, D., & Adomavicius, G. (2016). Recommendati ons with a purpose. RecSys 2016 - Proceedings of the 10th ACM Conference on Re commender Systems , 7â€“10. https://doi.org/10.1145/2959100.2959186 
Lazcorreta, E., Botella, F., & FernÃ¡ndez-Caballero, A. (2008). Towards personalized recommendation by two-step modified Apriori data mining algorithm. Expert Systems with Applications , 35(3), 1422â€“1429. https://doi.org/10.1016/j.eswa.2007.08.048 
Mainak, D. (2020). Collaborative Filtering and The First Userâ€™s Disadvantage: An Emerging Area of Concern. Retrieved April 20, 2020, from Digital Policy Organization website: http://www.digitalpolicy.org/ collaborative-filtering-first-users-disadvantage-emerging-area-concern/ 
Munawar, Zen and Putri, N. I. (2020). Keamanan Jari ngan Komputer Pada Era Big Data. J-SIKA| Jurnal Sistem Informasi Karya Anak Bangsa , 02(01), 14â€“20. 
Munawar, Z, Suryana, N., Saâ€™aya, Z. B., & Herdiana,  Y. (2020). Framework With An Approach To The User As An Evaluation For The Recommender Systems. 2020 Fifth International Conference on Informatics and C omputing (ICIC) , 1â€“5. https://doi.org/10.1109/ICIC50835.2020.9288565 
Munawar, Zen. (2017). Penggunaan Profil Media Sosia l Untuk Memprediksi Kepribadian. TEMATIK - Jurnal Teknologi Informasi Dan Komunikasi , 4(2 SE-Articles), 18â€“37. https://doi.org/10.38204/tematik. v4i2.176 
Munawar, Zen. (2018). Keamanan Pada E-Commerce Usah a Kecil dan Menengah. TEMATIK - Jurnal Teknologi Informasi Dan Komunikasi , 5(1), 1â€“16. https://doi.org/10.38204/tematik.v5i1.144 
Munawar, Zen. (2019a). Aplikasi Registrasi Seminar Berbasis Web Menggunakan QR Code pada Universitas XYZ. Tematik, Jurnal Teknologi Informasi Dan Komunikasi , 6(2), 68â€“77. https://doi.org/10.38204/tematik.v6i2.24 6 
Munawar, Zen. (2019b). Meningkatkan Kinerja Individ u melalui Kritik/Saran menggunakan Recommender System  . TEMATIK - Jurnal Teknologi Informasi Dan Komunikasi , 6(1 SE-Articles). https://doi.org/10.38204/tematik.v6 i1.185 Munawar, Zen. (2020a). Mekanisme keselamatan, keama nan dan keberlanjutan untuk sistem siber fisik. Jurnal Teknologi Informasi Dan Komunikasi , 7(1), 58â€“87. https://doi.org/10.38204/tematik.v7i1.371 
Munawar, Zen. (2020b). Perbaikan Teknis Sistem Penc atatan Persediaan Barang Berbasis Komputer Bagi Pedagang Buku Pasar Palasari  Kota Bandung Menghadapi Era Pasar Kompetitif. JASTâ€¯: Jurnal Aplikasi Sains Dan Teknologi , TEMATIK - Jurnal Teknologi Informasi Dan Komunikasi   Vol. 8 No. 1 Juni 2021 4(1), 52. https://doi.org/10.33366/jast.v4i1.1587 
Munawar, Zen, Fudsyi, M. I., & Musadad, D. Z. (2019 ). Perancangan Interface Aplikasi Pencatatan Persediaan Barang Di Kios Buku Palasari Bandung Dengan Metode User Centered Design Menggunakan Balsamiq Mockups. Jurnal Informatika , 6(2), 10â€“20. 
Munawar, Zen, & Putri, N. I. (2020). Keamanan IoT D engan Deep Learning dan Teknologi Big Data. TEMATIK - Jurnal Teknologi Informasi Dan Komunikasi , 7(2), 161â€“185. https://doi.org/10.38204/tematik.v7i2 .479 
Munawar, Zen, Putri, N. I., & Musadad, D. Z. (2020) . Meningkatkan Rekomendasi Menggunakan Algoritma Perbedaan Topik. J-SIKA| Jurnal Sistem Informasi Karya 
Anak Bangsa , 02(02), 17â€“26. Retrieved from 
https://ejournal.unibba.ac.id/index.php/j-sika/arti cle/view/378 
Munawar, Zen, Siswoyo, B., & Herman, N. S. (2017). Machine learning approach for analysis of social media. ADRI International. Journal. Information. Technolog y, 1, 
5â€“8. 
Pazzani, M., & Billsus, D. (2007). Content-Based Re commendation Systems. The Adaptive Web , 4321 , 325â€“341. LNCS. Polatidis, N., & K. Georgiadis, C. (2013). Recommender Systems:The Importance of Personalization in E-Business Environments. International Journal of E-Entrepreneurship and Innovation , 4(4), 32â€“46. https://doi.org/10.4018/ijeei.2013100103 
Putri, N. I., Komalasari, R., & Munawar, Z. (2020).  Pentingnya Keamanan Data dalam Intelijen Bisnis. J-SIKA| Jurnal Sistem Informasi Karya Anak Bangsa , 02(02), 41â€“
48. 
Raghani, V. (2020). Recommender Systems using Aprio ri â€“ An Application in Retail using Python. Retrieved April 20, 2020, from https://labs.sogeti.com/recommender-systems-using-a priori/ Schafer, J. Ben, Frankowski, D., Herlocker, J., & S en, S. (2007). Collaborative Filtering 
Recommender Systems. The Adaptive Web. Lecture Notes in Computer Science , (January 2007), 291â€“323. Retrieved from https://www.researchgate.net/profile/Shilad-Sen/publication/200121027_Collaborative_Filtering_R ecommender_Systems/links/547691850cf2778985b08077/Collaborative-Filtering-R ecommender-Systems.pdf 
Sharma, M., & Mann, S. (2013). A Survey of Recommen der Systemsâ€¯: Approaches and 
Limitations. International Journal of Innovations in Engineering  and Technology , 2(2), 8â€“14. Retrieved from https://pdfs.semanticscholar.org/fa41/dc4b60eccedf1c 41e2ae488044827dd79384.pdf 
Shirude, S., & Kolhe, S. (2016). Machine Learning U sing K-Nearest Neighbor for Library Resources Classification in Agent-Based Library Recommender System. In Advances in Computing Applications  (pp. 17â€“29). https://doi.org/10.1007/978-981-10-2630-0_2 
Wang, Y. F., Chuang, Y. L., Hsu, M. H., & Keh, H. C . (2004). A personalized recommender system for the cosmetic business. Expert Systems with Applications , 26(3), 427â€“434. https://doi.org/10.1016/j.eswa.2003.1 0.001 
Wei, S., Ye, N., Zhang, S., Huang, X., & Zhu, J. (2 012). Collaborative filtering TEMATIK - Jurnal Teknologi Informasi Dan Komunikasi   Vol. 8 No. 1 Juni 2021  recommendation algorithm based on item clustering a nd global similarity. 
Proceedings of the 2012 5th International Conferenc e on Business Intelligence and Financial Engineering, BIFE 2012 , (1), 69â€“72. https://doi.org/10.1109/BIFE.2012.23",sistem rekomendasi,"hibrid, mining asosiasi, apriori",e-commerce,
SISTEM REKOMENDASI HIBRID PEMILIHAN MOBIL BERDASARKAN PROFIL PENGGUNA DAN PROFIL BARANG,"SISTEM REKOMENDASI HIBRID PEMILIHAN MOBIL BERDASARKAN PROFIL PENGGUNA DAN PROFIL BARANG

Novianti Indah Putri, Rustiyana 1, Yudi Herdiana 2, Zen Munawar 3 

Abstrak 
Penelitian ini membahas tentang sistem rekomendasi berbasis web pada mobil. Tujuan penelitian ini adalah untuk merekomendasikan mobil berdasarkan model pengguna dan profil barang. Perancangan sistem reko mendasi mobil berbasis web dengan menggunakan algoritma rekomendasi hibrid. Al goritma pemberi rekomendasi hibrid yang diusulkan adalah kombinasi dari metode pemfilteran kolaboratif pengguna ke pengguna dan item ke item untuk menghasilkan rek omendasi pemilihan mobil. Model pengguna dirancang menggunakan fitur demografis, data klik dan riwayat penelusuran. Profil barang dibangun dengan mengguna kan berbagai atribut mobil, merek mobil, dan jenis mobil yang digunakan dalam penelitian ini. Dataset terdiri dari data pengguna dengan sesi digunakan untuk membuat model pengguna. Algoritma yang diusulkan dievaluasi dengan pengguna real time, akurasi dalam menghasilkan rekomendasi. Kinerja sistem yang diusulkan dapat di tingkatkan dengan menggunakan jaringan waktu nyata 
 
Kata Kunci  : Algoritma Pemfilteran Kolaboratif, Model pengguna, Sistem rekomendasi hibrid. 
 
1. Pendahuluan 
Rekomendasi sudah dimulai saat keberadaan manusia di mana manusia bisa merekomendasikan antar sesama manusia seperti bagai mana pemilihan dalam mendapatkan makanan, serta tempat tinggal. Bertamba hnya jumlah pupulasi manusia berpengaruh pula dalam meningkatnya kebutuhan akan produk yang ada di pasar. Di era globalisasi, terjadi peningkatan dalam perdagangan global yang mengarah ke berbagai macam barang pada produk tertentu misalnya. untuk m embeli kebutuhan mandi seperti sabun, ada berbagai jenis berdasarkan rasa, bau, merek. Hal ini juga berlaku untuk mobil. Seiring dengan meningkatnya jumlah kendaraan  di pasar global, informasi yang diperoleh setiap individu tentang produk tertentu melalui internet menjadi sangat luas. Seiring berjalannya waktu, teknologi tumbuh dan ber diri di atas apa  terlihat saat ini. Saat ini sebagian besar orang sadar tentang apa yang terjadi di sekitar mereka. Dengan meningkatnya persaingan di pasar, mobil dengan fitur serupa masuk ke pasar. Orang akan bingung tentang apa yang harus dipilih. Di sini algoritma rekomendasi berperan karena membantu pelanggan atau pengguna akhir dalam  menyarankan produk yang relevan berdasarkan selera mereka. Penelitian ini membahas tentang sistem rekomendasi berbasis web pada mobil. Tujuan utama dari penelitian ini adalah untuk merekomendasikan mobil berdasarkan model pengguna dan profil barang. Dalam penelitian ini, algoritma rekomendasi hibrid yang diusulkan berdasarkan metode pemfilteran kolaboratif pengguna ke pengguna dan item ke item digunakan untuk menghasilkan rekomendasi mobil. Metode ini digunakan agar menghasilkan suatu tampilan antarmuka pengguna aplikasi yang sesuai de ngan kebutuhan pengguna (Zen Munawar, Fudsyi, & Musadad, 2019). Model pengguna dirancang dengan fitur demografis, data klik dan riwayat penelusuran. Prof il barang dibuat menggunakan berbagai atribut mobil, merek mobil termasuk  jenis mobil yang digunakan dalam pekerjaan ini. Diperlukan dataset dari  pengguna dengan jumlah sesi terlibat dalam 
pembuatan model pengguna. Algoritma yang diusulkan diuji dengan pengguna waktu nyata dan akurasi dalam sistem rekomendasi.  
 
2. Sistem Rekomendasi 
Sistem rekomendasi merupakan perangkat lunak, yang digunakan untuk merekomendasikan item yang menarik bagi pengguna. Berdasarkan desainnya, sistem rekomendasi adalah sistem yang dipersonalisasi untuk pengguna. Desain merupakan tahapan perantara untuk memetakan spesifikasi atau kebutuhan aplikasi yang akan dibangun (Zen Munawar, 2019a). Sistem pemberi rekom endasi berguna untuk memberikan rekomendasi produk yang akan yang dipilih berdasarkan preferensi masa 
lalu, riwayat pembelian, dan informasi demografis ( Zen Munawar, Putri, & Musadad, 2020). Secara umum, sistem rekomendasi sangat berguna bagi pengguna yang belum atau kurang pengalaman serta kurang pengetahuan dalam memilih banyak alternatif dan untuk mengevaluasi alternatif, yang lebih relevan daripada yang lain. Terdapat dua jenis sistem rekomendasi, pertama sistem rekomendasi yang  dipersonalisasi dan kedua sistem rekomendasi yang tidak dipersonalisasi. Umumnya pen elitian lebih banyak sistem 
rekomendasi yang dipersonalisasi, contohnya sistem rekomendasi film, sistem rekomendasi item dari e-commerce , rekomendasi buku, rekomendasi music dan lain lain. Secara komersial, e-commerce dapat disebut sebagai kegiatan yang berusaha menciptakan transaksi yang panjang antara perusahaan dan individu (Zen Munawar, 2018). Individu dapat meminta pendapat mengenai buk u, musik, film dari orang lain untuk membuat keputusan. Inilah ide inti dari peran cangan sistem rekomendasi.  Alasan pemilihan sistem rekomendasi dari sudut pand ang bisnis, yaitu untuk meningkatkan penjualan, menjual barang yang lebih beragam, meningkatkan kepuasan pengguna,  meningkatkan loyalitas pengguna, lebih memahami kebutuhan pengguna. Sistem rekomendasi diperlukan karena sebelumnya ter dapat kelemahan pada sistem berbasis konten (Z Munawar, Suryana, Saâ€™aya, & Herd iana, 2020).  Komponen sistem rekomendasi terdiri dari pengguna, item, transaksi,  hubungan antara pengguna dan sistem rekomendasi merupakan  komponen inti dari sebuah sistem rekomendasi. Item diwakili oleh sekumpulan properti dan fitur. Fitur item dapat direpresentasikan sebagai representasi daftar, atau sebagai sekumpulan atribut atau sebagai representasi ontologis dari domain. Sistem rekomendasi dapat memiliki bany ak pengguna yang beragam. Untuk mencapai personalisasi, parameter berbeda seperti peringkat pengguna, atribut 
demografis seperti usia, jenis kelamin, profesi, pendapatan, dan lain-lain, atribut perilaku seperti pola penelusuran, data aliran klik , pola pencarian. Pengguna perlu dilibatkan dalam melakukan perancangan model pengguna. Jenis sistem pemberi rekomendasi, berbasis konten: sistem ini merekomendasikan item yang mirip dengan item lain yang disukai pengguna di masa lalu. Sistem pemberi rekomendasi yang dipersonalisasi menggabungkan ide dari pencarian informasi (Zen Munawar, 2019b). Kesamaan item dihitung berdasarkan  fitur yang terkait dengan item yang dibandingkan. Pemfilteran Kolaboratif: sistem ini disebut sebagai korelasi orang ke orang. Pemfilteran kolaboratif dianggap sebagai teknik yang paling populer dan diterapkan secara luas di sistem pemberi rekomendasi. Sistem ini bekerja pada metode lingkungan, yang difokuskan pada hubungan antara item-item atau antara pengguna. Berikutnya demografis: sistem ini merekomendasikan item berdasarkan profil demografis pengguna. Berbasis Pengetahuan: sistem ini merekomendasikan item berdasarkan pengetahuan domain tertentu tentang bag aimana fitur item tertentu memenuhi kebutuhan dan preferensi pengguna. Sistem ini akan bekerja lebih baik dari yang lain pada awalnya, tetapi jika tidak sepenuhnya dilengkapi dengan komponen pembelajaran, maka itu bisa gagal. Sistem berbasis kendala: sistem ini mirip dengan sistem rekomendasi berbasis pengetahuan. Sistem ini  merekomendasikan berdasarkan aturan eksplisit tentang bagaimana menghubungkan persyaratan pelanggan dengan fitur 
item. Berbasis komunitas: sistem ini merekomendasikan item berdasarkan preferensi teman pengguna. 
 
3. Penelitian Terkait 
Perancangan algoritma rekomendasi penyaringan kolab oratif berbasis umpan balik. Komponen umpan balik ini terdiri dari dua tingkat eksternal dan internal (Kavinkumar et al., 2015). Umpan balik eksternal adalah mengump ulkan informasi dari platform terbuka seperti situs web mobil, media sosial dan lain-lain. Umpan balik internal adalah mengumpulkan informasi dari pengguna yang mendapat rekomendasi. Ekstraksi 
berbagai komentar dari umpan balik ditambah dengan algoritma pemberi rekomendasi membuat model hibrid. Terdapat batasan untuk hal ini karena komponen umpan balik berisi komentar spam. Algoritma rekomendasi dinamis  untuk domain berita perlu di deskripsikan (Doychev, Lawlor, Rafter, & Smyth, 2014). Dalam domain berita, profil pengguna tidak akan tersedia dan merekomendasikan artikel berita untuk pengguna 
dengan menggunakan algoritma dinamis menjadi sulit. Rekomendasi mobil peringkat k teratas untuk pengguna(Chen, Feng, & Li, 2014). Penelitian sebelumnya sudah menyelidiki 
apakah ada efek signifikan dalam keakuratan model prediktif yang efektif  (Zen Munawar, 2017). Teknik pemfilteran kolaboratif berbasis item  dalam sistem rekomendasi berbasis 
web telah menghasilkan rekomendasi yang lebih baik (Sarwar, Karypis, Konstan, & Riedl, 2001). Model ini bekerja dengan kombinasi teknik pemfilteran kolaboratif berbasis item dan k-nearest neighbour. Perancangan sistem rekomendasi berbasis web menggunakan algoritma clustering dan algoritma genetika (K. jae Kim & Ahn, 2008).  Sistem rekomendasi rute untuk kendaraan didasarkan pada data yang diperoleh dari internet dan mobil (Yanagihara, Namiki, Nawa, Weir,  & Oguchi, 2013). Dunia saat ini tidak lepas dari peran data karena semua dibangun di atas sebuah fondasi data (Zen Munawar, Siswoyo, & Herman, 2017).  Algoritma prediksi dan metode keterkaitanm 
informasi dikembangkan, yang digunakan untuk mengimplementasikan struktur prototipe untuk memeriksa rute yang direkomendasikan. Sistem pemberi rekomendasi yang didasarkan pada teknologi merekomendasikan hal aman web yang tidak dikunjungi dan mungkin menarik bagi pengguna (Baraglia & Silve stri, 2004). Pola navigasi dan perilaku pengguna dalam sistem rekomendasi e-commerce (Y. S. Kim & Yum, 2011). 
Pemfilteran kolaboratif berdasarkan pola navigasi dan perilaku menganalisis tingkat kepercayaan antara klik pengguna dan item yang dite mpatkan di keranjang dengan item yang dibeli. Sebuah survei yang rumit dari berbagai  metode dan aplikasi sistem rekomendasi di domain yang berbeda (Adomavicius, G. , Tuzhilin, 2005). E-commerce membutuhkan sejumlah besar data, sering disebut dengan big data. Teknologi big data telah  terbukti  efektif  dalam  memproses berbagai  jenis data (Zen Munawar & Putri, 2020). Sistem pemberi rekomendasi untuk merekomenda sikan aplikasi seluler (Woerndl, Schueller, Wojtech, & Gmbh, 2007).  Perancangan sistem rekomendasi hybrid menggunakan teknik penyaringan berbasis pengetahuan dan kolaboratif (Burke, 2013). Sistem akan dirancang dan dipersiapkan untuk implementasi (Zen Munawar, 2020b). Perancangan sistem rekomendasi berbasis infrastruktur untuk periode pengisian kendaraan yang lama, stasiun terbatas untuk pengisian dan jaringan pintar yang belum berkembang  menyebabkan waktu yang sulit untuk penggunaan kendaraan listrik (Ferreira, Pereira, Filipe, & Afonso, 2011). Sistem rekomendasi yang memandu pengunjung untuk menemukan  aula pameran mobil yang 
sesuai (Guo, Zhu, Xu, Shang, & Ding, 2016). Profil pengunjung dikembangkan dengan mengambil ciri spasial dan temporal serta mendapatk an minat berdasarkan clustering. Model yang diusulkan terdiri dari 3 modul yang meli puti modul relevansi, modul kualitas dan modul integrasi. Dataset dunia nyata digunakan untuk memvalidasi modul yang diusulkan dan dicocokkan dengan model dasar yang berbeda. Sistem rekomendasi berbasis grafik menggunakan teknik pemfilteran berbasis konten dan kolaboratif (Huang, Chung, Ong, & Chen, 2002). Sistem rekomendasi berdasarkan gudang data yang mengubah pendekatan dua dimensi tradisional me njadi kemampuan multidimensi, hirarki dan profil (Adomavicius & Tuzhilin, 2001). Saat ini, sejumlah besar data yang 
dikumpulkan dan dihasilkan setiap hari menawarkan berbagai peluang analitis bagi organisasi untuk mengungkap informasi yang bermanfaat untuk operasinya (Munawar, Zen and Putri, 2020). Dari literatur diketahui bahwa membangun profil item dataset mobil itu sulit. Dataset mobil, yang tersedia di gudang, menjadi usang karena kedatangan model mobil baru di 
industri otomotif. Karena sumber yang berbeda memberikan informasi berbeda tentang mobil tertentu, mengonsolidasi dan membuat repositori adalah tugas yang menantang. Selain itu, penilaian untuk mobil dari pengguna yang berbeda tidak layak. Diperlukan pusat data untuk bisa mengimplementasikan sistem rekomendasi. Pusat data terdiri dari sekelompok server yang saling terhubung dan mampu melakukan komputasi kinerja tinggi (Zen Munawar, 2020a). Banyak sistem rekomendasi dirancang baik sebagai berbasis konten atau sebagai pemfilteran kolaboratif menggunakan peringkat. Penelitian ini menyarankan perancangan sistem rekomendasi hibrid menggunakan item-item kolaboratif filtering, pemfilteran kolaboratif peng guna-pengguna dan pencocokan dengan kendala pengguna. 
 
4. Hasil dan Pembahasan  
Penelitian ini menyarankan perancangan sistem rekom endasi mobil berbasis web. Model pengguna dirancang berdasarkan umpan balik te ntang mobil, kesukaan dan preferensi tentang mobil, klik pengguna dan item pencarian kata kunci. Model barang dirancang dengan semua fitur mobil yang sesuai, yang mencakup jarak tempuh, harga, tenaga, transmisi, merek, dll. Dengan mencocokkan model pengguna dengan model barang, rekomendasi yang tepat dihasilkan dalam sis tem. Ini direpresentasikan dalam gambar 1. 
Gambar 1. Model Umum Sistem Rekomendasi 
Berbagai langkah yang terlibat dalam proses ini yaitu pengumpulan data, pemrosesan awal data, eksekusi algoritma pemberi rekomendasi, evaluasi hasil, dan interpretasi hasil.  
4.1 Pengumpulan Data  
Tulang punggung dari algoritma pemberi rekomendasi adalah data, dan penyiapan kumpulan data. Informasi atau data yang dikumpulkan  dapat diubah dengan mudah menjadi format yang dapat dibaca dengan bantuan alat intelijen bisnis (Putri, 
Komalasari, & Munawar, 2020). Setelah dataset disiapkan, itu dibagi menjadi dataset training dan testing. Kumpulan data pelatihan digun akan untuk melatih algoritma dan kumpulan data pengujian digunakan untuk menguji kinerja model pemberi 
rekomendasi. Dalam penelitian ini digunakan dua dat aset. Dataset profil item adalah mobil dan set data model pengguna adalah set data aliran klik. Dataset yang terlibat dalam perancangan sistem rekomendasi mobil dengan nama dataset mobil dan dataset item dijelaskan sebagai berikut: Dataset mobil - profil item, dataset mobil berisi informasi tentang berbagai jenis mobil, merek, dan parameter terkait lainnya. Sebagian besar sistem yang dihasilkan komputer bersifat eksp lisit dan merupakan representasi simbolis untuk pengetahuan terkait tentang domain tertentu (Putri et al., 2020). Data 
mengenai merek dan detail mobil dikumpulkan dari be rbagai situs web dan situs web resmi model mobil tersebut. Model mobil terbaru yang tersedia di pasar termasuk merek dan jenis mobil digunakan dalam pekerjaan pencarian  ulang ini. Atribut dari kategori berikut seperti mesin dan transmisi, kapasitas, ken yamanan dan keamanan digunakan dalam penelitian ini. Mesin dan transmisi berisi semua spesifikasi kinerja mobil, kapasitas berisi semua fitur non-teknis seperti berat, tinggi, ruang, jumlah kursi, dll. Kenyamanan dan keamanan berisi semua aksesori tambahan yang diperlukan untu k mobil sesuai kenyamanan pengguna.   
Tabel 1. Daftar Atribut.  
No Atribut Mesin dan Transmisi 
1 Kecepatan Tertinggi 
2 Akselerasi (0-100 km / jam) 
3 Perpindahan Mesin (cc) 
4 Daya Maksimum 
5 Torsi Maksimum 
6 Deskripsi Mesin 
7 Radius Putar 
8 Jumlah Silinder 
9 Jenis Drive 
10 Pengisi Daya Turbo 
11 Pengisi Daya Super 
12 Katup Per Silinder 
13 Rasio kompresi 
14 Sistem Penyediaan Bahan Bakar 
15 Kotak persneling 
16 Jenis Roda Kemudi Kapasitas 
17 Kapasitas tempat duduk 
18 Jumlah Pintu 
19 Panjang 
20 Lebar 
21 Tinggi 
22 Jarak Bebas ke Tanah 
23 Sumbu Roda 
24 Tapak Depan 
25 Tapak Belakang 
26 Batasan Berat 
27 Berat kotor 
28 Ruang Kepala Depan 
29 Ruang Kaki Depan 
30 Ruang Kepala Belakang 
31 Ruang Kaki Belakang 
32 Kapasitas Tangki Bahan Bakar (Liter) 
33 Volume Kargo 
34 Ukuran Ban 
35 Jenis Ban 
36 Ukuran ban 
37 Ukuran Roda Paduan 
38 Jumlah Lantai Kenyamanan 
39 Pendingin ruangan 
40 Power steering 
41 Ventilasi A / C Belakang 
42 Tombol Start / Stop Mesin 
43 Pembuka Batang Jarak Jauh 
44 Pembuka Tutup Bahan Bakar Jarak Jauh 
45 Stopkontak Listrik Aksesori 
46 Tipe transmisi 
47 Kursi Belakang Lipat 
48 Sistem navigasi 
49 Kursi yang Dapat Disesuaikan 
50 Pemutar kaset 
51 Pemutar CD 
52 Pengubah CD 
53 Pemutar DVD 
54 FM / AM / Radio 
55 Kontrol Jarak Jauh Sistem Audio 
56 Speaker Depan 
57 Speaker Belakang 
58 Audio 2DIN Terintegrasi 
59 Konektivitas Bluetooth 
60 USB & Input tambahan 
61 Lampu Peringatan Bahan Bakar Rendah 
62 Kontrol Iklim Otomatis 
63 Kontrol Kualitas Udara 
64 Lampu Baca Belakang 
65 Sandaran Kepala Kursi Belakang 
66 Sandaran Lengan Tengah Kursi Belakang 
67 Kursi dengan Penghangat Ruangan Bagian Depan 
68 Kursi dengan Penghangat Ruangan Bagian Belakang 
69 Kursi kulit 
70 Kain Pelapis 
71 Kontrol suara 
72 Pegangan cangkir - Depan 
73 Pegangan cangkir - Belakang 
74 Jenis Peredam Kejut 
75 Lampu Bagasi 
76 Cermin Rias 
77 Pendingin Kotak Sarung Tangan 
78 Tempat Botol 
79 Penopang Lumbar Kursi 
80 Pengendali Pelayaran 
81 Roda Kemudi multifungsi 
82 Layar Sentuh 
83 Suspensi Depan 
84 Suspensi Belakang Keamanan 
85 Sistem Pengereman Anti-Lock 
86 Sensor Parkir 
87 Penguncian Sentral 
88 Kantung udara Sopir 
89 Kantung udara penumpang 
90 Kantung udara Samping-Depan 
91 Kantung udara Samping-Belakang 
92 Sabuk Pengaman Belakang 
93 Entri Kartu Akses Cerdas 
94 Peringatan Sabuk Pengaman 
95 Rem Bantuan 
96 Peringatan Pintu Ajar 
97 Sensor Kecelakaan 
98 Alarm Anti Pencurian 
99 Kunci Pintu Daya 
100  Kunci Pengaman Anak 
101  Balok Dampak Samping 
102  Balok Dampak Depan 
103  Kaca Spion Siang & Malam 
104  Kaca Spion Sisi Penumpang 
105  Mesin Immobilizer 
106  Tangki Bahan Bakar yang Dipasang Secara Terpusat 
107  Kamera belakang 
108  Kontrol traksi 
109  Lampu Depan Otomatis 
110  Follow Me Home Lampu Depan 
111  Jenis Rem Depan 
112  Jenis Rem Belakang 
113  Koefisien Drag 
114  Waktu Pengereman 
115  Sabuk Pengaman Depan Tinggi Dapat Disesuaikan Lainnya 
116  Diameter x Langkah 
117  Harga 
118  Tipe badan 
119  Negara Perakit 
120  Negara Produsen 
121  Sinkronisasi 
122  Jenis Kopling 
123  Jenis bahan bakar 
124  Waktu Garansi 
125  Jarak Garansi 
Model Pengguna 
Profil pengguna pengguna dibuat di mana setiap cata tan menggambarkan detail demografis, detail klik, dan detail pembelian. Detail sesi dibuat berdasarkan gambar 2. 
Gambar 2. Detail sesi 
Selain detail demografis pengguna, detail berikut y ang terkait dengan klik seperti Sesi-Id, Stempel-Waktu dan Item-Id, dicatat. Sesi-id mew akili nomor sesi, yang direpresentasikan sebagai integer. Stempel waktu me nunjukkan waktu ketika pengguna mengklik dalam format YYYY-MM-DD Thh:mm:ss.SSSZ. Item-id merepresentasikan id unik dari item yang telah diklik, direpresentasi kan dalam bentuk integer.  Rincian pembelian berisi ID unik barang yang telah dibeli, yang direpresentasikan dalam bentuk bilangan bulat. File pengujian hanya berisi klik dari pengguna. Adapun data yang diperlukan yaitu jumlah sesi, jumlah peng guna, jumlah item, dan jumlah merek.   
4.2 Pra-Pemrosesan Data  
Setelah menghapus contoh yang tidak lengkap, profil  Item memiliki 125 atribut dari 40 merek mobil dari 224 jenis mobil. Sebuah survei aca k terhadap 300 pengguna dilakukan untuk menentukan peringkat atribut mobil yang diper timbangkan untuk dibeli. Atribut yang dipilih adalah Mesin, Dis-penempatan, Tipe bodi, Harga, Jenis bahan bakar, Jumlah pintu, Kapasitas tempat duduk, Tipe Transmisi, Tipe penggerak, Ground clearance, Suspensi Depan, Suspensi Belakang, Tipe Peredam Kejut, Kantong Udara Pengemudi , Airbag Penumpang, Jenis Rem Depan, Jenis Rem Belakang.  
4.3 Eksekusi Algoritma Pemberi Rekomendasi  
Dalam penelitian ini, algoritma pemfilteran kolabor atif item-ke-item digabungkan dengan algoritma pemfilteran kolaboratif pengguna-ke-pengguna untuk menghasilkan rekomendasi yang efektif. Algoritma yang diusulkan bekerja seperti yang ditunjukkan pada gambar 3. 
Gambar 3. Cara Kerja Algoritma Rekomendasi Pemilihan Mobil  
Kemiripan antara item mobil dihitung dengan menggun akan algoritma rekomendasi penyaringan kolaboratif item ke item. Jumlah total klik untuk setiap item mobil oleh setiap pengguna dalam satu sesi dicatat. Kesamaan antar item dihitung berdasarkan probabilitas terjadinya klik untuk setiap item. Kesamaan antara pengguna dihitung menggunakan algoritma pemberi rekomendasi pemfilter an kolaboratif pengguna ke pengguna. Kemiripan dengan fitur demografis, klik pengguna dan riwayat penelusuran kata kunci pencarian dihitung antara pengguna. Keluaran dari algoritma pemberi 
rekomendasi item-ke-item digabungkan dengan keluaran dari algoritma pemberi rekomendasi pengguna ke pengguna untuk menghasilkan  rekomendasi akhir. 
Gambar 4 . Tangkapan layar dari dataset dengan atribut yang berbeda  
4.4 Evaluasi Hasil 
Akurasi adalah parameter yang digunakan untuk menge valuasi kinerja algoritma pemberi rekomendasi. Model terlatih diuji untuk 100  pengguna yang berbeda di mana 82 mengatakan memuaskan dengan rekomendasi dan 18 mengatakan tidak memuaskan dengan rekomendasi.  
4.5 Interpretasi Hasil  
Kinerja dievaluasi sebagai rasio jumlah total rekomendasi yang memuaskan dengan jumlah total rekomendasi yang dihasilkan. 83% adalah akurasi sistem yang diusulkan, yang menunjukkan kinerja sistem yang baik. 
 
5. Kesimpulan  
Ketika pasar global naik dan permintaan merek baru di ekonomi akan menyebabkan bermuculan model-model baru. Semua pabrikan mobil luar melihat pasar ini sebagai tempat untuk tumbuh dalam pangsa dalam ekonomi mobil global. Saat dunia bergerak ke puncak era baru, rekomendasi menjadi fakta yang tak terhindarkan. Hampir semua hal teknis dan non-teknis di dunia saat ini membutu hkan sistem rekomendasi. Fakta utama bahwa sistem rekomendasi tersebut mengakar kuat pada teknologi baru adalah karena keakuratan, presisi, dan keandalannya. Sistem rekomendasi memberikan pilihan yang dipersonalisasi untuk kebutuhan pengguna. Dalam pendekatan yang diusulkan, algoritma hibrid, yang merupakan kombinasi dari pengguna ke pengguna dan algoritma rekomendasi pemfilteran kolaboratif berbasis item ke item efisien dalam menyarankan rekomendasi.  Kesulitan pada dataset mobil adalah dimana data ter sebut mempunyai sifat yang dinamis sehingga sulit untuk memprediksi model mobil yang akan dikeluarkan dari mereknya. Kinerja sistem yang diusulkan dapat ditin gkatkan dengan menggunakan jaringan waktu nyata yang memungkinkan untuk memban gun situs web dan mengakses detail sesi. Pekerjaan penelitian ini dapat diperluas lebih jauh sebagai sistem rekomendasi berbasis Pengetahuan dengan menggunakan  representasi pengetahuan yang berbeda. Rekomendasi ahli dengan menggunakan sistem pakar juga dapat 
dipertimbangkan dengan menggunakan basis pengetahuan. Pada penelitian ini, model digunakan untuk mendefinisikan model pengguna dan profil item yang dapat ditingkatkan menjadi model pengguna berbasis ontologis dan profil item.  

Daftar Pustaka  
Adomavicius, G., Tuzhilin, A. (2005). Toward the Ne xt Generation of Recommender Systems: A Survey of the State-of-the-Art and Possi ble Extensions. IEEE Transactions on Knowledge and Data Engineering , 17 (6), 734â€“749. 
https://doi.org/10.1109/tkde.2005.99 
Adomavicius, G., & Tuzhilin, A. (2001). Multidimens ional recommender systems: A data warehousing approach. Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) , 2232 , 180â€“192. https://doi.org/10.1007/3-540-45598-1_17  
Baraglia, R., & Silvestri, F. (2004). An online rec ommander system for large Web sites. Proceedings - IEEE/WIC/ACM International Conference  on Web Intelligence, WI 2004 , 199â€“205. https://doi.org/10.1109/WI.2004.10158 
Burke, R. (2013). Integrating Knowledge-based and Collaborative-filtering 
Recommender Integrating Knowledge-based and Collabo rative-filtering Recommender Systems . (May 2000). 
Chen, Z., Feng, Y., & Li, H. (2014). A novel top-K automobiles probabilistic recommendation model using user preference and user  community. Proceedings - 11th IEEE International Conference on E-Business En gineering, ICEBE 2014 - Including 10th Workshop on Service-Oriented Applica tions, Integration and Collaboration, SOAIC 2014 and 1st Workshop on E-Com merce Engineering, ECE 2014 , 105â€“111. https://doi.org/10.1109/ICEBE.2014.28 
Doychev, D., Lawlor, A., Rafter, R., & Smyth, B. (2 014). An analysis of recommender algorithms for online news. CEUR Workshop Proceedings , 1180 , 825â€“836. Retrieved from http://ceur-ws.org/Vol-1180/CLEF2014 wn-Newsreel-DoychevEt2014.pdf 
Ferreira, J., Pereira, P., Filipe, P., & Afonso, J.  (2011). Recommender system for drivers of electric vehicles. ICECT 2011 - 2011 3rd International Conference on Electronics Computer Technology , 5, 244â€“248. https://doi.org/10.1109/ICECTECH.2011.5941995 
Guo, D., Zhu, Y., Xu, W., Shang, S., & Ding, Z. (20 16). How to find appropriate automobile exhibition halls: Towards a personalized  recommendation service for auto show. Neurocomputing , 213 , 95â€“101. https://doi.org/10.1016/j.neucom.2016.02.084 
Huang, Z., Chung, W., Ong, T.-H., & Chen, H. (2002) . A graph-based recommender system for digital library. The Second ACM/IEEE-CS Joint Conference on Digital Libraries - JCDL â€™02 , 65. https://doi.org/10.1145/544229.544231 
Kavinkumar, V., Reddy, R. R., Balasubramanian, R., Sridhar, M., Sridharan, K., & Venkataraman, D. (2015). A hybrid approach for recommendation system with added feedback component. 2015 International Conference on Advances in 
Computing, Communications and Informatics, ICACCI 2 015 , 745â€“752. https://doi.org/10.1109/ICACCI.2015.7275700 
Kim, K. jae, & Ahn, H. (2008). A recommender system  using GA K-means clustering in an online shopping market. Expert Systems with Applications , 34 (2), 1200â€“1209. https://doi.org/10.1016/j.eswa.2006.12.025 
Kim, Y. S., & Yum, B. J. (2011). Recommender system  based on click stream data using association rule mining. Expert Systems with Applications , 38 (10), 13320â€“13327. https://doi.org/10.1016/j.eswa.2011.04.154 
Munawar, Zen and Putri, N. I. (2020). Keamanan Jari ngan Komputer Pada Era Big Data. J-SIKA| Jurnal Sistem Informasi Karya Anak Bangsa , 02 (01), 14â€“20. 
Munawar, Z, Suryana, N., Saâ€™aya, Z. B., & Herdiana,  Y. (2020). Framework With An Approach To The User As An Evaluation For The Recom mender Systems. 2020 Fifth International Conference on Informatics and C omputing (ICIC) , 1â€“5. https://doi.org/10.1109/ICIC50835.2020.9288565 
Munawar, Zen. (2017). Penggunaan Profil Media Sosia l Untuk Memprediksi Kepribadian. TEMATIK - Jurnal Teknologi Informasi Dan Komunikasi , 4(2 SE-Articles), 18â€“37. https://doi.org/10.38204/tematik. v4i2.176 
Munawar, Zen. (2018). Keamanan Pada E-Commerce Usaha Kecil dan Menengah. TEMATIK - Jurnal Teknologi Informasi Dan Komunikasi , 5(1), 1â€“16. https://doi.org/10.38204/tematik.v5i1.144 
Munawar, Zen. (2019a). Aplikasi Registrasi Seminar Berbasis Web Menggunakan QR Code pada Universitas XYZ. Tematik, Jurnal Teknologi Informasi Dan Komunikasi , 6(2), 68â€“77. https://doi.org/10.38204/tematik.v6i2.2 46 Munawar, Zen. (2019b). Meningkatkan Kinerja Individ u melalui Kritik/Saran 
menggunakan Recommender System  . TEMATIK - Jurnal Teknologi Informasi Dan Komunikasi , 6(1 SE-Articles). https://doi.org/10.38204/tematik.v 6i1.185 
Munawar, Zen. (2020a). Mekanisme keselamatan, keama nan dan keberlanjutan untuk sistem siber fisik. Jurnal Teknologi Informasi Dan Komunikasi , 7(1), 58â€“87. https://doi.org/10.38204/tematik.v7i1.371 
Munawar, Zen. (2020b). Perbaikan Teknis Sistem Penc atatan Persediaan Barang Berbasis Komputer Bagi Pedagang Buku Pasar Palasari  Kota Bandung Menghadapi Era Pasar Kompetitif. JAST â€¯: Jurnal Aplikasi Sains Dan Teknologi , 4(1), 52. https://doi.org/10.33366/jast.v4i1.1587 
Munawar, Zen, Fudsyi, M. I., & Musadad, D. Z. (2019 ). Perancangan Interface Aplikasi Pencatatan Persediaan Barang Di Kios Buku Palasari Bandung Dengan Metode User Centered Design Menggunakan Balsamiq Mockups. Jurnal Informatika , 6(2), 10â€“20. 
Munawar, Zen, & Putri, N. I. (2020). Keamanan IoT D engan Deep Learning dan Teknologi Big Data. TEMATIK - Jurnal Teknologi Informasi Dan Komunikasi , 7(2), 161â€“185. https://doi.org/10.38204/tematik.v7i2 .479 
Munawar, Zen, Putri, N. I., & Musadad, D. Z. (2020) . Meningkatkan Rekomendasi Menggunakan Algoritma Perbedaan Topik. J-SIKA| Jurnal Sistem Informasi Karya Anak Bangsa , 02 (02), 17â€“26. Retrieved from https://ejournal.unibba.ac.id/index.php/j-sika/arti cle/view/378 
Munawar, Zen, Siswoyo, B., & Herman, N. S. (2017). Machine learning approach for analysis of social media. ADRI International. Journal. Information. Technolog y , 1, 5â€“8. 
Putri, N. I., Komalasari, R., & Munawar, Z. (2020).  Pentingnya Keamanan Data dalam Intelijen Bisnis. J-SIKA| Jurnal Sistem Informasi Karya Anak Bangsa , 02 (02), 41â€“
48. 
Sarwar, B., Karypis, G., Konstan, J., & Riedl, J. ( 2001). Item-Based Collaborative Filtering Recommendation Algorithms. World Wide Web Conference , 285â€“295. 
https://doi.org/10.1145/371920.372071 Woerndl, W., Schueller, C., Wojtech, R., & Gmbh, U.  (2007). A_hybrid_recommender_system_for_context-.pdf . 871â€“878. Yanagihara, T., Namiki, R., Nawa, K., Weir, D., & O guchi, K. (2013). Combining prediction methods with cyber information for proac tive route recommendation. 2013 IEEE International Conference on Cyber Technol ogy in Automation, Control and Intelligent Systems, IEEE-CYBER 2013 , 87â€“91. 
https://doi.org/10.1109/CYBER.2013.6705425",sistem rekomendasi,"hibrid, pemfilteran kolaboratif",data pengguna dengan sesi,akurasi
IMPLEMENTASI METODE COLLABORATIVE FILTERING UNTUK SISTEM REKOMENDASI PENJUALAN PADA TOKO MEBEL,"IMPLEMENTASI METODE COLLABORATIVE FILTERING UNTUK SISTEM REKOMENDASI PENJUALAN PADA TOKO MEBEL

Herny Februariyanti[1], Aryo Dwi Laksono[2], Jati Sasongko Wibowo[3], Mardi Siswo Utomo[4] 

Sistem rekomendasi adalah merupakan sistem yang dapat memberikan rekomendasi pada suatu item tertentu yang dapat digunakan untuk membantu  pengguna sistem  dalam mengambil suatu keputusan . Penelitian ini bertujuan untuk mengimplementasikan sistem rekomendasi menggunakan metode collaborative filtering pada e-commerce  untuk sistem penjualan pada Toko Mebel. Adanya  e-commerce  transaksaksi transaksi pembelian pembelian dapat dilakukan secara online  sehingga pelanggan tidak  harus datang ke toko , dengan demikian maka dapat menghemat waktu dan biaya. Dengan sistem rekomendasi yang diberikan pelanggan akan mendapatkan rekomendasi dari produk yang akan dibeli sebagai bahan pertimbangan dalam menentukan pilihan produk. Metode collaborative filtering akan melakukan proses pengevaluasian atau filtering (penyaringan) item yang didasarkan dari opini orang lain, dengan cara memberikan informasi kepada konsumen yang berdasarkan kemiripan karakteristik. Hasil penilitian ini bahwa sistem dapat memberikan rekomendasi sejumlah 3 (tiga) alternatif produk dan rekomendasi penjualan best seller  yang di dasarkan pada data penjulan produk paling banyak pada bulan dan tahun sebanyak tiga produk. Dari proses yang dilakukan dihasilkan nilai rekomendasi dari setiap produk untuk pelanggan. Produk yang memiliki nilai similaritas 1 dan nilai similaritas 0,6. Produk dengan nilai similaritas tertinggi lebih di utamakan untuk direkomendasikan kepada pelanggan . 

Kata Kunci :  rekomendasi,  collaborative  filtering, penjualan  
 
I. PENDAHULUAN  
Dewasa ini kemajuan teknologi mengalami pekembangan sangat pesat, selain itu di dunia bisnis teknologi  mempunyai peranan yang sangat penting. Melalui media internet/website baik pelaku bisnis  maupun  konsumen dapat melakukan transaksi dengan cara online  kapan pun dan dimana pun berada  dan dapat melakukan transaksi  dengan orang -orang di seluruh dunia.  Salah satu  Toko yang bergerak dibidang penjualan mebel yang ada pada di Kabupaten  Semarang yaitu menjual berbagai kebutuhan mebel seperti halnya yang dijual yaitu  lemari pakaian, meja makan, meja tamu, kursi tamu dan lain sebagainya. Proses penjualan Toko yang bergerak di bidang penjualan mebel saat ini pelanggan yang ingin melakukan transaksi pembelian maupun  mencari informasi terkait produk baru dari Toko harus datang langsung ke toko untuk mencari dan memilih produk yang ingin  dibeli dan melakukan transaksi ditempat. Dengan cara transaksi tersebut akan  membutuhkan waktu serta  biaya bagi pelanggan yang berada diluar kota. Selain itu, adanya persaingan yang tinggi di dunia bisnis  penjualan mebel mendorong Toko untuk memperluas pangsa pasar. Untuk memperluas jangkauan wilayah penjualan dilakukan dengan cara membuka toko didaerah lain akan membutuhkan dana yang cukup banyak karena untuk biaya sewa toko, biaya peralatan pendukung biaya pekerja, dan mungkin biaya lainnya dengan adanya toko baru dibandingkan dengan alternative  solusi jika penjualan dilakukan dengan berbasis web.  Untuk mengatasi permasalahan yang telah disebutkan di atas, dapat diambil solusi untuk pemecahan maslah tersebut adalah dengan dibangunnya  aplikasi e-commerce  yang memungkinkan transaksi penjualan dapat dilakukan oleh pelanggan dengan toko dengan cara online tanpa harus datang ke toko. Dengan demikian maka proses transaksi penjualan akan dapat menghemat waktu dan biaya, pelanggan juga bisa mendapatkan rekomendasi baru terkait produk yang akan dibeli berdasarkan perbandingan antar pola pengguna. Dengan berjualan melalui layanan e-commerce dengan fasilitas iklan/ads sangat dibutuhkan untuk menginformasikan sebuah produk dan menyebabkan orang yang sebelumnya tidak berminat untuk membeli selanjutnya akan menjadi tertarik serta mencoba produk tersebut. Metode collaborative filtering seringkali digunakan pada sistem rekomendasi . Metode collaborative filtering adalah  salah satu metode pada sistem rekomendasi dimana sistem akan melakukan proses dengan dilakukan penjumlahan  terhadap  rating atau pilihan terhadap suatu produk , selanjutnya akan ditemukan pola atau profile dari pengguna dengan cara melihat history rating dari pengguna ke sistem, selanjutnya  akan memberikan rekomendasi baru yang didasarkan pada perbandingan antar pola atau profile dari pengguna yang sudah ada.  
 
II. BAHAN DAN METODE  
Metode yang digunakan untuk pengembangan sistem adalah prototype  (Susanto & Meiryani, 2019)  Tahap-tahap pengembangannya adalah:  
1. Pengumpulan Kebutuhan  
Tahap pengumpulan kebutuhan dilakukan identifikasi kebutuhan dalam pengembangan sistem rekomendasi collaborative filtering dari Toko Mebel . Seperti identifikasi kebutuhan software  (perangkat lunak) dan kebutuhan hardware  (perangkat keras) . 
2. Membangun Prototyping  
Pada tahap prototyping adalah tahap perancangan sistem , yaitu akan dilakukan  proses perancangan menggunakan tools UML terdiri dari  use case diagram , class diagram,  activity diagram  selanjutnya akan dibuat perancangan antar muka dai sistem  yang akan dikembangkan . 
3. Evaluasi Prototyping  
Setelah tahap prototyping  akan dilakukan proses  evaluasi , dengan proses evaluasi akan diketahui apakah sistem  yang dikembangkan sudah sesuai dengan perancangan yang telah dibuat  ataukah belum . 
4. Mengkodekan Sistem  
Proses mengkodekan sistem adalah proses mengimplementasikan perancangan yang telah dibuat kedalam b ahasa pemrograman.  Penelitian ini dilakukan pembuatan model secara keseluruhan dari rencana penyelesaian/ pemecahan masalah dengan menggunakan program  PHP dan databasenya menggunakan MySQL.  
5. Menguji Sistem  
Pada tahap menguji sistem dilakukan pengujian terhadap prototyping  sampai pada pengkodean ke dalama bahasa pemrograman yang telah dibuat menggunakan pengujian black box . 
6. Evaluasi Sistem  Tahap evaluasi merupakan tahap yang akan melakukan evaluasi terhadap model prototyping  yang telah dibuat, model akan dibuat dan dilakukan perubahan dan perbaian yang di sesuaikan dengan kebutuhan yang diinginkan pengguna  sistem .  
Sistem Rekomendasi  
Sistem rekomendasi adalah merupakan sistem atau  aplikasi yang dibuat untuk dapat  menyediakan dan memberikan rekomendasi  dari  suatu item untuk membuat suatu keputusan yang diinginkan oleh pengguna  sistem  (Ungkawa et al., 2011) . Selanjutnya sistem  rekomendasi merupakan suatu alat dan teknik dalam software (perangkat lunak) yang dapat memberikan saran-saran kepada pengguna untuk item yang sekiranya dapat bermanfaat bagi pengguna dalam menentukan pilihan . (Ricci et al., 2011)  Saran-saran yang diberikan berhubungan dengan proses dalam pengambilan suatu keputusan, misalnya dalam menentukan item mana yang akan dibeli atau lagu mana yang ingin didengarkan.   Ada 2 (dua) tipe inputan (masukkan) berbeda yang sangat diperlukan dalam sistem rekomendasi , yaitu implicit input  dan explicit input . Implicit input dapat dihasilkan melalui pengamatan secara 
langsung dari kebiasaan pengguna dalam menggunakan sistem misalnya dari catatan penelusuran, catatan pembelian, pola pencarian . Sedangkan  Explicit input  didapatkan dari hasil penilaian yang diberikan oleh pengguna sistem secara langsung, misalnya adalah pemberian rating  atau thumbs -up/down  untuk suatu item (Ricci et al., 2011)   
Collaborative Filtering  
Metode Collaborative filtering adalah suatu proses untuk kegiatan dalam mengevaluasi item atau penyaringan item dengan menggunakan persepsi atau opini orang lain. Collaborative filtering melakukan proses penyaringan terhadap semua pengguna untuk mendapatkan informasi pengguna dalam memberikan suatu rekomendasi. Dalam proses penyaringan data Collaborative filtering bekerja berdasarkan kemiripan karakteristik pengguna  yang nantinya akan mampu memberikan suatu informasi yang baru kepada pengguna. Hal ini dikarenakan sistem akan memberikan informasi didasarkan pada pola dalam satu kelompok pengguna yang hampir mirip atau sama. Dibeberapa anggota kelompok dengan peminatan yang berbeda kemungkinan akan memberikan informasi yang baru yang 
kemungkinan dapat bermanfaat bagi anggota kelompok lainnya. Dengan demikian maka dapat diambil kesimpulan bahwa proses pemberian suatu rekomendasi dapat dibagi menjadi 3 (tiga) 
langkah yaitu: menemukan pengguna  yang mirip , pembuatan kedekatan atau ketetanggaan  (neighborhood ) serta penghitungan prediksi didasarkan pada  kedekatan yang dipilih. Kualitas dari sistem rekomendasi sangat tergantung dari persepsi atau opini pengguna lain terhadap  suatu item  tertentu . Sistem rekomendasi dengan jenis ini dioperasikan dalam sebuah ruang 2 (dua) dimensi pengguna x item. Rating yang diberikan oleh pengguna akan direpresentasikan sebagai R, dimana R merupakan  bilang bulat tidak negatif atau bilangan riil dengan jarak tertentu. Sistem rekomendasi  yang seperti itu akan melakukan proses prediksi rating yang akan diberikan kepada pengguna untuk suatu  item yang belum 
pernah diberikan  dirating sebelumnya oleh pengguna. Peggunaan collaborative filtering yang  sangat terkenal dalam sistem rekomendasi. Rating dalam  suatu sistem collaborative filtering dapat berbentuk:  
1. Model rating skalar dimana dapat terdiri dari rating numerik, contoh seperti angka 1 sampai 5.  
2.  Model rating biner, merupakan model  dengan cara  dipilih antara setuju atau tidak setuju , dapat juga merupakan pilihan baik atau buruk.  
3. Rating unary, yaitu model rating yang menggunakan cara  pengguna diin dikasikan sudah melakukan pembelian item atau 
observasi item atau melakukan rating item secara  positif .   
Dengan  cara ekspisit atau implisit, atau bisa keduanya secara bersamaan  rating dapat dikumpulan . Ketika pengguna 
sistemmemberikan opini terhadap suatu item secara langsung maka disebut sebagai rating eksplisit. Sedangkan jika secara preferensi secara langsung dari pengguna secara pasif dengan cara memonitor katifitas pengguna. Penilaian hanya berdasar kan pada perilaku pengguna, contoh  ketika seorang dari suatu perpustakaan memutuskan meminjam salah satu  item  buku, maka anggota tersebut akan dianggap menyukai atau tertarik dari item buku tersebut, sebaliknya jika anggota akan dianggap tidak menyukai atau tertarik pada item buku tertentu maka dia tidak akan meminjamnya. Dengan cara tersebut dapat membetuk user profile  effort  tambahhan user tidak perlu dilibatkan . Dengan cara ini maka kekurangannya adalah feedback dari pengguna sistem seringkali tidak tep at.(Schafer et al., 2014)  Metode Collaborative filetering  membagi dua kelas algoritma yang berbeda yaitu dengan menggunakan algoritma non probabilistic dan probabilistic. Metode Collaborative filtering  akan melakukan proses dengan cara melakukan penyaringan data dengan berdasarkan profile tingkah laku karakteristik pengguna  sistem. Dengan demikian maka sistem akan dapat memberikan informasi baru kepada pengguna lainnya, Hal tersebut  dikarenakan  sistem memberikan informasi berdasarkan pola satu kelompok pengguna yang match  (mirip ). (Nilashi et al., 2013)  Membagi metode collaborative fi letering  menurut teori dan penggunaannya menjadi  2 (dua) kelas yang berbeda yaitu dengan menggunakan algoritma probabilisti c dan non probabilistic. Metode atau 
algoritma akan dianggap probabilistik jika metode atau algoritma tersebut  berdasarkan model pro babilistik.  Dalam sistem rekomendasi model peratingan akan berbeda dengan model berbasis Collaboratif Filtering  ini memiliki 2  model yaitu :  
1. User-based Collaboratif Filtering Model User-based collaborative filtering diartikan  bahwa untuk dapat menemukan item yang menarik dengan menggunakan cara yang baik untuk  user  tertentu adalah menggunakan cara mencari user lain yang memiliki minat atau keinginan yang sama. diawal  user-based CF  akan  dapat menemukan pengguna terdekat (user neighbor) dengan cara menemukan pengguna yang mirip (user similarity, kemudian  setiap nilai rating yang didapatkan dari pengguna terdekat ( user neighbor ) yang 
nantinya digunakan sebagai bahan rekomendasi untuk  pengguna ( user ) yang aktif.  
2. Item-based Filtering untuk  model Item-based collaborative filtering memiliki skema atau  pola mirip dengan user-based,  jika sebelumnya user-based  akan dicari hubungan atau korelasi antara user, maka pada item-based collaborative filtering ini akan dicari korelasi  antar item yang disukai atau diminati oleh pengguna  sistem , selanjutnya akan merekomendasikan kepada pengguna sistem lainnya item -item yang saling berkolerasi.  E-commerce  E-commerce  merupakan  proses untuk menyalurkan  informasi, layanan , produk serta  proses pembayaran  menggunakan  telepon, jaringan  internet dan akses digital lainnya. E-commerce  merupakan kegiatan transaksi penjualan baik barang maupun  informasi dengan memanfaatkan layanan  jaringan internet. Menurut (Kozinets et al., 2010)  E-commerce didefinisikan sebagai proses  melakukan  pembelian, penjualan, mentransfer maupun per tukar an jasa, produk maupun  informasi menggunakan  jaringan komputer  melalui Internet  E-Commerce  adalah suatu kegiatan transaksi secara komersial antara penjual dan pembeli atau dapat juga dilakukan dengan pihak lain sengan adanya hubungan perjanjian yang sama untuk memberikan pelayanan, pengiriman suatu barang maupung peralihan suatu hak.  Dimana kegiatan transaksi yang dilakukan secara komersial menggunakan perangkat elektronik atau disebut sebagai media digital, dimana tidak diperlukan pertemuan secara fisik dengan oihak yang berkepentingan dimada media yang digunakan dapat diakses secara public network dan bukan secara private  network   (Barkatullah, 2013)  
Penelitian Terkait  
Penelitian  yang dilakukan oleh (Christianti & Hadiguna, 2011)  tentang proses transaksi di Toko Komputer Ekaria , dimana proses transaksi yang dilakukan  sampai saat ini masih secara umum dimana pelanggan harus datang ke toko untuk melihat  secara langsung  produk yang dijual dan melakukan transaksi di tempat. Dengan proses transaksi yang sedemikian rupa akan membutuhkan  waktu dan biaya bagi pelanggan yang berada di l uar Cianjur. Dengan dibangunnya aplikasi e-commerce maka pembelajaan dapat dilakukan secara online oleh pelanggan pelanggan sehingga secara otomatis akan sangat menghemat waktu dan biaya, serta dimungkinkan pangsa pasar penjualan komputer menjadi lebih luas. Perancangan sistem dalam penelitian tersebut menggunakan metode DFD dan ERD, sistem dibuat menggunakan pemograman PHP dan MySQL dan metode rekomendasi menggunakan collaborative filtering  PD Damai Motor belum mempunyai website e -Commerce untuk mempromosi kan produknya. Konsumen masih harus langsung datang ke ke tempat apabila ingin mendapatkan informasi produk dan hendak memesan produk sesuai dengan yang di inginkan. Konsumen harus menghubungi pihak PD Damai Motor via sms / telepon jika ingin mengetahui perkembangan produksi atas pesanannya. Dengan adanya aplikasi e-Commerce dengan sistem rekomendasi diharapkan dapat membantu 
dalam masalah pemesanan, penjualan barang, informasi perkembangan pemesanan, serta perekomendasi barang hingga spesifikasi barangpada  PD. Damai Motor. Perancangan sistem dalam penelitian tersebut menggunakan metode UML, sistem dibuat menggunakan pemograman PHP dan MySQL dan metode rekomendasi menggunakan collaborative filtering. (Oktora & Susanty, 2013)  Dewasa ini perkembangan merk laptop yang beredar di pasaran sangat banyak sekali. Karena laptop sekarang ini mempunyai bermacam-macam merk dan spesifikasi yang seringkali menyebabkan  orang-orang mengalami kesulitan maupun kesusahan dalam melakukan pen carian, memilih maupun melakukan pembelian laptop yang tepat dan sesuai dengan  kebutuhan  pengguna.  Sistem yang dibangun memberikan rekomendasi dengan  berdasarkan ketertarikan serta  kebutuhan dalam melakukan pencarian referensi suatu laptop. Perancangan sistem dalam penelitian tersebut menggunakan metode UML, sistem dibuat menggunakan pemograman android dan metode rekomendasi menggunakan collaborative filtering.  (Kurniawan, 2016) .  
uc Use Case Model
PelangganLogin
AdminEntri Produk
Kelola Order
Cetak laporanEntri Biaya 
KirimRegistrasi
Konfirmasi 
PembayaranLihat ProdukRekomendasi 
Produk
Pesan Produk
Lihat statusÂ«includeÂ»
Â«includeÂ»
class Class Model
PRODUK
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
BIAYAKIRIM
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
KONFIRM
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
#NAME?
act activity Model Sistem Pelanggan
Start
Pilih produk Proses collaborative 
filtering Finish Tampil detail produk dan rekomendasi 
produkHItung jarak antar pelanggan
Hitung similaritas antar pelanggan
Hitung tingkat rekomendasi

III. HASIL DAN PEMBAHASAN  
Perancangan Sistem  
Pada perancangan sistem akan  dibuat perancangan sistem yang dikembangkan dengan menggunakan diagram Unifed Modeling Languange  (UML) untuk memahami proses sistem yang berjalan.  
1. Use Case Diagram  
Pada Gambar 1.  Use case sistem rekomendasi collaborative filtering toko bergerak di bidan g penjualan mebel  berbasis e-commerce  dapat dilihat pada gambar 1 . Pelanggan melakukan registrasi atau login kemudian pelanggan melihat produk yang diinginkan dan akan ditampilkan rekomendasi produk yang sejenis. Pelanggan melakukan pemesanan produk kemudian melakukan konfirmasi pembayaran ke Toko. Pelanggan juga dapat melihat status pengiriman produk yang telah dibeli apakah status produk sudah dikirim atau belum. Admin mengelola data produk, data biaya kirim, pemesanan produk dari pelanggan dan cetak laporan yang diberikan kepada pimpinan.  
Gambar 1. Use Case Diagram   
2. Activity Diagram  
Pada gambar 2 diperlihatkan Activity diagram proses rekomendasi produk. Lihat produk dimulai dengan pelanggan memilih produk yang akan  dilihat kemudian sistem akan menampilkan detail produk yang dipilih beserta rekomendasi produk dengan metode collaborative filtering yang terdiri 
dari proses hitung jarak antar pelanggan, hitung similaritas produk dengan pelanggan, hitung tingkat rekomend asi produk.  Gambar 2. Activity Diagram Lihat Produk (Proses Rekomendasi Produk)  
3. Class Diagram  
Pada Gambar 3. Class diagram sistem rekomendasi collaborative filtering toko bergerak di bidang penjualan mebel berbasis e-commerce  dapat dilihat pada gambar 3.  Class produk dan class pelanggan berasosiasi dengan class order, class konfirm berelasi dengan class order, class biayakirim berelasi dengan class pelanggan, class produk dan class pelanggan berasosiasi dengan class rating, class produk dan class pelanggan berasosiasi dengan class dis, class produk dan class pelanggan berasosiasi dengan class hasil.  
Gambar 3 . Class Diagram  
Pembahasan  Hasil penelitian pada  sistem rekomendasi collaborative filtering Toko Mebel dengan berbasis e-commerce dari salah satu contoh pelanggan Andre Setiawan didapatkan rekomendasi produk yang belum pernah dilihat atau dibeli oleh pelanggan  tersebut yaitu  
1. Lemari Pakaian Mirroi dengan nilai similaritas 1  
2. Kursi Toril dengan nilai similaritas 0,6   
Proses perhitungan rek omendasi produk dengan metode collaborative filtering dari pelanggan Andre Setiawan terdiri dari proses sebagai berikut:  
1. Hitung jarak antar pelanggan Budi Rahayu dan Ika Sari dengan rumus Dis = 
(                 â€“ 
                      )Â². 
2. Hitung similaritas produk dengan pelanggan Budi Rahayu dan Ika Sari dengan rumus 
            = 1 / ( 1 + jumlah Dis )  
3. Hitung tingkat rekomendasi produk Lemari Pakaian Mirroi dan Kursi Toril dengan rumus 
         â„ . 
Pada Gambar 4. hasil rekomendasi hanya akan ditampilkan maksimal 3 produk yang belum pernah dilihat atau dibeli, nilai similaritas produk yang tertinggi sampai tingkat rekomendasi dengan similaritas terendah. Hasil rekomendasi diperlihatkan seperti gambar 4 
Gambar 4. Contoh Rekomendasi Untuk Pelanggan   
Proses perhitungan  sistem rekomendasi dengan metode collaborative filtering dari contoh pelanggan Andre Setiawan yaitu:  
1. Sistem rekomendasi collaborative filtering dengan 3 pelanggan yaitu Andre Setiawan, Budi Rahayu dan Ika Sari.  
2. Data rating berdasarkan transaksi penjualan pada Toko diperlihatkan seperti tabel 1 dimana nilai 1 menunjukkan pelanggan hanya melihat produk Toko dan nilai 2 menunjukkan 
pelanggan membeli  produk di Toko .  
Tabel 1.  Rating Berdasarkan Transaksi 
Penjualan  
Pelanggan  Produk  Nilai  
Andre Setiawan  Meja Makan Hervey  1 
 Lemari Pakaian Cool - 
White  1 
 Lemari Pakaian Melia 
Rattan  1 
 Kursi Makan Bugsy  2 
Budi Rahayu  Lemari Pakaian Mirroi  1 
 Lemari  Pakaian Melia 
Rattan  1 
 Kursi Toril  1 
 Meja Makan Hervey  2 
Ika Sari  Lemari Pakaian Mirroi  1 
 Lemari Pakaian Cool - 
White  1 
 Lemari Pakaian Melia 
Rattan  1 
 Kursi Toril  2 
3. Hitung tingkat kesamaan (similarity ) 
terhadap pelanggan  Andre Setiawan dengan pelanggan lain. Hitung distance  untuk setiap produk yang sama dengan produk pelanggan Andre Setiawan dengan Dis =                  â€“ 
                      )Â². 
a. Perhitungan pelanggan Andre Setiawan dengan Budi Rahayu  
1) Perhitungan Dis untuk produk Meja Makan Hervey     = (1 -2)Â² = 
1. 
2) Perhitungan Dis untuk produk Lemari Pakaian Melia Rattan      
= (1 -1)Â² = 0.  
3) Perhitungan Sim(Budi Rahayu) 
           =  1 / ( 1 + jumlah Dis ) =  
1 / (  1 + 1 + 0) = 1 / 2 = 0,5  
b. Perhitungan pelanggan Andre 
Setiawan dengan Ika Sari  
1) Perhitungan Dis untuk produk Lemari Pakaian Cool â€“ White      
= (1 -1)Â² = 0  
2) Perhitungan Dis untuk produk Lemari Pakaian Melia Rattan      
= (1 -1)Â² = 0  
3) Perhitungan Sim(Ika S ari) 
         = 1 / ( 1 + jumlah Dis ) = 1 
/ ( 1 + 0 + 0) = 1 / 1 = 1  
4) Hitung tingkat rekomendasi untuk setiap produk yang belum pernah dilihat atau dibeli oleh Andre Setiawan seperti tabel 2.  
Tabel 2. Perhitungan Rekomendasi Setiap 
Produk.  
Pelanggan  Sim  Lemari 
Pakaian 
Mirroi 
(R) Sim 
* R Kursi 
Toril 
(V) Sim * 
V 
Budi Rahayu  0,5 1 0,5 1 0,5 
Ika Sari  1 1 1 2 2 
Total    1,5  2,5 
âˆ‘Sim    1,5  1,5 
Rekomenda
si   1  1,67   
5) Nilai Sim * R pelanggan Budi Rahayu didapatkan dari nilai Sim (Budi Rahayu) yaitu  0,5 dikalikan dengan nilai rating produk Lemari Pakaian Mirroi dari pelanggan Budi Rahayu yaitu 1 sehingga nilai Sim * R yaitu 0,5 x 1 = 0,5.  Nilai 
Sim * V didapatkan dari nilai Sim (Budi Rahayu) yaitu 0,5 dikalikan dengan nilai rating produk Kursi Toril  dari pelanggan Budi Rahayu yaitu 1 sehingga nilai Sim * V yaitu 
0,5 x 1 = 0,5.  
6) Nilai Sim * R pelanggan Ika Sari didapatkan dari nilai Sim (Ika Sari) yaitu 1 dikalikan dengan nilai rating produk Lemari Pakaian Mirroi dari pelanggan Ika Sari yaitu 1 sehi ngga nilai Sim * R yaitu 1 x 1 = 1.  Nilai Sim * V didapatkan dari nilai Sim (Ika Sari) yaitu 1 dikalikan dengan nilai rating produk Kursi Toril dari pelanggan Ika Sari yaitu 2 sehingga nilai Sim * V yaitu 1 x 2 = 2.  
7) Nilai total Sim * R didapatkan dari penjumlahan Sim * R (Budi Rahayu) + Sim * R (Ika Sari) yaitu 0,5 + 1 = 1,5.  
8) Nilai total Sim * V didapatkan dari penjumlahan Sim * V (Budi Rahayu) + Sim * V (Ika Sari) yaitu 0,5 + 2 = 2,5.  
9) âˆ‘Sim didapatkan dari penjumlah Sim(Budi Rahayu) + Sim(Ika Sari ) = 0,5 +1 = 1,5.  
10) Rekomendasi didapatkan  dari rumus (âˆ‘Sim)â„Total. Untuk rekomendasi Lemari Pakaian Mirroi yaitu 1,5â„1,5 = 1 sedangkan rekomendasi Kursi Toril yaitu 
1,5â„2,5 = 0,6.  
Dari tabel 2 dari setiap produk untuk Andre Setiawan. Lemari Pakaian Mirroi didapatkan nilai rekomendasi sebesar 1 dan nilai rekomendasi Kursi Toril memiliki nilai similaritas sebesar 0,6. Produk dengan nilai rekomendasi tertinggi akan lebih diutamakan untuk ditawarkan kepada Andre Setiawan yaitu Lemari Pakaian Mirroi kemudian Kursi Toril seperti gambar 4. 

IV. KESIMPULAN  
Dari hasil penelitian system rekomendasi collaborative filtering bebasis e-commerce dapat dibuat kesimpulan bahwa  sistem rekomendasi dapat memberikan rekomendasi sejumlah 3 (tiga) produk dan rekomendasi dengan penjualan terbanyak ( best seller ) dengan dilihat dari  data penjualan paling banyak pada bulan dan tahun berjalan sebanyak 3  (tiga)  produk.  Dari proses rekomendasi menggunakan collaborative filtering didapatkan nilai rekomendasi dari setiap produk untuk pelanggan. Produk yang memiliki nilai similaritas 1 dan nilai similaritas 0,6. Produk dengan nilai tertinggi lebih di utamakan untuk ditawarkan oleh pelanggan. Untuk memberikan fitur tambahan kepada user maka dapat ditambahkan fasilitas up selling sehingga juga dapat menampilkan rekomendasi produk dengan kualitas diatas produk yang sedang dilihat . 
 
 
REFERENSI   
Barkatullah, A. H. (2013). Hukum Transaksi Elektronik -Sebagai Panduan Dalam Menghadapi Era Digital Bisnis e -
Commerce di Indonesia. In Nusamedia . 
Christianti, M., & Hadiguna, C. (2011). Commerce dengan Sistem Rekomendasi Berbasis Collaborative filtering pada Toko Komputer Ekaria Meliana. Prosiding Seminar Nasional Teknologi Informasi Dan Aplikasinya 2015 , 7, 157 â€“175. h?p://ww.cs.unud.ac.id  
Kurniawan, A. (2016). Sistem Rekomendasi Produk Sepatu Dengan Menggunakan. Seminar Nasional Tekno logi Informasi Dan Komunikasi , 2016 (Sentika), 610 â€“614. https://fti.uajy.ac.id/sentika/publikasi/ma
kalah/2016/92.pdf  Nilashi, M., Bagherifard, K., Ibrahim, O., Alizadeh, H., Nojeem, L. A., & Roozegar, N. (2013). Collaborative filtering recommender systems. Research Journal of Applied Sciences, Engineering and Technology , 5(16), 4168 â€“4182. https://doi.org/10.19026/rjaset.5.4644  
Oktora, R., & Susanty, W. (2013). Perancangan Aplikasi E -Commerce Dengan Sistem Rekomendasi Item -Based Collaborative Filltering. EXPE RT: Jurnal Manajemen Sistem Informasi Dan Teknologi , 3(1). https://doi.org/10.36448/jmsit.v3i1.477  
Ricci, F., Rokach, L., & Shapira, B. (2011). Recommender Systems Handbook. In Recommender Systems Handbook  (Issue October). https://doi.org/10.1007/978 -0-387 -85820 -3 
Schafer, J. Ben, Frankowski, D., Herlocker, J., & Sen, S. (2014). LNCS 4321 - Collaborative filtering Recommender Systems . January 2007 . 
Susanto, A., & Meiryani. (2019). System Development Method with The Prototype Method. International Journal of Scientific and Technology Research , 8(7), 141 â€“144.  
Ungkawa, U., Rosmala, D., & Aryanti, F. (2011). Pembangunan Aplikasi Travel Recommender dengan Metode Case Base Reasoning. Jurnal Informatika , 4(1), 57 â€“68.",sistem rekomendasi,collaborative Filtering,toko mebel,similaritas
Sistem Rekomendasi Beauty Shop Berbasis Collaborative Filtering,"Sistem Rekomendasi Beauty Shop Berbasis Collaborative Filtering

Erlangga Erlangga , Hadi Sutrisno 

ABSTRACT 
The increasing number of beauty places makes it difficult for consumers to determine a beauty shop that fits the required criteria, for example a beauty shop that has facial care, body and hair care services, good quality, and affordable prices. Preferences create a different sense of satisfaction for each person. Satisfaction in this case is 
the extent to which the perception of the beauty shop is in accordance with user expectations. The purpose of this study is to build an online beauty shop application that can provide recommendations for beauty shops in Bandar Lampung based on the beauty  shop rating. The application is built with a recommendation system using the Collaborative Filtering method. This research can make it easier to provide recommendations about beauty stores based on ratings given by other users. The feasibility test of the  software shows that the online beauty shop application with a recommendation system based on Collaborative Filtering was successfully tested using the Gutman scale questionnaire technique with good results.  
 
Kata Kunci: Beauty Shop, Recommendation System, Collaborative Filtering, Rating  
 
ABSTRAK 
Semakin banyaknya tempat kecantikan membuat konsumen kesulitan untuk menentukan toko kecantikan yang sesuai dengan kriteria yang dibutuhkan, misalnya toko kecantikan yang memiliki layanan perawatan wajah, perawatan tubuh dan rambut, kualitas bagus, dan harga terjangkau. Preferensi menciptakan rasa kepuasan yang berbeda untuk setiap orang. Kepuasan dalam hal ini adalah sejauh mana persepsi toko kecantikan tersebut sesuai dengan harapan pengguna.  Tujuan dari penelitian ini adalah membangun aplikasi toko kecantikan online yang dapat memberikan rekomendasi toko kecantikan di Bandar Lampung berdasarkan rating toko kecantikan tersebut. Aplikasi dibangun  dengan sistem rekomendasi menggunakan metode Collaborative Filtering.  Riset ini dapat memudahkan dalam memberikan rekomendasi tentang toko kecantikan berdasarkan rating yang diberikan oleh pengguna lain. Uji kelayakan perangkat lunak menunjukkan bahwa aplikasi toko kecantikan online dengan sistem rekomendasi berbasis Collaborative Filtering berhasil diuji dengan teknik angket skala Gutman dengan hasil yang baik.  
 
Kata Kunci : Beauty Shop, Sistem Rekomendasi, Collaborative Filtering, Rating

1. PENDAHULUAN  
Pesatnya perkembangan dan pertumbuhan teknologi informasi berdampak baik bagi perusahaan yang bergerak di bidang industri, penjualan dan jasa. Keberadaan teknologi informasi telah membawa metamorfosis  yang substansial  dalam proses transformasi bisnis menuju digitalisasi dan mobilitas [1]. Digitalisasi pemasaran dengan memanfaatkan teknologi online dapat memudahkan penawaran jasa atau promosi memiliki peluang yang sangat signifikan dalam memperluas pangsa pasar [2]. Digitalisasi pemasaran yang efektif akan mengubah pola pikir masyarakat tentang ketersediaan barang atau jasa. Respon akan perubahan suatu permintaan barang atau jasa sangat dipengaruhi oleh kegiatan pemasaran  pemasaran itu sendiri yang kemudian akan dipromosikan secara intensif melalui media massa berupa pemasaran dengan teknik modern [3]. Jika dilihat dari sisi pemilik usaha , digitalisasi pemasaran ini dapat memperluas area pema saran dan tentu saja akan memberikan kemudahan dalam  penyajian informasi. Dan jika dilihat dari sisi pelanggan, mencari barang atau jasa bisa didapatkan dengan mudah tanpa harus beranjak dari tempat duduk [4]. Perkembangan jasa kecantikan memang menjadi fenomena tersendiri, tentunya karena tuntutan hidup dan gaya hidup yang menuntut tampil lebih dari biasanya. Namun semakin banyaknya tempat kecantikan membuat konsumen kesulitan untuk menentukan toko kecantikan yang sesuai dengan kriteria yang dibutuhkan, misalnya toko kecantikan yang memiliki layanan perawatan wajah, perawatan tubuh dan rambut, kualitas bagus, dan harga terjangkau. Preferensi menciptakan rasa kepuasan yang berbeda untuk setiap orang. Kepuasan dalam hal ini adalah sejauh mana persepsi toko kecantikan tersebut sesuai dengan harapan pengguna.  Penelitian ini memiliki tujuan yakni membangun aplikasi toko kecantikan online (beauty shop online)  yang dapat memberikan rekomendasi toko kecantikan di Bandar Lampung berdasarkan rating toko kecantikan tersebut. Metode Collaborative Filtering  ini dilandaskan  pada konfrontasi  dan analisis banyak informasi tentang perilaku, aktivitas, atau selera pelanggan, dan memprediksi selera pelanggan berdasarkan kesamaan dengan pelanggan lain. Cara ini bertujuan untuk memberikan rekomendasi kepada pelanggan yang akan memilih atau membeli produk tertentu berdasarkan rating yang diberikan oleh pelanggan lain. Konsepnya sederhana, berupa asumsi bahwa seseorang yang menyukai produk tertentu juga akan menyukai produk tersebut.  Penelitian terdahulu menjelaskan bahwa  banyaknya produk yang ditawar kan menyulitkan sebagian pelanggan untuk menentukan pilihan produk apa yang akan dipilih dan sesuai dengan selera. Penerapan metode Collaborative Filtering  pada sistem rekomendasi pemilihan sepatu mampu memberikan rekomendasi produk sepatu yang sesuai deng an selera pelanggan, sehingga membantu mempermudah pelangga memilih sepatu yang akan dibeli [5]. Penerapan metode Collaborative Filtering  juga dapat membantu memberikan rekomendasi kepala pelanggan yang bingung memilih bahan dan desain plakat sesuai keinginan dan dengan harga yang bersahabat, di tengah banyaknya persaingan 
harga di pasar jasa pembuatan plakat [6]. Sementara penerapkan metode Collaborative Filtering  pada pemilihan buku dapat diterapkan dalam membuat sistem rekomendasi buku dengan menggunakan book proximity berdasarkan nilai rating. Hasilnya akan lebih akurat jika jumlah data yang digunakan banyak dan pengguna yang memberikan ratin g juga banyak . [7]. Cara kerja metode Collaborative Filtering  adalah dengan cara membuat database yang menyimpan berbagai macam item yang disukai pelanggan. Transaksi baru yang dilakukan oleh pelanggan akan disinkronkan dengan database untuk menangkap data historis yang paling layak dengan data baru. Kemudian disuguhkan sebagai sebuah rekomendasi kepada pelanggan yang bertransaksi  [8]. Sistem rekomendasi merupakan sesuatu yang krusial dari sistem informasi dan perdagangan elektronik. Sistem ini merupakan cara yang efektif untuk memilah berbagai informasi dan produk. Pencarian informasi yang akurat dan berkualitas sangat penting dalam banyak bidang kehidupan. Informasi  rating dibutuhkan agar dapat dengan mudah menemukan informasi yang berkualitas sesuai dengan preferensi pengguna dan rekomendasi banyak pihak [9]. 

2. METODOLOGI  
Tahap penelitian merupakan  kegiatan yang dilakukan secara terencana dan sistematis untuk mencapai tujuan tertentu. Tahapan penelitian dalam penelitian ini ditunjukkan pada Gambar 1. 
Gambar 1.  Tahapan Penelitian  
Tahap pertama adalah melakukan identifikasi  masalah. Review literatur mengenai penelitian ini diperoleh dari jurnal, buku dan e-book. Beberapa teknik pengumpulan data yang digunakan adalah observasi, wawancara, dokumentasi dan studi pustaka untuk memperoleh data yang valid. Objek penelitian diidentifikasi dengan definisi masalah dan ruang lingkup penelitian sehingga penelitian lebih terarah dan kurang ekstensif. Dan permasalahan utamanya adalah minimnya informasi tentang toko kecantikan yang memiliki kualitas  pelayanan yang baik sesuai rekomendasi dari pengguna lain.  
Tahapan kedua yaitu melakukan analisis dengan cara mengumpulkan data dan mengidentifikasi beberapa sampel jasa toko kecantikan di Kota Bandar Lampung untuk memperoleh informasi yang dibutuhkan untuk mencapai tujuan penelitian. Analisis kebutuhan sistem dilakukan untuk benar -benar memahami kebutuhan sistem baru dan mengembangkan sistem yang mengakomodasi kebutuhan sistem yang akan dibangun.  Tahapan ketiga yaitu melakukan pemodelan dengan membuat desain konseptual, desain database dan desain interface yang nantinya akan menjadi acuan dalam membangun aplikasi toko kecantikan online, dengan metode Collaborative Filtering berbasis android dan web.  Tahapan keempat adalah development sistem dan lakukan validasi sistem.   
3. HASIL DAN PEMBAHASAN  
A. Implementasi  Item -Based Collaborative Filtering  
1) Tahap  menghitung nilai kemiripan  
Tahap awal penghitungan nilai kesamaan antar item yang di beri rating  oleh pengguna . Bentuk penilaian dari pengguna berupa rating pada skala 1 -5. Berikut adalah hasil skenario pemeringkatan dengan 6 responden dan 6 produk jasa, yang dapat dilihat pada Tabel 1.
Tabel 1.  Skenario Rating  
No Nama Member  Produk 
Layanan A  Produk 
Layanan B  Produk 
Layanan C  Produk 
Layanan D  Produk 
Layanan E  Produk 
Layanan F  Rata-rata Rating  
1 Member 1  0 5 4 3 0 0 4.00 
2 Member 2  0 0 3 2 4 1 2.50 
3 Member 3  0 3 0 0 0 3 3.00 
4 Member 4  4 0 0 1 0 0 2.50 
5 Member 5  0 2 2 4 0 5 3.25 
6 Member 6  0 5 0 4 0 0 4.50 
Dengan menggunakan persamaan adjusted cosine , berikut kesamaan antara produk layanan B  dan layanan C . 
-1 
Dalam  menghitung nilai kemiripan, nilai yang akan dihasilkan oleh persamaan adjusted cosinus  berada pada rentang +1.0 hingga -1.0, sedangkan informasi korelasi antara kedua item tersebut diketahui jika  Nilai kesamaan 0 berarti kedua item tersebut tidak berkorelasi (independen). Nilai kesamaan mendekati +1.0 berarti kedua item tersebut cenderung mirip satu sama lain. Jadi jika rank suatu item diketahui maka rank item lain dapat diketahui dan disimpulkan dengan probabilitas tinggi. Dan nilai kesamaan mendekati -1.0 berarti kedua item tersebut saling bertentangan dan dalam hal ini juga peringkat suatu item dapat ditentukan berdasarkan peringkat item lainnya, namun keadaan saat ini adalah jika peringkat item  pertama meningkat maka peringkat item kedua akan sebaliknya, yaitu menurun.  Setelah menghitung kemiripan nilai lain dengan menggunakan rumus yang sama, diperoleh tabel nilai persamaan antar produk yang diperoleh seperti pada Tabel 2. Berdasarkan hitungan kemiripan pada Tabel 2 maka kemiripan ada pada Produk Layanan B dan Produk Layanan C, Produk Layanan C dengan Produk Layanan E, dan Produk Layanan D dengan Produk Layanan F.
Tabel 2. Kesamaan Antar Produk Layanan  
Produk Layanan 1  Produk Layanan 2  Nilai Kemiripan   Kemiripan  
Produk Layanan A  Produk Layanan B  0.00  Independen  
Produk Layanan A  Produk Layanan C  0.00  Independen  
Produk Layanan A  Produk Layanan D  -1.00  Bertentangan  
Produk Layanan A  Produk Layanan E  0.00  Independen  
Produk Layanan A  Produk Layanan F  0.00  Independen  
Produk Layanan B  Produk Layanan C  0.78  Mirip  
Produk Layanan B  Produk Layanan D  -0.97  Bertentangan  
Produk Layanan B  Produk Layanan E  0.00  Independen  
Produk Layanan B  Produk Layanan F  -1.00  Bertentangan  
Produk Layanan C  Produk Layanan D  -0.66  Bertentangan  
Produk Layanan C  Produk Layanan E  1.00  Mirip  
Produk Layanan C  Produk Layanan F  -0.95  Bertentangan  
Produk Layanan D  Produk Layanan E  -1.00  Bertentangan  
Produk Layanan D  Produk Layanan F  0.99  Mirip  
Produk Layanan E  Produk Layanan F  -1.00  Bertentangan  
2) Tahap mencari nilai prediksi  
Tahap selanjutnya, penciptaan nilai prediksi. Setelah 
mendapatkan satu set item yang sangat mirip berdasarkan penghitungan kesamaan, proses prediksi dijalankan yang akan memperkirakan nilai peringkat pengguna untuk item yang sebelumnya belum diberi peringkat oleh pengguna.  Setelah didapatkan nilai kesamaan antar produk jasa, nilai yang lebih besar dari 0 akan digunakan untuk mendapatkan nilai prediktif, karena nilai ini dianggap minimal untuk komunikasi antar produk. Untuk mendapatkan nilai prediksi produk yang belum dievaluasi oleh pengguna, digunakan persamaan penjumlahan terbobot  (weighted sum) . Perhitungan nilai prediksi Anggota 1 untuk produk layanan A, yaitu : -2 Setelah menghitung nilai prediksi  lainnya menggunakan rumus penjumlahan terbobot maka diperoleh tabel hasil prediksi pada Tabel 3. Berdasarkan hasil nilai prediksi di atas dapat dilihat bahwa member 1 mendapatkan rekomendasi produk layanan E, member 3 mendapatkan rekomendasi produk layana n D, member 4 mendapatkan rekomendasi produk layanan F, dan member 6 mendapatkan rekomendasi produk layanan C. 
Tabel 3. Hasil Nilai Prediksi  
Member  Produk Pelayanan  Prediksi  Kemiripan  
1 A -3.00 Bertentangan  
1 E 0.50 Mirip  
1 F -1.98 Bertentangan  
2 A -2.00 Bertentangan  
2 B -0.22 Bertentangan  
3 A 0.00 Independen  
3 C -0.29 Bertentangan  
3 D 0.03 Mirip  
3 E -3.00 Bertentangan  
4 B -1.00 Bertentangan  
4 C -1.00 Bertentangan  
4 E -1.00 Bertentangan  
4 F 1.00 Mirip  
5 A -4.00 Bertentangan  
5 E -2.33 Bertentangan  
Member  Produk Pelayanan  Prediksi  Kemiripan  
6 A -4.00 Bertentangan  
6 C 0.88 Mirip  
6 E -4.00 Bertentangan  
6 F -0.52 Bertentangan   
B. Uji Kelayakan Sistem  
Pada tahap ini, sistem yang dibangun dan menjalankan fungsi -fungsi yang dibutuhkan akan diuji menggunakan metode black box test untuk mengukur aspek fungsional interface sistem informasi. Pengujian kelayakan dilakukan dengan menggunakan test case berupa checklist yang menunjukkan analisis kebutuhan program. Dari daftar ini, ku esioner dibuat untuk melihat apakah fungsi tampilan berfungsi dengan baik atau sebaliknya.   Pengukuran fungsional antarmuka dilakukan oleh beberapa administrator toko. Pengujian kelayakan sistem ini menggunakan skala Guttmann. Skala Guttman sangat baik dalam memastikan  integritas  dimensi dan sikap atau sifat yang dipelajari, yang sering disebut atribut universal [10]. Penilaian perhitungan responden pada skala Guttman dapat dilihat pada Tabel 4 berikut.
Tabel  4. Skoring Skala Guttman  
Alternatif Jawaban  Skor  Positif  Negatif  
Ya 1 0 
Tidak  0 1 
Tanggapan  responden dapat digunakan sebagai skor terendah adalah """"nol"""" dan skor tertinggi adalah """"satu"""". Untuk alternatif jawaban dalam kuisioner diberikan kategori pernyataan positif yaitu Ya = 1 dan Tidak = 0, sedangkan kategori untuk setiap pernyataan negatif adalah Ya = 0 dan Tidak = 1. Penelitian ini menggunakan skala Gutmann dalam berbentuk checklist, sehingg a diharapkan mendapat jawaban yang tegas tentang data yang diperoleh.  Setelah memperoleh data tes instrumen, tabulasi dilakukan pada tabel Guttman dengan menata butir-butir berdasarkan skor jawaban """"Ya"""" tertinggi hingga terendah. Lantaran  instrumen pada penelitian sistem rekomendasi layanan jasa kecantikan  menggunakan angket skala Guttman, maka koefisien reproduktifitas digunakan untuk mendapatkan  tingkat validitas angket.  Uji kelayakan fungsional sistem ini melibatkan 5 admin beauty shop  di Bandar Lampung dengan menggunakan kuesioner yang telah disediakan yang berisi beberapa daftar fungsi pada aplikasi beauty shop seperti yang ditentukan dalam analisis kebutuhan sistem. 
Tabel  5. Uji Kelayakan Sistem  
No Interface  Fungsional  Ya Tidak  
1  Login  Aplikasi beauty shop  dapat melakukan login dengan baik  5 0 
2  Logout  Aplikasi beauty shop  dapat melakukan logout  dengan baik  5 0 
3  Beranda  Aplikasi beauty shop  dapat menampilkan halaman beranda sistem  5 0 
4  Data Pelayanan  Aplikasi beauty shop  dapat melakukan tambah data pelayanan  5 0 
5  Data Pelayanan  Aplikasi beauty shop  dapat melakukan ubah data pelayanan  5 0 
6  Data Pelayanan  Aplikasi beauty shop  dapat melakukan hapus data pelayanan  5 0 
7  Data Kategori  Aplikasi beauty shop  dapat melakukan tambah data kategori  5 0 
8  Data Kategori  Aplikasi beauty shop  dapat melakukan ubah data kategori  5 0 
9  Data Kategori  Aplikasi beauty shop  dapat melakukan hapus data kategori  5 0 
10  Data Petugas  Aplikasi beauty shop  dapat melakukan tambah data petugas  5 0 
11  Data Petugas  Aplikasi beauty shop  dapat melakukan ubah data petugas  5 0 
12  Data Petugas  Aplikasi beauty shop  dapat melakukan hapus data petugas  5 0 
13  Foto Salon  Aplikasi beauty shop  dapat melakukan update  foto-foto salon  5 0 
14  Appoint -ment Aplikasi beauty shop  dapat melakukan validasi booking user (tolak/terima)  5 0 
15  Data Pembayaran  Aplikasi beauty shop  dapat melakukan ubah status pembayaran  5 0 
16  Data Pembayaran  Aplikasi beauty shop  dapat melakukan hapus data pembayaran  5 0 
17  Edit Profil  Aplikasi beauty shop  dapat melakukan perubahan profil  dengan baik  5 0 
  e = Jumlah Error  0 
  n = Jumlah Responden * Banyak Pertanyaan = 5 * 17 = 85 
Koefisien reprodusibilitas pada sistem rekomendasi beauty shop  adalah  
Kr = 1 â€“ ( e / n  ) 
Kr = 1 â€“ ( 0 / 85 )           (3) 
Kr = 1 â€“ 0 
Kr = 1 
Selanjutnya dilakukan penghitungan koefisien reprodusibilitas (Kr) atau fungsional interface sistem dimana e adalah jumlah kesalahan atau jumlah total fungsi yang tidak valid, dan n dinotasikan sebagai jumlah total pilihan jawaban yaitu jumlah pertanyaan dikali jumlah responden.  Setelah dilakukan  uji instrumen dengan 17 pertanyaan pada 5 responden dan kesalahan total 0, reproduktifitas atau koefisien fungsional sistem adalah 
1. Rumus pengukuran fungsionalitas menjelaskan 
bahwa nilai yang mendekati angka 1 (0 <= Kr <= 1)  
dianggap sudah baik. Berdasarkan hasil tersebut, maka 
hasil uji instrumen pada sistem rekomendasi beauty shop 
ini dianggap memenuhi kriteria layak.  

4. KESIMPULAN  
Untuk memudahkan pengguna dalam menentukan salon kecantikan berdasarkan rating yang diberikan oleh pengguna lain, disediakan fitur rekomendasi. Fitur rekomendasi dibangun dengan mekanisme pemfilteran kolaboratif. Metode kolaboratif filtering merupakan metode yang tepat untuk diterapkan pada aplikasi toko kecantikan online dimana layanan yang direkomendasikan adalah layanan yang memiliki nilai rating tertinggi, sehingga memudahkan pengguna untuk menemukan informasi yang diinginkan secara cepat dan akurat. Be rdasarkan hasil pengujian kelayakan perangkat lunak menunjukkan bahwa aplikasi toko kecantikan online dengan sistem rekomendasi metode Collaborative Filtering  telah memenuhi kriteria layak.  

5. DAFTAR PUSTAKA  
[1] K. C. Laudon and C. G. Traver, E-Commerce 2014, 10th Edition , 10th ed. New York: Pearson, 2014.  
[2] J. Bernadi, â€œAplikasi Sistem Informasi Penjualan Berbasis Web pada Toko Velg YQ,â€ ComTech Comput. Math. Eng. Appl. , vol. 4, no. 2, pp. 731 â€“741, 2013, doi: 10.21512/comtech.v4i2.2504.  
[3] E. Erlangga and A. Furqon, â€œPortal e-Brosur 
Berbasis Modern Advertisi ng Methods Untuk Efektifitas Periklanan,â€ Expert J. Manaj. Sist. Inf. dan Teknol. , vol. 4, no. 1, pp. 20 â€“42, Jun. 2014, doi: 10.36448/jmsit.v4i1.488.  
[4] E. Erlangga, M. H. Anggraini, F. Ariani, and 
Y. Aprilinda, â€œAplikasi E -Marketing Panglong Kayu Menggun akan Metode Colaborative Filtering,â€ Explor. J. Sist. Inf. dan Telemat. , vol. 11, no. 1, pp. 57 â€“66, 2020, doi: 10.36448/jsit.v11i1.1460.  
[5] A. Kurniawan, â€œSistem Rekomendasi Produk Sepatu dengan Menggunakan Metode Collaborative Filtering,â€ Semin. Nas. Teknol. Inf. dan Komun. , pp. 610 â€“614, 2016, [Online]. Available: https://fti.uajy.ac.id/sentika/publikasi/makalah/2016/92.pd.  
[6] I. W. G. P. D armaja and I. B. M. Mahendra, 
â€œAplikasi E -commerce dengan Sistem Rekomendasi Berbasis Collaborative Filtering pada Penjualan Plakat,â€ in Prosiding Seminar Nasional Teknologi Informasi & Aplikasinya , 2015, pp. 242 â€“549. 
[7] M. Irfan, A. D. C., and F. H. R., â€œSistem Rekomendasi: Buku Online dengan Metode Collaborative Filtering,â€ J. Teknol. Technoscientia , vol. 7, no. 1, pp. 76 â€“84, 2014.  
[8] G. I. Marthasari, Y. Azhar, and D. K. Puspitaningrum, â€œSistem Rekomendasi Penyewaan Perlengkapan Pesta Menggunakan Colla borative Filtering dan Penggalian Aturan Asosiasi,â€ J. SimanteC , vol. 5, no. 1, pp. 1 â€“8, 2015.  
[9] E. B. Prasetya, â€œPerancangan Web Rank Menggunakan Collaborative Filtering Berdasarkan Kemiripan Konten,â€ Pros. Semnastek (Seminar Nas. Sains dan Teknol. , no. November, pp. 12 â€“14, 2015.  
[10] U. Rianse and Abdi, Metodologi Penelitian Sosial 
dan Ekonomi: Teori dan Aplikasi . Bandung, Indonesia: Alfabeta, 2013.",sistem rekomendasi,collaborative filtering,toko kecantikan di kota Bandar Lampung,skoring skala guttman
"Implementasi Algoritma Naive Bayes Classifier sebagai Sistem Rekomendasi Pembimbing Skripsi 
","Implementasi Algoritma Naive Bayes Classifier sebagai Sistem Rekomendasi Pembimbing Skripsi 

Marsani Asfi, Nopi Fitrianingsih 

ABSTRACT 
Dosen pembimbing memiliki peran mendampingi mahasiswa dalam proses penyusunan skripsi. Penentuan awal calon pembimbing diberbagai kampus seringkali bers ifat subjektif dan kebijakan langsung oleh ketua program studi ataupun dipilih langsung oleh mahasiswa. Penentuan dosen pembimbing terkadang belum dilakukan penyesuaian antara bidang ilmu skripsi yang dipilih mahasiswa dengan kompetensi dosen yang bersangkutan. Oleh karena itu, diperlukan suatu sistem pendukung keputusan dengan penerapan metode yang  tepat untuk menentukan dosen pembimbing. Algoritma Naive Bayes Classifier  merupakan sebuah metode klasifikasi. Pada penelitian ini digunakan acuan data training dosen pembimbing 1 sebanyak 217 dan data training dosen pembimbing 2 sebanyak 177, sedangkan data uji yang digunakan sebanyak 10 data.  Kriteria yang digunakan adalah kompetensi, jabatan fungsional dan homebase  dosen. Implementasi algoritma Naive Bayes Classifier  disisipkan dalam aplikasi sistem pengajuan skripsi terintegrasi SIMASITA CIC. Berdas arkan hasil pengujian algoritma Naive Bayes Classifier  didapatkan perbandingan tingkat kesesuaian dosen pembimbing 1 
sebesar 90% : 10% dan perbandingan tingkat kesesuaian dosen pembimbing 2 sebesar 30% :70%.  

KEYWORDS
Dosen Pembimbing, Skripsi, Naive Bayes Classifier . 
 
PENDAHULUAN 
Skripsi merupakan karya tulis ilmiah mahasiswa sebagai bagian dari persyaratan akhir pendidikan akademisnya[1]. Skripsi bertujuan agar mahasiswa mampu menyusun dan menulis suatu karya ilmiah sesuai dengan bidang ilmunya[2]. Dalam proses penyusunan skripsi, dosen pembimbing skripsi memiliki peran penting karena memiliki tanggung jawab untuk membimbing mahasiswa agar dapat menyelesaikan skripsi dengan baik dan tepat waktu sehingga skripsi tersebut berkualitas. Peranan dosen pembimbing skripsi secara garis besar adalah sebagai organisator, fasilitator, inovator, teladan, evaluator, konselor, motivator dan pemberi energi [3]. Salah satu permasalahan yang terjadi adalah pada tahap penentuan dosen pembimbing skripsi yaitu masih ditentukan berdasarkan subjektifitas dan kebijakan ketua program studi. Penentuan dosen pembimbing terkadang belum dilakukan penyesuaian antara bidang ilmu skripsi yang dipilih mahasiswa dengan kompetensi dosen yang bersangkutan. Oleh karena itu, diperlukan suatu sistem pendukung keputusan dengan penerapan metode yang tepat untuk menentukan dosen pembimbing. Salah satu metode yang dapat digunakan untuk sistem rekomendasi dosen pembimbing skripsi adalah algoritma Naive Bayes Classifier . Berdasarkan penelitian sebelumnya, menyatakan bahwa salah satu keunggulan penggunaan algoritma Naive Bayes Classifier  adalah nilai keputusan yang dihasilkan pada nilai probabilistik dengan independensi (ketidak bergantungan) yang kuat [4] . Naive Bayes Classifier  (NBC) adalah salah satu dari algoritma supervised document classification  (klasifikasi dokumen dengan pengawasan) yang sederhana namun efisien [5]. Algoritma Naive Bayes Classifier  dapat dijadikan suatu teknik untuk sistem rekomendasi dosen pembimbing dengan hasil perhitungan probabilitas antar kriteria yang telah ditentukan. Dengan adanya sistem rekomendasi dosen pembimbing , diharapkan dapat meningkatkan efisiensi waktu dan membantu ketua program studi dalam menentukan dosen pembimbing yang tepat sesuai dengan bidang ilmu skripsi mahasiswa dengan kompetensi dosen yang bersangkutan. Dalam penelitian ini, kriteria yang digunakan adalah  kompetensi,  jabatan fungsional dan homebase  dosen. Data history pembimbingan beberapa tahun sebelumnya dijadikan sebagai data training, sedangkan data testing digunakan untuk menguji  tingkat kesesuaian penentuan dosen pembimbing yang telah ditentukan oleh ketua program studi sebelumnya. 
A. Algoritma Naive Bayes Classifier 
Naive Bayes Classifier  merupakan sebuah metode klasifikasi 
yang berakar pada teorema Bayes[6]. Metode pengklasifikasian 
dengan menggunakan metode probabilitas dan statistik. Naive 
Bayes Classifier  memprediksi peluang di masa depan berdasarkan pengalaman di masa sebelumnya.  Formulasi umum dari prediksi bayes adalah sebagai berikut : 
ð‘ƒ(ð»|ð‘‹)=ð‘ƒ(ð‘‹|ð»).ð‘ƒ(ð»)
ð‘ƒ(ð‘‹)                     .... (1) 
Naive Bayes Classifier  menggunakan asumsi yang sangat kuat 
(naif) akan independensi dari masing-masing kondisi atau 
kejadian[5], dimana masing-masing petunjuk saling bebas 
(independen) satu sama lain. Dengan asumsi tersebut, maka 
berlaku suatu persamaan sebagai berikut : 
ð‘ƒ(ð»|ð‘‹)=  ð‘ƒ(ð») âˆ ð‘ƒ(ð‘‹ ð‘–|ð») ð‘›
ð‘–=1                                  ... (2) 
Keterangan : 
X : Data testing yang kelasnya belum diketahui. 
H : Hipotesis data X yang merupakan suatu kelas 
yang  lebih spesifik. 
P(H|X)   : Probabilitas hipotesis berdasar kondisi 
(posteriori probability. 
P(X|H) : Probabilitas hipotesis X berdasarkan kondisi H 
(disebut juga likelihood ). 
P(H) : Probabilitas hipotesis H ( prior probability ) 
P(X) : Probabilitas hipotesis X ( predictor prior  
probability ) 
Ide dasar dari aturan bayes adalah bahwa hasil dari hipotesis atau peristiwa (H) dapat diperkirakan berdasarkan pada beberapa bukti (X) yang diamati. Beberapa hal yang perlu diperhatikan : 
a. Sebuah probabilitas awal atau prior H atau P(H) adalah 
probabilitas dari suatu hipotesis sebelum bukti diamati. 
b. Sebuah probabilitas akhir H atau P(H|X) adalah probabilitas dari suatu hipotesis setelah bukti diamati.  
Algoritma Naive Bayes Classifier sangat cocok untuk melakukan klasifikasi pada dataset bertipe nominal. Untuk dataset bertipe nominal, perhitungannya menggunakan persamaan (1). Apabila dataset bertipe numerik maka digunakan perhitungan distribusi Gaussian. Perhitungan distribusi Gaussian dapat dilihat dari  persamaan (3), dimana dihitung terlebih dahulu nilai rata-rata Âµ sesuai pada persamaan (4), dan standard deviasi Ïƒ sesuai pada persamaan (5) [6]. Tipe data nominal adalah jenis data yang diperoleh dengan cara kategorisai atau klasifikasi, dan menunjukkan beberapa objek yang berbeda, contohnya : kode pos, jenis kelamin, nama kota, dan lain-lain. Sedangkan tipe data numerik adalah jenis data yang diperoleh dengan cara pengukuran dimana jarak dua titik pada skala sudah diketahui, contohnya:  umur, berat badan, tinggi badan, jumlah uang, dan lain-lain[6].  
ð‘“(ð‘¥)=  1
âˆš2ðœ‹.ðœŽ ð‘’âˆ’(ð‘¥âˆ’ðœ‡)2
2ðœŽ2                                  ... (3) 
ðœ‡ =  âˆ‘ð‘¥ð‘–ð‘›
ð‘–
ð‘›                                                      ... (4) ðœŽ =  âˆšâˆ‘(ð‘¥ð‘–âˆ’ðœ‡)2 ð‘›
ð‘–
ð‘›âˆ’1                                                    ... (5) 
Keterangan : 
f(x) : nilai gaussian 
x : nilai data 
Âµ : nilai rata-rata (mean) 
Ïƒ : standar deviasi 
Ï€ : nilai phi ( 3,146 atau 22â„7)  
e : 2, 7183 
x_i : nilai data ke-i 
n : jumlah data 
Langkah-langkah Algoritma Naive Bayes Classifier  adalah sebagai berikut : 
1) Menyiapkan dataset. 
2) Hitung jumlah kelas pada data training. 
3) Hitung jumlah kasus yang sama dengan kelas yang sama. 
Jika data atribut bertipe nominal maka gunakan persamaan 
(1). Sedangkan jika data atribut bertipe numerik maka 
gunakan persamaan (3). 
4) Kalikan semua hasil sesuai dengan data testing yang akan 
dicari kelasnya dengan menggunakan persamaan (2). 
Kemudian kalikan dengan hasil dari langkah kedua (jumlah 
kelas pada data training). 
5) Bandingkan hasil per kelas, nilai tertinggi ditetapkan sebagai kelas baru. 

METODE PENELITIAN 
A. Tahapan Penelitian 
Diagram alir tahapan penelitian seperti pada gambar 1. 
Perhitungan jumlah kelas 
Perhitungan jumlah kasus yang sama dengan kelas yang sama Perhitungan jumlah kasus yang sama dengan kelas yang sama
Perkalian semua hasil sesuai dengan data testing yang akan dicari kelasnya
Mengurutkan nilai probabilitas dari yang tertinggi
Penyesuaian kelas berdasarkan jabatan fungsional dan homebase  dosenPenyesuaian kelas berdasarkan jabatan fungsional dan homebase  dosen
Selesai
Data training 
Data training
Mulai
Data testing
Data testing
Rekomendasi dosen pembimbing 1 dan 2
Rekomendasi dosen pembimbing 1 dan 2 
Gambar 1. Proses Algoritma Naive Bayes Classifier  
Proses sistem rekomendasi dosen pembimbing skripsi dengan 
menggunakan algoritma naive bayes classifier  seperti pada 
gambar 1, yaitu :    
1) Menyiapkan dataset. 
Dataset terbagi menjadi 2 bagian yaitu data training  dan data testing . Sumber data training  merupakan data skripsi semua program studi di Universitas Catur Insan Cendekia. Data training terdiri dari data training untuk pembimbing 1 sebanyak 217, sedangkan data training untuk pembimbing 2 sebanyak 117. Sedangkan Sumber data data testing  merupakan data skripsi mahasiswa/i Universitas CIC yang akan dicari rekomendasi dosen pembimbing yang tepat. Data testing yang digunakan adalah sebanyak 10.  
Tabel 1. Jenis dan Jumlah data yang digunakan. 
No Jenis Data Pemb. 1 Pemb. 2 
1 Data Training 217 117 
2 Data Testing 10 10 
Dari tabel 1. Jumlah 217 dan 117 data training terdiri dari 
jumlah data pembimbing 1 dan 2 dari 5 Program studi. Sedangkan untuk jumlah 10 data testing diambil dari data pembimbingan skripsi di tahun berjalan.  
Selain dataset seperti tabel 1. Data set yang sesusia dengan 
kriteria yang digunakan yaitu kompetensi, jabatan fungsional dan homebase  dosen juga digunakan, seperti tabel 2, tabel 3 dan tabel 4. 
Tabel 2. Deskripsi Dataset Kompetensi 
No Nama Kompetensi Dosen 
1 Sistem Penunjang Keputusan 
2 Internet of Things 
3 Games 
4 Image Processing 
5 Data Mining 
6 Networking Security 
7 Model and Simulation 
8 Sistem Informasi 
9 Sistem Pakar 
10 Sistem Informasi Akuntansi 
11  Desain Komunikasi Visual 
12 Manajemen 
Tabel 3. Deskripsi Dataset Jabatan Fungsional 
No Nama Jabatan Fungsional Dosen 
1 Tenaga Pengajar 
2 Assisten Ahli 
3 Lektor 
4 Lektor Kepala 
5 Professor 
Tabel 4. Deskripsi Dataset Homebase Dosen 
No Nama Homebase Dosen 
1 Teknik Informatika (TI) 
2 Sistem Informasi (SI) 
3 Desain Komunikasi Visual(DKV) 
4 Manajemen (Mnjm) 
5 Akuntansi  (Akt) 
6 Manajemen Bisnis (MB) 
7 Manajemen Informatika (MI) 
8 Komputerisasi Akuntansi (KA) 
2) Perhitungan jumlah kelas. Tabel 5 contoh untuk mendapatkan nilai probabilitas dari setiap dosen. Dihitung dengan formula jumlah kelas dosen pembimbing dibagi total kelas dosen pembimbing.  
Tabel 5. Perhitungan Jumlah Kelas (Dosen Pembimbing 1) 
Prob. Dosen Jumlah Kelas/Total Kelas Nilai Probabilitas 
P(C=AN) = 3 / 217 = 0,013825 
P(C=AF) = 2 / 217 = 0,009217 
P(C=AS) = 6 / 217 = 0,027650 
P(C=Amr) = 17 / 217 = 0,078341 
P(C=AW) = 4 / 217 = 0,018433 
P(C=CL) = 1 / 217 = 0,004608 
P(C=DM) = 13 / 217 = 0,059908 
P(C=D MP) = 5 / 217 = 0,023041 
P(C=FA) = 10 / 217 = 0,046083 
P(C=FW ) = 2 / 217 = 0,009217 
dstnya........ 
Untuk dosen pembimbing 2, dilakukan dengan cara perhitungan yang sama.  
3) Perhitungan jumlah kasus yang sama dengan kelas yang 
sama.  
Tabel 6 adalah setiap kriteria yang sesuai dengan data testing  
akan dihitung nilai probabilitas bersyarat dari setiap dosen 
pembimbing. Pada penelitian ini, dihitung nilai probabilitas kompetensi dan homebase  setiap dosen sesuai dengan data testing dengan formula jumlah kompetensi atau homebase dibagi jumlah kelas dosen pembimbing.  
Tabel 6. Perhitungan jumlah kasus/kelas yang sama  
Kompetensi Dosen|Nama   Nilai Probabilitas 
P(Kompetensi=SIA|C=AN) 0/3 = 0,000000 
P(Kompetensi=SIA|C=AF) 0/2 = 0,000000 
P(Kompetensi=SIA|C=AS) 0/6 = 0,000000 
P(Kompetensi=SIA|C=Amr) 3/17 = 0,176471 
P(Kompetensi= SIA |C=AW) 0/4 = 0,000000 
P(Kompetensi=SIA|C=CL) 0/1 = 0,000000 
P(Kompetensi=SIA |C=DM) 12/13 = 0,923077 
P(Kompetensi= SIA |C=D MP) 0/5 = 0,000000 
P(Kompetensi= SIA |C=FA) 0/10 = 0,000000 
P(Kompetensi=SIA | C=FW) 1/2 = 0,500000 
dstnya....... 
4) Perkalian semua hasil sesuai dengan data testing  yang akan dicari kelasnya. 
Selanjutnya, dihitung nilai probabilitas setiap dosen 
pembimbing dengan mengalikan semua hasil dari tahap 2 dan 3 tersebut.  
Sebagai contoh perhitungan : 
P{(Kompetensi=Sistem Informasi Akuntansi |  
C=Amroni)*(Prodi=SI | C=Amroni)*(C=Amroni)} = 
0,937500*0,750000*0,090395 = 0,063559  
5) Mengurutkan nilai probabilitas dari yang tertinggi. 
6) Penyesuaian kelas berdasarkan jabatan fungsional dan homebase  dosen.  
Tabel 7 merupakan hasil penyesuaian kelas berdasarkan 
jafung dan homebase. Rekomendasi dosen pembimbing dilakukan penyesuaian jabatan fungsional dan homebase  sesuai dengan ketentuan berikut : 
a. Dosen yang akan direkomendasikan sebagai pembimbing 1 adalah dosen yang memiliki homebase sesuai dengan program studi mahasiswa/i serta minimal memiliki jabatan fungsional Asisten Ahli. 
b. Dosen yang akan direkomendasikan sebagai pembimbing 2 adalah dosen yang memiliki jabatan fungsional minimal Tenaga Pengajar serta memiliki homebase sesuai dengan program studi mahasiswa/i atau dapat juga diluar dari program studi mahasiswa/i.  
Tabel 7. Penyesuaian kelas berdasarkan homebase  dosen. 
Dosen Nilai Probabilitas Jabatan Fungsional Homebase 
MA 0,055300 Lektor SI 
MH 0,055300 Asisten Ahli SI 
FW 0,004608 Lektor SI 
IS 0,004608 Tenaga Pengajar SI 
LM 0,032258 Lektor SI 
7) Rekomendasi dosen pembimbing 1 dan 2. 
Hasil dari perhitungan algoritma naive bayes classifier tersebut berupa nama dosen yang direkomendasikan sebagai pembimbing 1 dan 2.  
B. Metode Pengembangan Sistem 
Dalam penelitian ini, digunakan metode pengembangan sistem 
dengan pendekatan terstruktur dan sistematis sesuai dengan 
pradigma Waterfall Model . Gambar 2, merupakan tahapan dari metode  Waterfall Model  :  
Communication  
Project Initiation & Requirements 
Gathering Planning  
Estimating, 
Scheduling, 
Tracking Modeling
Analysis & Design Construction  
Code & Test Deployment 
Delivery, 
Support, 
Feedback 
Gambar 2. Metode Waterfall [1][7] 
Keterangan : 
1. Communication (Project Initiation & Requirements 
Gathering) 
Komunikasi awal dengan customer  yaitu ketua program studi dilakukan untuk memahami alur proses bisnis. Hasil komunikasi tersebut dijadikan dasar untuk menganalisis 
permasalahan yang dihadapi dan mengumpulkan data-data 
yang diperlukan, dan mendefinisikan fitur dan fungsi dari 
aplikasi. Pengumpulan data-data tambahan diperoleh dari 
jurnal, artikel, paper  dan internet.  
2. Planning (Estimating, Scheduling, Tracking) 
Tahapan perencanaan menjelaskan tentang estimasi tugas-tugas teknis yang akan dilakukan, resiko- resiko yang dapat terjadi, sumber daya yang diperlukan dalam membuat sistem, 
produk kerja yang ingin dihasilkan, penjadwalan kerja yang 
akan dilaksanakan, dan tracking  proses pengerjaan sistem.    
3. Modeling (Analysis & Design) 
Tahapan modeling  adalah tahap perancangan dan pemodelan 
arsitektur sistem yang berfokus pada perancangan struktur data, arsitektur software , tampilan interface , dan algoritma program. Tujuannya untuk lebih memahami gambaran besar dari apa yang akan dikerjakan.  
4. Construction (Code & Test) 
Tahapan construction  merupakan proses penerjemahan bentuk desain menjadi kode atau bentuk bahasa yang dapat dibaca oleh mesin. Setelah pengkodean selesai, dilakukan pengujian terhadap sistem dan juga kode yang sudah dibuat. Tujuannya untuk menemukan kesalahan yang mungkin terjadi untuk nantinya diperbaiki.   
5. Deployment (Delivery, Support, Feedback) 
Tahapan deployment  merupakan tahapan implementasi software  ke customer , perbaikan, evaluasi dan pengembangan software  berdasarkan umpan balik yang diberikan agar sistem dapat tetap berjalan dan berkembang sesuai dengan fungsinya. 

HASIL DAN PEMBAHASAN 
A. Hasil Implementasi Sistem 
Gambar 3 dan 4 merupakan sebagian  form dalam sistem SIMASITA CIC yang digunakan ketua program studi untuk melakukan validasi penentuan dosen pembimbing skripsi. Pada 
form ini ditampilkan form login sistem serta rekomendasi dosen pembimbing 1 dan 2 dari perhitungan algoritma naive bayes classifier. 
Gambar 3. Form Login sistem SIMASITA CIC  
Gambar 4. Halaman Penentuan Dosen Pembimbing 
Tabel 8 . Implementasi untuk Data testing 1 sd data testing 10 
No Mahasiswa Prodi Bidang Ilmu/Kompetensi Pembimbing 
1 & 2 
1 Mahasiswa : Leony Rizka Mutiara SI Sistem Informasi 
Akuntansi Pembimbing 1 : Marsani Asfi 
Pembimbing 2 : Amroni 
Judul Skripsi : Analisis Umur Piutang Atas Biaya Kuliah Dengan Metode Pencatatan Ledgerless Bookkeeping Studi Kasus : Universitas CIC Cirebon. 
2 Mahasiswa : Wahyu Septiawan TI Keamanan Jaringan Pembimbing 1 : Ridho Taufiq Subagio 
Pembimbing 2 : Muhammad Hatta 
Judul Skripsi : Analisis dan Implementasi Security Network  Fail2ban  terhadap Serangan Dos Pada Web Server  (Studi Kasus : Universitas CIC).  
3 Mahasiswa : Haeva Reza Amri TI Sistem Informasi 
Pembimbing 1 : Ridho Taufiq Subagio 
Pembimbing 2 : Kusnadi 
Judul Skripsi : Penerapan Metode Customer Satisfaction Index  (CSI) untuk Mengukur Tingkat Kepuasan Layanan Manajemen Universitas Catur Insan Cendekia.  
4 Mahasiswa : Cindy Natalia Tanu SI Sistem 
Informasi Pembimbing 1 : Lena Magdalena 
Pembimbing 2 : Muhammad Hatta 
Mahasiswa : 
Judul Skripsi : Sistem Informasi Pengelolaan Alumni berdasarkan IAPS 4.0.  
5 Mahasiswa : Leilly TI Sistem 
Informasi Pembimbing 1 : Kusnadi 
Pembimbing 2 : Tiara Eka Putri 
Judul Skripsi : Rancangan Bangun Aplikasi LINE Chatbot Informasi dan Edukasi Kesehatan Mental.  
6 Mahasiswa : Surandi TI Networking 
Pembimbing 1 : Ridho Taufiq Subagio 
Pembimbing 2 : Kusnadi 
Judul Skripsi : Implementasi Load Balancing  Menggunakan NGINX  dengan Metode Round Robin Pada Learning Management System Moodle .  
7 Mahasiswa : Yunika Renatalia  SI Sistem Penunjang Keputusan 
Pembimbing 1 : Marsani Asfi 
Pembimbing 2 : Rifqi Fahrudin 
Judul Skripsi : Sistem Pendukung Keputusan Pemilihan Jurusan dengan Metode Profil Matching   
8 Mahasiswa : Rizky Arbilah  TI IOT 
Pembimbing 1 : Kusnadi 
Pembimbing 2 : Wanda Ilham 
Judul Skripsi : Penyiraman Air dan Nutrisi  Otomatis Menggunakan Arduino Uno (Studi Kasus : Kebun Buah Naga Desa Winduhaji).  
9 Mahasiswa : Rizki Yulistiani MB Manajemen 
Pembimbing 1 : Amroni  
Judul Skripsi : Pengaruh Brand Image dan Biaya Ongkir Terhadap Keputusan Konsumen dalam Menggunakan Jasa JNE di Kota Cirebon 10 
Mahasiswa : Adjie Priyanto KA Sistem Informasi 
Akuntansi 
Pembimbing 1 : Suwandi 
Pembimbing 2 : Agus Sevtiana 
Judul Skripsi : Sistem Informasi Penjualan Tunai Obat Menggunakan Metode Cash Basis Pada Apotek Jasa Prima Medical Centre  Cirebon.   
Data testing pada tabel 8, kemudian digunakan dalam proses 
implementasi sistem seperti pada gambar 5 sampai dengan 
gambar 14. Berikut adalah tampilan implementasi form  rekomendasi dosen pembimbing skripsi dengan menggunakan algoritma naive bayes classifier  dengan 10 data testing  mengikuti 7 tahapan seperti pada gambar 1.  
Tahap 1 : Menyiapkan dataset.  
Gambar 5. Data Testing  1   
Gambar 6. Data Training  Dosen Pembimbing 1 
Tahap 2 : Perhitungan jumlah kelas. 
Dosen Pembimbing 1  
Gambar 7 . Step 1 Penentuan Dosen Pembimbing 1 
Tahap 3: Perhitungan jumlah kasus yang sama dengan kelas yang sama.  
Dosen Pembimbing 1  
Gambar 8 . Step 2 Penentuan Dosen Pembimbing 1 (Bidang 
Ilmu/ Kompetensi) 
Gambar 9 . Step 2 Penentuan Dosen Pembimbing 1 (Prodi/Homebase) 
Tahap 4 : Perkalian semua hasil sesuai dengan data testing  yang akan dicari kelasnya. 
a. Dosen Pembimbing 1 
Gambar 10. Step 3 Penentuan Dosen Pembimbing 1 
b. Dosen Pembimbing 2 
Perlakuan yang sama dilakukan untuk penentuan calon pembimbing 2. Hasil seperti pada sistem gambar 10. 
Gambar 11 . Step 3 Penentuan Dosen Pembimbing 2 
Tahap 5 : Mengurutkan nilai probabilitas dari yang tertinggi.  
Dosen Pembimbing 1 
Gambar 12 . Step 4 Penentuan Dosen Pembimbing 1   
Tahap 6: Penyesuaian kelas berdasarkan jabatan fungsional dan homebase  dosen. 
Dosen Pembimbing 1  
Gambar 13 . Step 5 Penentuan Dosen Pembimbing 1   
Tahap 7 : Rekomendasi dosen pembimbing 1 dan 2. 
Dosen Pembimbing 1 
Gambar 14. Rekomendasi Dosen Pembimbing 1 
Ketujuh tahapan tersebut akan diperlakukan sama untuk data 
testing selanjutnya, baik untuk calon pembimbing 1 dan calon 
pembimbing 2. Hasil implementasi untuk 10 data testing lainnya diperoleh seperti pada tabel 9.  
Tabel 9. Hasil Implementasi 10 Data testing. 
Mhs ke-   Nama Pembimbing Pembimbing berdasarkanNaive Bayes  
1 2  1 2 
1 MA Amr  MA Amr 
2 RTS MH  RTS MH 
3 RTS Kus  RTS Kus 
4 LM MH  LM FW 
5 Kus TEP  Kus PS 
6 RTS Kus  RTS MA 
7 MA RF  MA WJL  
8 Kus WI  Kus PS 
9 Amr -  Amr LN 
10 Suw AS  DM Amr 
Nilai probabilitas hasil perhitungan seperti pada Tabel.10  
Tabel 10. Nilai Probabilitas 10 Data testing. 
Mhs ke-   Nama Pembimbing Nilai  Probabilitas  
1 2  1 2 
1 MA Amr  0,05543 0,063559 
2 RTS MH  0,01382 0,008475 
3 RTS Kus  0,02304 0,019328 
4 LM FW  0,02304 0,00565 
5 Kus PS  0,01382 0,011299 
6 RTS MA  0,00927 0,004036 
7 MA WJL   0,02304 0,008475 
8 Kus PS  0,02304 0,028249 
9 Amr LN  0,06455 0 
10 DM Amr  0,0553 0,01589 
C. Hasil Uji Data 
Pengujian sistem menggunakan acuan data training  dosen 
pembimbing 1 sebanyak 217 dan data training  dosen pembimbing 2 sebanyak 177. Data testing berupa data skripsi 
mahasiswa/i Universitas CIC. Hasil uji data testing sebanyak 10  seperti pada  seperti pada tabel 2.  Dosen Pembimbing 1: Dari tabel 2, dosen pembimbing 1 untuk data testing yang ke- 10 yang telah ditetapkan yaitu Suw , sedangkan hasil uji diperoleh adalah DM. Maka prosentase kesesuian data adalah 9/10 atau 90%. Sedangkan tingkat ketidaksesuaiannya adalah 1/10 atau 10 %. Dosen Pembimbing 2: Dari tabel 2, dosen pembimbing 2 untuk data testing yang ke-4 yang telah ditetapkan yaitu MH, sed angkan hasil uji diperoleh adalah FW, data testing ke-5 yang telah ditetapkan adalah TEP, sedangkan hasil uji diperoleh adalah PS, data testing ke-6, data testing ke-7, data testing ke-8, data testing ke-9 dan ke-10 berturut-turut adalah Kus, RF,WI dan AS, berdasarkan hasil naive bayes diperoleh MA,WJL,PS,LN, dan Amr. Maka prosentase kesesuian data adalah 3/10 atau 30%. Sedangkan tingkat ketidaksesuaiannya adalah 7/10 atau 70 %. 

PEMBAHASAN 
Berdasarkan hasil pengujian dengan menggunakan 10 data testing  dan data training  dosen pembimbing 1 sebanyak 217 serta data training  dosen pembimbing 2 sebanyak 177 menghasilkan : 
1. Rekomendasi dosen pembimbing skripsi dengan nilai 
probabilitas tertinggi.  
2. Dimana dari hasil uji dosen pembimbing 1 terdapat 9 data 
yang sesuai dengan data testing  dan 1 data tidak sesuai 
dengan data testing ,  
3. Hasil uji dosen pembimbing 2 terdapat 4 data yang sesuai 
dengan data testing  dan 6 data tidak sesuai dengan data 
testing .  
4. Perbandingan persentase kesesuaian dosen pembimbing 1 
sebesar 90% : 10% dan  
5. Perbandingan persentase kesesuaian dosen pembimbing 2 
sebesar 30% : 7 0%. 
6. Adanya ketidaksesuaian pada hasil pengujian tersebut 
dikarenakan penentuan bidang ilmu/ kompetensi yang belum 
detail dan sumber data uji (data training ) merupakan data 
masa lalu sedangkan data yang diuji sebagai data testing  
sekarang merupakan data baru dimana terdapat dosen-dosen 
baru yang ditetapkan sebagai dosen pembimbing.  
7. Sehingga dari pengujian rekomendasi dosen pembimbing 
tersebut, disimpulkan bahwa algoritma naive bayes classifier 
dapat diterapkan sebagai sistem rekomendasi dosen 
pembimbing skripsi. 

KESIMPULAN 
Berdasarkan hasil penelitian ini dapat disimpulkan bahwa : 
1. Algoritma naive bayes classifier dapat diterapkan dalam 
sistem rekomendasi dosen pembimbing skripsi sesuai 
kriteria yang telah ditentukan, dengan perbandingan tingkat  
kesesuaian dosen pembimbing 1 sebesar 90% : 10% dan 
tingkat  kesesuaian dosen pembimbing 2 sebesar 30% : 7 0%. 
2. Sistem rekomendasi dosen pembimbing dengan penerapan 
algoritma naive bayes classifier  dapat meningkatkan 
efisiensi waktu dan membantu ketua program studi dalam 
menentukan dosen pembimbing yang tepat sesuai dengan 
bidang ilmu skripsi mahasiswa dengan kompetensi dosen 
yang bersangkutan. 

REFERENCES      
[1] â€œKBBI. â€œKamus Besar Bahasa Indonesia (Kbbi)â€. Internet ://Kbbi.Web.Id., [Diakses 31 Oktober 2019]. 
[2] R. Fitriyani, â€œPERANCANGAN SISTEM PROSEDUR SKRIPSI MENGGUNAKAN METODE BPMN DAN RAD PADA KAMPUS STMIK MERCUSUAR,â€ J. TEKNOM , vol. 2, no. 2, pp. 1 â€“13, 2018. 
[3] W. A. Dewa and L. S. Rahmawati, â€œAnalisis dan Desain 
Sistem Pendukung Keputusan Penentuan Dosen Pembimbing 
Tugas Akhir Menggunakan Metode AHP,â€ J. Technopreneur , vol. 6, no. 2, p. 81, 2018, doi: 10.30869/jtech.v6i2.208. 
[4] I. N. F. Patmi Kasih, â€œSistem Bantu Pemilihan Dosen 
Pembimbing Tugas Akhir Berdasarkan Kategori Pilihan dan 
Keahlian Dosen menggu nakan NaÃ¯ve Bayes,â€ Semin. Nas. 
Teknol. Informasi, Komun. dan Apl. , vol. 04, no. SNATIKA, 
pp. 62 â€“68, 2017. 
[5] U. Pujianto, T. Widiyaningtyas, D. D. Prasetya, and B. 
Romadhon, â€œPenerapan algoritma naÃ¯ve bayes classifier 
untuk klasifikasi judul skripsi dan tugas akhir berdasark an 
Kelompok Bidang Keahlian,â€ TEKNO , vol. 27, no. 1, p. 79, 
Jul. 2019, doi: 10.17977/um034v27i1p79-92. 
[6] J. Suntoro, Data Mining: Algoritma dan Implementasi 
dengan Pemrograman PHP . Elex Media Komputindo, 2019, 
pp.33- 34 
[7] R. S. Pres sman, â€œRekayasa Perangkat Lunak Pendekatan 
Praktisi (Buku Satu),â€ Yogyakarta Andi , 2002, pp.42.",sistem rekomendasi,Naive Bayes Classifier,dosen pembimbing,kesesuaian
SISTEM REKOMENDASI PENERIMAAN MAHASISWA BARU MENGGUNAKAN NAIVE BAYES CLASSIFIER  DI INSTITUT PENDIDIKAN INDONESIA,"SISTEM REKOMENDASI PENERIMAAN MAHASISWA BARU MENGGUNAKAN NAIVE BAYES CLASSIFIER  DI INSTITUT PENDIDIKAN INDONESIA

Andri Suryadi1, Erwin Harahap2  

Abstract  
The quality of a university in creating qualified graduates is determined by the prospective students who enter the college. One of the things that can determine the quality is how the selection process of candidates for good student acceptance. However, the selection process of admissions in every college of course  is different. Often the input of prospective students who enter the university is not in accordance with the expected so that the impact of graduate results. Therefore it is necessary for a system that can support the decision in the selection of new student candid ates in order to get a good student input. This research builds a Recommendation System that will assist in the selection process of universities for the selection team of new student candidates. This recommendation system uses the naive Bayes classifier method where the test scores of incoming selection of students who have been accepted will be used as training data and then classified based on the value of ipk that has been obtained. The value of the ipk will be a benchmark for the formation of classes-classes that are recommendations to the selection team. The classes that are formed are classes whose ipk value is at the accepted point and the class whose ipk value is not accepted. Then given a new student data, if the prospective student enters the sa fe class then it will be recommended to be accepted but otherwise it will be recommended to be rejected  

Keyword  :  Recommendation System, Naive bayes Classifier, College.  
 
1. PENDAHULUAN  
1.1 Latar belakang  
Setiap Pendirian Perguruan Tinggi memiliki  tujuan  menghasilkan  lulusan  yang berkualitas  dan berdaya saing . Namun dalam  menghasilkan  lulusan  yang berkualitas  tentunya  tidak  terlepas  dari input  calon  mahasiswa  dalam  proses  seleksi  masuk  perguruan  tinggi . Hal ini sejalan  dengan  pendapat  M.Rosul Asmawi (2006) yang mengatakan  bahwa  untuk  dapat  menghasilkan  produk  yang baik maka  harus  menanam  bibit-bibit yang baik. Untuk mendapatkan  bibit yang baik perlu  adanya  seleksi  yang baik pula. Dengan demikian  untuk  mendapatkan  calon  mahasiswa  yang berkualitas  maka  perlu  adanya  saringan  yang baik. Masing-masing Perguruan Tinggi tentunya memiliki sistem sendiri dalam proses seleksi masuk  (Giovani, Ronny Ardi.2011) . Hanya saja biasanya dalam pelaksanaan proses seleksi yang dilakukan banyak mahasiswa yang nilai kelulusannya tidak sesuai yang diharapkan. Oleh karena itu perlu adanya suatu sistem yang dapat mendukung keputusan dalam seleksi calon mahasiswa baru guna mendapatkan input  calon mahasiswa yang baik  sebagai prediksi guna memperoleh hasil seleksi yang baik ( A. G. Mabrur and R. Lubis.2012 ).  
Penelitian ini bertujuan untuk membangun sebuah Sistem Rekomendasi yang akan membantu dalam tim dalam proses seleksi perguruan tinggi  calon mahasiswa  baru. Sistem Rekomendasi  ini menggunakan metode naive bayes  classifier  dimana nilai tes kompetensi dasar mahasiswa yang telah diterima akan dijadikan data latih kemudian diklasifikasikan berdasarkan nilai ipk yang telah diperolehnya  (Septian Nugroho, Y.2014) . Nilai ipk tersebut akan menjadi patokan pembentukan kelas-kelas yang merupakan rekomendasi kepada tim penyeleksi. Kelas-kelas rekomendasi yang terbentuk adalah kelas yang nilai ipk nya berada pada titik diterima  dan kelas yang nilai ipk nya tidak berada pada titik tidak diterima . Kemudian diberikan sebuah data calon mahasi swa beserta hasil nilai seleksinya, jika calon mahasiswa tersebut memasuki kelas diterima  maka akan direkomendasikan untuk memasuki Perguruan Tinggi yang dimaksud. Namun sebaliknya jika calon mahasiswa tersebut berada pada kelas tidak diterima maka calon mahasiswa tersebut tidak direkomendasikan untuk memasuki Perguruan Tinggi . Dengan adanya sistem ini diharapkan input  dari calon mahasiswa  akan lebih baik dan akan berdampak pada kualitas lulusan dari Perguruan Tinggi . 
2.2 Permasalahan penelitian  
Mengacu  pada latar belakang yang telah diuraikan sebelumnya, maka rumusan masalah pada penelitian ini adalah sebagai berikut:  
a. Bagaimana membangun Sistem Rekomendasi menggunakan metode naive bayes dalam proses seleksi penerimaan calon mahasiswa baru?  
b. Bagaimana Sistem Rekomendasi menggunakan metode naive bayes ini dapat membantu dalam proses seleksi penerimaan mahasiswa baru?   
2.3 Wawasan dan rencana pemecahan masalah  
Sistem Rekomendasi yang akan dibangun ini menggunakan  metode naive bayes classifier sedangkan pembangunan aplikasinya sistem rekomendasi ini menggunakan model waterfall .   
2.4 Tujuan Penelitian  
Tujuan yang ingin dicapai dari penelitian ini adalah sebagai berikut:  
a. Sebagai Sistem Pendukung Keputusan yang dapat membantu merekomendasikan tim penyeleksi dalam memilih calon mahasiswa sesuai yang diinginkan.  
b. Membantu proses seleksi penerimaan mahasiswa 
baru.  
c. Dapat meningkatkan input  kualitas dari calon mahasiswa.  
 
2. PEMBAHASAN  
Sistem Pendukung Keputusan merupakan sistem informasi interaktif yang menyediakan informasi, pemodelan, dan pemanipulasian data. Sistem ini digunakan untuk membantu pengambilan keputusan dalam situasi yang semiterstruktur dan situasi yang tidak terstruktur, dimana tak seorang pun tahu secara pasti bagaimana keputusan seharusnya dibuat (Turban, 2 005). Pengambilan keputusan secara universal didefinisikan sebagai pemilihan diantara berbagai alternatif. Pengertian ini mencakup baik pembuatan pilihan pemecahan masalah.  Pengambilan keputusan pada hakekatnya terdapat tiga langkah utama (Simon, 1977) ya itu: 
a. Kegiatan Intelijen  
Menyangkut pencarian berbagai kondisi lingkungan yang diperlukan bagi keputusan.  
b. Kegiatan Desain  
Tahap ini menyangkut pembuatan pengembangan dan penganalisaan berbagai rangkaian kegiatan yang mungkin dilakukan.  
c. Kegiatan Pemilihan  
Pemilihan serangkaian kegiatan tertentu dari 
alternatif yang tersedia.  Dalam pengambilan keputusan terdapat karakteristik dan kemampuan ideal (Turban,2005) seperti digambarkan pada gambar 2.1 dibawah ini  
Gambar 2.1 Karakteristik dan kemampuan ideal pendukung keputusan   
1) Pendukung keputusan menyediakan dukungan bagi pengambil keputusan utamanya dalam situasi semi terstruktur dan tak terstruktur dengan memadukan pertimbangan manusia dan informasi terkomputerasi. Berbagai masalah tak dapat diselesaikan (atau tak dapat diselesaikan secara memuaskan) oleh sistem terkomputerisasi lain, seperti EDP atau MIS, tidak juga dengan metode atau tool kuantitatif standar.  
2) Dukungan disediakan untuk berbagai level manajerial yang berbeda, mulai dari pimpinan puncak sampai man ajer lapangan.  
3) Dukungan disediakan bagi individu dan juga bagi group. Berbagai masalah organisasi melibatkan pengambilan keputusan dari dalam group. Untuk masalah yang strukturnya lebih sedikit sering kali hanya membutuhkan keterlibatan beberapa individu dari departemen dan level organisasi yang berbeda.  
4) Sistem pendukung keputusan menyediakan dukungan ke berbagai keputusan yang berurutan atau saling berkaitan.  
5) Sistem pendukung keputusan mendukung berbagai fase proses pengambilan keputusan: kegiatan intelejen, desain dan pemilihan.  
6) Sistem pendukung keputusan mendukung berbagai proses pengambilan keputusan dan style yang berbeda-beda.  
7) Sistem pendukung keputusan selalu bisa beradaptasi sepanjang masa. Pengambilan keputusan harus reaktif, mampu mengatasi perubahan kondisi secepatnya dan beradaptasi 
untuk dapat menangani perubahan.  
8) Sistem pengambilan keputusan mudah untuk digunakan. Pengguna harus merasa nyaman dengan sistem ini.  
9) Sistem pengambilan keputusan mencoba untuk meningkatkan efektivitas dari pengambilan keputusan (akurasi, jangka, waktu, kualitas).  
10) Pengambilan keputusan memiliki control yang menyeluruh terhadap semua langkah proses pengambilan keputusan dalam menyelesaikan masalah. Sistem pengambilan keputusan secara 
khusu ditujukan untuk mendukung dan tak menggantikan pengambil keputusan. Pengambilan keputusan dapat menindaklanjuti rekomendasi komputer sembarang waktu dalam proses dengan tambahan pendapat pribadi atau pun tidak.  
11) Sistem pengambilan keputusan mengarah pada pembelajaran, yaitu mengarah pada kebutuhan baru dan penyempurnaan sistem, yang mengarah pada pembelajaran tambahan dan begitu selanjutnya dalam proses pengembangan dan peningkatan keputusan secara berkelanjutan.  
12) Pengguna harus mampu menyusun sendiri sistem yang sederhana. Sistem yang lebih besar dapat dibangun dalam organisasi pengguna tadi dengan melibatkan sedikit saja bantuan dari spesialis dibidang sistem informasi.  
13) Sistem pengambilan keputusan biasanya mendayagunakan berbagai model (standar atau sesuai keinginan pengguna) dalam mengan alisis berbagai keputusan.  
14) Sistem pengabilan keputusan dalam tingkat lanjut dilengkapi dengan komponen pengetahuan yang bisa memberikan silusi yang efisien dan efektif dari berbagai masalah yang pelik.   
Masih menurut (Turban, 2005) dalam pemakaian sistem pendukung keputusan terdapat beberapa keuntungan diantaranya:  
1) Mampu mendukung pencarian solusi dari masalah yang kompleks  
2) Respon cepat pada situasi yang tak diharapkan dalam kondisi yang berubah -ubah.  
3) Mampu menerapkan berbagai strategi yang berbeda pada kon figurasi berbeda secara cepat dan tepat.  
4) Pandangan dan pembelajaran baru.  
5) Memfasilitasi komunikasi.  
6) Meningkatkan control manajemen dan kinerja.  
7) Menghemat biaya.  
8) Keputusan lebih tepat.  
9) meningkatkan efektifitas menajerial, menjadikan seseorang dapat bekerja lebih singkat dan dengan sedikit usaha.  
10) Meningkatkan produktivitas analisis.   
Sistem Pendukung Keputusan Model Waterfall  
Dalam pengembangan Sistem Pendukung Keputusan ini menggunakan model waterfall. Model waterfall adalah proses pengembangan perangkat lunak tradisional yang umum digunakan dalam proyek-proyek perangkat lunak yang paling pembangunan. Ini adalah model sekuensial, sehingga penyelesaian satu set kegiatan menyebabkan dimulainya aktivitas berikutnya. Berikut gambar 
model waterfall:   
Gambar 2.2 Waterfall   
1) Perancangan / Analisis Sistem  
Ini adalah langkah pertama dan paling penting dari model waterfall. Ini melibatkan pengumpulan informasi mengenai solusi akhir dari kebutuhan pelanggan pelanggan dan pemahaman. Ini melibat kan definisi yang jelas tentang tujuan pelanggan, harapan terhadap proyek dan masalah produk akhir diharapkan untuk memecahkan.  
2) Desain Sistem  
Langkah ini dimulai dengan menggunakan informasi yang ditangkap di SRS. Ini dapat dianggap sebagai memberikan solusi untuk masalah di lingkup menggunakan sumber daya yang tersedia. Tahap ini terdiri dari bagaimana perangkat lunak akan dibangun, dengan kata lain perencanaan solusi perangkat lunak. Para pemangku kepentingan yang terlibat dalam modul ini adalah para pera ncang sistem. Desain perangkat lunak mungkin mencakup desain sistem dan desain komponen  
3) Implementasi  
Masukan dari fase ini adalah SDD sistem. """"Di sinilah perkembangan aktual sistem terjadi sesuai dengan spesifikasi desain. Langkah ini dilakukan oleh pengembang, desainer interface dan stakeholder lainnya dengan menggunakan alat seperti compiler, debugger, penerjemah dan Perancangan Desain 
Sistem  
Implementasi 
Pengujian  
Pemeliharaan editor media. 
Output dari langkah ini adalah komponen produk satu atau lebih yang dibangun berdasarkan standar yang telah ditetapkan coding dan perbaikan, pengujian dan terintegrasi untuk memenuhi kebutuhan arsitektur sistem  
4) Pengujian  
Pada fase ini kedua komponen individu dan solusi terintegrasi yang diverifikasi untuk melihat itu adalah bug gratis dan memenuhi spesifikasi kebutuhan perangkat lunak. Tester adalah stakeholder yang terlibat dalam fase model. Cacat yang ditemukan pada tahap ini diberikan sebagai umpan balik kepada para pengembang yang pada gilirannya memperbaiki masalah. Ini adalah tahap di mana produk dikembangkan didokumentasikan. 
5) Pemeliharaan  
Ini adalah tahap akhir dari model waterfall dan terjadi setelah instalasi sistem produk / di lokasi pelanggan. """"Tahap ini melibatkan membuat modifikasi pada sistem atau komponen individu untuk mengubah atribut atau meningkatkan kinerja sistem"""". Modifikasi yang muncul karena perubahan permintaan dipicu oleh pelanggan atau cacat yang ditemukan saat menggunakan sistem secara real time. Nomor revisi diperbarui dalam setiap rilis pemeliharaan.   
Naive Bayes Classifier  
Naive Bayes Classifier  merupakan teknik prediksi pengklasifikasian berbasis probabilistic sederhana berdasar pada penerapan teorema Bayes (aturan Bayes) dengan asumsi independensi (ketidaktergantungan) yang kuat (naif). Maksud independensi yang kuat adalah bahwa sebuah data tidak berk aitan dengan ada atau tidaknya data yang sama.  Prediksi Bayes  didasarkan pada teorema Bayes  dengan formula umum sebagai berikut:  
Gambar 2.3 Rumus Naive Bayes   
Penjelasan dari formula tersebut adalah sebagai berikut:  
Parameter  : Keterangan  
P(H|E)  : Pro babilitas akhir bersyarat  
(conditional probility ) suatu hipotesis H terjadi jika diberikan bukti ( evidence ) E terjadi.  
P(E|H)   : Probabilitas sebuah bukti E terjadi  akan mempengaruhi hipotesis H.  P(H)  : Probabilitas awal ( prior ) hipotesis  H terjadi tanpa memandang bukti 
apapun.  
P(E) : Probabilitas awal ( prior ) bukti E  terjadi tanpa memandang hipotesis bukti yang lain.   
Dari penjelasan diatas dapat disimpulkan bahwa hasil dari hipotesis atau peristiwa (H) diperkirakan berdasarkan pada beberapa bukti (E) yang diamati. ada beberapa hal penting dari aturan tersebut, yaitu:  
1) Sebuah probabilitas awal / prior H atau P(H) adalah probabilitas dari suatu hipotesis sebelum bukti diamati.  
2) Sebuah probabilitas akhir H atau P(H|E) adalah probabilitas dari suatu hipotesis setelah bukti diamati.  
Jadi dapat disimpulkan bahwa jika H merupakan vektor masukan yang berisi fitur dan E adalah label kelas, maka dalam naive bayes dituliskan P(H|E). Notasi tersebut berarti probabilitas label kelas E didapatkan setelah fitur-fitur H diamati. Notasi ini disebut juga probabilitas akhir ( posterior probability ) untuk E, sedangkan P(E) disebut probabilitas awal (prior probability )  
Klasifikasi dalam Proses Seleksi Ujian Masuk 
Perguruan Tinggi  
Proses Seleksi Ujian Masuk Perguruan Tinggi 
merupakan proses penting sebelum mahasiswa menempuh pendidikan disebuah Perguruan Tinggi. Biasanya setiap Perguruan Tinggi mempunyai visi dan misi yang berbeda -beda. Untuk mencapai hal tersebut dibutuhkan karakteristik input  mahasiwa yang sesuai dengan apa yang diinginkan oleh Perguruan Tinggi.  
Gambar 2.4 Gambar alur klasifikasi proses seleksi  
input data 
variabel tes 
kompetensi dasar  
klasifikasi 
Naive bayes  
Kelas rekomendasi dan kelas Tidak rekomendasi  
Masukan hasil dari tes kompetensi dasar  
Data hasil keluaran  
Input  data variabel tes merupakan data masukan yang akan dijadikan data latih menggunakan naive bayes. Data latih tersebut akan diklasifi kasikan sehingga menghasilkan kelas yang direkomendasikan dan tidak direkomendasikan. Setelah terciptanya kelas kemudian akan diuji data baru yang merupakan data nilai kompetensi dasar calon mahasiswa. Hasil akhir dari pengolahan data calon mahasiswa baru ini adalah kelas yang ditempatinya apakah masuk kedalam kelas rekomendasi atau tidak.  

3. METODE  PENELITIAN  
Tahapan Penelitian  
Tahapan penelitian dalam Sistem Pendukung Keputusan Seleksi Ujian Masuk Perguruan Tinggi ini dapat dilihat pada gambar 1 dengan penje lasan sebagai berikut:  
1. Studi Literatur  
2. Tahap pertama dalam penelitian ini adalah studi literature. Dalam studi literatur ini terdapat dua tahapan yaitu tentang sistem pendukung keputusan, model waterfall naive bayes dan naive bayes dalam seleksi ujian masuk Perguruan Tinggi.  
3. Data Penelitian  
4. Data penelitian terdapat dua macam yaitu data latih dan data uji. Data latih merupakan nilai dari tes kompetensi dasar mahasiswa pada waktu awal masuk ke Program Studi Pendidikan Teknologi Informasi. Sedangkan data uji adalah data calon mahasiswa yang akan masuk ke Program Studi Teknologi Informasi.  
5. Perangkat Lunak Model Waterfall  
6. Pembangunan Sistem Pendukung Keputusan menggunakan model waterfall. Model ini memiliki tahapannya diantaranya perancangan atau analisis sistem,  desain sistem, implementasi, pengujian dan pemelliharaan. Dari pembangunan perangkat lunak ini menghasilkan kelas dari data latih kemudian akan diuji coba dengan data uji dari calon mahasiswa.  
7. Klasifikasi Calon Mahasiswa  
8. Klasifikasi merupakan nilai akhir rekomendasi dari sistem pendukung keputusan ini. Nilai akhir ini akan memunculkan apakah calon mahasiswa tersebut diterima atau ditolak.  
Gambar 1. Tahapan Penelitian   
Teknik Pengumpulan Data  
Teknik yang digunakan dalam penelitian ini adalah teknik wawancara dan observasi. Teknik wawancara dilakukan terhadap sample  Program Studi di Institut Pendidikan Indonesia . Teknik wawancara ini akan menghasilkan kualitas calon mahasiswa yang diinginkan dan akan memasuki program studi tersebut sehingga menjadi acuan batas ambang dalam penentuan kelas. Sedangkan teknik observasi merupakan teknik analisis data dari nilai-nilai tes kompetensi dasar mahasiswa yang telah dilakukan. Data nilai tes kompetensi dasar ini akan dijadikan data latih pada sistem pendukung keputusan yang 
akan dibuat. Dengan dilakukannya teknik wawancara dan observasi diharapkan data yang akan dijadikan data latih menjadi lebih reliable . 
Perangkat Lunak Model waterfall  
Pengujian  Desain Sistem  Perancangan / Analisis Sistem  
Pemeliharaan  
Implementasi  
Hasil rekomendasi  
Klasifikasi Calon Mahasiswa  
1. Mendapatkan kelas dari data latih  
2. Testing Data uji calon mahasiswa  
Selesai  
Mulai   
a. Sistem Pendukung Keputusan (SPK)  
b. Model Waterfall  
c. Naive Bayes Classifier  
d. Naive Bayes dalam Seleksi Ujian Masuk Perguruan Tinggi IPI Studi Literatur  
Data Latih  
Data Uji 
Data Penelitian  
Lokasi Penelitian  
Penelitian ini akan dilaksanakan di Institut Pendidikan Indonesia  dengan sampel data latih adalah data mahasiswa  aktif. Sedangkan data input adalah data calon mahasiswa yang akan memasuki Institut Pendidikan Indonesia.  
 
4. HASIL  PEMBAHASAN  
Data Penelitian  
Untuk membuat Sistem Pendukung Keputusan Seleksi Ujian Masuk Perguruan Tinggi Menggunakan NBC (Naive Bayes Classifier)  ini hal yang paling penting adalah data penelitian yang terdiri dari data latih dan data uji. Data latih merupakan data mahasiswa yang telah menjalankan proses perkuliahan di Institut Pendidikan  Indonesia  yang disimpan dalam database yang akan diolah. Sedangkan data uji dalam penelitian ini adalah data calon mahasiswa baru yang akan diujikan terhadap sistem pendukung keputusan ini  
Data Latih  
Sebagaimana telah dijelaskan sebelumnya data latih merupakan data mahasiswa yang telah menjalani proses perkuliahan. Dalam hal ini mahasiswa Program Studi Pendidikan Teknologi Informasi. Variabel pada data latih yang diambil berupa nilai pada masing -masing mahasiswa pada saat tes seleksi masuk calon mahasiswa  baru dan nilai ipk yang diperoleh sekarang. Nilai tes seleksi masuk adalah nilai matematika, bahasa indonesia, bahasa inggris, kewarganegaraan  serta hasil wawancara berupa jarak dari tempat tinggal, status bekerja, keaktifan organisasi sedangkan ipk meru pakan hasil dari studi saat ini. Berikut adalah data mahasiswa yang akan dijadikan data latih pada sistem pendukung keputusan ini:  
Tabel 4.1 Data Latih  
Nama Calon Mahasiswa Nilai Seleksi  B O J ipksms 1 -6 
V K P W 
DADANG MUHAIMIN  S B K S Y T JAUH  KURANG  
FAJAR RENDI M S C S S Y Y JAUH  KURANG  
EDWIN DWITAMA S  S C S S Y T DEKAT  REKOMENDASI 
NOVA MENTARI S S K S T T DEKAT  REKOMENDASI 
AYU LESTARI S C K K Y Y DEKAT  REKOMENDASI 
SAEPUL HIDAYAT K K C 7 T T JAUH  KURANG  
Nama Calon Mahasiswa Nilai Seleksi  B O J ipksms 1 -6 
CITRA RETNO  S S K K T T DEKAT  REKOMEND ASI 
IQBAL AHMAD MAULANA S C S K Y Y DEKAT  REKOMENDASI 
AHMAD FAUZI HIKAMI  S C K K T T JAUH  KURANG  
SANTI JULIAWATI S S K K Y Y JAUH  REKOMENDASI 
YUDI RIYADI  S S K K T T DEKAT  KURANG  
RAHMA ALAWIYAH  S S K K T T JAUH  KURANG  
NOPA MUSTOPA K K S K T T DEKAT  KURANG  
RIZKI NUR IKLAS  S S K S T T JAUH  KURANG  
ELSA ERLIANTY S S K K Y T DEKAT  REKOMENDASI 
ALVY RIFQIHANI K K S S T T DEKAT  REKOMENDASI 
FAJAR KURNIA  K S K K Y Y JAUH  KURANG  
HUSNI YASIR  K C K K Y T JAUH  KURANG  
IMAM IHSANUDIN K K S K Y T JAUH  REKOMENDASI 
TOTOH ABDUL FATAH  S S K K T T JAUH  REKOMENDASI 
RENDI FIRMANSYAH  K K S K Y Y JAUH  KURANG  
ASEP KUSWANDI K K K K T T JAUH  KURANG  
SANTI SUSANTI K K K S Y T SEDANG KURANG  
YULY YULIANTI K K K S Y Y JAUH  REKOMENDASI 
HANI HADIYANI K K S K T T JAUH  REKOMEND ASI 
VICKY RIDWANSYAH  K K K K T Y JAUH  REKOMENDASI 
RINRIN RINDI REGINA  K K K S Y Y DEKAT  REKOMENDASI 
INDRI HANDAYANI  K K K K Y Y DEKAT  REKOMENDASI 
FAHMI NUR RAHMAN K K S K T T JAUH  REKOMENDASI 
TRIA AMINATI K K K K T T JAUH  REKOMENDASI 
GINA RAHAYU MEIL ANI C B C C Y Y SEDANG REKOMENDASI 
ABDUL MIMAR HIDAYAT C C S S Y Y JAUH  REKOMENDASI 
YUSUP SETIAWAN S B S S Y Y JAUH  REKOMENDASI 
SITI WULAN C B S S T T SEDANG REKOMENDASI 
Nama Calon Mahasiswa Nilai Seleksi  B O J ipksms 1 -6 
SARI  SURYA GUSTIAWAN  S B K S Y Y SEDANG REKOMENDASI 
INDRI INDRIANSYAH  S B S S T T SEDANG REKOMENDASI 
MIA MARDIAH C C K S T T JAUH  REKOMENDASI 
KUSNIARTI S C S K T T SEDANG REKOMENDASI 
SONI MUHAMAD SIDIK  S C S S Y Y SEDANG REKOMENDASI 
MUNAWAR SIDIK  C B K K T T JAUH  KURANG  
DEDE ALAMSYAH  S C K S Y Y JAUH  REKOMENDASI 
MUHAMMAD SHIDDIQ C C K K Y T JAUH  REKOMENDASI 
TANTRI SUCI RACHMAWATI  S C K K T T SEDANG REKOMENDASI 
MUMAN ABDUROHMAN  S S S S T T DEKAT  KURANG  
ELIT RAHMAWATI  C C K K T Y DEKAT  REKOMENDASI 
DIAN SITI FADILAH S C S K T T SEDANG REKOMENDASI 
DANI HANDIKA C C K K Y T SEDANG KURANG  
ASEP ISKANDAR S C K K T T SEDANG REKOMENDASI 
RAHAYU UTAMI  S C S S T Y DEKAT  REKOMENDASI 
POLA REKA NUR ASIYAH  S C K K T Y DEKAT  REKOMENDASI 
PAUZEN  C C K K Y Y SEDANG REKOMENDASI 
ADE ZAENAL MUTAQIN S C S K Y T DEKAT  KURANG  
GINA MASRUROH  C C K K T T SEDANG KURANG  
MUHAMMAD FITRA NURFAIZI S C K K Y T JAUH  REKOMENDASI 
YUDA RACHMAT M  S S K S T T JAUH  KURANG  
RINA NURAENI S C K K T T JAUH  REKOMENDASI 
DEDEN HERMANSYAH  S S K K Y Y DEKAT  REKOMENDASI 
ASEP RUSMAWAN AL KARIMI  S C K K T T SEDANG KURANG  
ANNISA  S C K K T T SEDANG REKOMENDASI 
Nama Calon Mahasiswa Nilai Seleksi  B O J ipksms 1 -6 
RIANA ABDUL AZIS  K S K S T Y DEKAT  REKOMENDASI 
SRI ARNA WINORA S S K S T T DEKAT  REKOMENDASI 
RAHMATULLAH TEGUH PANCA  S S K K Y T SEDANG KURANG  
SOPIAH  S S K K T T SEDANG REKOMENDASI 
YUNI MUHARANI K S S K T Y DEKAT  KURANG  
ASEP  K K K K Y Y DEKAT  KURANG  
Ket:  
V = Verbal, K= Kuantitatif, P= Penalaran, W= Wawancara  
B : Bekerja, O = Organisasi, J=Jarak  
K = Kecil, S= Sedang, C = Cukup, B = Besar   
Data Uji  
Data uji merupakan data yang akan diujikan kedalam sistem dalam hal data calon mahasiswa baru. Data yang diujikan kepada calon mahasiswa baru sama seperti data latih yaitu nilai hasil ujian tulis dan hasil wawancara. Nilai tersebut antara lain nilai seleksi yang berupa nilai Verbal, Kuantitatif, Penalaran, wawancaran, Peke rjaan,  organisasi dan jarak lokasi tempat tinggal. Data uji ini akan disimpan didatabase dan ditampilkan ke layar jika dibutuhkan .  
Proses Seleksi Masuk Perguruan Tinggi menggunakan Naive Bayes Classifier  
Proses seleksi masuk Perguruan tinggi di Institut Pendidikan Indonesia  diawali dengan data latih pada tabel 4.1. Kemudian selanjutnya masuk sebuah data baru dalam hal ini calon mahasiswa baru. Data calon mahasiswa baru tersebut akan diolah menggunakan naive bayes classifier berdasarkan data latih sehingga akan dihasilkan rekomendasi apakah calon mahasiswa tersebut direkomendasikan lulus atau tidak. Sebagai contoh data calon mahasiswa baru sebagai berikut:   
Tabel 4.2  Data calon mahasiswa baru  
Nama  V K P W B O J Hasil  
Anto  C C S S T T 5km ? 
V = Verbal, K= Kuantitatif, P= Penalaran, W= Wawancara  
B : Bekerja, O = Organisasi, J=Jarak  
K = Kecil, S= Sedang, C = Cukup, B = Besar  
Dengan menggunakan naive bayes classifier maka proses seleksi calon mahasiswa baru adalah sebagai berikut:  
a. Tahap 1 : Menghitung Class / Label Kelulusan  P(Y=Rekomendasi) = 42/65 = 0.646  
P(Y=Kurang) = 23/65 = 0.353  
b. Tahap 2 : Menghitung per Kelas / label Kelulusan  
P(PMP = Cukup | Y = Rekomendasi) = 7/42 = 0.166  
P(PMP = Cukup | Y = Kurang) = 3/23 = 0.130  
P(IND = Cukup | Y = Rekomendasi) = 19/ 42 = 0.452  
P(IND = Cukup | Y = Kurang) = 7/23 = 0.304  
P(ING = Sedang | Y = Rekomendasi) = 14/42 = 0.333  
P(ING = Sedang | Y = Kurang) =  6/23  = 0.260  
P(MTK = Sedang | Y = Rekomendasi) = 16/42 = 0.380  
P(MTK = Sedang | Y = Kurang) =  7/23 = 0.304  
P(Bekerja =  Tidak | Y = Rekomendasi) = 23/42 = 0.547  
P(Bekerja = Tidak | Y = Kurang) =  13/23 = 0.565  
P(Organisasi = Tidak | Y = Rekomendasi) = 23/42 = 0.547  
P(Organisasi = Tidak | Y = Kurang) =  18/23 = 0.782  
P(Jarak = Jauh | Y = Rekomendasi) = 15/42 = 0.357  
P(Jarak  = Jauh| Y = Kurang) =  11/23 = 0.478   
c. Tahap 3 : Menentukan variable rekomendasi dan variable kurang  
P(PMP=Cukup x IND=Cukup x ING=Sedang x 
MTK=Sedang x Bekerja=Tidak x Org=Tidak x 
Jarak=jauh | Rekomendasi )  
P | Rekomendasi =  0.166 x 0.452 x 0.333 x 0.380  x 0.547 x 0.547 x 0.357 = 0.00130  
P | Kurang = 0.130 x 0.304 x 0.260 x 0.304 x 0.565 x 0.782 x 0.478 = 0.00067  
Karena P | Rekomendasi lebih besar dari P | kurang 
maka hasil dari data calon mahasiswa baru tersebut direkomendasikan  untuk diterima.   
Perancangan perangkat lunak model Waterfall  
Desain penelitian menggunakan model sekuensial linear  atau sering disebut dengan model air terjun (waterfall). Desain penelitian dapat dilihat pada gambar berikut:    
Gambar 4.2 Model Waterfall   
Desain penelitian meliputi aktivitas-aktivitas berikut: Pemodelan sistem informasi harus dilakukan terlebih dahulu sebelum  mulai melakukan implementasi program atau pengkodean program. Pemodelan sistem informasi ini bertujuan untuk menemukan batasan-batasan masalah pada penerapan 
sistem.  
Analisis  
Tahan ini merupakan tahap awal dalam pengembangan sebuah perangkat lunak, tahapan ini digunakan untuk mengetahui informasi, model, dan spesifikasi dari sistem yang dibutuhkan , baik kebutuhan fungsional maupun keb utuhan non fungsional.  Kebutuhan funsional  merupakan kebutuhan utama yang berkaitan langsung dengan pelayanan sistem pengambilan keputusan  yang meliputi dibagi menjadi beberapa modul seperti yang tercantum dalam tabel di bawah ini:   
Tabel 4.3 Kebutuhan Fun gsionl  
No Deskripsi  Kebutuhan Fungsional  
1 User login untuk pengelola sistem pengambilan keputusan menggunakan Naive Bayes Classifier.  
2 Pengelolaan data latih secara manual pada sistem pengambilan keputusan berupa tambah data latih, edit data latih dan delete data latih.  
3 Pengelolaan data latih menggunakan import excel.  
4 Pencarian data latih yang telah di masukan kedalam database  
5 Pengelolaan data testing  berupa input data, edit data dan delete data  
6 Pencarian data testing yang telah dimasukan kedalam database  
7 Hasil rekomendasi dari pengolahan menggunakan Naive Bayes Classifier.  
Perancangan / Analisis 
Sistem  Desain 
Sistem  
Implementasi 
Pengujian  
Pemeliharaan 
Tabel 4.4 Kebutuhan non fungsional  
No Deskripsi  Kebutuhan Non-Fungsional  
1 Username dan password di enkripsi dengan md5.  
2 Validasi format username tanpa spasi  dan maximal 10 karakter.  
3 Authentication  dan Otorization  user berdasarkan username , password . 
4 Menentukan waktu idle pengaksesan.  
5 Tersedia 24 jam sehari, 7 hari seminggu  
6 Tidak pernah gagal dalam menampilkan, 
menginput atau mengubah informasi.  
7 Kemudahan pemakaian pada sistem yang sesuai.  
8 Interface menggunakan Bahasa Indonesia.  
9 Selalu muncul pesan kesalahan jika terjadi error.   
Desain Sistem  
Tahapan kedua dari model waterfall adalah desain dimana pada tahapan ini bertujuan membuat desain dari hasil analisis yang dilakukan pada tahapan pertama. Informasi, model dan spesifikasi yang diubah menjadi sebuah desain sistem yang nantinya akan dikodekan.  Data Flow Diagram atau DFD adalah salah satu tools penting yang digunakan oleh analis sistem. Penggunaan DFD dipopulerkan oleh DeMarco (1978) dan Gane & Sarson (1979) melalui metodologi analisis sistem terstruktur (structured systems analysis methodologies). Mereka menganjurkan agar DFD menjadi alat pertama yang digunakan â€œanalis sistemâ€ untuk membuat sebuah model sistem yang 
menunjukkan keterkaitan setiap komponen-komponen sistemnya. Komponen sistem tersebut adalah proses-proses dalam sistem, data yang digunakan oleh proses-proses tersebut, eksternal entitas yang berinteraksi dengan sistem dan aliran  data/informasi di dalam sistem. Dibawah ini gambar dari DFD untuk sistem pengambil keputusan   
Sistem pendukung keputusan 
(NBC) User Input Data Latih
Input Data testingUser Rekomendasi
Gambar 4.3 Kontek diagram  
0.1
Konversi data latih 
0.2
Pengolahan menggunakan NBCuser
Data Latih Input data
Nama, pmp, ind, ing, mtk,
Bekerja ,org,jarak ,ipk insert data
Nama, pmp, ind, ing, mtk,
Bekerja, org, jarak, ipk
Ambil data latih
Nama, pmp, ind, ing, mtk,
Bekerja, org, jarak, ipk Data Testing
Rekomenasi diterima atau tidak input data
Nama, pmp, ind, ing, mtk,
Bekerja, org, jarak, ipk
Ambil data testing
Nama, pmp, ind, ing, mtk,
Bekerja, org, jarak, ipk 0.3
Pengolahan data testing
Gambr 4.4 DFD Level 1   
Gambar DFD diatas merupakan gambaran dari alur data yang ada pada sistem pengembilan keputusan NBC. Dibawah ini merupakan penjelasan dari lebih lengkap dari alur datanya.  
1) Peran dari entitas user adalah untuk memberikan masukan berupa data latih maupun data testing, selain itu entitas ini juga berperan menerima informasi dari sistem informasi berupa rekomendasi siswa mana yang akan direkomendiasikan atau tidak.  
2) Peran dari proses konversi data latih adalah menerima masukan dari entitas user berupa input, edit dan delete data. Selanjutnya masukan yang dilakukan akan diolah oleh proses ini dengan cara mengkonversi nilai menjadi sekala penilaian.  
3) Peran dari proses konversi data latih adalah menerima masukan dari entitas user berupa input, edit dan delete data. Selanjutnya masukan yang dilakukan akan disimpan kedalam data testing.  
4) Peran dari proses pengolahan menggunakan NBC adalah membandingkan data latih dan data testing menjadi sebuah rekomendasi menggunakan algoritma Naive Bayes Classifier.  
5) Data latih digunakan untuk menyimpan data-data latih yang nantinya akan d igunakan oleh proses pengolahan menggunakan NBC.  
6) Data testing digunaan untuk menyimpan data-data testing yang nantinya akan digunakna oleh proses pengolahan menggunakan NBC.  Selain membuat desain sistem untuk alur data, dalam desain perangkat lunak juga ada yang desain untuk menggambarkan basis data yang digunakan dalam perangkat lunak. Basis data merupakan tempat penyimpanan data-data, dalam penelitian ini basis data dibuat untuk menumpan data latih, data user dan data testing. Berikut ini basis data untuk  sistem pengambilan keputusan NBC.   
User
PKid
nama
username
password
statusData Latih
PKid
nama
pmp
ind
ing
mtk
bekerja
org
jarak
ipkData Testing
PKid
no_reg
nama
pmp
indo
ing
mtk
bekerja
org
jarak
ipk 
Gambar 4.5 Rancangan basis data  
1) Tabel user digunakan untuk menyimpan data user, seperti nama, username, password dan status.  
2) Tabel data latih digunakan untuk menyimpan data-data latih yang nantinya akan digunakan untuk pengolahan. Data yang dimasukan kedalam data latih ini antara lain: nama, nilai pmp, nilai ind, nilai ing, nilai mtk, status bekerja, status organisasi, jarak rumah ke kampus, ipk.  
3) Tabel data testing digunakan untuk menyimpan data-data testing yang nantinya akan digunakan untuk pengolahan. Data yang dimasukan kedalam data latih ini antara lain: nama, nilai pmp, nilai ind, nilai ing, nilai mtk, status bekerja, status organisasi, jarak rumah ke kampus, ipk.  
Implementasi / Koding  
Tahap selanjutnya dari model Waterfall dalam pengembangan sistem pengambilan keputusan adalah tahap impementasi. Tahapan ini ada tahap pengembangan dengan melakukan pengkodean. Hasil dari pengkodean menghasilkan perangkat lunak. Pada penelitian ini perangkat lunak pada sistem pengambilan keputsan NBC antara lain:  
Gambar 4.6 dibawah ini merupakan tampilan login  untuk pengguna. Halaman login utama merupakan tampilan awal ketika pengguna akan masuk ke sistem. Pengguna akan diminta memasukan username dan password ketika akan masuk ke sistem 
tersebut.   
Gambar 4.6 Halaman login  
Selanjutnya Gambar 4.7 merupakan gambaran dashboard  ketika pengguna berhasil melakukan login . Pada halaman dashboard  ini pengguna dapat memilih menu yang telah disediakan diantaranya menu dashboard , data latih dan data testing .  
Gambar 4.7 Halaman Dashboard  
Kemudian pada menu data latih akan ditampilkan semua data latih dan juga disediakan tombol tambah data seperti pada gambar 3. 8.  
Gambar 4.8 Halaman data latih   
Pada gambar 3. 9 merupa kan tambah data latih jika pengguna akan menambahkan data latih.   
Gambar 4.9 Halaman Tambah data latih  
Selanjutnya menu data testing  dapat dilihat pada gambar 4.10. Menu data testing  ini pengguna akan melihat hasil dari pengolahan data mahasiswa disertai hasil rekomendasi atau kurang direkomendasikan. Setelah itu pengguna juga dapat menambah data testing  baru seperti dilihat pada gambar 4.11.  
Gambar 4.10 Pengelolaan Data Testing   
Gambar 4.11 halaman Tambah Data Testing   
Pengujian  
Tahapan terakhir dal am model waterfall adalah tahapan pengujian, dimana pada tahapan ini software yang telah dibuat diuji apakah sudah sesuai dengan kubutuhan atau belum. Dalam pengujian software ini dilakukan dengan pengujian Blackbox.  Dibawah ini adalah sekenario yang dilak ukan dalam pengujian menggunakan Blackbox : 
Tabel 4.5 Pengujian Sistem  
Keterangan  Scenario pengujian  
Hasil Pengujian  
User akan memasukan username dan password pada halaman yang tersedia. Apabila username dan password salah maka akan keluar peringantan username dan password salah. 
Berhasil  
Halaman dashboard merupakan halaman yang berisikan menu untuk menuju kepada halaman lainnya. Pada scenario pengujian yang dilakukan adalah meng-klik menu yang ditampilkan  Berhasil  
Tombol untuk menuju kehalaman tambah data manual.  
Berhasil  
Tombol untuk meng-entrikan data menggunakan excel.  
Berhasil  
Halaman untuk meng-entrikan data latih.  
Berhasil  
Tombol untuk mengirimkan data yang telah di inputkan kedalam data latih  
Berhasil  
Tombol untuk menuju keh alaman tambah data testing.  Berhasil  
Halaman untuk meng-entrikan data testing.  
Berhasil  
Tombol untuk mengirimkan data yang telah di inputkan kedalam 
data testing  
Berhasil 
Tampilan tabel hasil pengolahan menggunakan NBC yang menghasilkan rekomendasi untuk pengambilan keputusan.  Berhasil  
Tombol untuk menghapus data latih maupun data testing  Berhasil  
 
5. KESIMPULAN  DAN  SARAN  
Kesimpulan  
Dari penelitian yang telah dilakukan terdapat beberapa kesimpulan sebagai berikut:  
1) Sistem pendukung keputusan sel eksi ujian masuk perguruan tinggi menggunakan naive bayes classifier merupakan sistem yang dapat membantu dalam menyeleksi calon mahasiswa baru.  
2) Sistem pendukung keputusan seleksi ujian masuk perguruan tinggi menggunakan naive bayes classifier dapat mening katkan kualitas input terhadap perguruan tinggi.  
Saran  
Saran dari peneliti untuk pembaca adalah sebagai berikut:  
1) Keakuratan metode naive bayes classifier tergantung banyaknya data latih oleh karena itu perlu dicoba dengan  
2) data latih yang lebih banyak lagi .Perlu adanya pengembangan terhadap sistem misalnya dengan membuat sistem berbasis mobile.  
 
PUSTAKA  
A. G. Mabrur and R. Lubis.2012. """"Penerapan Data Mining untuk Memprediksi Kriteria Nasabah Kredit,"""" Jurnal Komputer dan Informatika (KOMPUTA), vol. 1, pp. 53 -57 
Fahrurozi Achmad. 2014. Klasifikasi Kayu Dengan Menggunakan Naive Bayes-Classifier. KNM XVII ITS Surabaya  Giovani, Ronny Ardi.2011. Sistem Pendukung Keputusan  Prediksi Kecepatan Studi Mahasiswa Menggunakan Metode ID3. Universitas Atmajaya Yogyakarta.  
Mustaqbal1.M. Sidi,  Firdaus.Roeri Fajri , Rahmadi.Hendra. 2015 . Pengujian Aplikasi Menggunakan Black Box Testing Boundary Value Analysis.Jurusan Teknik Informatika, Fakultas 
Teknik, Universitas Widyatama. Jurnal Ilmiah Teknologi Terapan ISSN : 2407 â€“ 3911 . 
Nugroho Yuda Septian. Data Mining Menggunakan Algoritma Naive Bayes Untuk Klasifikasi Kelulusan Mahasiswa Universitas Dian Nuswantoro. Jurusan Sistem Informasi, Fakultas Ilmu Komputer, Universitas Dian Nuswantoro  
Pressman, Roger S. 2002.â€Rekayasa Perangkat Lunak 
(Pendekatan Praktis).â€ Yogyakarta : Andi.  
Rodiyansyah, Sandi Fajar dan Winarko Edi.2012.  Klasifikasi Posting Twitter Kemacetan Lalu Lintas Kota Bandung Menggunakan Naive Bayesian Classification . FPMIPA UGM Yogayakarta  
S Andri, E Harapap.2017. Pemeringkatan Pegawai Berprestasi Menggunakan Metode AHP (Analytic Hierarchy Process) di PT. XYZ. Jurnal Teori dan Terapan Matematikan Vol.16 No.2 2017  
Shalahuddin, M dan Rosa AS. 2014. Rekayasa Perangkat Lunak terstruktur dn berbasis Objek. INFORMATIKA  
Somme rville.Ian.2004.Software Enggineering:7th 
Edition. McGraw-Hill 
Suryadi.Andri, Nurdiana, Dian.2015.  Sistem Pengambilan Keputusan Untuk Pemilihan Teknisi Lab Dengan Multi Kriteria Menggunakan Metode Ahp (Analytic Hierarchy Process). Jurnal 
Mosharafa Vol.4 No .1 Januari 2015  
Suryadi.Andri, Nurdiana Dian .2016.  Sistem Pendukung Keputusan Seleksi Ujian Masuk Perguruan Tinggi Menggunakan Nbc (Naive Bayes Classifier). Jurnal Kinetik Vol.1 No.3 2016 
Hal 173-182 Suryadi,. Andri.2015.  PERANCANGAN APLIKASI 
TES BERBASIS KOMPUTER (CBT) MENGGUNAKAN PENDEKATAN TERSTRUKTUR UNTUK PENERIMAAN MAHASISWA BARU DI PERGURUAN 
TINGGI. Petik Vol.1 No.1 2015 Hal. 68 -81. 
Wahyunningrum.Tenia, Januarita.Dwi.2015. Implementasi dan Pengujian Web E-commerce untuk Produk Unggulan Desa. Jurnal Politeknik Caltex Riau Vol.1 no.1 hal 57-66.",sistem rekomendasi,Naive Bayes Classifier,"nilai dari tes kompetensi dasar mahasiswa pada waktu awal masuk ke Program Studi Pendidikan Teknologi Informasi, data calon mahasiswa yang akan masuk ke Program Studi Pendidikan Teknologi Informasi",
SISTEM REKOMENDASI: BUKU ONLINE DENGAN METODE COLLABORATIVE FILTERING,"SISTEM REKOMENDASI: BUKU ONLINE DENGAN METODE COLLABORATIVE FILTERING

Moh. Irfan1, Andharini Dwi C2, Fika Hastarita R .3 

ABSTRACT  
The book is a source of information regarding all aspects of life, especially education. However, low interest in reading among the public is a major issue in education today. Recommendation systems can help recommend the reader to more easily obtain information about the books to be read. Therefore, in this study made an online book recommendation system using Collaborative Filtering. Collaborative Filtering is one of the methods that can be used in making the recommendation system. The results of this study showed that the average value of the MAE (Mean Absolute Error) on trial 1 (1.064) is smaller than 2 trials (1.21), 4 trials (2,474) and test 5 (3.526). This shows that the more the amount of data used and if there is a user who has never rate a, then the resulting system is relatively inaccurate and generate recommendations if using Collaborative Filtering bad.  
 
Keywords:  recommendation system, Collaborative Filtering, Online Book.  
 
INTISARI  
Buku merupakan sumber informasi semua aspek kehidupan khususnya pendidikan. Namun rendahnya minat baca dikalangan masyarakat menjadi persoalan penting di dunia pendidikan saat ini. Sistem  rekomendasi  dapat  membantu  merekomendasikan  para pembaca  agar lebih  mudah  mendapatkan  informasi  mengenai  buku  yang akan  dibaca.  Oleh  karena  itu, pada  penelitian  ini dibuat  sistem  rekomendasi  buku  online  menggunakan  metode  Collaborative Filtering.  Collaborative Filtering adalah salah satu metode yang dapat digunakan dalam membuat sistem rekomendasi. Hasil dari penelitian ini menunjukkan bahwa rata-rata nilai MAE ( Mean Absolute Error ) pada uji coba 1 (1,064) lebih kecil daripada uji coba 2 (1,21), uji coba 4 (2,474) dan ujicoba 5 (3,526). Hal ini menunjukkan bahwa semakin banyak jumlah data yang digunakan dan jika terda pat user yang belum pernah merating, maka sistem yang dihasilkan relatif tidak akurat dan menghasilkan rekomendasi yang buruk jika menggunakan Collaborative Filtering.  
 
Kata Kunci : Sistem Rekomendasi, Collaborative Filtering, Buku Online  
  
PENDAHULUAN  
Buku merupakan informasi segala kebutuhan yang diperlukan, dimulai dari iptek, seni budaya, ekonomi, politik, sosial dan pertahanan keamanan dan lain-lain. Upaya membaca buku membuka wawasan dunia intelek sehingga dapat mengubah masa depan serta mencerdas kan akal, pikiran dan iman.  Dengan membaca buku, selain pengetahuan akan semakin bertambah, 
pribadi akan semakin kaya, yang kesemuannya jelas akan menurunkan efek negatif terhadap anak-anak, yakni kenakalan.  Sedangkan anak yang tidak terbina minat bacanya sejak dini akan menghadapi peluang yang semakin kecil untuk mengembangkan pengetahuan setinggi-tingginya. Namun berdasarkan laporan Bank Dunia, Indonesia merupakan negara yang memiliki minat  baca sangat rendah. Hal tersebut sungguh disayangkan, mengingat sebagai negara besar, Indonesia memiliki potensi besar untuk menjadi negara  yang unggul. Rendahnya minat baca di kalangan masyarakat  menjadi  persoalan  penting  di dunia  pendidikan  saat ini. Untuk  itu diperlukan  sebuah  sistem  yang  dapat  membantu  merekomendasi kan para pembaca  agar lebih  mudah  mendapatkan  informasi  buku-buku  yang  akan  dibaca  selanjutnya.   Sistem rekomendasi sendiri telah digunakan secara luas oleh hampir semua area bisnis dimana seorang konsumen memerlukan informasi untuk membuat suatu keputusan. Terdapat dua pendekatan yang umumnya digunakan dalam  membuat sitem rekomendasi, yaitu content based filtering  dan collaborative filtering . Content based filtering  merupakan metode yang bekerja dengan mencari kedekatan suatu item yang akan direkomendasikan ke user dengan items yang telah diambil oleh pengguna  sebelumnya berdasarkan kemiripan antar kontennya. Namun, sistem rekomendasi berbasis konten ini masih memiliki kelemahan, yaitu karena semua informasi dipilih dan direkomendasikan berdasarkan konten,  maka pengguna tidak mendapatkan rekomendasi pada jenis konten yang berbeda. Selain itu, sistem rekomendasi ini kurang efektif untuk pengguna pemula, karena pengguna yang masih pemula tidak mendapat masukan dari pengguna sebelumnya. (Li, 2002)  Pendekatan lain untuk menutup 
kelemahan dari content based filtering dikembangkan, yaitu collaborative filtering . Sistem collaborative filtering adalah metode yang digunakan untuk memprediksi kegunaan item berdasarkan penilaian pengguna sebelumnya.  Collaborative Filtering dapat digunakan untuk membuat sistem rekomendasi, akan tetapi perhitungan dalam algoritma sangat bergantung pada hasil rekomendasi. Seperti halnya skenario yang digunakan dalam perhitungan similarity, antara metode pearson correlation dan adjusted cosine similarity memberikan hasil yang berbeda. Berdasarkan beberapa kelebihan dari metode collaborative filtering , pada penelitian ini metode ini diterapakan pada pembuatan sistem rekomendasi buku online menggunakan dataset buku book crossing dengan dilihat akurasinya menggunakan beberapa skenario, yaitu dengan menggunakan cold start problem dan non-cold start problem pada perhitungan prediksinya.   
 
METODE  
Sistem  rekomendasi merupakan sebuah (web) alat personalisasi yang menyediakan pengguna sebuah informasi daftar item -item yang sesuai dengan keinginan masing-masing 
pengguna. Sistem rekomendasi menyimpulkan preferensi pengguna dengan menganalisis ketersediaan data pengguna, informasi tentang pengguna dan lingkungannya. Oleh karena itu sistem rekomendasi akan menawarkan kemungkinan dari penyaringan informasi personal sehingga hanya informasi yang sesuai dengan kebutuhan dan preferensi pengguna yang akan ditampilkan di sistem dengan menggunakan sebuah teknik atau model rekomendasi.  Ada beberapa metode atau teknik yang digunakan dalam sistem rekomendasi. Setiap metode disesuaikan dengan permasalahan dalam menghasilkan sebuah informasi yang sesuai. Metode atau pendekatan yang dipilih pada sistem rekomendasi bergantung pada permasalahan yang akan diselesaikan, teknik rekomendasi yang berbeda-beda digunakan untuk aplikasi yang berbeda, dasar dari suatu tujuan dan objektif dari sebuah aplikasi. Dari penelitian terbaru metode atau teknik rekomendasi memiliki beberapa sejumlah kemungkinan klasifikasi. (Uyun, 2011)  Sistem collaborative filtering adalah metode yang digunakan untuk memprediksi kegunaan item berdasarkan penilaian pengguna sebelumnya, misalnya cara pemberian rating terhadap suatu item (Lam, 2004) .Metode ini merekomendasikan item-item yang dipilih oleh pe ngguna lain dengan kemiripan model item dari pengguna saat ini. Walaupun dalam beberapa riset collaborative filtering terbukti dapat menutupi beberapa kekurangan pendekatan content based dan banyak diimplementasikan dalam aplikasi nyata, namun pendekatan ini memiliki beberapa kekurangan, antara lain: (Uyun, 2011)  Cold-start problem , karena pendekatan collaborative filtering melakukan prediksi berdasarkan rating yang diberikan user pada item, maka menjadi suatu masalah ketika suatu item baru masuk ke dalam sistem dan belum di-rating sama sekali oleh user. Akibatnya item tersebut tidak akan pernah direkomendasikan kepada user.  Sparsity , untuk ukuran data yang besar, banyak item yang baru sedikit di-rating oleh user, akibatnya item tersebut memiliki nilai predik si yang relatif tidak akurat dan menghasilkan rekomendasi yang buruk.  Salah satu metode sistem rekomendasi adalah collaborative filtering.  Berikut ini adalah tahap-tahap memberikan rekomendasi menggunakan collaborative filtering.  Dasar perhitungan similarity pada item-based collaborative filtering antara dua buah item i dan j adalah dengan mencari user mana saja yang telah memberi rating pada item i dan j lalu gunakan metode perhitungan similarity . Pada ICHM terdapat dua buah matriks, matriks group-rating dan matriks item-rating , maka perhitungan similarity juga dilakukan untuk masing -masing matriks lalu hasilnya digabungkan untuk perhitungan prediksi.  Metode pearson correlation-based similarity merupakan metode perhitungan berbasis korelasi yang paling banyak diimplementasikan untuk perhitungan nilai similarity . Korelasi Pearson  mengukur  seberapa besar hubungan linear  antara dua variabel . Koefisien  korelasi Pearson  berasal dari model  regresi linier  yang memiliki asumsi yaitu bahwa hubungan antara dua variabel harus linier , dengan  kesalahan  harus independen dan  memiliki distribusi  probabilitas dengan  mean 0 dan varians  (berdistribusi Normal (0,1) . (Li, 2002)  Metode pearson correlation-based similarity ditunjukkan oleh Persamaan  
ï€¨ï€©ï€¨ï€©ï€¨ï€©
ï€¨ï€©ï€¨ï€© ïƒ¥ ïƒ¥ïƒ¥
ï€½ ï€½ï€½
ï€­ ï€­ï€­ï€­
ï€½
mul lumuk kul lumuk ku
R R R RR RR R
lksim
12
0,12
,,1,
,
Keterangan: 
sim(k,l) adalah nilai similarity antara item k dan item l  
m adalah jumlah total user yang merating item k dan item l  
kR dan lR  adalah rating rata-rata pada item k dan item l  
kuR,dan luR, adalah rating yang diberikan oleh user u kepada item k dan item l  
Adjust Cosine Similarity
Cosine similarity merupakan metode yang sering digunakan  untuk menghitung kesamaan  pengguna,  tetapi metode ini memiliki  satu kekurangan . Perbedaan  skala rating  antara berbagai pengguna  akan menghasilkan  simarity  yang sangat berbeda . Sebagai contoh , user A merating buku terbaik dengan rating  4 dan tidak pernah  member rating  5 pada buku apapun,  dan member rating  1 pada  buku terjelek , tidak sesuai dengan  tingkat standar rating yaitu  2. Tetapi  user B selalu  merating  sesuai dengan tingkat  standar,  member rating  5 pada  buku terbaik , dan 2  pada  buku yang jelek . Jika menggunakan cosine similarity , keduanya  sangat berbeda . Adjusted  cosine similarity  mengatasi  kelem ahan dari cosine similarity . (Djamal, 2010)  Metode Cosine similarity  dapat ditunjukkan oleh Persamaan  
ï€¨ï€©ï€¨ï€©ï€¨ï€©
ï€¨ï€©ï€¨ï€© ïƒ¥ ïƒ¥ïƒ¥
ï€½ ï€½ï€½
ï€­ ï€­ï€­ ï€­
ï€½
m
uu lum
uu kuu lum
uu ku
R R R RR RR R
lksim
12
,
12
,,
1
,
Keterangan:  
sim(k,l) adalah nilai similarity antara item k dan item l  
m adalah jumlah total user yang merating 
item k dan item l  
uR adalah rating yang diberikan oleh 
user u  pada semua item  kuR, dan 
luR, adalah rating yang diberikan oleh user u kepada item k dan item l  
Menghitung Prediksi  dengan Non Cold Start Problem. 
Metode weighted average of deviation  yang didapat dari rata-rata item yang telah di rating  merupakan metode yang digunakan untuk prediksi rating  pada item k yang telah di rating . Rumus berikut ini merupakan perhitungan prediksi rating pada item l untuk user u.  
ï€¨ï€©
ïƒ¥ïƒ¥
ï€½ï€½ï‚´ï€­
ï€«ï€½n
in
ll lu
k ku
lksimlksimR R
R P
11
,
|),(|),(  
Keterangan:  
Pu,k adalah prediksi rating item k untuk user u  
n adalah jumlah rated item user u  luR,
adalah rating dari user u  untuk item l  
kR dan lR adalah rating rata-rata untuk 
item k dan item l  Sim(k,l) adalah nilai similarity antara item 
k dengan seluruh rated item active user  
Cold Start Problem. 
Metode perhitungan prediksi pada non cold-start problem yaitu weighted average of deviation masih kurang dapat  diimplimentasikan pada masalah item baru yang belum di rating  karena kR yang  merupakan nilai rata-rata pada item k akan bernilai nol (karena belum ada yang memberi rating ). Oleh karena itu digunakan metode weighted sum untuk menghitung prediksi rating pada kasus item baru. Berikut rumus perhitungannya pada persamaan    
Keterangan:  
Pu,k adalah prediksi rating item k untuk user u  
n adalah jumlah rated item user u  
luR,adalah rating diberikan user u  kepada item l  
Sim(k,l) adalah nilai similarity antara item k dengan seluruh rated item ke -l  
Akurasi sistem rekomendasi dilihat berdasarkan nilai mean absolute error  (MAE)., yaitu rata-rata dari error yang di absolutkan. Dimana error merupakan selisih  dari nilai rating  sebenarnya dengan nilai rating hasil prediksi. Berikut adalah perhitungan MAE yang ditunjukkan oleh Persamaan.   
NR P
MAEN
uiu iuïƒ¥
ï€½ï€­
ï€½1, ,  
Dimana Pu,i  adalah prediksi rating user u untuk item i dan Ru,i  adalah nilai rating sebenarnya yang telah diberikan oleh user u untuk item i. 
 
PEMBAHA SAN  
Dalam penelitian ini dilakukan beberapa pengujian, hasil pengujian yang diperoleh tersebut adalah sebagai berikut:  
Pada uji coba 1 dilakukan pengujian dengan data yang digunakan sebanyak 5 user dan 5 buku dengan besarnya rating yang berfariasi. Dari hasil uji coba 1 dapat disimpulkan bahwa hasil prediksi yang dihasilkan oleh sistem cukup akurat dan sama hasilnya dengan prediksi manual yang dihitung oleh Microsoft Excel, ini juga di buktikan oleh kecilnya MAE yang diberikan oleh sistem.   
Tabel 1 Tabel rating user terhadap buku  
User  1 2 3 4 5 
Buku  1 3 0 8 4 5 
2 5 8 7 3 7 
3 7 4 0 7 6 
4 8 7 9 9 8 
5 10 3 8 3 7  
Langkah pertama adalah mencari nilai rata-rata rating dari setiap buku.   
Tabel 2 Tabel rata -rata rating  
User   1 2 3 4 5 rata-rata rating  
Buku  1 3 0 8 4 5 4 
2 5 8 7 3 7 6 
3 7 4 0 7 6 4,8 
4 8 7 9 9 8 8,2 
5 10 3 8 3 7 6,2 
Langkah kedua adalah mencari nilai rating â€“ (rata-rata rating) lalu dikuadratkan.  Langkah ketiga adalah mencari 
jumlah dari nilai rating -(rata-rata rating)2 perbuku dan selanjutnya diakarkan. Terlihat seperti pada Tabel 3.  
ïƒ¥ïƒ¥
ï€½ï€½ï‚´
ï€«ï€½n
ln
llu
k ku
lksimlksim R
R P
11
,
Tabel 3 Tabel jumlah rating -(rata-rata rating)2 perbuku  
Sum (rating -(rata-rata rating)2) 
Akar Sum (rating -(rata-rata rating)2) 
34 5,830952  
16 4 
34,8 5,899152  
2,8 1,67332  
38,8 6,22896 5  
Langkah keempat menhitung similariy antar buku dengan persamaan rumus dibawah. Terlihat seperti pada Tabel 5.  
ï€¨ï€©ï€¨ï€©ï€¨ï€©
ï€¨ï€©ï€¨ï€© ïƒ¥ ïƒ¥ïƒ¥
ï€½ ï€½ï€½
ï€­ ï€­ï€­ï€­
ï€½
m
ul lum
uk kul lum
uk ku
R R R RR RR R
lksim
12
0,12
,,1,
, 
Keterangan:  
sim(k,l) adalah nilai similarity antara item k dan item l  
m adalah jumlah total user yang merating ite m k dan item l  
kR dan lR  adalah rating rata-rata pada 
item k dan item l  kuR,
dan luR, adalah rating yang 
diberikan oleh user u kepada item k dan item l  
Tabel 4 Tabel similarity  
Sim(1 ,1) 1 
sim(1,2)  -0,085749293  
sim(2,3)  -0,593305566  
sim(3,4)  -0,182349202  
sim(4,5)  0,17269415  
sim(1,3)  -0,494219459  
sim(1,4)  0,819920062  
sim(1,5)  0,468051455  
sim(2,4)  -0,597614305  
sim(2,5)  0,080270162  
sim(3,5)  -0,103413708  
Setelah diketahui nilai  dari similarity antar buku, langkah selanjutnya adalah menghitung nilai prediksi buku terhadap user. Hasil dari prediksi manual dapat diimplimentasi kedalam Tabel 5.  Tabel 5  Hasil prediksi manual uji coba 1 
menggunakan M. Excel   
Tabel 6 Hasil MAE sistem uji coba 1  
MAE  
Buku 1  1,07 
Buku 2  0,57 
Buku 3  1,24 
Buku 4  0,48 
Buku 5  0,92 
Gambar 1. Hasil prediksi si stem uji coba  
1 Hasil Prediksi  User  1 2 3 4 5 
Buku  1 3,86 1,81 6,71 3,41 4,185  
2 5,23 7,39 7,3 3,86 6,163  
3 6,03 5,02 1,55 5,49 4,82 
4 8,13 6,00 9,88 8,79 8,178  
5 7,83 3,43 8,60 4,26 6,852  
Pada uji coba 2 dilakukan uji coba dengan data sebanyak 5 user dan 5 buku dengan besarnya rating yang berfariasi dan   terdapat user baru yang belum pernah  merating sama sekali.  Dari hasil uji coba 2 dapat disimpulkan bahwa hasil prediksi yang dihasilkan oleh sistem cukup akurat dan sama hasilnya dengan prediksi manual yang dihitung oleh Microsoft Excel, ini juga dibuktikan oleh kecilnya MAE yang diberikan oleh 
sistem. Apabila ada salah satu user yang belum pernah merating sama sekali maka sistem tetap akan memberikan rekomendasinya terhadap user tersebut berdasarkan hasil dari nilai rating yang diberikan oleh user lain yang telah merating.   
Tabel 7 Tabel rating user terhadap buku 
uji coba 2  User  
1 2 3 4 5 
Buku  1 3 0 8 4 0 
2 5 8 7 3 0 
3 7 4 0 7 0 
4 8 7 9 9 0 
5 10 3 8 3 0  
Langkah pertama adalah mencari nilai rata-rata rating dari setiap buku. Terlihat seperti pada Tabel 8  dibawah ini   
Tabel 8 Ta bel rata-rata rating  
User   1 2 3 4 5 rata-rata rating  
Buku  1 3 0 8 4 0 3 
2 5 8 7 3 0 4,6 
3 7 4 0 7 0 3,6 
4 8 7 9 9 0 6,6 
5 10 3 8 3 0 4,8 
Langkah kedua adalah mencari nilai rating â€“ (rata-rata rating) lalu dikuadratkan.   
Langkah ketiga adalah mencari jumlah dari nilai rating -(rata-rata rating)2 perbuku dan selanjutnya diakarkan. Terlihat seperti pada Tabel 9. dibawah ini   
Tabel 9 Tabel jumlah rating -(rata-rata rating)2 perbuku  Sum (rating -(rata-rata rating)2) Akar Sum (rating -(rata-rata rating)2) 
44 6,63325  
41,2 6,418723  
49,2 7,014271  
57,2 7,563068  
66,8 8,173127   
Langkah keempat menhitung similariy antar buku dengan persamaan rumus (2.1). Terlihat seperti pada tabel 4.10  
ï€¨ï€©ï€¨ï€©ï€¨ï€©
ï€¨ï€©ï€¨ï€© ïƒ¥ ïƒ¥ïƒ¥
ï€½ ï€½ï€½
ï€­ ï€­ï€­ï€­
ï€½
m
ul lum
uk kul lum
uk ku
R R R RR RR R
lksim
12
0,12
,,1,
,
Keterangan:  
sim(k,l) adalah nilai similar ity antara item k dan item l  
m adalah jumlah total user yang merating item k dan item l  
kR dan lR adalah rating rata-rata pada 
item k dan item l  kuR, dan luR, adalah rating yang 
diberikan oleh user u kepada item k dan item l   
ï€¨ï€©
))6,40()6,43()6,47()6,48()6,45(())30()34()38()30()33(()6,40)(30()6,43)(34()6,47)(38()6,48)(30()6,45)(33(2,1
2 2ï€­ï€«ï€­ï€«ï€­ï€«ï€­ï€«ï€­ ï€­ï€«ï€­ï€«ï€­ï€«ï€­ï€«ï€­ï€­ï€­ï€«ï€­ï€­ï€«ï€­ï€­ï€«ï€­ï€­ï€«ï€­ï€­ï€½ sim
ï€¨ï€©
))6,4()6,1()4,2()4,3()4,0(()()3()1()5()3()0(()8,13()6,1()12()2,10()0(2,1
ï€­ï€«ï€­ï€«ï€«ï€« ï€­ï€«ï€«ï€«ï€­ï€«ï€«ï€­ï€«ï€«ï€­ï€«ï€½ sim
ï€¨ï€©
2,41 44142,1
ï‚´ï€½ sim 
ï€¨ï€©
41872,6 63325,6142,1ï‚´ï€½ sim  
ï€¨ï€©328816112,02,1ï€½ sim
 (2
.1) 
Tabel 10 Tabel similarity  
Sim(1,1)  1 
sim(1,2)  0,328816112  
sim(2,3)  0,115497394  
sim(3,4)  0,531 579889  
sim(4,5)  0,672987635  
sim(1,3)  -0,107463533
sim(1,4)  0,657793514  
sim(1,5)  0,627139777  
sim(2,4)  0,704497544  
sim(2,5)  0,545166541  
sim(3,5)  0,289559158   
Setelah diketahui nilai dari similarity antar buku, langkah selanjutnya adalah menghitung ni lai prediksi buku terhadap user. Dapat diimplimentasi kedalam Tabel 11   
Tabel 11 Hasil prediksi manual uji coba 2 menggunakan M. Excel  
Gambar 2. Hasil prediksi sitem uji coba 2  Tabel 12 Hasil MAE dari uji coba 2  MAE  
Buku 1  1,37 
Buku 2  1,23 
Buku 3  1,12 
Buku 4  0,96 
Buku 5  1,46  
Pada uji coba 3 dilakukan pengecekan terhadap sistem dengan 
menggunakan perbandingan terhadap perhitungan manual pada Microsoft Excel. Data yang digunakan sebanyak 5 user dan 6 buku dengan besarnya rating yang berfariasi dan terdapat buku baru yang belum  pernah dirating sama sekali.  Dari hasil uji coba 3 dapat disimpulkan bahwa apabila terdapat buku baru dan belum pernah dirating sama sekali oleh user maka buku tersebut tidak akan direkomendasikan oleh sistem.  
\\\\ 
Gambar 3. Buku baru tidak pernah dirating  Hasil 
Prediksi  User  1 2 3 4 5 
Buku  1 4,450  1,974  6,587  3,205  -1,217  
2 6,312  5,25 7,2 4,537  -0,325  
3 6,386  3,994  2,789 4,836  -0,659  
4 8,559  6,550  8,736  7,308  1,8456  
5 7,142  4,339  7,421  4,97 0,1192  
Pada uji coba 4 dilakukan pengecekan terhadap sistem dengan menggunakan data yang digunakan sebanyak 10 user dan 5 buku dengan besarnya rating yang berfariasi. Dari hasil uji coba 4 dapat disimpulkan bahwa semakin banyak user  yang menggunakan sistem maka hasil dari prediksi yang dihasilkan kurang akurat.  
Gambar 4 Hasil prediksi kurang akurat  
Pada uji coba 5 dilakukan pengecekan terhadap sistem dengan 
menggunakan data yang digunakan sebanyak 5 use r dan 10 buku dengan besarnya rating yang berfariasi. Pada Tabel 4.27 digambarkan besarnya rating yang diberikan oleh user terhadap 5 buah buku. Dari hasil uji coba 5 dapat disimpulkan bahwa semakin banyak data, dalam hal ini adalah buku yang digunakan seb anyak 10 dan jika dibandingkan dengan percobaan 1 yaitu 5 buku maka hasil rekomendasi yang dihasilkan kurang baik.   
Gambar 5 Hasil MAE uji coba 1,2,3,4 dan 5

KESIMPULAN  
Metode collaborative  filtering dapat diimplementasikan dalam pembuatan sistem rekom endasi buku dengan melihat kedekatan buku berdasarkan nilai rating. Metode ini lemah ketika diimplementasikan pada buku baru yang belum pernah dirating sama sekali.  Hasil prediksi rating  setiap buku untuk masing-masing user dengan menggunakan metode collab orative filtering  kurang baik. Hal ini ditunjukkan berdasarkan rata-rata nilai MAE ( Mean Absolute Error ) buku pada uji coba 1 yakni 1,064 lebih kecil dari pada uji coba 
2 yakni 1,21, uji coba 4 yakni 2,474 dan ujicoba 5 yakni 3,526. Hal ini menunjukkan bah wa semakin banyak jumlah data yang digunakan dan jika terdapat user yang belum pernah merating, maka sistem yang dihasilkan relatif tidak akurat dan menghasilkan rekomendasi yang buruk.  Oleh karena itu  pada  penelitian selanjutnya, metode collaborative  filtering diharapkan agar diimplementasikan pada data yang memiliki item yang banyak dirating oleh user. Apabila terdapat  data yang banyak dan  memiliki item baru yang sedikit di-rating oleh user,  maka diharapkan menggunakan metode yang lebih baik dari collaborative  filtering , misalnya adalah ICHM  (Item-Based Clustering Hybrid Method) . ICHM  (Item-Based Clustering Hybrid Method) adalah salah satu metode yang menggunakan pendekatan hybrid atau menggabungkan kedua pendekatan yaitu Content Based Filtering dan Collaborative Filtering.  
 
DAFTAR PUSTAKA  
Djamal, A Rhamadanus. Maharani, Warih dan Kurniati, Angelina 
Prima (2010). Analisis dan Implementasi Metode Item-Based Clustering Hybrid Pada Recomender Sytem.  
Lam, S. And Riedl, J. (2004). Shilling recommender systems  for fun and profit. In Proceedings of the 13th InternationalWWW Conference . New York. . 
Li, Qing and Kim, Byeong Man 2002. An Approach for Combining 
Content-based and Collaborative Filters. Departement of Computer Sciences,  Kumoh National Institute of Tech nology.  
Sarwar, Badrul et al. 2001. Item-based Collaborative Filtering Recommender System Algorithm. GroupLens Research  
Group/Army HPC Research Center, Department of Computer Science and Engineering, University of Minnesota. Mienneapolis.  
Uyun, S. Fahrurro zi, I. dan Mulyanto, A. 2011. Item Collaborative Filtering untuk Rekomendasi Pembelian Buku secara Online . JUSI, Vol. 1, 
No. 1 ISSN 2087 -8737",sistem rekomendasi,Collaborative Filtering,5 user dan 5 buku dengan besarnya rating yang berfariasi,"similatity, MAE"
PENERAPAN ALGORITMA APRIORI PADA SISTEM REKOMENDASI BARANG DI MINIMARKET BATOX,"PENERAPAN ALGORITMA APRIORI PADA SISTEM REKOMENDASI BARANG DI MINIMARKET BATOX

Nur Fitrina1) Kustanto 2) Retno Tri Vulandari 3) 

ABSTRACT  
Recommendations are the result of observation, data processing, and decision making in purchasing multiple products simultaneously. In processing large data the right method is needed.  Association rules are one of the techniques in data mining, this metho d can produce patterns of relationships indirectly from a number of data.  The purpose of this study is a system for purchasing goods, most likely from each combination of goods purchases. The research method used is direct interview to obtain information in the form of sales data and system requirements. The design model uses the System Development Life Cycle (SDLC). The system design method used is the Unified Modeling Language (UML). The goods recommendation system with a priori algorithm is made web -based using the PHP programming language and MySQL as a database. The results achieved in this study are a combination of 2 item sets with a minimum support of 30% and minimum confidence of 70%.  
 
Keywords: Recommendations, Association Rule, Apriori Algorithm . 
 
I. PENDAHULUAN  
Sebuah bisnis akan selalu membutuhkan sebuah informasi. Kemampuan mengolah data menjadi  informasi sangatlah diperlukan. Kecepatan informasi yang diperoleh sebuah perusahaan dapat memberikan keuntungan dalam menyusun sebuah strategi bisnis yang efektif dan efisien, salah satu keuntungan adanya kecepatan informasi adalah adanya system rekomendasi.  Adanya persaingan yang ketat merupakan salah  satu dampak kemajuan Teknologi  Informasi. Banyaknya pasar modern yang semakin bermunculan menambah tingkat kompetisi dalam persaingan pasar dalam melayani kebutuhan konsumen. Dari hal tersebut maka setiap usaha harus memiliki strategi bisnis yang dirancang sedemikian rupa agar tetap bertahan dalam persaingan pasar. Salah satu strategi adalah mengenai ketersediaan stok barang yang sesuai dengan kebutuhan konsumen.  Minimarket Batox salah satu unit yang berkecimpung di dalam dunia bisnis jual-beli yang menyediakan segala kebutuhan sehari-hari masyarakat yang berdiri dari tahun 2006.  Kendala yang sering dihadapi oleh Minimarket Batox terkait mengenai stok. Minimarket Batox mengalami kendala dalam jenis persediaan barang. Karena kekurangan persediaan jenis stok barang maka akan berdampak pada kekecewaan konsumen.  Pada Minimarket Batox setiap transaksi dicatat dalam sistem dan disimpan dalam database sistem. Dari data tersebut dapat dihasilkan sebuah informasi baru berupa sistem rekomendasi barang terkait yang sering dibeli konsumen . Salah satu metode yang dapat menyelesaikan masalah tersebut adalah association rule apriori, metode ini dapat menghasilkan kombinasi item yang ada pada transaksi pembelian  [1]. Hasil dari penelitian ini adalah sistem rekomendasi barang dengan metode algoritma apriori  dalam  pengambilan keputusan  di minimarket Batox. . 
 
II. TINJAUAN PUS TAKA  
2.1. Algoritma Apriori  
Penggalian data yang banyak membutuhkan algoritma yang  tepat. Algoritma apriori adalah salah satu algoritma pengambilan data dengan aturan asosiasi (Association rule ) untuk menentukan hubungan asosiasi suatu kombinasi item  [2]. Aturan yang menyatakan asosiasi terhadap beberapa atribut seringkali disebut market basket analysis  atau affinity analysis . Cara kerja atau tahapan kerja dari Algoritma Apriori dijelaskan pada  Gambar 1 . 
Gambar  1 Flowchart Algoritma Apriori   
Tiap iterasi menghasilkan pola frekuensi tinggi dengan panjang yang sama dimulai dari iterasi pertama yang menghasilkan pola frekuensi tinggi dengan panjang satu. Berikut tahapan algoritma apriori [3] : 
1. Pencarian kandidat itemset  (k-itemset).  
2. Penetapan pola frekuensi tinggi. Kriteria item yang termasuk dalam pola frekuensi tinggi adalah item dengan support melebihi dari ketentuan minimal support.  Jika tidak diperoleh pola frekuensi tinggi baru maka seluruh proses dihentikan dan kembali ke tahapan awal.   
2.2. Studi Literatur  
Sistem Rekomendasi Penelusuran Buku dengan Penggalian Association Rule  menggunakan Algoritma Apriori. Transaksi peminjaman buku di Badan Perpustakaan dan Kearsipan Provinsi Jawa Timur. Langkah-Langkah penelitian adalah mencari data peminjaman buku di Badan Perpustakaan dan Kearsipan Provinsi Jawa Timur, mengolah data sesuai sistem rekomendasi penelusuran buku yang berisi kode buku, nama buku, menghitung generate rule  dengan apriori yang sebelumnya menentukan minimal support  dan minimal confidence, pembuatan sistem dengan penerapan apriori, pengujian dengan pembuatan grafik waktu eksekusi support dan confidence. Hasil penelitian ini berupa asosiasi antar buku, sebagai dasar rekomendasi alternatif peminjaman buku, yang didapatkan dari perhitungan minsup dan minconf (dengan data yang digunakan sebanyak 63% dari data transaksi tahun 2009 - 2012). Data yang akan di uji memiliki persebaran yang tidak seimbang, cenderung pada transaksi dengan satu atau dua buku saja, sehingga rekomendasi yang ditemukan algoritma sedikit. Kelebihan adalah waktu eksekusi lebih cepat karena menerapkan perhitungan apriori sehingga tidak perlu melihat catatan peminjaman dahulu. [4] Data  transaksi penjualan obat pada Apotek Musi  dengan metode Apriori. Hasil penelitian adalah terbentuk nya suatu sistem pendukung keputusan yang dapat menentukan prediksi pola pembelian obat di Apotek Musi . Kekurangan adalah tidak dijelaskan secara lengkap bagaimana pembuatan sistem.  Kelebihan adalah pengetahuan baru yang dapat diperoleh berdasarkan hasil perhitungan algoritma apriori dan sistem yang dibangun dapat dilakukan pengaturan tata letak obat secara berdekatan untuk memudahkan keberadaan obat [5]. Metode association rule dengan algoritma Apriori yang dapat menemukan kombinasi item yang ada pada transaksi penjualan. Kombinasi item yang dihasilkan dari proses Apriori ini kemudian akan digunakan sebagai bahan rekomendasi strategi promosi penjualan yang berupa pembentukan paket belanja. Hasil dari penelitian ini berupa sistem informasi yang menghasilkan pembentukan paket belanja. [6] 
 
III. METODE PENELITIAN  
Dalam metode penelitian ini menggunakan System Development Life Cycle  (SDLC) yaitu Analisa, Desain, Konstruksi, Implementasi, dan Pengujian.  
3.1. Analisa  
Analisa dilakukan untuk mengetahui kebutuhan sistem. Dalam analisa dilakukan pengumpulan data sebagai sumber penelitian dengan tahapan sebagai berikut :  
1. Pengumpulan Data  
Metode ini digunakan untuk mengumpulkan data mengenai Minimarket Batox dan data yang dibutuhjan sistem. Data yang digunakan adalah data penjualan produk dengan data testing 30 transaksi data training berjumlah 100 transaksi. Selain itu, penelitian ini menggunakan metode pengumpulkan data pustaka. Data diambil dari mempelajari buku refrensi, mencari sumber yang berkaitan dengan penelitian baik dari internet maupun jurnal skripsi.  
2. Pengolahan Data 
Data ya ng di dapat dari data transaksi kemudian diolah agar menghasilkan data training. Langkah pertama adalah proses pembersihan data dengan mencari data yang memiliki sedikit kesalahan data atau clean data. Setelah menjadi data training, data tersebut dapat dig unakan untuk perhitungan dengan metode Apriori  [7]. 
3.2. Desain Sistem  
Tahapan selanjutnya merupakan desain sistem. Dalam melakukan desain sistem dirancang dengan permodelan Unified Modeling Languange  (UML). Setelah perancangan, kemudian membuat desain sistem dimana terdiri dari desain database, desain input, dan desain output  [8]. 
3.3. Konstruksi 
Tahapan pembuatan sistem ini merupakan tahapan dimana rancangan atau cetak biru sistem ini mulai dikerjakan dan dibuat  menjadi sebuah sistem yang utuh, dan dapat digunakan. Dalam penelitian ini menggunakan bahasa pemrograman PHP dan MySql sebagai database. 
3.4. Implementasi  
Tahapan ini merupakan tahapan dimana sebuah sistem sudah diimplementasikan  dibuat, Pada tahapan ini sistem diimplementasikan dengan menggunakan Algoritma Apriori.  
3.5. Pengujian  
Pengujian aplikasi  dilakukan dengan metode black box dan uji validitas. Pengujian black box adalah pengujian aspek fungsional program. Sedangkan pengujian validitas lebih 
dilakukan uji mengenai perhitungan algoritma itu sendiri yaitu algoritma apriori. Selain itu dilakukan uji di Minimarket Batox dengan membandingkan rekomendasi sistem dengan data pembelian barang pada periode tertentu sehingga dapat diketahui seberapa validitas sistem.  
 
IV. HASIL DAN PEMBAHASAN  
Pada penelitian ini data training  yang diambil berupa 100 data transaksi penjualan produk. Data training  terdiri  dari nomor faktur penjualan, kode barang, nama barang. Kemudian langkah kedua dilakukan pencarian Frequency Item . 
Data training  dikelompokan sesuai jenis barang dan di representasikan  dalam bentuk biner. Dari data training didapatkan 118 item . Pencarian kandidat pertama dengan menentukan nilai support pada item pada calon kandidat pertama dengan rumus pencarian support. Support  adalah nilai  persentase kombinasi sebuah item dalam database dan confidence  adalah kuatnya hubungan keterkaitan antar item dalam database.  
-1
Kemudian memilih item yang memiliki support lebih dari minimal support  yang telah ditentukan yaitu 30% sebagai kandidat pertama. Berikut kandidat pertama dan nilai support  terdaftar dalam Tabel 1 .  
Tabel  1 Kandidat  Pertama  
Daftar Item  Jumlah  Support  
Cofemix20g  44 44.00%  
Gula Pasir 1kg  47 47.00%  
Indomie Goreng  30 30.00%  
Sedap Kuah Ayam 
Bawang  43 43.00%  
Teh Nyapu Pack 40g  44 44.00%  
Telur Kiloan  39 39.00%  
Langkah selanjutnya adalah pencarian kandidat kedua. Pencarian kandidat kedua dengan mengkombinasikan item dari  kandidat pertama. Sehingga didapatkan item yang berpasangan. Jika kombinasi yang digunakan lebih dari satu maka cara untuk menemukan support dari dua item yaitu item A dan item B digunakan rumus beriku t [9]. 
-2
Pencarian nilai support dengan kombinasi dua item dilihat dari Tabel 2 .  
Tabel  2 Kandidat Kedua  
Daftar Item Jumlah  Support  
Cofemix 20g, Gula pasir 1kg  32 32.00%   
Iterasi berhenti pada kombinasi kedua karena item yang memenuhi syarat minimal support hanya satu kombinasi. Dari kombinasi tersebut dapat dibentuk aturan asosiasi sebagai berikut :   
{Cofemix}  â†’ {Gula Pasir}  
{Gula Pasir}  â†’ {Cofemix}   
Dari aturan asosiasi tersebut dicari confidence masing-masing dan diseleksi berdasarkan minimal confidence yang ditetapkan. Confidence  yang merupakan ukuran ketepatan suatu rule yang terkandung dalam Item A dan Item B dapat menggunakan rumus berikut  [9] . 
-3
Confidence tiap aturan asosiasi dapat dilihat pada Tabel 3 .  
Tabel  3 Nilai Confidence  
Anticedent  Consequent  Confidence  
Cofemix 20g  Gula Pasir 1kg  73.00%  
Gula Pasir 1kg  Cofemix 20g  68.00%   
Dari nilai confidence  tiap kombinasi, aturan asosiasi yang memenuhi syarat minimal confidence sebesar 70% hanya 1 yaitu aturan asosiasi pertama dengan nilai confidence 
73.00%.  
4.1 Use Case Diagram  
Use case diagram mempresentasikan sebuah interaksi antar  aktor dengan sistem, berikut ini adalah use case diagram sistem  rekomendasi barang dengan algoritma apriori  seperti yang terlihat pada Gambar 3.   
Gambar  2 Use Case Diagram Sistem Rekomendasi Barang  
4.2 Class Diagram  
Class diagram menggambarkan keadaan (atribut atau  properti) suatu sistem, sekaligus menawarkan layanan untuk memanipulasi keadaan tersebut (metode atau fungsi). Berikut adalah class diagram  sistem rekomendasi  barang dengan algoritma apriori seperti yang terlihat pada Gambar 4.   
Gambar 3 ClassDiagram Sistem Rekomendasi Barang  
4.3 Sequence Diagram  
Sequence diagram  menjelaskan interaksi objek yang berdasarkan urutan waktu atau tahapan yang harus dilakukan. Berikut Sequence Diagram perhitungan apriori :  
1. Sequence diagram untuk mengelola proses rule menghasilkan aturan asosiasi dengan apriori.   
Gambar  4 Sequence Diagram Proses Rule   
2. Sequence diagram  pencarian Frequency Item 
Gambar  5 Sequence Diagram pencarian frequent item  
3. Sequence diagram  simulasi aturan asosiasi  
Gambar  6 Sequence Diagram Simulasi  
4.4 Activity Diagram  
Activity Diagram menggambarkan berbagai alir aktivitas dalam sistem yang sedang dirancang, bagaimana masing-masing alir berawal, decision yang mungkin terjadi, dan bagaimana  mereka berakhir  [10]. Berikut activity diagram perhitungan apriori dan simulasi pada Gambar 8.  
Gambar  7 Activity Diagram Apriori   
4.5 Implementasi  
Implementasi dari sistem rekomendasi barang dengan algoritma apriori dapat dijelaskan sebagai berikut : 
1. Desain Halaman Rule dan Simulasi Rekomendasi  
Pada halaman ini akan menampilkan data input  rule dan aturan asosiasi hasil generate rule.  Pada halaman sim ulasi ditampilkan bagaimana simulasi rekomendasi barang sesuai barang yang dipilih seperti  yang terlihat pada Gambar 11 dan Gambar 12 .  
Gambar  8 Halaman Rule   
Gambar  9 Halaman Simulasi   
2. Pengujian Sistem 
Pengujian sistem akan dilaksanakan dengan cara pengujian fungsionalitas sistem. Pengujian  fungsionalitas sistem dilakukan dengan teknik pengujian black box testing  dan uji validitas . Berikut merupakan tabel pengujian BlackBox  dari perhitungan apriori .   
Tabel  4 Uji BlackBox Rule  
Test Case  Hasil 
Harapan  Hasil 
Keluaran  Hasi 
Uji 
Input minimal confidence dan minimal support dengan nilai  0-100 
Cek besaran nilai dan tersimpan di tabel rule database apriori  
Data rule tersimpan di tabel rule database apriori  
Sesuai  
Input minimal confidence dan minimal support dengan nilai  
Kosong atau tidak diisi
Penolakan dan muncul internal error  
Muncul tampilan internalerr error  
Sesuai   
Adapun pengujian fun gsional sistem dengan teknik Uji validitas adalah seperti terlihat pada Tabel 5. 
Tabel  5 Uji Validitas  
Data  Event yang sudah berlangsung  
Sistem (Algoritma Apriori)  
Perbedaan  Yang terjadi  
Data Testing  
Telur  
Indomie 
Goreng  
Minyak Sawit  
Sedap Soto  
Gula Pasir  
Tepung Terigu 
Ct 
Susu Sachet 
Gold  
Samsoe 12  
Djarum Super 
12
Teh Nyapu  
The Gopek  
Gula Wates  
Sedap Ayam bawang  
Cofemix  
Gula Pasir  
Sedap Ayam Bawang  
Indomie Goreng  
Telur  
1 item yang perlu ditambahkan dalam rekomendasi yaitu Cofemix.  
Data Training  
Telur  
Indomie Goreng  
Minyak Sawit  
Sedap Soto  
Gula Pasir  
Tepung Terigu 
Ct 
Susu Sachet 
Gold  
Samsoe 12  
Djarum Super 
12
Teh Nyapu  
Teh Gopek  
Gula Wates  
Sedap Ayam 
bawang  
Cofemix  
Cofemix  
Gula Pasir  
Sedap Ayam Bawang  
Indomie Goreng  
Telur 
Teh Nyapu 
Tidak ada lagi rekomendasi item yang belum terpenuhi.   
Dari hasil pengujian terdapat perbedaan kuantitas. Pada event yang berlangsung kuantitas lebih banyak dari rekomendasi item pada sistem disebabkan karena adanya perbedaan sudut pandang dalam penentuan. Pada event yang berlangsung ber dasarkan jumlah pembelian barang selanjutnya.  Sedangkan pada penelitian ini sudut pandang didasarkan pada pola pembelian konsumen sehingga didapatkan prediksi barang yang saling terkait dalam keranjang barang konsumen.  Dari hal tersebut maka sistem dapat  menjadi sebuah referensi dalam merekomendasikan barang untuk melengkapi pembelian stok pada event yang berlangsung.  
  
V. PENUTUP  
5.1 Kesimpulan  
Adapun kesimpulan yang didapat dari kegiatan penelitian ini adalah sebagai berikut:  
ï‚· terciptanya sebuah sistem rekomendasi barang untuk pembelian barang dengan menggunakan algoritma apriori.  
ï‚· Dari pengujiantersebut dapat disimpulkan bahwa algoritma yang digunakan program sesuai dengan perhitungan algoritma 
apriori. Selain itu dilakukan uji di Minimarket Batox dengan membandingkan rekomendasi sistem menghasilkan adanya perbedaan kuantitas pada jenis barang yang terpilih.   
5.2 Saran  
Sistem rekomendasi barang dengan algoritma apriori ini memiliki kelemahan diantara sistem tidak terintegrasi dengan sistem yang telah berjalan di  Minimarket Batok. Algoritma apriori memiliki kelemahan yaitu melakukan scan data yang berulang-ulang sehingga memori yang terpakai cukup banyak. Penelitian ini dapat dikembangakan pada metode aturan asosiasi lainya, seperti FP-Growth  dan Hash Based. Keduanya diketahui merupakan algoritma pengembangan dari algoritma apriori.  
 
DAFTAR PUSTAKA  
[1] G. I. Marthasari, Y. Azhar, and D. K. Puspitaningrum, â€œSistem Rekomendasi Penyewaan Perlengkapan Pesta menggunakan C ollaborative Filtering dan Penggalian Aturan Asosiasi,â€ J. SimanteC , vol. 5, no. 1, pp. 1 â€“8, 2015.  
[2] D. Larose, Discovering Knowledge in Data: An Introduction to Data Mining (Third Edition) . New Jersey: John Wiley & Sons, 2014.  
[3] L. Kusrini, Algoritma Data Mining . Yogyakarta: Andi Offset, 2009.  
[4] N. Wandi, â€œPengembangan Sistem Rekomendasi Penelusuran Buku dengan Penggalian Association Rule,â€ J. Tek. ITS , 
vol. 1, pp. 15 â€“20, 2012.  
[5] R. Yanto, â€œImplementasi Data Mining dengan Metode Algoritma Apriori dalam Menentukan Pola Pembelian Obat,â€ Citec J., vol. 2, pp. 46 â€“52, 2015.  
[6] R. P. Indahyahni, â€œPenggunaan Algoritma Apriori untuk Menentukan Rekomendasi Strategi Penjualan pada Toserba DIVA,â€ Jurnal TIKomSiN, Vol. 6, No. 2, Oktober 2018  ISSN Cetak   : 2338-4018  ISSN Online   : 2620-7532  27 Kediri, 2015.  
[7] N. Diahpangastuti, â€œSistem Rekomendasi Bidang  Minat Mahasiswa Menggunakan Metode Association Rule dan Algoritma Apriori,â€ Surabaya, 2014.  
[8] R. M. Anggraeni, â€œPerbandingan Algoritma Apriori dan Algoritma FP-Growth untuk Rekomendasi pada Tramsaksi Peminjaman Buku di Perpustakaan Universitas Dian Nusw antoro,â€ Semarang, 2015.  
[9] D. Listriani, A. H. Setyaningrum, and F. E. M. A, â€œPenerapan Metode Asosiasi Menggunakan Algoritma Apriori pada Aplikasi Analisa Pola Belanja Konsumen,â€ J. Tek. Inform. , vol. 9, no. 2, pp. 120 â€“127, 2016.  
[10] I. Fahmi, H. Suyon o, and M. Sarosa, â€œOptimasi Seleksi Aturan Untuk Rekomendasi Bundling Produk Melalui Kombinasi Algoritma Apriori dan Utility Weighted Score ( UWS ),â€ vol. 10, no. 2, pp. 59 â€“62, 2016.",sistem rekomendasi,"apriori, association rule",data transaksi,"minimum support, minimum confidence"
SISTEM REKOMENDASI PAKET WISATA SE-MALANG RAYA MENGGUNAKAN METODE HYBRID CONTENT BASED DAN COLLABORATIVE,"SISTEM REKOMENDASI PAKET WISATA SE-MALANG RAYA MENGGUNAKAN METODE HYBRID CONTENT BASED DAN COLLABORATIVE

Bambang  Tri Wahyo U, Angga Widya Anggriawan  

ABSTRAK  
Sistem rekomendasi merupakan suatu aplikasi untuk menyediakan dan merekomendasikan suatu item dalam membuat suatu keputusan yang diinginkan oleh pengguna. Metode hybrid content dan collaborative based  nearest neighbor dibuat untuk mengatasi kekurangan yang terdapat pada metode content dan collaborative based. Kota Malang merupakan objek yang akan digunakan dalam membangun sistem rekomendasi yang akan dibuat yaitu sistem rekomendasi paket wisata. Dengan menggunakan data history transaksi yang diproses dengan metode Content-based dan metode Collaborative, selanjutnya 
dilakukan proses hybrid dan menghasilkan hasil rekomendasi paket wisata yang sesuai bagi wisatawan.  

Kata kunci: Sistem Rekomendasi, Metode Hybrid, Content-based Filtering, Collaborative-based Filtering, nearest neighbor.  

ABSTRACT  
Recommendation system is an application to provide and recommend an item in making a decision that is desired by the user. Hybrid method of content and collaborative based nearest neighbor made to overcome deficiencies in content  and collaborative based methods. Malang is the object that will be used in building a system of recommendations that will be made of recommendation system package tours. Using transaction history data that are processed by the method of Content-based and Collaborative methods, then carried out 
the process of hybrid and produce recommendations for the appropriate package tours for tourists.  
 
Keywords: Recommendation System, Hybrid Recommendation, Collaborative-Content Based Filtering,  nearest neighbor .  
 
PENDAHULUAN  
Sistem rekomendasi telah banyak digunakan oleh hampir sebagian besar area bisnis dimana konsumen perlu membuat suatu keputusan atau rekomendasi pilihan dari informasi yang disediakan.Area pariwisata merupakan salah satu contoh bisnis area yang menerapkan sistem rekomendasi untuk membantu para wisatawan  dalam membuat keputusan bagi perjalanan mereka. Internet dan world wide web menyediakan banyak informasi dibidang pariwisata karena pariwisata memiliki pengalaman menarik bagi para wisatawan namun sangat sulit untuk menemukan informasi paket wisata yang sesuai dengan keinginan para penggunanya. Maka dibuatlah suatu sistem rekomendasi bagi industri pariwisata atau perjalanan untuk menawarkan serta merekomendasikan paket tempat-tempat wisata di Malang dan sekitarnya kepada para wisatawan yang sesuai dengan keinginan mereka.  Sistem rekomendasi didefinisikan sebagai aplikasi pada website e-commerce untuk mengusulkan informasi dan menyediakan fasilitas yang diinginkan pengguna dalam membuat suatu keputusan (Ricci, F., 2002).Sistem ini diasumsikan seperti penggambaran kebutuhan dan keinginan pengguna melalui pendekatan metode rekomendasi untuk mencari suatu item dengan menggunakan rating berdasarkan kemiripan dari karakteristik informasi pengguna.  Terdapat beberapa metode yang digunakan untuk mendukung cara kerja sistem rekomendasi dalam menghasilkan sebuah informasi diantaranya seperti demographic recommendation, collaborative recommendation, content-based recommendation dan knowledge based recommendation.  Metode collaborative dan content-based adalah metode yang sering digunakan pada sistem rekomendasi karena teknik ini menyaring informasi berdasarkan keinginan pengguna dan berdasarkan content yang disediakan (Sebastia, L et al., 2009). Namun terdapat beberapa kekurangan dalam kedua metode tersebut.Maka untuk menu tupi kelemahan pada metode-metode   tersebut dapat dilakukan dengan menggunakan metode hybrid yaitu menggabungkan beberapa metode yang terdapat pada sistem rekomendasi untuk menghasilkan item rekomendasi yang sesuai dengan keinginan pengguna. Untuk mendukung  cara kerja metode tersebut maka diperlukan algoritma classification yang akan mendukung kemampuan sistem rekomendasi dalam memberikan informasi yang sesuai. Salah 
satunya adalah algoritma Nearest Neighbor (NN).  Algoritma Nearest Neighbor (NN) merupakan algoritma pendekatan untuk mencari kasus dengan menghitung kedekatan antara kasus baru dengan kasus lama yaitu berdasarkan pencocokan bobot dari sejumlah atribut yang ada. Nearest Neighbor akan mengklasifikasikan hanya jika atribut dari kasus baru sesuai dengan salah satu atribut pada kasus lama (Ricci, F et al., 
2010).  Oleh karena itu pada penulisan tugas akhir ini akan diteliti menggunakan metode hybrid (content-based dan collaborative) dengan objek paket wisata pada sistem rekomendasi menggunakan algoritma Nearest Neighbor (NN).  
 
LANDASAN TEORI  
1. Sistem Rekomendasi  
Konsep sistem rekomendasi telah digunakan secara luas oleh hampir semua area bisnis dimana seorang konsumen memerlukan informasi untuk membuat suatu keputusan. Sistem rekomendasi paket wisata atau perjalanan menggunakan konsep ini dapat menolong para wisatawan untuk memutuskan tujuan perjalanan mereka, akomodasi dan aktivitas di tempat tujuan.  Sistem rekomendasi merupakan model aplikasi dari hasil observasi terhadap keadaan dan keinginan pelanggan . Oleh karena itu sistem rekomendasi memerlukan model rekomendasi yang tepat agar yang direkomendasikan sesuai dengan keinginan pelanggan, serta mempermudah pelanggan mengambil keputusan 
yang tepat dalam menentukan produk yang akan digunakannnya.  
Menurut Sebastia, L et al (2009) sistem rekomendasi merupakan sebuah (web) alat personalisasi yang menyediakan pengguna sebuah informasi daftar item-item yang sesuai 
dengan keinginan masing-masing pengguna. Sistem rekomendasi menyimpulkan preferensi pengguna dengan  menganalisa ketersediaan data pengguna, informasi tentang pengguna dan lingkungannya. Oleh karena itu Sebastia, L et al (2009) menyatakan sistem rekomendasi akan menawarkan kemungkinan dari penyaringan informasi personal sehingga hanya informasi yang sesuai dengan kebutuhan dan preferensi pengguna yang akan ditampilkan di sistem dengan menggunakan sebuah teknik atau model rekomendasi.  Berdasarkan metode rekomendasi yang 
sering digunakan, sistem rekomendasi dibagi dalam beberapa klasifikasi yaitu: content-based recommendation, collaborative-based recommendation dan hybrid-based recommendation dan beberapa peneliti menambahkan metode knowledge based recommendation.   
Gambar 1 Klasifikasi Sistem Rekomendasi    
2. Hybrid Recommender System  
Secara umum pendekatan hybrid recommender system  adalah menggabungkan lebih dari satu pendekatan sistem rekomendasi dengan tujuan untuk mengatasi kekurangan masing-masing pendekatan, sehingga menghasilkan sebuah rekomendasi yang baik. Terdapat beberapa cara panggabungan yang dapat dilakukan yaitu :  
a. Penggabungan secara linier ( Hybrid Linear Combination ) 
Penggabungan ini menggabungkan hasil prediksi (rating) dari metode content-based  dan collaborative . Penggabungan ini dilakukan dengan cara pemberian ranking atau rating. Penggabungan ini digambarkan pada gambar 2.3 berikut :   
Gambar 1 Hybrid Linear Combination  
b. Penggabungan secara sekuensial ( Sequential Combination ) 
Penggabungan ini adalah melakukan perhitungan pada salah satu metode (misalkan content -based ) kemudian hasilnya digabungkan dengan metode lainnya (misalkan collaborative ). Penggabungan ini digambarkan pada gambar 2.4 berikut :   
Gambar 2 Hybrid Sequentional Combination  
Penggabungan Item-based Clustering Hybrid Method  (ICHM ) Penggabungan ini mengintegr asikan informasi item dan rating pengguna untuk menghitung kemiripan item-item. Item-based clustering Hybrid Method  (ICHM) marupakan sebuah metode yang menerapkan penggabungan hybrid recommendersystem  dengan tujuan untuk meningkatkan akurasi prediksi pende katan collaborative filtering  dan menangani masalah item baru yang belum dirating (cold-star problem).     
Gambar 3 Item-based Clustering Hybrid Method  Burk,  R.  (2002)  memperkenalkan  taxonomi  untuk  sistem rekomendasi  hybrid.  Taxonomi  ini  diklasifikasikan  ke  dalam  tujuh kategori, yaitu:  
a) Weighted hybrid  : Nilai  komponen dari  sistem  rekomendasi yang berbeda digabungkan secara numerik atau menggunakan algoritma linier.  
b) Switching hybrid   : Sistem memilih komponen-komponen dari setiap rekomendasi dan menerapkan komponen yang dipilih.  
c) Mixed hybrid : Rekomendasi dari berbagai sistem rekomendasi disajikan bersama.  
d) Feature  Combination  : Fitur-fitur  yang  berasal  dari  berbagai sumber  pengetahuan  digabungkan  dan  diberikan  algoritma rekom endasi.  
e) Feature  Augmentation   :  Merupakan  salah  satu  teknik rekomendasi  yang  digunakan  untuk  menghitung  sebuah  fitur atau  sekumpulan  fitur  yang  kemudian  menjadi  bagian  yang dimasukkan ke teknik berikutnya.  
f) Cascade  : Merupakan  rekomendasi   yang  memiliki  prioritas tinggi  sebagai  solusi  pemecahan  masalah  dalam  melakukan perbaikan  
g) Meta-level  : merupakan  salah  satu  teknik  rekomendasi  yang diterapkan  dan  menghasilkan  beberapa  jenis  model,  yang kemudian digunakan sebagai input  oleh teknik berikutnya  
3. Algoritma Nearest Neighbor  
Algoritma  nearest  neighbor adalah  sebuah  metode  untuk  melakukan  klasifikasi terhadap  objek  berdasarkan  data  pembelajaran  yang  jaraknya  paling  dekat  dengan objek tersebut (Widiarsana, et al ., 2011).  Algoritma  nearest neighbor  juga disebut dengan  lazy  learner  yang  mudah  menyimpan  data  di  dalam  memori  dan  dapat mengklasifikasikan item baru dengan membandingkan item tersebut dengan item yang telah tersimpan dengan menggunakan fungsi kesamaan ( similarity function ) Menurut  Kusrini  dan  Emha  (2009)  algo ritma  nearest  neighbor adalah pendekatan  untuk  mencari  kasus  dengan  menghitung  kedekatan  antara  kasus  baru dengan  kasus  lama  dengan  berdasarkan  pada  pencocokan  bobot  dari  sejumlah  fitur yang  ada  yang  memiliki  kesamaan  ( similiarity ).  Tujuan  dari  algoritma  ini  untuk mengklasifikasikan  objek  baru  berdasarkan  atribut  dan  training  sample .  Classifier  tidak  menggunakan  model  apapun  untuk  dicocokan  dan  hanya  berdasarkan  pada memori. Adapun rumus untuk menghitung algoritma ini yaitu :   
Keterangan :  
T = kasus baru  
S = kasus yang ada dalam memori (penyimpanan)  
n = jumlah atribut dalam setiap kasus  
i = atribut individu anatara 1 s/d n  
f = fungsi similiarity  atribut i antara kasus  T dan kasus S  
w = bobot yang dibe rikan pada atribut ke -i 

PEMBAHASAN  
1. Blog Diagram Sistem yang Akan Dibangun   
Gambar 4 Blog Diagram Sistem yang akan dibangun  
Berdasarkan sistem yang akan dibangun ini user dapat menggunakan bantuan sistem agar dapat memberi keputusan mengenai paket wisata yang akan dipilih yang sesuai dengan keinginannya dan akan lebih mudah dalam  melakukan pencarian.   
2. Analisa Masalah  
Banyaknya permasalahan yang telah dialami dalam menentukan suatu keputusan memilih paket wisata, membuat wisatawan sering mengalami kesulitan dalam mencari maupun memilih paket wisata yang sesuai dengan apa yang di inginkan. Sehingga wisatawan terkadang membutuhkan waktu yang lama dalam penyeleksian paket wisata yang sesuai dengan keinginannya dan memilih salah satu tempat wisata yang akan dikunjungi. Dengan adanya permasalah-permasalahan tersebut mengakibatkan menurunnya daya tarik wisatawan terhadap tempat wisata yang ada di Kota Malang Raya.  Melihat permasalahan diatas maka dibutuhkan sebuah solusi baru untuk dapat menyelesaikannya, dan sebuah sistem rekomendasi merupakan salah satu solusi untuk permasalahan yang sering dihadapi oleh wisatawan. Dimana sistem akan membantu wisatawan dalam mencari paket wisata dan dapat membantu merekomendasikan paket wisata yang sesuai dengan keinginan dan kebutuhan.  Dengan adanya sistem ini diharapkan dapat membantu wisatawan dalam memutuskan tempat wisata yang akan dikunjungi, sehingga segala permasalahan wisatawan dapat teratasi dengan efektif dan efisien. Tidak menutup kemungkinan dengan sebuah solusi baru ini akan dapat meningkatkan daya tarik wisatawan logistik maupun asing untuk mengunjungi tempat wisata yang ada di Kota Malang Raya.  Dalam penyaringan informasi pada sistem rekomendasi ini dengan menggunakan metode Hybrid (Content Based- Collaborative filtering) dan menggunakan algoritma Nearest Neighbor. Dengan menggabungkan beberapa metode ini maka akan dapat memberikan hasil rekomendasi yang sesuai dengan keinginan wisata wan. Karena dalam penyaringan informasi untuk metode Hybrid (Content Based-Collaborative filtering) menggunakan profil user dan aktifitas rating terhadap tempat wisata. Sehingga wisatawan tidak akan kesulitan dalam menentukan, dan memutuskan paket wisata yang akan dipilih 
berdasarkan keinginannya.  
3. Studi Kasus  
Untuk melakukan perhitungan nearest neighbor pada sistem ini, misalkan pada database sistem telah terdapat 10 kasus user yang memilih rekomendasi paket wisata berdasarkan preferensi sebagai berikut:  
Tabel 1 Atribut Pengguna Baru  
No Variabel  Bobot  
1 Aktivitas  Refreshing  
2 Harga  Sedang  
3 Jenis wisata  Wisata Alam  
4 Lama perjalanan  2 Hari   
Untuk melakukan perhitungan nearest neighbor data user baru akan dibandingkan dengan data user lama yang terdapat  pada tabel . Kemudian dilakukan langkah-langkah sebagai berikut untuk menentukan similarity user baru dengan user sebelumnya:  
Tabel 2 ContohAtribut Rekomendasi Pengguna Lama  
No Aktivitas  Harga  
1 refreshing  MURAH  
2 refreshing  MURAH  
3 honeymoon  SEDANG  
4 adventure  MAHAL  
5 refreshing  SEDANG  
6 honeymoon  MAHAL  
7 refreshing  SEDANG  
8 refreshing  MAHAL  
9 adventure  MAHAL   
10 honeymoon  MURAH   
Berdasarkan data atribut rekomendasi pengguna lama tersebut, maka akan dilihat bagaimana kedekatan atau kesamaan antara pengguna baru dengan pengguna lama berdasarkan kedekatan atribut atau karakter dari paket wisata  yang di sukai oleh pengguna.  Langkah berikutnya adalah menghitung nilai similarity antara user  baru dengan user  lama. Maka akan ditentukan terlebih dahulu nilai dari kedekatan setiap atribut  dan bobotnya. Menghitung kedekatan user  baru dengan user  no. 01:00
a) Kedekatan nilai atribut aktivitas : refreshing - refreshing = 1  
b) Bobot atribut aktivitas : 1  
c) Kedekatan nilai atribut Harga: sedang - murah = 0.75  
d) Bobot atribut Harga: 0.75  
e) Kedekatan nilai atribut jenis wisata: wisata alam-wisata alam = 1  
f) Bobot atribut jenis wisata: 0.5  
g) Kedekatan nilai atribut lama perjalanan: 2 hari â€“ 1 hari = 0.75  
h) Bobot atribut lama perjalanan: 0.25  
Tabel 3 Contoh Kedekatan Antar Pengguna  
No Aktivitas  Harga  
1 1 0,75  
2 1 0,75  
3 0,25  1 
4 0,5 0,75  
5 1 1 
6 0,25  0,75  
7 1 1 
8 1 0,75  
9 0,5 0,75  
10 0,25  0,75   
Setelah diketahui hasil kedekatan antar pengguna lama dengan pengguna baru, kemudian dihitung nilai kedekatannya seperti berikut.   
Similarity (t,s)   = (   ) (   ) (   ) (   )         
=(   ) (         ) (     ) (         )                
=     
=      
Di atas adalah nilai hasil kedekatan dari antara pengguna baru dengan pengguna dengan Id-user 1, untuk melihat hasil kedekatan pengguna yang lain dapat dilihat tabel berikut . 
Tabel 4 Hasil Nilai kedekatan  
No Hasil  
1 0,9 
2 0,825  
3 0,6 
4 0,7 
5 1 
6 0,5 
7 0,925  
8 0,875  
9 0,6 
10 0,6  
Dari langkah 1-10 diketahui bahwa nilai tertinggi terdapat pada user 5 dengan nilai jarak 
1.Berarti user 5 memiliki kemiripan dengan user baru, sehingga hasil rekomendasi user 5 dapat direkomendasikan kepada user baru.Dari  tabel diatas akan di ambil dari 5 nilai kedekatan tertinggi, kedekatan tertinggi antara user baru dengan user lama di antaranya adalah user 5, user 7, user 1, user 8, dan user 2. Berdasarkan hasil kedekatan antar user  tersebut akan di ambil data history paket wisata yang telah dilakukan oleh user dan akan dijadikan kandidat paket wisata yang akan direkomendasikan, kemudian di cari hasil peratingan dengan menggunakan metode collaborative filtering. Berikut adalah data history paket wisata user dari hasil perhitungan dengan metode content based filtering.  
Tabel 5 History Pembelian Paket Wisata User 
Rekomendasi  
No Paket Wisata  
1 Paket Bromo Sempu 2 Hari  
2 Paket Malang Batu -Blitar 3 Hari  
3 Paket Gunung Bromo Tour  
4 Paket Kawah Ijen Bromo Malang Batu 4D3N  
5 Paket Surabaya 
Berikut ini adalah data paket wisata yang akan direkomendasikan menggunakan proses perhitungan metode collaborative filtering dengan total yang didapat dari data transaksi yang berjumlah 500.  
Tabel 6 Paket Wisata Rekomendasi  
Paket Wisata  Total  
Paket Bromo 
Sempu 2 Hari  23 
Paket Malang 
Batu -Blitar 3 Hari  20 
Paket Gunung 
Bromo Tour  32 
Paket Kawah Ijen 
Bromo Malang 
Batu 4D3N  14 
Paket Surabaya 
Tour 2 Hari  18 
Proses hitung paket wisata rekomendasi berdasarkan rating untuk setiap item yang akan direkomendasikan :  
Paket Bromo Sempu 2 Hari    = (       ) 
  =   
  =    
Di atas merupakan proses perhitungan nilai rekomendasi Paket Bromo Sempu 2 Hari, untuk paket wisata rekomendasi lainnya dapat dilihat pada tabel 3.15.  
Tabel 7 Hasil Rekomendasi  
Paket Wisata  NR 
Paket Gunung Bromo Tour  100  
Paket Bromo Sempu 2 Hari  80 
Paket Malang Batu-Blitar 3 Hari  80 
Paket Kawah Ijen Bromo Malang Batu 4D3N  60 
Paket Surabaya Tour 2 Hari  60  
Berdasarkan hasil rekomendasi dengan nilai 3 tertinggi akan dijadikan rekomendasi kepada user baru dan ditampilkan pada halaman rekomendasi. Dari tabel 3.15 paket wisata yang akan di rekomendasikan adalah Paket Gunung Bromo Tour, Paket Bromo Sempu 2 Hari, dan Paket Malang Batu-Blitar 3 Hari.  

IMPLEME NTASI DAN PENGUJIAN  
1. Implementasi Halaman Utama Untuk User (Customer)  
Pada halaman depan ini terdapat beberapa menu utama yang dapat digunkan oleh user, terdapat menu home, about us, car rental, paket wisata, rekomendasi, dan contact. Berikut ini merupakan tampilan dari halaman utama untuk user.  
Gambar 5  Halaman Utama  
2. Implementasi Menu Rekomendasi  
Pada menu rekomendasi ini dapat digunakan ketika user tersebut sudah mengisi form rekomendasi. Tujuan menu ini adalah mempermudah dalam memilih paket wisata dan  menentukan paket wisata mana yang akan dituju sesuai dengan atribut rekomendasi setiap user. Proses perhitungan pada menu rekomendasi ini menggunakan metode content based filtering dan collabortive filtering. Menu Count adalah menu untuk melihat proses perhitungan sistem berdasarkan hasil rekomendasi tersebut. Berikut ini adalah tampilan menu rekomendasi.  
Gambar 6 Menu Rekomendasi   
3. Pengujian Beta ( Kuesioner ) 
Pengujian beta dengan mengggunakan kuesioner terhadap pihak terkait. Tujuan dari pengujian beta dengan kuesioner kepada pengguna, apakah aplikasi yang dibuat dapat diterapkan untuk membantu dalam penyelesaian masalah dan menentukan atau memilih paket wisata yang akan direkomendasikan kepada 
pengguna.  Dalam pengujian kuesioner sistem ini menggunakan 30 data pengguna baru yang memiliki kesamaan atribut rekomendasi, di mana setiap pengguna baru tersebut akan menjalankan sistem yang telah dibuat, Kemudian melakukan pemilihan paket wisata dari total semua paket wisata yang telah diproses untuk di jadikan rekomendasi. Hasil kecocokan tiap pengguna baru akan dijumlahkan dengan hasil kecocokan pengguna lainnya, total hasil kecocokan semua paket wisata yang di rekomendasikan kepada pengguna baru akan di bagii dengan jumlah nilai korespondensi paket wisata rekomendasikan. Kemudian hasil tersebut akan dikalikan dengan 100%, maka akan didapat persentase hasil pengujian kuesioner. Hasil kuesioner terhadap sistem yang dijalankan oleh pengguna baru dapat ditunjukkan pada tabel 4.2.  
Tabel 8 Hasil Kuesioner  Dengan Metode 
Hybrid (Content based â€“ Collabortive)  
Hasil kuesioner sistem pada metode hybrid(content based -collaborative) dapat dihitung dengan cara menghitung sebagai berikut : Hybrid = (Total Kecocokan/Total Koresponden)* 100%
 = ( 93 / 120 ) * 100%  
 = 0.77 * 100%  
 = 77 %  
 
PENUTUP  
1. Kesimpulan  
Berdasarkan implementasi dan pengujian yang telah dilakukan maka dapat diambil kesimpulan sebagai berikut :  
a) Telah berhasil dibuat sistem rekomendasi dengan metode hybrid dengan menggunakan algoritma nearest neigbor pada paket wisata.  
b) 2. Pada pengujian Betha (kuesioner) didapatkan nilai hasil ketepatan untuk metode hybrid(content based-collaborative) 77% mendekati dengan hasil perhitungan system dan nilai hasil ketepatan.   
2. Saran  
Penelitian ini menggunakan metode hybrid (content -based dan collaborative) dengan algoritma nearest neighbor, oleh karena itu dapat dikembangkan dan diteliti lebih lanjut dengan penggabungan metode serta algoritma lainnya pada ruang lingkup sistem rekomendasi.Sehingga dapat menghasilkan rekomendasi yang lebih baik.  
 
DAFTAR PUSTAKA  
[1] Adomavicius, G dan Tuzhilin, A. Toward the Next Generation of Recommender Systems: A survey of the st ate-of-the-art and possible extensions. IEEE transaction on knowledge and data engineering 17(6): hal.734 -749. 2005.  
[2] Anonymous. â€œKeputusan Dirjen Pariwisata Nomor (Kep -06/U/IV/1992) tentang Pelaksanaan Ketentuan Usaha Konvensi, Perjalanan Intensif dan Pame ranâ€, Dirjen Pariwisata Republik Indonesia. 1992.  
[3] Baudisch, P. Joining collaborative and content-based filtering. In Integrated Publication and Information Systems Institute IPSI: hal. 1 -5. 1999.  
[4] Belka, T dan PlÃ¶ÃŸnig, M. Designing recommender systems for tourism. Cairo. In Proceedings of ENTER. 2004.  Nama  BKI2D BS2H KI2D KIBF2D  
Annas  v v  v 
Patria  v v v  
Buchory  v  v v 
Nur  v v  v 
Rudianto   v v v 
Resa  v v v  
Yevi  v v  v 
Ria v  v v 
Rendik  v v v  
David  v v v v 
Aan   v  v 
Chris  v v v v 
Asti   v v v 
Ni Made   v v v 
Yudha  v v v  
Agung D   v v v 
JUMLAH  25 23 23 22 
TOTAL  93 
BKI2D =Paket Wisata Bromo Kawah 
IjenTour 2 Hari  
BS2H  = Paket Wisata Bromo Sempu 2 Hari  
KI2D  = Paket Wisata Kawah Ijen Tour 2 Hari  
KIBF2D  = Paket Wisata Kawah Ijen Blue Fire 
Tour 2H  
BKI2D  = Paket Wisata Bromo Kawah Ijen 
Tour 2 Hari  
[5] Bogers, T dan Bosch, A. V. D. Comparing and evaluating information retrieval algorithms for news recommendation. In the Proceedings of the 2007 ACM Conference, Minneapolis, MN, USA. RecSysâ€Ÿ07. ACM, New York, pp  141-144. 2007.  
[6] Burk, R. Hybrid Recommender Systems: Survey and Experiments. User Modeling and User-Adapted Interaction, Vol. 12(4), 331-370. 2002.  
[7] Burk, R. Hybrid recommender systems. In Proceedings of The Adaptive Web, pp 377-408. 2007.  
[8] Fathansyah. Basis  Data. Informatika Bandung, Bandung. 1999.  
[9] Jogiyanto.HM. Analisis & Desain Sistem Informasi. Yogyakarta: Andi Offset. 1990.  
[10] Kadir, Abdul. Dasar Pemrograman Web Dinamis Menggunakan PHP. Yogyakarta: Andi Offset. 2002.  
[11] Karyono, Hari. Kepariwisataan. Jakarta: Gramedia Widia Sarana Indonesia. 1997.  
[12] Kusrini & Emha. Algoritma Data Mining. Edisi ke-1. Yogyakarta: Andi Offset. 2009.  
[13] Li, Qing dan Kim, Byeong Man. An Approach for Combining Content -based and Collaborative Filters. Departement of Computer Science, Kumoh  National Institute of Technology. 2002.  
[14] Lundberg, Donald D. Ekonomi Pariwisata. Jakarta: PT Gramedia Pustaka Utama. 1997.  
[15] Pendit, Nyoman S. Ilmu Parawisata Sebuah Pengantar Perdana. Jakarta: PT Pradnya Paramita. 1990.  
[16] Ricci, F. Travel recommender system. IEEE Intelligent Systems 17(6): 55 -57. 2002.  
[17] Ricci, F., Rokach, L., Shapira, B., Kantor, B, P. Recommender System Handbook. London: Springer New York Dordrecht Heidelberg. 2010.  
[18] Sebastia, L., Garcia, I., Onaindia, E., Guzman, C. e-Tourism: A tourist recomm endation and planning application. International Journal on Artificial Intelligence Tools 18(5): 717 -738. 2009.  
[19] Smith, Valene L. Tourism Alternative. USA : The University of Ttennsylvania Press. 1991.  
[20] Suwantoro, Gamal. SH, Dasar-dasar Pariwisata. Yogyakarta: Andi Offset. 1997.  
[21] Widiarsana, O., Putra, N.W., Budiyasa, P.G.I., Bismantara, A.N.I., Mahajaya, S.N. Data Mining: Metode Clasification K -Nearest Neighbor (KNN). Bali: Program Studi Teknologi Informasi Universitas Udayana. 2011.",sistem rekomendasi,"hybrid, content-based filtering, collaborative-based filtering, nearest neighbor",rekomendasi paket wisata,"similarity, nilai kedekatan"
SISTEM REKOMENDASI PRODUCT EMINA COSMETICS DENGAN MENGGUNAKAN METODE CONTENT-BASED FILTERING,"SISTEM REKOMENDASI PRODUCT EMINA COSMETICS DENGAN MENGGUNAKAN METODE CONTENT-BASED FILTERING

Fatoni Batari Agung Larasati1, Herny Februariyanti2  

Abstract 
Emina cosmetic is a cosmetic product from Paragon Technology and Innovation Company with the concept of cosmetics for teenagers and young adults. Over time, Emina products will certainly increase in variants. With the increasing number of products, sometimes the customer find it difficult to determine the right product to use, therefore a system is needed that can recommend products according to customer 
interests and needs. This study designed an application to provide Emina cosmetic recommendations to customers based on the previously searched product.  The recommendation process is carried out by comparing the similarities between the products that the customer is looking for with the existing product description. This study uses a content-based filtering method where this method can be used to recommend 
products based on the availability of content / product descriptions. To calculate the similarity between sentences using the cosine similarity algorithm. Initially, the product description will be weighted using tf idf, then the similarity value will be calculated using the cosine similarity algorithm. Products containing keywords will be calculated for their similarity values and ranking based on the highest to lowest similarity values. In this study, the product with the highest similarity was obtained with a value of 0.7195.  

Keywords : Recommender System, Content-Based Filtering, Cosine Similarity Algorithm, tf-idf, Cosmetic  
 
Abstrak  
Emina cosmetic merupakan produk kosmetik dari PT Paragon Technology and Innovation dengan mengusung konsep kosmetik untuk remaja dan dewasa muda. Seiring berjalannya waktu, produk emina tentunya akan bertambah varian. Dengan semakin bertambahnya jumlah produk, para customer terkadang akan merasa kesulitan dalam menentukan produk yang tepat untuk digunakan, maka dari itu dibutuhkan sistem yang dapat merekomendasikan produk sesuai dengan ketertarikan dan kebutuhan customer. Penelitian ini bertujuan untuk merancang sebuah aplikasi yang dapat memberikan rekomendasi kosmetik emina kepada customer berdasarkan produk yang dicari sebelumnya.  Proses rekomedasi dilakukan dengan membandingkan kesamaan antara produk yang dicari customer dengan deskripsi produk yang ada. Penelitian ini menggunakan metode content-based filtering  dimana metode tersebut dapat digunakan untuk merekomendasikan produk berdasarkan ketersediaan konten/ deskripsi  produk. Untuk menghitung kesamaan antar kalimat menggunakan algoritma cosinesimilarity . Mulanya deskripsi produk akan dilakukan pembobotan dengan tfidf , lalu akan dihitung nilai similaritasnya dengan algoritma cosinesimilarity . Produk yang mengandung kata  kunci akan dihitung nilai kemiripannya dan dilakukan perangkingan berdasarkan nilai similaritas tertinggi hingga terendah. Dalam penelitian ini, produk dengan similaritas tertinggi didapat dengan nilai sebesar 0,7195.  
 
Kata kunci : Sistem Rekomendasi, Content-based filtering, Algoritma cosine similarity, tf-idf, kosmetik   
 
1. PENDAHULUAN  
Berkembangnya dunia kosmetik dewasa ini semakin melesat, terlebih dengan hadirnya beauty vlogger  dan beautyinfluencer  yang juga ikut mempengaruhi gaya hidup masyarakat tentang penggunaan kosmetik. Menurut Tranggono (dalam Suhartini, dkk., 2013) penggunaan kosmetik dibagi menjadi 2, yaitu kosmetik perawatan kulit ( skin care ) yaitu kosmetik untuk memelihara, merawat dan mempertahankan kondisi kulit. Sedangkan yang kedua adalah kosmetik riasan (dekoratif atau MISI make up), yaitu jenis kosmetik yang digunakan untuk mempercantik dan menutup ketidaksempurnaan pada kulit wajah, sehingga menghasilkan penampilan yang lebih menarik. Dengan beragam jenis make up  dan skincare  dari brand emina cosmetics, terkadang membuat para customer emina bingung dalam memilih jenis kosmetik yang diperlukan. Selama ini ketika customer memilih produk dilakukan dengan cara manual yaitu dengan melakukan searching di internet mengenai produk yang diperlukan. Untuk membantu customer mendapatkan lebih banyak pilihan produk yang sesuai, maka diperlukan adanya sebuah system rekomendasi yang dapat memberikan saran ataupun rekomendasi kepada para customer untuk memilih product Emina Cosmetics berdasarkan ketertarikan dan kebutukan dalam pencarian referensi. Dalam membangun system rekomendasi untuk menentukan produk yang sesuai kebutuhan customer, terdapat beberapa metode yang sering digunakan yaitu Collaborative Filtering, Content-Based Filtering, dan Hybrid. Collabo rative filtering menggunakan riwayat product yang disukai atau penilaian sebagai dasar untuk menentukan rekomendasi. Pada content-based filtering  menggunakan kesamaan produk untuk ditawarkan kepada pembeli seperti judul atau deskripsi. Sedangkan metode Hybrid menggabungkan metode dua atau lebih metode untuk menghasilkan rekomendasi yang lebih baik. Pada penelitian ini, penulis menggunakan metode content-based filtering  yang menggunakan ketersediaan konten sebuah item sebagai basis dalam pemberian rekomendasi (Ricci, 2011). Content-based filtering dipilih karena dalam proses rekomendasi tidak membutuhkan adanya penilaian pengguna lain (rating) sebagai dasar pemberian rekomendasi. Pada penelitian ini, parameter yang digunakan hanya deskripsi produk yang mirip dengan kata kunci yang dicari oleh customer. Berdasarkan item yang dicari oleh customer, system dapat merekomendasikan item baru yang memiliki kemiripan deskripsi konten dengan item lama. Jenis barang dibagi berdasarkan vektor komponen pembentuknya, misaln ya kategori face make up, kategori lip make up, kategori skincare dll. Sistem rekomendasi akan memudahkan perusahaan dalam memberikan informasi produk yang sedang dicari maupun yang direkomendasikan oleh sistem kepada customer.  
 
2. TINJAUAN PUSTAKA  DAN TEORI  
Dalam penelitian yang telah dilakukan oleh Parwita (2019) yang mengusung metode content-based filtering  salah satunya adalah penelitian yang menguji akurasi metode content-based filtering  dalam dokumen UPP dan dokumen publikasi atau penelitian calon dosen pembimbing digunakan sebagai dasar penentuan rekomendasi. Penelitian ini meninjau pengaruh stopword  dalam tingkat akurasi penentuan rekomendasi dokumen. Penelitian ini menyimpulkan bahwa system rekomendasi dengan proses stopwordremoval  masih lebih unggul dibandingkan sistem rekomendasi tanpa proses stopwordremoval . [1] Penelitian selanjutnya dilakukan oleh Fiarni C & Maharani (2019) yang merancang sebuah sistem rekomendasi untuk alternative produk kepada customer menggunakan metode content-based filtering  berdasarkan karakteristik dan history transaksi menggunakan algoritma cosine similarity.  Algoritma cosine similarity  digunakan untuk menghitung nilai kesamaan suatu produk. Metode content-based filtering  dapat menyediakan rekomendasi customer yang sesuai dengan karakteristik perusahaan dan transaksi pembelian yang terjadi.[2]  Penelitian yang dilakukan oleh badriyah & Syarif (2018) menggunakan metode content-based filtering  algoritma apriori, dimana pola-pola kombinasi item yang dibeli akan dianalisis. Sistem  dapat memberikan rekomendasi produk berdasarkan transaksi belanja yang pernah dilakukan oleh pembeli di e-commerce. Sistem 
dapat menampilkan produk rekomendasi untuk setiap user member yang aktif. Dan pada setiap detail produk yang ditampilkan, dapat direkomendasikan produk lain berdasarkan prosentasi kemunculan dari produk lain dari user yang sedang menampilkan detail produk pada saat itu. Semakin besar nilai support dan confidence yang diberikan maka akan semakin sedikit rekomendasi yang ditampilkan dan semakin kecil nilai support dan confidence yang diberikan maka akan semakin banyak rekomendasi yang ditampilkan.[3]  Penelitian selanjutnya dilakukan oleh Wijaya & Alfian (2018) yang menggunakan dua metode sekaligus yaitu content-based filtering  dan collabo rative filtering  dengan tujuan memberikan saran ataupun rekomendasi laptop kepada cutomer berdasarkan ketertarikan dan kebutuhan customer. Algoritma yang digunakan untuk metode collaborative filtering  yaitu Adjusted-cossine similarity untuk menghitung kemiripan antar customer, dan algoritma weighted sum untuk perhitungan prediksinya, sedangkan untuk metode content based filtering  
algoritma yang digunakan adalah tf-idf untuk pencarian ketersediaan konten yang ada. [4]  Kurniawati S.B (2018) melakukan peneliti an mengenai STBI (Sistem Temu Kembali Informasi) MISI pencarian buku perpustakaan dengan metode 
content-based filtering , dimana pengunjung perpustakaan nantinya akan menginput kata kunci buku yang akan dicari, selanjutnya dengan metode cosine similarity, system  akan menampilkan buku apa saja yang direkomendasikan berdasarkan kata kunci yang diinput pengunjung.[5]   
2.1 Sistem Rekomendasi  
Sistem rekomendasi adalah suatu alat atau teknik perangkat lunak yang digunakan untuk melakukan prediksi terhadap suatu objek. Sistem rekomendasi dapat memberikan saran-saran item yang bermanfaat bagi pengguna (Ricci, et al., 2011). Saran tersebut dapat digunakan untuk menentukan pengambilan keputusan oleh user, seperti menentukan item yang akan dibeli, menentukan musik yang akan dide ngarkan, film 
apa yang akan ditonton, berita mana yang akan dibaca, dsb.  Sistem rekomendasi memiliki 2 inputan yang berbeda, yaitu implicit input dan explicit input (Hu, et al., 2008). Pada implicit input, didapat dengan cara mengamati kebiasaan pengguna, seperti riwayat pemesanan, riwayat penelusuran, pola pencarian, dll. Sedangakan pada explicit input didapat dengan hasil penilaian yang diberikan oleh user, seperti pemberian rating, pemberian tanda favorite item, ataupun thumbs-up/down pada item tertentu  Klasifikasi sistem rekomendasi dapat dibagi menjadi beberapa tipe: content-based, collaborative-based, hybrid-based. Beberapa peneliti menambahkan metode knowledge based , seperti pada gambar 2.1 yang menunjukkan gambar klasifikasi sistem rekomendasi.    
Gambar 2.1 Klasisfikasi Sistem Rekomendasi    
2.2. Collaborative Filtering   
Collaborative Filtering adalah tipe sistem rekomendasi yang didasarkan pada pemberian rating oleh pengguna. Dalam hal ini, dicontohkan rekomendasi film pada sebuah website. Rating user akan merekomendasikan  film yang belum pernah ditonton pengguna lain, tetapi pengguna yang menonton dan menyukai film serupa. Untuk menentukan apakah dua pengguna serupa atau tidak, filter ini mempertimbangkan film yang ditonton keduanya dan bagaimana mereka memberikan rating. Dengan melihat kesamaan item, algoritma jenis ini pada dasarnya akan memprediksi laju film untuk pengguna yang belum menontonnya, berdasarkan pada tarif pengguna yang serupa. Agar dapat bekerja secara akurat, jenis filter ini perlu  penilaian pengguna (rating), dan tidak semua pengguna menilai produk secara konstan. Beberapa dari mereka nyaris atau tidak pernah menilai apa pun. Karakteristik lain dari metode ini adalah keragaman dalam rekomendasi, yang dapat dikatakan baik atau buruk , tergantung pada kasusnya. Sebagai contoh, katakanlah pengguna A sangat menyukai film -film dystopian dan komedi gelap. Pengguna B juga menikmati film-film dystopian tetapi tidak pernah menonton komedi gelap. Collaborative Filtering akan merekomendasikan pertunjukan komedi gelap kepada pengguna B, berdasarkan pada selera yang dimiliki kedua pengguna untuk film dystopian. Skenario ini dapat memperoleh 2 hasil: pengguna B sangat menyukai komedi gelap, dalam hal ini berarti sitem rekomenadasi berhasil. Atau, pengguna B benar -benar menikmati gaya komedi yang lebih ringan, dan dalam hal ini rekomendasinya belum berhasil.   
2.3 Content Based Filtering  
Berbeda dengan Collaborative Filtering, Content-Based Filtering tidak melibatkan pengguna lain dalam menentukan rekomendasi, namun hanya pengguna itu sendiri. Berdasarkan 
apa yang dicari user, algoritma ini hanya akan memilih item dengan konten yang mirip untuk direkomendasikan. Hal ini akan membuat keragaman rekomendasi lebih sedikit, tetapi akan berfungsi baik walaupun pengguna tidak memberikan penilaian (rating) Sebagai contoh, katakanlah pengguna A sangat menyukai film-film dystopian dan komedi gelap. Pengguna B juga menikmati film-film dystopian tetapi tidak pernah menonton komedi gelap. content-based filtering hanya akan terus merekomendasikan film dystopian atau sejenisnya. Tentu saja ada banyak kategori yang dihitung kesamaannya, contoh dalam film dapat dibangun sistem rekomendasi berdasarkan genre saja, atau mungkin sutradara, aktor utama, dsb. Metode content-based filtering akan mengekstrak informasi yang terdapat pada item kemudian membandingkannya dengan informasi item yang pernah dilihat atau disukai oleh user. Metode tersebut biasa digunakan untuk merekomendasikan, artikel, berita, maupun situs web. Teknik â€“ teknik yang biasa digunakan dalam content-based filtering seperti TF-IDF, Bayesian Classifiers, Cluster analysis, decision trees dan artificial neural networks. Metode ini memiliki kelebihan yaitu dapat memberikan rekomendasi tanpa diperlukan adanya rating oleh customer, melainkan memberikan rekomendasi berdasarkan informasi item (dalam penelitian ini deskripsi produk), sedangkan kekurangan dari metode conten-based filtering yaitu system tidak dapat memberikan rekomendasi pada user yang belum pernah melak ukan aktivitas apapun.   
 
3. METODOLOGI PENELITIAN   
Implementasi metode content-based filtering pada pemilihan produk cosmetic emina dapat memudahkan customer untuk mendapatkan saran produk berdasarkan pencarian customer.  Pengelolaan database hanya dapat dil akukan oleh admin, pada awalnya admin akan melakukan login ke dalam aplikasi terlebih dahulu. Pada menu admin, terdapat beberapa halaman yang akan dapat diakses yaitu menu kategori, kosmetik, dan stopword. Pada menu kategori, admin dapat mengelola data kat egori seperti menambah kategori, menghapus kategori, dan mengedit kategori yang sudah diinput sebelumnya. Kategori nantinya akan dipilih oleh user sebelum mencari rekomendasi produk. Selanjutnya terdapat menu produk. Pada menu kosmetik  berisi seluruh produ k yang tampil pada menu home user. Seperti pada menu kategori, admin dapat melakukan penambahan, menghapus, dan mengedit produk. Apabila admin ingin menambahkan produk admin harus mengisi kolom nama produk, kategori, harga, deskripsi produk, dan upload foto. Menu selanjutnya adalah stopword. Admin dapat  mengelola data stopword. Stopword adalah kata hubung yang nantinya akan  dihilangkan  melalui proses stopword removal.  Untuk keluar dari menu, admin dapat melakukan logout.  Pada menu customer terdapat 2 menu yaitu home dan rekomendasi . Menu home menampilkan semua produk yang terdapat pada aplikasi.  Pada awalnya, customer akan memiih kategori terlebih dahulu. Kategori diinput oleh admin dengan klasifikasi data tertentu. Selanjutnya customer menginput kata kunci  yang 
diinginkan. Apabila data valid maka sistem akan menyimpan data kata kunci dalam tabel term, kunci, temp, term, dan data rekomendasi produk akan muncul di interface rekomendasi. Data valid disini adalah apabila produk yang kata kunci nya yang diinput oleh customer tersedia dalam system. Sebagai contoh,customer menginputkan kata kunci â€œkrim pemutih wajahâ€ dalam halaman rekomendasi. Kata kunci tersebut tidak akan menghasilkan rekomendasi karena tidak tersedia produk dengan deskripsi â€œkrim pemutih wajahâ€ dalam system rekomendasi emina cosmetics ini.   
Gambar 3.1 Diagram  Sistem Rekomendasi   
3.1. Pengumpulan  Data  
Objek dalam penelitian ini adalah Brand Emina Cosmetics yang saat penelitian ini dibuat memiliki 87 varian produk yang berbeda.  Penulis melakukan wawan cara langsung dengan assistant trainer di PT Paragon Technology and Innovation, dimana assistant trainer yang memiliki data product knowledge brand kosmetik emina yang merupakan data yang diolah dalam system rekomendasi. Data produk selanjutnya di klasifi kasikan sesuai dengan jenis produk diantaranya adalah :  
1. Face Make Up  
Berisi produk make up wajah  
2. Lip Make Up  
Berisi produk make up bibir  
3. Eye Make Up  
Berisi produk make up mata  
4. Cheek Make Up  
Berisi produk make up pipi  
5. Body Care  
Berisi produk perawatan tubuh  
6. Lip Care  
Berisi produk perawatan bibir  
7. Skin care  
Berisi produk perawatan wajah  
8. Nail  
Berisi produk untuk kuku  
9. Other  
Berisi produk / tools kecantikan  
Gambar 3.2 Activity Diagram Rekomendasi  
Proses rekomendasi dengan metode content-based filtering pada penelitian ini menggunakan algoritma cosine similarity dilakukan dengan tahapan sebagai berikut :  
1. Customer menginput kata kunci pada kolom cari sesuai dengan produk yang akan dicari  
2. System akan membaca teks (deskripsi produk) secara baris per baris. Pada proses membaca teks system melakukan proses 
tokenisasi, yaitu membagi teks yang dapat berupa kalimat, paragraf atau dokumen, menjadi token-token/bagian-bagian 
tertentu, dan pada waktu yang bersamaan dilakukan juga proses penghapusan karakter tertentu, seperti  tanda baca, tagtag html.  Sebagai contoh kata â€œ Emina cc cream dapat menyamarkan pori dan garis halus pada wajah. â€ menghasilkan 11 token yaitu â€œeminaâ€, â€œccâ€, â€œcreamâ€, â€œdapatâ€,  â€œmenyamarkanâ€, â€œporiâ€, â€œdanâ€, â€œgarisâ€, â€œhalusâ€, â€œpadaâ€, â€œwajahâ€  
3. Stopword remo val, yaitu menghilangkan kata hubung yang kurang penting sebagai contoh : dan, di, ke, dari, yang, dll.  
4.  Menentukan bobot setiap term dari produk yang mengandung kata kunci. Bobot dalam dokumen dihitung dengan menggunakan tf-idf. TF - IDF dikenal efisien, mudah dan memiliki hasil yang akurat (Robertson, 2006:45). Metode ini menghitung nilai Term Frequency (TF) dan Inverse Document Frequency (IDF) pada setiap token (kata) di setiap dokumen dalam korpus. Frekuensi kemunculan sebuah kata  dalam dokumen tertentu dan inverse frekuensi dokumen yang mengandung kata tersebut digabungkan untuk menghitung bobot. Metode ini akan menghitung bobot setiap token t di dokumen d dengan rumus berikut : 
IDF = (D/DF)  
W = TF * (IDF +  1)  
Keterangan :  
TF : jumlah kemunculan kata atau term dalam dokumen  
IDF = inverse document frequency  
D = jumlah semua dokumen  
DF = jumlah dokumen yang mengandung kata (term)  
W : bobot setiap dokumen  
Setelah bobot (W) masing-masing dokumen diketahui, maka dilakukan proses pengurutan dimana semakin be sar nilai W, semakin besar tingkat similaritas dokumen tersebut terhadap kata kunci, demikian sebaliknya.   
5. Hitung kemiripan vektor [kosmetik] query Q dengan setiap dokumen yang  ada. Kemiripan antar kosmetik dihitung dengan algoritma cosine similarity menggunakan rumus similarity :   
A = Vektor A, yang akan dibandingkan kemiripannya  
B = Vektor B, yang akan dibandingkan kemiripannya  
A â€¢ B = dot product antara vektor A dan vektor  
B |A| = panjang vektor A |B| = panjang vektor B  
|A||B| = cross product ant ara |A| dan |B|  
 
4. HASIL DAN PEMBAHASAN   
Proses rekomendasi emina cosmetics dilakukan dengan tahapan text preprocessing, pembobotan TF-IDF, dan perhitungan cosine similarity,  Pada penelitian kali ini, akan dihitung nilai produk yang akan direkomendasikan apabila customer memilih kata kunci â€œloose powder untuk kulit berminyakâ€:  
1. Text Prepocessing  
Lakukan text preprocessing pada deksripsi produk dengan tujuan agar data yang dipakai dapat diproses menjadi angka dengan TF-IDF dan cosine similarity . Tahapan dalam  proses ini adalah tokenisasi dan stopword  removal. Preprocessing dilakukan pada item yang mengandung kata kunci saja sehingga proses pencarian tidak memakan waktu yang lama, dimana deskripsi produk yang mengandung kata kunci pada penelitian ini ada 10 dok umen . Hasil dari preprocessing dapat dilihat dalam tabel 4.1  
Tabel 4.1  Hasil Prepocessing  
Doc Kode  Nama Produk  Setelah Prepocessing  
Q - Loose powder untuk kulit berjerawat  loose powder kulit jerawat  
D1 S0001  Bare with me mineral compact powder 01 fair,  14 gr  complexion powder wajah halus bebas kilap seharian warna kulit merata hasil ringan bebas kilap memiliki varian warna fair light beige amber ebony cocok tampil natural memiliki kandungan soft focus agent kesan halus membantu menyerap minyak praktis dibawa bentuk compact  
D2 S0002  Emina bare with me mineral loose powder 01 fair 8 g  complexion powder wajah halus bebas kilap seharian warna kulit merata memiliki tekstur ringan halus tahan memiliki 4 pilihan warna fair light beige amber ebony cocok tampil natural memiliki kandungan soft focus agent kesan halus membantu menyerap minyak  
D3 S0003  Emina sebum complexion powder fighter loose powder 8 g mengandung partikel sebum absorbent menyerap minyak berlebih cocok kulit berjerawat rentan berjerawat bedak translucent berwarna less pigmen cocok warna kulit setting powder ringan kulit bebas kilap shine free  
D4 S0004  Emina bright stuff loose powder 55 g complexion powder mencerahkan tampilan wajah kulit wajah halus micro smooth particle dilengkapi glitter tampilan wajah glowing natural matte finish tekstur ringan nyaman mudah dibaurkan efek mencerahkan natural kulit wajah tingkat coverage diatur sheer to full tahan  
D5 S0005  Beauty bliss bb cream light, 20 ml primer makeup wajah dewy halus kelembaban menutupi kemerahan kulit 
wajah pelembab foundation ringan dipakai seharihari diperkaya vitamin c vitamin e menjadikan kulit halus bercahaya mengandung spf 32 melindungi kulit wajah sinar matahari warna light  
D6 S0006  City chic cc cake peach, 12 gr complexion powder wajah halus bebas kilap seharian warna kulit merata membantu memperbaiki tekstur kulit bertahap kombinasi unik cc cream powder hasil halus diperkaya apricot antioksidan membantu rehidrasi kulit mudah diaplikasikan longlasting ringan mudah dibaur tahan bebas kilap  
D7 S0007  Emina city chic cc cream natural 20 ml hadir color changing technology mengubah warna krim putih warna sesuai warna kulit shade pilihan light natural menyamarkan pori pori garis halus kerutan wajah mengandung vitamin c vitamine berperan antioksidan menjaga sel bahaya radikal bebas menjadikan wajah halus mengandung ekstrak aloe vera allantoin agen pelembab menghidrasi kulit  
D8 S0009  Emina bare with me mineral cushion 01 light 15 g  dewy matte finish tampilan matte lembab efek kulit sehat segar kandungan oil absorber kulit berminyak efek 1 tingkat cerah perlindungan sinar uva uvb tekstur ringan tahan buildable coverage  
D9 S0010  Emina refill bare with me mineral cushion 01 light 15 g  refill cushion dewy matte finish tampilan matte lembab efek kulit sehat segar kandungan oil absorber kulit berminyak efek 1 tingkat cerah perlindungan sinar uva uvb tekstur ringan tahan buildable coverage  
D10  S0095  Emina daily matte loose powder 01 light beige 20 g  complexion powder daily matte loose powder ringan bare with me cocok sehari memiliki coverage rendah bare with me selling pointnya tampilan matte bebas kilap ringan sasaran daily matte customer muda  
2. Pembobotan TF-IDF 
Pembobotan dilakukan pada deskripsi produk yang mengandung kata kunci, setiap dokumen yang mengandung term diberi nilai 1. Pembobotan setiap term dapat dilihat pada tabel 
4.2. Tabel 4.2 Bobot Term  
term  TF Loose  Powder  Kulit  Jerawat  
Q 1 1 1 1 
D1  1 1  
D2  1 1  
D3  1 1 1 
D4  1 1  
D5   1  
D6  1 1  
D7   1  
D8   1  
D9   1  
D10  1 1   
Nilai DF merupakan jumlah dari term yang ditemukan pada setiap dokumen. Hitung nilai IDF dengan rumus IDF = Log(n/DF). Hasil perhitungan idf seperti yang ditampilkan pada tabel 4.3.  
Tabel 4.3 Hasil Perhitungan idf   
term  DF D/DF  IDF 
Loose  2 5,5 0,7404  
Powder  7 1,5714  0,1963  
Kulit  10 1,1 0,0414  
Jerawat  2 5,5 0,7404   
Lakukan perhitungan Wdt dengan rumus Wdt=tf.idf, dan didapatkan hasil seperti pada tabel 4.4.  
Tabel4. 4 Perhitungan Wdt   
term  Wdt=TF.IDF  
Loose  Powder  Kulit  Jerawat  
Q 0,7404  0,1963  0,0414  0,7404  
D1 0,0000  0,1963  0,0414  0,0000  
D2 0,0000  0,1963  0,0414  0,0000  
D3 0,0000  0,1963  0,0414  0,7404  
D4 0,0000  0,1963  0,0414  0,0000  
D5 0,0000  0,0000  0,0414  0,0000  
D6 0,0000  0,1963  0,0414  0,0000  
D7 0,0000  0,0000  0,0414  0,0000  
D8 0,0000  0,0000  0,0414  0,0000  
D9 0,0000  0,0000  0,0414  0,0000  
D10  0,7404  0,1963  0,0000  0,0000  
3. Perhitungan cosine similarity  
Kemiripan vector [kosmetik] query q dihitung dengan setiap dokumen yang ada menggunakan rumus cosine similarity . Hitunghasil perkalian skalar antara Q dan 10 dokumen lain. Hasilnya perkalian dari setiap dokumen dengan Q dijumlahkan dan hasilnya diperlihatkan seperti pada tabel 4.5    
Tabel 4.5 Perkalian Skalar  
term  WD*Wdi  Total  
D1 0,0000  0,0385  0,0017  0,0000  0,0402  
D2 0,0000  0,0385  0,0017  0,00 00 0,0402  
D3 0,0000  0,0385  0,0017  0,5481  0,5883  
D4 0,0000  0,0385  0,0017  0,0000  0,0402  
D5 0,0000  0,0000  0,0017  0,0000  0,0017  
D6 0,0000  0,0385  0,0017  0,0000  0,0402  
D7 0,0000  0,0000  0,0017  0,0000  0,0017  
D8 0,0000  0,0000  0,0017  0,0000  0,0017  
D9 0,0000  0,0000  0,0017  0,0000  0,0017  
D10  0,5481  0,0385  0,0000  0,0000  0,5866   
Hitung panjang vector setiap dokumen, termasuk Q dengan mengakarkan penjumlahan wdt yang berada pada kolom total. Hasil perhitungan panjang vector dapat dilihat dalam tabel 4.6.   
Tabel 4.6 Perhitungan Panjang Vektor   
term  Panjang Vektor  Total  Akar  
Q 0,5481  0,5481  0,548 1 0,5481  1,1364  1,0660  
D1 0,0000  0,0385  0,0017  0,0000  0,0402  1,0660  
D2 0,0000  0,0385  0,0017  0,0000  0,0402  1,0660  
D3 0,0000  0,0385  0,0017  0,5481  0,5883  1,0660  
D4 0,0000  0,0385  0,0017  0,0000  0,0402  1,0660  
D5 0,0000  0,0000  0,0017  0,0000  0,0017  1,0660  
D6 0,0000  0,0385  0,0017  0,0000  0,0402  1,0660  
D7 0,0000  0,0000  0,0017  0,0000  0,0017  1,0660  
D8 0,0000  0,0000  0,0017  0,0000  0,0017  1,0660  
D9 0,0000  0,0000  0,0017  0,0000  0,0017  1,0660  
D10  0,5481  0,03 85 0,0000  0,0000  0,5866  1,0660  
Terapkan rumus cosine similarity dengan menghitung kemiripan antar dokumen D1 sampai D10. Contoh perhitungan hanya dituliskan dalam D1, D3, dan D5 karena pada dokumen yang lain yaitu D2, D4, D6, D7, D8, D9, dan D10 memili ki nilai perhitungannya yang sama dengan dokumen yang dicontohkan 
dibawah ini.   
Similarity (Q,D1)=  0,0402 / (1,0660 * 0,2005)  
  = 0,0402 / 0,2137  
  = 0,1881   
Similarity (Q,D3)=  0,5883 / (1,0660 * 0,7670)  
  = 0,5883 / 0,8176  
  = 0,7195   
Similarity (Q,D5)=   0,0017 / (1,0660 * 0,0412)  
  = 0,0017 / 0,0439  
  = 0,0387     
Urutan produk yang menjadi rekomendasi dari pencarian dengan kata kunci â€œloose powder untuk kulit berminyakâ€ dapat dilihat pada tabel 
4.7. Produk yang memiliki nilai similaritas yang sama diuru tkan berdasarkan abjad. Implementasi pada sistem menghasilkan interface seperti pada gambar 4.1.   
Tabel 4.7 Hasil Rekomendasi  
Doc Nama Produk  Nilai 
Cosine  Ranking  
D3 Emina sebum fighter loose powder 8 g  0,7195  1 
D10  Emina daily matte loose powder 01 light beige 20 g  0,7195  2 
D1 Bare with me mineral compact powder 01 fair, 14 gr 0,1881  3 
D6 City chic cc cake peach, 12 gr  0,1881  4 
D2 Emina bare with me mineral loose powder 01 fair 8 g  0,1881  5 
D4 Emina bright stuff loose powder 55 g  0,1881  6 
D5 Beauty bliss bb cream light, 20 ml  0,0387  7 
D8 Emina bare with me mineral cushion 01 light 15 g  0,0387  8 
D7 Emina city chic cc cream natural 20 ml  0,0387  9 
D9 Emina refill bare with me mineral cushion 01 light 15 
g 0,0387  10 
Gambar 4.1 Hasil Rekomendasi  
 
5. Kesimpulan dan Saran   
Metode content basedfiltering  menggunakan kesamaan produk untuk ditawarkan kepada pembeli seperti judul atau deskripsi produk, metode ini tidak memerlukan parameter semacam rating untuk menghasilkan suatu rekomendasi. Algoritma cosine  similarity  cocok dipergunakan pada data yang tidak terdapat nilai subjektif seperti similaritas antara teks berdasarkan kemiripan kata dalam teks. Dalam penelitian sistem rekomendasi emina cosmetics dengan metode content-based filtering  menghasilkan 10 pr oduk rekomendasi dengan hasil akhir perhitungan cosine tertinggi dengan nilai similaritas 0,7195.  Untuk penelitian selanjutnya, produk yang disediakan dalam sistem rekomendasi dapat ditambah menjadi lebih banyak sehingga mendukung hasil rekomendasi produk yang akurat dan semakin beragam serta dapat dikembangkan menjadi platform mobile android.  
 
Daftar Pustaka:   
[1] Parwita, W. G. S. 2019. Pengujian Akurasi Sistem Rekomendasi Berbasis Content-Based Filtering. Informatika Mulawarman: Jurnal Ilmiah Ilmu Komputer , 14(1), 27 -32. 
[2] Fiarni, C., & Maharani, H. 2019. Product Recommendation System Design Using Cosine Similarity and Content-based Filtering Methods. IJITEE (International Journal of Information Technology and Electrical Engineering),  3(2), 42 -48. 
[3] Badriyah, T.,  Fernando, R., & Syarif, I. 2018. Sistem Rekomendasi Content Based  Filtering Menggunakan Algoritma Apriori . Konferensi Nasional Sistem Informasi (KNSI)  2018.  
[4] Wijaya, A., & Alfian, D. 2018. Sistem Rekomendasi Laptop Menggunakan Collaborative Filtering Dan Content-Based Filtering . Jurnal Computech & Bisnis,  12(1), Nov-27
[5] Kurniawati, S. B. 2018. Sistem Temu Kembali Informasi Pencarian Buku Perpustakaan dengan Metode Cosine Similarity (Studi Kasus di Perpustakaan Otoritas Jasa Keuangan Kantor Regional 3 Jawa Tengah dan DIY), Skripsi , Program Studi Teknik Informatika FTI Unisbank, Semarang.  
[6] Harun, R., Pelangi, K. C., & Lasena, Y. 2020. PENERAPAN DATA MINING UNTUK MENENTUKAN POTENSI HUJAN HARIAN DENGAN MENGGUNAKAN ALGORITMA K NEAREST NEIGHBOR (KNN). Jurnal Manajemen Informatika dan Sistem Informasi , 3(1), 8 -15. 
[7] L. Mutawalli, M. T. A. Zaen, and I. F. Suhriani, â€œSistem Identifikasi Persebaran Pecemaran Air Oleh Limbah di Indonesia Menggunakan Average Linkage Dan K-Mean Cluster,â€ MISI (Jurnal Manaj. Inform. Sist. Infor masi), vol. 1, no. 2, pp. 36 â€“42, 2018  
[8] M. Nawawi, M. T. A. Zaen, and M. F. Zulkarnaen, â€œImplementasi Metode Analytic Hierarchy Process (AHP) Untuk Penentuan Penerima Bantuan Kube di Dinas Sosial Lombok Tengah,â€ MISI (Jurnal Manaj. Inform. Sist. Informasi), vol. 2, no. 1, pp. 1 â€“8, 2019.  
[9] Imtihan, K., & Fahmi, H. (2020). ANALISIS DAN PERANCANGAN SISTEM INFORMASI DAERAH RAWAN KECELAKAAN DENGAN MENGGUNAKAN GEOGRAPHIC INFORMATION SYSTEMS (GIS).  Jurnal Manajemen Informatika dan Sistem Informasi , 3(1), 16 -23. 
[10] Sa'ada ti, Y., Fadli, S., & Imtihan, K. (2018). Analisis Penggunaan Metode AHP dan MOORA untuk Menentukan Guru Berprestasi Sebagai Ajang Promosi Jabatan.  Sinkron: Jurnal dan Penelitian Teknik Informatika , 3(1), 82 -90. 
[11] Imtihan, K., Hadawiyah, R., & Lombok, H. A. S. (2018). Sistem Informasi Penggajian Guru Honorer Menggunakan Konsep Agile Software Development dengan Metodologi Extreme Programming (XP) pada SMK Bangun Bangsa.  IJNS -Indonesian Journal on Networking and Security , 7(2).",sistem rekomendasi,"content-based filtering, cosine similarity, tf-idf",data product knowledge brand kosmetik emina,similarity
Penerapan Metode Content Based Filtering Dalam Implementasi  Sistem Rekomendasi Tanaman Pangan,"Penerapan Metode Content Based Filtering Dalam Implementasi  Sistem Rekomendasi Tanaman Pangan

Putri Nastiti  

Abstrak 
Panjangnya rantai distribusi merup akan 
salah satu permasalahan pokok di sektor pangan yang 
berdampak pada mahalnya harga-harga pangan. Permasalahan ini  sejalan dengan prioritas pembangunan Kabupaten Sleman tahun 2017 untuk  mewujudkan kemandirian ekonomi dengan menggerakkan sektor strategis  ekonomi lokal termasuk   diantaranya peningkatan penerapan teknologi pertanian . Hal ini berkaitan  dengan bagaimana cara memperpendek rantai pemasaran sehingga dapat meningkatkan kesejahteraan petani . Dalam upaya memangkas rantai distribusi yang terlalu panjang, maka penelitian ini menawarkan solusi sebuah sistem rekomendasi yang dapat mencatat data lahan pertanian serta merekomendasikan lahan pertanian mana saja yang berpotensi menghasilkan komoditas tanaman pangan . Dengan adanya sistem ini, pemasaran hasil  pertanian khususnya kepada pedagang akan lebih efektif dan efisien , artinya  sistem mampu memberikan rekomendasi lahan yang sesuai untuk pengguna. Dalam pembuatannya, sistem rekomendasi ini akan menerapkan teori Content Based Filtering . 

Kata Kunci: content based filtering, sistem rekomendasi, 
tanaman pangan    
 
I. PENDAHULUAN  
Di negara Indonesia yang merupakan daerah agraris, masih terdapat banyak petani yang kesulitan dalam mendistribusikan hasil panennya. Seperti yang disampaikan oleh Direktur Jendral Hortik ultura bahwa rantai distribusi bahan pangan yang berlangsung selama ini adalah sebagai berikut, sebagian besar petani yang berkelompok dan membentuk suatu kelompok tani biasanya menyalurkan hasil pertaniannya kepada pengepul. Terbagi menjadi beberapa jenis  pengepul yaitu pengepul tingkat kecil, tingkat besar, baik di tingkat kecamatan, maupun tingkat kabupaten, selanjutnya diteruskan kepada pedagang besar [1]. Permasalahan panjangnya distribusi merupakan salah satu permasalahan pokok di sektor pangan yang berdampak pada mahalnya harga-harga pangan [2].  Hal ini juga terjadi di Propinsi Daerah Istimewa Yogyakarta, khususnya Kabupaten Sleman. Tercantum di dalam prioritas pembangunan Kabupaten Sleman tahun 2017 poin ketujuh yaitu  mewujudkan kemandirian ekonomi dengan menggerakkan sektor strategis ekonomi lokal termasuk   diantaranya peningkatan penerapan teknologi pertanian. Ini juga terkait dengan bagaimana cara memperpendek rantai pemasaran sehingga dapat meningkatkan kesejahteraan petani [3]. Idealnya  hasil pertanian dapat disalurkan oleh petani langsung kepada konsumen. Namun  kenyataannya, hasil pertanian tidak bisa 
langsung sampai pada konsumen, melainkan harus melewati 
beberapa rantai distribusi. Hal ini menjadikan proses 
penyaluran hasil pertanian menjadi k urang efektif dan 
efisien, dari segi waktu dan juga biaya.  Dalam dua dekade terakhir, akibat terjadi revolusi dalam teknologi internet, jumlah informasi yang tersedia juga meningkat signifikan. Sistem rekomendasi adalah salah satu inovasi dalam  revolusi  tersebut [4] . Sistem rekomendasi menyediakan pendekatan dalam memfasilitasi keinginan dari pengguna sistem [5]  dan secara rutin digunakan untuk menyarankan item berdasarkan preferensi pengguna di masa lalu [6]. Model statistik yang terdiri dari Vector Space Model  dan probabilistic model  menjadi dasar dari algoritma sistem rekomendasi untuk mengambil informasi yang relevan [7] . Dalam upaya untuk memangkas rantai distribusi yang terlalu panjang, maka solusi yang ditawarkan berupa sebuah sistem yang dapat mencatat data lahan pertanian serta merekomendasikan lahan pertanian mana saja yang berpotensi menghasilkan komoditas tanaman pangan, berupa padi khususnya untuk daerah Cangkringan yang masih dalam proses pemulihan pasca bencana Merapi. Sistem tersebut harus dapat diakses dimanapun dan kapanpun, pengguna juga secara cepat dapat mengakses informasi melalui sistem tersebut.  Dengan adanya aplikasi mobile ini, pemasaran hasil pertanian khususnya kepada pedagang akan lebih efektif dan efisien , artinya  sistem mampu memberikan rekomendasi lahan yang sesuai untuk pengguna. Dalam pembuatannya, sistem rekomendasi ini akan menerapkan teori content based filtering .   

II. METODOLOGI  PENELITIAN  
A. Tinjuan Pustaka  
Penelitian ini dilakukan tidak terlepas dari penelitian-
penelitian ya ng pernah dilakukan sebelumnya, antara lain:  
Thorat et . al. (2015) dalam publikasi ilmiah berjudul â€œ Survey on Collaborative Filtering, Content-based Filtering and Hybrid Recommendation System â€ memberikan gambaran 
menyeluruh mengenai sistem rekomendasi yang m encakup 
metode collaborative filtering, content-based filtering dan 
pendekatan hybrid recommender system  [8]. Dalam penelitian tersebut dikatakan bahwa untuk meningkatkan kualitas rekomendasi, beberapa pendekatan hybrid digunakan terutama untuk collaborat ive filtering dan content based filtering. Algoritma hybrid  digunakan untuk mengintegrasikan informasi lokasi ke dalam algoritma rekomendasi yang ada.  Jovita et . al. (2015) dalam publikasi ilmiah berjudul â€œUsing Vector Space Model in Question Answering Systemâ€ menggunakan metode vector space model  untuk merepresentasikan pengetahuan dan mengambil jawaban untuk setiap pertanyaan  [9]. Dalam penelitian tersebut setiap query akan dibandingkan dengan pengetahuan berdasarkan pengukuran kesamaan keduanya. Data sampel yang digunakan untuk menguji model diambil dari dua kementerian yaitu Kementerian Pendidikan dan Kebudayaan serta  Kementerian Pariwisata dan Ekonomi Kreatif. Dalam percobaan, 150 pertanyaan diberikan pada sistem. Percobaan tersebut menghasilkan 0,662 recall dan 0,548 precision .  
B. Content Based Filtering  
Sistem rekomendasi memanfaatkan berbagai sumber informasi untuk menyediakan pengguna suatu prediksi dan rekomendasi. Sistem rekomendasi memanfaatkan konsep information filtering [10]. Pada information filtering pengguna sudah mempunyai profil yang merepresentasikan kepentingan jangka panjang dan sistem mencoba memberikan kepada setiap pengguna item yang relevan. Berdasarkan pada ukuran kesamaan antara masing -masing profil, sistem memilih dan membuat pering kat pada item yang relevan, kemudian diberikan kepada pengguna. Terdapat dua pendekatan pada information filtering, yaitu collaborative filtering dan content -based filtering.  Penelitian ini akan menggunakan pendekatan content-based filtering. Sistem akan memilih dan melakukan peringkat item berdasarkan kesamaan profil pengguna dan profil item. Keuntungan dari pendekatan ini adalah pengguna mendapatkan wawasan tentang mengapa suatu item dianggap relevan untuk mereka, karena konten di setiap item diketahui dari representasinya. Namun pendekatan ini juga mempunyai kelemahan, misalnya kenyataan bahwa pendekatan ini berfokus pada kemiripan kata kunci. Pendekatan ini tidak mampu menangkap hubungan yang lebih kompleks pada level semantik yang lebih dalam, berdasark an pada berbagai jenis atribut yang berhubungan dengan obyek terstruktur dari teks. Kesamaan antara representasi dari pengguna dan representasi dari item akan didasarkan pada prinsip kedekatan yang menyatakan bahwa jarak dari dua deskripsi item secara lang sung berkaitan den gan kesamaan mereka [11].  Minat atau preferensi pengguna juga diwakili oleh serangkaian fitur yang sama, yang disebut profil pengguna. Rekomendasi dibuat dengan membandingkan profil pengguna dengan item kandidat yang dinyatakan dalam set  fitur yang sama. Pendekatan paling sederhana untuk rekomendasi berbasis konten adalah dengan menghitung kesamaan profil pengguna dengan setiap item. Terdapat beberapa cara untuk merepresentasikan agar dapat digunakan sebagai komponen pembelajaran, salah satunya adalah Vector Space Model .  Pada metode ini, dokumen D direpresentasikan sebagai vektor m dimensional. Dimana setiap dimensi berkorespondensi terhadap term yang berbeda dan m adalah total jumlah term yang  dipakai dalam koleksi dokumen. Vektor dokume n adalah ditulis sebagai, wi adalah bobot dari term t i yang menunjukkan tingkat kepentingan. Jika pada dokumen D tidak mengandung term t i maka bobot dari wi adalah nol. Bobot term dapat ditentukan dengan menggunakan skema tf-idf [12]. Pada pendekatan ini bobot 
dihitung berdasarkan pada seberapa sering sebuah term muncul pada sebuah dokumen, dan seberapa sering ditemukan dalam koleksi dokumen.   
C. Vector Space Model  
Vector space model  adalah suatu model yang digunakan untuk mengukur kemiripan antara suatu doku men dengan suatu query . Pada model ini, query dan dokumen dianggap sebagai vektor-vektor pada ruang n-dimensi, dimana n adalah jumlah dari seluruh term yang ada dalam leksikon  [13]. Leksikon adalah daftar semua term yang ada dalam indeks . Vector space model digunakan karena pada metode ini memungkinkan proses pemeringkatan dokumen. Metode ini menghitung nilai cosinus dari dua vektor. Dua vektor tersebut adalah bobot dari tiap dokumen dan bobot dari query . Bobot dokumen dan query digunakan untuk  proses pemeringkatan dokumen, seperti yang terlihat pada Gambar  1 berikut.    
Gambar 1. Vector S pace Model.  
Pembobotan term dalam vektor dokumen dapat ditentukan dalam banyak cara. Pendekatan yang umum, dan digunakan dalam tugas akhir ini adalah metode TF-IDF [12, 13]. Pada metode ini, bobot term ditentukan oelh dua faktor: seberapa sering term j  terdapat dalam dokumen i ( term 3 frequency tf i,j) dan seberapa sering muncul dalam seluruh dokumen koleksi ( document frequency df j). Tepatnya bobot term j pada dokumen i dirumus kan seperti berikut:   
wi,j = tf i,j x idf j = tfi ,j x log N/df j                                            (1)  
N merupakan jumlah dokumen yang terdapat dalam koleksi dokumen. Idf merupakan singkatan dari inverse document frequency . Metode ini memberikan bob ot tinggi pada term yang sering muncul pada sedikit dokumen pada dokumen set. Setelah bobot term dihitung, diperlukan suatu fungsi pemeringkatan untuk mengukur kemiripan antara query dan dokumen vektor. Pengukuran kemiripan yang umum dikenal sebagai penguk uran kosinus. Pengukuran ini menentukan sudut antara vektor dokumen dan query ketika direpresentasikan dalam V-dimensional Euclidean, dimana v adalah ukuran vocabulary. Tepatnya kemiripan antara dokumen D i dan query Q didefinisikan sebagai berikut :  
-2 
D. Pengukuran Performansi  
Cara  konvensional untuk mengukur kualitas hasil yang dikembalikan oleh sebuah sistem dalam menanggapi permintaan adalah dengan menggunakan recall dan precision.  
i. Recall  
Recall adalah proporsi dari semua dokumen relevan yang 
dapat ditemukan-kembali oleh sebuah proses pencarian di sistem. Pada kasus ini adalah lahan pertanian ditemukan dalam proses pencarian. Rumusnya adalah : 
Recall  =   jumlah dokumen relevan yang berhasil ditemukan      (3) 
         jumlah seluruh dokumen yang ditemukan  
ii. Precision  
Precision  adalah proporsi jumlah dokumen yang ditemukan dan dianggap relevan untuk kebutuhan si pencari informasi . 
Precision =  jumlah dokumen relevan yang berhasil ditemukan   (4) 
                  jumlah seluruh dokumen yang relevan  
 
E. Tahapan Penelitian  
1. Pengumpulan Data dan Analisis  
Penulis melakukan studi pustaka untuk mengumpulkan informasi. Studi pustaka dilakukan dengan mempelajari teori-teori serta literatur yang mendukung penelitian ini terutama yang berhubungan dengan recommender system, content-based filtering, serta perangkat lunak yang digunakan untuk membangun sistem.  Selain itu penulis juga mengumpulkan data seperti data lahan pertanian yang terdapat di Kabupaten Sleman yang digunakan untuk penelitian ini.  Data lahan pertanian yang akan digunakan dalam penelitian ini sebanyak 1000 data lahan pertanian yang terdiri dari informasi berikut: kelompok tani, jenis tanaman pangan, varietas, tanggal tanam, tanggal panen, lokasi ( longitude, latitude ), hasil panen.   
2. Pengembangan sistem  
Metode yang dipakai untuk mengembangkan sistem yang dipakai adalah pendekatan content -based filtering  dengan pengukuran kemiripan (measuring similarity) antara profil item dan profil user menggunakan algoritma cosine similarity .  
3. Evaluasi Sistem  
Kualitas hasil yang dikembalikan oleh sistem dalam menjawab respon permintaan dari pengguna akan diukur menggunakan metode recall dan precision. Nilai recall precision inilah yang menentukan berhasil atau tidaknya sistem yang diba ngun dengan metode content-based filtering ini dan implementasi vector space model.    
 
III. HASIL  DAN  PEMBAHASAN  
Sebelum dilakukan implementasi program, perlu dilakukan analisis dan desain sistem  untuk mempermudah implementasi program karena sebagai acuan untuk  menghasilkan program yang baik.   
a. Gambaran Umum Sistem  
Seperti yang telah disampaikan di latar belakang masalah, sistem yang akan dibuat ini digunakan untuk memberikan informasi mengenai lahan pertanian di kawasan Sleman, DIY. Sistem yang akan dibangun mem punyai sasaran pengguna yaitu masyarakat pada umumnya dan para pedagang pada khususnya yang ingin mengetahui informasi hasil pertanian berupa tanaman padi yang berada di kawasan Sleman tersebut. Informasi yang akan didapatkan oleh pengguna sistem adalah pemilik lahan, tanggal tanam, perkiraan masa panen, dan perkiraan hasil panen, letak lokasi, dan luas lahan.  Sistem mempunyai 2 level pengguna yaitu pedagang dan petani yang bertugas melakukan update data. Pengguna tersebut mempunyai hak untuk mendapatkan rekomendasi mengenai informasi lahan pertanian yang ditampilkan oleh sistem. Dalam pembangunan sistem rekomendasi lahan pertanian ini, penulis mengumpulkan data pertanian Kecamatan Cangkringan dari Dinas Pertanian Kabupaten Sleman.   
b. Arsitektur  Sistem  
Pada Gambar 2 terlihat bahwa mobile digunakan sebagai dumb terminal . Sedangkan penyimpanan data dan proses rekomendasi, seperti perhintungan menggunakan vector space model  terjadi di web server . 
Gambar  2. Arsitektur Sistem Secara Umum .  
Gambar 3  dan 4  berikut merupakan arsitektur aplikasi, 
atau proses yang terjadi pada web server :  
kel_tani, varietas, 
tgl tanam, tgl 
panen, jumlah
data corpus
(varietas, jumlah)
Vector Space 
ModelUser (Pedagang tengkulak)
    ð‘¤ð‘„,ð‘—   Ã—   ð‘¤ð‘–,ð‘—   ð‘£
ð‘—=1
     ð‘¤2ð‘„,ð‘— ð‘£
ð‘—=1   Ã—       ð‘¤2ð‘–,ð‘— ð‘£
ð‘—=1 
List Rekomendasi similarity process 
Masukan profil pengguna
(nama, varietas, jumlah)  
Gambar 3. Arsitektur Sistem Untuk Pedagang .   
Petani
Masukan profil 
item
(kel_tani,varietas, jumlah, lokasi)
perubahan database
profil item yang telah berubah  
Gambar 4. Arsitektur Sistem Untuk Petani .  
Hasil rekomendasi pada penelitian ini didapatkan dengan 
menggunakan metode Vector Space Model, dengan mengukur kedekatan antara profil pengguna dan profil item menggunakan rumus cosine similarity . Pada implementasi vector space model  pada umumnya adalah untuk menghitung kemiripan dokumen. Namun pada penelitian ini,  vector space model  tidak digunakan untuk menghitung kemiripan dokumen, tetapi menghitung kemiripan profil item dan profil pengguna.  Berikut adalah contoh perhitungan kemiripan profil dengan algoritma vector space model , yang telah disesuaikan dengan kasus pada penelitian ini :  
Kolom pedagang pada Tabel 1 tersebut merupakan user query . Pada Tabel 1 terlihat bahwa user (pedagang) menginginkan padi varietas impari sebesar 30 ton, situbagendit 40 ton, dan ciherang 20 ton. Tetapi untuk melakukan proses perhitungan  selanjutnya angka tersebut perlu dinormalisasi. Tabel 2 adalah  hasil normalisasinya . Ide dari metode vector space model  ini adalah menghitung nilai cosinus  sudut dari dua vector.  Pada kasus ini adalah W dari petani sebagai profil item dengan W dari pedagang sebagai profil user. Nilai w sudah didapat, seperti yang tercantum pada Tabel 3. Pada tahap tersebut bobot dari query  dikalikan dengan bobot item yang terdapat di setiap record lahan, kemudian dijumlahkan untuk setiap lahannya. Kemudian langkah selanjutnya adalah mengkuadratkan bobot query. Bobot item 
di setiap lahan juga dikuadratkan. Kemudian dijumlahkan 
untuk tiap lahannya. Hasilnya seperti pada Tabel 4. Langkah terakhir adalah dengan memasukkan rumus cosine similarity . Hasilnya seperti pada Tabel 5. Jika dilihat dari hasil perhitungan, dapat ditarik kesimpulan bahwa yang mendekati kemiripan dengan profil pedagang adalah petani nomor 6 dengan nilai similarity  mencapai 0,95. Dalam metode penghitungan cosine similarity, hasil yang paling mirip adalah yang mendekati nilai satu .  
Tabel  1. Bobot Sebelum Normalisasi .  
Pedagang  Petani 1  Petani 2  Petani 3  Petani 4  Petani 5  Petani 6  Petani 7  Petani 8  Petani 9  Petani 10  
Impari  30 0 80 100 0 0 50 0 0 0 100 
Situbagendit  40 0 0 80 0 0 80 0 90 0 50 
Ciherang  20 120 0 0 0 0 60 60 70 90 0 
IR64  0 0 0 0 70 70 0 0 0 0 40 
Cibodas  0 0 0 0 0 0 0 0 0 0 0 
Cisadane  0 0 40 0 40 40 0 0 0 0 0 
Fatmawati  0 0 0 0 0 0 0 0 0 0 0  
Tabel 2. Bobot Setelah Normalisasi .  
Pedagang  Petani 1  Petani 2 Petani 3  Petani 4  Petani 5  Petani 6  Petani 7  Petani 8  Petani 9  Petani 10  
Impari  0,3 0 0,8 1 0 0 0,5 0 0 0 1 
Situbagendit 0,44444444  0 0 0,888889  0 0 0,888889  0 1 0 0,555556  
Ciherang  0,16666667  1 0 0 0 0 0,666667  0,666667  0,777778  1 0 
IR64  0 0 0 0 0 1 0 0 0 0 0,571429  
Cibodas  0 0 0 0 1 0 0 0 0 0 0 
Cisadane  0 0 1 0 0 1 0 0 0 0 0 
Fatmawati  0 0 0 0 1 0 0 0 0 0 0  
Tabel 3. Perkalian Query dan Item.  
ped*petani1  ped*petan
i 2 ped*petan
i 3 ped*petan
i 4 ped*petan
i 5 ped*petan
i 6 ped*petan
i 7 ped*petan
i 8 ped*petan
i 9 ped*petani 
10 Impari  0 0,24 0,3 0 0 0,15 0 0 0 0,3 
Situbagendit  0 0 0,395062  0] 0 0,395062  0 0,444444  0 0,246914  
Ciherang  0,16666667  1 0 0 0 0,111111  0,111111  0,12963  0,166667  0 
IR64  0 0 0 0 0 0 0 0 0 0 
Cibodas  0 0 0 0 0 0 0 0 0 0 
Cisadane  0 0 1 0 0 0 0 0 0 0 
Fatmawati  0 0 0 0 0 0 0 0 0 0 
SUM  0,16666667  0,24 0,695062  0 0 0,656173  0,111111  0,574074  0,166667  0,546914  
Tabel  4. Kuadrat Dari Bobot. 
Pedagang2 Petani 
12 Petani 22 Petani 32 Petani 42 Petani 52 Petani 62 Petani 72 Petani 82 Petani 92 Petani 102 
Impari  0,09 0 0,64 1 0 0 0,25 0 0 0 1 
Situbagendit  0,19753086  0 0 0,790123  0 0 0,790123  0 1 0 0,308642  
Ciherang  0,02777778  1 0 0 0 0 0,444444  0,444444  0,604938  1 0 
IR64  0 0 0 0 0 1 0 0 0 0 0,326531  
Cibodas  0 0 0 0 1 0 0 0 0 0 0 
Cisadane  0 0 1 0 0 1 0 0 0 0 0 
Fatmawati  0 0 0 0 1 0 0 0 0 0 0 
SUM  0,31530864  1 1,64 1,790123  2 2 1,484568  0,444444  1,604938  1 0,635173  
AKAR  0,5615235  1 1,280625  1,337955  1,414214  1,414214  1,218428  0,666667  1,266862  1 1,278739   
Tabel  5. Hasil Per hitungan .  
Petani1  Petani2  Petani3  Petani4  Petani5  Petani6  Petani7  Petani8  Petani9  Petani10  
COSINE  0,29681156  0,33375  0,925154  0 0 0,95907  0,296812  0,806995  0,296812  0,761674   
c. Use Case Diagram  
Use Case Diagram  menjelaskan urutan kegiatan yang dilakukan  aktor  dan sistem untuk mencapai tujuan tertentu, menggambarkan fungsionalitas yang diharapkan dari sebuah  
sistem. Use Case Diagram  juga serta mempresentasikan interaksi antar aktor/pelaku dengan sistem.  Gambar 5 berikut Use Case Diagram  yang digunakan pada sistem rekomendasi ini.   
Petani 
Lihat rekomendasi
Login
Registrasi
Kelola data
Pedagang depends on 
depends on 
Gambar 5. Use Case Diagram Sistem .  
d.  A ctivity Diagram  
Activity diagram  adalah representasi grafis dari seluruh 
tahapan alur kerja. Diagram ini mengandung aktivitas, pilihan tindakan, perulangan da n hasil dari aktivitas . Activity diagram  menjelaskan aktivitas antara user dengan sistem. Gambar 6 dan 7 adalah activity diagram  yang terdapat pada sistem ini . 
1. Tampil halaman cari rekomendasi
2. Tekan tombol â€˜pilih varietasâ€™ 
3. Tampil halaman pilih varietas
5. Simpan data yang telah dipilih pengguna ke dalam database
4. Pilih satu / beberapa varietas dengan menekan centang, setelah itu tekan tombol pilih
10. Simpan posisi pengguna ke dalam database
6. Tampil halaman cari rekomendasi
7. Tekan tombol â€˜perlihatkan posisi andaâ€™ untuk mengetahui titik koordinat posisi pengguna saat mengakses sistem.
8. Tampil halaman posisi pengguna
9. Tekan tombol menu â€˜simpan posisiâ€™
11. Menampilkan halaman cari rekomendasi
12. Isi jumlah permintaan pada kolom yang sudah disediakan, tekan Lihat Rekomendasi
13. Menampilkan informasi mengenai profil yang telah dimasukkan pengguna
14. Menekan tombol â€˜lanjutkanâ€™
15. Menampilkan halaman rekomendasi
16. Tekan menu rekomendasi berdasar jarak
17. Tampil halaman rekomendasi yang disesuaikan jarak terdekat antara pengguna dengan petani 
Gambar 6. Diagram Aktivitas Cari Rekomendasi .   
1. Tampil halaman profil pengguna (pedagang)
2. Tekan menu, pilih menu â€˜Lihat Rekomendasiâ€™
3. Hitung nilai cosim tiap petani dengan hitungcosimpedagang.php
4. Tampil 15 petani dengan nilai cosim terbesar
5. Tekan salah satu kolom petani
6. Ambil data dari database, dan tampilkan halaman detail rekomendasi
Gambar 7. Diagram Aktivitas Lihat Rekomendasi . 
e. Implementasi Use Case  
1. Implementasi Use Case  
Lihat Rekomendasi  
Gambar 8. Tampilan Halaman Lihat Rekomendasi .  
Setelah berhasil login , maka sistem akan menampilkan data profil pedagang yang  berupa varietas dan jumlah permintaan. Untuk mengetahui rekomendasi petani yang sesuai dengan profil pedagang, dapat menekan tombol â€˜Lihat Rekomendasiâ€™. Untuk menambah varietas tanaman sebagai profil, dapat menekan tombol menu pada handphone, dan memilih menu â€˜Tambah Dataâ€™. Sedangkan untuk menu â€˜Pencarian Baruâ€™ digunakan apabila penggguna ingin melakukan pencarian rekomendasi tetapi tidak berdasarkan profil yang tersimpan dalam database . 
Gambar 9. Tampilan Halaman Hasil Rekomendasi .  
Setelah menekan tom bol â€˜Hasil Rekomendasiâ€™ maka sistem akan menampilkan daftar petani yang cocok dengan profil pedagang. Petani yang ditampilkan hanya yang mempunyai nilai cosinus similarity dengan urutan 15 terbesar .  
2. Imple mentasi Use Case Cari Rekomendasi    
Gambar 10. Tampilan Cari Rekomendasi .  
Setelah menekan tombol â€˜Pencarian Baruâ€™ maka sistem akan menampilkan halaman cari rekomendasi. Terdapat tiga hal yang harus diisi oleh pengguna, yaitu varietas, posisi sementara, dan jumlah permintaan . 
Gambar 11. Tampilan Pilih Varietas   
Halaman pilih varietas digunakan oleh pengguna yang terdaftar sebagai pedagang. Setelah masuk ke halaman cari rekomendasi, pengguna diminta untuk memasukkan pilihan varietas yang nantinya akan digunakan sebagai profil item.   
Gambar 1 2. Tampilan Lokasi Pedagang .  
Halaman lokasi pedagang digunakan oleh pengguna yang terdaftar sebagai pedagang. Setelah masuk ke halaman cari rekomendasi, pengguna diminta untuk memasukkan posisi saat mengakses aplikasi.  Tekan tombol menu, dan pilih menu â€˜Simpan Pos isiâ€™ maka longitude latitude pengguna akan tersimpan dalam database.  
Gambar 13. Tampilan Menu Pilihan Rekomendasi Berdasar Jarak . 
Gambar 14. Tampilan Hasil Rekomendasi Kelompok Tani .  
Setelah menekan tombol â€˜Lanjutkanâ€™ pada halaman cari rekomendasi, lalu sistem akan menampilkan halaman hasil rekomendasi. Jika pengguna ingin mendapatkan hasil rekomendasi yang juga mempertimbangkan jarak lokasi lahan dengan posisi sementara pengguna, maka dengan menekan menu â€˜Rekomendasi Berdasar Jarakâ€™ sistem akan mena mpilkan hasil rekomendasi yang telah diurutkan berdasar jarak yang paling dekat .  
f.  Pengujian Kinerja Sistem  
1. Pengujian Presisi Sistem  untuk Rekomendasi Pedagang  Pengukuran presisi dilakukan dengan membandingkan kelompok tani yang relevan bagi pedagang , dengan kelompok tani hasil rekomendasi sistem. Terdapat total 75 sampel data produk yang digunakan sebagai item query, dan 10 sampel profil pedagang sebagai item profil . Sedangkan hasil yang dikeluarkan sistem adalah sebanyak 15 rekomendasi.   
Tabel 6. Sampel Profil Kelompok Tani 1 .  
Varietas : Cibodas, Inpari 4, Cimelati, Situ Patenggang, Inpari 1, IR 66, Bernas prima, Cilamaya muncul, Ciherang, Cisadane, IR 36, Fatmawati, Cisantana  Pedagang  Urutan dalam sistem :  
Laurin  1 
David  2 
Pandu  3 
Bonita  4 
Christina  5 
Rory  6 
Varietas : Situ bagendit, IR 64, Cisadane, Mendawan. Intani 1, Intani 2, Bernas Prima, IR 42, Rokan, Fatmawati, Inpari 1, Konawe, Cibodas, Inpari 2, Cisantana  
Pedagang  Urutan dalam sistem : 
David  1 
Bonita  2 
Laurin  3 
Christina  4 
Pandu  5 
Rory  6  
Tabel 8. Sampel Profil Kelompok Tani 3 .  
Varietas : Impari, Rokan, Cisadane, Inpari 3, Siak Raya, Ciapus, Ciherang, Hipa 8 Pioneer, Cisokan, Ciliwung, IR 66, Cibodas, IR 36, Celebes, Kalimas, Inpari 1, Inpari 2, IR 64, Fatmawati  
Pedagang  Urutan dalam sistem :  
Putri  1 
Pandu  2 
Rory  3 
Laurin  4 
David  5 
Christina  6 
Bonita  7  
Tabel 9. Sampel Profil Kelompok Tani 4 .  
Varietas : Ciherang, Fatmawati, Cimelati, Situ Patenggang, Inpari 1, Margas ari, IR 36, Cisokan, Hipa 8 Pioneer, IR 42, Impari, IR 64, Gilingsing, Inpari 2, Cibodas  
Pedagang  Urutan dalam sistem :  
Putri  1 
Laurin  2 
Christina  3 
Pandu  4 
David  5 
Bonita  6  
Tabel 10. Sampel Profil Kelompok Tani 5 .  
Varietas : Cibodas, Gilingsing,  Ciapus, Ciherang, Fatmawati, Inpari 2, IR 64, Cisadane, Situ bagendit, Cisantana, Batang Gadis, Rokan, IR 36  
Pedagang  Urutan dalam sistem :  
David  1 
Pandu  2 
Rory  3 
Christina  4 
Laurin  5 
Bonita  6 
Tabel  11. Revelansi Hasil Pencarian Rekomedasi Pedagang .  
Profil 1  Profil 2  Profil 3  Profil 4  Profil 5  
Pdg 1  R R R R R 
Pdg 2  R R R R R 
Pdg 3  R R R R R 
Pdg 4  R R R R R 
Pdg 5  R N R R R 
Pdg 6  R R R R N 
Pdg 7  N R R N R  
Keterangan :  
Pdg : 7 sampel profil pedagang  
Profil : 5 sampel profil kelompok tani yang diujikan   
Tabel  12. Hasil Perhitungan Precision Rekomendasi Pedagang .  
No Relevan  Not 
Relevan  Hasil 
Rekomendasi  Precision  
Profil 1  6 1 7 0,85 
Profil 2  6 1 7 0,85 
Profil 3  7 0 7 1,00 
Profil 4  6 1 7 0,85 
Profil 5  6 1 7 0,85 
Jumlah  4,40 
Rata-rata 0,88% 88,00%  
Keterangan :  
Nilai precision didapatkan dengan rumus :  
|relevant  ïƒ‡ retrieved | / | retrieved |. Dapat dilihat hasil presisi untuk profil kelompok tani 1 sampai 5. Kemudian nilai keseluruhan presisi dirata-rata dan didapatkan hasil rata-rata presisi yaitu 88.00%.  

IV. KESIMPULAN  
Pembangunan sistem ini menggunakan algoritma vector space model . Terdapat 1000 lahan yang digunakan sebagai data sampel dalam sistem. Dari proses implementasi kesimpulan  bahwa pedagang mendapatkan informasi mengenai petani mana saja yang memiliki profil yang sama dengannya. Petani mendapatan informasi mengenai pedagang mana saja yang memiliki profil yang sama dengannya.  Pengujian presisi dilakukan dengan membandingkan kelompok tani yang relevan bagi pedagang, yaitu kelompok tani yang dipilih oleh pedagang dengan kelompok tani hasil rekomendasi sistem.  Berdasarkan pengujian terhadap 10 profil pedagang dengan 15 rekomendasi kelompok tani teratas, didapatkan hasil presisi rata-rata sebesar 78.40% . Sistem akan lebih baik apa bila pengujian sistem dilakukan tidak hanya menggunakan precision tetapi juga menggunakan recall.  

REFERENSI  
[1] Rachman, F. (2017). Begini Distribusi Pangan dari 
Petani, Pengepul, Sampai Konsumen . Diakses dari : https://finance.detik.com/berita -ekonomi -bisnis/d-3415  
106/begini -distribusi -pangan -dari-petani -pengepul -
sampai -konsumen  
[2] Juli, P. (2017). Penataan Sektor Pangan. Majalah Info 
Singkat Ekonomi dan Kebijakan Publik , Vol. IX, No. 
07. Pusat Penelitian Badan Keahlian DPR RI . 
[3] Balai Penyuluhan Pertanian, Pe rikanan, Kehutanan 
BP3K (2017). UPT BP3K Wilayah II Gelar Potensi 
Pertanian . Diakses dari: http:// www.slemankab.go.id/  
9043/upt -bp3k -wilayah -ii-gelar -potensi -pertanian.slm  
[4] Deshpande, M.G., Muddebihalkar, A.V., Jadhav, A.B.  
& Kokate, S. (2016). Hybrid Conte nt-Based Filtering 
Recommendation Algorithm on Hadoop. International 
Journal of Advanced Research in Computer Engineering 
& Technology , Vol. 5. 
[5] Kalita, J., Balas, V.E., Borah, S., & Pradhan, R. (Eds.). (2019).  Recent Developments in Machine Learning and 
Data Analytics , Vol. 740. Singapore: Springer 
Singapore. Diakses dari: https://doi.org/10.1007/978 -
981-13-1280 -9 
[6] Achakulvisut, T., Acuna, D.E., Ruangrong, T., & 
Kording, K. (2016). Science Concierge: A fast content -
based recommendation system for scientific publications.  PLoS ONE , 11(7). Diakses dari: https://doi.org/10.1371/  journal.pone.0158423  
[7] Singh, J.N.  & Dwivedi, S.K. (2012). Analysis of Vector 
Space Model in Information Retrieval . International 
Journal of Computer Applications , 14-18. [8] B.Thorat, P., Gou dar, R.M. & Barve, S. (2015). Survey on Collaborative Filtering and Content -Based Recommending.  International Journal of Computer Application , 110(4), 31â€“36. Diakses dari:  https://doi.org/ 10.5120/19308 -0760  
[9] Jovita,  Linda, Hartawan, A., & Suhartono, D. (20 15). 
Using Vector Space Model in Question Answering System. In  Procedia Computer Science , Vol. 59, pp. 305â€“311. Elsevier.  Diakses dari:  https://doi.org/10.1016/  j.procs.2015.07.570  
[10] Bobadilla, J., Ortega, F., Hernando, A. & GutiÃ©rrez, A. (2013). Recommender  Systems Survey.  Knowledge -
Based Systems , 46, 109â€“132. Diakses dari https://doi.org/10.1016/j.knosys.2013.03.012  
[11] Lu, Z., Dou, Z., Lian, J., Xie, X. & Yang, Q. (2015). 
Content -Based Collaborative Filtering For News Topic Recommendation. In  AAAI 2015: Procee dings of the Twenty -ninth AAAI Conference on Artificial Intelligence , pp. 217 â€“223. Diakses dari:  https://doi.org/10.1080/714965461  
[12] Jing, L., Ng, M.K. & Huang, J.Z. (2010). Knowledge -
based vector space model for text clustering.  Knowledge 
and Information S ystems , 25(1), 35â€“55. Diakses dari:  
https://doi.org/10.1007/s10115 -009-0256 -5 
[13] Gadge, J., Sane, S. & Kekre, H.B. (2015). Performance 
Analysis of Layered Vector Space Model in Web 
Information Retrieval.  International Journal of Applied 
Information Systems , 8(5), 7â€“15. Diakses dari:  https://doi.org/10.5120/ijais15 -451320",sistem rekomendasi,"content based filtering, cosine similarity",data lahan pertanian,"presisi, precision"
Sistem Rekomendasi pada Buku dengan Menggunakan Metode Trust-Aware Recommendation,"Sistem Rekomendasi pada Buku dengan Menggunakan Metode Trust-Aware Recommendation

Mohammad Iqbal Fathurrahman#1, Dade Nurjanah#2, Rita Rismala#3 

Abstrak  
Sistem rekomendasi merupakan fitur yang banyak digunakan pada perangkat lunak zaman sekarang. Sistem rekomendasi sangat berguna untuk pengguna yang menggunakan sebuah perangkat lunak terutama sistem rekomendasi pada buku, karena fitur ini dapat memanjakan pengguna dengan memberikan rekomendasi buku yang mungkin sesuai dengan preferensi bu ku 
yang diinginkan. Sistem rekomendasi pada Tugas Akhir ini menggunakan metode Trust-Aware, dimana metode ini merupakan hasil penggabungan metode Collaborative Filtering dan PageRank. Dimana Collaborative Filtering menggunakan similarity metric untuk melak ukan penghitungan rating, dan PageRank menggunakan trust metric untuk melakukan penghitungan terhadap setiap buku yang dikunjungi dengan melakukan show synopsis. Kemudian akan dilakukan pengukuran hasil pengujian terhadap sistem rekomendasi ini menggunakan  MAE. Pengujian dilakukan dengan 3 skenario yang menggunakan 3 jenis jumlah data yang berbeda. Hasil pengujian memberikan 
angka 1,267 , 1,294 dan 1,181, yang artinya ketiga nilai tersebut tidak mempunyai selisih yang tidak terlalu jauh. Sehingga dapat ditarik kesimpulan bahwa metode Trust-Aware dapat digunakan pada sistem rekomendasi buku dan tidak terpengaruh oleh jumlah buku yang digunakan.  
 
Kata kunci:  sistem rekomendasi, collaborative filtering, pagerank, trust-aware  
 
1. Pendahuluan  
Sistem rekomendasi adalah salah satu fitur pada sebuah perangkat lunak yang sangat bermanfaat untuk memudahkan pengguna. Sistem rekomendasi sendiri sangat diperlukan 
dikarenakan terlalu banyaknya jenis dan jumlah data yang ada. Dengan adanya sistem rekomen dasi, pengguna akan dimanjakan dengan rekomendasi â€“ rekomendasi buku yang sesuai dengan preferensi masing â€“ masing pengguna, sehingga pengguna tidak perlu repot melakukan pencarian buku yang diinginkan. Sistem rekomendasi sendiri harus dapat menganalisis sekian banyak data tentang pengguna dan buku yang tersedia, dapat juga didukung dengan data rating  agar hasil yang diberikan lebih akurat. Teknik untuk sebuah sistem rekomendasi pada buku yang telah ada adalah Collaborative Filtering (CF) . Secara khusus, si stem rekomendasi  yang berbasis CF mengandalkan rating yang 
diberikan oleh pengguna lain. Pada dasarnya CF mencoba untuk secara otomatis menemukan pengguna yang mirip dengan yang aktif dan merekomendasikan kepadanya item yang disukai oleh 
pengguna serupa ini. Intuisi sederhana ini efektif dalam menghasilkan rekomendasi dan banyak digunakan. Namun sistem rekomendasi yang berbasis pada CF menderita beberapa kelemahan inheren yang bersifat intrinsik di proses menemukan pengguna serupa [1].  Untuk mengatasi kekurangan tersebut maka perlu dibuat metode hasil pengembangan metode CF sebelumnya, yaitu Trust-Aware. Metode ini dapat menganalisis pengguna baru tersebut dengan menggunakan data dari lingkaran pertemanannya sehingga sistem dapat memberikan rekomendasi yang lebih akurat dibanding metode pendahulunya. Metode ini juga dapat memilih diantara sekian banyak tem an yang dimiliki, teman yang mana yang akan dijadikan acuan untuk memberikan rekomendasi, hal itu didapat dari data trust antar sesama pengguna. Teman yang mempunyai tingkat trust paling tinggi mempunyai kemungkinan lebih besar akan digunakan sebagai acuan  daripada teman yang lainnya  [1]. Metode ini pernah digunakan sebelumnya pada sosial media  [2].  
 
2. Tinjauan Pustaka  
2.1  Sistem Rekomendasi  
Sistem rekomendasi dapat didefinisikan sebagai program yang mencoba untuk merekomendasikan item yang paling cocok (produk atau jasa) untuk pengguna tertentu (individu atau bisnis) dengan memprediksi minat pengguna di item berdasarkan informasi terkait tentang item, pengguna dan interaksi antara item dan pengguna. Tujuan dari pengembangan sistem rekomendasi adalah untuk mengurangi informasi yang berlebihan dengan mengambil informasi dan layanan yang paling relevan dari sejumlah besar data, sehingga memberikan layanan pribadi. Fitur yang paling penting  dari sebuah sistem rekomendasi adalah kemampuannya untuk â€œmenebakâ€ preferensi dan kepentingan pengguna dengan menganalisis perilaku pengguna dan / atau perilaku pengguna lain untuk menghasilkan rekomendasi pribadi  [3]. Saran te rhadap buku pada Amazon adalah contoh dunia nyata dari operasi sebuah industri yang mementingkan sebuah sistem rekomendasi  [4].  Ekspektasi dari sebuah sistem rekomendasi ada memberikan rekomendasi dan estimasi yang bagus ( accu racy), memprediksi rating  buku  (coverage ), merekomendasikan buku baru (novelty ), merekomendasikan buku  yang berbeda ( diversity ), tidak terjadi perubahan rekomendasi yang banyak dalam waktu yang singkat ( stabillity ), dan tidak terpengaruh oleh serangan (resistance to attacks ) [5]. Tantangan utama sebuah sistem rekomendasi adalah:  
#NAME?
berkali-kali. Hal ini membuat lebih sulit untuk menghitung kesamaan.  
#NAME?
dapat menyebabkan ia mendapatkan hasil yang tidak akurat. Hal ini mungkin terjadi karena pengguna lain yang memiliki kemiripan dengan pengguna ini tidak dapat ditemukan  
#NAME?
rating  yang cukup, yang menyebabkan tidak direkomendasikan kepada pengguna.   
- Attacks : Sistem rekomendasi memiliki ancaman terhadap serangan, seperti menyalin keseluruhan profil pengguna dan membuat sistem berpikir bahwa si penyerang dan pengguna tersebut sangat mirip. Hal ini membuat penyerang dapat membodohi sistem dan membuatnya menyara nkan item apapun yang di rating  oleh penyerang kepada pengguna  [5].  
2.1.1  Collaborative Filtering  
Collaborative Filtering (CF) adalah salah satu teknik rekomendasi yang popular yang prediksi dan rekomendasinya berbasis pada nilai rating  atau tingkah laku dari pengguna lain dalam sistem tersebut. Anggapan mendasar pada metode ini adalah opini pengguna lain dapat dipilih dan diagregasikan untuk memberikan prediksi dari preferensi pengguna aktif. Intinya, diasumsikan bahwa apabila beberapa pengguna mempunyai minat yang sama terhadap suatu buku, maka besar kemungkinan mereka mempunyai minat yang sama juga untuk buku yang lain [6]. Teknik ini telah banyak digunakan pada berbagai aplikasi, contohnya adalah MovieLens [7], Netnews  [8], dan pada Amazon.com [9]. Kelebihan teknik CF  memungkinkan pengguna aktif untuk mendapatkan rekomendasi berdasarkan produk yang pengguna dengan minat yang sama telah membeli dan diberi nilai positif, dan dengan menggunakan peringkat sebelumnya pengguna aktif dan riwayat transaksi untuk membangun model yang menyediakan satu set baru produk serupa [10]. Namun kekurangan pada teknik ini adalah penggunanya tidak bisa memilih pengguna mana yang ingin dijadikan acuan agar mendapatkan rekomendasi produk yang diinginkan.  
2.1.2  Content-based Recommendation  
Teknik Content-based  Recommendation  (CB) merekomendasikan artikel atau komoditas yang mirip dengan item yang sebelumnya disukai oleh pengguna tertentu. Prinsip-prinsip dasar dari sistem rekomendasi Content-based  adalah: 1) Untuk menganalisis deskripsi item disukai oleh pengguna tertentu untuk menentukan atribut umum pokok (preferensi) yang dapat digunakan untuk membedakan barang-barang tersebut. preferensi ini disimpan dalam profil pengguna. 2) 
Untuk membandingkan atribut masing-masing item dengan profil pengguna sehingga hanya item yang memiliki tingkat kesamaan yang tinggi dengan profil pengguna akan direkomendasikan [3]. Penerapan teknik Content -based  telah banyak digunakan, beberapa contohnya ada lah untuk melakukan spam filtering  pada email [11], fitur filtering pada berbagai On-Line Social Networks  [12], dan bahkan untuk spam filtering  pada fitur SMS [13]. Penerapan teknik Content-based  ini pernah digunakan pada buku sebelumnya  [14]. 
Tahapan yang terjadi adalah: 1) Mengekstrak informasi dan membangun database . 2) Mempelajari profile. 3) Memproduksi, menjelaskan, dan me-revisi rek omendasi. Dari ke-tiga tahapan diatas, didapatkan hasil eksperimen berupa: 1) Metodologi yang berupa koleksi data, evaluasi performansi, dan diskusi metodologis. 2) Hasil dasar. 3) Hasil dari peran Collaborative Content [14]. Teknik Content-based ini mempunyai kelebihan yaitu dapat menganalisis produk dan menemukan kemiripan dengan pengguna aktif untuk merekomendasikan produk. Tidak seperti CF, teknik ini tidak memerlukan database  aktif dari riwayat pembelian [10]. Namun kekurangan pada teknik ini adalah ketidakmampuan menangani pengguna baru yang sistem tidak memiliki informasi apa â€“ apa terhadap pengguna baru tersebut, atau yang biasa dikenal dengan cold start.
2.2  Trust-Aware  Recommendation  
Beberapa teknik diatas adalah pendekatan yang paling tua dan banyak digunakan pada sistem rekomendasi. Namun seiring berjalannya waktu, teknik â€“ teknik tersebut mulai â€œusangâ€ dan berbagai kekurangannya membuat kurang dapat diaplikasikan pa da sistem rekomendasi yang ada pada hari ini. Sehingga perlu dibuat teknik â€“ teknik baru yang berlandaskan teknik pendahulunya yang lebih efektif dan dapat mengatasi kekurangan â€“ kekurangan yang ada. Salah satu teknik baru tersebut adalah Trust-Aware Recom mendation.  Di dalam lingkungan desentralisasi dimana semua orang bebas untuk membuat konten dan tidak ada entitas quality control  yang terpusat, mengevaluasi kualitas dari konten â€“ konten ini menjadi hal yang penting. Situasi ini dapat dilihat pada komunit as online  (contohnya, pada Slashdot.org dimana berjuta â€“ juta pengguna dapat menerbitkan berita dan komen setiap hari), dalam jaringan peer-to-peer ( dimana anggotanya dapat memasukkan corrupted item) , atau pada website berbelanja online  (seperti eBay.com, dimana para pengguna dapat membuat lelang palsu). Pada lingkungan â€“ lingkungan ini, adalah sebuah strategis yang bagus untuk melimpahkan tugas penilaian kualitas kepada pengguna â€“ pengguna nya sendiri. Sistem dapat menanyakan pengguna â€“ penggunanya untuk me-rating  pengguna lain: dengan cara ini, seorang penggua dapat mengekspresikan tingkat kepercayaannya kepada pengguna lain yang ia sedang berinteraksi. Contohnya pada sebuah kalimat kepercayaan adalah â€œSaya, Alice, mempercayai Bob dengan skala 0.8â€. sistem  kemudian dapat mengagregasikan semua kalimat kepercayaan ke sebuah jaringan kepercayaan tunggal yang merepresentasikan hubungan / relasi antara sesama pengguna [2]. Metode ini dapat mengatasi kelemahan pada metode- sebelumnya  yaitu cold start, karena metode ini dapat melihat sebuah kesamaan preferensi dari user baru dengan user lama dengan  melihat lingkaran pertemanan user baru tersebut, sehingga sistem dapat memberikan rekomendasi yang lebih akurat. Metode ini mempunyai arsitektur sebagai berikut [1]: Berdasarkan gambar di atas, dapat dijelaskan tahapan proses pada metode ini:  
- Trust Metric:  
Modul Trust Metric  berperan sebagai inputan dari jaringan trust dan mengeksploitasi propagasi untuk memprediksi, untuk setiap pengguna, seberapa banyak seorang pengguna bisa percaya dengan pengguna lain. Modul ini nantinya akan menghasilkan Estimated Trust  Matrix [15].  
- Similarity Metric:  
Mengkomputasi tingkat kemiripan dari seorang pengguna dengan setiap pengguna lain adalah salah satu langkah dasar dalam teknik CF. Tugasnya adalah mengkomputasi korelasi antara 2 pengguna, dan menghasilkan outputan berupa n x n matriks User Similarity yang pada kolom ke -i menganduk nilai similarity  dari pengguna ke -i dengan setiap pengguna lain. Nilai korelasi digunakan pada tahap berikutnya sabagai 
pertimbangan untuk rating  pengguna, berdasarkan hal itu, jika seorang pengguna A me-rating  barang mirip dengan pengguna B, maka rating  pengguna A berguna untuk memprediksi rating  dari pengguna B [15]. 
- Rating P rediction:  
Gambar 1 Arsitektur Trust Aware  
Tahap ini adalah langkah terakhir yang klasik dari CF. Prediksi rating  dari pengguna saat ini adalah jumlah dari rating  yang diberikan ke item i oleh tetangga a. Tetangga dapat diambil dari matriks User Similarity  atau dari matriks Estimated Trust  dan weights   adalah sel pada matriks yang dituju.  
2.3  PageRank  
PageRank adalah salah satu metode global trust metric  yang paling banyak digunakan  [1]. PageRank  adalah metode yang dapat menghubungkan 1 item ke item lain. PageRank dapat digambarkan seperti sebuah node  yang terhubung dengan node  lain melalui arrow, dimana arah arrow dapat menun jukkan keterkaitan sebuah node terhadap node lain, dimana dalam contoh kasus buku bisa saja sebuah node  tersebut mengutip dari node lain [16]. Namun terdapat batasan dalam pengerjaan Tugas Akhir ini. Dikarenakan Tugas Akhir ini  berbasis desktop  jadi untuk penerapan PageRank  menggunakan pendekatan yang sedikit berbeda. Ketika pengguna ditampilkan daftar buku terdapat tombol â€œShow Synopsisâ€ , dimana nilai trust akan bertambah setiap pengguna melakukan klik pada tombol Show Synopsis  tersebut.  

3. Desain Sistem  
3.1  Gambaran Umum Sistem  
Sistem ini dibangun dengan mengikuti alur sebagai berikut:    
Gambar 2 Contoh PageRank  dalam sebuah grafik [16] 
Gambar 3 Flowchart Gambaran Umum Sistem  
Berikut penjelasan alur sistem berdasarkan Gambar 3:  
- Dataset: Sistem menerima inputan dataset . 
#NAME?
filtering  
#NAME?
yang melakukan show synopsis  pada setiap buku  
- Trust-Aware : Sistem menjalankan algoritma Rating  Predictor . 
#NAME?
berdasarkan hasil perhitungan Trust-Aware  
3.2  Dataset  
Dataset yang digunakan pada Tugas Akhir ini adalah data buku, rating , pengguna yang telah terdaftar dan asal pengguna. Dataset buku didapat dari Book -Crossing (http://www2.informatik.uni -freiburg.de/~cziegler/BX/ ). Jumlah buku yang digunakan sebanyak 100 dari 271,379 buku yang disediakan. Hal ini dikarenakan waktu untuk memproses buku lebih dari 100 akan memakan waktu yang sangat lama, termasuk untuk membaca data maupun untuk memproses data buku beserta rating  nya. 
3.2.1  Book-Crossing   
Dataset Book -Crossing memberikan 3 jenis data, yaitu dataset  buku, pengguna dan rating , namun yang digunakan hanya dataset buku saja karena dataset user yang diberikan berisi userdengan alamat yang berada di luar negeri. Dataset buku tersebut mempunyai format csv  (comma-separated values).  Data buku tersebut mempunyai 8 atribut, yaitu ISBN, Book -Title, Book -Author, Year -of-Publication, Publisher, Image -URL -S, Image -URL -M, Image -URL -L. 
Table 1 contoh format dan isi data buku  
ISBNS""""0399135782Group"""" es.amazon.com/images/P/0399135782.01.MZZZZZZZ.jpg""""
s/P/0399135782.01.LZZZZZZZ.jpg""""  
0609804618 America's Finest News Source""""
Press"""" s.amazon.com/images/P/0609804618.01.MZZZZZZZ.jpg"""" /P/0609804618.01.LZZZZZZZ.jpg""""  
Untuk melengkapi data yang tidak disediakan oleh Book -Crossing maka perlu dibuat dataset lain seperti dataset user, region, survey page dan survey rating . 
Table 2 contoh format dan isi data user  
id_user
1
11
Table 3 contoh format dan isi data region  
id_region
1107
1871
Table 4 contoh format dan isi data survey page  
id
16
36
Table 5 contoh format dan isi data survey rating  
id
21
72
3.3.1  Pure Collaborative Filtering  
Untuk penerapan CF menggunakan teknik yang banyak digunakan yaitu Pearson Correlation Coefficient  [15].  
ð‘¤ð‘Ž,ð‘¢= âˆ‘ (ð‘Ÿð‘Ž,ð‘–âˆ’ ð‘ŸÌ…ð‘Ž)(ð‘Ÿð‘¢,ð‘–âˆ’ ð‘ŸÌ…ð‘¢)ð‘š
ð‘–=1
âˆšâˆ‘ (ð‘Ÿð‘Ž,ð‘–âˆ’ ð‘ŸÌ…ð‘Ž)2 ð‘š
ð‘–=1  âˆ‘ (ð‘Ÿð‘¢,ð‘–âˆ’ ð‘ŸÌ…ð‘¢)2 ð‘š
ð‘–=1   (3-1) 
Keterangan:  
ð‘¤ð‘Ž,ð‘¢ : Nilai user similarity . 
ð‘ŸÌ…ð‘Ž,ð‘– : Rating  user a terhadap item i . 
ð‘ŸÌ…ð‘Ž : Rata â€“ rata rating oleh user a. 
ð‘ŸÌ…ð‘¢,ð‘– : Rating  tetangga user a terhadap item i . 
ð‘ŸÌ…ð‘¢ : Rata â€“ rata rating tetangga user a terhadap item i.  
m : Jumlah user yang memberi rating  terhadap item i . 
3.3.2  PageRank  
Algoritma PageRank  oleh Google didesain untuk memproses jaringan link seperti yang ditunjukkan pada Gambar 2. Kunci utama algoritma nya ditunjukkan pada rumus berikut  [16]: 
Keterangan:  
PageRank(A)  : menunjukkann nilai dari Page(A)  
d  : Damping Factor  yang bernilai antara 0 sampai 1, biasanya 0.85  
Pi  : 1 dari n page  yang memberikan link menuju Page(A)  
O(Pi)   : outdegree dari Page(Pi) yang berada dalam jaringan link tersebut 
3.4  Trust-Aware  
Tahap berikutnya adalah melakukan perhitungan menggunakan Rating Predictor. Tahap ini adalah langkah klasik terakhir dari CF [1].   
ð‘ð‘Ž,ð‘–= ð‘ŸÌ…ð‘Ž+ âˆ‘ ð‘¤ð‘Ž,ð‘¢ð‘˜
ð‘¢=1 (ð‘Ÿð‘¢,ð‘–âˆ’ ð‘ŸÌ…ð‘¢)
âˆ‘ ð‘¤ð‘Ž,ð‘¢ð‘˜
ð‘¢=1 (3-3) 
Keterangan:  
ð‘ð‘Ž,ð‘–   : Prediksi rating  terhadap item i . 
ð‘ŸÌ…ð‘Ž : Rata â€“ rata rating oleh user a  
ð‘ŸÌ…ð‘¢     : Rata â€“ rata dari rating  yang diberikan oleh user u. 
ð‘Ÿð‘¢,ð‘–     : Rating oleh user u terhadap item i .  
ð‘¤ð‘Ž,ð‘¢ : Bobot dari user similarity dari a dan u yang telah dihitung pada tahap sebelumnya.  
k : Jumlah user yang melakukan rating terhadap item i . 
 
4. Pengujian dan Analisis  
4.1  Strategi Pengujian  
Tujuan dari sistem yang dibangun adalah memberikan daftar buku dari yang paling direkomendasikan kepada user sampai yang paling tidak direkomendasikan. Sebuah buku dianggap menarik apabila hasil prediksi rating  bernilai tinggi berdasarkan penggabungan PageRank dan CF. Pengujian sistem dilakukan dengan menggunakan evaluation metrics  yaitu Mean Absolute Error (MAE) . Pengujian ini dipengaruhi oleh jumlah buku, rating  dan user, dengan variabel jumlah buku yang bisa diubah.   
ð‘ƒð‘Žð‘”ð‘’ð‘…ð‘Žð‘›ð‘˜ (ð´)=1âˆ’ð‘‘+ð‘‘ Ã— âˆ‘ð‘ƒð‘Žð‘”ð‘’ð‘…ð‘Žð‘›ð‘˜ (ð‘ƒð‘–)
ð‘‚(ð‘ƒð‘–)ð‘›
ð‘–=1 (3-2)  
4.2  Skenario Pengujian   
ð‘€ð´ð¸ = 1
ð‘›âˆ‘ |ð‘›
ð‘–=1ð‘“ð‘–âˆ’ ð‘¦ð‘–| (4-1) 
Berdasarkan rumus MAE, skenario pengujian dilakukan sebagai berikut:  
Table 6 skenario pengujian  
No Pengujian  Keterangan  
1 MAE dengan data rating TA dan data CF  Data rating TA: fi 
Data rating CF: yi Jumlah buku yg digunakan: 101 
2 MAE dengan data rating TA dan data CF  Data rating TA: fi 
Data rating CF: yi Jumlah buku yg digunakan: 51  
3 MAE dengan data rating TA dan data CF  Data rating TA: fi 
Data rating CF: yi Jumlah buku yg digunakan: 11  
4.3  Analisis Hasil Pengujian  
Berikut ditampilkan statistik dari data rating  dan klik pada show synopsis dan yang didapatkan:  
Table 7 statistik rating  
Rating  Jumlah rating  
1 62 
2 109 
3 143 
4 185 
5 92 
Table 8 statistik klik show synopsis  
ID Buku  Jumlah Klik Show Synopsis  
1 â€“ 20 228 
21 â€“ 40 250 
41 â€“ 60 261 
61 â€“ 80 224 
81 â€“ 101 205  
Hasil dari setiap pengujian ditampilkan sebagai berikut:  
Table 9 tabel pengujian  
Nomor Pengujian  Total Rating 
(TA)  Total Rating 
(CF)  Jumlah 
buku  Jumlah 
User  MAE  
(skala 5)  
1 180 308 101 20 1.267  
2 92 158 51 20 1.294  
3 19 32 11 20 1.181   
Pada Table 9, terlihat bahwa pada semua hasil pengujian mendapatkan nilai dengan perbedaan yang tidak terlalu jauh. Hal ini menunjukkan bahwa jumlah buku tidak berpengaruh terlalu besar pada hasil akhir rekomendasi. Maka dapat disimpulkan metode Trust-Aware  ini mempun yai nilai akurasi yang cukup stabil terhadap berapapun jumlah buku yang digunakan.  
 
5. Kesimpulan dan Saran  
5.1  Kesimpulan  
Berdasarkan hasil pengujian dan analisis yang telah dilakukan, dapat ditarik beberapa kesimpulan, yaitu Sistem rekomendasi yang menggunakan metode Trust-Aware  dapat memberikan rekomendasi yang cukup akurat dengan memberikan nilai MAE 1,267 pada 101 buku, 1,294 pada 51 buku dan 1, 181 pada 11 buku dan tidak terpengaruh terhadap berapapun jumlah buku yang digunakan.  
5.2  Saran  
Terdapat beberapa saran yang dapat dijadikan pertimbangan untuk pengembangan penelitian selanjutnya adalah sebagai berikut:  
1. Penelitian  pada Tugas Akhir ini hanya dilakukan secara offline sehingga belum bisa sepenuhnya merepresentasikan kemampuan maksimal dari setiap unsur pada sistem rekomendasi yang dibangun, maka untuk penelitian selanjutnya dapat dilakukan secara online untuk dapat memberikan hasil evaluasi yang lebih optimal.  
2. Penerapan metode ini sebaiknya dilakukan ketika riset terhadap metode ini sendiri telah sempurna sehingga dapat memberikan hasil rekomendasi yang jauh lebih akurat.  
 
Daftar Pustaka   
[1]  P. A. Paolo Massa, â€œTrust-aware Recommender Systems,â€ Trust -aware Recommender Systems, pp. 17 -24, 2007.  
[2]  M. N. R. D. G. Na Li, â€œTrust -aware Privacy Control for Social Media,â€ Human Factors in Computing System, pp. 1597 -1602, 2011.  
[3]  D. W. M. M. W. W. G. Z. Jie Lu, â€œRecommender System Application Developments: A Survey,â€ pp. 1 -30, 2015.  
[4]  V. S. Prem Melville, â€œRecommender System,â€ Encyclopedia of Machine Learning, pp. 829-837, 2010.  
[5]  F. P. Makbule Gulcin Ozsoy, â€œTrust Based Recommendati on Systems,â€ Advances in SOsial Networks Analysis and Mining, pp. 1 -8, 2013.  
[6]  J. T. R. J. A. K. Michael D. Ekstrand, â€œCollaborative Filtering Recommender Systems,â€ Foundations and TrendsÂ® in Human-Computer Interaction, pp. 175 -243, 2011.  ISSN : 2355-9365 e-Proceeding of Engineering : Vol.4, No.3 Desember 2017 | Page 4976 
[7]  J. A. K. J. R. Jonathan L. Herlocker, â€œExplaining Collaborative Filtering Recommendations,â€ Proceedings of the 2000 ACM conference on Computer supported cooperative work, pp. 241 -250, 2000.  
[8]  N. I. M. S. P. B. J. R. Paul Resnick, â€œGroupLens: An Open A rchitecture for Collaborative Filtering of Netnews,â€ Proceedings of the 1994 ACM conference on Computer supported cooperative work, pp. 175 -186, 1994.  
[9]  B. S. J. Y. Greg Linden, â€œAmazon.com recommendations: Item-to-item collaborative filtering,â€ IEEE Internet Computing, pp. 76 -80, 2003.  
[10]  A. S. H. R. A. M. M. Sanjeevan Sivalapan, â€œRecommender Systems in E -Commerce,â€ pp. 
1-6, 2014.  
[11]  A. Y. Tiago A. Almeida, â€œContent-Based Spam Filtering,â€ Proceedings of the International Joint Conference on Neural Networks, pp. 1 -7, 2010.  
[12]  E. B. B. C. M. C. E. F. Marco Vanetti, â€œContent -Based Filtering in On -Line SOcial 
Networks,â€ Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), pp. 127 -140, 2011.  
[13]  G. C. B. E. P. S. Jose Maria Gomez Hidalgo, â€œContent Based SMS Spam Filtering,â€ Proc. of the 2006 DOCENG, pp. 107-114, 2016.  
[14]  L. R. Raymond J. Mooney, â€œContent -Based Book Recommending Using Learning for Text Categorization,â€ Pro- ceedings of the Fifth ACMConference on Digital Libraries, pp. 195-204, 2000.  
[15]  P. A. Paolo Massa, â€œTrust -aware Collaborative Filtering for Recomme nder Systems,â€ On the Move to Meaningful Internet Systems 2004: CoopIS, DOA, and ODBASE, pp. 492-508, 2004.  
[16]  P. W. Jiang Li, â€œArticleRank: a PageRank -based alternative to numbers of citations for analysing citation networks,â€ Emerald Insight, 2009.",sistem rekomendasi,"trust-aware recomendation, collaborative filtering, conten-based recommendation",dataset book-crossing,MAE
Sistem Rekomendasi Film Menggunakan Content Based Filtering,"Sistem Rekomendasi Film Menggunakan Content Based Filtering

Muhammad Fajriansyah1, Putra Pandu Adikara2, Agus Wahyu Widodo3 

Abstrak  
Pertumbuhan banyaknya penonton bioskop yang meningkat selaras dengan banyaknya jumlah film yang diproduksi. Berbagai film dengan alur cerita, genre, dan tema film yang serupa ataupun berbeda-beda meramaikan pasar industri dari bidang perfilman di luar negeri hingga dalam negeri. Dari banyaknya film yang diproduksi membuat calon penonton bingung dan kesulitan untuk mencari dan 
menentukan film apa yang akan ditonton selanjutnya sehingga menghabiskan waktu lebih banyak dalam mencari film. Beberapa orang menggu nakan fitur yang disediakan di beberapa situs untuk mencari film untuk memutuskan film yang akan ditonton. Setiap orang memiliki selera yang berbeda-beda dan cenderung memilih menonton film yang serupa dengan film yang disukainya. Salah satu cara untuk men dapatkan informasi yang tepat terhadap film adalah dengan sistem rekomendasi. Setiap film memiliki beberapa informasi berupa genre film dan sinopsis film yang berbeda-beda. Pada penelitian 
ini untuk mendapatkan hasil rekomendasi menggunakan algoritme content based  filtering  dengan mencari kemiripan bobot dari term pada bag of words  hasil pre-processing  sinopsis film dan judul film. Pembobotan dilakukan menggunakan metode TF-IDF yang telah dinormalisasi. Kemudian hasil pembobotan akan melalui tahap cosine  similarity  untuk mencari kemiripan berdasarkan bobot dan diakhiri dengan filtering  berdasarkan genre. Hasil pengujian yang dilakukan pada penelitian dengan melibatkan tiga partisipan dengan total jumlah film sebanyak 4000 judul film didapatkan nilai akurasi menggunakan mean average precision  @K (MAP@K) sebesar 0.823254 untuk jenis kueri single kueri dan 0.7500556 untuk jenis kueri multiple seeds kueri. Dari hasil tersebut didapatkan untuk jenis kueri single  kueri menghasilkan rekomendasi yang lebih baik darip ada jenis kueri multiple  seeds  kueri.  

Kata kunci : film, sistem rekomendasi, content based filtering, TF -IDF, cosine similarity, MAP@K  

Abstract  
The growth in the number of cinema audiences is increasing in line with the large number of films being produced . Various films with plot stories, genres, and film themes that are similar or different have enlivened the industrial market from overseas to domestic film. Of the many films produced, it makes potential viewers confused and difficult to find and determin e what film to watch next so that they spend more time looking for films. Some people use the features provided on some sites to search for movies to decide which movie to watch. Everyone has different tastes and tends to choose to watch movies that are similar to the movies he likes. One way to get the right information about a film is a recommendation system. Each film has some information in the form of different genre films and synopsis films. In this study, to obtain the recommendation results using a content based filtering algorithm by looking for the similarity in weight of the terms in the bag of words result of pre-processing film synopsis and film title. The weighting is carried out using the TF -IDF method which 
has been normalized. Then the weigh ting results will go through the cosine similarity stage to look for similarities based on weights and end with filtering based on genre. Based on the results of tests carried out by involving three participants with a total number of films as many as 4000  film titles, the accuracy value is obtained using the mean average precision @K (MAP @ K) is 0.823254 for the single query type and 0.7500556 for the multiple seed query type. From these results, it is found that the single query type produces better recommendations than the multiple seed query type.  

Keywords : film, recommendation system, content based filtering, TF -IDF, cosine similarity, MAP@K  
 
1. PENDAHULUAN  
Pertumbuhan pasar  industri dari bidang perfilman di luar negeri hingga dalam negeri Jurnal Pengembangan Teknologi Informasi dan Ilmu Komputer  2189  Fakultas Ilmu Komputer, Universitas Brawijaya  kian menjanjikan. Dilihat dari banyaknya jumlah penonton bioskop yang terus meningkat dari tahun ke tahun. Per 2018 angka jumlah penonton bioskop di Indonesia saja telah mencapai lebih dari  50 juta penonton dengan jumlah produksi film luar negeri hingga dalam negeri sebanyak hampir 200 judul film yang telah tayang di seluruh Indonesia  (Tren Positif Film Indonesia | Indonesia.go.id, 2019).  Dari sekian banyaknya film yang diproduksi membuat calon penonton kesulitan dalam menentukan film yang akan ditontonnya. Untuk mencari film tentunya akan memakan waktu, selain itu film yang sudah ditentukan untuk ditonton belum tentu sesuai dengan keinginan calon penonton setelah menontonnya, sehingga akan menghabiskan waktu lebih banyak lagi. Menonton film melalui bioskop, platform penyedia layanan streaming, maupun penyewaan dan pembelian kaset DVD juga diperlukan biaya, akan terbuang sia-sia apabila film yang ditonton tidak sesuai keinginan.   Mereka yang kesulitan untuk memilih menonton film apa memutuskan untuk mengunjungi beberapa situs seperti suggestmemovie.com yang memberikan saran film kepada pengguna atau situs StayIn app yang memberikan kuesioner secara umum untuk mencari tahu suasana hati pengunjung situs dengan beberapa pertanyaan. Dari semua solusi berikut pengunjung situs mengaku terkadang harus mencoba beberapa kali untuk mendapat film yang dianggap bagus (Mihir, 2019). Pada salah satu platform penyedia layanan streaming  digital terbesar saat ini, Netflix sering kali membuat kebingungan penggunanya karena banyaknya pilihan film atau serial yang bisa ditonton. Hal ini mendorong Netflix untuk mengeluarkan fitur untuk menjadi solusi permasalahan berikut yang disebut dengan shuffle  play yang akan memutar film atau serial yang dipilihkan oleh 
sistem (Putri, 2020).  Terdapat penelitian untuk mendapatkan 
suatu rekomendasi produk oleh (Shrivastava and Sisodia, 2019). Penelitian tersebut menggunakan nama produk berbahasa Inggris sebagai kueri pada suatu pro duk dan data uji pada produk lainnya kemudian dicari kemiripannya antar keduanya. Dengan menggunakan Teknik bag of word, nama produk akan diubah ke matriks yang menyimpan kata unik dalam bentuk term berserta jumlahnya. Kata unik tersebut diberi bobot dengan metode pembobotan TF-IDF. Kemiripan antar produk didapat dengan menghitung jarak masing-masing bobot. Hasil dari menghitung kemiripan dari semua produk akan dilakukan pemeringkatan sesuai dengan jarak terkecil ke terbesar.  Dalam mencari kemiripan dapat menggunakan metode cosine  similarity  yang digunakan dalam penelitian sistem temu kembali buku berbahasa Arab yang ditulis oleh (Fauzi, Arifin and Yuniarti, 2017). Dengan memadukan frekuensi kata, inverse  frekuensi dokumen, inverse  frekuensi kelas, dan inverse  frekuensi buku yang menjadi nilai hitung pembobotan term. Hasil pembobotan akan dicari kemiripannya pada setiap dokumen menggunakan metode cosine  similarity . Untuk lebih mendukung hasil sistem dapat menggunakan metode multiple  seed kueri  seperti yang digunakan pada penelitian pembuatan playlist  lagu otomatis oleh (Platt, 2007). Dengan menghitung kemiripan dari banyak lagu (multiple seed), sistem akan membuat secara otomatis playlist  dengan memasukkan lagu yang dianggap memiliki kesamaan antara satu lagu dengan lagu lainnya dan membuang lagu yang dianggap tidak sama dengan lagu lainnya. Hasil sistem merupakan kumpulan lagu yang memiliki kemiripan satu sama lain yang lebih tinggi daripada lagu yang tidak ada di playlist . Dari penelitian-penelitian beri kut penulis ingin meneliti sistem rekomendasi untuk data film dengan mendeteksi kemiripan dari suatu film yang telah ditonton dengan film-film lainnya menggunakan data sinopsis dan judul film tersebut maka dapat diurutkan berdasarkan peringkat film-film yang paling mirip dengan film yang telah ditonton dan akan dijadikan rekomendasi film yang akan ditonton selanjutnya. Sehingga tidak perlu lagi menghabiskan waktu dengan mencari film satu persatu. Selain itu dengan sistem rekomendasi juga penonton tidak akan  terpaku untuk hanya menonton film yang sedang tayang di bioskop saja namun juga hasil rekomendasi dapat berupa film-film yang tersedia di tempat penyewaan atau pembelian dalam bentuk lain seperti kaset atau platform penyedia layanan streaming  yang tidak sedang tayang di bioskop, sehingga industri yang bekerja dalam film tersebut mendapatkan hasil penjualan.  Berdasarkan masalah yang telah dijelaskan sebelumnya, penulis mengajukan penelitian dengan judul â€œSistem Rekomendasi Film Menggunakan Content  Based  Filtering â€. Jurnal Pengembangan Teknologi Informasi dan Ilmu Komputer  2190  Fakultas Ilmu Komputer, Universitas Brawijaya  Dengan memanfaatkan fitur sinopsis dan judul film yang diberi nilai bobot dengan metode pembobotan TF-IDF. Hasil pembobotan akan dicari kemiripannya menggunakan metode cosine  similarity  dengan menghitung kemiripan fitur pada antara kueri film dengan fitur pada film lainnya. Penghitungan akan diakhiri dengan filtering  genre terhadap genre kueri. Hasil sistem juga akan didukung dengan fitur multiple  seeds  kueri.  

2. KAJIAN PUSTAKA  
2.1 Sistem Rekomendasi  
Sistem rekomendasi merupakan program atau sistem penyaringan informasi yang menjadi solusi dalam masalah kelebihan informasi dengan cara menyaring sebagian informasi penting dari banyaknya informasi yang ada dan bersifat dinamis sesuai dengan preferensi, minat, atau perilaku pengguna terhadap suatu barang. Sistem rekomendasi  dirancang untuk memahami dan memprediksi preferensi pengguna berdasarkan perilaku pengguna (Rao, 2019).Sistem rekomendasi diharuskan memiliki kemampuan untuk memprediksi apakah pengguna tertentu akan memilih barang yang berdasarkan preferensi, minat, perilaku pengguna, atau pengguna lainnya. Sistem rekomendasi dapat membantu dalam mengambil keputusan di dalam informasi yang kompleks dan banyak secara obyektif. 
Terdapat beberapa metode yang dapat digunakan dalam membangun sebuah sistem rekomendasi antara lain content  based  filtering , collaborative  filtering , hybrid  filtering , dan lain sebagainya (Isinkaye, Folajimi and Ojokoh, 2015).  Terdapat dua metode pendekatan pada sistem rekomendasi tes (Isinkaye, Folajimi and Ojokoh, 2015):  
a. Content  Based  Filtering  
Menggunakan kemiripan antar produk yang akan direkomendasikan dengan produk yang disukai pengguna.  
b. Collaborative Filtering  
Menggunakan kemiripan kueri dengan item pengguna dengan peng guna lain.  
2.2 Content  Based  Filtering  
Content  Based  Filtering pada Sistem rekomendasi adalah metode yang mempertimbangkan perilaku dari pengguna dari masa lalu yang kemudian diidentifikasi pola perilakunya untuk merekomendasikan barang yang sesuai dengan pola perilaku tersebut (Reddy et al., 2019). Metode content  based  filtering  menganalisis preferensi dari perilaku pengguna dimasa lalu untuk membuat model. Model tersebut akan dicocokkan dengan serangkaian karakteristik atribut dari barang yang akan direkomendasikan. Barang dengan tingkat kecocokan tertinggi akan menjadi rekomendasi untuk pengguna.  
2.3 Pre-processing  
Pre-processing  merupakan tahap menyeleksi data mentah yang akan diproses di setiap dokumen meliputi tokenisasi, case folding , filtering , dan stemming  (INFORMATIKALOGI, 2016). Tujuan utama dari tahap ini adalah dapat merepresentasikan setiap dokumen menjadi fitur pada vektor dengan memisahkan kata yang menyusun suatu dokumen (Kadhim, 2018). Pada umumnya data tidak melalui seluruh metode pre-processing  yang ada. Melihat bagaimana karakteristik data itu sendiri, pemilihan  metode pre-processing  apa saja yang akan digunakan dapat berpengaruh pada kualitas data keluaran proses.  
2.3.1 Cleaning  
Cleaning  merupakan proses menghilangkan tanda baca karena tidak memengaruhi isi informasi dokumen. Contoh hasil cleaning  ditunjukkan pa da Tabel 1.  
Tabel 1 Contoh Hasil Proses Cleaning  Dokumen  
no Kalimat  Masukan  Hasil  
1 With the help of a German bounty hunter, a freed slave sets out to rescue his wife from a brutal Mississippi plantation owner.  With the help of a German bounty hunter  a freed slave sets out to rescue his wife from a brutal Mississippi plantation owner  
2 After being held captive in an Afghan cave, billionaire engineer Tony Stark creates a unique weaponized suit of armor to fight evil.  After being held captive in an Afghan cave billionaire engineer Tony Stark creates a unique weaponized suit of armor to fight evil  
3 When Tony Stark's world is torn apart by a formidable 
terrorist called the Mandarin, he starts an odyssey of rebuilding and retribution.  When Tony Starks world is torn apart by a formidable terrorist called the Mandarin he starts an odyssey of rebuilding and retribution  
2.3.2 Case  Folding  
Case  folding  merupakan proses mengonversi seluruh huruf kapital yang ada pada setiap kata menjadi huruf kecil dengan tujuan konsistensi data.  Contoh hasil case folding  ditunjukkan pada Tabel 2   
Tabel 2 Contoh Hasil Proses Case  Folding  Dokumen  
no Kalimat  Masukan  Hasil  
1 With the help of a German bounty hunter a freed slave sets out to rescue his wife from a brutal Mississippi plantation owner  with the help of a german bounty hunter a freed slave sets out to rescue his wife from a brutal mississippi plantation owner  
2 After being held captive in an Afghan cave billionaire engineer Tony Stark creates a unique weaponized suit of armor to fight evil  after being held captive in an afghan cave billionaire engineer tony stark creates a unique weaponized suit of armor  to fight evil  
3 When Tony Starks world is torn apart by a formidable terrorist called the Mandarin he starts an odyssey of rebuilding and retribution  when tony starks world is torn apart by a formidable terrorist called the mandarin he starts an odyssey of rebuilding and retribution  
2.3.3 Tokenisasi  
Tokenisasi merupakan proses memisahkan kata yang menyusun suatu dokumen dengan menggunakan tanda baca sebagai karakter pemisah kata ( delimiter ). Tanda baca, angka, dan karakter selain alfabet akan dihilangkan . Contoh dari hasil tokenisasi ditunjukkan pada Tabel 3.  
Tabel 3 Contoh Hasil Proses Tokenisasi Dokumen  
no Kalimat  Masukan  Hasil  
1 with the help of a german bounty hunter a freed slave sets out to rescue his wife from a brutal mississippi plantation owner  ['with', 'the', 'help', 'of', 'a', 'german', 'bounty', 'hunter', 'a', 'freed', 'slave', 'sets', 'out', 'to', 'rescue', 'his', 'wife', 'from', 'a', 'brutal', 'mississippi', 'plantation', 'owner' ] 
2 after being held captive in an afghan cave billionaire 
engineer tony stark creates a unique weaponized suit of armor to fight evil  ['after', 'being', 'held', 'captive', 'in', 'an', 'afghan', 'cave', 'billionaire', 'engineer', 'tony', 'stark', 'creates', 'a', 'unique', 'weaponized', 'suit', 'of', 'armor', 'to', 'fight', 'evil' ] 
3 when tony starks world is torn apart by a formidable terrorist called the mandarin he starts an odyssey of rebuilding and retribution  ['when', 'tony', 'starks', 'world', 'is', 'torn', 'apart', 'by', 'a', 'formidable', 'terrorist', ' called', 'the', 'mandarin', 'he', 'starts', 'an', 'odyssey', 'of', 'rebuilding', 'and', 'retribution' ] 
2.3.4 Lemmatization  
Lemmatization  merupakan proses mengembalikan kata menjadi bentuk kata dasarnya dengan menyesuaikan kata tersebut pada kamus/ wordnet  (vocabulary  dan morphological  analysis ) biasanya bertujuan untuk menghilangkan akhiran infleksional saja (Manning, Raghavan and Schutze, 2008). Metode ini sangat bagus untuk kata-kata yang bersifat perubahan tidak beraturan seperti kata dalam bahasa Inggr is. Contoh dari hasil lemmatization  ditunjukkan pada Tabel 4 .  
Tabel 4 Contoh Hasil Proses lemmatization  Dokumen  
no Kalimat  Masukan  Hasil  
1 ['with', 'the', 'help', 'of', 'a', 'german', 'bounty', 'hunter', 'a', 'freed', 'slave', 'sets', 'out', 'to', ' rescue', 'his', 'wife', 'from', 'a', 'brutal', 'mississippi', 'plantation', 'owner' ] ['with', 'the', 'help', 'of', 'a', 'german', 'bounty', 'hunter', 'a', 'freed', 'slave', 'set', 'out', 'to', 'rescue', 'his', 'wife', 'from', 'a', 'brutal', 'mississippi', 'plantation', 'owner' ] 
2 ['after', 'being', 'held', 'captive', 'in', 'an', 'afghan', 'cave', 'billionaire', 'engineer', 'tony', 'stark', 'creates', 'a', 'unique', 'weaponized', 'suit', 'of', 'armor', 'to', 'fight', 'evil' ] ['after', 'being', 'held', 'captive', 'in', 'an', 'afghan', 'cave', 'billionaire', 'engineer', 'tony', 'stark', 'creates', 'a', 'unique', 'weaponized', 'suit', 'of', 'armor', 'to', 'fight', 'evil' ] 
3 ['when', 'tony', 'starks', 'world', 'is', 'torn', 'apart', 'by', 'a', 'formidable', 'terrorist', 'called', 'the', 'mandarin', 'he', 'starts', 'an', 'odyssey', 'of', 
'rebuilding', 'and', 'retribution' ] ['when', 'tony', 
'starks', 'world', 'is', 'torn', 'apart', 'by', 'a', 'formidable', 'terrorist', 'called', 'the', 'mandarin',  'he', 'start',  'an','odyssey', 'of', 'rebuilding', 'and', 'retribution' ]  
Pada penelitian ini penulis menggunakan lemmatization  dari library  yang telah disediakan oleh Natural  Language  Toolkit  (NLTK) dalam bahasa python. Program dan cara penggunaan library  dapat dilihat melalui tautan berikut: 
http://www.nltk.org/api/nltk.stem.html?highlight=lemmatizer.  
2.3.5 Stopword  Removal  
Algoritme stopword  removal  atau biasa disebut stopword /stoplist  merupakan algoritme untuk menghapus kata -kata yang dianggap tidak dapat mewakili suatu dokumen (tidak deskriptif) dengan menggunakan pendekatan bag-of-word  dan minimal panjang kata 2 huruf. Pada penelitian ini penulis menggunakan stoplist  untuk Bahasa Inggris yang telah disusun oleh Natural  Language  Toolkit  (NLTK). Stoplist  ini berjumlah 127 kata yang harus dihapus. Contoh dari hasil stopword  removal ditunjukkan pada Tabel 5.  
Tabel 5 Contoh Hasil Proses Stopword  Removal  Dokumen  
no Kalimat  Masukan  Hasil  
1 ['with', 'the', 'help', 'of', 'a', 'german', 'bounty', 'hunter', 'a', 'freed', 'slave', 'set', 'out', 'to', 'rescue', 'his', 'wife', 'from', 'a', 'brutal', 'mississippi', 'plantation', 'owner' ] ['with', 'the', 'help', 'of', 'a', 'german', 'bounty', 'hunter', 'a', 'freed', 'slave', 'set', 'out', 'to', 'rescue', 'his', 'wife', 'from', 'a', 'brutal', 'mississippi', 'plantation', 'owner' ] 
2 ['after', 'being', 'held', 'captive', 'in', 'an', 'afghan', 'cave', 'billionaire', 'engineer', 'tony', 'stark', 'creates', 'a', 'unique', 'weaponized', 'suit', 'of', 'armor', 'to', 'fight', 'evil']  ['after', 'being', 'held', 'captive', 'in', 'an', 'afghan', 'cave', 'billionaire', 'engineer', 'tony', 'stark', 'creates', 'a', 'unique', 'weaponized', 'suit', 'of', 'armor', 'to', 'fight', 'evil' ] 
3 ['when', 'tony', 'starks', 'world', 'is ', 'torn', 'apart', 'by', 'a', 'formidable', 'terrorist', 'called', 'the', 'mandarin', 'he', 'start', 'an', 'odyssey', 'of', 'rebuilding', 'and', 'retribution' ] ['when', 'tony', 'starks', 'world', 'is', 'torn', 'apart', 'by', 'a', 'formidable', 'terrorist' , 'called', 'the', 'mandarin', 'he', 'start', 'an', 'odyssey', 'of', 'rebuilding', 'and', 
'retribution' ] 
2.4 Term  Weighting  
Pembobotan pada sistem rekomendasi kerap menggunakan metode vector  space  model  dalam memodelkan setiap dokumen yang merepresentasikan suatu barang yang akan menjadi kandidat rekomendasi, setiap dokumen direpresentasikan pada matriks yang berisi term dengan nilai bobotnya dan setiap nilai bobotnya menunjukkan nilai kepentingan term tersebut pada suatu dokumen (Fauzi, Arifin and Yuniarti, 2017). Terdapat beberapa metode pembobotan seperti term frequency , inverse  document  frequency , dan TF-IDF. Setiap dokumen akan terlebih dahulu melalui tahap pre-processing  untuk menyiapkan data mentah  untuk dilakukan pembobotan.  
2.4.1 Term  Frequency  
Term  frequency  merupakan salah satu metode pembobotan yang paling sederhana dalam memberi nilai bobot pada suatu term. Setiap term dianggap memiliki kepentingan pada suatu dokumen yang berbanding lurus dengan banyaknya kemunculan term pada dokumen tersebut (Fauzi, Arifin and Yuniarti, 2017). Metode ini menggunakan frekuensi kemunculan term untuk setiap dokumen. Nilai bobot setiap term pada setiap dokumen didapat dari logaritma frekuensi kemunculan term tersebut.  Rumus term frequency  dapat dilihat pada Persamaan 1.   
ð’˜ð’•,ð’…={ðŸ+ð¥ð¨ð ðŸðŸŽð’•ð’‡ð’•,ð’…, ð’‹ð’Šð’Œð’‚  ð’•ð’‡ð’•,ð’…>ðŸŽ
ðŸŽ, ð’‹ð’Šð’Œð’‚  ð’•ð’‡ð’•,ð’…=ðŸŽ       (1) 
Keterangan:  
ð‘“ð‘¡,ð‘‘ = banyaknya kemunculan term (t) pada 
dokumen ( d) 
Pada Persamaan 2.1 tf_(t,d) merupakan banyaknya kemunculan term pada suatu dokumen. penggunaan logaritma bertujuan untuk mengurangi selisih frekuensi kemunculan antar term agar tidak te rlalu lebar. Untuk setiap nilai bobot term dengan frekuensi term lebih dari nol akan ditambah 1 untuk membedakan nilai bobot term yang memiliki kemunculan 1 kali dan tidak sama sekali.  
2.4.2 Inverse  Document  Frequency  
Metode pembobotan inverse  document  frequency  menilai bahwa setiap term yang langka (tidak banyak dijumpai pada banyak dokumen) dianggap memiliki kepentingan yang lebih daripada term yang umum (banyak dijumpai pada banyak dokumen).  Nilai bobot setiap term dianggap memiliki kepentingan yang bertolak belakang dengan banyaknya dokumen yang mengandung term tersebut (Fauzi, Arifin and Yuniarti, 2017). Metode ini menggunakan jumlah dokumen yang mengandung term dan jumlah dokumen secara keseluruhan. Nilai bobot setiap term didapat dari logaritma jumlah dokumen secara keseluruhan dibagi dengan jumlah dokumen yang mengandung term. Rumus inverse  document  frequency  dapat dilihat pada Persamaan 2.2.     
ð‘–ð‘‘ð‘“ð‘¡=log10(ð‘
ð‘‘ð‘“ð‘¡)  (2) 
Keterangan:  
N = jumlah  dokumen  
ð‘‘ð‘“ð‘¡ = jumlah dokumen yang mengandung  term 
(t)  
Pada Persamaan 2 dft yang merupakan jumlah dokumen yang mengandung term t akan selalu memiliki nilai lebih kecil sama dengan N yang merupakan jumlah dokumen.  
2.4.3 TF-IDF 
TF-IDF ( Term  Frequency -Inverse  Document  Frequency ) merupakan angka statistik yang menunjukkan relevansi suatu term dengan beberapa dokumen sehingga term tersebut dapat menjadi kata kunci dari dokumen tertentu. Dari nilai tersebut beberapa dokumen tertentu dapat diidentifikasi atau dikategorikan (Qaiser and Ali, 2018). Metode TF-IDF adalah 
salah satu metode term weighting  yang populer digunakan. Nilai bobot TF -IDF didapat dari perkalian nilai tf ( Term  Frequency ) suatu term pada suatu dokumen dengan nilai idf ( Inverse  Document  Frequency ) term tersebut. Rumus 
TF-IDF dapat dilihat pada Persamaan 3.   
wð‘¡,ð‘‘=wtfð‘¡,ð‘‘Ã—idfð‘¡  (3) 
Keterangan:  
wtfð‘¡,ð‘‘ = bobot  log TF  term ( t) pada  dokumen ( d)  
ð‘–ð‘‘ð‘“ð’• = nilai inverse document frequency  pada 
term ( t)  
Normalisasi pada pembobotan term:  
wð‘¡,ð‘‘=wð‘¡,ð‘‘
âˆšâˆ‘ wð‘¡,ð‘‘ð‘›
ð‘¡=12    (4) 
Keterangan:  
ð‘Šð’•,ð’… = bobot  TF-IDF term ( t) pada  dokumen ( d)  
n = jumlah term  
Pada Persamaan 3 menjelaskan Wt,d yang merupakan bobot nilai term frequency  dari term t dan dokumen d dikali dengan nilai inverse  document  frequency  dari term tersebut. Pada normalisasi Persamaan 4 bobot yang dihasilkan TF -IDF akan diubah menjadi rentang [0,1] dengan membaginya dengan nilai Panjang dokumen untuk mengurangi selisih antar nilai bobot term yang terpaut jauh.  
2.5 Cosine  Similarity  
Cosine  similarity  adalah salah satu metode pengukuran kemiripan antar dua dokumen yang berbeda dengan menghitung kosinus sudut yang terbentuk oleh vektor yang merepresentasikan masing-masing dokumen (Fauzi, Arifin and Yuniarti, 2017). Fitur yang ada pada suatu dokumen yang  merupakan dimensi membentuk sebuah vektor. Kedua vektor yang terbentuk dari dua dokumen dapat dicari kemiripannya dengan menghitung jarak antar vektor. Ada beberapa metode untuk 
menghitung jarak antar dua vektor seperti euclidean  distance  dan cosine  similarity seperti pada Gambar 1.  
Gambar 1 Euclidean  Distance  dan Cosine  Similarity  
Sumber: Wang, Chen, & Wu, 2017   
Pada gambar 1 simbol A dan B merupakan vektor yang dicari jarak antar keduanya menggunakan euclidean  distance  yang dengan simbol dist(A, B) d an cosine  similarity  dengan simbol COS Î¸. Simbol Z, X, dan Y merupakan fitur dari dokumen. Pada umumnya metode cosine  similarity  memang digunakan untuk data mining , sistem temu kembali informasi, dan sistem rekomendasi untuk mencari kemiripan antar kedua v ektor dokumen. Rumus cosine  similarity  dapat dilihat pada Persamaan 5 dan untuk normalisasi TF-IDF dapat dilihat pada Persamaan 6.   
cos (ð‘ž,ð‘‘)= ð‘žÃ—ð‘‘  
|ð‘ž|Ã—|ð‘‘|=âˆ‘ ð‘žð‘–ð‘‘ð‘–|ð‘£|
ð‘–=1
âˆšâˆ‘ ð‘žð‘–ð‘‘ð‘–|ð‘£|
ð‘–=12
Ã—âˆ‘ ð‘žð‘–ð‘‘ð‘–|ð‘£|
ð‘–=12 (5) 
Keterangan:  
ð‘ž = bobot TF-IDF pada kueri   
ð‘‘ = bobot TF -IDF pada dokumen   
Dengan normalisasi pada pembobotan term:   
cos (ð‘ž,ð‘‘)= ð‘žÃ—ð‘‘=âˆ‘ ð‘žð‘–ð‘‘ð‘–|ð‘£|
ð‘–=1  (6) 
Keterangan:  
ð‘ž = bobot TF-IDF pada kueri   
ð‘‘ = bobot TF -IDF pada dokumen   
Hasil yang didapat dari Persamaan 5 dan 
2.6 akan berupa nilai dengan rentang  [0,1]. 
Semakin besar nilai yang didapat (mendekati 1) maka semakin kecil sudut yang dihasilkan oleh kedua vektor tersebut yang berarti semakin mirip kedua dokumen yang dibandingkan, sebaliknya semakin kecil nilai yang didapat (mendekati 0) maka semakin be sar sudut yang dihasilkan oleh kedua vektor tersebut dan semakin beda kedua dokumen yang dibandingkan, sehingga dapat disimpulkan bahwasanya tingkat kemiripan berbanding lurus dengan nilai kosinus.  

3. IMPLEMENTASI ALGORITME  
Perancangan sistem dengan visualisasi flowchart  untuk mempermudah memahami alur proses dan aliran data sistem dalam pembuatan sistem oleh pengembang dan pembaca.  
Gambar 2 Diagram Alir Sistem Data Latih  
Gambar 3 Diagram Alir Sistem Data Uji   
Gambar 2 menunjukkan Diagram alir sistem untuk data latih . Secara umum sistem akan memulai dengan memuat data film dari API sebagai data latih , data film tersebut dilanjutkan dengan pre-processing  untuk memecah dokumen/film dan mendapatkan term. Dari term tersebut sistem akan melakukan pembobotan pada setiap term pada setiap dokumen dengan pembobotan TF-IDF yang dinormalisasi untuk membentuk model yang disimpan dalam fail.  Gambar 3 menunjukkan Diagram alir 
sistem untuk data latih . Sistem memuat fail yang disimpan dan merekam judul film yang pernah ditonton pengguna sebagai kueri/data uji. Data film dari judul film yang direkam akan melalui pre-processing  dan pembobotan seperti halnya data latih. Nilai bobot data uji akan dicari kemiripannya melalui metode cosine  similarity  dengan setiap dokumen data latih dari model. Data hasil dari perhitungan akan disaring sepuluh besar data latih dengan nilai kemiripan tertinggi, memiliki minimal satu genre  yang sama dengan data uji, dan memastikan film yang sama tidak akan masuk hasil rekomendasi.  

4. PENGUJIAN DAN ANALISIS  
Terdapat tiga metode evaluasi yaitu pengujian precision  @K, average  precision  @K, dan mean  average  precision  @K. 
Pengujian tersebut mengukur precision  yang diberikan system rekomendasi melalui hasil rekom endasi yang diberikan dan membandingkan precision  yang menggunakan single  kueri dan multiple  seeds  kueri. Dengan menghitung precision  pada penggunaan satu atau lebih judul film kueri yang dipilihnya. Dari ketiga partisipan individu dengan setiap individu akan menguji 5 kali sistem dengan 5 kueri yang berbeda. Presisi dihitung dari 10 peringkat teratas judul film hasil rekomendasi yang diberikan berapa kali partisipan memutuskan hasil rekomendasi yang diberikan relevan terhadap kueri.  
4.1 Precision  @K Single  Kueri  
Tabel 6 Hasil Pengujian Precision @K  Single  Kueri  
Partisipan  Kueri  Peringkat  Keterangan  P@K  Nilai  Partisipan  
1 Fast & Furious  1 Relevan  P@1  1 
2 Relevan  P@2  1 
3 Relevan  P@3  1 
4 Relevan  P@4  1 
5 Tidak  P@5  0,8 
6 Relevan  P@6  0,833333  
7 Tidak  P@7  0,714286  
8 Tidak  P@8  0,625  
9 Tidak  P@9  0,555556  
10 Relevan  P@10  0,6 
â€¦ â€¦ â€¦ â€¦ â€¦ 
â€¦ â€¦ â€¦ â€¦ â€¦ 
Rush Hour 
3 1 Relevan  P@1  1 
2 Relevan  P@2  1 
3 Tidak  P@3  0,666667  
4 Relevan  P@4  0,75 
5 Relevan  P@5  0,8 
6 Tidak  P@6  0,666667  
7 Tidak  P@7  0,571429  
8 Tidak  P@8  0,5 
9 Relevan  P@9  0,555556  
10 Tidak  P@10  0,5 
Partisipan  
2 Hereditary  1 Relevan  P@1  1 
2 Tidak  P@2  0,5 
3 Relevan  P@3  0,666667  
4 Relevan  P@4  0,75 
5 Relevan  P@5  0,8 
6 Relevan  P@6  0,833333  
7 Relevan  P@7  0,857143  
8 Tidak  P@8  0,75 
9 Relevan  P@9  0,777778  
10 Tidak  P@10  0,7 
â€¦ â€¦ â€¦ â€¦ â€¦ 
â€¦ â€¦ â€¦ â€¦ â€¦ 
Captain Phillips  1 Relevan  P@1  1 
2 Relevan  P@2  1 
3 Relevan  P@3  1 
4 Relevan  P@4  1 
5 Relevan  P@5  1 
6 Relevan  P@6  1 
7 Tidak  P@7  0,857143  
8 Relevan  P@8  0,875  
9 Tidak  P@9  0,777778  
10 Tidak  P@10  0,7 
Partisipan  
3 Harry Potter and the Prisoner of Azkaban  1 Relevan  P@1  1 
2 Relevan  P@2  1 
3 Relevan  P@3  1 
4 Relevan  P@4  1 
5 Relevan  P@5  1 
6 Relevan  P@6  1 
7 Tidak  P@7  0,857143  
8 Tidak  P@8  0,75 
9 Relevan  P@9  0,777778  
10 Tidak  P@10  0,7 
â€¦ â€¦ â€¦ â€¦ â€¦ 
â€¦ â€¦ â€¦ â€¦ â€¦ 
King Kong  1 Relevan  P@1  1 
2 Tidak  P@2  0,5 
3 Tidak  P@3  0,333333  
4 Relevan  P@4  0,5 
5 Tidak  P@5  0,4 
6 Relevan  P@6  0,5 
7 Relevan  P@7  0,571429  
P@8  0,625  
9 Relevan  P@9  0,666667  
10 Tidak  P@10  0,6  
Pada Tabel 6 menunjukkan peringkat 4 teratas sebagian besar relevan terhadap kueri dengan nilai precision  P@4 minimal 0,5. Sebagian besar nilai precision  cukup konsisten pada peringkat teratas dan mulai naik turun pada peringkat 4 hingga peringkat 10. Dapat disimpulkan bahwa partisipan mulai beranggapan hasil sistem rekomendasi mulai tidak relevan pada peringkat akhir hasil rekomendasi. Hal ini bisa terjadi karena peringkat yang lebih tinggi memiliki nilai kemiripan dengan kueri lebih tinggi dari peringkat yang lebih rendah. Pada Tabel 6.2 juga menunjukkan untuk precision  kesepuluh hasil rekomendasi (P@10) untuk seluruh partisipan menunjukkan paling sedikit  0,5 dengan rata-rata 0,72 dan untuk 5 peringkat teratas menunjukkan paling sedikit 0,4 dengan rata-rata 0.813333333.  Menurut partisipan tingginya tingkat relevan dapat dipengaruhi oleh sekuel atau prekuel dari film pada kueri. Tingkat keunikan film yang jarang terlihat pada film lainnya seperti film bertema sulap juga berpengaruh pada rendahnya tingkat relevan.  
4.2 Average  Precision @K Single  Kueri  
Tabel 7 Hasil Pengujian AP@K Single  Kueri  
Partisipan  Kueri  AP@10  Rata-rata 
partisipan 1 Fast & Furious  0,812817  0,853889  Tranformers  0,942103  Iron Man  0,956389  Batman Begins  0,857103  Rush Hour 3 0,701032  
partisipan 2 Hereditary  0,763492063 0,788285714  Sinister  0,678532  Jason Bourne  0,915437  Now You See Me  0,662976  Captain Phillips  0,920992  
partisipan 3 Harry Potter and the Prisoner of Azkaban  0,908492  0,827587  The Hunger Games  0,880437  The Avengers  0,853929  Jurassic World  0,925437  King Kong  0,569643   
Pada Tabel 7 menunjukkan titik paling rendah rata -rata pengujian precision  AP@10 untuk seluruh partisipan berada di angka 0,788285714 dan tertinggi 0,853889, namun terdapat beberapa hasil pengujian precision  AP@10 berada di angka rendah seperti 0,569643, 0,662976, dan 0,678532. Rata-rata 
dari AP@10 masih kukuh di atas 0 ,78, meski terdapat beberapa hasil pengujian precision AP@10 berada di angka rendah tersebut . 
4.3 Mean Average Precision @K Single  Kueri  
Tabel 8 Hasil Pengujian MAP @K Single  Kueri  
Jumlah Penguji  MAP@3  
3 0,823254   
Pada Tabel 8 menunjukkan dari tiga penguji hasil pengujian precision  menyentuh angka 0,823254 adalah hasil rekomendasi yang relevan terhadap kueri dan sisanya sebesar 0.176746 tidak relevan terhadap kueri.  
4.4 Precision @K Multiple Seeds  Kueri  
Tabel 9 Hasil Pengujjan Precision  @K Multiple  
Seeds  Kueri  
Penguji  Kueri 1  Kueri 2  Peringkat  Keterangan  P@K  Nilai  
partisipan 1 The Martian  Interstellar  1 Relevan  P@1  1 
2 Relevan  P@2  1 
3 Relevan  P@3  1 
4 Relevan  P@4  1 
5 Tidak  P@5  0,8 
6 Relevan  P@6  0,833333
7 Relevan  P@7  0,857143
8 Relevan  P@8  0,875  
9 Tidak  P@9  0,777778
10 Tidak  P@10 0,7 
â€¦ â€¦ â€¦ â€¦ â€¦ â€¦ 
â€¦ â€¦ â€¦ â€¦ â€¦ â€¦ 
Venom  Deadpool  1 Relevan  P@1  1 
2 Relevan  P@2  1 
3 Relevan  P@3  1 
4 Relevan  P@4  1 
5 Relevan  P@5  1 
6 Relevan  P@6  1 
7 Tidak  P@7  0,857143
8 Tidak  P@8  0,75 
9 Tidak  P@9  0,666667
10 Tidak  P@10 0,6 
partisipan 2 Non-stop Taken  1 Relevan  P@1  1 
2 Relevan  P@2  1 
3 Relevan  P@3  1 
4 Relevan  P@4  1 
5 Relevan  P@5  1 
6 Relevan  P@6  1 
7 Relevan  P@7  1 
8 Relevan  P@8  1 
9 Tidak  P@9  0,888889
10 Relevan  P@10 0,9 
â€¦ â€¦ â€¦ â€¦ â€¦ â€¦ 
â€¦ â€¦ â€¦ â€¦ â€¦ â€¦ 
Mr. Bean's Holiday  Johnny English Reborn  1 Relevan  P@1  1 
2 Relevan  P@2  1 
3 Relevan  P@3  1 
4 Tidak  P@4  0,75 
5 Tidak  P@5  0,6 
6 Relevan  P@6  0,666667
7 Relevan  P@7  0,714286
8 Relevan  P@8  0,75 
9 Relevan  P@9  0,777
10 Relevan  P@10 0,8 
partisipan 3 Pitch Perfect  The Greatest Showman  1 Tidak  P@1  0 
2 Tidak  P@2  0 
3 Relevan  P@3  0,333333
4 Relevan  P@4  0,5 
5 Relevan  P@5  0,6 
6 Tidak  P@6  0,5 
7 Relevan  P@7  0,571429
8 Tidak  P@8  0,5 
9 Tidak  P@9  0,444444
10 Tidak  P@10 0,4 
â€¦ â€¦ â€¦ â€¦ â€¦ â€¦ 
â€¦ â€¦ â€¦ â€¦ â€¦ â€¦ 
The Day After Tomorrow  Geostorm  1 Tidak  P@1  0 
2 Relevan  P@2  0,5 
3 Tidak  P@3  0,333333
4 Relevan  P@4  0,5 
5 Tidak  P@5  0,4 
6 Relevan  P@6  0,5 
7 Tidak  P@7  0,428571
8 Relevan  P@8  0,5 
9 Relevan  P@9  0,555556
10 Relevan  P@10 0,6 
Pada Tabel 9 menunjukkan hasil yang dianggap partisipan relevan tidak terlalu terpaut terhadap tingginya peringkat. Beberapa hasil pengujian menunjukkan hasil rekomendasi justru relevan terhadap kueri pada peringkat tengah atau akhir. Pada beberapa hasil cukup konsisten hingga peringkat ke-6 baru mulai menurun, menurut pendapat partisipan ini disebabkan kedua kueri film yang identik pada satu tema yang juga umum digunakan pada banyak film seperti film bertema superhero . Beberapa hasil  rekomendasi  lainnya memiliki 
tingkat relevan yang rendah meskipun berada di peringkat yang tinggi, menurut partisipan ini disebabkan hasil rekomendasi yang didapat adalah film animasi yang tidak dianggap relevan dengan kueri yang bukan merupakan film animasi, meskipun memang dari segi cerita cukup mirip dengan kueri.  
4.5 Average Precision @K Multiple Seeds Kueri  
Tabel 10 Hasil Pengujian AP@K Multiple 
Seeds  Kueri  
partisipan  Kueri 1  Kueri 2  AP@10  Rata-rata 
partisipan 1 The Martian  Interstellar  0,884325  0,898659  Joker  Batman Begins  0,915437  Captain America: The Winter Soldier  Man of Steel  0,914325  Prometheus  Arrival  0,891825  Venom  Deadpool  0,887381  
partisipan 2 Non-stop Taken  0,978889  0,71046  EXAM  Gone Girl  0,697698  Source Code  Searching  0,777817  Karate Kid  Southpaw  0,292024  Mr. Bean's Holiday  Johnny English Reborn  0,805873  
partisipan 3 Pitch Perfect  The Greatest Showman  0,384921  0,641048  Resident Evil: Afterlife  World War Z 0,968889  The Sorcerer's Apprentice  Fantastic Beasts  0,550357  The Girl With the Dragon Tattoo  Flightplan  0,869325  The Day After Tomorrow  Geostorm  0,431746   
Pada Tabel 10 menunjukkan perbedaan yang cukup signifikan dari ketiga hasil pengujian AP@10 ketiga pengguna. Pada partisipan 1 menunjukkan nilai yang cukup tinggi karena keseluruhan kueri memiliki nilai yang rata-rata yang cukup tinggi secara konsisten. Berbeda halnya dengan yang ditunjukkan pada partisipan 2 dan partisipan 3 yang menunjukkan nilai AP@10 yang cukup rendah disebabkan tidak konsistennya hasil dengan beberapa hasil yang cukup rendah dan ada juga yang cukup tinggi.  
4.6 Mean Average Precision @K Multiple Seeds Kueri  
Tabel 11 Hasil Pengujian MAP @K Multiple 
Seeds  Kueri  Jumlah Penguji  MAP@3  
3 0.7500556   
Pada Tabel  11 menunjukkan dari tiga penguji hasil pengujian precision  menyentuh angka 0.7500556 adalah hasil rekomendasi yang relevan terhadap kueri  dan sisanya sebesar 0.2499444 tidak relevan terhadap kueri.  
4.6 Perbandingan Hasil Single Kueri dan 
Multiple Seeds Kueri  
Tabel 11 Perbandingan Hasil Single Kueri dan Multiple Seeds Kueri  Jenis Kueri  MAP@3  
Single  kueri  0.823254  
Multiple  seeds  kueri  0.7500556   
Pada Tabel 11  menunjukkan jenis kueri single kueri memiliki nilai MAP@3 lebih tinggi dari multiple seeds kueri dengan selisih 0.0731984. Hal ini disebabkan adanya kelebihan dan kekurangan pada multiple seeds kueri seperti pada multiple seeds kueri akan memiliki genre yang lebih lebar dibanding single kueri karena gabungan dari kedua genre kueri. Begitu halnya juga terhadap term yang ada pada multiple seeds kueri namun term yang juga terdapat pada kedua kueri akan mendapatkan nilai yang lebih tinggi daripada single kueri.  

5. KESIMPULAN  
Berdasarkan dari  hasil pengujian dan analisis dari implementasi yang telah dilakukan dapat disimpulkan bahwa berdasarkan hasil pengujian dan analisis dari implementasi yang telah dilakukan. Jenis kueri multiple seeds  kueri cukup berpengaruh terhadap hasil rekomendasi film menggunakan content based filtering  dengan fitur judul, genre, dan sinopsis, pembobotan TF -IDF, dan cosine  similarity . multiple  seeds  kueri memperkuat nilai bobot untuk term yang ada pada ke semua kueri yang memungkinkan untuk mendapat hasil rekomendasi dengan tema yang sama. multiple  seeds  kueri memperbanyak jumlah term dan genre  sehingga melebarkan hasil rekomendasi terhadap film dengan tema yang berbeda.  Dari evaluasi yang telah dilakukan dengan metode MAP@K kepada tiga pengguna. Tingkat akurasi dari penggunaan metode content  based  filtering dalam sistem rekomendasi film dengan fitur judul, genre, dan sinopsis, pembobotan TF-IDF, dan cosine  similarity  dihitung mencapai 0.823254 untuk jenis kueri single  kueri dan 0.7500556 untuk jenis kueri multiple  seeds kueri.  

6. DAFTAR PUSTAKA  
Fauzi, M. A., Arifin, A. Z. and Yuniarti, A. (2017) â€˜Arabic book retrieval using class and book index based term weightingâ€™, Internat ional Journal of Electrical and Computer Engineering, 7(6), pp. 3705 â€“3710. doi: 10.11591/ijece.v7i6.pp3705 -3711.  INFORMATIKALOGI (2016) Text Preprocessing | INFORMATIKALOGI. Available at: https://informatikalogi.com/text -preprocessing/ (Accessed: 20 Septem ber 2020).  
Isinkaye, F. O., Folajimi, Y. O. and Ojokoh, B. A. (2015) â€˜Recommendation systems: Principles, methods and evaluationâ€™, Egyptian Informatics Journal. Ministry of Higher Education and Scientific Research, 16(3), pp. 261 â€“273. doi: 10.1016/j.eij.20 15.06.005.  Kadhim, A. I. (2018) â€˜An Evaluation of Preprocessing Techniques for Text Classificationâ€™, 16(6), pp. 22 â€“32. 
Manning, C., Raghavan, P. and Schutze, H. (2008) â€˜Chapter 2: The term vocabulary & postings listsâ€™, Introduction to Information Retrieval , (c).  
Mihir, P. (2019) 5 Fastest Ways to Find a Good Movie or Film Worth Watching, makeuseof.com. Available at: https://www.makeuseof.com/tag/fastest-ways -good -movie -film-watching/ (Accessed: 22 December 2020).  Pal, A., Parhi, P. and Aggarwal, M. (2018) â€˜ An improved content based collaborative filtering algorithm for movie recommendationsâ€™, 2017 10th International Conference on Contemporary Computing, IC3 2017, 2018 -Janua(August), pp. 1 â€“3. doi: 10.1109/IC3.2017.8284357.   
Qaiser, S. and Ali, R. (2018) â€˜Text  Mining: Use of TF -IDF to Examine the Relevance of Words to Documentsâ€™, International Journal of Computer Applications, 181(1), pp. 25 â€“29. doi: 10.5120/ijca2018917395.   
Reddy, S. R. S. et al. (2019) â€˜Content -Based Movie Recommendation System Using Genre Co rrelationâ€™, in Satapathy, S. C., Bhateja, V., and Das, S. (eds) Smart Intelligent Computing and Applications. Singapore: Springer Singapore, pp. 391 â€“397. Shrivastava, R. and Sisodia, D. S. (2019) â€˜Product Recommendations Using Textual Similarity Based Lear ning Modelsâ€™, 2019 International Conference on Computer Communication and Informatics, ICCCI 2019. IEEE, pp. 1 â€“7. doi: 10.1109/ICCCI.2019.8821893.  
Tren Positif Film Indonesia | Indonesia.go.id 
(2019). Available at: https://indonesia.go.id/ragam/seni/sosia
l/tren-positif -film-indonesia (Accessed: 28 August 2020).  
Virgina Maulita Putri (2020) Netflix Uji Coba Fitur Shuffle Play, detikInet. Available at: https://inet.detik.com/mobile -apps/d -5139122/netflix -uji-coba -fitur-shuffle -play (Accessed: 10 December 
2020 ). 
Wang, L., Chen, Z. and Wu, J. (2017) â€˜An opportunistic routing for data forwarding based on vehicle mobility association in vehicular ad hoc networksâ€™, Information (Switzerland), 8(4). doi: 10.3390/info8040140.",sistem rekomendasi,"Content Based Filtering, TF-IDF, cosine similarity",data film,precision
SISTEM REKOMENDASI PENENTUAN JUDUL SKRIPSI MENGGUNAKAN ALGORITMA DECISION TREE,"SISTEM REKOMENDASI PENENTUAN JUDUL SKRIPSI MENGGUNAKAN ALGORITMA DECISION TREE

A Sofalul Khazari1), Fitri Marisa2), Indra Dharma Wijaya3)

Abstract
One of the requirements to obtain a Bachelor's degree, a student must make a thesis. Thesis is a scientific work that 
is used as a good condition in Private Universities (PTS) and State Universities (PTN) in Indonesia. In the thesis, students are required to apply science according to the field of science that has been pursued. However, the reality of existing students are still confused in determining the title or field that will be discussed in the thesis. Therefore, the authors try to make a recommendation system of thesis title determination that can help students Informatics Engineering University of Widyagama Malang to determine the title of the thesis in accordance with the capabilities and standards determined by the department. With the method of Decision tree using ID3 algorithm, it is expected this system can help students to not difficulty in determining the title of the thesis. 
 
Keywords: data mining, decision tree, ID3. 
 
PENDAHULUAN  
Skripsi merupakan sebuah momentum yang sangat menentukan bagi mahasiswa tingkat akhir. Salah satu syarat untuk mendapatkan predikat sarjana baik pada Perguruan Tinggi Negeri (PTN) maupun Perguruan Tinggi Swasta (PTS) mewajibkan mahasiswanya untuk mengerjakan skripsi sesuai bidang keilmuan yang dipelajari. Dalam tahap awal pengerjaan skripsi, pada umumnya mahasiswa dibingungkan dengan langkah-langkah penentuan tema atau judul skripsi yang akan diajukan, sehingga dapat memperlambat proses pengajuan skripsi. Sehingga langkah awal dalam menentukan judul skripsi itu merupakan momentum dimana proses tersebut dapat menentukan proses jalannya penulisan skripsi. Problematika mengenai skripsi harus diselesaikan dengan segera, salah satu caranya dengan memanfaatkan sistem teknologi informasi itu sendiri. Oleh karena itu, penyusun membuat sistem rekomendasi yang dapat membantu mahasiswa dalam pengambilan judul skripsi yang sesuai dengan kemampuan mahasiswa tersebut, dengan menggunakan algoritma Decision Tree. 
 
LANDASAN TEORI 
A. Skripsi 
Skripsi adalah sebuah karya ilmiah yang ditulis oleh mahasiswa program S1 yang membahas tentang bidang atau topik tertentu berdasarkan dari suatu  hasil kajian pustaka yang ditulis oleh para ahli, hasil pengembangan, atau hasil penelitian lapangan.[1](Huda, 2011). Dalam pengerjaannya, mahasiswa dibimbing minimal oleh dua orang dosen pembimbing. Bimbingan ini dilakukan agar hasil dari skripsi tersebut berkualitas baik dari segi teknik penyampaiannya maupun isinya. Penulisan skripsi adalah bagian dari kegiatan pendalaman displin ilmu lewat kegiatan menulis bagi mahasiswa program S1. Bahkan karena sangat penting, kelulusan program S1 ini ditentukan oleh kualitas dari hasil skripsi. 
B. Data Mining 
Data mining is the process of discovering insightful, interesting, and novel patterns, as well as descriptive, understandable, and predictive models from large-scale data.[2](Zaki & JR., 2014). Data mining merupakan suatu proses menemukan hubungan yang berarti, pola, dan kecenderungan, dengan memeriksa dalam sekumpulan data besar yang tersimpan dalam penyimpanan dengan menggunakan teknik pengenalan pola seperti teknik statistik dan matematika. Dari definisi diatas, dapat ditarik kesimpulan bahwa data mining adalah suatu pencarian dan analisa terhadap koleksi-koleksi database yang berjumlah besar. Sehingga dapat ditemukan suatu pola yang menarik dengan tujuan mengekstrak informasi dan pengetahuan yang akurat dan potensial, serta dapat memberi pemahaman dan berguna dari database yang besar serta digunakan untuk membuat suatu keputusan promosi yang akan disebarkan. 
C.Decision Tree 
Metode ini merupakan salah satu metode yang ada pada teknik klasifikasi dalam data mining. Metode pohon keputusan mengubah fakta yang sangat besar menjadi pohon keputusan yang merepresentasikan aturan. Pohon keputusan juga berguna untuk mengekplorasi data, menemukan hubungan tersembunyi antara sejumlah calon variabel input dengan sebuah variabel target. Data dalam pohon keputusan biasanya dinyatakan dalam bentuk tabel dengan atribut dan record. Atribut menyatakan suatu parameter yang disebut sebagai kriteria dalam pembentukan pohon. Misalkan untuk menentukan main tenis, kriteria yang diperhatikan adalah cuaca, angin, dan suhu. Salah satu atribut merupakan atribut yang menyatakan data solusi per item data yang disebut atribut hasil.[3](Acmad & Slamat, 2012). 
D. Pohon Keputusan ID3 
Algoritma ID3 (Iterative Dichotomiser 3) adalah sebuah metode yang digunakan dalam membuat pohon keputusan, dimana algoritma ID3 ini oleh J. Ross Quinlan pada sekitar akhir 1970-an dan awal 1980-an[4]. Algoritma pada metode ini menggunakan konsep dari entropy informasi, dimana Algoritma ID3 melakukan pencarian secara menyeluruh (greedy) pada semua kemungkinan pohon keputusan.Cara  kerja algoritma ID3 dapat digambarkan sebagai berikut :[5](Defiyanti & Pardede, 2010) 
1. Hitung entropy dan information gain dari setiap atribut dengan menggunakan rumus:  
() = âˆ’+2+ âˆ’ âˆ’
2
âˆ’               
.............(1)  
Keterangan: 
S = ruang (data) sampel yang digunakan untuk training 
P+ = jumlah yang bersolusi positif (mendukung) pada data sampel untuk kriteria tertentu 
P
- 
#NAME? 
bersolusi negatif (tidak mendukung) pada data sampel untukkriteria tertentu
(
, 
) = 
(
) 
âˆ’ 
âˆ‘
""        ""
âˆˆ
""        ""
(
)
|
|
|
|
(
)  ...(2) 
Keterangan: 
S = ruang (data) sampel yang digunakan untuk training 
A = atribut 
V = suatu nilai yang mungkin untuk atribut A 
Nilai(A) = himpunan yang mungkin untuk atribut A 
|Sv| = jumlah sampel untuk nilai V 
|S| = jumlah seluruh sampel data 
Entropy(Sv) = entropy untuk sampel-sampel yang memiliki nilai V 
2. Bentuk simpul yang berisi atribut tersebut. 
3. Menghitung lagi information gain yang akan terus dilakukan sampai semua data masuk dalam kelas yang sama. Atribut yang telah dipilih tidak diikutkan lagi dalam perhitungan nilai information gain. 
 
ANALISIS DAN PERANCANGAN SISTEM 
Penelitian ini menggunakan Metode Decision Tree dengan algoritma ID3 untuk mengelompokkan data kategorikal hingga menghasilkan rekomendasi yang sesuai dengan kemampuan dan minat dari mahasiswa tersebut. Selanjutnya melakukan analisis lebih mendalam terhadap hasil rekomendasi tersebut untuk membantu mahasiswa dalam menentukan judul skripsi yang sesuai. 
A. Flowchart Program Aplikasi
Gambar 1. Flowchart Aplikasi
B. Perancangan Sistem
Gambar 2. Use Case Diagram
Gambar 3. Activity Diagram Manage Data Mahasiswa  
Gambar. 4 Activity Diagram Input Minat
C. Perancangan Antarmuka 
Perancangan antar muka merupakan uraian dari sketsa program yang akan dibuat. Pada desain interface ini juga akan dijelaskan jalannya program yang akan dibangun. Berikut desain interface pada rancang Sistem Rekomendasi Penentuan Judul Skripsi menggunakan metode Decision Tree dapat dilihat dibawah ini.
Gambar. 5 Analisa
Gambar. 6 Hasil Rekomendasi

HASIL PENELITIAN DAN PEMBAHASAN 
Dalam mengimplementasi sistem kali ini, user terlebih dahulu harus melakukan login, login tersebut bertujuan agar user bisa mengoperasikan sistem. Jika user telah melakukan login, maka akan muncul gambar seperti di bawah ini.
Gambar 7. Beranda 
Pada menu beranda diatas merupakan tampilan awal dari aplikasi sistem rekomendasi penentuan judul skripsi menggunakan algoritma Decision Tree untuk memberikan rekomendasi judul skripsi saat setelah login berhasil dilakukan oleh mahasiswa. 
Gambar 8. Halaman Rekomendasi
Pada halaman rekomendasi diatas merupakan tampilan yang berisi penentu rekomendasi. Halaman rekomendasi akan digunakan untuk mengolah atribut untuk mengetahui hasil rekomendasi. Sebelum mengetahui hasil rekomendasi, mahasiswa memilih minat tema skripsi yang mau diambil.  
Gambar 9. Pilih Minat
Gambar 10. View Rekomendasi 
Untuk melihat hasil rekomendasi, mahasiswa memilih minat dari rumpun judul rekomendasi yang diinginkan. Setelah memilih minat, maka selanjutnya mahasiswa akan mendapatkan rekomendasi judul skripsi.

KESIMPULAN DAN SARAN 
Dari uraian yang telah dibahas, maka dapat diambil kesimpulan yaitu : 
1. Pohon Keputusan ID3 dapat digunakan sebagai rekomendasi dalam menentukan judul skripsi. 
2. Pohon Keputusan ID3 tersebut sangat dipengaruhi oleh pengelompokan dan pengambilan sampel-sampel data dari populasi data seluruhnya. 
3. Pembentukan pohon keputusan dapat dibentuk sesuai data training yang di set sehingga jurusan tidak perlu melakukan perombakan pada pogram jika penilaian berubah.

REFERENSI 
Huda, M., 2011. Perkembangan Keilmuan di STAIN Ponorogo. Jurnal Dialogia, p.111.  http://jurnal.stainponorogo.ac.id/index.php/justicia/article/download/100/82 
Zaki, M.J. & JR., W.M., 2014. Data Mining and Analysis. 1st ed. New York: Cambridge University Press. 
Acmad, B.D.M. & Slamat, F., 2012. Klasifikasi Data Karyawan Untuk Menentukan Jadwal Kerja. Jurnal IPTEK, 16 No.1. http://jurnal.itats.ac.id/klasifikasi-data-karyawan-untuk-menentukan-jadwal-kerja-menggunakan-metode-decision-tree/ 
Han, J. & Kamber, M., 2006. Data Mining Concepts and Techniques. 2nd ed. USA: Elsevier. 
Defiyanti, S. & Pardede, C., 2010. Perbandingan Kinerja Algoritma ID3 dan C4.5 dalam Klasifikasi Spam-Mail. Proceeding Seminar Ilmiah Nasional Komputer dan Sistem Intelijen (KOMMIT 2010), (ISSN: 1411-6286). http://repository.gunadarma.ac.id/964/",sistem rekomendasi,"decision tree, ID3","data mahasiswa, judul skripsi",
Sistem Rekomendasi Tempat Kos di Sekitar Kampus ITHB Menggunakan Metode AHP,"Sistem Rekomendasi Tempat Kos di Sekitar Kampus ITHB Menggunakan Metode AHP

Evasaria Magdalena Sipayung a, Cut Fiarni b, Sherly Sutopo c 


ABSTRACT  
Dalam memilih tempat kos terdapat beberapa kriteria yang harus diperhatikan, pada penelitian ini digunakan tujuh kriteria dalam memilih tempat kos, diantaranya adalah fasilitas kamar, ketersediaan listrik dan air, jarak tempat kos ke kam pus, akses tempat kos ke jalan protokol, kebersihan tempat kos, aman dari banjir, dan reputasi tempat kos. Setiap orang tentunya memiliki perbedaan akan tingkat penilaian (preferensi) antara satu kriteria dan kriteria lainya dan setiap tempat kos pun memiliki harga dan fasilitas yang berbeda-beda. Hal inilah yang terkadang membuat seseorang sulit untuk membandingkan kos yang satu dengan lainya. Pada sistem yang ada saat ini, rekomendasi yang diberikan hanya berupa list tempat kos berdasarkan 
pencocokan antara inputan dengan database saja dan tidak memperlihatkan urutan kos yang menjadi alternatif terbaik. Pada penelitian dilakukan  penentuan preferensi terhadap kriteria untuk memilih tempat kos dengan menggunakan metode Analytical Hierarchy Process (AHP). Sistem rekomendasi tempat kos dilakukan dengan melakukan filter input harga tempat kos dan penilaian terhadap kriteria preferensi fasilitas utama, ketersediaan  listrik dan air, jarak tempat 
kos ke kampus, akses tempat kos ke jalan protokol, kebersihan tempat kos, lingkungan keadaan banjir dan reputasi yang telah ditentukan oleh user. Perhitungan bobot preferensi masing-masing kriteria terhadap alternatif tempat kos sehin gga dihasilkan total nilai masing-masing alternatif kos. Berdasarkan penelitian yang dilakukan, reko mendasi yang diberikan tergantung dari penilaian preferensi setiap kriteria. Hasil yang diberikan berupa rangking alternatif tertinggi ke rangking terendah sesuai dengan preferensi yang dipilih untuk mempermudah mahasiswa menentukan tempat kos yang sesuai dengan kebutuhannya. 

KATA KUNCI  
Kriteria Tempat Kos, Analytical Hierarchy Process, Rangking 

1. PENDAHULUAN 
Bandung merupakan ibu kota Jawa Barat menjadi salah satu kota tujuan untuk melanjutkan pendidikan ke jenjang yang lebih tinggi. Institut Teknologi Harapan Bangsa (ITHB) merupakan salah satu perguruan tinggi swasta yang ada di Bandung. Pada umumnya mahasiswa membutuhkan tempat tinggal sementara selama kurang lebih 4 tahun selama masa kuliah di Bandung,  seperti kontrakan atau tempat kos.  Dalam menentukan tempat kos tentunya ada beberapa kriter ia yang harus diperhatikan. Beberapa kriteria tersebut, diantaranya: harga, fasilitas, lokasi, jarak, akses, kondisi lingkungan sekitar, kebersihan, kenyamanan, keamanan dan lain sebagainya. Selama ini, mahasiswa cenderung tidak memiliki panduan dalam  memilih sebuah tempat kos. Perbedaan preferensi masing-masing orang terhadap kriteria kebutuhan dalam memilih tempat kos serta ketersediaan tempat kos yang memiliki harga dan penawaran akan fasilitas yang bervariasi seringkali menjadi salah satu penyebab seseorang kesulitan untuk mendapatkan tempat  kos yang sesuai dengan kebutuhannya. ITHB sebagai sekolah telematika telah menyediakan sistem untuk membantu mahasiswanya untuk memudahkan dalam mencari tempat kos [1]. Sistem yang tersedia di website  ITHB saat ini dapat melakukan pencarian tempat kos dengan mencocokan input ( profile matching ) dengan lokasi, tipe kos berdasarkan gender, range harga dari yang termurah hingga yang termahal terhadap database . Sistem ini masih belum dapat memberikan rekomendasi tempat kos berdasarkan prefere nsi kriteria kebutuhan masing-masing mahasiswa.  Program Kota Tanpa Kumuh (KOTAKU) adalah satu dari sejumlah upaya strategis Direktorat Jenderal Cipta Karya Kementerian Pekerjaan Umum dan Perumahan Rakyat untuk mempercepat penanganan permukiman kumuh di Indonesia, dengan menggunakan 7 indikator pengukuran tingkat kekumuhan, yang paling mempengaruhi kondisi kekumuhan yang disusul dengan kondisi penyediaan air minum, kondisi pengelolaan air limbah, kondisi pengelolaan persampahan, kondisi jalan permukiman, kondisi proteksi kebakaran, dan kondisi drainase [2]  Terdapat beberapa faktor yang menjelaskan keputusan 
mahasiswa dalam memilih rumah kos. Faktor-faktor yang digunakan untuk memilih kos terdiri dari: faktor referensi, 
citra/reputasi (berkaitan dengan keyakinan dan sikap), kea manan (berkaitan dengan kepribadian dan konsep diri), harga (berkaitan dengan situasi ekonomi) [3]. Faktor yang digunakan memilih kos pada penelitian yang dilakukan oleh Haryadi [4], Saputro [5], dan Maulidah [6], terdiri dari: lingkungan, pelayanan, fasilitas, lokasi.  Terdapat tujuh faktor yang menjelaskan keputusan mahasiswa dalam memilih rumah kos, yaitu kondisi lingkungan, harga, fasilitas, referensi, lokasi, keamanan, dan kenyamanan [ 7].  Pendukung Keputusan Pemilihan Kost di Sekitar Kampus UNP Kediri memberikan rekomendasi atau saran tempat kost yang sesuai dengan kriteria konsumen terdiri dari: biaya, jarak, fasilitas, dan luas kamar [8]. Metode AHP digunakan untuk 
menghitung bobot dari setiap kriteria sedangkan metode TOPSIS digunakan dalam perankingan untuk mendapatkan alternatif kost terbaik. Terdapat 6 kriteria yang digunakan dalam sistem ini, yaitu jarak, harga, luas, jenis kost, batas jam malam dan keamanan. Sistem ini akan memberikan 5 rekomendasi kost terbaik kepada user berdasarkan perhitungan dengan metode AHP dan TOPSIS. Metode AHP digunakan untuk menghitung bobot dari setiap kriteria sedangkan metode TOPSIS digunakan dalam perankingan untuk mendapatkan alternatif kost te rbaik [9]. Dalam melakukan pemilihan tempat kost ini dapat menggunakan metode Analytic Hierarchy Process (AHP) dan Simple Additive Weighting  (SAW) untuk mendapatkan tempat kost yang baik. Dari pengujian yang telah dilakukan bahwa jumlah kriteria sangatlah berpengaruh dalam hasil perangkingan [10]. Sistem Pendukung Pendukung Pengambilan Keputusan Pemiliahn Tempat Kost dengan 3 kriteria jarak, harga, dan fasilitas [11 ].  
 
2. METODE 
Pada bagian ini dijelaskan tentang metode yang digunakan untuk menyelesaikan rekomendasi tempat kos di sekitar Kampus ITHB dengan metode Analytical Hierarchy Process  (AHP). Pada 
penelitian ini metode yang dibahas terdiri dari analisi s sistem yang terdiri dari analisis masalah dan solusi.  
2.1.  Analisis Sistem 
Analisis sistem terdiri dari analisis masalah dan anal isis solusi. 
2.1.1.  Analisis Masalah 
Permasalahan utama yang dibahas dalam penelitian ini adalah 
kesulitan dalam menentukan tempat kos yang sesuai dengan 
kriteria kebutuhan masing-masing mahasiswa. Pada website  
ITHB saat ini terdapat housing referral untuk membantu 
mahasiswanya untuk memudahkan dalam mencari tempat kos, 
ditunjukkan pada Gambar 1. Pada website tersebut terda pat 
kriteria lokasi, tipe kos berdasarkan gender , range harga dari yang termurah hingga yang termahal yang dilakukan matching dengan data yang terdapat pada database . Saat ini mahasiswa belum memiliki panduan dalam memilih dan mengolah informasi tempat kos sementara informasi tempat kos yang didapatkan sangat banyak, sehingga dapat diusulkan alternatif solusi pemecahan masalah, yaitu dengan menentukan kriteria apa saja yang paling mempengaruhi dalam memilih tempat kos dan juga memberikan rekomendasi kos yang sesuai dengan kebutuhan masing-masing mahasiswa. 
Gambar 1. Website ITHB Housing Referral  
Dan dari hasil kuesioner didapatkan bahwa mencari tempat kos 
yang sesuai dengan kebutuhan bukanlah hal yang mudah serta 
belum adanya informasi tempat kos yang merekomendasikan 
tempat kos berdasarkan preferensi masing-masing orang, 
sehingga membuat bingung untuk menentukan tempat kos yang 
sesuai. Oleh karena itu dari hasil kuesioner pun didapatkan bahwa dibutuhkan sebuah alat bantu yang dapat memberikan rekomendasi tempat kos yang sesuai dengan kebutuhan dan kepentingan masing-masing orang. Solusi yang diberikan untuk mengatasi permasalahan yang terjadi dari sisi informasi yaitu menemukan kriteria-kriteria apa saja yang digunakan sebagai kriteria dalam memberikan rekomendasi tempat kos. Sedangkan dari sisi metode dibutuhkan sebuah metode yang mampu membantu menyaring informasi sehingga hanya informasi yang sesuai dengan kebutuhan dan preferensi pengguna yaitu berupa sistem rekomendasi yang membantu dalam memberikan rekomendasi tempat kos yang sesuai dengan bobot kepentingan pengguna. 
2.1.2.  Analisis Solusi 
Pengumpulan data pertama dilakukan dengan cara observasi   mengenai tempat kos di sekitar daerah ITHB. Lalu dilakukan juga wawancara kepada pihak penjaga/pemilik kos. Studi literature tentang penelitian terdahulu. Dari hasil pengumpulan di dapat 6 kriteria utama (fasilitas, harga, lokasi, lingkungan, reputasi, kenyamanan) yang dibagi ke dalam 25 sub kriteria ditnnjukkan pda Tabel 1 [4][5][6]. Untuk mempermudah proses perhitungan AHP maka dilakukan reduksi kriteria untuk mencari kriteria utama dengan melakukan kuesioner kepada kepada mahasiswa ITHB angkatan 2010. Kuesioner yang digunakan adalah kuesioner pertanyaan tertutup untuk mengetahui langkah-langkah yang dilakukan mahasiswa sebelum menentukan tempat kos dan untuk mengetahui kriteria yang mempengaruhi mahasiswa dalam memilih tempat kos. Pada kuesioner pertanyaan mengenai  kriteria yang mempengaruhi pemilihan tempat kos digunakan untuk skala AHP.   
Tabel  1. Kriteria yang mempengaruhi pemilihan tempat kos  
Langkah-langkah seorang mahasiswa dalam memilih tempat kos, 
didapat dari hasil kuesioner yang diberikan kepada mahasiswa 
dan mahasiswi ITHB dimana mahasiswa menentukan urutan dari 
langkah memilih tempat kos yang ditunjukkan pada Tabel 2.   
Tabel  2. Urutan langkah memilih tempat kos 
Langkah Memilih Tempat Kos  Urutan  
Mencari referensi tempat kos   
Menentukan budget   
Menghubungi/mengunjungi langsung tempat kos   
Survey ke tempat kos   
Menanyakan fasilitas yang ditawarkan   
Negosiasi harga dan sistem pembayaran   
Mencariari alternatif kos yang lain   
Lainya :    
Hasil urutan menjadi langkah-langkah pemilihan tempat kos  
ditunjukkan pada Gambar 2, yang terdiri dari:  
1. Mencari Informasi Tempat Kos 
Mahasiswa mencari informasi tempat kos yang ada di sekitar kampus. Pada tahap ini mahasiswa terlebih dahulu mencari informsi mengenai lokasi tempat kos yang ada, tentunya disesuaikan dengan kebutuhan dari masing-masing mahasiswa.  
2. Menentukan Budget  
Tahap kedua biasanya orang cenderung untuk menentukan kisaran harga, dimana kisaran harga ini tentunya didapat setelah mengetahui harga rata-rata untuk sebuah tempat kos pada umumnya.  
3. Survei Tempat Kos 
Mahasiswa melakukan survei mendatangi langsung tempat kos, untuk melihat langsung keadaan tempat kos. Pada tahap ini, merupakan tahap lanjut, ketika informasi sudah didapat  dan telah menentukan beberapa referensi maka biasanya seseorang akan melakukan survei langsumg ke tempat kos untuk melihat kondisi fisik tempat kos yang telah ditentukan sebelumnya. Kemudian melihat keadaan lingkungan sekitar tempat kos, 
4. Menanyakan Fasilitas Kos 
Menanyakan tentang tentang fasilitas apa saja yang ditawarkan, dilakukan saat melakukan survei langsung tahap selanjutnya, biasanya akan dipertanyakan mengenai fasilitas-fasilitas yang didapat.  
5. Negosiasi Sistem Pembayaran  
Setelah melakukan survei dan mengetahui fasilitas-fasilitas yang di dapat, pada umumnya orang akan melakukan negosiasi harga. Biasanya yang akan dipertanyakan hal-hal seperti sistem pembayaran kos, ataupun negosiasi harga. 
6. Mempertimbangkan Kondisi Kos 
Pada tahap ini akan melihat secara keseluruhan proses dari proses awal yaitu menaci refernsi lokasi tempat kos, harga tempat kos, dan fasilitas yang di dapat, apakah sebanding atau tidak. Selain itu juga membandingkan antara tempat kos yang satu dengan yang lain. Jika dirasa tidak sesuai maka akan kembali  ke proses survei tempat kos lain yang telah ditentukan pada proses awal  
No Kriteria  Sub Kriteria  SP P KP TP 
1 Fasilitas Fasilitas utama (kasur, meja belajar, lemari, kursi)      
2 Fasilitas tambahan (internet, water heater, tv cable, AC)      
3 Fasilitas kos dengan kamar mandi dalam     
4 Fasilitas kos seperti ruang tamu, dapur, tempat untuk mencuci dan menjemur baju     
5 Fasilitas tempat parkir yang cukup luas      
6 Fasilitas listrik, dan air yang memadai (daya listrik cukup, air tidak susah)     
7 Fasilitas loundry (pakaian dicuci dan distrika-kan)     
8 Harga Harga sewa kos sudah termasuk dengan biaya lain (listrik, sampah, air)     
9 Sistem pembayaran yang flexible (bisa per bulan/ per tahun)     
10 Ada toleransi atas keterlambatan pembayaran     
11 Ada diskon jika melakukan pembayaran untuk satu tahun secara cash     
12 Lokasi Jarak dari kos ke kampus cukup terjangkau dengan  berjalan kaki     
13 Jarak dari kos ke kampus terjangkau dengan kendaraan umum/pribadi     
14 Kos dekat dengan akses yang diperlukan (warung makan, warnet, mini market, londry)     
15 Tempat kos dekat dengan  akses jalan raya dan transportasi umum       
16 Lingkungan Lingkungan kos yang bersih       
17 Kondisi bangunan terlihat baik dan terawat     
18 Tempat kos tidak rawan banjir     
19 Kenyamanan Kos yang ditempati kondusif untuk beristrahat dan belajar       
20 Respon pemilik/penjaga kos terhadap kerusakan fasilitas kos      
21 Keramahan pemilik/penjaga kos      
22 Reputasi Citra kos yang akan anda tempati      
23 Tempat kos ada jam malam     
24 Tempat kos aman dari pencurian       
25 Keberadaan tuan rumah, ibu kos/penjaga kos       
Memilih Tempat Kos Pada tahap ini merupakan tahap pemilihan akhir, tempat kos mana yang akan dipilih. 
Gambar 2. Flowchart Pemilihan Tempat Kos 
Setelah mendapatkan langkah-langkah dalam pemilihan kos,  dilanjutkan dengan proses perancangan kuesioner, serta proses penyebaran kuesioner yang dilakukan untuk mengumpulkan data yang akan digunakan dalam proses pengolahan data. Langkah yang dilakukan dalam perancangan serta penyebaran kuesioner ditunjukkan pada Gambar 3.  
Setelah menetapkan populasi dan sampel yang diuji, langkah selanjutnya adalah mempertimbangkan jenis kuesioner yang 
dipakai. Dalam penelitian ini, disebarkan kuesioner sebanyak satu kali. Kuesioner disusun dengan menggunakan pertanyaan 
tertutup untuk mengetahui langkah-langkah yang dilakukan oleh mahasiswa sebelum memilih tempat kos.   
Pertanyaan terbuka bertujuan untuk mengetahui kriteria yang mempengaruhi mahasiswa dalam memilih tempat kos. Pada kuesioner pertanyaan tertutup mengenai kriteria yang mempengaruhi pemilihan tempat kos dijawab menggunakan skala penilaian AHP. Skala penilaian AHP memiliki nilai  1, 3, 5, 
dan 7 dimulai dari tidak penting sampai sangat penting. Hal ini dikarenakan dalam kriteria tersebut dapat dilihat dari tingkat kepentingan terhadap minat dari sebuah tempat kos.   
Gambar 3. Flowchart Pemilihan Tempat Kos 
Dari kuesioner yang telah dibuat, digunakan empat pilihan yang harus dipilih salah satu. Empat pilihan tersebut diberi 4 jenis ranking poin yang sama dimana 7 = Sangat Penting (SP),  5 = Penting (P), 3 = Kurang Penting (KP), 1 = Tidak Penting (TP).  Penilaian dengan empat pilihan tersebut dilakukan untuk menghindari adanya kecenderungan responden untuk mengisi pilihan netral, yang dapat mengakibatkan hasil kuesioner yang telah disebarkan menjadi tidak dapat diolah.   Penggambaran mekanisme kerja model AHP menggunakan penyerdehanaan hirarki permasalahan pemilihan tempat  kos. Terdapat tiga level dalam hirarki tersebut, terdiri dari : 
a) Level 1 menunjukkan sasaran yang ingin dicapai. 
b) Level 2 menunjukkan beberapa kriteria yang digunakan 
untuk memilih tempat kos 
c) Level 3 menunjukkan alternatif tempat kos yang ada.  
Hasil kuesioner yang dilakukan terhadap mahasiswa ITHB  menunjukkan bahwa ada faktor kenyamanan menjadi kriteria yang dianggap kurang penting selain itu belum ada acuan yang dapat digunakan untuk melakukan penilaian terhadap kriteria 
kenyamanan. Sehingga hanya digunakan 5 kriteria utama, yaitu fasilitas, harga, lokasi, lingkungan, dan reputasi. Kriteria harga tidak dapat dijadikan sebagai perbandingan pada perhitungan AHP, maka kriteria harga akan dijadikan filter dalam memilih tempat kos. Oleh karena itu yang menjadi kriteria utama dalam sistem usulan adalah fasilitas, lokasi, lingkungan, dan reputasi. Masing-masing kriteria tersebut dibagi lagi ke dalam sub kriteria. Hirarki alternatif kriteria AHP ditunjukkan pada Gambar 4.
Gambar 4. Hirarki Alternatif Kriteria AHP   
Dari keseluruhan kriteria yang didapat kemudian dibagi menjadi masing-masing sub kriteria untuk penilaian sebuah tempat  kos, yaitu: 
1.Fasilitas dengan sub kriteria fasilitas utama dan fasilitas listrik, dan air yang memadai  
2.Lokasi dengan sub kriteria jarak dari kos ke kampus dan loksi kos dekat dengan akses jalan jalan raya dan transportasi umum (jalan protokol)  
3.Lingkungan dengan sub kriteria lingkungan kos yang bersih  dan tempat kos tidak rawan banjir 
4.Reputasi kos  
3. HASIL  
Pada tahap pengolahan data menggunakan metode AHP untuk mengetahui nilai bobot dari setiap kriteria yang didapat  
berdasarkan input yang ada dengan melihat seluruh nilai dari hasil kuesioner tersebut. Perhitungan dengan metode AHP ini 
mengikuti langkah-langkah metode AHP [12]. Pengolahan data hasil kuesioner menggunakan alat bantu Microsoft Excel dan metode Analityc Hierarchy Process  (AHP) untuk mendapatkan rekomendasi dari alternatif-alternatif tempat kos yang ada. Pengolahan ini bertujuan untuk mengetahui preferensi dari setiap kriteria yang didapat berdasarkan input dari mahasiswa yang diwakili oleh kuesioner dan sampel dari  populasi mahasiswa Sistem Informasi Institut Teknologi Harapan Bangasa (ITHB) Bandung. Dari setiap kriteria yang diprioritaskan mahasiswa dijadi kan kriteria dalam rekomendasi untuk pemilihan tempat kos tersebut, dengan melihat seluruh nilai dari hasil kuesioner tersebut. Langkah-langkah perhitungan metode Analytic Hierarchy Process  (AHP), ditunjukkan pada Gambar 5.  
Proses pembobotan dalam metode AHP terdiri dari:  
Pertama melakukan perhitungan terhadap bobot kriteria yang telah ditentukan untuk mencari masing-masing bobot dari setiap kriteria yang diinput sebelumnya.   
Kedua adalah proses perhitungan nilai dari setiap masing- masing alternatif tempat kos, untuk memperoleh rekomendasi tempat kos, dilakukan perhitungan terhadap bobot kriteria yang telah didapatkan sebelumnya dengan alternatif tempat kos. 
Terakhir setelah didapatkan hasil dari perhitugan terhadap masing-masing alternatif baru dilihat hasil yang paling tertinggi untuk  kemudian diurutkan untuk setiap alternatif yang diberikan. Sehingga menghasilkan output berupa rekomendasi tempat kos berdasarkan preferensi dari urutan tertinggi ke urutan terendah. Setelah mendapatkan kriteria dan sub kriteria yang digunakan dengan metode AHP sehnigga dapat memberikan rekomendasi tempat kos maka dikembangkan sistem rekomendasi dengan  sistem usulan yang ditunjukkan pada Gambar 6.  
Sistem rekomendasi tempat kos yang dikembangkan diawali  dengan memasukkan preferensi pengguna dari masig-masing kriteria. Sistem rekomendasi melakukan perhitungan dengan 
metode AHP dan menampilkan hasil rekomendasi berupa rangking dari tempat kos. 
Pengguna memasukkan preferensi dari masing-masing kriteria seperti ditunjukkan pada Gambar 8 dan sistem rekomendasi melakukan perhitungan dengan metode AHP dan menampilkan hasil rekomendasi berupa rangking dari tempat kos.  
Gambar 5. Flowchart Perhitungan AHP 
Flowchart Sistem Rekomendasi Tempat Kos
Output Proses Input
START
Pilih Preferensi 
Masing-Masing 
Kriteria
Menyusun Matrix 
Perbandingan 
Berpasangan
Menyusun Matrix 
Normalisasi 
Perbandingan 
Berpasangan dan Rata-ratanya
Uji Konsistensi:
#NAME?
#NAME?
Index (CI)
#NAME?
Ratio (CR)
KONSISTEN?
Bobot 
Kriteria
Menentukan Harga Kos
Konversi Nilai 
Alternatif
Menghitung Total 
Nilai Alternatif
Total Nilai 
Masing-masing 
Alternatif Pemilihan 
Alternatif dengan 
Total Nilai 
Tertinggi
Rangking 
Alternatif 
Kos YA
FINISH TIDAK 
Gambar 6. Flowchart Sistem 
Aktor yang berinteraksi dengan sistem rekomendasi tempat kos terdiri dari admin dan user atau pengguna yang memerlukan 
rekomendasi tempat kos. Interaksi antara aktor dan sistem 
rekomendasi digambarkan dengan use case diagram  [13] 
ditunjukkan pada Gambar 7.   
Gambar 7. Use Case Diagram  Sistem Rekomendasi  
Sistem rekomendasi tempat kos dikembangkan dengan PHP dan 
database MySQL [14]. Perancangan sistem rekomendasi tempat 
kos meliputi perancangan database dengan membuat skema relasi [14] ditunjukkan pada Gambar 8 dan user interface. 
Database terdiri dari 2 tabel yaitu tempat kos dan nilai kriteria.  
Gambar 8. Skema Relasi Sistem Rekomendasi Tempat Kos  
Pengujian sistem rekomendasi tempat kost dilakukan dengan 
blackbox testing  [15]. Graphical User Interface  (GUI) input preferensi dari kriteria pemilihan kos ditunjukkan pada Gambar 9.  
Gambar 9. Input Preferensi Sistem Rekomendasi Tempat Kos 
Berdasarkan input preferensi yang dimasukkan pengguna pada 
Gambar 9 dilanjutkan perhitungan dengan metode AHP dan menghasilkan rekomendasi tempat kost berupa rangking 
ditunjukkan pada Gambar 10. Rangking pertama merupakan 
tempat kos yang paling direkomendasikan yang artinya paling  
sesuai dengan kriteria pengguna. 
Gambar 10. Hasil Rekomendasi Tempat Kos 

4. PEMBAHASAN 
Pada pembahasan ini menjelaskan contoh perhitungan untuk 
menghitung perbandingan antar kriteria, dan dapat dilihat  bahwa tiap kriteria memiliki tingkat kepentingan berbeda dengan menggunakan skala perbandingan berpasangan pada Tabel 3.  
Tabel 3. Skala Perbandingan Berpasangan   
Pada Tabel 3, terdapat lima enam perbandingan berpasangan 
yang perlu diberikan penilaian berdasarkan rumus judgmen t 
nÃ—(n-1)/2. Dimana n adalah jumlah kriteria yang ada yait u 4 kriteria, jadi perhitungannya adalah nÃ—(n-1)/2 = 4Ã—(4-1)/2 = 6 perbandingan berpasangan.  
Tabel  4. Perbandingan Berpasangan Kriteria Utama 
Fasilitas Utama  Listrik, Air Jarak ke Kampus Akses Jalan Protokol Kebersihan Lingkungan Lingkungan Alam (TP) Reputasi (SPS) Fasilitas Utama (SP) 
1,0000 0,3333 0,2000 0,1429 0,1111 0,1429 0,2000 
Listrik, Air (SPS) 3,0000 1,0000 0,6000 0,4286 0,3333 0,4286 0,6000 
Jarak ke Kampus (STP) 5,0000 1,6667 1,0000 0,7143 0,5556 0,7143 1,0000 
Akses Jalan Protokol (P) 7,0000 2,3333 1,4000 1,0000 0,7778 1,0000 1,4000 
Kebersihan (P) 9,0000 3,0000 1,8000 1,2857 1,0000 1,2857  
Lingkungan Alam (TP) 7,0000 2,3333 1,4000 1,0000 0,7778 1,0000 1,4000 
Reputasi (SPS) 5,0000 1,6667 1,0000 0,7143 0,5556 0,7143 1,0000 
Total Nilai 37,0000 12,3333 7,4000 5,2857 4,1111 5,2857 7,4000  
Langkah selanjutnya adalah membuat normalisasi kriteria 
berpasangan. Tabel 4 merupakan hasil perhitungan normalisasi kriteria berpasangan.   
Nilai W = (0.0811
Untuk menguji konsistensi dari hasil yang didapat maka: 
1.Hitung Nilai Î»maks= 4 
2.Consistency Index = 0.00 
3.Random Index = 0.9 
4.Consistency Ratio = 0.00  
Consistency Ratio yang didapat sama dengan nol sehingga nilai eigen vector  dikatakan konsisten. Hasil perhitungan ditunjukkan pada Tabel 5.  
Untuk menghitung bobot pada setiap alternatif, langkah pertama yang dilakukan, yaitu memberikan nilai terhadap setiap  alternatif berdasarkan kriteria yang dimiliki oleh harga tempat kos. Pada proses penilaian ini, nilai yang diberikan berdasarkan atribut asli yang dimiliki oleh tempat kos dengan harga >Rp 1.250.000 . Hasil perhitungan ditunjukkan pada Gambar 11.  
Konversi ke dalam nilai AHP Nilai Kepentingan Kriteria 
1 TP (Tidak Penting) 
3 KP (Kurang penting) 
5 P (Penting) 
7 SP (Sangat Penting) 
9 MP (Mutlak Penting) 
Tabel  5. Perhitungan Normalisasi Kriteria Utama 
Fasilitas Utama  Listrik, Air Jarak ke Kampus Akses Jalan Protokol Kebersihan Lingkungan Lingkungan Alam (TP) Reputasi (SPS) Fasilitas Utama (SP) 
0,0270 0,0270 0,0270 0,0270 0,0270 0,0270 0,0270 
Listrik, Air (SPS) 0,0811 0,0811 0,0811 0,0811 0,0811 0,0811 0,0811 
Jarak ke Kampus (STP) 0,1351 0,1351 0,1351 0,1351 0,1351 0,1351 0,1351 
Akses Jalan Protokol (P) 0,1892 0,1892 0,1892 0,1892 0,1892 0,1892 0,1892 
Kebersihan (P) 0,2432 0,2432 0,2432 0,2432 0,2432 0,2432 0,2432 
Lingkungan Alam (TP) 0,1892 0,1892 0,1892 0,1892 0,1892 0,1892 0,1892 
Reputasi (SPS) 0,1351 0,1351 0,1351 0,1351 0,1351 0,1351 0,1351 
Total Nilai 1,0000 1,0000 1,0000 1,0000 1,0000 1,0000 1,0000  
Gambar  11. Contoh Matriks Kriteria Alternatif  
Dari perkalian antara kriteria dan bobot maka didapat hasil akhir alternatif tempat kos dengan peringkat ditunjukkan pada Gambar 11, sebagai berikut: 
1. Kos Dago asri E4 
2. Kos Tubagus 9 
3. Kos Cisitu Lama IX No. 15 
4. Kos Tubagus 88 
5. Kos Tubagus 30 
6. Kos Tubagus Dalam 5 
7. Kos Tubagus XIII/4 
Gambar 11. Matriks Bobot Alternatif Kost untuk Setiap Kriteria
 
5. KESIMPULAN 
Sistem rekomendasi tempat kos dilakukan dengan melakukan 
filter input harga tempat kos dan penilaian terhadap kriteria preferensi fasilitas utama, ketersediaan listrik dan air,  jarak tempat kos ke kampus, akses tempat kos ke jalan protokol, kebersihan tempat kos, lingkungan keadaan banjir dan reputasi yang telah ditentukan oleh user.  Hasil pengujian aplikasi dengan metode AHP menghasilkan perhitungan yang konsisten antara perhitungan manual dengan bantuan Microsoft Excel dengan perhitungan menggunakan aplikasi. Hasil pengujian yang dilakukan membuktikan adanya perbedaan preferensi terhadap kriteria yang dipilih berpengaruh terhadap hasil urutan rangking  rekomendasi alternatif yang diberikan. 

DAFTAR PUSTAKA 
[1] ITHB. 2019. Housing Referral. [Online] ithb.ac.id. Tersedia di http://ithb.ac.id/indekos/  [2019, Februari 28]. 
[2] Silvia Yolanda Sastanti, Charitas Fibriani. 2019. Analisis Tingkat Permukiman Kumuh Menggunakan Metode AHP Berbasis SIG pada Kota Magelang, Jurnal Nasional Teknologi dan Sistem Informasi, Vol. 05 No. 01 (2019). 
[3] Kotler, Philip dan Gary Amstrong. 2001. Principles of 
Marketing. Jakarta: Erlangga. 
[4] Haryadi, Wahyu. 2009. Faktor-faktor yang Menjadi Pertimbangan Perilaku Konsumen dalam Memilih Tempat Kos (Studi Kasus pada Mahasiswa Fakultas Ekonomi Universitas Negeri Malang Angkatan Tahun 2006). Skripsi. Fakultas Ekonomi Universitas Negeri Malang. 
[5] Saputro, Trio Hendhi. 2010. Pengaruh Pelayanan Dan Citra 
Terhadap Kepuasan Konsumen Melalui Keputusan Pembelian Sebagai Variabel Intervening Pada Hotel Ungaran Cantik Di Kabupaten Semarang. Skripsi. Fakultas Ekonomi Universitas Negeri Semarang. 
[6] Maulidah, Mustika Sari. 2011. Faktor-Faktor yang Dipertimbangkan Mahasiswa dalam Memilih Kos. Skripsi.  Fakultas Ilmu Sosial dan Politik Universitas Pembangunan 
Nasional â€œVeteranâ€ Jawa Timur. 
[7] Nilakusmawati, Siti Hajar, Made Susilawati, D.P.E. 2012. 
Faktor-faktor Yang Mempengaruhi Keputusan Mahasiswa Dalam Memilih Rumah Kos. Jurnal. Fakultas MIPA Universitas Udayana Alternatif KosKetersediaan Fasilitas Umum Kejadian Mati Listrik, Air Jarak kos ke kampus Jarak ke Jalan Protokol Ketersediaan Tempat Sampah Kejadian Banjir Kejadian Pencurian
Kos 27 Tubagus XII/14 40 10 10 30 20 20 20
Kos 28 Tubagus Dalam 5 30 20 20 10 20 40 40
Kos 29 Dago Asri E4 30 20 30 40 50 40 40
Kos 30 Cisitu Lama15 10 20 20 40 50 40 40
Kos 31 Tubagus 88 40 10 20 30 50 40 40
Kos 32 Tubagus 9 40 10 10 40 50 40 40
Kos 33 Tubagus 30 40 10 10 40 20 40 40
Alternatif Kos Ketersediaan Fasilitas Umum Kejadian Mati Listrik, Air Jarak kos ke kampus Jarak  ke Jalan Protokol Ketersediaan Tempat Sampah Kejadian Banjir Kejadian Pencurian Total Nilai Rangking
Tubagus XII/14 1,0800 0,8110 1,3510 5,6760 4,8640 3,7840 2,7020 20,2680 7
Tubagus Dalam 5 0,8100 1,6220 2,7020 1,8920 4,8640 7,5680 5,4040 24,8620 6
Dago Asri E4 0,8100 1,6220 4,0530 7,5680 12,1600 7,5680 5,4040 39,1850 1
Cisitu Lama 15 0,2700 1,6220 2,7020 7,5680 12,1600 7,5680 5,4040 37,2940 4
Tubagus 88 1,0800 0,8110 2,7020 5,6760 12,1600 7,5680 5,4040 35,4010 3
Tubagus 9 1,0800 0,8110 1,3510 7,5680 12,1600 7,5680 5,4040 35,9420 2
Tubagus 30 1,0800 0,8110 1,3510 7,5680 4,8640 7,5680 5,4040 28,6460  
Evasaria Magdalena Sipayung  https://doi.org/10.25077/ TEKNOSI.v7i2.2021.52-60  60[8] Erna Daniati. 2015. Sistem Pendukung Keputusan Pemilihan Kost di Sekitar Kampus UNP Kediri Menggunakan Metode Simple Additive Weighting (SAW). Seminar Nasional Teknologi Informasi dan Multimedia. 
[9] Sugianto, Herik, Yulianti, Hengky Anra. 2016. Sistem 
Pendukung Keputusan Pemilihan Tempat Kost Khusus Mahasiswa dengan Metode AHP dan TOPSIS Berbasis Web (Studi Kasus : Kota Pontianak). Jurnal Sistem dan Teknologi Informasi (JUSTIN) Vol. 1, No. 1, (2016). 
[10] Putra Aditya Primanda , Edy Santoso, Tri Afirianto. 2018. Pemilihan Kost di Sekitar Universitas Brawijaya menggunakan Metode Analitycal Hierarchy Process (AHP) dan Simple Additive Weighting (SAW). Jurnal Pengembangan Teknologi Informasi dan Ilmu Komputer.  Vol. 2, No. 6, Juni 2018, hlm. 2094-2103. 
[11] Pramudityo, Bastian. 2018. Sistem Pendukung Pengambilan 
Keputusan Pemiliahn Tempat Kost Menggunakan Google Map API dengan Metode Promethee. Skripsi. Fakultas Sains dan Teknologi Universitas Sanata Dharma Yogyakarta. 
[12] Saaty, T.L. 1994. Fundamental of Decision Making and 
Priority Theory with the Analytic Hierarchy Process. RWS  
Publications. 
[13] N. Adi, Rational Rose untuk Pemodelan Berorientasi Objek, Informatika, 2005. 
[14] S. Avi, Henry F. Korth, dan S. Sudarshan, Database System Concepts, 6th edition, McGraw-Hill Education, 2010. 
[15] Y. Kustiyahningsih, D. Rosa, Pemrograman Basis Data 
Berbasis Web Menggunakan PHP dan Mysql, Yogyakarta: Graha Ilmu, 2011.  
[16] Mustaqbal, M.S.M., Firdaus, R.F.F., dan Rahmadi, H.R. 
Pengujian Aplikasi Menggunakan Black Box Testing Boundary Value Analysis (Studi Kasus Aplikasi Prediksi 
Kelulusan SNMPTN). Jurnal Ilmiah Teknologi Terapan 
(JITTER), 2015

BIODATA PENULIS 
Evasaria Magdalena Sipayung 
Menerima gelar Sarjana Teknik dari Sekolah Tinggi Teknologi 
Telkom Bandung Jurusan Teknik Informasi pada tahun 2003, dan 
gelar Magister Teknik dari Institut Teknologi Bandung, Sekolah Tinggi Elektro Indonesia (STEI) pilihan Teknologi Informasi pada tahun 2007.  
Cut Fiarni 
Menerima gelar Sarjana Teknik dari ITB Jurusan Fisika pada  
tahun 1999, dan gelar Magister Teknik dari Sekolah Tinggi 
Elektro Informatika (STEI) ITB jurusan Teknologi Informasi pada tahun tahun 2005.  
Sherly Sutopo 
Menerima gelar Sarjana Komputer dari Institut Teknologi Harapan Bangsa Program Studi Sistem Informasi pada tahun 
2016.",sistem rekomendasi,"AHP, Analytical Hierarchy Process",kos di sekitar daerah ITHP,
SISTEM REKOMENDASI  KREDIT PERUMAHAN RAKYAT DENGAN MENGGUNAKAN METODE COLLABORATIVE FILTERING ,"SISTEM REKOMENDASI  KREDIT PERUMAHAN RAKYAT DENGAN MENGGUNAKAN METODE COLLABORATIVE FILTERING 

AGUS PAMUJI  

Abstrak
Di kota besar seperti Jakarta, Bandung, Surabaya, dan lainnya, kebutuhan akan tempat tinggal memiliki peranan sangat penting ketika menunjang kebutuhan bisnis. Contoh 
kebutuhan bisnis itu sendiri ada lah tempat bekerja, berdagang dan sebagainya. Meskipun demikian, kebutuhan akan rumah atau tempat tinggal dikota besar seperti Jakarta dan 
sekitarnya sulit untuk menentukan lokasi. Hal ini menjadi alasan agar setiap orang ingin terbebas dari kemacetan. Disamping itu, lahan di Jakarta sangat terbatas, sehingga sebagian orang akan memilih lokasi di  sekitar kota Jakarta seperti Tang erang, Bekasi, Depok, dan Bogor. Sistem rekomendasi akan membantu merekomendasikan kepada pencari tempat tinggal agar mudah mencarinya. Oleh sebab itu, didalam penelitian ini akan membuat  sistem rekomendasi dengan menggunakan metode Collaborative Filtering. Hasil penelitian ini menunjukan bahwa hasil prediksi rating setiap developer  untuk masing-masing pengguna  dengan menggunakan metode collaborative filtering kurang efektif. Hal tersebut menunjukan bahwa semakin banyak jumlah data yang digunakan dan jika terdapat pengguna yang belum pernah merating , maka sistem yang dihasilkan relatif tidak akurat dan menghasilkan rekomendasi yang tidak efektif.  
 
Kata kunci : Sistem Rekomendasi, Rumah, Coll aborative Filtering, Merating, Kredit  
 
Abstract 
A large city such as Jakarta, Bandung, Surabaya, and others, the need for somewhere to stay has a very important role when supporting business needs.  For Examples of business requirement itself is a place of  work, trade and so on.  , However, the need for home or place of residence big cities like Jakarta and surrounding areas is difficult to determining the location. This is the reason that everyone wants to be free from congestion.  In addition, the land in Jakarta is very limited, so most people will choose locations around the city such as Tangrang Jakarta, Bekasi, Depok, and Bogor. Recommendation system will help recommend to search this study  will make a recommendation system using Collaborative Filtering. These results indicate that the predicted outcome rating of each developer for each user by using collaborative filtering methods are less effective.  It shows that the more the amount of data used and if there are users who have never rate a, then the resulting system is relatively inaccurate and resulted in a recommendation that is not effective.  
 
Keywords: Recommendation System, House, Collaborative Filtering, rate a, Credit   

PENDAHULUAN  
Di kota besar seperti Jakarta, Bandung, Surabaya, dan lainnya, kebutuhan akan tempat tinggal memiliki peranan sangat penting ketika menunjang kebutuhan bisnis. Contoh kebutuhan bisnis itu sendiri adalah tempat bekerja, berdagang dan sebagainya. Meskipun demikian, kebutuhan akan rumah atau tempat tinggal dikota besar seperti Jakarta dan sekitarnya sulit untuk menentukan lokasi. Hal ini menjadi alasan agar setiap orang ingin terbebas dari kemacetan. Di  samping itu, lahan di Jakarta sangat terbatas, sehingga sebagian orang akan memilih lokasi di  sekitar kota Jakarta seperti Tang erang, Bekasi, Depok, dan Bogor. Sejumlah tempat tinggal tentu selain letak yang strategis, bebas banjir, bebas kemacetan, serta akses jalan menuju ibu kota sebagai pusat  bisnis menjadi pertimbangan. Terkait dengan meningkatn ya keb utuhan tempat tinggal banyak pengembang properti yang ingin berusaha menawarkan dan menyediakan hunian atau tempat tinggal baik melalui sistem pembayaran kredit maupun tunai. Namun, banyak pembeli yang ingin memilih tempat tinggal sulit bahkan ragu-ragu untuk memilih pengembang begitupula tempat atau lokasi yang akan dihuni. Kesulitan dan keraguan yang dialami pembeli adalah keterbatasan informasi pengembang yang terpercaya dan ditambah kurangnya pengalaman dalam  membeli rumah untuk tempat tinggal. Oleh sebab itu, pembeli ingin mencari dan menerima saran, bagaimana, dimana, dan apa yang diharuskan pembeli ketika ingin membeli rumah.  Berdasarkan kondisi dan fenomena diatas, penelitian ini akan membahas penerapan sistem  rekomendasi yang dapat membantu, menjelaskan, menggambarkan, memberikan informasi serta saran kepada pengguna sebagai pembeli rumah untuk memilih tempat tinggal yang dikehendakimnya. Sistem rekomendasi telah hadir dan digunakan secara luas oleh hampir semua area bisnis dimana orang atau konsumen memerlukan informasi sebagai saran untuk membuat keputusan  (Moh.  Irfan, 2014: 77).  Penelitian ini yang didalamnya berkaitan dengan tempat tinggal maka akan muncul rumusan masalah yaitu bagaimana membuat sistem rekomendasi untuk membantu pengguna atau pembeli untuk membeli rumah sebagai tempat tinggal. Selanjutnya, bagaimana sistem rekomendasi memberikan nilai yang memiliki akurasi yang cukup tinggi sehingga dapat dipercaya oleh pengguna atau pembeli.  
Sistem Rekomendasi  
Sistem rekomendasi adalah sebuah alat perangkat lunak dan teknik-teknuik yang menyediakan saran untuk item -item yang paing memungkinkan menarik untuk pengguna tertentu  (Francesco Ricci, 2015, 1) . Selanjutnya, Sistem rekomendasi merupakan sebuah  (web) alat personalisasi yang menyediakan pengguna sebuah informasi daftar item-item yang sesuai dengan keinginan masing-masing pengguna  (Moh. Irfan, 2014 : 77). Sugesti atau saran berkaitan dengan proses membuat keputusan beraneka macam. Contohnya item apa yang dibeli, musik apa yang didengar, berita online  apa yang dibaca.  
Item adalah pengertian umum yang digunakan pengguna untuk menunjukan sistem rekomendasi apa untuk pengguna. Sebuah Recomender system  (RS) secara  nomal fokus pada item khusus ( contoh CD  atau berita). Demikian juga perancangannya, tampilan antar muka peggunanya, dan inti teknik rekomendasi digunakan untuk menghasilkan rekomendasi untuk semua disesuaikan untuk memberikan saran yang berguna, dan  saran efektif untuk jenis item tertentu.  Sistem Rekomendasi terutama diarahkan terhadap individu yang secara personal kurang memiliki pengalaman atau kompetensi untuk mengevaluasi secara potensial item Faktor yang ber lebihan. Sebagai contoh, mungkin menawarkan. Contoh utama adalah buku sistem rekomendasi ya ng membantu pengguna dalam memilih buku untuk dibaca. Pada situs web terkenal contohnya amazon.com , situs yang menggunakan sistem rekomendasi untuk penyimpanan personal online  untuk setiap pelanggan.  Semenjak sistem rekomendasi yang biasanya pribadi, peng guna yang berbeda atau keuntungan kelompok pengguna yang beragam. Hal ini adalah jauh lebih mudah untuk menghasilkan dan biasanya ditampilkan dalam majalah atau koran. Contoh khas seperti buku dan CD.  Sementara mungkin berguna dan efektif dalam situasi ter tentu, jenis rekomendasi non-pribadi tidak bisa diselesaikan dengan penelitian RS . Sistem rekomendasi terdapat dua pendekatan yang umumnya digunakan dalam membuat sitem rekomendasi. Pertama,  content based filtering  merupakan metode yang bekerja dengan mencari kedekatan suatu item yang akan direkomendasikan ke penguna dengan item  yang telah diambil oleh pengguna sebelumnya berdasarkan kemiripan antar kontennya. Namun, sistem rekomendasi berbasis konten ini masih memiliki kelemahan, yaitu karena semua informasi dipilih dan direkomendasikan berdasarkan konten, maka pengguna tidak mendapatkan rekomendasi pada jenis konten yang berbeda. Selain itu, sistem rekomendasi ini kurang efektif untuk pengguna pemula, karena pengguna yang masih pemula tidak mendapat masukan dari pengguna sebelumnya. Pendekatan atau metode kedua adalah collaborative filtering . Pendekatan ini untuk menutup kelemahan dari content based . Sistem collaborative filtering  adalah metode yang digunakan untuk memprediksi kegunaan item berdasarkan peni laian pengguna sebelumnya . Collaborative filtering  melakukan penyaringan data berdasarkan kemiripan karakteristik konsumen  sehingga mampu memberikan informasi yang baru kepada konsumen karena sistem memberikan informasi berdasarkan p ola satu kelompok konsumen yang hampir sama (Shofwatul Uyun, 2011) .  Secara umum proses pemberian rekomendasi terdiri atas tiga langkah, yaitu:  penemuan similar user, pembuatan ketetanggaan ( neighborhood ), dan penghitungan prediksi berdasarkan tetangga yang dipilih (Shofwatul Uyu n, 2011) . Collaborative filtering menghasilkan prediksi atau rekomendasi bagi pengguna atau pelanggan yang dituju terhadap satu item atau  lebih. Item dapat terdiri atas apa saja yang dapat disediakan manusia seperti misalnya buku, film, seni, artikel, atau  tujuan wisata. Rating dalam collabora tive filtering dapat berbentuk, model rating skalar yang terdiri atas rating numerik seperti 1 sampai 5,  model rating biner dengan memilih antara setuju atau tidak setuju atau dapat pula baik atau buruk, serta rating unary dapat  mengindikasikan bahwa pengguna telah mengobservasi atau membeli item atau merating item dengan positif  (Shofwatul Uyun, 2011).   
Algoritma Collaborative Filtering  
Didalam metode collaborative filtering, Schafer membagi kedalam dua kelas yang berbeda menurut teori dan kepraktisannya, yaitu algoritma non-probabilistik dan algoritma probabilistik. Suatu algori tma dianggap probabilistik bila algoritma tersebut berdasarkan model probabilistik  (Jannach dkk, 2011) . Algoritma tersebut mewakili distribusi  probabilitas saat menghitung prediksi rating atau daftar rangking rekomendasi. Algoritma non-probabilistik yang terkenal yaitu nearest neighbours algorithm. Algoritma ini dibagi menjadi  dua kelas yaitu user-based dan item-based (Schafer dkk, 2007).   
a. User-Based Collaborative Filtering  
User-based nearest neighbour algorithm menggunakan teknik statistika untuk menemukan sekumpulan pengguna, dikenal sebagai tetangga (neighbour), yang memiliki sejarah setuju dengan penggun a yang menjadi sasaran. Setelah sekum pulan 
tetangga terbentuk, sistem menggunakan algoritma yang berbeda untuk menggabungkan kesukaan neighbours untuk menghasilkan prediksi atau rekomendasi N-teratas untuk active user. (Sarwar dkk, 2001) >> shofwatul . 
b. Item-to-Item Collaborative Filtering  
Item-based collaborative filtering merupakan metode rekomendasi yang didasari  atas adanya kesamaan antara pemberian rating terhadap suatu produk dengan produk yang dibeli. Dari tingkat kesamaan  produk, kemudian dibagi dengan parameter kebutuhan pelanggan untuk  memperoleh nilai kegunaan produk. Produk yang memiliki nilai kegunaan terti nggilah yang kemudian dijadikan rekomendasi (Purwanto, 2009)  
 
METODE  
Di bawah ini merupakan diagram pemrosesan sistem rekomendasi menggunakan item based collaborative filtering :   
Gambar 1. Metode Dan Rancangan Sistem Rekomendasi   
Pertama dimulai dari pengumpulan nilai rating dari setiap pengguna, kemudian nilai rating tersebut dibuat dalam kolom matriks atau tabel. Setiap nilai rating akan dibuat nilai rata-rata rating dan selanj utnya akan dihitug similarity item-rating. Dasar perhitungan similarity pada ite m-based collaborative filtering antara dua buah item i dan j adalah dengan mencari user mana saja yang telah memberi rating pada item i dan j lalu gunakan metode perhitungan similarity (Kurniawan, 2016). Metode pearson correlation based similarity merupakan metode perhitungan berbasis korelasi yang paling banyak diimplementasikan untuk perhitungan nilai similarity. Korelasi Pearson mengukur seberapa besar hubungan linear antara dua variabel. Koefisien korelasi 
Pearson berasal dari model regresi linier yang memiliki asumsi yaitu bahwa hubungan antara dua variabel  harus linier, dengan kesalahan harus independen dan memiliki distribusi  probabilitas dengan mean 0 dan varians  (berdist ribusi Normal (0,1). ( Aggarwal, 2015 ) Metode pearson correlation-based similarity ditunjukkan oleh Persamaan  Cosine similarity merupakan metode yang sering digunakan untuk menghitung kesamaan pengguna, tetapi metode ini memiliki satu kekurangan. Perbeda an skala rating antara 
berbagai pengguna akan menghasilkan simarity yang sangat berbeda. Sebagai cont oh, user A merating developer  terbaik dengan rating 4 dan tidak pernah member rating 5 pada developer yang lain , dan memberi rating 1 pada developer terjelek, tidak sesuai dengan tingkat standar rating yaitu 2. Tetapi user B selalu  merating sesuai dengan tingkat standar, memberi rating 5 pada developer  terbaik, dan 2 pada developer  yang jelek. Jika menggunakan cosine 
similarity, keduanya sangat berbeda. Adjusted cosine  similarity mengatasi kelemahan dari cosine similarity (Djamal, 2010) . Metode Cosine similarity dapat ditunjukkan oleh Persamaan   Metode weighted average  of deviation yang didapat dari rata-rata item yang telah dirating merupakan metode yang di gunakan untuk prediksi rating pada item k yang  telah dirating. Rumus berikut ini merupakan perhitungan prediksi rating pada item l untuk user u.  Metode perhitung an prediksi weighted average of deviation masih kurang dapat diimplimentasikan pada masalah item baru yang  belum dirating karena  Rk yang merupa kan nilai rata-rata pada item k akan bernilai nol (karena belum ada yang memberi rating). Oleh karena itu digunakan metode weighted sum untuk menghitung prediksi rating pada kasus item bar u. Akurasi sistem  rekomendasi dilihat berdasarkan nilai mean absolute error (MAE), yaitu rata-rata dari error yang di absolutkan. Dimana error merupakan selisih dari nilai rating  sebenar nya dengan nilai rating hasil prediksi.  Berikut adalah perhitungan MAE yang ditunjukkan  oleh Persamaan.  
 
HASIL DAN PEMBAHASAN   
Dalam penelitian ini dilakukan  beberapa pengujian, hasil pengujian  yang di peroleh tersebut adalah sebagai  berikut:  Pada uji coba 1 dilakukan  pengujian dengan data yang digunakan  sebanyak 3 pengguna  dan 5 developer dengan  besarnya rating yang berfariasi. Dari  hasil uji  coba 1 dapat disimpulkan bahwa  hasil predi ksi yang dihasilkan oleh system  cukup akurat di buktikan oleh  kecilnya MAE yang diberikan oleh  sistem.   
Tabel  1. Rating pengguna terhadap developer  
Hasil prediksi Pengguna  
Pengguna 1  Pengguna 2  Pengguna 3  Developer  
1 4 8 4 
2 6 3 1 
3 1 7 7 
4 4 3 6 
5 8 7 2  
Proses pertama adalah mencari nilai rata-rata rating developer sebagaimana disajikan pada tabel 2.   
Tabel 2. Rata -rata rating developer 
Hasil prediksi Pengguna Rata-rata rating  Pengguna 1  Pengguna 2  Pengguna 3  Developer  
A 4 8 4 5,33 
B 6 3 1 3,33 
C 1 7 7 5,00 
D 4 3 6 4,33 
E 8 7 2 5,67  
Langkah kedua adalah mencari nilai rating â€“ (rata-rata rating) lalu dikuadratkan. Langkah ketiga adalah  mencari jumlah dari n ilai rating -(rata-rata rating)2 perbuku dan selanjutnya diakarkan. Terlihat seperti pada Tabel 3.   
Tabel 3.  Jumlah rating -(rata-rata rating)2 perbuku  Sum (rating - (rata-rata rating)2)  Akar Sum  (rating -(ratarata rating)2)  
10,67  3,2660  
12,67  3,5590  
24,00  4,8990  
4,67 2,1602  
20,67  4,5461  
Langkah keempat menghitung similariy antar buku dengan persamaan rumus dibawah . Terlihat seperti pada Tabel  
Tabel 4. Nilai Similarity Pearson  
sim(A,B)  -2,88889  
sim(A,C)  10,66667  
sim(A,D)  -5,333 33 
sim(A,E)  5,333333  
sim(B,C)  -11,3333  
sim(B,D)  -8,22222  
sim(B,E)  10,05556  
sim(C,D)  3,666667  
sim(C,E)  -4,59259  
sim(D,E)  -8,66667   
Setelah diketahui nilai dari similarity antar buku, langkah selanjutnya adalah menghitung nilai prediksi buku terhadap  user. Hasil dari prediksi manual dapat diimplimentasi kedalam Tabel .  
Tabel 5. Hasil Prediksi Uji Coba ke 1  Hasil prediksi  Pengguna Pengguna 1 Pengguna 2 Pengguna 3  Developer  
1 9,33  13,33  9,33  
2 9,33  6,33  4,33  
3 6,00  12,00  12,00  
4 8,33  7,33  10,33  
5 13,67  12,67  7,67   
Selanjutnya dari nilai hasil prediksi akan menghasilkan nilai MAE sebagai berikut :  
Tabel 6 Hasil Mean Absolute Error ( MAE ) sistem uji coba 1  
Nama Developer  Nilai MAE  
Developer 1  3,33 
Developer 2  3,67 
Developer 3  6,33 
Developer 4 3,00 
Developer 5  5,33  
Uji MAE tersebut akan dilakukan sebanyak 5 kali dan hasilnya ditunjukan pada tabel 7 dibawah ini : 
Tabel 7. Hasil Uji MAE  
Nama Developer  Nilai MAE  
Uji 1  4,89 
Uji 2  4,22 
Uji 3  3,67 
Uji 4  4,22 
Uji 5  6,44 
Gambar 2 . Hasil M AE Uji 1,2,dan 3  
 
PENUTUP  
Simpulan  
Berdasarkan hasil penelitian yang dilakukan bahwa dapat simpulkan diantaranya : Metode collaborative filtering  dapat diterapkan  dalam pembuatan sistem rekomendasi Kredit Perumahan  Rakyat khususnya  memilih developer  dengan  melihat kedekatan developer  berdasarkan nilai rating. Metode ini lemah ketika diimplementasikan pada developer yang baru yang belum pernah dirating sama sekali. Hasil prediksi rating setiap developer  untuk masing-masing pengguna  dengan menggunakan metode collaborative filtering kurang efektif. Hal ini ditunjukkan berdasarkan rata-rata nilai MAE ( Mean Absolute Error ). Hal ini menunjukkan bahwa semakin banyak jumlah data yang digunakan dan jika terdapat peengguna  yang belum pernah merating, maka sistem yang dihasilkan relatif tidak akurat dan menghasilkan rekomendasi yang buruk   
Saran  
Penelitian selanjutnya, metode collaborative filtering diharapkan agar daat diterapkan dan diaplikasikan  pada data yang memiliki item yang  cukup  banyak dirating oleh setip pengguna. Apabila terdapat data yang banyak dan memiliki item baru yang sedikit di -rating oleh setiap pengguna , maka diperlukamn  menggunakan metode yang lebih efektif  dari collaborative filtering, misalnya adalah ICHM ( Item-Based Clustering Hybrid Method ). ICHM  (Item-Based Clustering Hybrid Method ) adalah salah satu metode yang menggunakan pendekatan hybrid atau menggabungkan kedua pendekatan yaitu Content Based Filtering  dan Collaborative Filtering . 

DAFTAR PUSTAKA  
Aggarwal, C. C. (2016). Recommender Syste m. New York: Springer.  
Arias, J. J., Vilas, A. F., & Redondo, R. P. (2012). Recomender System for the wb social . Verlag Heidelberg: Springer.  
Christanti, M., & Hadiguna, C. (2011). Aplikasi E -Commerce dengan Sistem Rekomendasi Berbasis Collaborative Filter ing pada Toko Komputer Ekaria . Jurnal Informatika, 7 (2), 157 -175. 
Fernanda, F., Yuhana, U. L., & Purwitasari, D. (2013). Rancang Bangun Aplikasi Pengelompokan dan Pemberi Rekomendasi Berita Lomba Online Menggunakan Klasifikasi Fuzzy Berbasis Kerangka Kerja  Spring . JURNAL 
TEKNIK POMITS, 2 (1), A105 -A110.  
Irfan, M., C, A. D., & R, F. H. (2014). Sistem Rekomendasi : Buku online Dengan Metode Collaborative Filtering . JURNAL TEKNOLOGI TECHNOSCIENTIA, 7 (1), 76 -84. 
Jannach, D., Zanker, M., Felfernig, A., & Freidrich , G. (2011). An Introduction Recomender System . Cambridge: Cambridge University Press.  
Kurniawan, A. (2016). Sistem Rekomendasi Produk Sepatu Dengan Menggunakan Metode Collaborative Filtering . Seminar Nasional Teknologi Informasi dan Komunikasi 2016 (SENTI KA 2016)  (hal. 610 -614). Yogyakarta: Sentika.  
Negre, E. (2015). Information and Recommender System . New York: John & Willey.  
Neuman, A. W. (2009). Recommender Systems for Information Providers . Verlag Heidelberg: A Springer Company.  
Oktora, R., & Susanty, W. (2012). Perancangan Aplikasi E -Commerce Dengan Sistem Rekomendasi Item -Based Collaborative Filltering . Jurnal Manajemen sistem Informasi Dan Teknoligi , 29-42. 
Ricci, F., Rokach, L., & Shapira, B. (2015). Recommender System Handbook . New York: 
Springer.  
Utomo, B., & Suhari, Y. (2013). Rekomendasi Film Berbasis Web Pada Bioskop Mini Menggunakan Algoritma Nearest -Neighbor . Dinamika Informatika, 5 (1), 26 -39. 
Uyun, S., Fahrurozi, I., & Mulyanto, A. (2011). Item Collaborative Filtering untuk Rekomendasi Pembel ian Buku secara Online . JUSI, 1 (1), 63 -70.",sistem rekomendasi,"collaborative filtering, cosine similarity",pengguna dan developer,"MAE, Similarity Pearson"
Sistem Rekomendasi Produk Pena Eksklusif Menggunakan Metode Content-Based Filtering dan TF-IDF,"Sistem Rekomendasi Produk Pena Eksklusif Menggunakan Metode Content-Based Filtering dan TF-IDF

Mariani Widia Putri1, Achmad Muchayan2, Made Kamisutara3 

Abstract                          
The grading system is currently trending. Today's public habits rely more on online transactions for a variety of personal reasons. The recommendation system offers an easier and faster way for users not to have to take the time to find the item they want. Intergovernmental competition also changes so it must  be renewed in order to change potential customers. Therefore we need a system that can support this. So in this study, the authors built a recommendation system using Content-Based Filtering and Term Frequency Inverse Document Frequency (TF-IDF) metho ds from the Information Retrieval (IR) model. To obtain efficient results and in accordance with the needs of solutions in improving Customer Relationship Management (CRM). The recommendation system is provided as a solution to  increase customer brand awareness and minimize transaction failures due to lack of information that can be delivered directly or offline. The data used consisted of 258 product product codes, each of which had eight categories and 33 forming keywords in accordance with the company's product knowledge. The TF-IDF calculation results show a weight value of 13,854 when displaying the first best product recommendations, and have an accuracy of 96.5% in providing pen recommendations.                         
Keywords: recommendation system, content-based filtering, TF-IDF, CRM. 

Abstrak                         
Sistem rekomendasi saat ini sedang menjadi tren. Kebiasaan masyarakat yang saat ini lebih mengandalkan transaksi secara online dengan berbagai alasan pribadi. Sistem rekomendasi menawarkan cara yang lebih mudah dan cepat sehingga pengguna tidak perlu meluangkan waktu terlalu banyak untuk menemukan barang yang diinginkan. Persaingan antar pelaku bisnis pun berubah sehingga harus mengubah pendekatan agar bisa menjangkau calon pelanggan. Oleh karena itu dibutuhkansebuah sistem yang dapat menunjang hal tersebut. Maka dalam penelitian  ini, penulis membangun sistem rekomendasi produk menggunakan metode Content-Based Filtering dan Term Frequency Inverse Document Frequency (TF-IDF) dari model Information Retrieval (IR). Untuk memperoleh hasil yang efisien dan sesuai dengan kebutuhan solusi dalam meningkatkan Customer Relationship Management (CRM). Sistem rekomendasi dib angun dan diterapkan sebagai solusi agar dapat meningkatkan brand awareness pelanggan dan meminimalisir terjadin ya gagal transaksi di karenakan kurang nya informasi yang dapat disampaikan secara langsung atau offline. Data yang  digunakan terdiri dari 258 kode produk produk yang yang masing-masing memiliki delapan kategori dan 33 kata kunci pembentuk sesuai dengan product knowledge perusahaan. Hasil perhitungan TF-IDF menunjukkan nilai bobot 13,854 saat menampilkan rekomendasi  produk terbaik pertama, dan memiliki keakuratan sebesar 96,5% dalam memberikan rekomendasi pena.                         

Kata kunci: sistem rekomendasi, pemfilteran berbasis konten, TF-IDF, CRM . 

1. Pendahuluan                          
Dalam dunia bisnis yang semakin berkembang membuat banyak hal yang bergerak sangat dinamis dan penuh persaingan. Pelaku bisnis berusaha berpikir kritis agar dapat bertahan dan jika mungkin juga bisa mengembangkan skala bisnis mereka untuk mencapai tujuan. Misalnya dengan penerapan Customer Relationship Management (CRM) dalam sebuah perusahaan yang diharapkan nantinya dapat memberikan dampak yang baik bagi perusahaan [1], [2]. Penerapan CRM juga dapat dilakukan dengan membangun sistem rekomendasi yang bertujuan untuk mempermudah pelanggan dalam mengenali produk dan memastikan bahwa data dapat diolah dengan baik agar dapat dimanfaatkan untuk analisa dalam pemilihan strategi penjualan kedepan [3]. Dari beberapa pendekatan yang memungkinkan, algoritma TF-IDF dikenal efisien dalam menghitung tingkat kemiripan antara dokumen dan kata kunci. TF-IDF berfokus dalam menghitung kemiripan item satu dengan item lainnya [4]. Dengan batasan terletak pada pena khusus yakni brand  Parker. Sedangkan metode Content-Based Filtering (C-BF) digunakan untuk menentukan kategori apa saja yang akan digunakan dalam perhitungan. Metode ini memungkinkan untuk membentuk profil pengguna berdasarkan kategori pembentuk suatu item. Sehingga memberikan rekomendasi sesuai deskripsi kategori profil pengguna tersebut [4]. Dalam penelitian ini item yang dimaksud adalah produk pena Parker. Permasalahan yang sering terjadi adalah keterbatasan informasi yang dimiliki karyawan mengenai kebutuhan pelanggan. Sehingga cenderung mengakibatkan terjadinya gagal transaksi. Sistem rekomendasi dibuat agar dapat mengurangi kemunkinan kerugian perusahaan dan meningkatkan brand awarness  produk pena Parker yang dimiliki pelanggan. Karena semakin pelanggan dapat mengenali produk, maka semakin tinggi pula brand awareness akan produk tersebut. Beberapa penelitian sebelumnya yang juga membahas mengenai hal ini diambil sebagai referensi adalah penelitian berjudul Sistem Rekomendasi Paket Wisata Se-Malang Raya Menggunakan Metode Hybrid Content Based  dan Collaborative  yang menggunakan algoritma Nearest Neighbor  untuk mencari kasus dengan menghitung jarak dan pencocokan bobot dan atribut yang ada. Hasil dari penelitian tersebut memiliki tingkat akurasi sebesar 77% dengan menggunakan kuesioner sebagai metode pengujiannya [5]. Referensi penelitian selanjutnya berjudul Sistem Rekomendasi Laptop Menggunakan Collaborative Filtering  dan C-BF yang menggunakan consine  similarity  berdasarkan rating  yang diberikan pengguna lain. Hasil dari metode hybrid menunjukan jumlah data yang besar membutuhkan waktu eksekusi lebih lama dan metode content-based filtering memberikan waktu eksekusi lebih cepat dibandingkan collaborative  filtering  [4]. CBF sebagai metode utuk rekomendasi film juga banyak diimplementasikan diantaranya pada penelitian dengan judul Content-based filtering for recommendation systems using multiattribute networks. CBF digunakan untuk merekomendasikan film yang paling sesuai dengan kriteria yang dimasukkan. Kriterianya meliputi aktor, direktur film, penulis, aliran film, warna, tahun keluar film, dan kata kunci. Membandingkan pendekatan menggunakan data dari MovieLens, mendapati bahwa pendekatan yang dilakukan berhasil unggul dalam hal ketahanan dan akurasi. Metode yang diusulkan juga dapat mengatasi spesialisasi yang berlebih serta masalah ketersebaran yang mempengaruhi sistem rekomendasi [6]. Kemudian pada penelitian berjudul Research paper classification systems based on TF-IDF and LDA schemes melakukan pengelompokan makalah penelitian menggunakan algoritma pengklaster K-Means dan algoritma pembobotan TF-IDF. Sistem rekomendasi bekerja dengan mengelompokkan makalah peneitian berdasarkan makalah penelitian serupa yang belum pernah dilihat atau baca agar pengguna dapat menemukan makalah penelitian terkait dengan mudah. TF-IDF memiliki fungsi yang cukup banyak diantaranya seperti sistem rekomendasi buku dan usulan metode ekstraksi kata kunci dari inti sari novel [7] , melakukan pencarian dan pengelompokan terhadap artikel penelitian yang memiliki banyak kesamaan subjek dengan melakukan perhitungan menggunakan skema TF-IDF [8]. Tujuan dari penelitian ini adalah membangun sebuah sistem rekomendasi pena eksklusif menggunakan metode C-BF dengan algoritma TF-IDF untuk pembobotan yang sebelumnya masih sedikit digunakan. Diharapkan sistem rekomendasi yang dibangun pada penelitian ini dapat memberikan hasil terbaik sesuai dengan kriteria pengguna. Dengan adanya sistem rekomendasi ini, diharapkan calon pembeli dan penjual 
dapat lebih efisien sebelum bertransaksi.                         
2. Metode Penelitian                         
Pada penelitian ini penulis menggunakan C-BF untuk melakukan pemilahan konten yang akan dijadikan parameter pembobotan pemilihan pena. Dalam implementasinya C-BF menggunakan TF-IDF untuk melakukan pembobotan nilai atribut. Dibutuhkan alur yang sistematis agar penelitian ini berhasil dan sistem rekomendasi memiliki nilai akurasi yang baik.         
2.1. Metode Perancangan                         
Gambar 1. Alur Perancangan Sistem                 
Pada Gambar 1 menunjukkan alur perancangan system rekomendasi melalui 7 tahapan proses yang dimulai dari analisa kebutuhan dengan rincian kegiatan mencari permasalahan yang kemudian dapat diterapkan CRM untuk mengatasi masalah tersebut. Kemudian penulis melakukan studi pustaka untuk memperkaya pengetahuan terkait sistem yang akan dibangun. Dua tahap tersebut membutuhkan waktu satu minggu kerja dengan durasi 4 jam perhari dan penulis diharuskan mengunjungi lokasi penjualan pena. Selain melakukan studi pustaka, penulis juga mempelajari setiap pena dengan ciri khususnya. Penulis mendapatkan penjelasan secara rinci dari staf pena ekslusif secara langsung sebagai product knowledge  penulis. Kemudian pengumpulan data dilakukan dengan mengajukan permohonan kepada instansi terkait. Penulis mendapatkan data dalam bentuk beberapa 
berkas digital diantaranya file penjualan 3 bulan terakhir, gambar pena dengan banyak jenis dan spesifikasi lengkap beserta harga. Data tersebut berfungsi sebagai spesifikasi yang nantinya akan dikaitkan dengan kriteria pembobotan.  Selanjutnya perancangan sistem merupakan proses pembuatan desain, alur penggunaan serta alir data. Perancangan sistem ini mengarah kepada sistem rekomendasi pemiihan pena eksklusif. Dirancang menggunakan bahasa pemrograman Hypertext Preprocessor (PHP) dengan MySQL sebagai database . Pembangunan sistem menggunakan framework  Laravel versi 7 dengan PHP versi 7.2.5. Sistem memiliki 4 halaman utama meliputi halaman pendaftaran yang berfungsi untuk memasukkan kriteria pembobotan dan merekam hasil rekomendasi,kedua terdapat halaman masuk yang berfungsi untuk mengambil kembali rekaman data rekomendasi yang pernah dibuat,ketiga terdapat halaman hasil rekomendasi dengan tampilan 4 pena teratas, yang terakhir ada halaman detail pena yang berisikan informasi rinci mengenai pena yang dipilih. Proses pembangunan sistem membutuhkan waktu 1 Bulan terhadap keseluruhan sistem dari tampilan hingga engine  sistem. Pada proses pengujian sistem dilakukan sebagai tolak ukur kesesuaian fungsi sistem rekomendasi yang telah dibangun. Pengujian dilakukan dengan melakukan validasi hasil rekomendasi sistem dengan wawancara langsung terhadap pengguna yang menentukan pilihan pena. Yang terakhir adalah menarik kesimpulan dari keseluruhan proses meliputi penelitian, analisa kebutuhan, studi literatur, pengumpulan data hingga pengujian.                         
2.2. Sistem Rekomendasi                         
Sistem rekomendasi adalah salah satu hal yang digunakan dalam menerapkan CRM. Banyak nya platform online  yang menerapkan sistem rekomendasi dalam kegiatan bisnis mereka. Untuk melihat kebiasaan pelanggan dan yang paling penting adalah merekomendasikan sesuatu yang sesuai dengan masing-masing pelanggan [4], [9].                         
2.3. Customer Relationship Management                         
CRM merupakan sebuah fungsi yang menunjang perusahan pada bidang penjualan, pemasaran, serta pelayanan, dengan tujuan untuk meningkatkan penilaian kepuasan pelanggan [1]. CRM dapat memiliki dampak jangka panjang maupun pendek dan strategi yang digunakan sangat bervariasi [10]. Metode CRM yang digunakan pada penelitian ini untuk membantu pelanggan menentukan pilihan pena, melakukan efisiensi proses tidak harus datang ke toko utk menentukan pena, serta memastikan ketersediaan pena. Menyimpan data pengguna serta menggunakan untuk kepentingan promosi juga menjadi nilai tambah sistem rekomendasi ini dalam konteks CRM.                         
2.4. Content-Based Filtering                         
C-BF merupakan metode untuk memilah konten yang sudah ada dan disesuaikan dengan konteks studi kasus sebelum dilakukan pembobotan terhadap algoritma TF-IDF. Secara garis besar C- BF menggunakan konten atribut yang sudah tersedia dan tidak mengambil opini lain untuk merekomendasikan konten serupa [4], [11]. Pada penelitian ini C-BF menggunakan TF-IDF sebagai algoritma untuk melakukan perhitungan pembobotan nilai terhadap atribut konten dan pengguna. Secara umum C-BF digambarkan sebagai berikut: [12] Pada Gambar 2 merupakan skema C-BF bekerja. Sistem rekomendasi menampilkan hasil rekomendasi produk untuk pengguna yang sesuai atau memiliki kesamaan antara atribut konten dan atribut yang dimiliki oleh pengguna. Penentuan rekomendasi mengambil nilai pembobotan tertinggi terhadap konten atribut dan pengguna. C-BF menjadi skema untuk sistem rekomendasi untuk pembobotan serta penilaian atribut dalam menentukan rekomendasinya adalah peran TF-IDF. Dalam implementasinya C-BF 
menggunakan persamaan sebagai berikut:                  
ð‘¢(ð‘, ð‘ )= ð‘ ð‘ð‘œð‘Ÿð‘’(ð‘ƒð‘Ÿð‘œð‘“ð‘–ð‘™ð‘’ð´ð‘¡ð‘¡ð‘Ÿ (ð‘), ð¶ð‘œð‘›ð‘¡ð‘’ð‘›ð‘¡ (ð‘ ))      (1)                         
Gambar 2. Skema C-BF                 
Dimana utilitas konten ð‘  untuk pengguna ð‘ dihitung dengan berdasarkan utilitas ð‘¢ (c,s) yang ditetapkan pengguna ð‘ ke item ð‘ âˆˆS yang mirip dengan s [12] . Dalam konteks penelitian ini, sistem menentukan rekomendasi kepada pengguna c dengan cara mencoba menemukan kesamaan di antara beberapa pena yang memiliki skor tertinggi berdasarkan pembobotan kecocokan atribut pengguna dan pena. Kemudian hasil pembobotan akan diurutkan dari yang terbesar hingga terkecil.                          
2.5. Term Frequency Inverse Document Frequency          
TF-IDF pada dasarnya bekerja dengan pola menentukan frekuensi relatif dari kata-kata dalam sebuah dokumen tertentu dibandingkan dengan proporsi terbaik dari kata di atas seluruh kumpulan dokumen [13], [14]. Kata-kata dengan nilai TF tinggi memiliki arti penting dalam sebuah dokumen, sedangkan DF menyiratkan berapa kali suatu kata muncul dalam kumpulan dokumen. Metode ini menghitung kata muncul dalam banyak dokumen. Pada penelitian ini algoritma yang digunakan adalah TF-IDF dengan menggunakan perhitungan TF biner dan TF murni. TF biner berfungsi untuk mengetahui ada atau tidaknya kata dalam sebuah dokumen, jika ada maka bernilai satu (1) jika tidak bernilai nol (0) . Sedangkan untuk TF murni menilai terhadap jumlah kemunculan kata atau term pada sebuah dokumen. Sebagai contoh jika sebuah kata/ term muncul sebanyak lima kali maka kata tersebut bernilai lima (5) [15] â€“[17]. IDF merupakan perhitungan setelah nilai TF ditemukan. IDF menghitung bagaimana TF didistribusikan secara luas pada koleksi dokumen item produk yang bersangkutan. Nilai TF-IDF dapat dihitung menggunakan rumus 1 dan 2 sebagai berikut :                          
ð¼ð·ð¹ = (ð·                        
ð·ð¹)                                   
-1                        
ð‘Š = ð‘‡ð¹âˆ— (ð¼ð·ð¹ + 1)                 (2) Dimana ð· merupakan jumlah semua dokumen sedangkan ð·ð¹ adalah jumlah dokumen yang mengandung atribut atau term  [4]. Kemudian pada rumus 2 TF merupakan jumlah kecocokan atau kemunculan atribut dan W adalah bobot setiap dokumen.  Pada penelitian ini jenis formula yang digunakan adalah TF murni dan binari.  Hasil didapat dari sistem melakukan penilaian berdasarkan kemiripan dengan sebuah vektor pembentuk item. Item akan muncul jika kriteria masukan sesuai dengan pengguna.                         
2.6. Alur Proses Sistem Rekomendasi Pena                 
Alur kerja sistem rekomendasi meliputi pendaftaran, pengisian pembobotan yang meliputi data pengguna dan juga kriteria pena yang diinginkan, lihat detail pena, hasil rekomendasi pena serta konfirmasi persetujuan terhadap pelanggan untuk sistem dapat mengolah data yang dimasukkan. Pengguna juga dapat melihat keseluruhan pena yang tersedia dan lokasi toko yang menyediakan pena. Kapasitas kerja sistem memuat lingkup rekomendasi pena pada studi kasus pena ekslusif. Alur proses sistem rekomendasi dari registrasi, proses perhitungan hingga hasil rekomendasi oleh sistem ditampilkan pada Gambar 2 secara sistematis.          
Gambar 2 menyajikan alur proses sistem rekomendasi dalam bentuk diagram alir dengan uraian sebagai berikut: Proses awal setelah berhasil mengakses sistem atau aplikasi akan dihadapkan pada halaman menu awal sistem yang menyajikan beberapa pena best seller dan menu pendaftaran serta untuk masuk sebagai pengguna. Sebelum pengguna ingin menampilkan rekomendasi pena yang sesuai dengan kriteria pengguna itu sendiri, maka perlu melakukan pendaftaran, yang nantinya masukan dari pendaftaran tersebut berfungsi sebagai parameter pembobotan. Ketika pengguna telah melakukan pendaftaran maka sistem akan melakukan perhitungan dan menampilkan hasil rekomendasi pena menurut sistem. Selanjutnya skenario ketika pengguna sudah melakukan pendaftaran adalah jika pengguna ingin masuk kedalam sistem hanya perlu memasukkan username dan password  yang pernah dibuat sebelumnya, dan apabila berhasil maka sistem rekomendasi akan menampilkan hasil sebelumnya berdasarkan kriteria pembobotan yang telah dilakukan sebelumnya oleh pengguna.                         
2.7. Pengujian SistemPengujian sistem penting untuk dilakukan sebagai tolak ukur keberhasilan sistem rekomendasi. Proses pengujian pada penelitian ini 
menggunakan metode kualitatif yakni dengan cara mencocokkan hasil rekmendasi sistem dengan hasil wawancara pena pilihan pelanggan atau pengguna. Rumus menghitung nilai akurasi yang digunakan pada penelitian ini dapat dilihat pada rumus 2 [18].                         
ð‘ð‘–ð‘™ð‘Žð‘– ð´ð‘˜ð‘¢ð‘Ÿð‘Žð‘ ð‘– =  ð½ð‘¢ð‘šð‘™ð‘Žâ„Ž â„Žð‘Žð‘ ð‘–ð‘™ ð‘ ð‘’ð‘ ð‘¢ð‘Žð‘–                        
ð½ð‘¢ð‘šð‘™ð‘Žâ„Ž ð‘¢ð‘—ð‘– ð‘ð‘œð‘ð‘Ž ð‘¥ 100%             (3)                         
Gambar 2. Alur Proses Sistem Rekomendasi                 
Dimana jumlah hasil sesuai adalah hasil rekomendasi sistem yang dicocokkan dengan hasil wawancara dan kuisioner. Jumlah uji adalah total percobaan sistem dan wawancara, dalam penelitian ini berjumlah 100 [19] . Kemudian jumlah pembagian dikali 100 dan dibagi 100 akan menghasilkan nilai akurasi berupa persentase. 
                        
3.  Hasil dan Pembahasan                         
Proses pembangunan sistem dilakukan dalam waktu 1 bulan meliputi proses perancangan sistem, penentuan Bahasa pemrograman, penentuan basis data, pembuatan layout  tampilan sistem, implementasi algoritma, pembangunan sistem secara utuh, hingga tahap pengujian. Untuk proses penggalian data membutuhkan waktu satu minggu. Sedangkan untuk proses pengujian membutuhkan waktu satu minggu dan total pengerjaan penelitian ini membutuhkan waktu 1 bulan 2 minggu.         
3.1. Hasil Perancangan Sistem Rekomendasi                 
Dari proses penggalian data tersebut penulis mendapatkan beberapa berkas data pena. Kemudian dikumpulkan ke dalam satu berkas dengan format excel untuk memudahkan export  ke sistem rekomendasi sebagai data master awal. Data yang digunakan disajikan pada Tabel 1 sebagai berikut. Pada Tabel 1 menyajikan data dengan kolom nomor, kode pena, dan nama produk . Kode pada setiap produk bersifat unik, yang berarti tidak ada kesamaan kode antara produk satu dengan lainnya.  Sedangkan pada kolom lengkapnya meliputi kode, nama produk, merk, stok pada setiap toko, harga, dan product knowledge .  Total data yang didapat berjumlah 258 data pena berbagai jenis, warna, fungsi, bentuk pena, dan harga. Kemudian untuk menentukan parameter pembobotan, penulis mengkaji setiap pena dengan product knowledge  yang tersedia hingga menghasilkan beberapa parameter sebagai pembobotan.  Dari hasil kaji pena, beberapa pena sudah tidak tersedia lagi sehingga kami melakukan seleksi dengan membersihkan data yang tidak digunakan seperti data produk isi ulang tinta pena, kotak pena. Beberapa parameter pembobotan disajikan pada Tabel 2. Pada Tabel 2 menampilkan parameter serta atributnya. Parameter yang pertama adalah harga, parameter kedua adalah jenis kelamin, parameter ini berpengaruh terhadap selera pena yang akan direkomendasikan. Berdasarkan hasil analisa lapangan, pengguna dengan jenis kelamin perempuan cenderung menyukai model pena yang sederhana, memiliki varian warna yang cantik, dan memiliki tinta tipis (untuk menulis). Berbeda dengan laki-laki yang dominan kepada desain pena sederhana, memiliki warna netral, ukuran pena yang relatif besar, dan memiliki tinta tebal. Parameter selanjutnya adalah warna klip dengan atribut warna gold, silver dan limited . Warna klip merupakan salah satu parameter yang cukup berperan, karena klip pena lebih sering terlihat ketika pena diletakkan pada saku. Berikutnya adalah kegunaan dengan dua atribut antara lain tanda tangan dan menulis. Parameter ke-lima adalah fitur ukir nama. Selanjutnya adalah parameter body  atau tubuh pena yang dipegang ketika menulis   terdapat ukuran besar, standard, dan slim. Berikutnya parameter pekerjaan dengan pilihan atribut wiraswasta, pengusaha, pejabat, dosen, mahasiswa. Parameter terakhir adalah warna. Terdapat 14 pilihan warna yang tersedia, namun pada beberapa jenis pena tidak memiliki seluruh warna tersebut, akan tetapi sistem akan menampilkan hasil rekomendasi paling sesuai berdasarkan kriteria pengguna. Berdasarkan kajian penelitian terdahulu serta analisa kebutuhan, dengan sembilan (9) parameter pembobotan penulis yakin sistem rekomendasi menggunakan metode C-BF dengan algoritma perhitungan pembobotan TF-IDF pada penelitian ini mampu memberikan hasil rekomendasi yang tepat dan mendapatkan nilai akurasi yang baik. Pembuatan sistem 
pada penelitian ini fokus terhadap fungsi agar rekomendasi berjalan dengan semestinya, namun tidak mengesampingkan unsur kecantikan atau pengalaman pengguna agar pengguna dapat menggunakan dengan nyaman dan tidak membingungkan. Sistem hanya memiliki tampilan dan menu yang sederhana, tidak rumit dan sangat cocok digunakan segala usia. 
Tabel 1. Data Detail Pena                         
No Kode  Nama Produk                         
1 0690620 P.duofold 05 black ptrb                         
2 0690650 P.duofold 05 black ptbp                         
3 0781030 P.exec shi chrm 2bp/1sty/1pc x                 
4 0789130 P.sonnet 07 laq blk ct rb                         
5 0789140 P.sonnet 07 laq blk ct bp                         
6 0789490 P.sonnet 07 ss ct rb                         
7 0808310 P.sonnet 07 ch silver ct bp                         
8 0808530 P.sonnet 07 ch black ct bp                         
253 774560 P.esprit blue ct 1bp/1stls                         
254 774590 P.esprit red ct bp m                         
255 836780 P.urban ss ct rb                         
256 836820 P.urban fash silver ct rb                         
257 836860 P.urban fash pink ct rb                         
258 Sev0009rwm P.v88 white rb                          
Tabel 2. Atribut dan Parameter Pembobotan         
Parameter Atribut Harga Harga Gender Pria, Wanita Warna Klip Gold, Silver, Limited Kegunaan Tanda tangan, Menulis Ukir Nama Iya, Tidak Body Slim, Standard, Besar Usia Usia Pekerjaan Wiraswasta, Pengusaha, Pejabat, Dosen, Mahasiswa Warna Hitam, SS, Silver, Biru, Gold, Gray, Putih, Coklat, Pink, Hijau, Merah, Ungu, Orange, Kuning                 
Pada halaman menu awal Gambar 3 pengunjung sistem rekomendasi akan disajikan dengan pena yang memiliki predikat penjualan terbaik. Predikat penjualan terbaik diambil dari pembelian pena selama 3 bulan terakhir. Pada proses ini sistem hanya menampilkan pena yang memiliki riwayat penjualan terbanyak dan belum melakukan rekomendasi terhadap masukan pengguna. Selanjutnya agar pengguna atau pengunjung dapat dibantu oleh sistem rekomendasi, maka perlu melakukan pendaftaran pada sistem. Pada Gambar 4 Halaman pendaftaran, sistem menampilkan halaman pendaftaran yang terdiri dari 3 langkah berisi masukan kepada sistem. Pada langkah pertama meliputi nama lengkap pengguna, alamat email, nomor telepon, password  untuk masuk kedalam sistem dengan fungsi tambahan ketika login  dapat memperlihatkan hasil rekomendasi terakhir parameter dan persetujuan pengolahan data pengguna yang ditujukan kepada calon pengguna. Pada langkah ini pengguna wajib mengisi setiap form yang tersedia, karena data tersebut juga akan berfungsi sebagai basis data toko jika ada penawaran terkait sebagai salah satu pemanfaatan konteks CRM . Langkah kedua adalah memasukkan parameter sebagai dasar perhitungan pembobotan algoritma TF-IDF untuk menentukan rekomendasi pena yang sesuai dengan pelanggan. Parameter pembobotan pada sistem meliputi jenis kelamin, warna klip, fungsi pena, fitur ukir nama, bentuk body pena, usia, pekerjaan, dan terakhir warna pena. Kemudian pada langkah ketiga adalah memberikan pelanggan hak untuk memilih apakah data yang telah dimasukkan dapat disimpan dan diolah oleh sistem untuk kepentingan rekomendasi pena yang tepat. Setelah pengguna melakukan pendaftaran, maka sistem akan menampilkan hasil rekomendasi pena dari perhitungan TF-IDF berdasarkan parameter yang telah dimasukkan ke dalam sistem. Namun jika pengguna belum melakukan pendaftaran, maka system rekomendasi tidak bisa melakukan perhitungan dikarenakan tidak ada parameter yang dimasukkan untuk dihitung. Ketika pendaftaran telah dilakukan, pengguna juga dapat melakukan aktifitas masuk ke sistem rekomendasi untuk melihat hasil rekomendasi terakhir yang ditampilkan berdasarkan kriteria yang sebelumnya dimasukkan kedalam sistem. Halaman hasil rekomendasi disajikan pada Gambar 5 sebagai berikut:          
Pada Gambar 5 merupakan tampilan hasil rekomendasi beberapa pena dari perhitungan TF-IDF oleh sistem. Hasil rekomendasi menampilkan 4 teratas dengan nilai yang paling sesuai terhadap kriteria pena dan pengguna. Tampilan rekomendasi berupa 4 gambar pena dengan judul dan dilengkapi dengan harga pena, jika gambar pena di klik maka akan menampilkan keterangan rincian pena termasuk nilai pembobotan algoritma TF-IDF. Pengguna juga dapat melihat spesifikasi detail pena seperti warna klip, gambar pena, bentuk body , fungsi, lokasi outlet yang menyediakan pena terkait, serta jumlah stok tersedia pada outlet yang disajikan  pada Gambar 6. Gambar 6. Halaman Detail Pena                         
Pada Gambar 6 menyajikan tampilan system rekomendasi dengan konten rincian meliputi harga, spesifikasi, nilai bobot, gambar pena serta kriteria pena. Pena dengan nama P Urban mblk gt bp memiliki harga 510.000 serta menampilkan beberapa kriteria meliputi gender pria dan wanita, warna klip gold, fungsi untuk menulis, tersedia fitur ukir, ukuran body  standard, umur berkisar 17 sampai 35 tahun , 3 pilihan pekerjaan (wiraswasta, dosen, mahasiswa), pena hitam dan nilai bobot perhitungan TF-IDF sebesar 10.75. Pengguna juga dapat melihat toko yang menyediakan pena terkait. 
Gambar 3. Halaman menu awal                         
Gambar 4. Halaman pendaftaran                 
Gambar 5. Halaman Hasil Rekomendasi                 
Keterangan pada Gambar 7 adalah berupa informasi mengenai dimana outlet yang menyediakan jenis pena yang dipilih serta stok yang tersedia. Stok akan ter-update  dengan karyawan memasukkan stok secara manual. Hal tersebut tentu sangat membantu dari sisi pelanggan maupun karyawan pena. Karena pada sisi karyawan, pembelian pena jenis apapun wajib untuk
dilayani serta memberikan pelayanan terbaik untuk memenuhi target penjualan bulanan.                          
3.2. Pengujian                         
Setelah sistem rekomendasi selesai dibangun, diperlukan metode pengujian untuk mengetahui bagaimana tingkat akurasi sistem yang telah dibangun. Penulis menggunakan metode kualitatif dengan cara         mencocokkan hasil rekomendasi sistem dan hasil survey keinginan pelanggan melalui kuisioner serta wawancara. Proses pengujian dilakukan di lokasi penjualan kepada 100 pelanggan sehingga hasil yang didapat lebih valid. Pada Tabel 3 menampilkan hasil pengujian terhadap 100 data uji sistem dan wawancara serta kuisioner diantaranya 61 wanita dan 39 pria dengan umur berkisar antara 20 hingga 60 tahun. Dari data tersebut mendapatkan nilai kesesuaian sebanyak 94 data sesuai, 5 data kurang sesuai, dan 1 data tidak sesuai. Untuk data sesuai memiliki nilai 1, kurang sesuai memiliki nilai 0.5, sedangkan tidak sesuai memiliki nilai 0 atau tidak mendapatkan nilai. Maka jika dikonversi kedalam nilai akan menghasilkan 94 poin untuk data sesuai, 2.5 poin untuk data kurang sesuai dan 0 poin untuk data 
tidak sesuai dengan total poin 96.5. Pada Gambar 8 menyajikan Grafik nilai kesesuaian berdasarkan pengujian. Total nilai kesesuaian adalah 96,5 dari 100 data yang telah dilakukan uji. Maka untuk akurasi kesesuaian dalam presentase, sistem rekomendasi ini mampu mendapatkan nilai akurasi 96.5%. Pada kolom kriteria merupakan hasil wawancara dan proses masukan di sistem rekomendasi yang memuat beberapa pertanyaan antara lain: jenis kelamin, umur, pekerjaan, warna klip pena yang disukai , kegunaan pena, body pena, warna pena kesukaan, dan terakhir ketersediaan fitur ukir pada pena. Kemudian terdapat kolom aktual dan sistem yang dimana kolom aktual merupakan hasil dari wawancara dan kuisioner, sedangkan pada kolom sistem merupakan hasil dari sistem rekomendasi yang telah dibangun pada penelitian ini. Pada kolom terakhir yaitu nilai sesuai yang merupakan nilai dengan perhitungan jika sistem dan aktual mendapatkan hasil 2 pena yang sama maka bernilai 1.00 atau sesuai, jika hanya 1 yang sama maka bernilai 0.50 atau kurang sesuai sedangkan apabila pena pertama maupun pena kedua tidak ada yang sama maka bernilai 0 atau tidak sesuai.                          
4.  Kesimpulan                         
Berdasarkan hasil penelitian, sistem rekomendasi yang telah penulis bangun mampu menghasilkan akurasi senilai 96,5% dan dapat dikatakan sesuai dengan kebutuhan pelanggan. Kontribusi penelitian ini membangun sistem rekomendasi pemilihan pena yang dapat dijadikan alat bantu pemilihan pena terhadap calon pelanggan serta dapat meminimalisir terjadinya miss stock . Penelitian yang akan datang diharapkan dapat mengembangkan baik dari segi metode yang digunakan, sebagai contoh dapat mengembangkan          
Gambar 7. Halaman Informasi Stok dan Lokasi  Outlet 
Gambar 8. Grafik Nilai Kesesuaian 9451                        
Sesuai Kurang Sesuai Tidak Sesuai
Tabel 3. Data Pengujian                          
No Kriteria  Sistem Aktual Nilai Sesuai                 
1 Pria, 30, wiraswasta, gold, menulis, standar, hitam, tidak P.im prem black gt tb P.im black gt bp m blk tb P.im prem black gt tb P.im black gt bp m blk tb 1.00                 
2 Wanita, 22, mahasiswa, gold, menulis, slim, hitam, pink, iya P.jotter pink bp P.jotter original magenta ct P.jotter pink bp P.jotter original magenta ct 1.00         
3 wanita, 24, lainnya, silver, tanda tangan, standar, putih, merah, iya P.im prem bg red ct rb P.im white ct rbhd tb P.im prem bg red ct rb P.im white ct rbhd tb 1.00 
99 Wanita, 17, lainnya, silver, menulis, standar, hitam, merah, coklat, silver, tidak P.vector2 std red bp m P.im prem mtl brown ct bp P.vector2 std red bp m 0.50         
100 Wanita, 46, lainnya, gold, tanda tangan, standar, gold, silver, ss, iya P.urban prem aur pwd gt rbhd P. im brushed metal gt rb hd tb P.urban prem aur pwd gt rbhd P. im brushed metal gt rb hd tb 1.00                         
menggunakan teknik machine learning seperti Fuzzy Logic serta dengan studi kasus yang berbeda. Dengan harapan hasil yang dikeluarkan lebih maksimal dan akurat.                          
Daftar Pustaka                         
[1] A. Fauzi and E. Harli, â€œPeningkatan Kualitas Pelayanan Melalui CRM dengan Metode RAD,â€ J. RESTI (Rekayasa Sist. dan Teknol. Informasi) , vol. 1, no. 1, p. 76, 2017, doi: 10.29207/resti.v1i1.16.                         
[2] C. S. D. Prasetya, â€œSistem Rekomendasi Pada E-Commerce Menggunakan K-Nearest Neighbor,â€ J. Teknol. Inf. dan Ilmu Komput. , vol. 4, no. 3, p. 194, 2017, doi: 10.25126/jtiik.201743392.                         
[3] C. D. Rumiarti and I. Budi, â€œSegmentasi Pelanggan Pada Customer Relationship Management di Perusahan Ritelâ€¯: Studi Kasus PT. Gramedia Asri Media,â€ J. Sist. Inf. (Journal Inf. Syst. , vol. 13, no. 1, pp. 1 â€“        7, 2017, doi: https://doi.org/10.21609/jsi.v13i1.525.         
[4] A. E. Wijaya and D. Alfian, â€œSistem Rekomendasi Laptop Menggunakan Collaborative Filtering Dan Content-Based Filtering,â€ J. Comput. Bisnis , vol. 12, no. 1, pp. 11 â€“27, 2018.                         
[5] B. T. W. Utomo and A. W. Anggriawan, â€œSistem Rekomendasi Paket Wisata Se-Malang Raya Menggunakan Metode Hybrid Content Based Dan Collaborative,â€ J. Ilm. Teknol. Inf. Asia , vol. 9, no. 1, pp. 6 â€“13, 2015.         
[6] J. Son and S. B. Kim, â€œContent-Based Filtering for Recommendation Systems using Multiattribute Networks,â€ Expert Syst. Appl. , vol. 89, pp. 404 â€“412, 2017, doi: 10.1016/j.eswa.2017.08.008.                         
[7] E.-S. You, G.-H. Choi, and S.-H. Kim, â€œStudy on Extraction of Keywords Using TF-IDF and Text Structure of Novels,â€  J. Korea Soc. Comput. Inf. , vol. 20, no. 2, pp. 121â€“129, 2015, doi: 10.9708/jksci.2015.20.2.121.         
[8] S. W. Kim and J. M. Gil, â€œResearch Paper Classification Systems Based on TF-IDF and LDA Schemes,â€ Human-centric Comput. Inf. Sci. , vol. 9, no. 1, 2019, doi: 10.1186/s13673-019-0192-7.                         
[9] R. Gavval, V. Ravi, K. R. Harshal, A. Gangwar, and K. Ravi, â€œCUDA -Self-Organizing Feature Map Based Visual Sentiment Analysis of Bank Customer Complaints for Analytical CRM,â€ pp. 1â€“ 21, 2019, [Online]. Available: http://arxiv.org/abs/1905.09598. 
[10] H. E. Pramudiya, Y. Dri Handarkho, and F.S. Rahayu, â€œPengimplementasian CRM Pada Pembangunan E-Commerce untuk Usaha Mikro Kecil Menengah (Studi Kasusâ€¯: Dolanan Puzzle),â€ pp. 257â€“ 268, 2015.                         
[11] S. M. Ali, G. K. Nayak, R. K. Lenka, and R. K. Barik, â€œGenome Tags and Content-Based Filtering,â€ pp. 85â€“ 94, 2018, doi:https://doi.org/10.1007/978-981-10-8360-0_8. 
[12] M. Misal and U. Nagaraj, â€œRecommender System Methods and Feedback Mechanisms: A Survey,â€ Int. J. Innov. Res. Comput. Commun. Eng. (An ISO Certif.Organ. , vol. 3, no. 11, pp. 11710 â€“11716, 2015, doi: 10.15680/IJIRCCE.2015.         
[13] N. C. Haryanto, L. D. Krisnawati, and A. R. Chrismanto, â€œTemu Kembali Dokumen Sumber Rujukan dalam Sistem Daur Ulang Teks,â€ J. Teknol. dan Sist. Kompu t., vol. 8, no. 2, pp. 140 â€“149, 2020, doi: 10.14710/jtsiskom.8.2.2020.140-149.                         
[14] S. Qaiser and R. Ali, â€œText Miningâ€¯: Use of TF-IDF to Examine the Relevance of Words to Documents,â€ vol. 181, no. 1, pp. 25â€“29, 2018.                         
[15] M. M. Stiawan and R. Hidayat, â€œPengembangan Sistem Identifikasi Fakta Dan Tidak Fakta Berita di Media Informasi Berbahasa Indonesia,â€ no. November, pp.34â€“39, 2019. 
[16] C. Yin, L. Zhang, M. Tu, X. Wen, and Y.Li, â€œTF -IDF Based Contextual Post-Filtering Recommendation Algorithm in Complex Interactive Situations of Online to Offline: An Empirical Study,â€ Teh. Vjesn. , vol. 26, no. 6, pp. 1529 â€“1536, 2019, doi: 10.17559/TV-20190515161539.         
[17] M. Mohammedid and N. Omar, â€œQuestion Classification Based on Bloomâ€™s Taxonomy Cognitive Domain using Modified TF- IDF and Word2vec,â€ PLoS One, vol. 15, no. 3, pp. 1 â€“21, 2020, doi: 10.1371/journal.pone.0230442.         
[18] T. F. Ramadhani, I. Fitri, and E. T. E. Handayani, â€œSistem Pakar Diagnosa Penyakit ISPA Berbasis Web Dengan Metode Forward Chaining,â€ JOINTECS (Journal Inf. Technol. Comput. Sci. , vol. 5, no. 2, p. 81, 2020, doi: 10.31328/jointecs.v5i2.1243.                         
[19] W. G. S. Parwita, â€œPengujian Akurasi Sistem Rekomendasi Berbasis Content-Based Filtering,â€ Inform. Mulawarman  J. Ilm. Ilmu Komput. , vol. 14, no. 1, p. 27, 2019, doi: 10.30872/jim.v14i1.1272.",sistem rekomendasi,"Content-Based Filtering, TF-IDF",produk pena eksklusif,akurasi
Sistem Rekomendasi Skincare Menggunakan Metode Content-Based Filtering dan Algoritma Apriori,"Sistem Rekomendasi Skincare Menggunakan Metode Content-Based Filtering dan Algoritma Apriori

Dwi Ayu Nur Safitri1, Risa Helilintar2, Lilia Sinta Wahyuniar3 

Abstrak 
Dalam pemilihan produk skincare, konsumen masih sering mengalami kesalahan memilih karena kurang mengenal tipe/jenis kulit masing-masing serta kurangnya pengetahuan mengenai produk skincare itu sendiri. Sehingga konsumen terkadang kesulitan dalam menentukan produk skincare yang tepat untuk digunakan. Penggunaan skincare yang tidak tepat akan berdampak buruk bagi kulit wajah. Berdasarkan permasalahan tersebut, maka dibutuhkan sistem yang dapat merekomendasi produk skincare yang sesuai dengan kebutuhan konsumen. Penelitian ini bertujuan untuk merancang sebuah aplikasi yang dapat memberikan rekomendasi produk skincare kepada konsumen berdasarkan produk yang disukai sebelumnya. Penel itian ini dilakukan dengan menggunakan metode -Based Filtering dan Algoritma Apriori. Proses rekomendasi dilakukan dengan menghitung nilai kemiripan  konten suatu item yang menghasilkan rating produk tertinggi hingga terendah dan juga menghitung nilai minimum support serta nilai minimum confidence untuk  menentukan  aturan asosiasi  suatu kombinasi itemset . Hasil dari penerapan metode Content-Based Filtering pada sistem rekomendasi skincare dengan 40 data produk  skincare didapatkan hasil rating tertinggi sebesar  0,447 dan menggunakan minimum nilai support=40%, nilai minimum  confidence=40% membentuk  aturan asosiasi dengan hasil nilai confidence sebesar 88,89%. Dari hasil tersebut dapat disimpulkan bahwa metode Content-Based Filtering dan Algoritm a Apriori mampu memberikan hasil rekomendasi yang cukup baik.  
 
Kata Kunci Sistem Rekomendasi, Content-Based Filtering, Apriori.  

1. PENDAHULUAN  
Setiap  orang  memiliki  tipe/jenis  kulit  wajah  yang  berbeda-beda, tergantung pada jenis kelamin, usia hingga genetik. Pada dasarnya terdapat 5 jenis kulit wajah manusia, yaitu kulit normal, berminyak, kering, sensitif dan kombinasi. Banyak orang yang belum  mengenal  dan mengetahui  apa  tipe/jenis kulit  yang  dimiliki. Padahal  mengetahui  tipe/jenis  kulit  itu  sangat penting, sebab  ini  akan  menentukan  jenis  perawatan dan produk skincare  yang dibutuhkan. Selain  kurangnya  pengetahuan  mengenai tipe/jenis  kulit  wajah, masih  terdapat  juga  orang  yang  belum  memiliki  pengetahuan  mengenai skincare  yang  tepat  untuk  permasalahan  kulit  wajah.  Apalagi  konsumen memiliki  jenis/tipe  kulit  wajah  yang  berbeda-beda.  Hal  ini  membuat konsumen  memerlukan  pertimbangan  dalam  membuat  keputusan menggunakan  skincare  yang  benar benar  dibutuhkan.  Skincare  tersebut terdiri  dari  pembersih  wajah   (cleansing ),  toner,  serum,  pelembab  wajah ( moisturizer ), tabir surya (sunscreens ) dan lain sebagainya.  Dalam  pemilihan  skincare,  konsumen  masih  sering  mengalami kesalahan  dalam  memilih  produk  skincare  yang  mana  tidak  sesuai  dengan  tipe/jenis kulit yang dimiliki dan permasalah kulit yang sedang dialami saat itu.  Hal  tersebut  akan  memberikan  dampak  buruk  terhadap  kulit  wajah. Dampak buruk yang bisa terjadi adalah kulit mengalami alergi, muncul ruam yang  berwarna  
rahan,  perih,  gatal -gatal  bahkan  fatalnya  bisa mengalami peradangan kulit kronis.  Berdasarkan  permasalahan  diatas  maka  perlu  membangun  sebuah sistem  yang mampu membantu merekomendasi konsumen dalam pemilihan skincare  yang  tepat  agar mampu meminimalisir terjadinya kesalahan dalam memilih skincare oleh konsumen .  Sistem ini menggunakan metode Content-Based Filtering  dan Algoritma Apriori.  Tujuan dari penelitian ini adalah untuk merekomendasikan produk skincare menggunakan metode Content-Based Filtering  dan Algoritma Apriori , sehingga membantu konsumen dalam menentukan produk skincare apa saja yang tepat untuk digunakan.  Metode Content-Based Filtering   memberikan hasil rekomendasi berdasarkan atribut/konten untuk menghitung nilai kemiripan suatu produk [1]. Atribut/konten dalam suatu objek mampu memberikan informasi mengenai kebutuhan atau minat pengguna. Algoritma yang digunakan adalah tf-idf. Sedangkan algoritma apriori memberikan rekomendasi berdasarkan histori transaksi.  

2. METODE PENELITIAN  
Pada penelitian ini menggunakan pendekatan metode deskriptif kualitatif dengan teknik pengambilan data menggunakan pemanfaatan dokumen tertulis, termasuk sumber -sumber tertulis dari hasil wawancara terbuka pada kuesioner, buku harian seseorang dan catatan program.  
2.1 Tahapan Penelitian  
Pada pembuatan sistem ini  menggunakan alur penelitian deskriptif kualitatif yaitu, Studi literatur, pengumpulan data, analisa sistem, perancangan sistem, pengujian, evaluasi sistem dan dokumentasi . Berikut merupakan alur penelitian yang ditunjukan pada Gambar 1 dibawah ini :  
Gambar 1. Diagram Alur Penelitian  
2.2 Metode Pengumpulan Data  
Data yang digunakan dalam penelitian ini adalah berjenis data sekunder yang mana data tersebut berasal dari sumber yang tidak langsung memberikan data kepada pengumpul data seperti melalui orang lain maupun melalui dokumen  [2]. Berikut metode pengumpulan data yang digunakan dalam penelitian ini :  
a. Kuesioner  
Penulis melakukan kuesioner terhadap 20 responden dengan memberikan beberapa pertanyaan terkait data penelitian yang  diolah dalam sistem rekomendasi.  
b. Studi Literatur  
Pada tahapan ini, penulis melakukan pencarian dan perbandingan referensi yang terkait  dengan sistem rekomendasi, content -based filtering , algoritma apriori, pemrograman PHP dan beberapa artikel yang berhubungan dengan penelitian yang dilakukan.  
 
3. HASIL DAN  PEMBAHASAN  
3.1 Flowchart   
Flowchart  dibawah ini menggambarkan alur dari sistem rekomendasi skincare yang dimulai dari menginputkan data, perhitungan menggunakan Content-Based Filtering , perhitungan algoritma apriori. Setelah semua proses perhitungan selesai, maka akan tampil hasil rekomendasi skincare.  Gambar Flowchart  dapat dilihat pada Gambar 2 berikut :   
Gambar 2. Flowchart Sistem Rekomendasi  
3.2 Data Flow Diagram  
Data Flow Diagram  menggambarkan aliran proses yang terjadi pada sistem rekomendasi ini yang dimulai dari login, mengolah data hingga laporan. DFD dapat dilihat pada Gambar  dibawah ini  
Gambar 4. Data Flow Diagram  
3.3 Entity Relationship Diagram  
Berikut merupakan desain relasi antar entitas pada basis data yang diperlukan sesuai  dengan rancangan sistem yang akan dibuat, ERD dapat dilihat pada Gambar 3 dibawah ini :   
Gambar 3. Flowchart  Sistem Rekomendasi   
Studi Literatur  
Pengumpulan 
Data  
Analisa Sistem  
Perancangan 
Sistem  
Pengujian  
Evaluasi Sistem  
Dokumentasi  
3.4 Content-Based Filtering  
Metode Content -Based Filtering  merupakan metode dalam sistem rekomendasi yang mampu menghasilkan sebuah rekomendasi berdasarkan content /atribut  yang terkait dengan item lain yang dibandingkan.  Rekomendasi produk menurut hasil uraian kemiripan produk yang sudah ditafsir pemakainya adalah konsep dari Content-Based Filtering [3]. Metode ini  biasanya banyak diterapkan pada sistem penjualan online, film, berita, buku, musik dan lain-lain.  Terdapat tahap -tahap dalam Content-Based Filtering , diantaranya adalah sebagai berikut :  
a. Suatu item dipisah berdasarkan suatu vektor komponen pembentuknya.  
b. Pengguna akan memberikan nilai suka/tidak suka pada item pilihan yang nantinya akan membentuk sebuah rating pada item tersebut.  
c. Sistem akan membuat profil pengguna berdasarkan bobot vektor komponen suatu item. Pembuatan profil tersebut menggu nakan algoritma TF-IDF [4]. TF merupakan jumlah term dalam suatu dokumen. Sedangkan nilai IDF dapat dihitung menggunakan rumus :  
ð‘–ð‘‘ð‘“ ð‘–=log(ð‘›
ð‘‘ð‘“ð‘–)â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦ â€¦â€¦ .....(1)  
3.5 Algoritma  Apriori  
Algoritma apriori merupakan algoritma pengambilan data dengan aturan asosiasi untuk menentukan hubungan asosiatif suatu kombinasi itemset. Untuk menentukan kandidat kombinasi itemset dapat diperoleh dengan memperhatikan nilai minimum support dan nilai minimum confidence.  Banyaknya hasil rekomendasi yang ditampilkan tergantung dari nilai support dan nilai confidence yang diberikan [5 ]. Untuk mendapatkan nilai support suatu item dapat menggunakan rumus sebagai berikut :  
ð‘†ð‘¢ð‘ð‘ð‘œð‘Ÿð‘¡ (ð´)=(âˆ‘ ð‘¡ð‘Ÿð‘Žð‘›ð‘ ð‘Žð‘˜ð‘ ð‘–  ð‘šð‘’ð‘›ð‘”ð‘Žð‘›ð‘‘ð‘¢ð‘›ð‘”  ð´
ð‘‡ð‘œð‘¡ð‘Žð‘™  ð‘‡ð‘Ÿð‘Žð‘›ð‘ ð‘Žð‘˜ð‘ ð‘–) ..................  (2) 
Sedangkan rumus untuk menentukan nilai minimum support kombinasi 2 item adalah sebagai berikut :  
ð‘†ð‘¢ð‘ð‘ð‘œð‘Ÿð‘¡ (ð´,ðµ)=(âˆ‘ ð‘¡ð‘Ÿð‘Žð‘›ð‘ ð‘Žð‘˜ð‘ ð‘–  ð‘šð‘’ð‘›ð‘”ð‘Žð‘›ð‘‘ð‘¢ð‘›ð‘”  ð´ðµ
ð‘‡ð‘œð‘¡ð‘Žð‘™  ð‘‡ð‘Ÿð‘Žð‘›ð‘ ð‘Žð‘˜ð‘ ð‘–) ............  (3) 
Nilai confidence merupakan nilai kepastian kuatnya suatu hubungan antar item. Rumus mencari nilai confidence adalah sebagai berikut :  
Confidence =(âˆ‘ð‘¡ð‘Ÿð‘Žð‘›ð‘ ð‘Žð‘˜ð‘ ð‘–ð‘šð‘’ð‘›ð‘”ð‘Žð‘›ð‘‘ð‘¢ð‘›ð‘”ð´ðµ
âˆ‘ð‘‡ð‘Ÿð‘Žð‘›ð‘ ð‘Žð‘˜ð‘ ð‘–ð‘¦ð‘Žð‘›ð‘”ð‘šð‘’ð‘›ð‘”ð‘Žð‘›ð‘‘ð‘¢ð‘›ð‘”ð´)ð‘¥100% ...(4) 3.6 Association  Rule 
Association Rule  (aturan asosiasi) merupakan metode dalam data mining yang mencari sekumpulan item yang sering muncul secara bersamaan [6]. Assoc iation Rule  diperlukan suatu variabel ukuran yang ditentukan sendiri oleh user untuk menentukan batasan sebanyak apa hasil output  yang diinginkan oleh user.   
3.7 Simulasi Algoritma  
Perhitungan dengan menggunakan metode Content-Based Filtering  dan algoritma apriori memerlukan data produk dengan beberapa kriteria produk dan data pengguna skincare yang menggunakan produk skincare apa saja. Data produk yang diperlukan dapat dilihat pada tabel 1 berikut :  
Tabel 1. Data Produk  
No. Nama Produk  
1. Wardah Aloe Hydramild Facial Wash  
2. Y.O.U Simply Bright Facial Wash  
3. Npure Marigold Face Toner  
4. Viva Face Tonic  
5. Wardah  Lightening Face Toner  
6. Everwhite Peptide Anti Aging Serum  
7. Wardah Micro Gel Serum  
8. Roro Mendut Temulawak Pore Control Serum  
9. Everwhite Be Bright Day Cream  
10. Elsheskin Moisturizer for Acne Skin  
11. Wardah Perfect Bright SPF 28  
12. Key Glow  Snail Serum  
Kriteria yang diperlukan adalah jenis kulit, harga, usia dan juga kondisi kulit. Keterangan dari masing-masing kriteria, diantaranya adalah sebagai berikut :   
K1 = jenis kulit normal  
K2 = jenis kulit kering  
K3 = jenis kulit berminyak  
K4 = jenis kulit kombinasi  
K5 = jenis kulit sensitif  
K6 = harga  <50.000  
K7 = harga >50.000 - <100.000  
K8 = harga >100.000  
K9 = usia remaja  
K10 = usia dewasa  
K11 = kondisi kulit berjerawat  
K12 = kondisi kulit kusam  
K13 = kondisi kulit noda hitam  
Data produk yang dilengkapi dengan kriteria/atribut dari suatu item memiliki nilai dari kriteria berupa angka 1 untuk â€œYaâ€ dan angka 0 untuk â€œTidakâ€. Disebelah kanan kriteria merupakan data rating item yang di inputkan oleh user sebelumnya. Rating tersebut  digunakan untuk perhitungan mencari rating item lainnya.  
Tabel 2. Data Produk dan kriteria   
Kemudian data akan diolah dengan cara nilai kriteria item dikalikan dengan nilai rating setiap item. Setelah itu nilai tersebut akan dijumlahkan untuk mendapatkan total nilai per kriteria 1 hingga kriteria 13. Maka hasil nya seperti berikut  : 
Tabel 3. Proses Perhitungan Kriteria 
Kemudian dari hasil total kriteria di atas, maka perlu dilakukan normalisasi dan hasilnya dapat dilihat pada tabel dibawah ini:  
Tabel 4. Hasil Normalisasi   
Setelah mendapatkan hasil dinormalisasi, maka hasil tersebut akan dikalikan dengan  nilai kriteria dari item yang belum mendapatkan nilai rating. Kemudian dijumlah dan dikalikan dengan range tertinggi dari rating yaitu 10. Maka rating yang didapat dari kedua item adalah sebagai berikut :  
Tabel 5. Proses Perhitungan Rating  
Tabel 6. Data Pemakai Produk Skincare   
Daftar produk pada Tabel 6 diatas akan digunakan untuk perhitungan menggunakan algoritma apriori . Langkah yang digunakan adalah mencari nilai support item untuk kombinasi 1 itemset dengan minimum support yang ditentukan yaitu 40%.  
Tabel 7. Proses Perhitungan Support 1 itemset   
Dengan minimum support 40%, maka data yang terpilih dari kombinasi 1 item set dapat dilihat pada Tabel 7 dengan huruf bercetak tebal.  Selanjutnya akan dilakukan perhitungan untuk mencari kombinasi 2 itemset.   
Tabel 8. Proses Perhitungan Support 2 itemset   
Minimum support yang digunakan untuk kombinasi 2 itemset adalah  40%. Maka data yang terpilih dari kombinasi 2 itemset dapat dilihat pada Tabel 8 dengan produk berhuruf tebal . Selanjutnya membuat kombinasi 3 itemset dengan minimum support 40%. Kombinasi 3 itemset yang memenuhi minimum support 40% adalah sebagai berikut  : 
Tabel 9. Proses Perhitungan Support 3 itemset  
Kombinasi 3 itemset akan membentuk sebuah 
aturan asosiasi dengan keterangan sebagai berikut :  
Tabel 10. Hasil Aturan Asosiasi   
3.3 Implementasi Sistem  
1) Tampilan Halaman Login  
Halaman login merupakan halaman yang pertama kali akan muncul ketika program dijalankan. Pada halaman ini, admin atau pengguna akan diarahkan untuk login terlebih dahulu agar dapat mengakses halaman selanjutnya pada sistem rekomendasi skincare. Tampilan halaman login dapat dilihat  pada Gambar 5 sebagai berikut  :  
Gambar 5.Tampilan Login   
2) Tampilan  Halaman Utama  
Pada halaman utama terdapat sidebar di sebelah kiri. Dimana pada sidebar tersebut terdapat menu halaman utama, proses filtering, data pemakai  skincare,  proses apriori, hasil dan logout. Tampilan tersebut dapat dilihat pada Gambar 6 dibawah ini  :  
Gambar 6.Tampilan Halaman Utama   
3) Tampilan Proses Filtering  
Dalam form ini tersedia data produk skincare yang mana akan diolah dengan menambah, mengedit, menghapus dan menginput nilai suka untuk proses content -based filtering . Tampilan tersebut dapat dilihat pada Gambar 7 berikut:.  
Gambar 7.Tampilan  Proses Content-Based Filtering   
4) Tampilan  Hasil Filtering  
Hasil filtering akan ditampilkan pada halaman Proses Filtering dibagian paling bawah. Hasil ini berisi tabel yang memuat perankingan berdasarkan rating tertinggi hingga terendah. Tampilan ini dapat dilihat pada Gambar 8 sebagai berikut :  
Gambar 8. Tampilan Proses Content -Based Filtering  
5) Tampilan Proses Apriori  
Pada halaman ini pengguna dapat memilih range tanggal, menginputkan nilai minimum support dan nilai minimum confidence untuk diproses perhitungan apriori. Tampilan halaman tersebut dapat dilihat pada gambar d ibawah ini :  
Gambar 9. Tampilan Proses Apriori   
6) Tampilan  Hasil  
Pada halaman ini dapat dilihat laporan hasil akhir dalam bentuk tabel berisikan view rule, nilai support  dan nilai confidence . Pada tabel tersebut juga disediakan hasil laporan dalam bentuk pdf. Tampilan halaman hasil dapat dilihat pada Gambar 10 sebagai berikut :   
Gambar 10. Tampilan  Hasil  
 
4. SIMPULAN  
Berdasarkan hasil dan pembahasan sebelumnya, dapat diambil kesimpulan dari pembuatan sistem rekomendasi skincare  
menggunakan metode content-based filtering dan algoritma apriori , dalam usaha untuk membantu menyelesaikan permasalahan pengguna skincare,  maka dari penelitian ini dapat ditarik kesimpulan sebagai berikut :  
a. Sistem rekomendasi skincare berhasil dibangun dengan menggabungkan metode content-based filtering dengan algoritma apriori .   
b. Dengan dibangunnya sistem rekomendasi skincare menggunakan metode content-based filtering dan algoritma apriori  maka konsumen mampu meminimalisir terjadinya kesalahan pemilihan produk  skincare yang tidak tepat.  
 
5. SARAN  
Adapun saran yang dapat  diberikan  mengenai  penelitian  tentang  menentukan  rekomendasi  produk skincare, dapat  menentukan  rekomendasi  dengan  berbagai  metode  tidak  hanya  dengan  menggunakan  metode  Content-Based  Filtering  dan Algoritma  Apriori.  

DAFTAR PUSTAKA  
[1] Fiarni, C., & Maharani, H. 2019. Product Recommendation System Design Using Cosine Similarity and Content -based Filtering Methods . IJITEE (International Journal of Information Technology and E lectrical Engineering), 3(2), 42-48. 
[2] Sugiyono, Metode Penelitian Kuantitatif Kualitatif dan R & D . Bandung: CV. Alfabeta, 2017.  
[3] Lukas Tommy, Chandra Kirana & Vivi Lindawati (2019). Recommender System Dengan Kombinasi Apriori dan Content-Based Filte ring Pada Aplikasi Pemesanan Produk. Register: Jurnal TeknoInfo â€“ Vol.13, No. 2.  
[4] Wijaya,  A.,  &  Alfian,  D.  2018.  Sistem Rekomendasi  Laptop  Menggunakan  Collaborative  Filtering  Dan  Content-Based Filtering .  Jurnal   Computech  &  Bisnis,  12(1), 11-27. 
[5] Badriyah,  T.,  Fernando,  R.,  &  Syarif,  I.  2018. 
Sistem  Rekomendasi  Content  Based Filtering  Seminar Nasional Inovasi Teknologi  e-ISSN: 2549 -7952  UN PGRI Kediri, 24  Juli 2021    p-ISSN: 2580-3336  248 Menggunakan  Algoritma  Apriori . Konferensi  Nasional  Sistem  Informasi (KNSI) 2018.  
[6] Kusrini dan Emha T Luthfi, Algoritma Data Mining , Yogyakarta, Andi Offset, 2009 .",sistem rekomendasi,"Content-Based Filtering, Apriori",data produk skincare,"support, confidence"
SISTEM REKOMENDASI PENENTUAN DOSEN PEMBIMBING TUGAS AKHIR DENGAN MENGGUNAKAN ALGORITMA RABIN-KARP,"SISTEM REKOMENDASI PENENTUAN DOSEN PEMBIMBING TUGAS AKHIR DENGAN MENGGUNAKAN ALGORITMA RABIN-KARP

Abu Salam1, Verdian Putra Wicaksana2, Khafiizh Hastuti3

Abstrak
Penentuan dosen pembimbing tugas akhir merupakan faktor penting terhadap pengerjaan tugas akhir mahasiswa. Namun, kurangnya informasi mengenai dosen pembimbing dapat 
menghambat mahasiswa dalam melakukan penentuan dosen pembimbing. Dengan demikian, diperlukan sistem yang dapat membantu mahasiswa sehingga dapat dimudahkan dalam 
melakukan penentuan dosen pembimbing tugas. Masalah tersebut yang menjadi dasar penelitian ini. Penelitian  dilakukan dengan mengembangkan sistem berbasis web dengan menggunakan metode pengembangan sistem web-engineering dan menerapkan algoritma Rabin-Karp yang merupakan algoritma pencocokan pola string. Peran algoritma Rabin-Karp dalam sistem ini yaitu melakukan pencocokan pola string antara topik tugas akhir mahasiswa dengan judul penelitan yang telah dilakukan oleh setiap dosen pembimbing untuk mendukung sistem dalam memberikan rekomendasi kepada mahasiswa mengenai dosen pembimbing tugas akhir. Sistem rekomendasi penentuan dosen pembimbing tugas akhir yang dihasilkan dari penelitian ini dapat memberikan rekomendasi kepada mahasiswa mengenai dosen pembimbing tugas akhir yang telah melakukan penelitian sesuai dengan topik tugas akhir mahasiswa. Namun masih perlu adanya perubahan maupun peningkatan algoritma agar mampu menghasilkan rekomendasi yang memiliki performa lebih baik dan tidak bergantung pada data penelitian dosen pembimbing.
 
Kata Kunci: Sistem rekomendasi, dosen pembimbing, Algoritma Rabin-Karp, web-engineering
 
Abstract 
Determining in thesis advisor is an important factor in process of student thesis. However, lack information about thesis advisor can inhibit student in determining an advisor for their thesis. Thus, a system is needed that can help student in determining thesis advisor. That problem is the basis of this research. This research is about developing a web-based system that is developed by using web-engineering, a system development method, and using Rabin-Karp algorithm, a string pattern-matching algorithm. Role of Rabin-Karp algorithm in this system is to do string pattern matching between thesis topic and title of research that have been done by each thesis advisor to support the system in providing recommendation to students about thesis advisor. Recommendation system in determining thesis advisor resulting from this research can provide recommendation to students about thesis advisor that have been done researches that is suit with student thesis topic. But there is still need for change and improvement of the algorithm so that the system can be able provide a better recommendation and does not depend on data of thesis advisor research.  

Keywords : Recommendation system, thesis advisor, Rabin-Karp algorithm, web-engineering

1. PENDAHULUAN  
Menurut Undang - Undang Republik Indonesia nomor 12 tahun 2012 tentang Pendidikan Tinggi, pendidikan tinggi berfungsi mengembangkan kemampuan dan membentuk watak serta peradaban bangsa yang bermartabat dalam rangka mencerdaskan kehidupan bangsa [1]. Pendidikan tinggi memiliki beberapa tingkatan yang mana setiap mahasiswa yang menyelesaikan setiap tingkatan pada pendidikan tinggi akan mendapatkan suatu gelar, misalnya mahasiswa Strata Satu (S1) akan mendapatkan gelar sarjana apabila telah menyelesaikan studinya dalam jangka waktu tidak lebih dari yang telah ditentukan. Mahasiswa S1 yang ingin menyelesaikan studinya harus memenuhi beberapa syarat. Salah satu yang menjadi syarat mahasiswa menyelesaikan pendidikan jenjang S1 yaitu tugas akhir [2]. Tugas Akhir adalah suatu karya ilmiah berdasarkan kegiatan mandiri mahasiswa berupa hasil penelitian yang membahas suatu masalah yang sesuai dengan bidang ilmu pada program studi yang ditempuh oleh mahasiswa dengan menggunakan aturan yang berlaku dan dibimbing oleh dosen pembimbing [2]. Mahasiswa akan melakukan bimbingan dengan dosen pembimbing tugas akhir selama proses pengerjaan tugas akhir. Dosen pembimbing tugas akhir memiliki peran penting karena memiliki tanggung jawab untuk memastikan bahwa mahasiswa mampu menyusun tugas akhir dengan baik hingga tugas akhir tersebut siap diujikan dan berkualitas [3]. Peranan dosen pembimbing tugas akhir secara garis besarnya: (1) sebagai organisator, (2) sebagai fasilitator, (3) sebagai inovator, (4) sebagai penemu, (5) sebagai teladan, (6) sebagai evaluator, (7) sebagai pemandu, (8) sebagai pencipta, (9) sebagai konselor, dan (10) sebagai motivator, penyemangat, dan pemberi energi [4]. Oleh karena itu, penentuan dosen pembimbing tugas akhir juga memiliki faktor penting karena akan berpengaruh terhadap bimbingan yang akan dilakukan oleh mahasiswa selama proses pengerjaan tugas akhir.  Mahasiswa dapat dimudahkan dalam melakukan penentuan dosen pembimbing tugas akhir apabila terdapat sistem yang dapat memberikan rekomendasi kepada mahasiswmengenai dosen pembimbing yang memiliki keahlian dalam bidang ilmu yang sesuai dengan topik tugas akhir mahasiswa. Penelitian mengenai sistem rekomendasi telah dilakukan oleh Anand Shanker Tewari, Abhay Kumar, dan Asim Gopal Barman [5] dalam penelitiannya yang berjudul â€œBook Recommendation System Based on Combine Features of Content Based Filtering, Collaborative Filtering and Association Rule Miningâ€. Sistem rekomendasi yang dihasilkan dari penelitian tersebut dapat memberikan rekomendasi kepada pembeli mengenai buku yang dia tertarik. Sistem rekomendasi tersebut menggunakan beberapa parameter, seperti isi buku dan kualitas buku berdasarkan rating yang diberikan oleh pembeli lain  Sistem pendukung keputusan dengan menerapkan metode simple additive weighting diusulkan oleh Pristiwanto [6] untuk penentuan dosen pembimbing tugas akhir. Namun, penelitian tersebut 
memiliki kelemahan karena hanya mencakup 2 bidang keahlian yaitu komputer dan non komputer sehingga metode simple additive weighting tidak sesuai pada penelitian yang akan dilakukan yang mana dapat menangani banyak bidang keahlian.
Sistem rekomendasi pada penelitian ini tidak menggunakan beberapa metode yang biasanya dilakukan pada sistem rekomendasi pada umumnya karena tidak adanya unsur rating pada parameter yang akan digunakan pada penelitian ini. Parameter yang digunakan pada penelitian ini yaitu topik tugas akhir mahasiswa dan judul penelitian yang telah dilakukan oleh setiap dosen. Sistem rekomendasi pada penelitian ini akan memanfaatkan algoritma Rabin-Karp merupakan algoritma pencocokan string yang dapat menangani kelemahan cakupan bidang keahlian yang terdapat pada penelitian yang dilakukan oleh Pristiwanto [6] dan dapat menangai seluruh parameter yang digunakan pada sistem rekomendasi ini. Sebelumnya, algoritma Rabin-Karp telah digunakan Salmuasih untuk melakukan penelitian yang berjudul â€œPerancangan Sistem Deteksi Plagiat pada Dokumen Teks dengan Konsep Similarity Menggunakan Algoritma Rabin-Karpâ€ [7]. Algoritma Rabin-Karp juga telah digunakan pada suatu penelitian yang berjudul â€œImplementasi Algoritma Rabin-Karp untuk Menentukan  Keterkaitan Antara Publikasi Penelitian Dosen Tahun 2013â€ [8]. Algoritma Rabin-Karp digunakan dalam penelitian ini karena dapat melakukan pencocokan pola string antara topik tugas akhir mahasiswa dengan judul penelitian yang telah dilakukan oleh setiap dosen pembimbing tugas akhir sehingga dapat menentukan dosen pembimbing tugas akhir tanpa bergantung pada jumlah bidang keahlian.  Penelitian ini akan menggunakan algoritma Rabin-Karp dalam perancangan sistem rekomendasi dalam penentuan dosen pembimbing tugas akhir sehingga dapat memberikan rekomendasi dosen pembimbing tugas akhir yang telah melakukan penelitian yang sesuai dengan topik tugas akhir mahasiswa.     

2. METODE  
Penelitian mengenai penerapan sistem rekomendasi pernah dilakukan oleh Pearl Pu, Li Chen, dan Rong Hu [9] dalam penelitiannya yang berjudul """" A User-Centric Evaluation Framework for Recommender Systemsâ€. Berdasarkan penelitian tersebut, tugas utama dari sistem rekomender adalah menyarankan item yang menarik bagi pengguna dan kualitas item yang ditawarkan menentukan kesuksesan sistem tersebut. Penelitian ini menjelaskan beberapa hal yang mempengaruhi kualitas rekomendasi. Hal pertama yaitu sejauh mana pengguna menganggap bahwa rekomendasi yang diberikan sesuai dengan selera dan preference mereka. Kedua, bagaimana pengguna menerima rekomendasi baru dan dianggap menarik. Ketiga, bagaimana item yang direkomendasikan dapat memberi daya tarik kepada pengguna. Keempat, tingkat keanekaragaman item dalam daftar rekomendasi. Dan yang terakhir, apakah rekomendasi mempertimbangkan konteks umum.  Penelitian mengenai sistem untuk menentukan dosen pembimbing tugas akhir telah dilakukan oleh Pristiwanto sebelumnya pada penelitan yang berjudul â€œSistem Pendukung Keputusan dengan Metode Simple Additive Weighting untuk Menentukan Dosen Pembimbingâ€. Sistem tersebut menggunakan fuzzy dengan menerapkan metode simple additive weighting dalam menentukan keputusan dengan cara menentukan bobot pada setiap atribut. Atribut-atribut yang digunakan pada penelitian tersebut adalah 4 kriteria yang menjadi bahan pertimbangan dalam proses penentuan dosen pembimbing tugas akhir, yaitu: pendidikan, status, bidang keahlian, dan golongan. Bobot nilai pada setiap kriteria ditentukan oleh setiap kategori yang terdapat pada setiap kriteria, misal: kriteria bidang keahlian memiliki 2 kategori yaitu komputer yang bobot nilai 1 dan non komputer yang memiliki bobot nilai 0,50 [6].   Penelitian mengenai penerapan algoritma Rabin-Karp pernah dilakukan oleh Salmuasih [7] dalam penelitiannya yang berjudul """"Perancangan Sistem Deteksi Plagiat pada Dokumen Teks dengan Konsep Similarity Menggunakan Algoritma Rabin Karpâ€. Penelitian tersebut memanfaatkan algoritma Rabin-Karp dalam mencocokan string (string matching) antara suatu dokumen teks dengan dokumen teks lainnya dengan tujuan untuk mendeteksi unsur plagiat antar dokumen teks tersebut.   Penelitian mengenai penerapan algoritma Rabin-Karp juga pernah dilakukan oleh Handrie Noprisson, Boko Susilo, dan Ernawati pada penelitiannya yang berjudul Implementasi Algoritma Rabin-Karp untuk Menentukan Keterkaitan Antar Publikasi Penelitian Dosen Tahun 2013 (Studi Kasus: Website Lembaga Penelitian Universitas Bengkulu)â€œ. Algoritma Rabin-Karp pada penelitian tersebut dimanfaatkan untuk melakukan pencocokan string antar dua dokumen teks dengan tujuan agar sistem dapat memberikan rekomendasi 5 judul jurnal terhadap user sistem yang memiliki keterkaitan dengan jurnal yang sedang diakses oleh user tersebut [8].   Sistem pendukung keputusan dengan metode simple additive weigthing untuk menentukan dosen pembimbing yang dihasilkan pada penelitian yang dilakukan oleh Pristiwanto [6] kurang efektif karena hanya memiliki 2 kategori pada kriteria bidang keahlian yaitu komputer dan non komputer. Berdasarkan penelitian mengenai algoritma Rabin-Karp yang dikemukakan di atas, algortima tersebut dapat dimanfaatkan dalam penerapan pada sistem rekomendasi dalam penentuan dosen pembimbing tugas akhir. Berdasarkan dua pernyataan diatas, Penelitian yang akan dilakukan yaitu perancangan suatu sistem rekomendasi yang dapat memberikan rekomendasi terhadap mahasiswa dalam penentuan dosen pembimbing tugas akhir yang dapat melibatkan banyak kategori pada kriteria bidang keahlian dengan memanfaatkan algoritma Rabin-Karp dalam pencocokan string yang memiliki tujuan untuk melakukan pencocokan antara kata kunci topik tugas akhir yang diusulkan oleh mahasiswa dengan kata kunci pada penelitian yang telah dilakukan oleh setiap dosen dan bidang ilmu yang dikuasai oleh setiap dosen. Sistem rekomendasi tersebut juga akan menangani aspek - aspek kualitas rekomendasi seperti yang dijelaskan pada penelitian yang dilakukan oleh Pearl Pu, Li Chen, dan Rong Hu[9].  Metode yang diusulkan dalam penelitian ini adalah dengan menerapkan algoritma Rabin-Karp pada sistem rekomendasi dalam penentuan dosen pembimbing tugas akhir.  
Gambar 9. Tahap Algoritma Rabin-Karp  
Algoritma Rabin-Karp adalah algoritma pencocokan pola string yang menggunakan dengan cara mengubah setiap karakter pada teks menjadi numerik dengan menggunakan fungsi hash.  Penerapan algoritma Rabin-Karp pada sistem rekomendasi dalam penentuan dosen pembimbing tugas akhir ini mencakup beberapa tahap, yaitu: 
a. Data yang akan dianalisis berupa string pada topik tugas akhir dan string pada judul penelitian yang telah dilakukan oleh setiap dosen pembimbing tugas akhir. 
b. Menghilangkan tanda spasi pada kedua string dan mengubah seluruh karakter pada kedua string menjadi huruf kecil atau lowercase. 
c. Melakukan string parsing pada string topik tugas akhir mahasiswa dan string judul penelitian dosen pembimbing. 
d. Melakukan pencocokan pola string antara string pada topik tugas akhir dengan string pada judul penelitian yang telah dilakukan oleh dosen pembimbing tugas akhir menggunakan algoritma Rabin-Karp. 
e. Apabila terdapat kesamaan hash value yang dihasilkan dari fungsi hash pada saat melakukan algoritma Rabin-Karp antara string pada topik tugas akhir dengan string pada judul penelitian yang telah dilakukan oleh dosen pembimbing tugas akhir, maka akan dilakukan pencocokan karakter per karakter pada kedua string tersebut dan apabila terdapat kecocokan secara keseluruan karakter pada kedua string tersebut maka dilakukan pembobotan nilai terhadap dosen pembimbing tersebut atas topik tugas akhir tersebut. 
f. Sistem akan memberikan rekomendasi dosen pembimbing tugas akhir berdasarkan kecocokan judul penelitian sesuai dengan topik tugas akhir tersebut dengan urutan bobot nilai secara descending.  
 
3. HASIL DAN PEMBAHASAN 
3.1 Implementasi Login 
Implementasi antarmuka halaman login pada sistem rekomendasi ini yaitu sebagai berikut:   
Gambar 10. Antarmuka Login  
Sebelum mengakses fungsi-fungsi utama sistem rekomendasi dosen pembimbing, user diharuskan untuk melakukan login pada antarmuka login tersebut.  
3.2 Implementasi Pemilihan Dosen Pembimbing Tugas Akhir Antarmuka rekomendasi penentuan dosen pembimbing akan muncul apabila user berhasil melakukan login sebagai mahasiswa. Berikut adalah antarmuka pemilihan dosen pembimbing tugas akhir:
Gambar 11. Antarmuka Pemilihan Dosen Pembimbing  
Antarmuka pemilihan dosen pembimbing tugas akhir terdiri dari beberapa bagian yaitu: bagian input peminatan (RPLD, IF, atau SKKD), bagian input topik tugas akhir mahasiswa, dan bagian daftar rekomendasi dosen pembimbing yang akan muncul sesuai dengan input peminatan dan topik tugas akhir mahasiswa. Mahasiswa hanya dapat memilih salah satu dosen pembimbing dan apabila mahasiswa telah memilih salah satu dari dosen pembimbing tersebut maka akan muncul antarmuka mengenai informasi dosen pembimbing yang dipilih seperti pada gambar berikut:   
Gambar 12. Antarmuka Dosen Pembimbing Terpilih   
Mahasiswa dapat mengganti dosen pembimbing dengan menekan tombol â€œBatal Pilihâ€ pada antarmuka tersebut. Hasil uji coba penerapan algoritma Rabin-Karp dalam mendukung proses rekomendasi dosen pembimbing tugas akhir dapat dilihat pada gambar berikut:   
Gambar 13. Antarmuka Uji Coba Pemilihan Dosen Pembimbing  
Berdasarkan gambar di atas, dapat disimpulkan bahwa rekomendasi dosen pembimbing yang teratas yaitu Ajib Susanto, M.Kom. Hal ini dikarenakan Ajib Susanto, M.Kom memiliki bidang kajian RPLD dan telah melakukan penelitian terkait dengan inputan topik tugas akhir, yaitu e-commerce. Berikut adalah daftar penelitian yang telah dilakukan oleh Ajib Susanto, M.Kom:   
Gambar 14. Daftar Penelitian Ajib Susanto, M.Kom  
Pengujian black-box dilakukan untuk menguji apakah sistem telah berfungsi sesuai kebutuhan fungsional sistem. Berikut adalah hasil pengujian black-box pada sistem rekomendasi penentuan dosen pembimbing tugas akhir :   
Tabel 1: Hasil Pengujian Black-Box 
No Kasus Uji Output yang diharapkan Hasil 
1 Login Menampilkan halaman login. Sesuai 
2 Halaman utama mahasiswa Menampilkan halaman beranda mahasiswa. Sesuai 
3 Halaman utama dosen pembimbing Menampilkan halaman beranda dosen pembimbing. Sesuai 
4 Halaman utama administrator Menampilkan halaman beranda administrator. Sesuai 
5 Daftar mahasiswa Menampilkan daftar mahasiswa yang tersimpan dalam sistem. Sesuai 
6 Daftar dosen pembimbing Menampilkan daftar dosen pembimbing yang tersimpan dalam sistem. Sesuai 
7 Daftar dosen pembimbing mahasiswa Menampilkan daftar relasi dosen pembimbing dan mahasiswa yang tersimpan dalam sistem. Sesuai 
8 Daftar Penelitian Menampilkan daftar penelitian yang tersimpan dalam sistem. Sesuai 
9 Edit profil Menyimpan data profil yang baru dalam database. Sesuai 
10 Tambah mahasiswa Menyimpan data mahasiswa dalam database. Sesuai 
11 Tambah dosen pembimbing Menyimpan data dosen pembimbing dalam database. Sesuai 
12 Tambah penelitian Menyimpan data penelitian dalam database. Sesuai 
13 Tambah relasi dosen pembimbing mahasiswa Menyimpan relasi dosen pembimbing mahasiswa dalam database. Sesuai 
14 Edit mahasiswa Mengubah data mahasiswa dalam database. Sesuai 
15 Edit dosen pembimbing Mengubah data dosen pembimbing dalam database. Sesuai 
16 Edit penelitian Mengubah data penelitian dalam database. Sesuai 
17 Edit relasi dosen pembimbing mahasiswa Mengubah relasi dosen pembimbing mahasiswa dalam database. Sesuai 
18 Simpan kata kunci topik Menyimpan kata kunci topik tugas akhir dalam database. Sesuai 
19 Rekomendasi dosen pembimbing Menampilkan rekomendasi dosen pembimbing sesuai dengan inputan topik tugas akhir Sesuai  
Berdasarkan hasil uji coba penerapan algoritma Rabin-Karp dan hasil pengujian black-box pada sistem rekomendasi penentuan dosen pembimbing tugas akhir, dapat dilihat bahwa sistem yang dibangun telah memenuhi kebutuhan fungsionalitasnya dan penerapan algoritma Rabin-Karp dapat mendukung sistem dalam melakukan rekomendasi dosen pembimbing berdasarkan kecocokan pola string topik tugas akhir mahasiswa terhadap penelitian yang telah dilakukan oleh setiap dosen pembimbing.   

4. KESIMPULAN DAN SARAN   
4.1 Kesimpulan  
Kesimpulan yang dapat didapat dari pembahasan atas hasil penelitian ini yaitu sebagai berikut: 
1. Sistem rekomendasi penentuan dosen pembimbing tugas akhir yang dibangun dapat menghasilkan rekomendasi daftar pilihan dosen pembimbing tugas akhir yang telah melakukan penelitian sesuai dengan topik tugas akhir mahasiswa sehingga dapat memudahkan mahasiswa dalam menentukan dosen pembimbing tugas akhir. Daftar rekomendasi dosen pembimbing yang dihasilkan diurutkan berdasarkan bobot nilai setiap dosen pembimbing tugas akhir terhadap topik tugas akhir mahasiswa secara descending. 
2. Sistem rekomendasi penentuan dosen pembimbing tugas akhir yang dibangun menerapkan algoritma Rabin-Karp dalam melakukan pencocokan pola string antara topik tugas akhir mahasiswa dengan judul penelitian yang telah dilakukan oleh dosen pembimbing tugas akhir. Penerapan algoritma Rabin-Karp dapat membantu sistem dalam melakukan proses perekomendasian dosen pembimbing tugas akhir mahasiswa terhadap mahasiswa. Tahapan pencocokan string pada algoritma Rabin-Karp pada sistem rekomendasi penentuan dosen pembimbing ini terdiri dari 2 tahap pencocokan yaitu pencocokan hash value dan pencocokan setiap karakter pada kedua string. 
3. Sistem rekomendasi penentuan dosen pembimbing tugas akhir dirancang dan dibangun dengan tampilan yang sederhana agar mudah digunakan oleh pengguna yang terdiri dari administrator, dosen pembimbing tugas akhir, dan mahasiswa. Fitur-fitur yang disediakan pada sistem rekomendasi ini merupakan fitur utama yang diperlukan dalam melakukan rekomendasi penentuan dosen pembimbing tugas akhir.  
4.2 Saran 
Penelitian dalam rancang bangun sistem rekomendasi penentuan dosen pembimbing ini masih memiliki beberapa kekurangan dan kelemahan yang dapat dikembangkan dalam penelitian selanjutnya. Saran bagi penelitian selanjutnya yaitu sebagai berikut:  
1. Sistem rekomendasi penentuan dosen pembimbing tugas akhir hanya fokus pada sistem rekomendasinya saja dan tidak memiliki fitur-fitur untuk menangani kegiatan setelah pemilihan rekomendasi seperti : bimbingan online, pendaftaran sidang tugas akhir, dan penjadwalan sidang tugas akhir. 
2. Sistem rekomendasi penentuan dosen pembimbing tugas akhir menerapkan algoritma Rabin-Karp untuk melakukan pencocokan pola string namun hasil rekomendasi yang dihasilkan oleh sistem ini sangat bergantung pada jumlah data penelitian. Sehingga semakin banyak data penelitian yang terdapat pada sistem ini mengakibatkan semakin akuratnya rekomendasi yang dihasilkan. Diharapkan terdapat suatu metode atau algoritma yang mendukung dalam sistem rekomendasi penentuan dosen pembimbing tugas akhir ini yang memiliki performa yang tidak bergantung pada jumlah data penelitian.
 
DAFTAR PUSTAKA
[1] Pendidikan Tinggi,"""" in Undang - Undang Republik Indonesia Nomor 12 Tahun 2012. Jakarta. 
[2] Tim Penyusun Buku Pedoman Tugas Akhir Fasilkom UDINUS, Buku Pedoman Tugas Akhir TI-S1 Fasilkom UDINUS, 2nd ed. Semarang, 2013. 
[3] R. M. Hariyati, """"Survey Kinerja Dosen Pembimbing Skripsi dan Kualitas Skripsi Mahasiswa Akuntansi STIE Malangkucecwara,"""" Jurnal Dinamika Akuntansi, vol. 4, pp. 121-128, September 2012. 
[4] Zulkifli N., """"Persepsi Mahasiswa Tentang Peranan Dosen Pembimbing Dalam Pembuatan Tugas Akhir (Skripsi) Mahasiswa Pada Program Studi Administrasi Pendidikan Fkip Universitas Riau Pekanbaru (2011),"""" EDUCHILD, vol. 1, pp. 50-58, 2012. 
[5] A.S. Tewari, A. Kumar, and A.G. Barman, """"Book recommendation system based on combine features of content based filtering, collaborative filtering and association rule mining,"""" in Advance Computing Conference (IACC), 2014 IEEE International, Gurgaon, 2014, pp. 500-503. 
[6] Pristiwanto, """"Sistem Pendukung Keputusan dengan Metode Simple Additive Weighting untuk Menentukan Dosen Pembimbing Skripsi,"""" Majalah Ilmiah Informasi dan Teknologi Ilmiah (INTI), vol. II, pp. 11-15, February 2014.
[7] Salmuasih, """"Perancangan Sistem Deteksi Plagiat pada Dokumen Teks dengan Konsep Similarity Menggunakan Algoritma Rabin Karp ,"""" Sekolah Tinggi Manajemen Informatika dan Komputer AMIKOM, Yogyakarta, Skripsi 2013. 
[8] H. Noprisson, B. Susilo, and Ernawati, """"Implementasi Algoritma Rabin-Karp untuk Menentukan Keterkaitan Antar Publikasi Penelitian Dosen Tahun 2013 (Studi Kasus: Website Lembaga Penelitian Universitas Bengkulu),"""" Jurnal Teknologi Informasi, vol. 9, Oktober 2013. 
[9] P. Pu, L. Chen, and R. Hu, """"A User-Centric Evaluation Framework for Recommender Systems,"""" in Proceedings of the fifth ACM conference on Recommender systems, New York, United States of America, 2011, pp. 157-164.",sistem rekomendasi,Rabin-Karp,"topik tugas ahir, dosen pembimbing tugas ahir",
PERFORMA APRIORI DAN COLLABORATIVE FILTERING UNTUK SISTEM REKOMENDASI,"PERFORMA APRIORI DAN COLLABORATIVE FILTERING UNTUK SISTEM REKOMENDASI

Albertus Bayu Aji Priyono

Abstrak   
Sistem rekomendasi adalah sebuah program yang mencoba untuk memprediksi sebuah item (lagu, buku, film, berita dan sebagainya) berdasarkan informasi yang diperoleh dari pengguna. Informasi yang diberikan oleh pengguna dapat diperoleh secara eksplisit dan implisit yang merupakan proses pembangkitan profil pengguna. Yang dimaksud secara eksplisit adalah informasi tersebut diberikan langsung oleh pengguna. Misalnya, memberikan rating terhadap film yang pernah ditonton. Sedangkan yang dimaksud secara implisit adalah informasi tersebut diperoleh tanpa diketahui oleh pengguna. Misalnya, dengan melakukan penelusuran dari transaksi yang pernah dilakukan oleh pengguna. Pembuatan sistem rekomendasi lokasi pariwisata dengan menggunakan metode Collaborative Filtering dan Algoritma Apriori bertujuan untuk menghasilkan sebuah sistem yang secara otomatis melakukan perhitungan dalam memberikan rekomendasi objek pariwisata yang tepat bagi pengguna yang menjadi target rekomendasi serta menghasilkan paket perjalanan wisata berdasarkan pola kebiasaan wisatawan dalam mengunjungi tempat wisata favoritnya.  

Kata Kunci : sistem rekomendasi, apriori, collaborative filtering  

Abstract   
Recommendation system is a program that tries to predict an item (song, book, movie, news, etc.) based on information obtained from the user. The information provided by the user can be obtained explicitly and implicitly that a userâ€™s profile generation process. Which is explicitly referred to the information given directly by the user. For example, a rating of the film ever watched. While the definition of the information that taken by implicitly is obtained without being noticed by the user. For example, by doing a search of the transactions that have been done by the user. Tourism recommendation system using the Collaborative Filtering and Apriori algorithm aims to produce a system that automatically perform calculations in providing appropriate recommendations tourism attraction for target users and generate recommendations based on the pattern of travel package tourists in the habit of visiting his favorite sights.  

Keyword : recomenndation system, apriori, collaborative filtering  

PENDAHULUAN    
Sistem rekomendasi dapat mem-bantu para pengguna menemukan infor-masi tersebut dengan memberikannya sa-ran secara personal. Kemampuan suatu sistem rekomendasi yaitu menyesuaikan outputnya sesuai karateristik pengguna tertentu, dimana hal ini menyiratkan bah-wa sistem tersebut harus dapat menyim-pulkan apa yang pengguna butuhkan berdasarkan kegiatan sebelumnya atau interaksi dengan pengguna atau pengguna serupa lainnya. Selain itu, sistem reko-mendasi juga dapat membantu travel agent dalam pembuatan paket yang tepat sesuai kombinasi objek wisata yang didapatkan dari pola kebiasaan wisata-wan. Dari kedua hal tersebut, dapat di-tarik kesinambungan antara rekomendasi bagi pengguna dan rekomendasi paket wisata bagi penyedia perjalanan wisata, sehingga didapatkan objek dan paket wisata yang tepat bagi pengguna. Terdapat 2 pendekatan sistem reko-mendasi dalam proses rekomendasi, yaitu Content Based Filtering dan Collabo-rative Filtering. Dalam penelitian ini di-implementasikan kedua pendekatan ter-sebut. Namun setiap proses memiliki ke-lebihan dan kekurangannya masing â€“ ma-sing. Kelebihan metode Content Based Filtering (CBF) dibandingkan dengan Collaborative Filtering (CF) adalah dapat merekomendasikan item baru kepada target pengguna berdasarkan kemiripan fitur yang dikandung oleh item sebe-lumnya yang disukai pengguna tersebut dengan melihat rating item yang positif, tidak seperti Collaborative Filtering yang sangat bergantung dengan perhitungan rating oleh pengguna lainnya  [1]. Untuk menganalisis pola â€“ pola kombinasi item dalam penelitian ini digunakan Algoritma Apriori. Kelebihan aturan asosiasi dengan Apriori ini adalah lebih sederhana dan dapat menangani data yang besar  [3]. Sedangkan algoritma lainnya memi-liki kelemahan dalam penggunaan memo-ri saat jumlah data besar, tentunya ber-pengaruh terhadap banyaknya item yang diproses. Penting tidaknya aturan asosi-sasi dapat diketahui dengan 2 parameter, minimum support (prosentase kombinasi item dalam database) dan minimum con-fidence (kuatnya hubungan antar item da-lam aturan asosiatif), keduanya ditentu-kan oleh pengguna. Penggunaan Apriori ditujukan untuk menemukan peraturan asosiasi dalam sistem rekomendasi ber-basis content yang terlihat dari keterhu-bungan antara pola kebiasaan wisatawan dalam mengunjungi objek wisata. Se-hingga diharapkan, sistem rekomendasi yang dibangun ini dapat memberikan rekomendasi yang tepat bagi seorang pengguna tersebut terhadap munculnya item baru nantinya.  

METODE PENELITIAN    
Proses kerja sistem dibagi menjadi 3 tahapan besar, yaitu pengumpulan data melalui interaksi pengguna dengan sis-tem, perhitungan rekomendasi lokasi pa-riwisata untuk pengguna dengan meng-gunakan pendekatan Collaborative Filte-ring dan perhitungan pola kebiasaan wi-satawan untuk menentukan paket wisata sesuai objek wisata yang sering dikun-jungi oleh wisatawan dengan mengguna-kan Algoritma Apriori. Dua metode utama yang digunakan dalam penelitian ini adalah Collaborative Filtering dan Algoritma Apriori. Colla-borative Filtering bekerja dengan cara menjumlahkan rating atau pilihan dari suatu produk, menemukan profil / pola pengguna dengan melihat history rating yang diberikan pengguna, dan menghasil-kan suatu rekomendasi baru berdasarkan perbandingan antar pola pengguna  [2]. Biasanya nilai rating dapat berupa binary (suka/tidak suka) atau voting.   
Gambar 1 : Alur Proses Collaborative Filtering   
Gambar 2 : Alur Proses Algoritma Apriori Algoritma 
Apriori melakukan pen-carian frequent itemset dengan menggu-nakan teknik association rule. Algoritma ini menggunakan pengetahuan frekuensi atribut yang telah diketahui sebelumnya untuk memproses informasi selanjutnya. Pada Algoritma Apriori menentukan kan-didat yang mungkin muncul dengan cara memperhatikan minimum support dan minimum confidence. Support adalah nilai pengunjung atau persentase kom-binasi sebuah item dalam database [4].Tahapan pertama dalam perhitungan Algoritma Apriori untuk menemukan association rules yaitu mengumpulkan data transaksi yang terjadi dalam periode tertentu. Tahapan berikutnya adalah membuat tabel tabular untuk melakukan perhitungan jumlah kunjungan di masing-masing objek wisata. Pada tahap ini, dapat dilihat jumlah kunjungan yang terjadi pada objek wisata sebanyak data transaksi. Langkah selanjutnya adalah mem-buat kombinasi 2 itemsets pada setiap objek wisata dan frekuensi masing-ma-sing kombinasi dihitung sesuai dengan data tabular pada tabel. Setelah frekuensi masing-masing itemsets ditemukan, lang-kah selanjutnya menyeleksi frekuensi yang lebih besar atau sama dengan batas minimal yang telah ditentukan. Tahapan selanjutnya adalah menganalis hasil dari langkah sebelumnya. Apabila terdapat itemsets yang tidak memenuhi batas mi-nimum dari jumlah frekuensi yang telah ditentukan, maka itemsets tersebut tidak dipergunakan pada perhitungan selan-jutnya. Kemudian langkah berikutnya ada-lah dengan membuat 3 itemset yang se-suai dengan susunan kombinasi yang baru. Setelah dilakukan penyesihan yang sama dengan cara sebelumnya apabila terdapat itemsets yang tidak memenuhi batas minimun support, maka selanjutnya dilakukan perhitungan persentase confi-dence berdasarkan data yang baru. Sete-lah itu baru dilakukan perhitungan final untuk nilai rekomendasi, yaitu support dikalikan dengan confidence [5].  

HASIL DAN PEMBAHASAN 
Pada proses perhitungan rekomen-dasi, terdiri dari dua bagian yaitu perhi-tungan berdasarkan metode Collaborative Filtering untuk rekomendasi pengguna dan perhitungan berdasarkan Algoritma Apriori untuk rekomendasi paket wisata berdasarkan pola kebiasaan pengguna. Proses perhitungan nilai rekomendasi menggunakan metode Collaborative Fil-tering digunakan untuk mendapatkan objek - objek wisata yang akan direko-mendasikan kepada pengguna yang sedang login di dalam sistem. Pada dasar-nya Collaborative Filtering dibagi men-jadi dua jenis, yaitu : (1) User Based Collaborative Filtering, yaitu mem-berikan rekomendasi berdasarkan opini pengguna lain yang memiliki kesukaan yang sama dengan pengguna yang men-jadi target rekomendasi. (2) Item Based Collaborative Filtering, menghitung tingkat kesamaan antara beberapa produk yang berbeda berdasarkan penilaian pengguna. Pada penelitian ini, digunakan User Based Collaborative Filtering untuk menghasilkan nilai rekomendasi yang berbeda- beda untuk setiap penggunanya, sehingga memiliki saran yang lebih personal berdasarkan kemiripan aktifitas serta kesukaan dengan pengguna lainnya.  
Tabel 1 : Pemberian Nilai Objek Pariwisata 
Pengguna Objek Pariwisata Nilai John Doe Borobudur 1 Keraton 1 Prambanan 2 Jon Smith Borobudur 2 Keraton 2 Prambanan 2 Malioboro 2 Parangtritis 2  Pengguna Objek Pariwisata Nilai Jane Doe Borobudur 1 Keraton 1 Malioboro 2 Parangtritis 2 Alan Drake Keraton 1 Prambanan 1 Parangtritis 2 Nathan Brooke Borobudur 2 Keraton 2 Prambanan 2 Malioboro 2 Parangtritis 1  
Tabel 1 menunjukkan contoh pem-berian nilai objek wisata berdasarkan transaksi yang terjadi. Nilai 1 menun-jukkan pelanggan hanya melihat objek wisata dan nilai 2 menunjukkan pelang-gan melakukan transaksi untuk pergi ke objek wisata tersebut. Sistem akan mem-berikan rekomendasi objek pariwisata untuk pelanggan dengan nama John Doe. Perhitungan pertama yang dilakukan adalah menghitung similarity (Sim) atau tingkat kesamaan antara John Doe dengan pelanggan lain. Hitung distance (Dis) untuk setiap nilai objek wisata yang sama dengan objek wisata yang pernah dikunjungin John Doe. Gambar 1 merupakan rumus perhitungannya.  Dimana, ð‘›ð‘–ð‘™ð‘Žð‘–ð‘‚ð‘ð‘—ð‘Šð‘–ð‘ ð‘Žð‘¡ð‘Ž+,-./0 adalah nilai dari produk pengguna yang akan diberikan rekomendasi.  ð‘›ð‘–ð‘™ð‘Žð‘–ð‘‚ð‘ð‘—ð‘Šð‘–ð‘ ð‘Žð‘¡ð‘Ž/12,-3,-./0        adalah nilai dari produk pengguna yang akan dibandingkan. Dis dari setiap produk yang sama akan dijumlahkan untuk menghitung Sim dengan menggunakan perhitungan seperti pada gambar 2. Perhitungan selanjutnya adalah menghitung tingkat rekomendasi untuk setiap produk yang belum pernah dilihat atau dibeli oleh bayu. Perhitungan dapat dilakukan seperti pada gambar 3. Dengan menggunakan rumus tersebut maka hasil yang didapatkan untuk perhitungan seperti pada tabel 2.  ð·ð‘–ð‘ =(ð‘›ð‘–ð‘™ð‘Žð‘–ð‘‚ð‘ð‘—ð‘Šð‘–ð‘ ð‘Žð‘¡ð‘Ž+,-./0âˆ’        ð‘›ð‘–ð‘™ð‘Žð‘–ð‘‚ð‘ð‘—ð‘Šð‘–ð‘ ð‘Žð‘¡ð‘Ž/12,-3,-./0): Gambar 1. Perhitungan tingkat kesamaan  antara John Doe dengan pelanggan lain  ð‘†ð‘–ð‘š/12,-3,-./0=        1(1+        Î£ð·ð‘–ð‘ ) Gambar 2. Perhitungan Sim  Î£(ð‘†ð‘–ð‘š        Ã—        ð‘›ð‘–ð‘™ð‘Žð‘–ð‘‚ð‘ð‘—ð‘Šð‘–ð‘ ð‘Žð‘¡ð‘Ž)Î£ð‘†ð‘–ð‘š 
Gambar 3. Perhitungan Tingkat Rekomendasi  ""
Tabel 2 : Perhitungan Rekomendasi 
Pengguna Sim Mal Sim x Mal Par Sim x Par John Doe 0.33 2 0.66 2 0.66 Jon Smith 1 2 2 2 2 Jane Doe 0.5 - - 2 1 Alan Drake 0.5 2 1 1 0.5 Nathan Brooke   3.66  4.16 Sim SUM   1.83  2.33 Total / sim SUM   2  1.78  
Gambar 4 : Alur Algoritma Apriori 
Dari Tabel 2 didapatkan nilai reko-mendasi dari setiap objek pariwisata un-tuk pelanggan dengan id John Doe. Malioboro memiliki nilai 2 dan Parang-tritis memiliki nilai 1.78. Objek pari-wisata dengan nilai rekomendasi tertinggi akan lebih diutamakan untuk ditawarkan kepada John Doe. Hasil dari rekomendasi akan berbeda untuk setiap pengguna yang menjadi target rekomendasi, sehingga sistem akan semakin berkembang seiring dengan bertambahnya data dari sisi pengguna, aktifitas pengguna dan data objek pariwisata. Langkah selanjutnya adalah mela-kukan perhitungan dengan menggunakan algoritma apriori. Proses perhitungan rekomendasi dengan meng-gunakan Algoritma Apriori digunakan untuk menghasilkan rekomendasi paket wisata berdasarkan pola kebiasaan pengguna yang terdaftar di dalam sistem. Pada tahapan ini dicari kombinasi â€“ kombinasi itemset yang sesuai dengan association rule yang sudah ditentukan. 
Tabel 3 : Tabel Final Association Rule 
Aturan (X Â®Y) Sup (X âˆª Y) Sup(X) Confidence Keraton â€“ Prambanan Â® Parangtritis  50% 50% 100% Keraton â€“ Parangtritis Â® Prambanan 50% 75% 66.67% Prambanan â€“ Parangtritis Â® Keraton 50% 50% 100% Borobudur Â® Prambanan 50% 50% 100% Prambanan Â® Borobudur 50% 75% 66.67% Keraton Â® Prambanan 50% 75% 66.67% Prambanan Â® Keraton 50% 75% 66.67% Keraton Â® Parangtritis 75% 75% 100% Parangtritis Â® Keraton 75% 75% 100% Prambanan Â® Parangtritis 50% 75% 66.67% Parangtritis Â® Prambanan 50% 75% 66.67%  Hasil akhir dari Algoritma Apriori ini lah yang akan menjadi rekomendasi untuk paket perjalanan wisata yang di-tujukan bagi travel agent. Sehingga pem-buatan paket wisata, dapat dilakukan se-cara otomatis berdasarkan pola kebiasaan wisatawan dalam mengunjungi daerah wisata favoritnya. Pada setiap sistem di-perlukan pengujian performa sistem un-tuk mengukur efektifitas proses kerja dari sistem tersebut. Dalam hal ini apakah sistem dapat bekerja secara stabil dengan terjadinya perubahan parameter dan memberikan nilai rekomendasi yang te-pat, atau terjadi perubahan kinerja sistem karena perubahan tersebut. Pada analisis performa sistem ini dibagi menjadi dua jenis pengujian yaitu berdasarkan penga-ruh perubahan jumlah pengguna yang terdaftar di dalam sistem dan pengaruh perubahan jumlah objek wisata terhadap kualitas rekomendasi. Analisa performa sistem dihitung berdasarkan nilai precision, recall dan f-measure. Dimana precision adalah bagian dari dokumen yang diambil yang relevan dengan informasi yang dicari. perhi-tungan precision dilakukan seperti pada gambar 5. Sedangkan recall adalah persentase semua dokumen yang relevan yang di-kembalikan dari hasil pencarian. perhi-tungan recall dilakukan seperti pada gam-bar 6. Selain precision dan recall, kedua pengukuran tersebut terkadang digunakan bersama â€“ sama untuk memberikan peng-ukuran yang seimbang dan tunggal. Pengukuran ini yang disebut dengan F-Measure, seperti pada gambar 7.  ð‘ð‘Ÿð‘’ð‘ð‘–ð‘ ð‘–ð‘œð‘›=        ð‘ð‘œð‘Ÿð‘Ÿð‘’ð‘ð‘¡ð‘™ð‘¦        ð‘Ÿð‘’ð‘ð‘œð‘šð‘šð‘’ð‘›ð‘‘ð‘’ð‘‘        ð‘–ð‘¡ð‘’ð‘šð‘¡ð‘œð‘¡ð‘Žð‘™        ð‘Ÿð‘’ð‘ð‘œð‘šð‘šð‘’ð‘›ð‘‘ð‘’ð‘‘        ð‘–ð‘¡ð‘’ð‘š Gambar 5. Perhitungan Nilai Precision  ð‘Ÿð‘’ð‘ð‘Žð‘™ð‘™=        ð‘ð‘œð‘Ÿð‘Ÿð‘’ð‘ð‘¡ð‘™ð‘¦        ð‘Ÿð‘’ð‘ð‘œð‘šð‘šð‘’ð‘›ð‘‘ð‘’ð‘‘        ð‘–ð‘¡ð‘’ð‘šð‘¡ð‘œð‘¡ð‘Žð‘™        ð‘–ð‘¡ð‘’ð‘š        ð‘™ð‘–ð‘˜ð‘’ð‘‘        ð‘ð‘¦        ð‘¢ð‘ ð‘’ð‘Ÿ  Gambar 6. Perhitungan Recall  ð¹âˆ’ð‘šð‘’ð‘Žð‘ ð‘¢ð‘Ÿð‘’=2        Ã—        ð‘ð‘Ÿð‘’ð‘ð‘–ð‘ ð‘–ð‘œð‘›        Ã—        ð‘Ÿð‘’ð‘ð‘Žð‘™ð‘™ð‘ð‘Ÿð‘’ð‘ð‘–ð‘ ð‘–ð‘œð‘›+        ð‘Ÿð‘’ð‘ð‘Žð‘™ð‘™ Gambar 7. Perhitungan F-Measure 
Gambar 8 : Pengujian pengaruh jumlah pengguna terhadap kualitas rekomendasi 
Gambar 9 : Pengujian pengaruh jumlah objek pariwisata terhadap kualitas rekomendasi  
Data yang dipergunakan dalam pe-nelitian ini berasal dari data hasil survei, dimana data di dapatkan dari survei secara langsung secara personal. Pada proses ini akan dikumpulkan data - data yang dibutuhkan, yaitu nilai rating lokasi pariwisata sesuai minat pengguna, keter-tarikan pengguna dengan objek wisata tertentu, pilihan pengguna untuk berwi-sata ke objek wisata yang ditawarkan serta kesamaan data pengguna yang satu dengan yang lainnya sesuai data yang telah dikumpulkan. Dari Gambar 8, dapat dilihat bahwa pada posisi jumlah pengguna sebanyak 2 user, baik precision, recall dan f-measure berhasil mencapai nilai minimum-nya. Jadi, ketiga parameter utama performansi sistem tersebut mengalami kondisi ter-buruk yaitu sistem bekerja dengan tidak efektif pada saat jumlah pengguna hanya 2 user, karena rasio recall dan precision mengalami progress yang sama dan se-cara otomatis f-measure juga mengalami hal ini.  Dengan jumlah pengguna yang semakin besar, maka performansi sis- tem menjadi lebih baik karena meng-hasilkan kombinasi objek wisata yang bermacam-macam walaupun tingkat du-kungan data kecil (pada data training). Artinya, kombinasi objek wisata yang jarang sekalipun memiliki kesempatan kemunculan yang sama dengan kombi-nasi objek wisata yang didukung banyak data latih sehingga kemungkinan menjadi kandidat rekomendasi juga semakin besar. Selain jumlah pengguna, jumlah objek pariwisata juga sangat mem-pengaruhi kinerja sistem pada tahap kedua ini yaitu dapat menurunkan nilai precision dimana telah diketahui bahwa precision sangat diutamakan dalam me-lihat performansi sistem yang baik. Se-perti terlihat pada gambar 9, nilai preci-sion semakin menurun dengan seiringnya bertambahnya jumlah objek pariwisata.  

SIMPULAN DAN SARAN  
Pembuatan sistem rekomendasi dengan menggunakan metode Collabo-rative Filtering dan Algoritma Apriori memiliki tingkat ketepatan yang cukup baik. Namun hal ini harus diseimbangi dengan adanya aktifitas serta jumlah pengguna yang seimbang dengan jumlah objek pariwisata yang ditawarkan di dalam sistem. Semakin besar jumlah pengguna dengan jumlah objek pariwi-sata yang sedikit, akan menghasilkan rekomendasi yang tepat, namun sebalik-nya semakin besar jumlah objek pari-wisata dengan jumlah pengguna yang se-dikit akan membuat sistem menjadi kurang efektif. Dalam pembuatan sistem rekomen-dasi ini masih menggunakan jumlah data dan alur sistem yang sangat sederhana. Belum terdapatnya sistem Content Mana-gement System juga salah satu keku-rangan dalam pembuatan sistem reko-mendasi ini agar lebih mempermudah da-lam pengaturan data. Selain itu, metode Collaborative Filtering dan Algoritma Apriori masih dapat dikembangkan lagi agar menghasilkan sistem rekomendasi hybrid.  

DAFTAR PUSTAKA  
[1] Diahpangastuti, N. (2013). Sistem rekomendasi bidang minat maha-siswa menggunakan metode asso-ciation rule dan algoritma apriori.  
[2] J. Ben Schafer, D. F. (2007). Collaborative filtering recommender systems. 
[3] Rahma Oktoria, W. M. (2010). Content based recommender system menggunakan algoritma apriori. 
[4] Sasmadi, E. (2010). Multi attribute decision making pada recommender system menggunakan metode weighted sum model. 
[5] Sterneckert, A. B. (2003). Critical Incident Management. Taylor & Francis.",sistem rekomendasi,"apriori, collaborative filtering",objek pariwisata,"precision, recall, f-measure"
Performa Algoritma User K-Nearest Neighbors pada Sistem Rekomendasi di Tokopedia,"Performa Algoritma User K-Nearest Neighbors pada Sistem Rekomendasi di Tokopedia

Rama Dian Syah  

Abstract  
The biggest marketplace in Indonesia such as Tokopedia has data on e-commerce activities that always increase with time. Large data  growth  in Marketplace  can cause problems for users . Buyers who have difficulty in finding the best product that suits their needs and sellers who have difficulty in promoting products that are often visited by buyers can be overcome. The recommendation system can overcome these problems by providing specific product recommendations to be promoted and offered to buyers. This research implements the Recommendation System using the Item Rating Prediction Method by applying the User K-Nearest Neighbors  Algorithm. The Recommendation System provides recommendations based on ratings on products given by the buyer. Algorithm performance  in Recommendation System is measured by the parameters of Root Mean Square Error (RMSE), Mean Absolute Error (MAE) and Normalized Mean Absolute Error (NMAE). The performance values obtained are RMSE = 0.713, MAE = 0.488 and NMAE = 0.122.  Perfomance values below 1 proves that the User K -Nearest Neighbors Algorithm is suitable as a rating prediction model on recommendation system.    
 
Keywords : Recommendation System 
 
Abstrak  
Pasar online  terbesar di Indonesia seperti To kopedia memiliki data aktifitas perdagangan secara elektronik  yang selalu bertambah seiring waktu. Pertumbuhan  data yang besar pada pasar online  dapat menimbulkan masalah bagi pengguna. Pembeli yang mengalami kesulitan pada pencarian produk terbaik yang sesuai dengan kebutuhannya dan penjual yang kesulitan pada promosi produk yang sering dikunjungi 
pembeli dapat diatasi. Sistem rekomendasi dapat mengatasi masalah tersebut dengan memberikan rekomendasi produk tertentu untuk dipromosikan dan ditawarkan kepada  pembeli. Penelitian ini mengimplementasikan Sistem Rekomendasi menggunakan Metode Item Rating Prediction  dengan menerapkan Algoritma User K-Nearest Neighbors . Sistem Rekomendasi memberikan rekomendasi berdasarkan penilaian  pada produk yang diberikan oleh pembeli. Performa algoritma pada Sistem 
Rekomendasi  diukur dengan parameter Root Mean Square Error  (RMSE), Mean Absolute Error  (MAE) dan Normalized Mean Absolute Error  (NMAE). Nilai performa yang didapat yaitu RMSE = 0.713, MAE = 0.488 dan NMAE = 0.122.  Nilai performa dibawah 1 membuktikan bahwa algoritma User K-Nearest 
Neighbors cocok sebagai model prediksi rating pada sistem rekomendasi.  
 
Kata Kunci : Sistem Rekomendasi 
 
1. Pendahuluan  
Data merupakan elemen penting dalam perkembangan teknologi saat ini. Data dapat menghasilkan informasi yang dibutuhkan untuk perkembangan suatu sistem agar sesuai dengan kebutuhan pengguna. Pertambahan data yang sangat besar terjadi pada sistem online Marketplace.   Kemudahan transaksi yang ditawarkan oleh Marketplace  sangat membantu pengguna dalam melakukan aktifitas jual beli secara online. Marketplace terbesar di Indonesia seperti Tokopedia memiliki jumlah pengguna yang sangat banyak sehingga menimbulkan pertambahan data yang sangat cepat.  Masalah yang dapat ditimbulkan seperti pembeli yang mengalami kesulitan pada pencarian produk yang sesuai dengan kebutu hannya atau penjual yang ingin mempromosikan produknya yang sering dikunjungi pembeli dapat diatasi.  Sistem rekomendasi dapat mengatasi masalah pertumbuhan data dengan memberikan rekomendasi kepada pengguna Marketplace . Sistem rekomendasi merupakan sistem yang digunakan untuk mempelajari informasi dari data masa lalu dan memberikan saran (Choudhary & Tulasi, 2019) . Sistem Rekomendasi merupakan salah satu implementasi dari Machine Learning . Sistem Rekomendasi memiliki beberapa metode dan algoritma yang dapat diterapkan. Pengujian performa dari penerapan algoritma pada Sistem Rekomendasi dapat mengukur keberhasilan algoritma dalam memberikan rekomendasi kepada pengguna.  Beberapa penelitian telah dilakukan terhadap Sistem Rekomendasi pada E-Commerce . Kai Wang melakukan penelitian dengan mengusulkan  Sistem Rekomendasi pada E-Commerce menggunakan algoritma RNN (K. Wang et al., 2019) . Hasil penelitiannya yaitu peforma dari algoritma diukur berdasarkan parameter Mean Absolute Error (MAE).  Penelitian yang lainnya dilakukan oleh Arie Satia Dharma tentang Sistem Rekomendasi menggunakan algoritma KNN berdasarkan personalisasi pengguna (Dharma & Samosir, 2019) . Hasil penelitiannya adalah performa dari algoritma KNN yang diukur berdasarkan parameter Root Mean Square Error  (RMSE).  Pada penelitian ini dila kukan pengujian performa Algoritma User K-Nearest Neighbors yang diterapkan pada Sistem Rekomendasi di Tokopedia. Data yang digunakan berjumlah 40608 pengguna Tokopedia yang memberikan rating pada produk. Pengujian performa Algoritma diukur berdasarkan par ameter Root Mean Square Error (RMSE), Mean Absolute Error (MAE) dan Normalized Mean Absolute Error (NMAE).  
 
2. Metode Penelitian  
Penelitian ini dilakukan dengan 5 tahapan penelitian yaitu: (1) Pengumpulan Data
Preprocessing Data
(4) Pelatihan
penelitian terlihat pada Gambar 1.  
Gambar 1. Tahapan Penelitian   
2.1 Pengumpulan Data  
Pengumpulan data dilakukan dengan berbagai teknik untuk bahan penelitian  (Roh et al., 2019) . Data yang digunakan pada penelitian ini berasal dari Tokopedia Product Reviews . Data diambil dari website  Kaggle.com. Data yang digunakan berjumlah 40608 reviews  pengguna Tokopedia. Data berukuran 9.98 MB. Sumber data yang digunakan terlihat pada Gambar  2. Gambar 2. Sumber Data   
2.2 Preprocessing  Data  
Preprocessing Data  dilakukan untuk  transformasi data mentah menjadi data yang berkualitas  serta menghilangkan duplikasi data (Syah, 2020) . Preprocessing  Data dilakukan dengan  seleksi atribut dari beberapa atribut yang ada pada dataset. Atribut yang  digunakan akan diberikan target role  sebagai tugas dari atribut tersebut. Berikut atribut yang akan digunakan terdapat pada Gambar 2 .  
Gambar 2. Atribut yang digunakan   
Keterangan Gambar 2:  
â€¢ Target Role Label merupakan atribut yang khusus digunakan untuk target pembelajaran operator.  Atribut yang menjadi target pembelajaran yaitu atribut rating.  
â€¢ Target Role Item Identification  digunakan untuk mengidentifikasi produk pada Tokopedia.  
â€¢ Target Role User Identification  digunakan untuk mengidentifikasi pengguna yang memberikan penilaian  
pada  produk di Tokopedia.   
2.3 Perancangan Algoritma  
Algoritma yang digunakan dalam penelitian ini adalah User K-Nearest Neighbors . Algoritma ini termasuk salah satu dari metode Collaborative Rating Prediction . Algoritma ini membagi data menjadi 2 bagian yaitu data latih dan data uji. Data latih digunakan oleh algoritma sebagai dasar prediksi. Data uji digunakan oleh algoritma sebagai penilaian hasil prediksi (Prasetya, 2017) . Tahapan Algoritma KNN yaitu:  
1. Penetapan k (jumlah tetangga terdekat).  
2. Perhitungan jarak data latih dengan data uji.  
3. Pengurutan jarak tersebut berdasarkan nilai yang terkecil sejumlah k.  
4. Penetapan kelompok data uji berdasarkan label mayoritas k.   
2.4 Pelatihan  
Pelatihan pada dataset dilakukan untuk melatih algoritma (Shafique & Hato, 2015) . Pelatihan dataset Tokopedia Product Reviews  yang sudah diolah pada saat preprocessing data dengan algoritma User K-Nearest Neighbors  yang sudah dirancang. Dataset yang digunakan dibagi menjadi dua data dengan persentase 80% sebagai training dataset dan 20%  sebagai testing dataset.   
2.5 Pengujian  
Pengujian dilakukan untuk mengetahui performa algoritma terhadap dataset yang telah diproses  (Belavagi & Muniyal, 2016) . Algoritma yang akan dilakukan pengujian dan evaluasi yaitu algoritma User K-Nearest Neighbors . Nilai performa yang didapat akan membuktikan keakurasian model yang telah dirancang. Terdapat  3 Parameter uji yang digunakan dalam 
pengujian yaitu (Wang & L u, 2018) : 
1. Root Mean Square Error (RMSE)  
ð‘…ð‘€ð‘†ð¸=âˆšâˆ‘(ð‘ŸÌ‚ð‘›âˆ’ð‘Ÿð‘›)2 ð‘
ð‘›=1
ð‘ 2. Mean Absolute Error (MAE)  
ð‘€ð´ð¸=âˆ‘|ð‘ŸÌ‚ð‘›âˆ’ð‘Ÿð‘›|ð‘
ð‘›=1
ð‘ 
3. Normalized  MAE  (NMAE).  
ð‘ð‘€ð´ð¸=âˆ‘|ð‘ŸÌ‚ð‘›âˆ’ð‘Ÿð‘›|ð‘
ð‘›=1
âˆ‘ð‘Ÿð‘›ð‘
ð‘›=1 
Keterangan  dari rumus parameter uji : 
â€¢ rÌ‚n = rating predi ksi 
â€¢ rn  = rating pengguna pada dataset  
â€¢ N  = jumlah pasangan prediksi rating antara pengguna pada dataset dan  hasil prediksi  

3. Hasil dan Pembahasan  
Dataset yang digunakan pada model sistem rekomendasi di Tokopedia berjumlah 40607 data pengguna dengan 3 atribut. Tool RapidMiner versi 9 digunakan untuk mengelola data 
menggunakan model yang dirancang.  
3.1 Model Algoritma User K-Nearest Neighbors  
Model yang dirancangan menggunakan beberapa operator yaitu Set Role, Split Data, User k-NN, Apply Model  dan Performance . Model yang dirancang terdapat pada Gambar 3.  
Gambar 3. Model Algoritma User K-Nearest Neighbors   
Pada Gambar 3 tahapan yang dilakukan yaitu:  
1. Dataset yang diinput merupakan dataset tokopedia yang ditampung pada Retrieve Data . 
2. Atribut dari dataset akan diberikan tugas atribut menggunakan operator Set Role. 
3. Partisi dataset deng an rasio 0.8 dan 0.2 menggunakan operator Split Data . 
4. Pelatihan dataset menggunakan operator User k-NN. 
5. Penerapan model menggunakan operator Apply Model  6. Pengujian Model menggunakan operator Performance .  
3.2 Performa Algoritma User K-Nearest Neighbors  
Nilai performa dari model yang dirancang dengan Algoritma User K-Nearest Neighbors  diukur dengan parameter  Root Mean Square Error (RMSE), Mean Absolute Error (MAE) dan Normalized  Mean Absolute Error  (NMAE). Performa dari model yang sudah dirancang terpada pada Tabel 1.
Tabel 1. Nilai Performa Model dengan Algoritma User k-NN  
Performa Vector  Nilai  Performa  
RMSE  0.713  
MAE  0.488  
NMAE  0.122   
Parameter MAE dan RMSE merupakan parameter yang digunakan untuk menghitung perbedaan antara nilai prediksi rating dengan nilai rating pengguna sesungguhnya (Wang & Lu, 2018) . Paramater NMAE merupakan normalisasi dari nilai MAE. Nilai MAE, RMSE dan nilai NMAE semakin kecil maka hasil prediksi rating  dari sistem reko mendasi semakin 
akurat (Muliadi & Lestari, 2019) . 
 
4. Kesimpulan  
Pada penelitian ini disajikan Sistem Rekomendasi dengan Algoritma User K-Nearest Neighbors  untuk pr ediksi peringkat penilaian  produk oleh pengguna di Tokopedia. Performa dari model yang dirancang didapatkan nilai RMSE = 0.713, MAE = 0.488 dan NMAE = 0.122.  Nilai performa yang didapatkan sangat kecil yaitu dibawah 1 yang membuktikan bahwa Algoritma User K -Nearest Neighbors cocok sebagai model untuk pr ediksi rating pada Sistem Rekomendasi.  
 
Daftar Pustaka  
Belavagi, M. C., & Muniyal, B. (2016). Performance Evaluation of Supervised Machine Learning Algorithms for Intrusion Detection. Procedia Computer Science , 89, 117â€“123. https://doi.org/10.1016/j.procs.2016.06.01 6 
Choudhary, B. T., & Tulasi, B. (2019). Recommender system for personalised travel itinerary. International Journal of Electrical and Computer Engineering , 9(5), 4460 â€“4465. https://doi.org/10.11591/ijece.v9i5.pp4460 -4465
Dharma, A. S., & Samosir, T. (2019 ). The User Personalization with KNN for Recommender System. SinkrOn , 3(2), 45 â€“48. https://doi.org/10.33395/sinkron.v3i2.10047  Muliadi, K. H., & Lestari, C. C. (2019). Rancang Bangun Sistem Rekomendasi Tempat Makan Menggunakan Algoritma Typicality Based Collaborative Filtering. Techno.Com , 18(4), 275â€“287. https://doi.org/10.33633/tc.v18i4.2515  
Prasetya, C. S. D. (2017). Sistem Rekomendasi Pada E-Commerce Menggunakan K -Nearest Neighbor. Jurnal Teknologi Informasi Dan Ilmu Komputer , 4(3), 194. https://doi.org /10.25126/jtiik.201743392  
Roh, Y., Heo, G., & Whang, S. E. (2019). A Survey on Data Collection for Machine Learning: A Big Data - AI Integration Perspective. IEEE Transactions on Knowledge and Data 
Engineering , PP(c), 1 â€“1. https://doi.org/10.1109/tkde.2019 .2946162  
Shafique, M. A., & Hato, E. (2015). Formation of Training and Testing Datasets, for Transportation Mode Identification. Journal of Traffic and Logistics Engineering , 3(1), 77â€“80. https://doi.org/10.12720/jtle.3.1.77 -80 
Syah, R. D. (2020). Metode Decision Tree untuk Klasifikasi Hasil Seleksi Kompetensi Dasar pada CPNS 2019 di Arsip Nasional Republik Indonesia . Jurnal Ilmiah Informatika Komputer , 25(2), 107 â€“114. https://doi.org/10.35 760/ik.2020.v25i2.2750  
Wang, K., Zhang, T., Xue, T., Lu, Y., & Na, S. -G. (2019). E-Commerce Personalized Recommendation Analysis by Deeply -learned Clustering. Journal of Visual Communication and Image Representation , 71. https://doi.org/10.1016/j.jvcir.201 9.102735  
Wang, W., & Lu, Y. (2018). Analysis of the Mean Absolute Error (MAE) and the Root Mean Square Error (RMSE) in Assessing Rounding Model. IOP Conference Series: Materials Science and Engineering , 324(1). https://doi.org/10.1088/1757 -899X/324/1/01204 9",sistem rekomendasi,K-Nearest Neighbor,Tokopedia Product Reviews,"MAE, RMSE, NMAE"
Sistem Rekomendasi Pemilihan Sekolah Menengah Atas (SMA) Sederajat Kota Malang Menggu nakan Metode AHP-ELECTRE Dan SAW,"Sistem Rekomendasi Pemilihan Sekolah Menengah Atas (SMA) Sederajat Kota Malang Menggu nakan Metode AHP-ELECTRE Dan SAW

Suherni Prahesti1, Dian Eka Ratnawati2, Heru Nurwasito3 

Abstrak  
Pendidikan merupakan aspek yang penting bagi masyarakat. Salah satu jenjang pendidikan formal adalah pendidikan menengah yaitu Sekolah Menengah Atas (SMA). Sekolah adalah lembaga yang memberikan pengajaran untuk siswa dibawah pengawasan guru. Setiap tahun ajaran baru, siswa akan memilih sekolah terbaik yang sesuai dengan keinginannya. Terdapat banyak pilihan sekolah dengan berbagai tawaran yang diberikan. Dengan begitu, calon siswa akan mengalami kesulitan dalam menentukan sekolah yang sesuai dengan kriteria yang diinginkan. Penelitian ini bertujuan untuk memberikan rekomendasi sekolah berdasarkan kriteria yang 
diinginkan oleh calon siswa dengan menerapkan metode AHP-ELECTRE dan SAW ke dalam sistem. Metode AHP digunakan dalam pembobotan dari setiap kriteria,  metode ELECTRE melakukan klasifikasi alternatif yang masuk ke dalam kelompok direkomendasikan, dan SAW melakukan perankingan alternatif. Untuk pengujian, hasil pengujian akurasi sistem adalah sebesar 82,98%. Hasil akurasi didapatkan dengan membandingkan hasil rekomendasi sistem dengan data yang telah didapatkan.  

Kata kunci : pendidikan, SMA, AHP, ELECTRE, SAW  

Abstract  
Education is the important aspect for society. One of the education formal stages is, Senior High School. School is the institution which gi ves a preaching for students in teacherâ€™s control. In every new school year, students will choose the best school that they want. There is a lot of choices of school with various offer is given. So, the student candidate will have a trouble in deciding sch ool which is fit in with the criteria that they want. This research is purpose to gives a recommendation for school based on criteria that student wants with applying AHP-ELECTRE and SAW method into a system. AHP method is used for weighting every criteria , ELECTRE method did an alternative classification into the group recommended, and SAW method did a ranking of alternatives. For testing, the results of accuracy test on system is 82,98%. The accuracy of the results obtained by comparing the recommendations data on the system with the data that has been obtained.  

Keywords : education, senior high school, AHP, ELECTRE, SAW   
 
1. PENDAHULUAN  
Sekolah adalah sebuah lembaga yang dirancang untuk mengajarkan siswa dibawah pengawasan guru yang bertujuan untuk mengembangkan siswa melalui proses pembelajaran. Jenjang pendidikan formal terdiri atas pendidikan dasar, pendidikan menengah dan pendidikan tinggi. Untuk pendidikan menengah terdiri atas pendidikan menengah umum dan pendidikan menengah kejuruan. Pendidikan menengah berbentuk sekolah menengah atas (SMA), madrasah aliyah (MA), sekolah menengah kejuruan (SMK), dan madrasah aliyah kejur uan (MAK).  Pemilihan sekolah merupakan salah satu hal yang sangat penting dikarenakan pilihan sekolah akan mempengaruhi pendidikan masa depan. Di era globalisasi saat ini membuat keputusan untuk memilih sekolah yang tepat tidaklah mudah. Selain jumlah sek olah yang banyak, setiap sekolah juga memberi beragam tawaran dan pilihan kepada para calon siswanya (Uyun, 2011). Beberapa calon siswa juga memiliki kriteria mengenai sekolah yang akan dipilih, mulai dari letak sekolah, prestasi yang pernah dicapai oleh sekolah, kegiatan ekstrakurikuler, fasilitas dan sarana prasarana yang dimiliki sekolah. Maka dari itu, dalam pemilihan sekolah para orang tua dan siswa pasti akan menyeleksi sekolah-sekolah dengan predikat yang terbaik dan sesuai dengan keinginan.  Para orang tua dan calon siswa untuk menentukan sekolah yang tepat dengan kriteria-kriteria yang diinginkan pasti akan menemui kesulitan. Apalagi bagi mereka yang tidak memiliki banyak waktu untuk mensurvei semua sekolah yang ada di daerah tempat tinggal mereka at au daerah baru (Uyun, 2011). Dengan berkembangnya teknologi informasi saat ini, penggunaan teknologi informasi seperti sistem rekomendasi diharapkan dapat memberikan solusi dalam membantu proses pengambilan keputusan terkait permasalahan pemilihan sekolah.   26   Jurnal Teknologi Informasi dan Penelitian sebelumnya mengenai penggunaan metode AHP dilakukan oleh Johan I., dimana penelitian yang dilakukan tersebut menggunakan metode AHP dan SAW. Kedua metode tersebut digunakan untuk menentukan Line Up dalam cabang olahraga futsal. Metode AHP digu nakan untuk penghitungan bobot dari masing-masing kriteria dan SAW digunakan untuk perankingan. Hasil pengujian akurasi menghasilkan nilai sebesar 87,273%. Terdapat 48 data uji yang cocok dan 7 data uji yang tidak cocok dari total 55 data yang diujikan (Is mail, 2015).   Penelitian yang dilakukan oleh Fennia M. dengan menggunakan metode ELECTRE dan SAW untuk seleksi penerimaan peserta didik baru di SMA Brawijaya Smart School (BSS) kota Malang. Metode ELECTRE digunakan untuk menentukan peserta didik yang layak diterima dan metode SAW digunakan untuk menentukan peserta didik yang diterima dalam kelompok keminatan tertentu. Hasil dari penelitian ini, pengujian fungsionalitas memiliki tingkat kesesuaian presentase sebesar 100%, hasil pengujian akurasi sistem deng an metode ELECTRE dan SAW memiliki tingkat kesesuaian yang didasarkan pada data hasil seleksi penerimaan peserta didik baru SMA BSS pada tahun 2014/2015 dengan presentase tertinggi sebesar 84,37% dan terendah sebesar 44% (Maghfiroh, 2015).  Penelitian lainnya yang dilakukan oleh Ibnu Aqli dengan menggunakan 3 metode yaitu metode AHP ELECTRE dan TOPSIS. Dimana penggunaan ketiga metode tersebut untuk memb erikan rekomendasi dalam pemilihan  Sekolah Menengah Atas Sederajat  di Kota Malang. Dengan membandingka n data rekomendasi yang dikeluarkan oleh sistem dengan data yang didapat dari pakar  diperoleh hasil pengujian akurasi sistem sebesar 82,98%(Aqli,2016).  Dalam penelitian ini akan digunakan metode AHP-ELECTRE dan SAW. Metode AHP digunakan sebagai pembobotan kriteria. Metode ELECTRE digunakan untuk pengelompokan data alternatif, dimana dalam pengelompokan tersebut terdiri atas kelompok rekomendasi dan tidak direkomendasikan. Metode SAW digunakan untuk perankingan hasil, perankingan yang dilakukan berdasarkan h asil data alternatif kelompok yang direkomendasikan.  Dengan menggunakan ketiga metode tersebut, diharapkan dapat memberikan rekomendasi dalam pemilihan Sekolah Menengah Atas.   
1.2 BATASAN MASALAH  
1. Data yang digunakan dalam penelitian ini adalah data Sekolah Menengah Atas Sederajat di Kota Malang.  
2. Data yang digunakan diperoleh dari Website resmi Dinas Pendidikan Kota Malang (data PPDB tahun 2011 -2015) dan Website dari masing-masing sekolah SMA Sederajat di Kota 
Malang. Data yang diperoleh antara lain rayon, nilai maksimal dan minimal, pagu, prestasi akademik dan prestasi non akademik, ekstrakurikuler dan fasilitas.  
3. Metode yang digunakan merupakan penggabungan metode AHP, ELECTRE dan SAW tanpa membandingkan dengan metode yang lain.  
4. Kriteria-kriteria yang digunak an antara lain jarak sekolah, nilai, prestasi yang dimiliki sekolah, fasilitas yang dimiliki sekolah dan ekstrakurikuler yang dimiliki sekolah.  

2. TINJAUAN PUSTAKA  
Berikut hasil penelitian-penelitian sebelumnya yang terkait atau memiliki kesesuaian dengan sistem rekomendasi dengan menggunakan metode AHP, ELECTRE dan SAW. Ditunjukkam pada Tabel 1.   
Tabel 1. Tinjauan Pustaka  
No. Judul  Hasil  
1. Pemodelan Sistem Pendukung Keputusan Penentuan Line Up dalam Cabang Olahraga Futsal Menggunakan Metode AHP -SAW (Studi Kasus : Hefotris FILKOM UB) (Ismail, 2015)  Hasil berupa penentuan Line Up tim futsal Hefotris. Tingkat akurasi sebesar 87,273% . 
2. Rekomendasi Kecocokan Tanaman Hortikultura Berdasarkan Komposisi Struktur Tanah Pada Kota Batu Menggunakan 
Metode SAW (Rachmawati, 2015)  Hasil berupa rekomendasi lahan yang cocok dan terdapat 25 lahan yang tidak valid dengan pakar.  Tingkat akurasi sebesar 83%.  
3. Sistem Pendukung Keputusan Seleksi Penerimaan Peserta Didik Baru Menggunakan Metode ELECTRE dan SAW (Studi Kasus: SMA Brawijaya Smart School Kota Malang) (Maghfiroh, 2015)  Hasil berupa rekomendasi peserta didik yang diterima berdasarkan kelompok peminatan tertentu. Tingkat akurasi sebesar 84,37% . 
2.1 ANALYTICAL HIERARCHY PROCESS (AHP)  
Analitycal Hierarchy Process  (AHP) adalah suatu model pendukung keputusan yang dikembangkan oleh Thomas L. Saaty. Model pendukung keputusan ini akan menguraikan masalah multi faktor atau multi kriteria yang kompleks menjadi suatu hirarki. Dengan hirarki, masalah yang kompleks dapat diuraikan ke dalam kelompok-kelompoknya dan kemudian diatur sehingga permasalahan akan terlihat lebih terstruktur dan sistematis (Saragih, 2013).  Prinsip kerja AHP adalah menyederhanakan suatu persoalan kompleks yang tidak terstruktur, strategik, dan dinamik menjadi bagian -bagiannya, serta menata dalam suatu hirarki. Kemudian tingkat kepentingan setiap variabel diberi nilai numeric secara subjektif tentang arti penting variabel tersebut secara relatif dibandingkan dengan variabel lain  (Faisal, 2015) . Proses  metode AHP dapat dilihat pada Gambar 1.    
Mulai
Matriks Perbandingan Berpasangan
CR <= 0,1
Bobot Prioritas Kriteria
Return No
Yes Perhitungan AHP
Normalisasi Matriks 
Perbandingan Berpasangan
Menghitung Bobot Prioritas
Menghitung Lamda Maks
Menghitung CI & CR 
Gambar  1. Diagram Alir Metode AHP  
2.2 ELIMINATION ET CHOIX TRANDUISANT 
LA REALITE (ELECTRE)  
Yang pertama kali menggunakan konsep hubungan outranking untuk memperkenalkan metode Elimination and Choice Expressing Reality  (ELECTRE) adalah Roy (1968) dan Benayoun et al. (1966). Sejak saat itu, ber bagai model ELECTRE mulai berkembang berdasarkan permasalahan yang ada untuk menemukan solusi kernel atau untuk perankingan urutan alternatif, tingkat signifikansi kriteria harus diperhitungkan (benar atau semu) dan informasi preferensial (bobot, indeks concordance, indeks discordance, efek veto) (Tzeng, 2011).  ELECTRE merupakan salah satu metode pengambilan keputusan multikriteria berdasarkan pada konsep outranking dengan menggunakan perbandingan berpasangan dari alternatif -alternatif berdasar kan setiap kr iteria yang sesuai (Pareira, 2014).  Proses  metode ELECTRE  dapat dilihat pada Gambar 2.   
Mulai
Memasukkan 
Data pengguna
Return Perhitungan ELECTRE
Hasil Keputusan 
Alternatif yang direkomendasikan
Menghitung Normalisasi 
Matriks Keputusan
Menentukan Aggregate 
Dominance Matriks Menentukan Himpunan 
Concordance dan Discordance
Menghitung Matriks 
Concordance dan Discordance
Perkalian Bobot dengan Normalisasi Matriks 
Keputusan
Eliminasi Alternatif yang tidak direkomendasikan 
Gambar  2. Diagram Alir Metode ELECTRE  
2.3 SIMPLE ADDITIVE WEIGHTING (SAW)  
Metode Simple Additive Weighting (SAW)  juga dikenal dengan istilah metode penjumlahan terbobot. Konsep dasar SAW adalah mencari penjumlahan terbobot dari rating kinerja pada setiap alternatif pada semua atribut. Metode SAW membutuhkan proses normalisasi matriks keputusan (X) ke suatu skala yang dapat diperbandingkan dengan semua alternatif yang ada (Tobing, 2014). Proses  metode SAW  dapat dilihat pada Gambar 3.  Mulai
Membuat Matriks Keputusan
Normalisasi Matriks Keputusan
Perangkingan
Selesai
Data alternatif dari hasil 
perhitungan ELECTRE Perhitungan SAW
Rekomendasi Sekolah Menengah Atas Sederajat Evaluasi Alternatif Keputusan  
Gambar  3. Diagram Alir Metode SAW   

3. METODE  
Penelitian ini menggunakan 3 metode yaitu AHP-ELECTRE dan SAW. Ketiga metode tersebut digunakan untuk menghasilkan rekomendasi sekolah sesuai dengan masukkan dari pengguna. Diagram alir sistem secara umum terlihat pada Gambar 4.   
Mulai
Memasukkan data pengguna
Selesai
Perhitungan AHP
Perhitungan ELECTRE
Bobot prioritas kriteria
Perhitungan SAW 
Alternatif data direkomendasikan
Rekomendasi sekolah 
Gambar 4. Diagram Alir Sistem Secara Umum   
Dalam perancangan sistem rekomendasi pemilihan sekolah menengah atas (SMA) Sederajat di Kota Malang ini pengguna akan diminta untuk memasukkan kriteria-kriteria yang diinginkan dalam memilih sekolah. Dari masukkan peng guna tersebut data akan diproses menggunakan metode AHP-ELECTRE dan SAW.  Metode yang digunakan pertama kali adalah metode AHP digunakan untuk pemberian bobot pada setiap kriteria yang diberikan kepada pengguna. Setelah hasil perhitungan metode AHP yang berupa bobot prioritas kriteria telah didapatkan selanjutnya akan digunakan dalam perhitungan metode ELECTRE. Dimana perhitungan ELECTRE digunakan untuk mengelompokkan data alternatif yang dibagi menjadi 2 kelompok yaitu kelompok data yang direkomendasikan dan tidak 
direkomendasikan. Data alternatif kelompok yang direkomendasikan selanjutnya dihitung pada metode SAW selanjutnya, sedangkan data kelompok yang tidak direkomendasikan akan dieliminasi. Alternatif kelompok data direkomendasikan ini selanjutnya akan  digunakan pada metode SAW untuk dilakukan perankingan. Sehingga didapatkan hasil urutan rekomendasi sekolah yang paling mendekati kriteria.  Alur perancangan metode yang digunakan terlihat pada Gambar 5.  
Gambar 5. Alur Perancangan Metode   
Dari Gambar 5  diatas, data masukkan pengguna dihitung menggunakan metode AHP terlebih dahulu, setelah metode AHP menghasilkan bobot kriteria, selanjutnya dihitung menggunakan metode ELECTRE untuk pengelompokan alternatif, kelompok alternatif yang masuk ke dalam kelompok direkomendasikan akan digunakan pada metode SAW untuk dilakukan perankingan hasil alternatif.  

4. PENGUJIAN DAN ANALISIS  
Pengujian akurasi sistem adalah dengan membandingkan data hasil rekomendasi sekolah dari sistem dengan data hasil survey. Tujuan dari pengujian  adalah untuk mengetahui banyaknya data yang sesuai antara hasil dari sistem dengan hasil survey. Dikatakan sesuai apabila hasil dari sistem mengeluarkan rekomendasi sekolah yang masuk ke dalam ranking 5 besar dan rekomendasi sekolah tersebut terdapat pada data hasil survey.  Skenario pengujian adalah pengguna memasukkan data pribadi dan mengisi kriteria-kriteria yang diinginkan. Kemudian diproses oleh sistem dengan menggunakan 3 metode yaitu metode AHP, ELECTRE dan SA W. Hasil keluaran dari 
sistem merupakan perankingan hasil perhitungan metode SAW. Dimana hasil perankingan tersebut merupakan urutan yang termasuk ke dalam 5 besar. Apabila hasil sekolah yang direkomendasikan oleh sistem masuk ke dalam ranking 5 besar maka  sudah sesuai dengan data hasil survey.  Hasil pengujian dengan data uji sebanyak 47. Diperoleh data yang sesuai sebanyak 39, sedangkan data yang tidak sesuai sebanyak 8. Sehingga didapatkan akurasi sistem dengan perhitungan sebagai berikut :  
ð´ð‘˜ð‘¢ð‘Ÿð‘Žð‘  ð‘–= 47âˆ’8
47Ã—100% =82,98%  
Nilai akurasi tidak mencapai 100% dikarenakan adanya data hasil dari sistem tidak mengeluarkan rekomendasi sekolah yang sesuai dengan data survey dan tidak masuk ke dalam ranking 5 besar. Pada pengujian metode ELECTRE hasil yang didap at tidak mencapai 100%, sehingga pada pengujian metode SAW hasil akurasinya tidak mencapai 100%. Karena, perolehan ranking sekolah yang masuk ke dalam 5 besar pada metode SAW berasal dari kelompok yang direkomendasikan pada perhitungan metode ELECTRE. Hasil pengujian metode SAW terdapat hasil yang tidak sesuai, dikarenakan pada perhitungan metode ELECTRE terdapat sekolah yang masuk ke dalam kelompok direkomendasikan sesuai dengan data survey, tetapi pada perhitungan metode SAW sekolah tersebut tidak masuk ke dalam ranking 5 besar. Hasil pengujian sistem terlihat pada Gambar 6.   
Gambar  6. Hasil Pengujian Sistem  

5. KESIMPULAN  
Berdasarkan hasil perancangan, implementasi, dan pengujian yang telah dilakukan pada bab sebelumnya, maka dalam penelitian ini dapat diambil kesimpulan :  
1. Sistem rekomendasi pemilihan SMA Sederajat kota Malang menggunakan 3 metode yaitu metode AHP, ELECTRE dan SAW. Metode AHP digunakan dalam pemberian bobot kriteria yang akan digunakan pada metode selanjutnya. Metode  ELECTRE 
digunakan dalam pengelompokan data alternatif yang masuk ke dalam kelompok yang direkomendasikan, untuk data dalam kelompok yang tidak direkomendasikan akan dieliminasi. Kelompok yang direkomendasikan tersebut digunakan dalam metode SAW untuk dila kukan perankingan data alternatif sekolah dimana dalam melakukan ranking diambil alternatif sekolah ke dalam 5 besar.  
2. Nilai akurasi dari pengujian sistem dengan menggunakan 47 data uji didapatkan hasil akurasi sebesar 82,98%. Dengan hasil yang didapatkan berasal dari pengelompokkan data alternatif yang masuk ke dalam kelompok yang direkomendasikan. Hasil akurasi sistem tidak dapat mencapai lebih dari 82,98% karena pada metode ELECTRE yang dilakukan pengelompokkan data, memiliki akurasi yang tidak lebih dari 82,98%. Hal ini dapat terjadi karena sistem dalam memberikan rekomendasi mempertimbangkan prestasi sekolah, ekstrakurikuler sekolah dan fasilitas sekolah. Sedangkan dalam kenyataannya setiap sekolah memiliki prestasi, ekstrakurikuler dan fasilitas sekolah yang berbeda -beda.  

6. DAFTAR PUSTAKA  
AQLI, I., EKA, D. R. & DATA M. 2016. Sistem Rekomendasi Pemilihan Sekolah Menengah Atas Sederajat Kota Malang Menggunakan Metode AHP ELECTRE dan TOPSIS. Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK) FILKOM UB Vol.  3 No. 4.  
AWANG, R. S., 2006. Analisis Pemilihan Sekolah Menengah Atas Semarang Berdasarkan Efektifitas Jarak, Saran Angkutan Umum dan Tingkat Unggulan Sekolah dengan Menggunakan Sistem Informasi Geografis dan AHP . Universitas Negeri Semarang.  
FADLIL, J., MAHMUDY, WF ., 2007. Pembuatan Sistem Rekomendasi Menggunakan Decision Tree dan Clustering . Kursor Vol. 3, No. 1.    
FAISAL, PERMANA, S., 2015. Sistem Penunjang Keputusan Pemilihan Sekolah Menengah Kejuruan Teknik Komputer dan Jaringan yang Terfavorit dengan Menggunakan Multi-Criteria Decision Making . Jurnal Teknologi Informasi dan Ilmu Komputer Vol. 2, No. 1. Universitas Trilogi.  
FAUZI, W. , 2016. Sistem Pendukung Keputusan Penerima Bantuan Dana Rutilahu dengan Menggunakan Metode ELECTRE . Universitas Jenderal Achmad Yani.  
ISMAIL, J., 2015. Pemodelan Sistem Pendukung Keputusan Penentuan Line Up dalam Cabang Olahraga Futsal Menggunakan Metode AHP-SAW (Studi Kasus : Hefotris FILKOM UB). DORO : Repositor i Jurnal Mahasiswa PTIIK Universitas Brawijaya , Vol. 6,  No.  29. 
KUSRINI, GOLE, A., 2007. Sistem Pendukung Keputusan Penentuan Prestasi Pegawai Nakertrans Sumba Barat di Waikabubak . STMIK AMIKOM Yogyakarta, SNATI 2007.  
MAGHFIROH, F., 2015. Sistem Pendukung Keputusan Seleksi Penerimaan Peserta Didik Baru Menggunakan Metode ELECTRE dan 
SAW . DORO : Repositori Jurnal Mahasiswa PTIIK Univer sitas Brawijaya , Vol. 5 No. 3.  
MUFIZAR, T., 2015. Sistem Pendukung Keputusan Pemilihan Dosen Berprestasi di STMIK Tasikmalaya Menggunakan Metode Simple 82,98%17,02% HASIL PENGUJIAN SISTEM
SESUAI TIDAK SESUAI 30   Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK) , Vol. 4, No. 1, Maret  2017 , hlm. 25-30 
Additive Weighting (S AW). CSRID Journal, Vol. 07 No. 3. STMIK Tasikmalaya.  PANDUAN PPDB KOTA MALANG . 2015. Malang  
PAREIRA O., JOKO S., ARDANARI P., 2014. Sistem Pendukung Keputusan Pemilihan Tempat Wisata di Timor Leste dengan Metode ELECTRE. S2. Universitas Atma Jaya Yogyaka rta. 
PERMENDIKNAS RI. 2007. Standar Pengelolaan Pendidikan Oleh Satuan Pendidikan Dasar dan Menengah (Peraturan Menteri Pendidikan Nasional Republik Indonesia Nomor 19 Tahun 2007) . 
RACHMAWATI,  2015. Rekomendasi Kecocokan Tanaman Hortikultura Berdasarkan Komposisi Struktur Tanah Pada Kota Batu Menggunakan Metode SAW. DORO : Repositori Jurnal Mahasiswa PTIIK Universitas Brawijaya, Vol. 5 No. 18.   
SARAGIH, S. H ., 2013. Penerapan Metode Analitycal Hierarchy Process (AHP) pada Sistem Pendukung Keputusan Pemilihan Laptop . STMIK Budi Darma Medan.  TOBING, G., L ., 2014. Sistem Pendukung Keputusan Pemilihan Jurusan pada Sekolah Menengah Kejuruan (SMK) Negeri 1 Siatas Barita dengan Metode Simple Additive Weighting (SAW) . STMIK Budi Darma Medan.  
TRISNAWARMAN, D., LIVER EJA, M ., 2006. Aplikasi Sistem Pendukung Keputusan Pemilihan Sekolah . Universitas Tarumanagara Jakarta.  
TZENG, G., HUANG, J., 2011. Multiple Attribute Decision Making Methods and Applications . CRC Press.  
UYUN, S., MADIKHATUN, Y ., 2011. Model Rekomendasi Berbasis Fuzzy untuk Pemilihan Sekolah Lanjutan Tingkat Atas . Jurnal Informatika Vol 5, No. 1. Universitas Islam Negeri Sunan Kalijaga.",sistem rekomendasi,"AHP-ELECTRE, SAW","data pribadi, Sekolah Menengah Atas",akurasi
SISTEM REKOMENDASI NILAI MATA KULIAH MENGGUNAKAN METODE CONTENT-BASED FILTERING,"SISTEM REKOMENDASI NILAI MATA KULIAH MENGGUNAKAN METODE CONTENT-BASED FILTERING

Puspaningtyas Sanjoyo Adi1)   

Abstrak 
Sistem rekomendasi merupakan sistem yang bertujuan memperkirakan informasi yang menarik bagi penggunanya dan juga membantu calon konsumen dalam memutuskan barang apa saja yang akan dibelinya. Pada awal semester, setiap mahasiswa mendaftar untuk menempuh suatu mata kuliah. Saat inilah, mahasiswa membutuhkan suatu rekomendasi mengenai nilai yang akan diperolehnya. Penelitian ini bertujuan membuat perkiraan nilai mata kuliah yang akan ditempuh oleh  seorang mahasiswa. Metode yang digunakan adalah metode content-based filltering. Metode content-based filering diimplementasikan den gan masukan sistem adalah dokumen silabus mata kuliah. Dokumen-dokumen ini selanjutnya diproses penghapusan stop word, stemming dan pengindeksan. Proses pengindeksan mengasilkan sebuah daftar kata dan frekuensinya pada dokumen tersebut. Setelah proses pengindeksan selesai, sistem akan melakukan penghitungan bobot kata dalam semua dokumen dengan algoritma TF-IDF. Menggunakan bobot kata ini, dokumen dapat dimodelkan dalam vekor yang dikenal dengan istilah vector space model. Berdasarkan model ini, setiap mata kuliah dihitung tingkat kemiripannya satu sama lain. Nilai tingkat kemirian ini selanjutnya digunakan untuk membangkitkan rekomendasi nilai menggunakan algoritma K Nearest Neighborhood. Sistem ini telah diujicobakan pada 10 mahasiswa T. Informatika USD angkatan 2006. Sistem membangkitkan  rekomendasi untuk nilai-nilai semester 3 dan semester 4. Nilai yang dibangkitkan sebanyak 176 buah dengan tingkat akurasi sebesar 53%. Tingkat akurasi ini sangat jelek karena masih belum tepatnya algoritma pembangkitan rekomendasi dalam hal ini algoritma K Nearest neighborhood. Masih diperlukan penelitian lanjutan untuk menyempurnakan sistem ini.  

Keyword : content based filtering, sistem rekomendasi 
 
1. PENDAHULUAN 
Sistem rekomendasi merupakan sistem yang bertujuan memperkirakan informasi yang menarik bagi penggunanya dan juga membantu calon konsumen dalam memutuskan barang apa saja yang akan dibelinya. Sistem rekomendasi secara khusus merupakan suatu sistem pemberian saran kepada penggunanya dan bersifat personal, berbeda untuk semua pengguna sistem. Dalam suatu perguruan tinggi, mahasiswa belajar dalam s uatu 
sistem kurikulum yang terdiri atas sekumpulan daftar mata kuliah dimana setelah menempuh mata kuliah, mahasiswa akan mendapatkan nilai. Nilai mata kuliah  yang akan diterima didasarkan atas kemampuan mahasiswa. Setiap mata kuliah mempunyai karakteristik yang berbeda satu sama lain. Karakteristik mata kuliah tercermin dari silabus dan satuan acara perkuliahan . Sistem rekomendasi nilai mata kuliah ini merupakan sistem yang bersifat personal bagi seorang mahasiswa. Pada awal semester, setiap mahasiswa mendaftar untuk menempuh suatu mata kuliah. Saat inilah, mahasiswa 
membutuhkan suatu rekomendasi mengenai nilai yang akan diperolehnya. Nilai suatu mata kuliah diperoleh  berdasar kemampuan mahasiswa yang juga sesuai dengan karakteristik mata kuliah tersebut.  Berdasarkan karakteristik suatu mata kuliah, profil  seorang mahasiswa dibentuk yang sesuai dengan kara kteristik mata kuliah. Penentuan profil mahasiswa sesuai kara kteristik mata kuliah merupakan implementasi dari metode content-based filtering . Dalam mengikuti perkuliahan, nilai suatu mata kuliah yang sejenis umumnya akan sama untuk seorang mahasiswa. Prinsip korelasi antar mata kuliah menjadi dasar dari metode content based filtering .  Berdasar latar belakang di atas, rumusan masalah penelitian ini adalah bagaimana membuat perkiraan nilai mata kuliah yang akan ditempuh oleh seorang mahasiswa dalam sebuah bentuk aplikasi sistem rekomendasi. 
 
2. TINJAUAN PUSTAKA 
Sistem rekomendasi merupakan suatu sistem yang bertujuan memperkirakan informasi yang menarik bagi penggunanya [1]  dan membantu calon konsumen dalam memutuskan barang apa yang akan dibelinya [8] . Perkiraan informasi ini bersifat personil yang dida sarkan atas profil dari pengguna sistem. Profil pengguna umumnya didasarkan atas penilaian menarik-tidaknya suatu infomasi yang pernah dibaca oleh pengguna. Sistem rekomendasi sudah banyak diterapkan pada berbagai model bursa elektronis. Salah satu metode yang digun akan adalah metode Content-based Filtering. Secara umum, metode content-based filtering membentuk profil penggunanya berdasarkan atribut pembentuk suatu item [4] . Sebagai contoh untuk suatu item dokumen, atribut pembentuknya adalah kata-kata/ term  yang terdapat pada dokumen tersebut. Parameter pembentuk  profil pengguna ini juga diberi nilai bobot berdas arkan kriteria tertentu, misalnya untuk kasus dokumen adalah frekuensi suatu kata/term dalam dokumen tersebut. Content-based filtering memberikan suatu rekomendasi berdasarkan hasil anal isa kemiripan item yang telah dinilai oleh para penggunanya. Metode ini pada awal nya diterapkan dalam sistem rekomendasi dokumen. Variasi 
metode ditawarkan berdasarkan suatu analisis isi dokumen dan pencarian keteraturan dalam berbagai dokumen. Pendekatan metode lain dilakukan menggunakan metode  klasifikasi dengan tujuan memperkirakan golongan suatu item atau teks, misalnya golongan disukai atau tidak disukai. Metode lain juga melakukan klasifi kasi dengan melakukan pembobotan suatu item atau teks dalam suatu nilai numerik.  Secara umum, metode content-based filtering  mempunyai 2 teknik umum dalam membuat rekomendasi yaitu heuristic-based  dan model-based [1] . Cosine similarity, Boolean query, teknik TF-IDF ( term frequency-invers document frequency ) dan Clustering  termasuk dalam golongan heuristic-based  sedangkan yang masuk dalam golongan model-based  adalah teknik Bayesian classifier & Clustering, Decision Tree dan  Artificial Neural Network . Penelitian ini akan menggunakan algoritma TF-IDF ( term frequency-invers document frequency ) sebagai pembentuk profil pengguna. Algoritma metode content-based filtering  dapat dijelaskan dalam langkah-langkah : 
1.  Suatu item barang dibagi-bagi berdasarkan suatu vektor komponen pembentuknya. Misalnya untuk sebuah film dibagi atas komponen aktor, sutradara, jenis film, dll. 
2.  Pengguna memberi penilaian suka atau tidak suka atas item tersebut. 
3.  Sistem akan membuat profil pengguna berdasarkan bob ot vektor komponen pembentuk suatu item. Pembuatan profil pengguna dapat menggunakan algoritma TF-IDF ( term frequency-invers document frequency ). TF adalah jumlah term dalam suatu dokumen. Sedan gkan nilai IDF dapat dihitung menggunakan rumus: 
ï£·ï£·
ï£¸ï£¶
ï£¬ï£¬
ï£­ï£«=
iidfnidf log ................................................... ................................................... ...............(1) 
n merupakan jumlah semua dokumen sedangkan df adalah jumlah dokumen yang memiliki term i. 
4.  Berdasarkan profil pengguna tersebut, sistem akan memperkirakan penilaian suka atau tidak suka suatu item berdasarkan analisis kemiripan profil pengguna  dengan vektor komponen pembentuk item. Jika sistem memperkirakan bahwa item tersebut akan disukai oleh pengguna maka item tersebut akan direkomendasikan ke pengguna. 
Metode ini memiliki kekurangan yang utama yaitu ketidakmampuan merekomendasikan jenis item yang baru atau belum pernah dilihat kepada seorang pengguna. Hal ini disebabkan oleh karena metode ini dibuat berdasarkan item-item yang pernah dinilai oleh peng guna tersebut. Tujuan penelitian inilah adalah mengembangkan suatu  perangkat lunak yang dapat membuat perkiraan nilai  dari mata kuliah yang ditempuh oleh seorang mahasiswa. Masukan sistem adalah daftar nilai terbaik dan daftar mata kuliah yang sedang ditempuh mahasiswa. Masukan lain nya adalah silabus dan SAP( satuan acara perkuliaha n). Studi kasus yang digunakan adalah program studi Teknik Informatika Universitas Sanata Dharma. Hasil penelitian diharapkan mampu membantu mahasiswa dalam mengenali kemampuan diri sendiri. Karakteristik 
mahasiswa diberikan dalam bentuk term/kata penting kuliah yang dikuasainya dengan baik. 
 
3. METODE PENELITIAN 
Langkah Kerja 
Metode penelitian yang diacu menggunakan metode pengembangan perangkat lunak berbasis obyek yang bersifat iteratif. Langkah-langkah metode pengemban gan perangkat lunak secara umum dapat dilihat pada tabel 1.  
Tabel 1. Langkah-langkah Pengembangan Perangkat Lunak 
No Pekerjaan Dokumen Keluaran 
1.   Analisis kebutuhan Dokumen Spesifikasi dan Kebutuhan 
2.  Analisis dan perancangan sistem Dokumen Teknis Pengembangan Perangkat Lunak 
3.  Pengembangan sistem Kode Program 
4.  Pengujian sistem Dokumen Pengujian Perangkat Lunak  
Proses Pembangkitan Rekomendasi  
Perangkat lunak akan dikembangkan berdasarkan proses pembangkitan rekomendasi seperti gambar 1. Masukan utama sistem adalah dokumen SAP/silabus kuliah dan daftar nilai mahasiswa. Keluaran sistem adalah perkiraan/rekomendasi nilai kuliah. Semua dokumen SAP akan diolah dengan cara menghilangkan kata-kata yang tidak penting(stop word), lalu diambil kata da sarnya (proses stemming). Proses indexing merupakan  proses penghitungan jumlah term dalam suatu dokumen sedang kan proses TF-IDF adalah penghitungan bobot dari setiap term pada suatu dokumen. Bobot inilah yang akan digunakan sebagai dasar pembentukan model vektor dari dokumen.  
Gambar 1. Proses pembangkitan rekomendasi  
Proses Penghapusan Stop Word, Stemming dan Indexing  Proses ini merupakan proses untuk menghilangkan kata-kata yang tidak penting seperti yang, adalah, dan , dll. Proses stemming merupakan proses untuk menemukan kata dasar. Misalnya, kata â€˜menghitungâ€™ mempunyai kata dasar â€˜hitungâ€™. Algoritma stemming yang digunakan adalah algoritma Nazief & Adrianiâ€™s. Pada penelitian  ini, satu mata kuliah diwakili oleh satu buah dokumen silabus. Dokumen silabus memuat identitas kuliah, tujuan instruksional umum, pokok bahasan dan sumber pustaka. Setelah sebuah dokumen selesai distemming, proses selanjutnya adlah pembuatan indeks untuk dokumen tersebut. Pada penelitian ini, metode yang digunakan adalah gabungan antara penggunaan mesin basis data MySql dan pohon biner seperti gambar 2. Pohon biner dipilih karena kecepatan dan kemudahan implementasinya. Database MySQL digunakan untuk menyimpan kamus kata-kata bahasa Indonesia dan stop word. Database MySQL juga digunakan untuk menyimpan seluruh indeks  dari keseluruhan dokumen silabus. Daftar mata kuliah beserta dokumen silabus dapat dilihat pada bagian hasil dan pembahasan. Indeks sebuah dokumen akan berisi informasi kata-kata dan jumlah kata yang terdapat dalam sebuah dokumen. Data indeks ini akan digunakan  sebagai vektor pembentuk queri masukan. Dengan menggabungkan seluruh indeks dokumen, sistem rekomendasi akan membentuk suatu inverted index (lihat gambar 3). Model inverted indeks ini nantinya akan digunakan untuk menghitung IDF ( invers document frequency ). 
Gambar 2. Pohon biner untuk pembentuk indeks dokumen 
Study result  course  document   Stop word, stemming,  indexing   Stop word,stemming, indexing  TF -IDF  TF-IDF  Similarity  Comparison  Analysis recomendation   memory 
â‰¥ < 
â‰¥ < â‰¥ < film variable 
variable  
2 memory  1 film  1 bit  2 Balanced Binary Tree    
Gambar 3. Model inverted indeks  
Proses Penghitungan Bobot Term dengan TF-IDF 
Penghitungan bobot term/kata pada dokumen menggunakan algoritma TF-IDF. Variabel TF merupakan jumlah suatu term/kata dalam suatu dokumen, sedangkan IDF merupakan invers document frequency dari sebuah term/kata yang dapat dihitung menggunakan rumus 1. Sedangkan bobot kata pada suatu dokumen dihitung berdasarkan rumus 2. 
ï£·ï£·
ï£¸ï£¶
ï£¬ï£¬
ï£­ï£«Ã—=
idididfntfw log, ,  .................................................. .......................(2) 
ditf, adalah jumlah term dalam sebuah dokumen. 
Dengan menggunakan bobot TF-IDF, sebuah dokumen dapat dimodelkan sebagai sebuah vektor (lihat gambar 
4). Dokumen iD dapat dimodelkan atas komponen iT sehingga jika seluruh dokumen dikumpulkan maka akan terbentuk matriks term-dokumen dengan nilai bobot term/TF-IDF sebagai nilainya. 
Gambar 4. Model vektor dokumen  
Proses Penghitungan Kemiripan (Similarity)  
system computer database science    
D2, 4
D5, 2 
D1, 3 
D7, 4 
Index terms  df 3 
241 Dj, tfj 
Index file Postings lists  â€¢ â€¢ 
         T1   T 2    â€¦.      T t 
D1    w 11   w 21    â€¦      w t1  
D2    w 12   w 22    â€¦      w t2  
 :       :      :               : 
 :       :      :               :  
Dn    w 1n   w 2n    â€¦      w tn 
Penghitungan kemiripan antar dokumen dilakukan dengan cara menghitung Cosine Similarity antara vektor dokumen koleksi dan vektor dokumen queri (lihat gam bar 5). Sebuah dokumen dan queri akan dimodelkan dalam vektor D dan Q berdasarkan atas nilai bobot semua term (lihat gambar 4). Tingkat kemiripan vektor D dan Q diukur berdasarkan perhitungan  Cosine Similarity  sbb: 
âˆ‘ âˆ‘âˆ‘
= ==
â†’â†’â†’â†’
â‹…â‹…
=
â‹…â‹…=
t
it
it
i
ii
i
wwww
iqijiqij
qdqdqdCosSim
1 12 21) (
),(..............................................(5) 
 
",sistem rekomendasi,"content-based filtering, TF-IDF, K-Nearest Neighbor, vector space model","nilai mata kuliah, silabus mata kuliah",akurasi
Sistem Rekomendasi Content-based Filtering Menggunakan TF-IDF Vector Similarity Untuk Rekomendasi Artikel Berita,"Sistem Rekomendasi Content-based Filtering Menggunakan TF-IDF Vector Similarity Untuk Rekomendasi Artikel Berita

Arif Akbarul Huda1,*, Rohmad Fajarudin2, Arifiyanto Hadinegoro3 

Abstrak
Populasi mahasiswa aktif prodi Informatika Universitas Amikom Yogyakrta pada semester Ganjil 2021 sebanyak 3870 
orang. Upaya pelacakan minat terhadap tiga pilihan konsentrasi dilakukan sejak dini, melalui rekomendasi literasi artikel. Ragam artikel diproduksi terus menerus dan diberikan secara berkelanjutan kepada Mahasiswa. Namun dengan banyaknya artikel yang ditawarkan setiap hari justru membuat mahasiswa kewalahan dan cenderung memimilih artikel yang kurang sesuai dengan apa yang sebenarnya diinginkan.  Untuk membantu menemukan informasi yang relevan, dikembangkanlah sistem rekomendasi. Sistem rekomendasi akan membantu mengestimasi nilai prediksi atau relevansi dari sebuah artikel dan kemudian membuat ranking atas artikel-artikel tersebut yang sesuai dengan minat pengguna. Teknik Content-based Filtering dipilih dalam pembuatan sistem 
rekomendasi pada penelitian ini. Dengan menggunakan dataset dari portal berita Kabar Informatika Universitas Amikom 
Yogyakarta, sistem rekomendasi Content -based Filtering pada penelitian ini mampu memberikan skor Recall@5 sekitar 73% dan Recall@10 sekitar 80%.  

Kata Kunci : Artikel Berita

Abstract 
The population of active students in the Informatics Bachelor Program, Universitas Amikom Yogyakarta, in the odd semester of 2021 is 3,870. Efforts to track interest in the three concentration options were carried out early on through article literacy recommendations. Various articles are produced continuously and provided on an ongoing basis to students. However, the many articles offered daily make students overwhelmed and tend to choose articles that do not match what they want.  To help solve this problem, recommender system is developed. A recommender system helps to estimate the prediction value or relevancy of an article and create a ranking according to user's taste. Content-based Filtering technique is used in this research. Using the dataset from Kabar Informatika news portal of University of Amikom Yogyakarta, the developed Content -based Filtering 
Recommendation System is able to produce Recall@5 score at around 73% and Recall@10 at around 80%.  

Keywords : Content-based Filtering

1. PENDAHULUAN  
Diambil dari  Pangkalan Data Dikti 2022 [1] , populasi mahasiswa aktif prodi Informatika  pada semester Ganjil 2021 
sebanyak 3870 orang.  Upaya pelacakan  minat terhadap tiga pilihan konsentrasi  dilakukan sejak dini, melalui  rekomendasi literasi  artikel . Tiga konsentrasi tersebut meliputi  Software Engineering & Big Data, Cloud Networking 
dan Multimedia yang kemudian  dalam platform berita direpresentasikan sebagai kategori artikel.  Ragam artikel diproduksi terus menerus dan diberikan secara berkelanjutan kepada Mahasiswa . Namun dengan banyaknya artikel yang ditawarkan setiap hari justru membuat mahasiswa kewalahan dan  cenderung memimilih artikel yang kurang sesuai dengan apa yang sebenarnya diinginkan.  Untuk membantu menemukan informasi yang relevan diantara banyaknya informasi yang ada, dikembangkanlah Sistem Rekomendasi [2]. Tujuan dari sistem rekomendasi adalah untuk memberikan konten (item) 
secara  efektif dan berarti kepada pengguna yang aktif didalam platform  [3]. Sistem Rekomendasi adalah seperangkat 
peralatan dan teknik yang memberikan saran kepada pengguna tentang item spesifik yang kemungkinan mereka minati. Sebuah sistem rekomendasi mencatat profil pengguna dan berdasarkan minat mereka, menyarankan sebuah produk atau layanan [4]. Saran yang diberikan bisa dalam domain  apapun mulai dari saran layanan web apa yang digunakan hingga artikel berita untuk dibaca [5]â€“[7]. Terdapat dua tipe sistem rekomendasi, yang dipersonalisasi dan yang tidak dipersonalisasi. Sistem rekomendasi yang dipersonalisasi adalah sistem yang mana setiap pengguna mendapatkan saran yang berbeda, sedangkan sistem rekomendasi yang tidak dipersonalisasi semua pengguna mendapatkan saran yang sama [8]. Yang perlu dilakukan oleh sistem rekomendasi yang dipersonalisasi adalah dua hal, yaitu (i) mengestimasi nilai prediksi untuk sebuah item (ii) memberikan ranking item-item tersebut berdasarkan nilai prediksinya [9]. Terdapat beberapa pengelompokan dalam sistem rekomendasi. Beberapa yang populer antara lain Content-based Filtering, Collaborative Filtering , dan kombinasi antara keduanya yang disebut dengan Hybrid  [10]. ]. Untuk dapat memberikan manfaat kepada pengguna, sistem rekomendasi dituntut untuk bisa memprediksi item yang relevan dengan pengguna. Pada referensi berikut untuk mencapai tujuan tersebut diperlukan beberapapertimbangan. Diantaranya adalah pertimbangan da lam pemilihan teknik sistem rekomendasi yang disesuaikan dengan ketersediaan data dan konteks penerapannya [11]. Untuk dapat memberikan manfaat kepada pengguna, sistem rekomendasi dituntut untuk bisa memprediksi item yang relevan dengan pengguna. Pada referensi berikut [11] untuk mencapai tujuan tersebut diperlukan beberapapertimbangan. Diantaranya adalah pertimbangan dalam pemilihan teknik sistem rekomendasi yang disesuaikan dengan ketersediaan data dan konteks penerapannya. Sistem rekomendasi artikel berita, pernah dikembangkan  menggunakan dice similarity [12] dan K-Nearest 
Neighbors(KNN) [13]. Pendekatan lain dilakukan [14] melalui pembobotan  Implicit Social Trust  dan Support Vector 
Regression  untuk memprediksi nilai topik sebuah artikel.  Sedangkan mekanisme peringkasan berita  telah dilakukan  
[15] menggunakan fitur pembobotan TFIDF.  Penelitian ini berfokus pada penggunaan metode Content-based Filtering dalam pembuatan sistem rekomendasi untuk artikel berita. Metode ini akan mendeskripsikan item, dalam hal ini artikel, menggunakan kata kunci. Algoritma yang dipakai dalam metode ini memprediksi item berdasarkan apa yang disukai oleh pengguna diwaktu lampau. Dalam Content-based Filtering, sistem membandingkan profil dari pengguna dengan profil dari konten (item) lalu mencari item yang mempunyai kemiripan kemudian menyarankannya ke pengguna [10]. Algoritma  TF-IDF dan Cosine Similarity dirancang sedemikian rupa dan dikemas dalam sebuah package  python  sehingga dapat Kembali digunakan untuk keperluan berikutnya.  

2. METOD OLOGI PENELITIAN  
2.1 Landasan Penelitian  
a. Sistem Rekomendasi  
Sistem Rekomendasi adalah seperangkat peralatan dan teknik yang dapat memprediksi nilai preferensi atau rating sebuah item dengan memanfaatkan informasi personal seseorang dan karakteristik item [16]. Sistem ini mampu  memberikan saran kepada pengguna tentang item spesifik yang kemungkinan mereka minati. Sebuah sistem rekomendasi mencatat profil pengguna dan berdasarkan minat mereka, menyarankan sebuah produk atau layanan [4][17]. Saran yang diberikan bisa dalam domain  apapun mulai dari saran layanan web apa yang digunakan hingga artikel berita untuk dibaca [5]â€“[7]. Tujuan dari sistem rekomendasi adalah untuk memberikan konten ( item) yang efektif dan berarti kepada penggu na yang aktif didalam platform [3]. Sebuah sistem rekomendasi secara abstrak dianggap sebagai integrasi dari tiga komponen utama, yaitu, pengumpulan data, mesin rekomendasi, dan antarmuka pengguna [18]. 
b. Content-based Filtering  
Content-based Filtering  adalah sebuah pendekatan yang relatif umum dalam bidang Information Retrieval . Area riset seputar Content -based Filtering  berfokus pada rekomendasi konten tekstual seperti laman web, buku, dan film [19][20]. Content-based Filtering  memberikan rekomendasi item dengan membandingkan fitur dari item tersebut [9], [19] . 
c. Term Frequency â€“ Inverse Document Frequency (TF -IDF)  
TF-IDF adalah sebuah model statistik untuk mengevaluasi seberapa penting kata dalam kumpulan dokumen [21]. TF-IDF digunakan secara luas untuk pemilihan fitur dalam pemrosesan informasi teks. Algoritma ini terdiri dari dua bagian: (1) Term Frequency  (TF) yang merepresentasikan frekuensi kemunculan sebuah kata dalam teks Inverse Document Frequency  (IDF) mengukur seberapa penting sebuah kata yang diimbangi dengan seberapa sering kemunculan sebuah kata dalam keseluruhan data. Nilai signifikansi dari sebuah kata meningkat bersamaan dengan frekuensi kemunculan pada sebuah teks, namun berbanding terbalik dengan meningkatnya frekuensi kemunculan dalam kumpulan teks [22]. TF-IDF adalah algoritma skema pemberatan yang paling populer [23]. Berikut adalah formula dari TF -IDF:  
ð‘¡ð‘“(ð‘¡,ð‘‘)=ð‘“ð‘¡,ð‘‘
âˆ‘ ð‘“ð‘¡â€²,ð‘‘ ð‘¡â€²âˆˆð‘‘        (1) 
ð‘–ð‘‘ð‘“(ð‘¡,ð·) = ð‘™ð‘œð‘” ð‘
|{ð‘‘âˆˆð·âˆ¶ ð‘¡âˆˆð‘‘}|       (2) 
ð‘¡ð‘“ð‘–ð‘‘ð‘“ (ð‘¡,ð‘‘,ð·) = ð‘¡ð‘“(ð‘¡,ð‘‘) âˆ™ ð‘–ð‘‘ð‘“(ð‘¡,ð·)      (3) 
d. Vector Space Model  
Vector Space Model adalah metode untuk mempresentasikan konten dari item, dalam hal ini konten artikel, kedalam vektor n-dimensi dimana n adalah jumlah keseluruhan kata yang telah diekstrak dari konten. Setiap posisi dalam vektor memberikan nilai berat (relevansi) dari sebuah kata pada item atau pengguna dan dihitung menggunakan TF-IDF [9]. 
e. Cosine Similarity  
Dua buah item dapat diukur nilai kempiripannya melalui beberapa cara, namun secara  garis besar didenfinisikan sebagai berikut: diberikan dua item, i1 dan i2, tingkat kemiripan diantara keduanya ditulis dengan fungsi sim(i1,i2)[24].  Salah satu algoritmanya adalah Cosine Similarity . Secara matematik, setiap dokumen diproyeksikan sebagai sebuah vektor multi -dimensi, kemudian dihitung sudut cosine antara kedua vektor. Semakin kecil sudutnya maka semakin mirip dokumen tersebut. Pada sistem rekomendasi Content-based Filtering , Cosine Similarity  diaplikasikan pada vektor fitur untuk mencari item memiliki kesamaan [9][25]. Berikut ini adalah formula dari  Cosine Similarity:  
ð‘ ð‘–ð‘š (ð‘–1,ð‘–2)=cos (ðœƒ)= ð´âˆ™ ðµ
||ð´|| ||ðµ|| = âˆ‘ ð´ð‘–ðµð‘–ð‘›
ð‘–=1
âˆšâˆ‘ ð´ð‘–2 ð‘›
ð‘–=1  âˆšâˆ‘ ðµð‘–2 ð‘›
ð‘–=1    (4) 
2.2 Tahapan Penelitian  
Tahapan p enelitian secara garis besar ditunjukkan pada Gambar 1. Tahap pertama dimulai dari melakukan analisis  kebutuhan dan ketersediaan data yang tersedia di portal berita Kabar Informatika dan melakukan studi literatur. Hal ini dilakukan dalam rangka untuk memilih metode sistem rekomendasi yang dapat memanfaatkan data yang tersedia dengan baik.   
Gambar 1.  Tahapan penelitian  
Dataset yang digunakan berasal dari portal berita Kabar Informatika Universitas Amikom Yogyakarta. Dataset yang tersedia memiliki fitur cukup lengkap seperti judul, penulis, kategori, dan konten artikel itu sendiri yang sangat mendukung dalam proses pembuatan rekomendasi. Dataset ini cukup kecil dengan jumlah artikel sebanyak 22 dan jumlah data interaksi artikel sebanyak 345 yang berasal dari 20 pengguna.  Tahap kedua melakukan peninjuan literas i melalui pencarian buku serta penelitian serupa melalui portal Garuda dan Google Scholar. Dilanjutkan tahap ketiga System Development yang mencakup proses perancangan, pengembangan dan implementasi . Proses perancangan dilakukan dengan metode waterfall. Metode waterfall dipilih karena proses perancangan setiap tahapnya yang secara alami bergantung dengan tahap sebelumnya untuk mulai mengerjakan tahap selanjutnya.   Rancangan arsitektur package mesin rekomendasi yang di bangun ditunjukkan pada Gambar 2. Proses 
perancangan dimulai dari pengumpulan data, pre-processing data yang telah dikumpulkan, membuat mesin rekomendasi, dan diakhir dilakukan evaluasi. Tahap evaluasi akan dilakukan menggunakan metrik Recall.   
Gambar 2.  Arsitektur Sistem Rekomendasi  
4. Evaluasi 3. System Development 2. Studi Lietartur 1. Analisis Kebutuhan
Semua elemen saling bekerja sama dalam setiap tahapan proses yang terjadi dimulai dari data mentah sampai dengan produksi rekomendasi artikel. Layer  Available Data menyediakan data operasional dari platform berita ke layer diatasnya. Pada layer Data Processing, bagian Pre-Processing akan  melakukan berbagai pemrosesan awal yang diperlukan agar data operasional dapat diproses. Selanjutnya bagian Feature Engineering mulai menyeleksi fitur-fitur yang tersedia pada data untuk kebutuhan pembuatan profil rekomendasi. Data yang telah diproses sampai tahap ini kemudian masuk ke layer Recommender Engine dimana data akan diproses menjadi rekomendasi. Secara garis besar terdapat tiga tahapan proses yang ditangani oleh empat bagian berbeda pada layer ini: (1) Membangun profil artikel dan pengguna Komputer yang digunakan dalam penelitian berspesifikasi CPU Intel Core i7 9750H, RAM 8GB dan SSD 256GB.  Pada proses penelitian menggunakan bahasa pemgoraman Phyton dengan beberapa  library yang terkait dalam topik, karena dalam penelitian menggunakan algoritma matematika menggunakan Library NumPy, dan beberapa library untuk  menangnani natural language Toolkit menggunakan NLTK. Dan dengan Ptyhon sebagai Enverimentnya, Untuk seluruh  daftar perangkat lunak dan pustaka (library) yang digunakan  ada pada tabel  1 di bawah : 
Tabel 1. Daftar Perangkat Lunak  
Nama  Versi  
Windows 11  21H1  
PyCharm Professional  2021.3.1  
Anaconda  2021.11  
Python  3.9 
Beautiful  Soup  4.10.0  
NLTK  3.6.7  
NumPy  1.22.0  
Pandas  1.3.5  
Requests  2.26.0  
Scikit-Learn  1.0.2  
SciPy  1.7.3  
Unidecode  1.3.2  
Pada penelitian ini, layer Recommender Engine diimplementasikan sebagai Package pada bahasa pemrograman  Python. Package ini didesain dengan memanfaatkan prinsip-prinsip dalam paradigma Pemrograman Berorientasi Objek seperti Abstraksi, Enkapsulasi, Pewarisan, dan Polimorfisme seperti ya ng diilustrasikan pada Gambar 3 di bawah.  
Gambar 3. Class Diagram 
Package Sistem Rekomendasi  pada Gambar 3 diatas dapat digunakan secara terpisah tanpa bergantung pada layer-layer dibawahnya. Sumber data lain dapat menggunakan Recommender Engine  ini dengan menyamakan struktur data yang digunakan.  Dalam  dataframe dibuat dalam 2 kolom untuk struktur data artikel dengan 2 variabel ID Artikel dengan data Int dan Fitur Artikel dengna type data string  datapat di lihat pada tabel 2 di bawah.  
Tabel 2. Struktur data artikel  
DataFrame: Artikel  
Column  Type  Deskripsi  
0 Int ID Artikel  
1 String  Fitur Artikel (Judul, Konten, dll)  
Selanjutnya dibutuhkan tabel data Interaksi, yang di buat dalam 3 kolom di mana terdapat ID pengguna, ID artikel serta skor bobot nantinya, lihat tabel 3 di bawah.  
Tabel 3. Struktur data interaksi  
DataFrame: Interaksi Pengguna - Artikel  
Column  Type  Index  Deskripsi  
user_id  Int|String  True  ID Pengguna  
article_id  Int False  ID Artikel  
weight  Float  False  Skor Bobot Interaksi Rata-rata 
Dataset  yang digunakan berasal dari portal berita Kabar Informatika Universitas Amikom Yogyakarta. Dataset  
yang tersedia memiliki fitur cukup lengkap seperti judul, penulis, kategori, dan konten artikel itu sendiri yang sangat mendukung dalam proses pembuatan rekomendasi. Dataset  ini cukup kecil dengan jumlah artikel sebanyak 22 dan jumlah data interaksi artikel sebanyak 345 yang berasal dari 20 pengguna.  

3. HASIL DAN PEMBAHASAN  
Sistem rekomendasi  yang dibuat adalah sistem rekomendasi top-N. Sistem rekomendasi ini akan membuat daftar rekomendasi artikel sebanyak N yang diurutkan berdasarkan seberapa relevan artikel tersebut dengan minat pengguna.  
Algoritma TF-IDF digunakan untuk menemukan kata-kata penting pada setiap  artikel dan dilakukan penilaian pada setiap kata. Proses perancangan sistem rekomendasi ini melalui beberapa tahap. Yang pertama, sumber data akan dikonsumsi melalui REST API yang memberikan data dalam format JSON. Kemudian data tersebut akan melalui tahap pre-processing. Pemrosesan yang ada di tahap ini berupa pembersihan data untuk menghilangkan semua kode formatting HTML yang ada. Setelah itu data akan melalui proses penghapusan stop word untuk meningkatkan efektivitas algoritma TF-IDF yang akan digunakaan.  Kedua, data yang telah melalui tahap pre -processing akan mulai diproses dengan melibatkan algoritma TF-IDF (Term Frequency â€“ Inverse Document Frequency). Algoritma TF-IDF digunakan untuk mencari kata-kata penting 
yang terdapat pada setiap artikel dengan memberikan skor untuk setiap kata. Contohnya jika kata â€œsayaâ€ frekuensi 
kemunculannya sangat tinggi di setiap artikel, maka algoritma ini akan memberikan skor rendah untuk kata tersebut di artikel yang memilikinya karena dianggap sebagai kata umum yang tidak memberikan informasi unik dari artikel. Sebaliknya jika kata â€œdata miningâ€ hanya sering muncul di beberapa artikel, maka algoritma ini akan memberikan skor tinggi. Hasil dari kalkulasi ini akan digunakan sebagai profil dari setiap artikel.  Ketiga adalah konstruksi profil minat pengguna dari data riwayat interaksi. Interaksi artikel yang terekam adalah interaksi membaca (Read), memberikan reaksi seperti menyukai artikel (React), dan membagikan artikel (Share). Masing-masing interaksi memiliki nilai atau bobot yang berbeda. Pada penelitian ini interaksi Read bernilai 1, React bernilai 2, dan Share bernilai 3. hasil uji data untuk riwayat data interaksi pengguna bisa di lihat pada tabel 4 di bawah  
Tabel 4. Sampel data riwayat interaksi pengguna  
user_id  article_id  event  weight  
1 3 SHARE  3 
1 3 COMMENT  2 
1 4 SHARE  3 
1 4 REACT  1 
1 5 SHARE  3 
1 5 COMMENT  2 
1 6 COMMENT  2 
1 6 REACT  1 
1 11 REACT  1 
1 13 COMMENT  2 
1 16 SHARE  3 
1 16 REACT  1 
1 17 REACT  1 
1 18 REACT  1 
1 19 COMMENT  2 
1 19 REACT  1 
1 20 COMMENT  2 
1 21 REACT  1 
Data skor interaksi individu dari setiap artikel akan dijumlahkan dan dirata-rata. Pengguna dapat berinteraksi 
dengan artikel berkali-kali. Karena itu untuk menormalkan data, logaritma natural diaplikasikan ke jumlah total dari 
skor interaksi setiap artikelnya. Hasil dari tahap ini akan memberikan skor akhir ke tiap artikel yang menandakan 
seberapa tertarik pengguna dengan artikel tersebut.hasil dari pengujian  data hasil sampel data riwayat interaksi 
pengguna yang telah di rata rata berdasarkan dari hasil tabel 4 di atas dapat di lihat pada tabel 5 di bawah.  
Tabel 5. Sampel data riwayat interaksi pengguna yang telah  di rata-rata [2]  
user_id  article_id  weight  
1 3 4,584963  
1 4 2,321928  
1 5 2,584963  
1 6 2,000000  
1 11 1,000000  
1 13 1,584963  
1 16 2,321928  
1 17 1,000000  
1 18 1,000000  
1 19 2,000000  
1 20 1,584963  
1 21 1,000000  
Keempat, mencari kesamaan artikel dari profil yang telah dikonstruksi menggunakan Vector Space Model dengan pengukurannya menggunakan formula Cosine Similarity. Secara teknis Cosine Similarity mencari cosinus dari sudut antara dua vektor, semakin mirip arah sudutnya maka semakin mirip kedua vektor tersebut. Vektor dalam hal ini adalah profil artikel, lebih tepatnya data skor dari setiap kata dalam setiap artikel yang merupakan hasil dari kalkulasi TF-IDF.  Dengan menggunakan Cosine Similarity, proses pembuatan rekomendasi dilakukan dengan mencari kemiripan artikel yang tersedia dengan artikel yang pernah berinteraksi dengan pengguna yang terekam dalam data riwayat interaksi.  Yang terakhir, daftar rekomendasi artikel yang dihasilkan pada tahap sebelumnya akan disesuaikan kembali sebelum disajikan kepada pengguna. Pemrosesan seperti cara pengurutan rekomendasi, seberapa banyak artikel yang disajikan, pengecualian artikel yang tidak ingin ditampilkan, dan semua pemrosesan lain yang diperlukan untuk mendukung penyajian rekomendasi akan dilakukan tahap ini.  Berikut ini adalah hasil pengujian sistem dalam pembuatan rekomendasi untuk beberapa pengguna yang berbeda  yaitu pengguna 1 dan pengguna 2, hasil relevance dari pengguna 1 dan pengguna 2 dapa t di lihat pada table 6 dan table 7 di bawah.   
Tabel 6. Hasil rekomendasi untuk pengguna 1  
id title relevance  
5 Tips dan trik jago ngoding bagi pemula  0,510365  
6 Mengenal Programming: Pengertian, Macam -Macam Bahasa Pemrograman, Jenis Profesi dan Manfaatnya  0,471760  
3 Masih Gagal Paham Abstraction  0,405593  
4 Perbedaan antara Front-end, Back-End dan Full-Stack Developper  0,396926  
16 Artificial Intelligence in Business: The Importance & How AI Carries an Impact On Your 
Future...  0,360467  
13 5 Kekurangan Programmer Pemula Jaman Now  0,332750  
19 What is Netiquette? How important is Netiquette? What are the rules of Netiquette?  0,295908  
20 Peluang Freelance Worker, sebagai Masa Depan Zillennial  0,254306  
17 Big Data, Potensi Tambang Emas Masa Depan  0,224291  
11 Zillennials Wajib Tahu, Inilah Startup di Indonesia yang Jadi Primadona Investasi Asia 
Tenggara  0,190918  
Tabel 7. Hasil rekomendasi untuk pengguna 2  
id title relevance  
12 5 Alasan Mengapa Yogyakarta Menjadi Kota Developer -nya Startup  0,483614  
13 5 Kekurangan Programmer Pemula Jaman Now  0,459938  
16 Artificial Intelligence in Business: The Importance &amp
Your Future...  0,433289  
11 Zillennials Wajib Tahu, Inilah Startup di Indonesia yang Jadi Primadona Investasi Asia Tenggara  0,382858  
15 Mendulang Uang dengan Kecerdasan Buatan  0,358070  
1 Membedah Ilmu Informatika Bersama Santri  0,355859  
18 Artificial Intelligence Buatan Petruk, Menggemparkan Karangkadempel  0,336855  
7 Swift Programming : Modular is Better  0,241970  
5 Tips dan trik jago ngoding bagi pemula  0,208354  
9 Simple MVP architecture for iOS App  0,194942  
Proses evaluasi dilakukan menggunakan metrik pengukuran Recall. Cara kerja pengukuran metrik ini adalah dengan mengambiln -sampel artikel yang belum pernah berinteraksi dengan pengguna yang bersangkutan, kemudian meminta sistem rekomendasi yang sudah di-train dengan dataset training untuk membuat daftar rekomendasi top-n namun dengan menghilangkan artikel yang pernah berinteraksi dengan pengguna di dalam training set. Masing-masing artikel dalam data interaksi testing set kemudian digabungkan dengan sampel artikel yang sebelumnya didapatkan. Jika hasil rekomendasi juga merekomendasikan artikel yang berada dalam daftar gabungan artikel yang belum pernah berinteraksi tersebut, maka hasil rekomendasi dianggap Hit atau berhasil.  Tabel 8 dibawah merupakan hasil dari evualuasi dengan matrik recall . 
Tabel 8. Hasil evaluasi dengan metrik Recall  
Pengguna  Total Artikel  Top 5 Hit  Top 10 Hit  Recall 5  Recall 10  
1 2 2 2 1,00 1,00 
2 2 2 2 1,00 1,00 
3 2 1 1 0,50 0,50 
4 2 2 2 1,00 1,00 
5 3 1 2 0,33 0,67 
6 2 1 1 0,50 0,50 
7 3 2 3 0,67 1,00 
8 3 2 2 0,67 0,67 
9 3 3 3 1,00 1,00 
10 2 1 1 0,50 0,50 
11 2 2 2 1,00 1,00 
12 2 1 1 0,50 0,50 
13 3 2 2 0,67 0,67 
14 2 1 1 0,50 0,50 
15 2 2 2 1,00 1,00 
16 2 2 2 1,00 1,00 
17 2 1 1 0,50 0,50 
18 2 2 2 1,00 1,00 
19 2 1 2 0,50 1,00 
20 2 2 2 1,00 1,00 
Global Recall  0,73 0,80 
Hasil  evaluasi menunjukkan metrik Recall@5 memberikan skor  0,73 atau sekitar 73%, kemudian Recall@10 memberikan skor 0,80 atau sekitar 80%. Artinya persentase dari sistem rekomendasi ini memberikan rekomendasi artikel yang relevan dengan pengguna di dalam daftar top 5 sebesar 73% dan dalam daftar top 10 sebesar 8 0%. 

4. KESIMPULAN  
Dengan dataset yang meskipun tidak memiliki banyak item namun memiliki fitur cukup lengkap masih sangat membantu sistem dalam membuat rekomendasi artikel yang sesuai dengan minat pengguna. Hasil evaluasi yang memberikan Recall@5 sekitar 73% dan Recall@10 sekitar 80% menunjukkan sistem dapat memberikan daftar rekomendasi dengan baik dan cukup relevan dengan apa yang pengguna minati. Meskipun demikian, keterbatasan data dapat diatasi dengan menambahkan, menggabungkan, atau menggantinya. Penggantian menjadi lebih mudah dikarenakan mesin rekomendasi yang tidak memiliki dependensi ke dataset yang digunakan.  Tentu masih banyak 
aspek dalam penelitian ini yang dapat ditingkatkan untuk membantu memperbaiki performa dari sistem rekomendasi. Building of Informatics, Technology and Science (BITS)  
Selain dengan meningkatkan kuantitas dari artikel itu sendiri, terdapat banyak hal yang dapat ditingkatkan. Pada aspek tokenization artikel contohnya, token relevansi yang diberikan saat memberikan rekomendasi menunjukkan beberapa kata yang berasal dari potongan kode program yang digunakan dalam artikel.  

REFERENCES   
[1] Pangkalan Data Pendidikan Tinggi, â€œJumlah Mahasiswa Prodi Informatika Universitas Amikom Yogyakarta Tahun 2019 -
2021 berdasarkan Pangkalan Data Pendidikan Tinggi,â€ 2022. [Online]. Available: https://pddikti.kemdikbud.go.id/data_pt/QzJERjg3QzMtMUE0RC00RjFBLTlDREYtNERENEY1NzBDQUE1.  
[2] J. Bobadilla, F. Ortega, A. Hernando, and A. GutiÃ©rrez, â€œRecommender systems survey,â€ Knowledge -Based Syst. , vol. 4 6, pp. 109 â€“132, Jul. 2013.  
[3] A. Gatzioura and M. Sanchez -Marre, â€œA Case -Based Recommendation Approach for Market Basket Data,â€ IEEE Intell. Syst. , vol. 30, no. 1, pp. 20 â€“27, Jan. 2015.  
[4] Y. Wang, N. Stash, L. Aroyo, L. Hollink, and G. Schreiber, â€œSeman tic Relations in Content -based Recommender Systems,â€ Proc. fifth Int. Conf. Knowl. capture , pp. 1 â€“8, 2009.  
[5] Z. Cao, X. Qiao, S. Jiang, and X. Zhang, â€œAn efficient knowledge -graph -basedweb service recommendation algorithm,â€ Symmetry (Basel). , vol. 11, no . 3, 2019.  
[6] X. Kong, M. Mao, W. Wang, J. Liu, and B. Xu, â€œVOPRec: Vector Representation Learning of Papers with Text Information and Structural Identity for Recommendation,â€ IEEE Trans. Emerg. Top. Comput. , vol. 9, no. 1, pp. 226 â€“237, Jan. 2021.  
[7] V. Setty and K. Hose, â€œEvent2Vec: Neural embeddings for news events,â€ 41st Int. ACM SIGIR Conf. Res. Dev. Inf. 
Retrieval, SIGIR 2018 , pp. 1013 â€“1016, 2018.  
[8] K. Shah, A. Salunke, S. Dongare, and K. Antala, â€œRecommender systems: An overview of different appro aches to recommendations,â€ in 2017 International Conference on Innovations in Information, Embedded and Communication Systems (ICIIECS) , 2017, pp. 1 â€“4. 
[9] S. Kanwal, S. Nawaz, M. K. Malik, and Z. Nawaz, â€œA Review of Text -Based Recommendation Systems,â€ IEEE Access , vol. 9, pp. 31638 â€“31661, 2021.  
[10] S. Gupta, â€œA Literature Review on Recommendation Systems,â€ Int. Res. J. Eng. Technol. , 2020.  
[11] F. Ricci, L. Rokach, and B. Shapira, Recommender System handbook . 2011.  
[12] S. Informatika and A. Polinema, â€œImplementasi Metode Dice Similarity Dalam Perancangan Sistem Rekomendasi Artikel 
Berita,â€ Siap) , p. 2020, 2020.  
[13] A. S. Dharma, R. B. Basadena, A. Hutasoit, and R. R. Pangaribuan, â€œSistem Rekomendasi Menggunakan Item -based 
Collaborative Filtering pada Konten Artikel Berita,â€ Jurnaltio , vol. 02, no. 01, 2021.  
[14] M. Widya Ningrum dan, â€œImplicit Social Trust Dan Support Vector Regression Untuk Sistem Rekomendasi Berita Implicit Social Trust and Support Vector Regression fo r News Recommender System,â€ vol. 3, no. 2, 2017.  
[15] N. K. Widyasanti, I. K. G. Darma Putra, and N. K. Dwi Rusjayanthi, â€œSeleksi Fitur Bobot Kata dengan Metode TFIDF untuk Ringkasan Bahasa Indonesia,â€ J. Ilm. Merpati (Menara Penelit. Akad. Teknol. Informa si), vol. 6, no. 2, p. 119, 2018.  
[16] S. N. M. Pavan Kumar P., S.Vairachilai, Sirisha Potluri, Recommender Systems Algorithms And Applications . Oxon: CRC Press, 2021.  
[17] A. Masdalena et al. , â€œImplementasi Metode Analytical Hierarchy Process Pada Sistem Pendukung Keputusan Rekomendasi Ikan Budidaya Berbasis Web,â€ vol. 4, no. 2, pp. 663 â€“673, 2022.  
[18] S. Athalye, â€œRecommendation System for News Reader Recommendation System for News Reader A Project Presented to 
The Faculty of the Department of Computer Sc ience San Jose State University In Partial Fulfillment Of the Requirements 
for the Degree Master of Science By S,â€ 2013.  
[19] M. D. Buhmann, Encyclopedia of Machine Learning and Data Mining . 2017.  
[20] E. T. Arifin, â€œPrediction Retweet Using User -Based and  Content-Based with ANN -GA Classification Method,â€ vol. 4, no. 2, pp. 522 â€“528, 2022.  
[21] M. Das, S. Kamalanathan, and P. Alphonse, â€œA Comparative Study on TF -IDF feature weighting method and its analysis using unstructured dataset,â€ CEUR Workshop Proc. , vol. 2870, pp. 98 â€“107, 2021.  
[22] Z. Zhu, J. Liang, D. Li, H. Yu, and G. Liu, â€œHot Topic Detection Based on a Refined TF -IDF Algorithm,â€ IEEE Access , vol. 7, pp. 26996 â€“27007, 2019.  
[23] J. Beel, B. Gipp, S. Langer, and C. Breitinger, â€œResearch -paper recomme nder systems: a literature survey,â€ Int. J. Digit. Libr. , vol. 17, no. 4, pp. 305 â€“338, Nov. 2016.  
[24] K. Falk, Practical Reommender Systems . Shelter Island, NY: Manning Publications Co., 2019.  
[25] I. G. Anugrah, â€œPenerapan Metode N -Gram dan Cosine Simila rity Dalam Pencarian Pada Repositori Artikel Jurnal 
Publikasi,â€ Build. Informatics, Technol. Sci. , vol. 3, no. 3, pp. 275 â€“284, 2021.",sistem rekomendasi,"TF-IDF, Vector Similarity","portal berita kabar Informatika Universitas Amikom,Yogyakarta",recall